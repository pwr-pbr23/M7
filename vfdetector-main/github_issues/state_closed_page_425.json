[{"number": 41135, "title": "Possible bug(?): tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor X>]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): >= 2.0\r\n- Python version: 3.6\r\n- Running on: CPUs (But I guess it happens on GPUs as well)\r\n\r\nThe following issue is very similar to this [one](https://github.com/tensorflow/tensorflow/issues/41111) I posted before. The difference here is that I use eager execution in the code and it produces an error of Keras symbolic tensors. To be fair I am not sure this is a bug or the error is on purpose. Here is the code to produce the error:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\nimport numpy as np\r\n\r\nclass MyWordEmbedding(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyWordEmbedding, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')\r\n        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end\r\n    \r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])\r\n\r\nclass EncoderLayer(tf.keras.layers.Layer):\r\n    def __init__(self, mask_para, **kwargs):\r\n        self.mask_para = mask_para\r\n        super(EncoderLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))\r\n        super(EncoderLayer, self).build(input_shape)\r\n\r\n    def call(self, x):\r\n        Qoutput = tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Koutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Voutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        a = tf.einsum('ajk,afk->ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(self.mask_para, axis=1), [1, 64, 1])\r\n        a = tf.matmul(a, Voutput)\r\n        print(a)\r\n        return a\r\n\r\n    def compute_mask(self, inputs, mask):\r\n        return mask\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\ndef create_encoder_model():\r\n    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = MyWordEmbedding()([word_ids_fr])\r\n    a = EncoderLayer(K.cast(K.not_equal(0, word_ids_fr), dtype='float32'))([a])\r\n    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)\r\n    return model\r\n\r\ndef create_model():\r\n    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = tf.keras.layers.Input(shape=(None, 512,))\r\n    b = MyWordEmbedding()([word_ids_en])\r\n    b = b + a\r\n    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)\r\n    return model\r\n    \r\ndef evaluate():\r\n    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')\r\n    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)\r\n\r\ndecoder_model = create_model()\r\nencoder_model = create_encoder_model()\r\nevaluate()\r\n```\r\n\r\nError:\r\n\r\n`tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'MatMul:0' shape=(3, 64, 512) dtype=float32>]`\r\n\r\nMeanwhile, I also provide a way to fix this as follows (just a simple modification):\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\nimport numpy as np\r\n\r\nclass MyWordEmbedding(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyWordEmbedding, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')\r\n        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end\r\n    \r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])\r\n\r\nclass EncoderLayer(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(EncoderLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))\r\n        super(EncoderLayer, self).build(input_shape)\r\n\r\n    def call(self, x):\r\n        mask_para = x[1]\r\n        Qoutput = tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Koutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Voutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        a = tf.einsum('ajk,afk->ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(mask_para, axis=1), [1, 64, 1])\r\n        a = tf.matmul(a, Voutput)\r\n        print(a)\r\n        return a\r\n\r\n    def compute_mask(self, inputs, mask):\r\n        return mask\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\ndef create_encoder_model():\r\n    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = MyWordEmbedding()([word_ids_fr])\r\n    a = EncoderLayer()([a, K.cast(K.not_equal(0, word_ids_fr), dtype='float32')])\r\n    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)\r\n    return model\r\n\r\ndef create_model():\r\n    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = tf.keras.layers.Input(shape=(None, 512,))\r\n    b = MyWordEmbedding()([word_ids_en])\r\n    b = b + a\r\n    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)\r\n    return model\r\n    \r\ndef evaluate():\r\n    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')\r\n    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)\r\n\r\ndecoder_model = create_model()\r\nencoder_model = create_encoder_model()\r\nevaluate()\r\n```\r\n", "comments": ["@hoangcuong2011 \r\n\r\nI have tried in colab with TF version 2.2, nightly versions and i am seeing the error message`(AttributeError: 'Tensor' object has no attribute '_datatype_enum'`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/7e2356466b56bc3dcb896afcab13cb76/untitled90.ipynb).Thanks!", "@ravikyram: Interesting. If you run it with TF 2.0, you got a different error - the one that I reported (see the gist [here](https://colab.research.google.com/drive/1LfiWeoYiWtGK8pjuG9xHOKfxdVDInPqp?usp=sharing))\r\nin any case this is very likely a bug. Any thoughts on this?", "I have a same problem, but runs well without BiLSTM:\r\n[https://github.com/AlucardNosferatu/LostXmas/issues/2#issue-658065152](https://github.com/AlucardNosferatu/LostXmas/issues/2#issue-658065152)", "> I have a same problem, but runs well without BiLSTM:\r\n> [AlucardNosferatu/LostXmas#2 (comment)](https://github.com/AlucardNosferatu/LostXmas/issues/2#issue-658065152)\r\n\r\nSolved", "Re-assigning to someone who's more familiar with Keras tensors.", "Hi @hoangcuong2011 \r\nThis unfortunately isn't the most helpful of error messages, but it is behaving as expected.\r\n\r\nKeras symbolic tensors cannot be passed to a layer's constructor, it is only valid to pass them into a layer's __call__. Your first example passes the symbolic tensors to the constructor and tries to use them, raising the error message. Your second example makes sure to pass all symbolic tensors as arguments to the layer calls, so it works.\r\n\r\nWe can look into trying to provide a more meaningful error message for this in the future once an upcoming refactoring of the internals lands.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41135\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41135\">No</a>\n", "@tomerk Thanks. I did not know that we should not pass Keras symbolic tensors to a layer's constructor? May I know why it is designed that way? (Why we should the tensor to a layer's call instead of constructor?)", "Hi @hoangcuong2011 , it's this way because models contain layer objects that they reuse, rather than re-creating the layers each time you call the model. These layers may get called in different settings (individually, as part of the larger model, in a tf.function, totally eagerly, etc.\r\n\r\nWe can handle Functional model definition via layer calls because we define `__call__` in Keras and have users just override `call`. So, we can track a variety of metadata under the hood. We use this metadata whenever you call the constructed model to get the model working in the above settings. (e.g. we keep track of what partially-created values need to be forwarded to what)\r\n\r\nBut, arbitrary layer constructors for custom layers don't give us the same ability to track model structure metadata. Arguably there's maybe stuff we could do with python's `__new__` in certain circumstances, but it would be very unreliable and would make for a poor user experience. So, it's the most straightforward to disallow it altogether.\r\n\r\nIt's generally fairly easy to make sure a layer takes all tensor inputs directly in `call` as opposed to in the constructor.\r\n", "@tomerk  Your answer is thoughtful and helpful to me. Thank you!"]}, {"number": 41134, "title": "Error with instalation of Tensorflow", "body": "\r\n**System information**\r\n- OS Platform and Distribution : Ubuntu 20.04\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.7.0\r\n- Installed using : pip\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: CPU\r\n\r\n\r\n\r\n**Describe the problem**\r\n   I am trying to install tensorflow via terminal in PyCharm, cant really use any other version of python or tensorflow cause my old  CPU. This is my last resort any newer version of tensorflow crashes immediately. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n        pip3 install tensorflow==1.15.0\r\n\r\n\r\n**Any other info / logs**\r\n ```\r\npip3 install tensorflow==1.15.0\r\nDefaulting to user installation because normal site-packages is not writeable\r\nCollecting tensorflow==1.15.0\r\n  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 412.3 MB 21 kB/s \r\nCollecting six>=1.10.0\r\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\nCollecting wrapt>=1.11.1\r\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /usr/local/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-v5_uvp33/wrapt/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-v5_uvp33/wrapt/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-gahhrkjb\r\n         cwd: /tmp/pip-install-v5_uvp33/wrapt/\r\n    Complete output (11 lines):\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/usr/local/lib/python3.7/site-packages/setuptools/__init__.py\", line 23, in <module>\r\n        from setuptools.dist import Distribution\r\n      File \"/usr/local/lib/python3.7/site-packages/setuptools/dist.py\", line 34, in <module>\r\n        from setuptools import windows_support\r\n      File \"/usr/local/lib/python3.7/site-packages/setuptools/windows_support.py\", line 2, in <module>\r\n        import ctypes\r\n      File \"/usr/local/lib/python3.7/ctypes/__init__.py\", line 7, in <module>\r\n        from _ctypes import Union, Structure, Array\r\n    ModuleNotFoundError: No module named '_ctypes'\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n\r\n```", "comments": ["So the problem is with the wrapt package, still dont know how to fix that.", "This is not a TF issue, recommend asking on StackOverflow.\r\n\r\nYou can try pinning down the dependency of `wrapt` you are installing (`pip install wrapt=... tensorflow=..`)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41134\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41134\">No</a>\n"]}, {"number": 41133, "title": "[TF/MLIR] Graph pruning / canonicalization pass doesn't eliminate some dead constant nodes", "body": "This is with the tensorflow trunk at e13ff2da43ab00dba94dd00d87a876b2a03f48e7 (Jul 6). \r\n\r\nThis is a reduced test case where both nodes/operations in the graph are supposed to be dead (results unused and not side-effecting), but neither the `-tf-executor-graph-pruning` nor the `-canonicalize` pass gets rid of them. However, if one of them is removed, `-canonicalize` is able to eliminate the other. Similar patterns are often DCE'd by `-tf-executor-graph-pruning` in the presence of other larger islands. \r\n\r\n```\r\nmodule {\r\n  func @main() attributes {tf.entry_function = {control_outputs = \"\", inputs = \"\", outputs = \"\"}} {\r\n    tf_executor.graph {\r\n      %outputs, %control = tf_executor.island wraps \"tf.Const\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n      %outputs_0, %control_1 = tf_executor.island wraps \"tf.Const\"() {value = dense<100> : tensor<1xi32>} : () -> tensor<1xi32>\r\n      tf_executor.fetch\r\n    }\r\n    return\r\n  }\r\n}\r\n```\r\nTo reproduce, run:\r\n```\r\n$ tf-opt -tf-executor-graph-pruning -canonicalize test_case.mlir\r\n```\r\n\r\nOS: CentOS 8 x86-64.\r\nTF built from sources with GCC 8.3.1 and with --linkopt='-fuse-ld=lld'. \r\n\r\n", "comments": ["Because if you import a graphdef without any fetch the pruning would just eliminate the entire graph, we rather not do anything: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/transforms/graph_pruning.cc#L90-L94", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41133\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41133\">No</a>\n", "On a narrow note, why would it be incorrect to eliminate everything here? Not having a fetch is still defined behavior, right? (I'm thinking about the multiple functions case - one of them could just be empty and completely removed. )", "It'd may be correct for a tf function that does not return anything, but at the same time we're trying to move away from the executor dialect for TF2 and functions.", "> It'd may be correct for a tf function that does not return anything, but at the same time we're trying to move away from the executor dialect for TF2 and functions.\r\n\r\nI see. What would the new entry point then be when converting/importing from TF Graphdef?\r\n", "Mainly SavedModel I think for loading from file. \r\nWhen running online we're working on having the tracing `tf.function` directly build MLIR in the first place without going through the Graph data structure.", "Please do keep the translation to tf.executor (`convert_graph_def` python binding) until the in-memory replacement (tracing `tf.function`) is available. Thanks!", "SavedModel are style storing GraphDef (and will continue for a while): so the conversion to tf.executor will stay there for a while!\r\n"]}, {"number": 41132, "title": "Docker with GPU 2.3rc0 CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid", "body": "It seem that the Docker image tensorflow/tensorflow:2.3.0rc0-gpu won't work with my GPU   **BUT** on the other hand the image tensorflow/tensorflow:2.2.0rc0-gpu works fine\r\n\r\nOr in other words, the solution to the present issue was to \"downgrade\" to  tensorflow/tensorflow:2.2.0rc0-gpu\r\ntensorflow/tensorflow:2.3.0rc0-gpu also works fine with CPU only.\r\n\r\n **System information**\r\n- Ubuntu 20.4\r\n- TensorFlow through Docker\r\n- TensorFlow version (use command below):\r\n- GPU model and memory: Geforce GTX 960M, coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\r\n- GPU drivers: 440.100\r\n\r\n\r\n**how to reproduce**\r\n``` \r\n> docker run -it --rm --gpus all  --entrypoint bash tensorflow/tensorflow:2.3.0rc0-gpu\r\n> python\r\n>>> import tensorflow as tf\r\n>>> inputs = tf.keras.layers.Input(shape=(None,), name=\"input\")\r\n>>> embedded = tf.keras.layers.Embedding(100, 16)(inputs)\r\n```\r\n**full stack trace:**\r\n```\r\n2020-07-06 18:46:55.604377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-07-06 18:46:55.608404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.608911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-07-06 18:46:55.608943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-06 18:46:55.610544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-06 18:46:55.611696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-06 18:46:55.611988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-06 18:46:55.613589: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-06 18:46:55.614478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-06 18:46:55.618025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-06 18:46:55.618159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.618734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.619206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-07-06 18:46:55.619480: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-07-06 18:46:55.643133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2693910000 Hz\r\n2020-07-06 18:46:55.643781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44161a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 18:46:55.643809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-07-06 18:46:55.725002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.725324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44aa610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 18:46:55.725349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0\r\n2020-07-06 18:46:55.725532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.725767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-07-06 18:46:55.725796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-06 18:46:55.725828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-06 18:46:55.725854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-06 18:46:55.725882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-06 18:46:55.725908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-06 18:46:55.725938: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-06 18:46:55.725988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-06 18:46:55.726091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.726485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-06 18:46:55.726724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-07-06 18:46:55.726756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 926, in __call__\r\n    input_list)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1098, in _functional_construction_call\r\n    self._maybe_build(inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 2643, in _maybe_build\r\n    self.build(input_shapes)  # pylint:disable=not-callable\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 323, in wrapper\r\n    output_shape = fn(instance, input_shape)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/embeddings.py\", line 135, in build\r\n    if (context.executing_eagerly() and context.context().num_gpus() and\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 1082, in num_gpus\r\n    self.ensure_initialized()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n```\r\n", "comments": ["Hmm... doesn't have trouble on my machine in the same container. Thanks a bunch for the exact replication commands.\r\n\r\n```\r\nroot@7b03d7e48af6:/# python\r\nPython 3.6.9 (default, Apr 18 2020, 01:56:04) \r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-07-06 21:27:04.584594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n>>> inputs = tf.keras.layers.Input(shape=(None,), name=\"input\")\r\n>>> embedded = tf.keras.layers.Embedding(100, 16)(inputs)\r\n2020-07-06 21:27:18.540476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-07-06 21:27:18.569953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:18:00.0 name: Quadro P1000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 5 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-07-06 21:27:18.570001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-06 21:27:18.985818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-06 21:27:19.579217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-06 21:27:19.836486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-06 21:27:20.597542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-06 21:27:21.103251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-06 21:27:22.960095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-06 21:27:22.960782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-07-06 21:27:22.961151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-07-06 21:27:23.000149: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3000000000 Hz\r\n2020-07-06 21:27:23.012170: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45be680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 21:27:23.012215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-07-06 21:27:23.113028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x462a940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 21:27:23.113113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\r\n2020-07-06 21:27:23.114100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:18:00.0 name: Quadro P1000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 5 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-07-06 21:27:23.114167: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-06 21:27:23.114213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-06 21:27:23.114240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-06 21:27:23.114267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-06 21:27:23.114293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-06 21:27:23.114317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-06 21:27:23.114344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-06 21:27:23.115591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-07-06 21:27:23.115649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-06 21:27:23.790561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-07-06 21:27:23.790610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-07-06 21:27:23.790617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-07-06 21:27:23.791319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: Quadro P1000, pci bus id: 0000:18:00.0, compute capability: 6.1)\r\n>>> \r\nroot@7b03d7e48af6:/# nvidia-smi\r\nMon Jul  6 21:28:02 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.34       Driver Version: 430.34       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro P1000        Off  | 00000000:18:00.0  On |                  N/A |\r\n| 34%   36C    P0    N/A /  N/A |    223MiB /  4037MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\nroot@7b03d7e48af6:/# \r\n```\r\n\r\nCan you include the output of `nvidia-smi`? This could be a case of ~~old drivers on your host machine~~ (440... could it be too new?), an issue with compute capabilities, or something else.", "Sure, here it is.\r\n440.100 and CUDA 10.2 seem to be the default on Ubuntu 20.04 (fresh install).\r\n\r\n``` \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 960M    Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   56C    P0    N/A /  N/A |      0MiB /  2004MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n``` \r\nSince it is mentioned in the TF docs that [the NVIDIA\u00ae CUDA\u00ae Toolkit does not need to be installed](https://www.tensorflow.org/install/docker) I thought that the CUDA version on the host machine would not matter. \r\nI also get the same behaviour as you with tensorflow/tensorflow:2.2.0rc0-gpu on the same machine.\r\n", "CUDA Compute Capability is inherent to your graphics card. There were some size-reduction changes to our binaries in 2.3 that adjusted handling of old capabilities (such as 5.0), but I believe TensorFlow 2.3 should still support capabilities as old as 3.5.\r\n\r\nCan you try to replicate this outside of a Docker container to see if it's related to your graphics card vs. the container environment?\r\n\r\nFYI @chsigg \r\n ", "We removed PTX for all but sm_70 from TF builds in cf1b6b3dfe9ba82e805fddf7f4462b2d92fe550a. We never shipped with kernels for sm_50, only sm_52. Apparently the driver was able to compile PTX for sm_52 to sm_50, even though it's not officially supported.\r\n\r\nIf you want to run on a sm_50 card, it would be best to build TF from source.", "Forgive my ignorance here, but with the change on cf1b6b3, I don't see `sm_70`, `sm_75`, or `compute_75` listed in the compute capabilities. Would a GPU (the Tesla T4 in our case) at compute_75 have a similar problem here?", "No, the driver will be able to JIT `compute_70` and use it for any compute capabilities 7.x.\r\nthe startup may be slow, but it will work.", "I believe `compute_70` implies `sm_70` so we should not need to JIT PTX for T4, V100.  @chsigg Is this correct?\r\n\r\n(It would indeed be a problem if we have to JIT for V100 since that would add startup latency for a popular GPU.)\r\n\r\nEdit: see https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda_configure.bzl.", "Actually, I have same error message after I run bazel tests with gpu benchmarks.\r\nSystem info:\r\n\r\nSystem: Ubuntu 18.04\r\nTensorflow version: 2.4.0-dev20200710\r\nGPU: 2 x Tesla V100\r\nDriver Version: 450.51.05    \r\nCUDA Version: 10.1.243, https://www.tensorflow.org/install/gpu#install_cuda_with_apt (Ubuntu 18.04, CUDA 10.1)\r\nBazel: 3.1.0 and 3.3.1\r\n\r\nInput:\r\n`bazel run --config=cuda -c opt --copt=\"-mavx\" eager_microbenchmarks_test -- --benchmarks=. `\r\nOutput:\r\n``` Starting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=0 --terminal_columns=80\r\nINFO: Reading rc options for 'run' from /home/xingyulong/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'run' from /home/xingyulong/tensorflow/.bazelrc:\r\n  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Found applicable config definition build:v2 in file /home/xingyulong/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:cuda in file /home/xingyulong/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file /home/xingyulong/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain\r\nINFO: Found applicable config definition build:linux in file /home/xingyulong/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/xingyulong/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nDEBUG: /home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5:\r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (1 packages loaded, 0 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (12 packages loaded, 14 targets configured)\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (21 packages loaded, 35 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (85 packages loaded, 902 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (118 packages loaded, 1030 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (222 packages loaded, 5895 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (287 packages loaded, 8881 targets configured)\r\nWARNING: /home/xingyulong/tensorflow/tensorflow/core/BUILD:1750:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\r\nWARNING: /home/xingyulong/tensorflow/tensorflow/core/BUILD:1775:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_headers_for_pybind: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\r\nWARNING: /home/xingyulong/tensorflow/tensorflow/core/BUILD:2162:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (306 packages loaded, 14342 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (348 packages loaded, 19532 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (351 packages loaded, 19917 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (356 packages loaded, 23062 targets configured)\r\nAnalyzing: target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (357 packages loaded, 23062 targets configured)\r\nWARNING: /home/xingyulong/tensorflow/tensorflow/python/BUILD:4667:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /home/xingyulong/tensorflow/tensorflow/python/BUILD:115:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nINFO: Analyzed target //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test (361 packages loaded, 30598 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/sandbox\r\n[0 / 226] [Prepa] BazelWorkspaceStatusAction stable-status.txt ... (2 actions, 0 running)\r\n7,264 / 9,082] [Prepa] Writing file tensorflow/core/kernels/data/experimental/libignore_errors_dataset_op.pic.lo-2.params [for host]\r\n[15,392 / 17,385] Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation [for host]; 1s local\r\n[22,092 / 23,859] Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation; 1s local ... (2 actions running)\r\n[30,382 / 30,594] [Prepa] Writing file tensorflow/python/gen_user_ops_py_wrappers_cc-2.params\r\nINFO: From Executing genrule //tensorflow/python/keras/api:keras_python_api_gen:\r\n2020-07-10 18:11:35.652291: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nINFO: From Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2:\r\n2020-07-10 18:11:35.652292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nINFO: From Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1:\r\n2020-07-10 18:11:35.862417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nINFO: From Executing genrule //tensorflow:tf_python_api_gen_v2:\r\n2020-07-10 18:11:35.859993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTarget //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test up-to-date:\r\n  bazel-bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test\r\nINFO: Elapsed time: 58.937s, Critical Path: 14.14s\r\nINFO: 17 processes: 17 local.\r\nINFO: Build completed successfully, 4672 total actions\r\nINFO: Running command line: external/bazel_tools/tools/test/test-setup.sh tensorflow/python/keras/benchmarks/eager_microbenchmarks_test '--benchmarks=.'\r\nINFO: Build completed successfully, 4672 total actions\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/python/keras/benchmarks:eager_microbenchmarks_test\r\n-----------------------------------------------------------------------------\r\n2020-07-10 18:11:41.266346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-10 18:11:42.762645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-07-10 18:11:42.840961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.841808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-07-10 18:11:42.841953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.842708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-07-10 18:11:42.842750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-10 18:11:42.844793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-10 18:11:42.846855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-10 18:11:42.847239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-10 18:11:42.849488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-10 18:11:42.850725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-10 18:11:42.850894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-07-10 18:11:42.851032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.851964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.852842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.853678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:42.854423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-07-10 18:11:42.854812: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-07-10 18:11:43.309452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.310269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-07-10 18:11:43.310402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.311151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-07-10 18:11:43.311184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-10 18:11:43.311210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-10 18:11:43.311224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-10 18:11:43.311234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-10 18:11:43.311244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-10 18:11:43.311254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-10 18:11:43.311262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-07-10 18:11:43.311347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.312197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.313078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.313907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-07-10 18:11:43.314671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-07-10 18:11:43.314714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.py\", line 326, in <module>\r\n    test.main()\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 58, in main\r\n    return _googletest.main(argv)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 66, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 476, in benchmarks_main\r\n    app.run(lambda _: _run_benchmarks(regex), argv=argv)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/absl_py/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/absl_py/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\nFile \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 66, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 476, in benchmarks_main\r\n    app.run(lambda _: _run_benchmarks(regex), argv=argv)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/absl_py/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/absl_py/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 476, in <lambda>\r\n    app.run(lambda _: _run_benchmarks(regex), argv=argv)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 456, in _run_benchmarks\r\n    instance_benchmark_fn()\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.py\", line 156, in benchmark_layers_advanced_activations_elu_overhead\r\n    x = tf.ones((1, 1))\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/ops/array_ops.py\", line 3068, in ones\r\n    tensor_shape.TensorShape(shape))\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py\", line 373, in _tensor_shape_tensor_conversion_function\r\n    return constant(s_list, dtype=dtype, name=name)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/home/xingyulong/.cache/bazel/_bazel_root/3240dade0c8746999ed99d7076f401e9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 549, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n``` \r\n\r\nBut, when I run models instead of running bazel test, it works fine.", "> when I run models\r\n\r\nAre you running these models also using a TF built from source, or are you running them using a pip installed binary?", "> > when I run models\r\n> \r\n> Are you running these models also using a TF built from source, or are you running them using a pip installed binary?\r\n\r\nI think it should be pip installed binary.\r\n```\r\nimport tensorflow as tf\r\n\r\ninputs = tf.keras.xxxxx\r\nxxxxx\r\n```", "> I think it should be pip installed binary.\r\n\r\nOk, so that could explain the discrepancy -- the TF binary you built for tests probably does not include sm_70 or compute_70.\r\n\r\nCan you grep for `TF_CUDA_COMPUTE_CAPABILITIES` in `.tf_configure.bazelrc` and share what you find there?", "> Can you grep for `TF_CUDA_COMPUTE_CAPABILITIES` in `.tf_configure.bazelrc` and share what you find there?\r\n\r\nI searched `.tf_configure.bazelrc` in my tensorflow folder, it's not exist.\r\n\r\nLet me clear my environment, I used pip to install tensorflow and download current tensorflow repo to run the bazel tests on `tensorflow/tensorflow/python/keras/benchmarks/eager_microbenchmarks_test.py` and found the error msg like I posted and it works fine when I was training model.", "It works for me after run `./configure` in TF folder.", "Hi all, I'm running into the same issue here. Both the Docker installation of Tensorflow and the local pip installation are giving me the same error:\r\n\r\n__tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid__\r\n\r\n__System information__\r\n\r\n- Ubuntu 16.04\r\n- TensorFlow through Docker, local TF installation with pip.\r\n- TensorFlow version: 2.3.0\r\n- GPU model and memory: Quadro M1000M coreClock: 1.0715 GHz coreCount: 4, deviceMemorySize: 3.95 GiB deviceMemoryBandwidth: 74.65GiB/s\r\n- computeCapability: 5.0\r\n- GPU drivers: 418.87.00\r\n- CUDA version: 10.1\r\n- cudNN version: 7.6.5\r\n\r\nI was able to reproduce this error in the docker container using the steps listed above, but also just following the steps listed [here](https://www.tensorflow.org/guide/gpu) lead to the same error. The GPU is detected ok using `tf.config.experimental.list_physical_devices('GPU')` but as soon as I try to define the `tf.constant` it fails immediately.\r\n\r\n2.2.0 works fine without any issues - both locally and through Docker.\r\n\r\n", "@navganti PTAL here https://github.com/tensorflow/tensorflow/issues/41892#issuecomment-667452483.", "@sanjoy I see! Thank you for the update.", "I'm seeing this error when I try to call TF_LoadSessionFromSavedModel (C API). It works correctly via the non-GPU docker image, but fails with the GPU docker image with the following error:\r\n\r\nCUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\nI'm using the latest docker image, i.e., tensorflow/tensorflow:latest-gpu built on 7/28/20.\r\nMy copy of the C API was downloaded a few days ago: libtensorflow-gpu-linux-x86_64-2.3.0\r\nMy GPU is a mobile Nvidia Geforce GTX 1660 Ti.\r\nNvidia driver version: 440.100\r\nCUDA version 10.2\r\nAccording to Wikipedia, my graphics chip has CUDA compute capability version 7.5, which seems to be the latest version of any chip that has been released, so I'm pretty sure the problem isn't my chip's CUDA capability.", "CUDA 10.1 and CUDNN 7.4 and 7.5 is failed. (TF 2.3)\r\nshould I try CUDA version 10.2?", "@motrek TF 2.3 should indeed work on compute capability 7.5.  However [this](https://forums.developer.nvidia.com/t/compute-capability/110091/5) suggests that it lacks tensor cores, it is possible that's why you get the error.", "@sanjoy You're right, the chip (1660 Ti) absolutely does lack Tensor Cores, but that shouldn't be a problem at all. No GTX chip has tensor cores either and the C API works fine on those.\r\n\r\nAlso, training via Python is GPU-accelerated on my laptop with this chip.\r\n\r\nIt's just the C API that's giving me this \"device kernel image is invalid\" error, which is clearly a bug somewhere. :(", "Hi everyone,\r\n\r\nTF nightly starting from the latest nightly build as of now should include SASS for compute capability 5.0, so it should work on GPUs like GeForce GTX 960M.  Please give it a try and let us know how it goes!", "@sanjoy I downloaded the nightly docker image but it seems to require CUDA 11. I'm not sure I'm prepared to switch to CUDA 11 yet... from a few cursory web searches, it seems like a lot of people are having a lot of problems with it.\r\n\r\nBut please note that my problem is that the C API isn't working (\"device kernel image is invalid\") and it's nothing to do with earlier versions of compute capability.\r\n\r\nI have a GTX 1660 Ti, which has compute capability 7.5.", "@motrek Actually I don't really understand of what is going on in your case (my previous message was mainly for folks running on GPUs with compute capability 5.0) since, as you've observed above, TF should work fine on compute capability 7.5.\r\n\r\nBtw, how are you using the docker images?  If you're using the ones listed at https://www.tensorflow.org/install/docker then you should only need a recent enough GPU driver on your host system.", "@sanjoy I've installed the \"latest-gpu\" docker image from that web page on my Ubuntu system.\r\n\r\nGPU acceleration works well when I do training via a Python script.\r\n\r\nBut I also want to do inference via the C API.\r\n\r\nI installed the C API library within my docker container via this page:\r\nhttps://www.tensorflow.org/install/lang_c\r\n\r\nBut when I call TF_LoadSessionFromSavedModel, it gives me the \"device kernel image is invalid\" message.\r\n\r\nIf you can help me with this, I would really appreciate it.", "@mihaimaruseac Could @motrek's issue indicate a bug in how we build libtensorflow.so?  I don't see the CUDA capabilities being configured [here](https://github.com/tensorflow/tensorflow/blob/0f1b6731b9369450ef5a6c2ad850d0fae788e92b/tensorflow/tools/ci_build/builds/libtensorflow.sh#L74).\r\n\r\nCC @angerson ", "Hmm, I don't recall having a distinction between building with or without GPU support for libtensorflow.so.", "@mihaimaruseac On this page:\r\n\r\nhttps://www.tensorflow.org/install/lang_c\r\n\r\nThere are two different versions of the C API library, one for CPU and one for GPU. The one for GPU is about twice the size as the CPU one. So there must be a difference somewhere.\r\n\r\nOn my system, I have also installed the docker image for TF without GPU support, and the C API library without GPU support, and this works fine with my code.", "Oh, you are right, I missed that.\r\n\r\nThen it seems we have a bug in the GPU CI.", "@mihaimaruseac If there's anything I can do to help debug this situation, please let me know! I am eager to get inference working with GPU support for my project.", "FYI @av8ramit, who IIRC set up the libtensorflow builds.\r\n\r\nOur GPU libtensorflow builds use the default configure setting, revealed by our internal `tensorflow/release/ubuntu_16/libtensorflow/gpu/nightly` job):\r\n\r\n```\r\n --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.0,6.0,6.0,6.0 \r\n```", "@angerson It seems there are two problems being discussed on this thread.\r\n\r\nOne is that some people have older graphics cards with compute capability < 6.0.\r\n\r\nThe problem I'm seeing isn't that, since my chip (1660 Ti) has compute capability 7.5.\r\n\r\nOne thing about the 1660 Ti is that it's a Turing chip but its Tensor Cores either don't exist or aren't enabled, so maybe that's tripping up TensorFlow somehow, if something in TensorFlow assumes that all Turing chips have Tensor Cores?", "@angerson I'll send a fix internally that matches the pip package config.", "I have a commit that should fix this. I'll keep monitoring to see if there are any other issues.", "@av8ramit Very sorry, I'm new to all of this. Will the fix eventually be available in the \"latest\" docker image and the C API libraries that are posted to the web page that I linked to (above)? Do you have any idea when that might happen? Thanks in advance.", "Hello @motrek I'll trigger a new push to [GCS](https://storage.googleapis.com/libtensorflow-nightly). Hopefully this next one or by tomorrow's version we can have something working. ", "Unfortunately it appears my change did not work, digging into why today.", "We're seeing the same issue as @motrek :\r\nWe can train a model using tf.keras without a problem.\r\n\r\nThen on the same system using `TF_LoadSessionFromSavedModel` from the C API and libtensorflow installed from https://www.tensorflow.org/install/lang_c we get\r\n`CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid`\r\n\r\nIf I hack our C++ application to link against `_pywrap_tensorflow_internal.so` instead then it seems to work. Although that's not a long term solution since the pywrap lib is considerably larger and we would also have to link our application against python.\r\n\r\nOS: Ubuntu 20.04\r\nGPU: RTX 2070\r\nDriver: 440.100\r\nTensorflow: 2.3.0", "Sorry I forgot to update this thread, but the latest GCS builds are built with the following computes:\r\n\r\n`sm_35,sm_50,sm_60,sm_70,sm_75,compute_80`", "> If I hack our C++ application to link against `_pywrap_tensorflow_internal.so` instead then it seems to work. Although that's not a long term solution since the pywrap lib is considerably larger and we would also have to link our application against python.\r\n\r\nSorry for the [probably very basic] question but how do you \"link against python\"? I found \"_pywrap_tensorflow_internal.so\" and tried linking with it but get a bunch of unresolved python symbols. (As one would expect from reading your post.)", "> Sorry I forgot to update this thread, but the latest GCS builds are built with the following computes:\r\n> \r\n> `sm_35,sm_50,sm_60,sm_70,sm_75,compute_80`\r\n\r\nI'm working off of this page to get the libraries:\r\n\r\nhttps://www.tensorflow.org/install/lang_c\r\n\r\nThere's a link to a \"GCS bucket\" but it goes to an XML file in my browser (Chrome) which seems like it's supposed to be read by a different piece of software that I don't have. I see that \"GCS\" is short for \"Google Cloud Storage\" but when I try to access (?) \"Google Cloud Storage,\" I'm asked to sign up for a service (including entering payment/credit card details).\r\n\r\nIf somebody could point me in the right direction for accessing the files in this \"GCS bucket\" I would appreciate it.\r\n\r\n(Also, looking at that XML file in my browser, all of the files that were modified on 09-15 are 'libtensorflow-cpu-linux-x86_64.tar.gz' ... I don't see any files that seem like they would have GPU support?)", "So that link is a browser representation of the GCS bucket `libtensorflow-nightly`. I may be describing it badly, but regardless I think the file you're looking for is [this](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/libtensorflow/gpu/nightly/132/20200916-033413/github/tensorflow/lib_package/libtensorflow-gpu-linux-x86_64.tar.gz) which was built last night. ", "> So that link is a browser representation of the GCS bucket `libtensorflow-nightly`. I may be describing it badly, but regardless I think the file you're looking for is [this](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/libtensorflow/gpu/nightly/132/20200916-033413/github/tensorflow/lib_package/libtensorflow-gpu-linux-x86_64.tar.gz) which was built last night.\r\n\r\nThanks for building this and posting this link. I appreciate it. I installed it and tried it--I no longer got the error about \"device kernel image is invalid\" but I did get a bunch of errors about not being able to load libraries that seem related to CUDA 11.\r\n\r\nI will have to consider whether or not I want to switch to CUDA 11, seems like a big change and I'm reluctant to touch anything since my training with GPU acceleration is already working well with my current setup.", "Glad we were able to solve the first issue, sorry about the new issues you are facing. Do you mind uploading some logs so I can see if that's something we can fix on our end? The package was built with our CUDA 11 toolchain.", "> Sorry for the [probably very basic] question but how do you \"link against python\"? I found \"_pywrap_tensorflow_internal.so\" and tried linking with it but get a bunch of unresolved python symbols. (As one would expect from reading your post.)\r\n\r\nI used `-l_pywrap_tensorflow -lpython3.8`\r\n\r\nIf the issue has been fixed in the nightly which is TF 2.4 and not in the stable 2.3 release then I'm going to have the same dependency problem with CUDA that you are since the default CUDA version is 10.1 in the Ubuntu 20.04 package repos.\r\n\r\n", "> Glad we were able to solve the first issue, sorry about the new issues you are facing. Do you mind uploading some logs so I can see if that's something we can fix on our end? The package was built with our CUDA 11 toolchain.\r\n\r\n@av8ramit yeah, all the errors I'm seeing are to do with not being able to load CUDA 11 libraries, which I'm sure is expected if you built the libraries against CUDA 11 and I don't have CUDA 11 installed. I'm happy to post logs here but I can't imagine they would be useful to anybody. I will think about installing CUDA 11 later, but it might not be for a while, since I was able to get my code working by linking it against the Python libraries as parnham suggested.", "> > Sorry for the [probably very basic] question but how do you \"link against python\"? I found \"_pywrap_tensorflow_internal.so\" and tried linking with it but get a bunch of unresolved python symbols. (As one would expect from reading your post.)\r\n> \r\n> I used `-l_pywrap_tensorflow -lpython3.8`\r\n\r\n@parnham Thanks so much for this. I don't have a good understanding of how the linker works with shared libraries but I was able to hack something together:\r\n\r\n- I found the absolute paths to these .so files and added them to the end of my link command, which worked\r\n- When I ran the executable, though, it said it couldn't find the .so files\r\n- I added the paths to the .so files to /etc/ld.so.conf and also added the paths to $LD_LIBRARY_PATH, I'm not sure if it was necessary to do both but there you go\r\n- The executable ran this time but failed to do inference with a CUDA error because the \"allow growth\" GPU option was not set to true (I don't know what \"allow growth\" does, but everybody seems to run into this problem, why isn't it set to true by default?!?!)\r\n- I found some code posted here to set \"allow growth\" to true via the C API:\r\nhttps://github.com/neargye/hello_tf_c_api/issues/21\r\n\r\nSo everything seems pretty fragile but IT'S WORKING. Thanks so much. My C API inference workload is now ~5x as fast running on my GPU vs. the CPU. Great speedup. This is for a private project so I don't mind that I'm linking against those python libraries.\r\n\r\nIf you can share what you did to allow gcc to link nicely against those libraries (not use absolute paths, etc.) that would be great, really appreciated.\r\n\r\nThanks again!", "Glad I could help a little @motrek \r\nYou should be able to link to python3.8 if you have the package `libpython3.8-dev` installed.\r\n\r\nFor linking to the `_pywrap_tensorflow` library I just created a symlink to it in `/usr/local/lib`\r\n```\r\nlrwxrwxrwx 1 root root    93 Sep 16 11:16  lib_pywrap_tensorflow.so -> /home/dan/.local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n```\r\nand then ran `ldconfig`. At which point it can be linked and also found at runtime.\r\n\r\nThere's a slightly cleaner solution to setting the \"allow growth\" option by including the experimental header\r\n```cpp\r\n#include <tensorflow/c/c_api_experimental.h>\r\n```\r\nand then use the `TF_CreateConfig` helper.\r\n```cpp\r\nauto options = TF_NewSessionOptions();\r\nauto config  = TF_CreateConfig(true, true, 8);\r\n\r\nTF_SetConfig(options, config->data, config->length, this->status);\r\nTF_DeleteBuffer(config);\r\n```\r\nUse the session options as normal.\r\n\r\n\r\n\r\n\r\n", "Apologies for adding more activity to this issue @av8ramit but we wanted to find out if there was going to be a point release of the TensorFlow C library v2.3 that has been patched with the correct CUDA capabilities? \r\nI only ask because v2.3 is the current stable version, it works with the standard CUDA version in Ubuntu 20.04, and when installing tensorflow through python for training with keras it also uses the same version.", "Looping in the release manager. @geetachavan1 would we be able to patch the fix for libtensorflow and release new binaries with the correct CUDA capabilities. Happy to help get this done internally. ", "For Nvidia 3090, Ubuntu 20.04, Cuda 10.1, Cudnn 7.6, Nvidia GPU driver 455 have the same isseu", "Hi. We have uploaded the 2.3.1 libtensorflow binaries. Apologies for the delay, I missed them during the patch release", "Hi @mihaimaruseac \r\n\r\nUsing the link from https://www.tensorflow.org/install/lang_c#download and assuming that the new version was in the same location, I downloaded https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.3.1.tar.gz\r\n\r\nUnfortunately that build seems to have the same issue:\r\n```\r\n2020-10-03 18:26:42.084881: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n```\r\nIn fact running a diff between the old and new libtensorflow.so.2.3.0 files shows them to be identical.\r\n\r\nEDIT: The 2.3.0 and 2.3.1 tar.gz files have the same md5sum", "This is interesting. Even if our recent changes to the build script had no effects, I would have expected the binaries to differ based on the patch release changes.", "Apolgies. It seems our CI uploaded the wrong package under the new name after we refactored parts of the CI. I think it should be fixed now, can you give it a try please?\r\n\r\n```\r\nmihaimaruseac@ankh:/tmp$ sha256sum libtensorflow-gpu-linux-x86_64-2.3.*\r\n5e4d934fd7602b6d002a89b972371151aa478ea99bf1a70987833e11c34c8875  libtensorflow-gpu-linux-x86_64-2.3.0.tar.gz\r\nbdfb52677cf9793dcd7b66254b647c885c417967629f58af4a19b386fa7e7e0f  libtensorflow-gpu-linux-x86_64-2.3.1.tar.gz\r\n```", "> Apolgies. It seems our CI uploaded the wrong package under the new name after we refactored parts of the CI. I think it should be fixed now, can you give it a try please?\r\n\r\nThis now works for me. Thanks for sorting this out. Might want to update the links on the C API page to point to the new versions.\r\n\r\nGPU: mobile GeForce GTX 1660 Ti", "Thank you so much @av8ramit and @mihaimaruseac - v2.3.1 is now working for us also!", "No problem! Hats off to @geetachavan1 and @mihaimaruseac who did the heavy lifting!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41132\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41132\">No</a>\n"]}, {"number": 41130, "title": "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none) ERROR: No matching distribution found for tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 10 64bits\r\n- pip install tensorflow\r\n- Tensorflow 2.2\r\n- python 3.8.3\r\n- installation with pip\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0 / 11.0\r\n- NVIDIA GEFORCE 920M\r\n\r\n\r\n\r\ni installed all the required packages and checked if my hardward is equiped with what i need, i have VT-X and GPU but can't install i have this kind of error:\r\n\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n\r\ncan anyone explain me why? and how to fix it?\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n\r\n", "comments": ["@nesrinebnh \r\nCould you please refer to [this link](https://github.com/tensorflow/tensorflow/issues/40822#issuecomment-650075807) and let us know if it helps.", "oh yeah true, i was running different versions of python, i missed this point. \r\nthank you", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41130\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41130\">No</a>\n", "hello,\nthank you for your reply, i would say your fast reply, yes it was my issue,\nthank you so much\nI'm so satisfied\n\nOn Mon, Jul 6, 2020 at 7:00 PM Saduf2019 <notifications@github.com> wrote:\n\n> @nesrinebnh <https://github.com/nesrinebnh>\n> Could you please refer to this link\n> <https://github.com/tensorflow/tensorflow/issues/40822#issuecomment-650075807>\n> and let us know if it helps.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/41130#issuecomment-654383372>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AKO7L3JBDMM73SNIGTF2NPTR2IGLHANCNFSM4OR2FELQ>\n> .\n>\n"]}, {"number": 41128, "title": "Slow TFLite GPU inference on Android, not matched with the benchmark", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 2\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): nightly build\r\n- Python version:\r\n- Bazel version (if compiling from source): 3.3.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWe're running GPU delegate on an Android phone (NDKr18b). However, it's very slow (15ms) compared with the latency running benchmark tool (6ms).\r\n\r\nThis is the performance reported by benchmark tool (6ms):\r\n![Screenshot from 2020-07-06 23-42-06](https://user-images.githubusercontent.com/1322198/86620587-c105fd80-bfe6-11ea-8c16-79c3b42a74f2.png)\r\n\r\nWhile this is the actual latency when running within our app (15ms)\r\n![Screenshot from 2020-07-06 23-43-36](https://user-images.githubusercontent.com/1322198/86620591-c2cfc100-bfe6-11ea-9f28-7566a57e983e.png)\r\n\r\nWe're using `libtensorflowlite_gpu_gl.so` generated by running the following:\r\n\r\n```\r\nbazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so  # for dynamic library\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Sorry for the very late response. Is this the same issue that you reported here: https://github.com/tensorflow/tensorflow/issues/41094? And does [the reply](https://github.com/tensorflow/tensorflow/issues/41094#issuecomment-655337940) by @hajuho help?"]}, {"number": 41127, "title": "Error TensorArrayWrite/TensorArrayWriteV3", "body": "\r\n**System information**\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7\r\n- GPU model and memory: GOOGLE COLAB\r\nI want to do the deep cosine metric training with the VeRI data set, for this, I followed some recommendations proposed by the author [here](https://github.com/nwojke/cosine_metric_learning/issues/5#issuecomment-381883310), my configuration files are the same used in this [repository ](https://github.com/duyao-art/cosine_metric_learning_customer)\r\n**any help will be very useful**\r\n\r\n`/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nTrain set size: 34291 images, 518 identites\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:243: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:250: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:252: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/queued_trainer.py:316: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:266: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ffd0c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ffd0c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/nets/deep_sort/network_definition.py:19: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\r\n\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff62438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff62438>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/nets/deep_sort/network_definition.py:28: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\r\n\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ffd0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ffd0fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff4fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff4fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f0c4ffd0b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f0c4ffd0b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff62550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff62550>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff62e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ff62e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ffd0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ffd0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff4fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff4fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fe1b4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fe1b4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4feff0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4feff0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fdd0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fdd0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ff4e0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ff4e0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdd0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdd0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fdc0a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fdc0a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdc04e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdc04e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4f08e2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4f08e2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ff4e4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4ff4e4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff2b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff2b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff2b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff2b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4f034f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4f034f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff4ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ff4ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fe4a358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4fe4a358>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4f034a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4f034a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdc0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fdc0b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ef2bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ef2bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4feff390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4feff390>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ee74828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ee74828>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4f08ef28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4f08ef28>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fe4a860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4fe4a860>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ef4b470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4ef4b470>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4eebe710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4eebe710>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4eebe240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4eebe240>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ee08710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f0c4ee08710>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4eebec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4eebec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4edebeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f0c4edebeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nfeature dimensionality:  128\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.flatten instead.\r\nWARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0c4f055cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0c4f055cc0>>: AttributeError: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4eebe048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f0c4eebe048>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0c4eea2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0c4eea2e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/nets/deep_sort/network_definition.py:84: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ndim is deprecated, use axis instead\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/nets/deep_sort/network_definition.py:94: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/nets/deep_sort/network_definition.py:97: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:615: sparse_softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\r\nInstructions for updating:\r\nUse tf.losses.sparse_softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:409: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\r\nInstructions for updating:\r\nUse tf.losses.compute_weighted_loss instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nDeprecated in favor of operator or tf.math.divide.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:154: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:121: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\r\nInstructions for updating:\r\nUse tf.losses.add_loss instead.\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/losses.py:142: The name tf.log is deprecated. Please use tf.math.log instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:280: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:282: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:284: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:290: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\r\n\r\n---------------------------------------\r\nRun ID:  cosine-softmax\r\nLog directory:  ./output/veri/cosine-softmax\r\n---------------------------------------\r\nWARNING:tensorflow:From /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/queued_trainer.py:404: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.MonitoredTrainingSession\r\n2020-07-06 14:06:25.932540: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-07-06 14:06:25.936373: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2020-07-06 14:06:25.936668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2121800 executing computations on platform Host. Devices:\r\n2020-07-06 14:06:25.936703: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\n2020-07-06 14:06:26.086949: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file utilities to get mtimes.\r\n2020-07-06 14:06:36.550855: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at tensor_array_ops.cc:447 : Invalid argument: TensorArray map/TensorArray_1_2: Could not write to TensorArray index 1 because the value shape is [220,322,3] which is incompatible with the TensorArray's inferred element shape: [159,184,3] (consider setting infer_shape=False).\r\nEnqueueError: TensorArray map/TensorArray_1_2: Could not write to TensorArray index 1 because the value shape is [220,322,3] which is incompatible with the TensorArray's inferred element shape: [159,184,3] (consider setting infer_shape=False).\r\n\t [[node map/while/TensorArrayWrite/TensorArrayWriteV3 (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:251) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node map/while/TensorArrayWrite/TensorArrayWriteV3:\r\n map/while/DecodeJpeg (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:250)\r\n\r\nOriginal stack trace for 'map/while/TensorArrayWrite/TensorArrayWriteV3':\r\n  File \"train_veri.py\", line 133, in <module>\r\n    main()\r\n  File \"train_veri.py\", line 97, in main\r\n    **train_kwargs)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 188, in train_loop\r\n    trainable_scopes=trainable_scopes)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 251, in create_trainer\r\n    filename_var, back_prop=False, dtype=tf.uint8)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 268, in map_fn\r\n    maximum_iterations=n)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\r\n    return_same_structure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3456, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(*lv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in compute\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in <listcomp>\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1191, in write\r\n    return self._implementation.write(index, value, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 293, in write\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 8288, in tensor_array_write_v3\r\n    flow_in=flow_in, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n2020-07-06 14:06:37.324861: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at tensor_array_ops.cc:447 : Invalid argument: TensorArray map/TensorArray_1_0: Could not write to TensorArray index 1 because the value shape is [235,345,3] which is incompatible with the TensorArray's inferred element shape: [134,111,3] (consider setting infer_shape=False).\r\nEnqueueError: TensorArray map/TensorArray_1_0: Could not write to TensorArray index 1 because the value shape is [235,345,3] which is incompatible with the TensorArray's inferred element shape: [134,111,3] (consider setting infer_shape=False).\r\n\t [[node map/while/TensorArrayWrite/TensorArrayWriteV3 (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:251) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node map/while/TensorArrayWrite/TensorArrayWriteV3:\r\n map/while/DecodeJpeg (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:250)\r\n\r\nOriginal stack trace for 'map/while/TensorArrayWrite/TensorArrayWriteV3':\r\n  File \"train_veri.py\", line 133, in <module>\r\n    main()\r\n  File \"train_veri.py\", line 97, in main\r\n    **train_kwargs)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 188, in train_loop\r\n    trainable_scopes=trainable_scopes)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 251, in create_trainer\r\n    filename_var, back_prop=False, dtype=tf.uint8)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 268, in map_fn\r\n    maximum_iterations=n)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\r\n    return_same_structure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3456, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(*lv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in compute\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in <listcomp>\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1191, in write\r\n    return self._implementation.write(index, value, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 293, in write\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 8288, in tensor_array_write_v3\r\n    flow_in=flow_in, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n2020-07-06 14:06:44.331223: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at tensor_array_ops.cc:447 : Invalid argument: TensorArray map/TensorArray_1_4: Could not write to TensorArray index 1 because the value shape is [230,308,3] which is incompatible with the TensorArray's inferred element shape: [433,568,3] (consider setting infer_shape=False).\r\nEnqueueError: TensorArray map/TensorArray_1_4: Could not write to TensorArray index 1 because the value shape is [230,308,3] which is incompatible with the TensorArray's inferred element shape: [433,568,3] (consider setting infer_shape=False).\r\n\t [[node map/while/TensorArrayWrite/TensorArrayWriteV3 (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:251) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node map/while/TensorArrayWrite/TensorArrayWriteV3:\r\n map/while/DecodeJpeg (defined at /content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py:250)\r\n\r\nOriginal stack trace for 'map/while/TensorArrayWrite/TensorArrayWriteV3':\r\n  File \"train_veri.py\", line 133, in <module>\r\n    main()\r\n  File \"train_veri.py\", line 97, in main\r\n    **train_kwargs)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 188, in train_loop\r\n    trainable_scopes=trainable_scopes)\r\n  File \"/content/gdrive/My Drive/Trainig_Cosenet/cosine_metric_learning-master/train_app.py\", line 251, in create_trainer\r\n    filename_var, back_prop=False, dtype=tf.uint8)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 268, in map_fn\r\n    maximum_iterations=n)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\r\n    return_same_structure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3456, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(*lv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in compute\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 260, in <listcomp>\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1191, in write\r\n    return self._implementation.write(index, value, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 293, in write\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 8288, in tensor_array_write_v3\r\n    flow_in=flow_in, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\r\n  warnings.warn(\"Attempting to use a closed FileWriter. \"\r\n2020-07-06 14:06:45.082525: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at tensor_array_ops.cc:447 : Invalid argument: TensorArray map/TensorArray_1_6: Could not write to TensorArray index 1 because the value shape is [165,213,3] which is incompatible with the TensorArray's inferred element shape: [176,242,3] (consider setting infer_shape=False).`\r\n\r\n\r\n", "comments": ["@jhonjam \r\nPlease share simple stand alone code or colab gist with the error faced for us to replicate and analyse the issue.", "Is there any particular reason to be using older version of tf and try using newer version if it helps resolve the issue.", "> \u00bfHay alguna raz\u00f3n particular para usar una versi\u00f3n anterior de tf e intentar usar una versi\u00f3n m\u00e1s nueva si esto ayuda a resolver el problema?\r\n\r\nwith a newer version of tf, other problems are generated such as tf.session", "@jhonjam\r\nPlease share simple stand alone code or colab gist with the error faced for us to replicate and analyse the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41127\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41127\">No</a>\n", "@jhonjam - Were you able to solve this issue? I am also seeing similar issue with tf-1.14", "@ankurtri  no, I had to train the model in the gpu of my laptop, I could not find a solution to train in google collab"]}, {"number": 41126, "title": "tf.io.decode_image rotates the images", "body": "When I read some image files tf.io.decode_image rotates the images by n*90 degrees in comparison with how the images are shown in image viewers programs such as IrfanView and OpenCV's imread. I'm attaching one of the images: https://imgur.com/vPMQPq7\r\nYou can check it using my code:\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\npath = r'path_to_folder'\r\n\r\nfilenames = os.listdir(path)\r\nnew_path = path + '_after_tf'\r\nif not os.path.isdir(new_path):\r\n    os.mkdir(new_path)\r\n\r\nfor filename in filenames:\r\n    img_bytes = open(os.path.join(path, filename), 'rb').read()\r\n    img = tf.io.decode_image(img_bytes)\r\n    new_img_bytes = tf.io.encode_jpeg(img)\r\n    tf.io.write_file(os.path.join(new_path, os.path.splitext(filename)[0] + '.jpg'), new_img_bytes)\r\n```\r\nIt inputs image files in folder \"path\" and outputs images after tf.io.decode_image, tf.io.encode_jpeg, tf.io.write_file in the folder with the same name + the suffix \"_after_tf\"\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.7\r\n", "comments": ["@samquar - I haven't been able to reproduce the issue (here is my [colab](https://colab.research.google.com/drive/1aK_MaGreXl4jbGNT4rq5N8wFYJT2NYcB?usp=sharing)). I'm wondering if I'm missing something that's different from your setup. Would you be able to provide a gist that shows and reproduces the exact issue you're seeing, please?  ", "@samquar,\r\nCan you please respond to the above comment? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41126\">No</a>\n"]}, {"number": 41125, "title": "nan bug running automatic differentiation", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10  and Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):  tf 2.2.0\r\n- Python version:  3.6.5\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the current behavior**\r\n\r\ntf.GradientTape() gives wrong high order derivatives of the Morse potential function.\r\n\r\n**Describe the expected behavior**\r\n\r\nSee minimon reproduction code below.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n\r\n\r\n ```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef main() :\r\n    x=np.arange(0.9,1.1,0.01)\r\n    print(gradientcalculation(x))\r\n    print(d3(x))\r\n\r\ndef morse(x): # this is morse potential\r\n    return (1.0-tf.math.exp(-(x-1.0)))**2\r\n\r\ndef d3(x):#this is analytical 3rd order derivative of morse potential\r\n    return np.exp(1.0-2.0*x)*(2.0*np.exp(x)-8.0*np.exp(1.0))\r\n\r\n#calculate gradient of morse potential:(1-e**(-1(r-1))**2\r\ndef gradientcalculation(x):\r\n    x=tf.convert_to_tensor(x,dtype='float64')\r\n    with tf.GradientTape() as t:\r\n            x=tf.convert_to_tensor(x,dtype='float64')\r\n    with tf.GradientTape() as t:\r\n        with tf.GradientTape() as t2:\r\n            with tf.GradientTape() as t3:\r\n                t3.watch(x)\r\n                t2.watch(x)\r\n                t.watch(x)\r\n                y=morse(x)\r\n            dy_dx=t3.gradient(y,x)\r\n        t.watch(dy_dx)\r\n        d2y_dx2=t2.gradient(dy_dx,x)\r\n    d3y_dx3=t.gradient(d2y_dx2,x)\r\n    return d3y_dx3\r\n\r\nmain()\r\n```\r\noutpu is :\r\n```\r\ntf.Tensor(\r\n[-7.56088023 -7.38939034 -7.22151283 -7.05717403 -6.89630172 -6.73882515\r\n -6.58467499 -6.4337833  -6.28608351 -6.14151039         nan -5.86148972\r\n -5.72591817 -5.5932252  -5.46335189 -5.3362405  -5.21183443 -5.09007824\r\n -4.97091762 -4.85429932 -4.74017119], shape=(21,), dtype=float64)\r\n[-7.56088023 -7.38939034 -7.22151283 -7.05717403 -6.89630172 -6.73882515\r\n -6.58467499 -6.4337833  -6.28608351 -6.14151039 -6.         -5.86148972\r\n -5.72591817 -5.5932252  -5.46335189 -5.3362405  -5.21183443 -5.09007824\r\n -4.97091762 -4.85429932 -4.74017119]\r\n```\r\n\r\nIt should output same values, but when x=1.0 , tf.GradientTape()  provide 'nan'.\r\n\r\n**Other info / logs** \r\nN/A", "comments": ["Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c53b6867d9280b2f5a8af8dce45b53e9/41125.ipynb). Thanks!", "@youli-jlu I tried to reproduce the issue but I am not getting any nan error in 2.5. Seems the issue was fixed in latest TF version. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/cdce58bc409e7c39b07a68702465236c/untitled86.ipynb).Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41125\">No</a>\n"]}, {"number": 41124, "title": "tf.summary.image log spam when using file_writer in graph mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: [Running on CPU]\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nRunning TF in 1.x graph mode, I create a trivial tf.summary.image. The error message below appears, although the code continues running, and the image summary is written.\r\n\r\n```\r\nERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.framework.ops.Operation'>):\r\n<tf.Operation 'fooey/write_summary/assert_non_negative/assert_less_equal/Assert/Assert' type=Assert>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n  File \"/home/rosea/conda/envs/tf2n/lib/python3.7/site-packages/tensorflow/python/ops/check_ops.py\", line 540, in assert_non_negative_v2\r\n    name=name)  File \"/home/rosea/conda/envs/tf2n/lib/python3.7/site-packages/tensorflow/python/ops/check_ops.py\", line 560, in assert_non_negative\r\n    return assert_less_equal(zero, x, data=data, summarize=summarize)  File \"/home/rosea/conda/envs/tf2n/lib/python3.7/site-packages/tensorflow/python/ops/check_ops.py\", line 924, in assert_less_equal\r\n    np.less_equal, x, y, data, summarize, message, name)  File \"/home/rosea/conda/envs/tf2n/lib/python3.7/site-packages/tensorflow/python/ops/check_ops.py\", line 372, in _binary_assert\r\n    return control_flow_ops.Assert(condition, data, summarize=summarize)  File \"/home/rosea/conda/envs/tf2n/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 237, in wrapped\r\n    error_in_function=error_in_function)\r\n==================================\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe error message should not appear.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nwriter = tf.summary.create_file_writer('.')\r\nwith writer.as_default():\r\n  y = tf.constant(0, shape=(2,2,2,2))  \r\n  s = tf.summary.image(name=\"foo\", data=y, step=0)\r\n\r\n# Error message occurs before code below runs\r\nwith tf.compat.v1.Session() as sess:\r\n  sess.run(writer.init())\r\n  sess.run(s)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\nSee previous issue: https://github.com/tensorflow/tensorflow/issues/33223'\r\nThe difference here is the use of the summary file writer.\r\n\r\nAny of the following changes make the error message go away:\r\n- Removing `with writer.as_default():` (though of course then nothing gets written)\r\n- using `tf.summary.scalar(\"foo\", tf.reduce_mean(y), step=0)` in place of `tf.summary.image(...)`\r\n- using eager execution instead of graph mode\r\n", "comments": ["@rosea-tf \r\nPlease refer to below links and let us know if it helps:\r\n[link](https://stackoverflow.com/questions/51248813/any-ideas-on-what-might-be-causing-this-tensorflow-error-object-was-never-used)\r\n[ link1](https://github.com/tensorflow/models/issues/6252#issuecomment-469396493) \r\n", "No, I don't think that applies. I'm not running distributed TF, and I don't have any actual unused operations here.", "@rosea-tf I think the root-cause is mixing `TF1.x` and `TF2.x` modules. Please donot mix the functionality. If you want to run it in graph mode then decorate with @tf.function. Please check the examples [here](https://www.tensorflow.org/api_docs/python/tf/summary).\r\n\r\nI updated your code and the working version is attached as a [gist](https://colab.research.google.com/gist/jvishnuvardhan/c218b443bc23005a995f1f969efb770d/41124.ipynb). Thanks!\r\n\r\n```\r\nimport tensorflow as tf\r\n#tf.compat.v1.disable_eager_execution()\r\n\r\nwriter = tf.summary.create_file_writer('./tmp/mylogs')\r\nwith writer.as_default():\r\n  y = tf.constant(0, shape=(2,2,2,2))  \r\n  s = tf.summary.image(name=\"foo\", data=y, step=0)\r\n  writer.flush()\r\n  \r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n# # Error message occurs before code below runs\r\n# with tf.compat.v1.Session() as sess:\r\n#   sess.run(writer.init())\r\n#   sess.run(s)\r\n```", "Hello, thanks for the response.\r\n\r\nThe guide at https://www.tensorflow.org/tensorboard/migrate (\"Example usage with legacy TF 1.x graph execution\") suggests that mixing the v1 and v2 modules in this way should work. My code is essentially the same as the example code there, except that instead of `tf.summary.scalar` (which works) I use `tf.summary.image` (which doesn't).\r\n\r\nIn my case, I need some of the v2 summary functionality, and migrating my code base from the v1 graph/session API to @tf.function's would be too much work. So my workaround is to enclose my `tf.summary.image` call in an error-suppressing context manager.\r\n\r\nTL;DR: kind of resolved for me with a workaround, but you may want to note in your migration guide that this issue exists when mixing the APIs.", "@rosea-tf When I ran your code as-is, it throws an error `ValueError: Expected scalar shape for Const:0, saw shape: (2, 2, 2, 2).`. Can you please share a colab gist. Thanks!\r\n\r\nGenerally, it is suggested not to mix the functionality of TF1.x and TF2.x as one is graph mode and the other is eager mode. Mixing both will results in compatibility issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41124\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41124\">No</a>\n"]}, {"number": 41122, "title": "Huge memory usage on hosts with 1TB RAM", "body": "**System information**\r\n\r\nWe use keras and TF for our models:\r\n\r\nCentos7\r\n\r\nPython 3.6.1\r\n\r\nKeras==2.2.4\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\n\r\ntensorboard==1.12.2\r\ntensorflow==1.12.0\r\ntensorflow-estimator==1.13.0\r\n\r\nThrere is no GPU on our servers.\r\n\r\n**Describe the current behavior**\r\n\r\nOur script loads trained model from files (json + h5) and predict some useful parameter.\r\nWhen we run script on small server with 8GB RAM and measure memory after script load model we see it take 160Mb commited memory 1,5GB  virtual size.\r\n\r\nWhen we run script on large production server with 1TB RAM and measure memory after script load exactly same model we see it take 220Mb commited memory 14GB  virtual size.\r\n\r\n**Describe the expected behavior**\r\n\r\nThere are some limitation from our DEVOPS team and our models must take not more 1GB commited and not more 2GB virtual size. So we would like to have same memory fingerprint on any server. If there is any way setup TF to use fixed memory size on any server?\r\n\r\n", "comments": ["> When we run script on large production server with 1TB RAM and measure memory after script load exactly same model we see it take 220Mb commited memory 14GB virtual size.\r\n\r\n@a-a-davydov,\r\nCould you please check if you are facing the same issue with TF v2.2 or TF v1.15? Thanks!", "Hello,\r\n\r\nI'm sorry, I can't setup new software on large server. It is require to get some agreements and plan admin team hours. It can take some weeks, I will inform you if we do it and test fresh TF behaviour on large server.\r\n\r\nNow we add following workaround in our code:\r\n\r\n```python\r\ndef init_keras_tf():\r\n        from keras.backend.tensorflow_backend import set_session\r\n        import tensorflow as tf\r\n        config = tf.ConfigProto()  # create TF configuration\r\n        config.gpu_options.allow_growth = True  # Disable memory pre allocation\r\n        sess = tf.Session(config=config)\r\n        set_session(sess)  # set this TensorFlow session as the default session for Keras\r\n```\r\n\r\nAs we see, gpu_options.allow_growth works well and for CPU RAM and we get same memory fingerprint on any server", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 41121, "title": "cmsis-nn: Revert dynamic allocation for quant params", "body": "File affected: cmsis-nn/depthwise_conv.cc\r\n\r\nDynamic allocation of memory for output shift and\r\nmultiplier fails(running whole networks) when\r\ndone together with scratch buffer for\r\noptimization. The issue is tracked in b/158779832.\r\nThis patch reverts back to static allocation\r\nfor output shift and multiplier until the scratch buffer\r\nissue is fixed.", "comments": []}, {"number": 41120, "title": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021DB69A21F8> and will run it as-is.", "body": "```\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\r\n    tf.keras.layers.MaxPooling2D(2, 2),\r\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(512, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer=\"adam\",\r\n              metrics=['accuracy'])\r\n\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\ntrain_datagen = ImageDataGenerator(rescale=1/255)\r\n\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        r'C:\\Users\\asus\\Downloads\\tf horse human\\\\horsehuman', \r\n        target_size=(300, 300),  \r\n        batch_size=128,\r\n        class_mode='binary')\r\n\r\nmodel.fit(train_generator,\r\n          steps_per_epoch=8,  \r\n          epochs=15)\r\n```\r\n\r\nThen it shows the warning.\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021DB69A21F8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n\r\n8/8 [==============================] - 45s 6s/step - loss: 0.5747 - accuracy: 0.6699\r\nEpoch 2/15\r\n8/8 [==============================] - 47s 6s/step - loss: 0.2592 - accuracy: 0.8821\r\nEpoch 3/15\r\n8/8 [==============================] - 41s 5s/step - loss: 0.2060 - accuracy: 0.9121\r\nEpoch 4/15\r\n8/8 [==============================] - 40s 5s/step - loss: 0.1459 - accuracy: 0.9466\r\nEpoch 5/15\r\n8/8 [==============================] - 41s 5s/step - loss: 0.0600 - accuracy: 0.9800\r\nEpoch 6/15\r\n8/8 [==============================] - 40s 5s/step - loss: 0.0341 - accuracy: 0.9855\r\nEpoch 7/15\r\n8/8 [==============================] - 41s 5s/step - loss: 0.0334 - accuracy: 0.9911\r\nEpoch 8/15\r\n8/8 [==============================] - 40s 5s/step - loss: 0.0198 - accuracy: 0.9911\r\nEpoch 9/15\r\n8/8 [==============================] - 39s 5s/step - loss: 0.0085 - accuracy: 0.9989\r\nEpoch 10/15\r\n8/8 [==============================] - 44s 6s/step - loss: 0.0043 - accuracy: 0.9990\r\nEpoch 11/15\r\n8/8 [==============================] - 46s 6s/step - loss: 0.0025 - accuracy: 1.0000\r\nEpoch 12/15\r\n8/8 [==============================] - 40s 5s/step - loss: 0.0014 - accuracy: 1.0000\r\nEpoch 13/15\r\n8/8 [==============================] - 40s 5s/step - loss: 0.0014 - accuracy: 1.0000\r\nEpoch 14/15\r\n8/8 [==============================] - 40s 5s/step - loss: 5.8768e-04 - accuracy: 1.0000\r\nEpoch 15/15\r\n8/8 [==============================] - 40s 5s/step - loss: 7.8857e-04 - accuracy: 1.0000\r\n\r\n\r\n", "comments": ["@lavish619 \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/37144#issuecomment-600350256) and let us know.\r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/589f516d5cc7ec1075cffcd889b9a24a/untitled260.ipynb), share all dependencies for us to replicate the issue faced.\r\n#38947 link link2 #32377 #38691 #32319 #37251\r\nAlso let us know the tf version.", "Yeah, this error was supposed to come because the dataset is stored on my device and I was using Jupyter Notebook instead of Google Colab, the directory written in code is a local directory on my laptop.\r\n\r\nMy current TensorFlow version is 2.2.\r\nPython 3.7\r\ngast 0.2.2(downgraded from 0.3.3) \r\nissue still persists.\r\n\r\nMoreover this does not happen in google colab. No warning in colab.\r\n\r\nAnd one more thing, it doesn't use GPU as cudnn is not included , so it runs on CPU. And it shows this on Jupyter Terminal\r\n```\r\n2020-07-06 21:26:03.586158: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-07-06 21:26:03.618454: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19e5b9ce190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 21:26:03.623269: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-07-06 21:26:03.626233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-07-06 21:26:03.629746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]\r\n2020-07-06 21:26:06.362261: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 727482368 exceeds 10% of free system memory.\r\n2020-07-06 21:26:06.890651: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 354041856 exceeds 10% of free system memory.\r\n2020-07-06 21:26:08.125578: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 354041856 exceeds 10% of free system memory.\r\n2020-07-06 21:26:10.103797: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 363741184 exceeds 10% of free system memory.\r\n2020-07-06 21:26:10.108353: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 727482368 exceeds 10% of free system memory.\r\n```\r\n\r\n> @lavish619\r\n> Please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/37144#issuecomment-600350256) and let us know.\r\n> I ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/589f516d5cc7ec1075cffcd889b9a24a/untitled260.ipynb), share all dependencies for us to replicate the issue faced.\r\n> #38947 link link2 #32377 #38691 #32319 #37251\r\n> Also let us know the tf version.\r\n\r\n", "Somehow its automatically gone. I just restarted everything, installed anaconda and TensorFlow again, and checked correctly for paths. And now it's working fine. However, now it is showing different error on GPU but this warning is gone so closing this issue."]}, {"number": 41119, "title": "Unable to convert ALBERT lite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.3 (19D76), also tried using colab runtime\r\n- TensorFlow installed from source\r\n- TensorFlow version: have tried multiple - 2.3.0-dev20200608, 2.4.0-dev20200705, 2.2.0, 1.15.0\r\n\r\n\r\nPlease refer to the [colab notebook](https://colab.research.google.com/drive/16eEDreq7F2DZLSFrQJJrrwPQ2MubKrh3#scrollTo=WOZp9iGvp9yb), I am able to convert [bert_en_uncased](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1) but not [albert_lite](https://tfhub.dev/tensorflow/albert_lite_base/1) even though albert lite is meant to be tflite compatible. \r\n\r\nI have tried different versions of tensorflow, as well as different ways of converting - from keras model / saved model / concrete function but none works :(\r\n\r\nrelated issue: https://github.com/tensorflow/tensorflow/issues/34396", "comments": ["Hey wing-yiu@  I have a fix for this. Please wait for landing.", "This should be fixed. @wing-yiu can you please retry.\r\n\r\nThanks", "Please reopen if needed", "@karimnosseir \r\n\r\nIs there a specific version of tensorflow that I'm supposed to use?\r\n\r\nI get the same error below when I use the colab notebook that was provided to convert from keras model.\r\n`InvalidArgumentError: Input 3 of node functional_3/albert_lite/StatefulPartitionedCall was passed float from functional_3/albert_lite/73237:0 incompatible with expected resource.`", "Please save the keras model into a saved model and use the from_saved_model API with tf-nightly version.", "Thank you, using `from_saved_model` works! Just a couple of questions:\r\n- The original [Albert Lite model](https://tfhub.dev/tensorflow/albert_lite_base/1) was 42.5mb, and after conversion it only reduced to 33.6mb. Is this expected behaviour? When I previously converted the [large BERT model](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1) it was able to reduce size by 4x from 400+mb to 100+mb.\r\n\r\n- Can you please briefly explain the changes that were made for this to work? Would like to learn from this in case I encounter similar issues in the future.", "The graph node pruning result can be vary depending on the part to be pruned in the model. During conversion, pruning will be conducted based on the control dependencies described in the graph and I guess the large BERT model could be pruned since they have a lot of heavy dangling nodes in the graph.\r\n\r\nV2 saved_model converter path is updated with the recent changes and capable to convert more TF models."]}, {"number": 41117, "title": "Error Converting ssd_mobilenet_v2_oid_v4_2018_12_12 To Tflite", "body": "**System information**\r\n- Windows 10 build 2004\r\n- pip install tf_night-cpu\r\n- TensorFlow version 2.4.0-dev20200705\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nfrom tensorflow.compat.v1.lite import TFLiteConverter\r\ndir = 'models/ssd_mobilenet_v2_oid_v4_2018_12_12/saved_model'\r\nconverter = TFLiteConverter.from_saved_model(dir)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-07-06 01:15:38.959932: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-07-06 01:15:38.964732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b8abaa2fa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-06 01:15:38.964778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:From tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\n2020-07-06 01:16:12.245270: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\r\n2020-07-06 01:16:12.245407: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-07-06 01:16:15.644668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-07-06 01:16:15.644700: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n2020-07-06 01:16:15.644707: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-07-06 01:17:05.110725: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\r\n2020-07-06 01:17:05.110861: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-07-06 01:17:08.586833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-07-06 01:17:08.586867: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-07-06 01:17:08.586874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-07-06 01:17:29.988798: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-07-06 01:17:29.988832: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nloc(callsite(\"Preprocessor/map/TensorArray\"(\"tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\":299:0) at callsite(\"tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\":324:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py\":198:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\":1922:0 at \"convert.py\":4:0))))): error: 'tf.TensorArrayV3' op is neither a custom op nor a flex op\r\n...\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.NonMaxSuppressionV3 {T = f32, T_threshold = f32, device = \"\"}\r\n\ttf.Size {device = \"\"}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArray_5\"], device = \"\", element_shape = #tf.shape<100x4>}...\r\n...\r\ntf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:299:0: note: called from\r\ntf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:324:0: note: called from\r\ntf\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py:198:0: note: called from\r\ntf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1922:0: note: called from\r\nconvert.py:4:0: note: called from\r\n<unknown>:0: note: loc(callsite(\"Preprocessor/map/while/TensorArrayReadV3@_functionalize_body_0\" at callsite(\"Preprocessor/map/while/LoopCond\"(\"tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\":299:0) at callsite(\"tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\":324:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py\":198:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\":1922:0 at \"convert.py\":4:0)))))): see current operation: %2 = \"tf.TensorArrayReadV3\"(%arg5, %arg1, %arg6) {device = \"\"} : (tensor<2x!tf.resource<tensor<*xf32>>>, tensor<i32>, tensor<f32>) -> tensor<*xf32>\r\n<unknown>:0: error: loc(callsite(\"Preprocessor/map/while/TensorArrayWrite/TensorArrayWriteV3@_functionalize_body_0\" at callsite(\"Preprocessor/map/while/LoopCond\"(\"tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\":299:0) at callsite(\"tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\":324:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py\":198:0 at callsite(\"tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\":1922:0 at \"convert.py\":4:0)))))): 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op\r\n...\r\n>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.NonMaxSuppressionV3 {T = f32, T_threshold = f32, device = \"\"}\r\n\ttf.Size {device = \"\"}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArray_5\"], device = \"\", element_shape = #tf.shape<100x4>}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArray_6\"], device = \"\", element_shape = #tf.shape<100>}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArray_7\"], device = \"\", element_shape = #tf.shape<100>}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArray_9\"], device = \"\", element_shape = #tf.shape<>}\r\n\ttf.TensorArrayGatherV3 {_class = [\"loc:@Preprocessor/map/TensorArray_1\"], device = \"\", element_shape = #tf.shape<300x300x3>}\r\n...\r\n  %18 = \"tfl.depthwise_conv_2d\"(%17, %cst_118, %cst_34) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x75x75x144xf32>, tensor<1x3x3x144xf32>, tensor<144xf32>) -> tensor<?x75x75x144xf32>\r\n  %19 = \"tfl.conv_2d\"(%18, %cst_64, %cst_119) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x75x75x144xf32>, tensor<24x1x1x144xf32>, tensor<24xf32>) -> tensor<?x75x75x24xf32>\r\n  %20 = \"tfl.add\"(%19, %16) {fused_activation_function = \"NONE\"} : (tensor<?x75x75x24xf32>, tensor<?x75x75x24xf32>) -> tensor<?x75x75x24xf32>\r\n  %21 = \"tfl.conv_2d\"(%20, %cst_65, %cst_37) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x75x75x24xf32>, tensor<144x1x1x24xf32>, tensor<144xf32>) -> tensor<?x75x75x144xf32>\r\n  %22 = \"tfl.depthwise_conv_2d\"(%21, %cst_120, %cst_36) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x75x75x144xf32>, tensor<1x3x3x144xf32>, tensor<144xf32>) -> tensor<?x38x38x144xf32>\r\n...\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttp://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_oid_v4_2018_12_12.tar.gz\r\n```\r\n\r\n**Failure details**\r\nIt gives the error above.", "comments": ["@jsl303 \r\nPlease refer to [this issue](https://github.com/tensorflow/tensorflow/issues/40129#issuecomment-639632248) and let us know if it helps.\r\n #34845", "Thanks for the pointer.\r\nTo what should I set converter.optimizations, target_spec, and experimental_new_converter?\r\nI'm trying to convert this to run on Coral Edge TPU.\r\n\r\nI get this.\r\n```\r\n>>> converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n>>> converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n>>> converter.experimental_new_converter = True\r\n>>> converter.inference_input_type = tf.uint8\r\n>>> converter.inference_output_type = tf.uint8\r\n>>> tflite_model = converter.convert()\r\n2020-07-06 08:08:18.526504: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-07-06 08:08:18.528582: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\n2020-07-06 08:08:27.066136: I tensorflow/lite/tools/optimize/quantize_weights.cc:219] Skipping quantization of tensor FeatureExtractor/MobilenetV2/Conv/Conv2D because it has fewer than 1024 elements (864).\r\n2020-07-06 08:08:27.068164: I tensorflow/lite/tools/optimize/quantize_weights.cc:219] Skipping quantization of tensor FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm;FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise;FeatureExtractor/MobilenetV2/expanded_conv_5/project/Conv2D because it has fewer than 1024 elements (288).\r\n2020-07-06 08:08:27.073381: I tensorflow/lite/tools/optimize/quantize_weights.cc:219] Skipping quantization of tensor FeatureExtractor/MobilenetV2/expanded_conv/project/Conv2D because it has fewer than 1024 elements (512).\r\n...\r\n......\r\n```\r\n", "@jsl303 \r\nI am unable to access the zip file shared to replicate the error faced.", "Hmm, I just tried again, and it worked for me.\r\nTry getting it from:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nDownload ssd_mobilenetv2_oidv4 under Open Images-trained models.", "As described the link below, I changed my original script to quantize to Integer only for coral, and it's the same.\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization\r\n\r\n```\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.representative_dataset = tf.lite.RepresentativeDataset(represent)\r\n```\r\n", "@jsl303 Can you please share `represent`. For an example, you can use the link you shared in the last post. https://www.tensorflow.org/lite/performance/post_training_quantization\r\n\r\nThanks!", "The folder imgs has some samples from open image dataset.\r\nhttps://storage.googleapis.com/openimages/web/download_v4.html\r\n\r\n```\r\nimport cv2\r\nfrom glob import glob\r\n\r\ndef represent():\r\n  for img in glob('imgs/*'):\r\n    x = cv2.imread(img)\r\n    x = cv2.resize(x, (300,300))\r\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\r\n    x = x/255\r\n    yield [x]\r\n```\r\n", "@jsl303 Can you please share a standalone code to reproduce the issue? Standalone code will result in faster resolution. Thanks!", "```\r\nimport random\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nfrom glob import glob\r\nimport numpy as np\r\nfrom tensorflow.compat.v1.lite import TFLiteConverter\r\n\r\ndef representative_dataset_gen():\r\n\tfiles = glob('../oid/**/*.jpg', recursive=True)\r\n\trandom.shuffle(files)\r\n\tfiles = files[:128]\r\n\tfor file in files:\r\n\t\timg = Image.open(file)\r\n\t\tif img.mode != 'RGB': img = img.convert('RGB')\r\n\t\timg = img.resize((300, 300), Image.NEAREST)\r\n\t\timg = np.asarray(img, dtype=np.uint8)\r\n\t\tyield [img]\r\n\r\nprint(tf.__version__)\r\nsaved_model = 'ssd_mobilenet_v2_oid_v4_2018_12_12/saved_model'\r\nconverter = TFLiteConverter.from_saved_model(saved_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_quant_model = converter.convert()\r\nopen(\"ssd_mobilenet_v2_oid_v4_300x300_full_integer_quant.tflite\", \"wb\").write(tflite_quant_model)\r\n```", "The procedure for converting SSDs to TFLite is a little different: [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md), in the sense that it requries an extra step to produce a 'TFLite-friendly' TF graph first.\r\n\r\nIf you follow the above link, you will need the following arguments to `export_tflite_ssd_graph`:\r\n```\r\n--pipeline_config_path=/.../ssd_mobilenet_v2_oid_v4_2018_12_12/pipeline.config --output_directory=/.../ssd_mobilenet_v2_oid_v4_2018_12_12/ --trained_checkpoint_prefix=/.../ssd_mobilenet_v2_oid_v4_2018_12_12/model.ckpt   --add_postprocessing_op=true\r\n```\r\n\r\nIf you were using the command-line converter, the arguments would then be:\r\n\r\n```\r\n--input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n  --inference_type=FLOAT \\\r\n  --input_shapes=1,300,300,3 \\\r\n  --input_arrays=normalized_input_image_tensor \\\r\n  --output_arrays=\\\r\n'TFLite_Detection_PostProcess',\\\r\n'TFLite_Detection_PostProcess:1',\\\r\n'TFLite_Detection_PostProcess:2',\\\r\n'TFLite_Detection_PostProcess:3' \\\r\n  --allow_custom_ops\r\n```\r\n\r\nThis generates the float version just fine, you can then try post-training quantization arguments to the converter :-).\r\n\r\n\r\n\r\n", "@jsl303  If this is still an issue then please feel free to look at the [updated instruction](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md) to convert sdd model with then new converter. Please let us know if it helps ? Thank you! \r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41117\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41117\">No</a>\n"]}, {"number": 41116, "title": "save_weights and load_weights do not work as expected when used to restore original initialized weights", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6.9\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThe `save_weights` and `load_weights` functions do not work as expected when used to save and restore the original, initialized weights of a model. For instance, in the following example, we create a model, save the original weights, corrupt the weights, and restore the original, uncorrupted weights.  The training results in a very high loss when the `corrupt_weights_but_restore` function is invoked, but a low loss when the `corrupt_weights_but_restore` is commented out.\r\n\r\n```python\r\nimport tempfile\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.datasets import boston_housing\r\n(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\r\ndef corrupt_weights_but_restore(model, X, Y):\r\n\r\n   # save original uncorrupted weights\r\n    new_file, weightfile = tempfile.mkstemp()\r\n    model.save_weights(weightfile)       \r\n\r\n   # corrupt/damage weights with very high learning rate\r\n    K.set_value(model.optimizer.lr, 100) \r\n    model.fit(X, Y, epochs=5)\r\n\r\n   # load original uncorrupted weights\r\n    model.load_weights(weightfile) \r\n    return model\r\n\r\n# build model\r\nmodel = Sequential()\r\nmodel.add(Dense(1, input_shape=(x_train.shape[1],), activation='linear'))\r\nmodel.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\r\n\r\n# uncommenting the line below produces high loss despite restoring original weights\r\nmodel = corrupt_weights_but_restore(model, x_train, y_train)\r\n\r\n# train\r\nK.set_value(model.optimizer.lr, 0.05)\r\nmodel.fit(x_train, y_train,\r\n          batch_size=32,\r\n          epochs=100)\r\n~                       \r\n```\r\n\r\n**Describe the expected behavior**\r\nLoss should be the same (and be low) regardless of whether or not `corrupt_weights_but_restore` is run, since the original, uncorrupted weights are restored in `corrupt_weights_but_restore`.\r\n", "comments": ["@amaiya \r\n\r\nI have tried in colab with TF version 2.2.Please, find the gist here. You are also seeing the same behavior?.Thanks!", "@ravikyram Sorry - where exactly is the gist?  I don't see a link i your post.\r\n\r\nIn TensorFlow 2.2.0, when the `corrupt_weights_but_restore` method is commented out, the training loss is around 30.  When it is uncommented and invoked, the loss is several hundred.  I've reproduced this across several different models and datasets.\r\n", "@amaiya \r\n\r\nSorry, my bad. Forgot to attach [gist](https://colab.research.google.com/gist/ravikyram/5ec20121376d550db67784ae6aeca738/untitled84.ipynb).You are also seeing the same behavior?Thanks!", "Thanks - no worries.   Yes that's the behavior I'm seeing.  Now, if you do either the following, the problem disappears and the loss is much lower (between 30 and 40 versus the loss of 702 shown in your gist):\r\n- comment out the line that calls `corrupt_weights_but_restore`\r\n- replace `save_weights` and `load_weights` with `model.save` and `load_model`, respectively\r\n\r\nThis suggests that `save_weights` and `load_weights` are not doing the right thing, which is problematic.\r\n\r\nSee [this Google Colab](https://colab.research.google.com/drive/19K5PxnxOxV00AdBQWLwB7Rc3-KWu_R0b?usp=sharing) that shows this.\r\n\r\n", "I have tried in colab with nightly version(`2.4.0-dev20200706`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/85dd12dbec8001a129e888d7b1392197/untitled87.ipynb).Thanks!", "Just a note -- h5 doesn't restore optimizer weights, so if the loss after training is extremely high, that could mean that the adam optimizer weights are corrupted from calling `model.fit()` on the high learning rate. I would suggest using the TF format, or recompiling the model after loading the weights.", "@k-w-w :  Thank you - it looks like you're exactly right about what's happening.  Thanks for the suggestions.  I am closing this issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41116\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41116\">No</a>\n"]}, {"number": 41115, "title": "Doc of rmsprop optimizer seems not consistent with the code", "body": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop", "comments": ["@tzm1003306213,\r\nCould you please point out the inconsistencies in the document and mention the required changes to be made? Thanks!", "> @tzm1003306213,\r\n> Could you please point out the inconsistencies in the document and mention the required changes to be made? Thanks!\r\n\r\n1) The momentum state update rule in document is \"mom_t = momentum * mom_t-1 + g_t / sqrt(rms_t + epsilon)\", while in the code is \"mom_t = momentum * mom_t-1 + g_t / (sqrt(rms_t) + epsilon)\".\r\n\r\n2) I noticed a previous version of RMSprop optimizer https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc#L564. The momentum state update rule is \"mom_t = momentum * mom_t-1 + (learning_rate * g_t) / sqrt(rms_t + epsilon)\", and the parameter update rule is \"theta_t = theta_t-1 - mom_t\". Why you use a different update rule in the current version?\r\n\r\n3) The centered momentum state update rule in document is \"mom_t = momentum * mom_t-1 + learning_rate * g_t / sqrt(rms_t - mg_t^2 + \\epsilon)\". It seems that in the code is \"mom_t = momentum * mom_t-1 + g_t / (sqrt(rms_t - mg_t^2) + epsilon)\". Similar difference in the parameter update.\r\n\r\n4)  \"x/x^2 = sign(x)\", is this a typo? I think it should be \"x/sqrt(x^2) = sign(x)\"\r\n\r\nThanks", "@tanzhenyu has done a lot of work on these optimizers. \r\n\r\nI assume the reason the epsilon was moved is just to make it simpler to think about the effect of the epsilon, `eps=1e-6` under the square root acts like `eps=1e-3` outside of the root. ", "The optimizer docs are cleaned and updated. See commit [f6302e4](https://github.com/tensorflow/tensorflow/commit/f6302e4ec726225036b3419af7d218e93aa06783#diff-5b552f23144694a0bad1666a8ce66710f6f1b4a0587c9bfecc45d6df1ecdbd38)\r\nFeel free to reopen if have any questions. Thanks!"]}, {"number": 41114, "title": "multilabel accuracy is lower in 2.2.0 than 2.1.0 for same code", "body": "The following simple multilabel classification example returns a **100% accuracy in TensorFlow 2.1.0** but only **60%  accuracy in TensorFlow 2.2.0**.  The loss appears to be the same, though.    **Why is this?** \r\n\r\n```python\r\nX = [[1,0,0,0,0,0,0],\r\n      [1,2,0,0,0,0,0],\r\n      [3,0,0,0,0,0,0],\r\n      [3,4,0,0,0,0,0],\r\n      [2,0,0,0,0,0,0],\r\n      [3,0,0,0,0,0,0],\r\n      [4,0,0,0,0,0,0],\r\n      [2,3,0,0,0,0,0],\r\n      [1,2,3,0,0,0,0],\r\n      [1,2,3,4,0,0,0],\r\n      [0,0,0,0,0,0,0],\r\n      [1,1,2,3,0,0,0],\r\n      [2,3,3,4,0,0,0],\r\n      [4,4,1,1,2,0,0],\r\n      [1,2,3,3,3,3,3],\r\n      [2,4,2,4,2,0,0],\r\n      [1,3,3,3,0,0,0],\r\n      [4,4,0,0,0,0,0],\r\n      [3,3,0,0,0,0,0],\r\n      [1,1,4,0,0,0,0]]\r\n\r\nY = [[1,0,0,0],\r\n    [1,1,0,0],\r\n    [0,0,1,0],\r\n    [0,0,1,1],\r\n    [0,1,0,0],\r\n    [0,0,1,0],\r\n    [0,0,0,1],\r\n    [0,1,1,0],\r\n    [1,1,1,0],\r\n    [1,1,1,1],\r\n    [0,0,0,0],\r\n    [1,1,1,0],\r\n    [0,1,1,1],\r\n    [1,1,0,1],\r\n    [1,1,1,0],\r\n    [0,1,0,0],\r\n    [1,0,1,0],\r\n    [0,0,0,1],\r\n    [0,0,1,0],\r\n    [1,0,0,1]]\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Embedding\r\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\r\nimport numpy as np\r\n\r\n\r\nX = np.array(X)\r\nY = np.array(Y)\r\nMAXLEN = 7\r\nMAXFEATURES = 4\r\nNUM_CLASSES = 4\r\nmodel = Sequential()\r\nmodel.add(Embedding(MAXFEATURES+1,\r\n                    50,\r\n                    input_length=MAXLEN))\r\nmodel.add(GlobalAveragePooling1D())\r\nmodel.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\nmodel.fit(X, Y,\r\n          batch_size=1,\r\n          epochs=200,\r\n          validation_data=(X, Y))\r\n```", "comments": ["I ran the code shared, please find the accuracy for [tf 2.2](https://colab.research.google.com/gist/Saduf2019/c8ce0b0ca9528248a67571c3f0d574d3/untitled259.ipynb) [tf 2.1](https://colab.research.google.com/gist/Saduf2019/720f9afebd68b6d6f89c6564282f23b6/untitled256.ipynb) [tf-nightly](https://colab.research.google.com/gist/gowthamkpr/6487b7f6c0e5b584f5be21ad48fc47b6/untitled298.ipynb)", "@amaiya I think this is related to a know issue. We can track the progress [here](https://github.com/tensorflow/tensorflow/issues/42045).\r\n\r\nSimple workaround is to change `'accuracy'` to `'binary_accuracy'`. When I modified your code, everything working well in TF2.3 similar to TF2.1. [Here](https://colab.research.google.com/gist/jvishnuvardhan/0a8f1a05f8d5dd55a8539cad07a99500/untitled256.ipynb) is the gist for your reference. Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. We can track progress of the root-cause in another issue mentioned above. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks, @jvishnuvardhan  \r\n\r\nI confirm that everything works when changing `accuracy` to `binary_accuracy` in both TF 2.1 and TF 2.2.  As this was [indicated to be a bug](https://github.com/tensorflow/tensorflow/issues/42045#issuecomment-674232499), I assume the old behavior of `accuracy` will return in TF 2.4.", "@amaiya I will close this issue and track the progress in that issue I mentioned in last response. Thanks!\r\n\r\nOnce the bug is resolved, I will also comment here. Thanks", "This is resolved in recent tf-nightly. Please feel free to reopen if you notice the issue.\r\nThis is available in stable TF2.4 in the near future. Thanks!", "@jvishnuvardhan I just tested this with `tf-nightly` and it is still broken when using `accuracy`. The issue should probably be re-opened, so that it can be resolved before stable TF 2.4 is released. Thanks."]}, {"number": 41113, "title": "SyncBatchNormalization layer segfaults on multi-worker with NCCL", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04 (in a Docker container, on an 18.04 host)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.24.1-3.0\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Nvidia TITAN X 11GB\r\n\r\n**Describe the current behavior**\r\nWhen training models with the `tf.keras.layers.experimental.SyncBatchNormalization` layer, and using `tf.distribute.experimental.MultiWorkerMirroredStrategy` to train across multiple workers with `tf.distribute.experimental.CollectiveCommunication.NCCL` communication, the model trains for some amount of time (e.g. several thousand steps), then crashes with a segfault.\r\n\r\n**Describe the expected behavior**\r\nThe model should train without segfaulting.\r\n\r\n**Standalone code to reproduce the issue**\r\nAn example is below. **Please note that this code must run on multiple workers.** The TF_CONFIG environment variable must be set appropriately for your specific multi-worker configuration. \r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ndef get_dataset():\r\n    x = tf.zeros([10], dtype=tf.float32)\r\n    x = tf.data.Dataset.from_tensors(x)\r\n\r\n    y = tf.constant([5])\r\n    y = tf.data.Dataset.from_tensor_slices(y)\r\n\r\n    dataset = tf.data.Dataset.zip((x, y))\r\n    dataset = dataset.batch(1)\r\n    dataset = dataset.repeat()\r\n    return dataset\r\n\r\ndef main():\r\n    # NOTE: You must set os.environ[\"TF_CONFIG\"] as appropriate\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)\r\n    # assert strategy.num_replicas_in_sync == 2\r\n\r\n    # Create dataset\r\n    dataset = get_dataset()\r\n\r\n    with strategy.scope():\r\n        # Construct model\r\n        model = keras.Sequential(\r\n            layers=[\r\n                tf.keras.layers.experimental.SyncBatchNormalization(),\r\n                tf.keras.layers.Dense(1),\r\n            ]\r\n        )\r\n        model.compile(\r\n            optimizer=keras.optimizers.Adam(),\r\n            loss=keras.losses.MeanSquaredError(),\r\n        )\r\n\r\n    model.fit(x=dataset, steps_per_epoch=10 ** 6, epochs=10 ** 3)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThis is reproducible across a wide array of contexts, for example a Keras model, an Estimator model, different GPU types, etc.\r\n\r\n**Other info / logs**\r\nI used `gdb` to inspect a coredump from the crashed process. The backtrace is:\r\n```\r\n#0  0x00007f1d68cef711 in tensorflow::NcclReducer::Run(std::function<void (tensorflow::Status const&)>) (this=this@entry=0x7f18cc011af0, \r\n    done=...) at external/org_tensorflow/tensorflow/core/kernels/collective_nccl_reducer.cc:185\r\n#1  0x00007f1d71797ca6 in tensorflow::BaseCollectiveExecutor::<lambda()>::operator()(void) const (__closure=<optimized out>)\r\n    at external/org_tensorflow/tensorflow/core/common_runtime/base_collective_executor.cc:276\r\n#2  0x00007f1d71797efe in std::_Function_handler<void(), tensorflow::BaseCollectiveExecutor::ExecuteAsync(tensorflow::OpKernelContext*, const tensorflow::CollectiveParams&, const string&, tensorflow::StatusCallback)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:316\r\n#3  0x00007f1d669a0e08 in std::function<void ()>::operator()() const (this=this@entry=0x7f185e7fbe60)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:706\r\n#4  0x00007f1d71cc4f44 in tensorflow::UnboundedWorkQueue::PooledThreadFunc (this=0x20758660)\r\n    at external/org_tensorflow/tensorflow/core/platform/default/unbounded_work_queue.cc:99\r\n#5  0x00007f1d71cc5004 in tensorflow::UnboundedWorkQueue::<lambda()>::operator() (__closure=<optimized out>)\r\n    at external/org_tensorflow/tensorflow/core/platform/default/unbounded_work_queue.cc:68\r\n#6  std::_Function_handler<void(), tensorflow::UnboundedWorkQueue::Schedule(tensorflow::UnboundedWorkQueue::WorkFunction)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...) at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:316\r\n#7  0x00007f1d669a0e08 in std::function<void ()>::operator()() const (this=<optimized out>)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:706\r\n#8  0x00007f1d71d136dd in std::__invoke_impl<void, std::function<void ()>>(std::__invoke_other, std::function<void ()>&&) (__f=...)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/invoke.h:60\r\n#9  std::__invoke<std::function<void ()>>(std::function<void ()>&&) (__fn=...) at external/gcc_7_4/usr/include/c++/7/bits/invoke.h:95\r\n#10 std::thread::_Invoker<std::tuple<std::function<void ()> > >::_M_invoke<0ul>(std::_Index_tuple<0ul>) (this=<optimized out>)\r\n    at external/gcc_7_4/usr/include/c++/7/thread:234\r\n#11 std::thread::_Invoker<std::tuple<std::function<void ()> > >::operator()() (this=<optimized out>)\r\n    at external/gcc_7_4/usr/include/c++/7/thread:243\r\n#12 std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::function<void ()> > > >::_M_run() (this=<optimized out>)\r\n    at external/gcc_7_4/usr/include/c++/7/thread:186\r\n#13 0x00007f1d2eb72ae0 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#14 0x00007f1da0c12184 in start_thread (arg=0x7f185e7fc700) at pthread_create.c:312\r\n#15 0x00007f1d9fdef03d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\r\n```\r\n\r\nDisassembling the function showed that this was the offending instruction:\r\n```\r\n   0x00007f1d68cef707 <+2651>:  jg     0x7f1d68cf0642 <tensorflow::NcclReducer::Run(std::function<void (tensorflow::Status const&)>)+6550>\r\n   0x00007f1d68cef70d <+2657>:  mov    0x18(%rbx),%rax\r\n=> 0x00007f1d68cef711 <+2661>:  mov    0x8(%rax),%rdi\r\n   0x00007f1d68cef715 <+2665>:  mov    (%rdi),%rax\r\n   0x00007f1d68cef718 <+2668>:  mov    0x20(%rbx),%rsi\r\n```\r\n\r\nAnd printing out the registers shows `rax            0x0                 0`, so some sort of pointer is set to 0. It therefore looks like there is some sort of null pointer exception in line 185 of `collective_nccl_reducer.cc`, which I believe is the line `col_ctx_->col_exec->UnblockDependencies(*col_params_);`. I don't have any idea why it would segfault there, however. The same line appears shortly above on line 176, so it's strange that it would segfault the second time.\r\n\r\nAlso, a log is attached [here](https://github.com/tensorflow/tensorflow/files/4875867/sbn_multinode_log.txt), however it is not very interesting as it just runs for a while and then segfaults.", "comments": ["@MinasTyuru \r\n\r\nI have tried in colab with TF version 2.2 and i am seeing the error message`(ModuleNotFoundError: No module named 'tflight'`).Request you to share colab link or simple standaalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!\r\n`", "@ravikyram Oops, sorry about that. I removed the line that was the problem and it should work now. Please keep in mind that the code **must run on multiple workers** to reproduce the issue. As far as I know, this is not possible on Google Colab.", "Hi @MinasTyuru, thanks for providing very detailed debugging information. BTW you can use virtual GPUs in colab to simulate a multiworker environment, but NCCL is not supported in this case, so probably not helpful for debugging this particular issue.\r\n\r\nCan you confirm that you do not see this issue if the  CollectiveCommunication is set to AUTO? Additionally, can you try and run on TF nightly and let me know what happens?", "@nikitamaia Thank you for the information! Yes, that's correct. Using AUTO or RING seems to work fine. Running on TF nightly may be a bit tricky on our infrastructure, I will get back to you on that.", "@nikitamaia Hi Nikita, I was able to reproduce on TF-nightly `2.4.0.dev20200708`. When using `AUTO` it works fine, but when using `NCCL` it immediately segfaults. Attached are [the failed log with NCCL](https://github.com/tensorflow/tensorflow/files/4893737/nccl_bad_log.txt) and [the successful log with AUTO](https://github.com/tensorflow/tensorflow/files/4893739/auto_good_log.txt).\r\n\r\n", "@MinasTyuru thank you for the report. It seems to be the case from the title, but I would like to confirm: does this issue only show up when using SyncBatchNormalization layer? (And goes away when not using it, or using a regular batch norm).\r\n\r\nGetting a segfault is terrible, we will look into it. \r\n\r\nWe have used SyncBatchNormalization for some models before with multi worker, so I am trying to see what's different here since your repro is quite simple. Would you mind trying one thing: Can you make the batch size bigger? Currently seems 1. Usually we try to split the batch across the replicas but since batch size of 1 cannot be split, the other replicas will end up getting empty batches. I am wondering if that's what is triggering this. Although, it would not explain why it works for some steps and then fails.. \r\n\r\n\r\n", "After some more investigation, it looks like we can reproduce the issue in some contexts but not others, so it's possible that it is some sort of configuration issue. I thought that I was able to reproduce on TF-nightly, but I believe that was due to a mistake I made when installing CUDA, and now I think it may work fine on TF-nightly. It may be related to how we build TensorFlow from source or something of that nature. I will investigate some more and let you know if it seems to be a problem on our end or not.", "thanks for the update @MinasTyuru .\r\n@dubey is looking into the segfault more - he thinks there is a possible race condition which might be leading to the seg fault and he is looking into a possible fix.\r\n\r\nRe: nightly, yes, your logs indicated that the issue with the nightly was that it was not able to find the GPUs and hence failed right away. I would guess that once you fix that issue, it may probably run into the segfault at some point later like with 2.2. \r\n\r\n\r\n\r\n", "Yes, we are seeing something similar. When I used a debugger, it changed the behavior. For example, it seems like adding a breakpoint after line 176 of `collective_nccl_reducer.cc`, which introduces a very small delay, causes TensorFlow to immediately segfault. In this case, it seems that the `col_ctx_` variable is set to a null pointer by `bfc_allocator.cc`. Perhaps this memory is inappropriately freed before it is finished being used? Is this behavior consistent with your hypothesis of the race condition? I'll post some more logs in ~12 hours.\r\n\r\nWe tried to reproduce on TF2.2 and TF-nightly, and on a clean build (i.e. installing TensorFlow from pip, etc.), it seems like it trains for a long time without any problems. But in our production environment (which changes some of the dependencies in the TensorFlow build and other build differences), we encounter the segfault, so perhaps subtle timing differences are triggering the underlying issue.", "Attached are a [stacktrace](https://github.com/tensorflow/tensorflow/files/4920487/stacktrace.txt) from when `col_ctx_` is set to 0 by the memory allocator, and the [assembly](https://github.com/tensorflow/tensorflow/files/4920489/assembly.txt) around that line. Thanks again!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41113\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41113\">No</a>\n", "@MinasTyuru I just submitted a change that should help with this issue.  Feel free to reopen if you encounter the segfault again.", "Should `col_impl` get a similar treatment too? If `col_ctx` could be freed prematurely, then so could `col_impl`.", "Thanks Ayush! I will test this out and see if it works.\r\n\r\n~Shimin, it looks to me like `col_impl` is a member of the `col_ctx` object and therefore does not need to be managed separately (it will be allocated and freed along with `col_ctx`).~ Oops, I meant `col_params_`, never mind.", "@dubey It seems like the change fixes the `col_ctx_` problem, however I'm still experiencing segfaults. I now observe that `col_ctx_` is nonzero pointer, however `col_ctx_->col_exec` is a zero pointer, like so:\r\n```\r\n(gdb) bt\r\n#0  0x00007fffbf8911a7 in tensorflow::NcclReducer::Run(std::function<void (tensorflow::Status const&)>) (this=0x7ffd9800f360, done=...)\r\n    at external/org_tensorflow/tensorflow/core/kernels/collective_nccl_reducer.cc:185\r\n#1  0x00007fffc83399e4 in tensorflow::BaseCollectiveExecutor::<lambda()>::operator() (__closure=<optimized out>)\r\n    at external/org_tensorflow/tensorflow/core/common_runtime/base_collective_executor.cc:275\r\n#2  std::_Function_handler<void(), tensorflow::BaseCollectiveExecutor::ExecuteAsync(tensorflow::OpKernelContext*, const tensorflow::CollectiveParams&, const string&, tensorflow::StatusCallback)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:316\r\n#3  0x00007fffbd5425c8 in std::function<void ()>::operator()() const (this=this@entry=0x7ffabcffce60)\r\n    at external/gcc_7_4/usr/include/c++/7/bits/std_function.h:706\r\n#4  0x00007fffc88674de in tensorflow::UnboundedWorkQueue::PooledThreadFunc (this=0x1ed20c40)\r\n    at external/org_tensorflow/tensorflow/core/platform/default/unbounded_work_queue.cc:99\r\n...\r\n(gdb) p col_ctx_\r\n$1 = std::shared_ptr<tensorflow::CollectiveContext> (use count 33194781, weak count -92074895) = {get() = 0x7ffd00555043}\r\n(gdb) p col_params_\r\n$2 = (const tensorflow::CollectiveParams *) 0x7fffc838ca46\r\n     <std::_Function_handler<void(), tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, tensorflow::int64)::<lambda()> >::_M_invoke(const std::_Any_data &)>\r\n(gdb) p col_ctx_->col_exec\r\n$3 = (tensorflow::CollectiveExecutor *) 0x0\r\n```\r\n\r\nI think that maybe `CollectiveExecutor` needs to be a shared pointer as well? And, as Shimin said, possibly `col_impl` also.\r\n\r\nAlso I think I don't have the required permissions to reopen this issue, so I'm just commenting on it.", "Thanks for the update.  Let me follow up internally.", "Shimin implemented the change that he suggested with `col_impl`:\r\n\r\n```\r\ndiff --git a/tensorflow/core/common_runtime/base_collective_executor.cc b/tensorflow/core/common_runtime/base_collective_executor.cc\r\nindex 0eebab9cf53..4d95059d018 100644\r\n--- a/tensorflow/core/common_runtime/base_collective_executor.cc\r\n+++ b/tensorflow/core/common_runtime/base_collective_executor.cc\r\n@@ -246,20 +246,20 @@ void BaseCollectiveExecutor::ExecuteAsync(OpKernelContext* ctx,\r\n                           col_params.is_source))\r\n                             ? &ctx->input(0)\r\n                             : nullptr;\r\n-  CollectiveImplementationInterface* col_impl = nullptr;\r\n-  Status status = CreateCollective(col_params, &col_impl);\r\n+  CollectiveImplementationInterface* col_impl_ptr = nullptr;\r\n+  Status status = CreateCollective(col_params, &col_impl_ptr);\r\n   if (!status.ok()) {\r\n     done_safe(status);\r\n-    TF_DCHECK_EQ(nullptr, col_impl);\r\n+    TF_DCHECK_EQ(nullptr, col_impl_ptr);\r\n     return;\r\n   }\r\n+  auto col_impl = std::shared_ptr<CollectiveImplementationInterface>(col_impl_ptr);\r\n   auto col_ctx = std::make_shared<CollectiveContext>(\r\n       this, dev_mgr_, ctx, CtxParams(ctx), col_params, exec_key, step_id_,\r\n       input, output);\r\n   status = col_impl->InitializeCollectiveContext(col_ctx);\r\n   if (!status.ok()) {\r\n     done_safe(status);\r\n-    delete col_impl;\r\n     return;\r\n   }\r\n   // Run on an unbounded work queue that can handle blocking work so as to not\r\n@@ -274,7 +274,6 @@ void BaseCollectiveExecutor::ExecuteAsync(OpKernelContext* ctx,\r\n         profiler::TraceMeLevel::kInfo);\r\n     col_impl->Run([col_impl, col_ctx, done_safe](const Status& s) {\r\n       done_safe(s);\r\n-      delete col_impl;\r\n     });\r\n   });\r\n }\r\n```\r\n\r\nI'm not sure what the relationship is between `col_impl` and the `col_exec` variable that seemed to be null previously, but it seems to fix the segfault. I'm doing some additional testing to be sure and will keep you posted.", "Thanks, I was working on a similar change internally, this time with a unit test that can reproduce the issue.  Yes please do keep me posted.", "Apologies for the delay, it looks like everything works without segfaulting now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41113\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41113\">No</a>\n"]}, {"number": 41112, "title": "[RPI Zero] ModuleNotFoundError: No module named 'tflite_runtime'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian GNU/Linux 10 (buster)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi Zero\r\n- TensorFlow installed from (source or binary): Compile natively on Raspberry Pi using https://www.tensorflow.org/lite/guide/build_rpi\r\n- TensorFlow version: Trying to install and Tensorflow lite as a standalone\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\nTrying to install Tensorflow Lite on RPI Zero as a standalone. However once installation is complete as per the following steps,\r\nsudo apt-get install build-essential\r\ngit clone https://github.com/tensorflow/tensorflow.git tensorflow_src\r\ncd tensorflow_src && ./tensorflow/lite/tools/make/download_dependencies.sh\r\n./tensorflow/lite/tools/make/build_rpi_lib.sh\r\n\r\nI can not import,\r\nimport tflite_runtime.interpreter as tflite\r\n\r\nError I am getting is \r\nModuleNotFoundError: No module named 'tflite_runtime'\r\n\r\nIn addition as per the instructions, I should see a static library. I do not see this either.\r\n`tensorflow/lite/tools/make/gen/lib/rpi_armv6/libtensorflow-lite.a`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["I am still facing this issue on RPI Zero.", "This are prebuilt Python wheels of tflite_runtime package. https://www.tensorflow.org/lite/guide/python\r\nBut I'm not sure it's compatible with RPI Zero.\r\n\r\nIf it doesn't work, you might need to build it by yourself.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package will help.", "t\r\n\r\n> This are prebuilt Python wheels of tflite_runtime package. https://www.tensorflow.org/lite/guide/python\r\n> But I'm not sure it's compatible with RPI Zero.\r\n> \r\n> If it doesn't work, you might need to build it by yourself.\r\n> https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package will help.\r\n\r\nI am using https://www.tensorflow.org/lite/guide/build_rpi. For Compile natively on Raspberry Pi.\r\n\r\nThe site states that \"The following instructions have been tested on Raspberry Pi Zero, Raspbian GNU/Linux 10 (buster), gcc version 8.3.0 (Raspbian 8.3.0-6+rpi1)\".\r\n\r\nSo I am puzzled at this thing not working on rpi zero and giving the error. I have done it a few times with the same error. The site which you are referring to does not have arm6l whl.", "libtensorflow-lite.a will work with your RPI zero. But it's C library not Python.\r\n\r\nYou might be able to build it on **RPI zero** with the following command.\r\n```\r\nsudo apt install swig libjpeg-dev zlib1g-dev python3-dev python3-numpy\r\npip install numpy pybind11\r\nsh tensorflow/lite/tools/make/download_dependencies.sh\r\nsh tensorflow/lite/tools/pip_package/build_pip_package.sh\r\n```", "> libtensorflow-lite.a will work with your RPI zero. But it's C library not Python.\r\n> \r\n> You might be able to build it on **RPI zero** with the following command.\r\n> \r\n> ```\r\n> sudo apt install swig libjpeg-dev zlib1g-dev python3-dev python3-numpy\r\n> pip install numpy pybind11\r\n> sh tensorflow/lite/tools/make/download_dependencies.sh\r\n> sh tensorflow/lite/tools/pip_package/build_pip_package.sh\r\n> ```\r\n\r\nterryheo...it ran something as it says on webpage but it is giving error. I am trying on RP4 now as RP0 is slow and if I can make whl on RP4, I can try on RP0 later.\r\n\r\nI had to modify commands like this 'cd tensorflow_src && ./tensorflow/lite/tools/pip_package/build_pip_package.sh'\r\n\r\ncollect2: error: ld returned 1 exit status\r\nmake: *** [tensorflow/lite/tools/make/Makefile:341: /home/pi/tensorflow_src/tensorflow/lite/tools/make/gen/linux_armv7l/bin/minimal] Error 1\r\nmake: Leaving directory '/home/pi/tensorflow_src'\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 227, in <module>\r\n    'build_py': CustomBuildPy,\r\n  File \"/usr/local/lib/python3.7/dist-packages/setuptools/__init__.py\", line 165, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/bdist.py\", line 143, in run\r\n    self.run_command(cmd_name)\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/bdist_dumb.py\", line 81, in run\r\n    self.run_command('build')\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n    self.run_command(cmd_name)\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 133, in run\r\n    self.run_command('build_ext')\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 125, in run\r\n    make()\r\n  File \"setup.py\", line 105, in make\r\n    subprocess.check_call(make_args(quiet=False))\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 347, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['make', 'SHELL=/bin/bash', 'BUILD_WITH_NNAPI=false', '-C', '/home/pi/tensorflow_src/tensorflow/lite/tools/pip_package/../../../..', '-f', 'tensorflow/lite/tools/make/Makefile', '-j', '1']' returned non-zero exit status 2.\r\n", "and where does it create whl file, when it creates.", "If you're using RPI4, just use prebuilt from https://www.tensorflow.org/lite/guide/python", "> If you're using RPI4, just use prebuilt from https://www.tensorflow.org/lite/guide/python\r\n\r\nI did that but my end goal is to work on RPi Zero and I am struggling. Not an expert so learning as I go. The instructions are failing from the link. Not sure if I am missing something. The sh commands are not working as it is so I am modifying as mentioned above. \r\n", "FYI\r\n\r\nI was able to find a working solution for running tensorflow(lite as well) on the ARM6 based raspberry pi (like the zero or the Pi1):\r\n\r\n- get a pre compilied tf python wheel from https://github.com/lhelontra/tensorflow-on-arm/releases or compile it on your own. \r\n- Install it on the device using pip3.\r\n\r\nin python:\r\n\r\n```\r\nimport tensorflow as  tf\r\n\r\nprint(str(tf.__version__)) # should print the version\r\ninterpreter = tf.lite.Interpreter(model_path) # for example if you just need the python tf lite runtime \r\n```\r\n\r\nAfter a long time looking for a good solution and struggling with static libs and cross compiling, I found this working pretty well and easy!", "Hi @rajurimu ! Inline with above comment.\r\nWe are checking to see whether you still need help in this issue . Have you checked these threads yet?[ link1,](https://www.tensorflow.org/lite/guide)[link2](https://github.com/tensorflow/tensorflow/issues/35663),[link3](https://stackoverflow.com/questions/62749168/modulenotfounderror-no-module-named-tflite-runtime),[link4 ](https://blog.paperspace.com/tensorflow-lite-raspberry-pi/). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41112\">No</a>\n"]}, {"number": 41111, "title": "Bug: tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor X with dtype Y and shape X ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): >= 2.0\r\n- Python version: 3.6\r\n- Running on: CPUs (But I guess it happens on GPUs as well)\r\n\r\nFrom my experience, this type of bug appears very often (I have posted a similar bug before https://github.com/tensorflow/tensorflow/issues/40977). Here is a (dumb) example where I write a custom layer and pass a parameter via __init__() when I call that layer (Note that I turn off eager_execution). Running the following code results in the below error:\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\nimport numpy as np\r\n\r\nclass MyWordEmbedding(tf.keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')\r\n        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end\r\n    \r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])\r\n\r\nclass EncoderLayer(tf.keras.layers.Layer):\r\n    def __init__(self, mask_para, **kwargs):\r\n        self.mask_para = mask_para\r\n        super(EncoderLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))\r\n        super(EncoderLayer, self).build(input_shape)\r\n\r\n    def call(self, x):\r\n        Qoutput = tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Koutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Voutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        a = tf.einsum('ajk,afk->ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(self.mask_para, axis=1), [1, 64, 1])\r\n        a = tf.matmul(a, Voutput)\r\n        return a\r\n\r\n    def compute_mask(self, inputs, mask):\r\n        return mask\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\ndef create_encoder_model():\r\n    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = MyWordEmbedding()([word_ids_fr])\r\n    a = EncoderLayer(K.cast(K.not_equal(0, word_ids_fr), dtype='float32'))([a])\r\n    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)\r\n    return model\r\n\r\ndef create_model():\r\n    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = tf.keras.Input(shape=(None, 512,))\r\n    b = MyWordEmbedding()([word_ids_en])\r\n    b = b + a\r\n    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)\r\n    return model\r\n    \r\ndef evaluate():\r\n    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')\r\n    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)\r\n\r\ndecoder_model = create_model()\r\nencoder_model = create_encoder_model()\r\nevaluate()\r\n```\r\nError:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype int32 and shape [?,?]\r\n\t [[{{node input_3}}]]\r\n```\r\n\r\nFixing this error is easy for this case because I know exactly where (see the solution below). In detail I pass the para though call function and not the __init__ function. Nonetheless finding this error in a big project is very difficult because I need to throw many lines of code to know exactly where it causes the error.\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\nimport numpy as np\r\n\r\nclass MyWordEmbedding(tf.keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')\r\n        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end\r\n    \r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])\r\n\r\nclass EncoderLayer(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(EncoderLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))\r\n        super(EncoderLayer, self).build(input_shape)\r\n\r\n    def call(self, x):\r\n        Qoutput = tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Koutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        Voutput =  tf.einsum('aij,jk->aik', x[0], self.Qdense)\r\n        mask_para = x[1]\r\n        a = tf.einsum('ajk,afk->ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(mask_para, axis=1), [1, 64, 1])\r\n        a = tf.matmul(a, Voutput)\r\n        return a\r\n\r\n    def compute_mask(self, inputs, mask):\r\n        return mask\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\ndef create_encoder_model():\r\n    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = MyWordEmbedding()([word_ids_fr])\r\n    a = EncoderLayer()([a, K.cast(K.not_equal(0, word_ids_fr), dtype='float32')])\r\n    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)\r\n    return model\r\n\r\ndef create_model():\r\n    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))\r\n    a = tf.keras.Input(shape=(None, 512,))\r\n    b = MyWordEmbedding()([word_ids_en])\r\n    b = b + a\r\n    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)\r\n    return model\r\n    \r\ndef evaluate():\r\n    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')\r\n    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)\r\n\r\ndecoder_model = create_model()\r\nencoder_model = create_encoder_model()\r\nevaluate()\r\n```\r\n", "comments": ["I am able to replicate this issue, please find the [gist here.](https://colab.research.google.com/gist/Saduf2019/c727e3fb2ca4ec5321fdd842a29c7b13/untitled260.ipynb)", "@hoangcuong2011 As this is a duplicate of the issue #40977 lets close the issue here and track it in one single place. thanks!", "@gowthamkpr if you look at the code carefully you will notice the source of the error is *very* different. \r\nI am fine if you want me close this one. I am just not sure once #40977 is fixed this one is fixed as well (because they are different).", "@hoangcuong2011 As you figured out how this error is being caused, are you saying that we need to improve the error message so we can easily debug this issue? ", "No. I suggested it is a bug. \r\n", "@hoangcuong2011 I am gonna go ahead and close this issue as it a duplicate and lets track it here #40977. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41111\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41111\">No</a>\n"]}, {"number": 41110, "title": "Artistic Style Transfer Android Demo missing \"Style blending\" code", "body": "Hi,\r\n\r\nI have two questions regarding \"Artistic Style Transfer with TensorFlow Lite\"\r\nhttps://www.tensorflow.org/lite/models/style_transfer/overview\r\n\r\n**1) Style Blending Missing in Android**\r\n\r\nIn [Artistic Style Transfer with TensorFlow Lite](https://www.tensorflow.org/lite/models/style_transfer/overview) blog, there is complete section for \"[Style blending](https://www.tensorflow.org/lite/models/style_transfer/overview#style_blending)\" which says\r\n> We can blend the style of content image into the stylized output, which in turn making the output look more like the content image. \r\n```\r\n# Define content blending ratio between [0..1].\r\n# 0.0: 0% style extracts from content image.\r\n# 1.0: 100% style extracted from content image.\r\n```\r\n\r\nBut in the [Android Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/android) for the same, there is no option or code for \"Style Blending\".\r\n\r\nCould you provide some code or guide me on how to achieve this in Android?\r\n\r\n**2) Face Blending**\r\n\r\nIf I am doing artistic style transfer on any portrait images, the face looks too wrinkled. Is there any technique to make the face look better? Something like,\r\nhttps://github.com/zfergus/face-preserving-style-transfer\r\n\r\n", "comments": ["@Khanh is this expected?", "> 1) Style Blending Missing in Android\r\n\r\nYou can follow the logic described in the [notebook](https://www.tensorflow.org/lite/models/style_transfer/overview#style_blending): \r\n1. run style_predict with your content image\r\n1. mix the style bottleneck of your content image and style image\r\n`blended_bottleneck = alpha * content_bottleneck + (1-alpha) * style_bottleneck`\r\n1. run style_transform with content_image and blended_bottleneck.\r\n\r\nYou can also refer to a community implementation here:\r\nhttps://github.com/farmaker47/video_style_transfer\r\n\r\n> 2) Face Blending\r\n\r\nYou can try with a different style transfer model which is larger but produce higher quality images here:\r\nhttps://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@InternetMaster1 Did I answer your question in [this comment](https://github.com/tensorflow/tensorflow/issues/41110#issuecomment-660772317)?", "Dear @khanhlvg ,\r\n\r\nMany thanks for your reply. \r\n\r\nThe logic for blending was clear, but I wasn't aware how to implement the same in Java for Android\r\n\r\nI will try our the code provided in your linked repo regarding blending\r\n\r\nhttps://github.com/farmaker47/video_style_transfer/blob/28e38183a1186036b7ae76640d59b6ac5aac109a/styleTransferModule/src/main/java/com/george/lite/examples/video_style_transfer/lib/StyleTransferModelExecutor.kt#L159\r\n\r\nMany thanks!", "@InternetMaster1 Could you please let us know if this is still an issue ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41110\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41110\">No</a>\n"]}, {"number": 41109, "title": "tensorflow hub pre-trained model hults training on custom given data due to EarlyStopping error", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nEverything written here is based on this [online link](https://www.tensorflow.org/hub/tutorials/tf2_text_classification) from tensorflow.\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import models\r\nfrom tensorflow.keras.models import load_model\r\nfrom tensorflow.keras.models import model_from_json\r\nfrom tensorflow.keras import regularizers\r\nimport tensorflow_docs.modeling as tfmodel\r\n\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n\r\nimport tensorflow_hub as hub\r\n\r\npartial_x_train_features=np.array([b'south pago pago victor mclaglen jon hall frances farmer olympe bradna gene lockhart douglass dumbrille francis ford ben welden abner biberman pedro cordoba rudy robles bobby stone nellie duran james flavin nina campana alfred e green treasure hunt adventure adventure',\r\n b'easy virtue jessica biel ben barnes kristin scott thomas colin firth kimberley nixon katherine parkinson kris marshall christian brassington charlotte riley jim mcmanus pip torrens jeremy hooton joanna bacon maggie hickey georgie glen stephan elliott young englishman marry glamorous american brings home meet parent arrive like blast future blow entrenched british stuffiness window comedy romance',\r\n b'fragments antonin gregori derangere anouk grinberg aurelien recoing niels arestrup yann collette laure duthilleul david assaraf pascal demolon jean baptiste iera richard sammel vincent crouzet fred epaud pascal elso nicolas giraud michael abiteboul gabriel le bomin psychiatrist probe mind traumatized soldier attempt unlock secret drove gentle deeply disturbed world war veteran edge insanity drama war',\r\n b'milka film taboos milka elokuva tabuista irma huntus leena suomu matti turunen eikka lehtonen esa niemela sirkka metsasaari tauno lehtihalmes ulla tapaninen toivo tuomainen hellin auvinen salmi rauni mollberg small finnish lapland community milka innocent year old girl live mother miss dead father prays god love haymaking employ drama',\r\n b'sleeping car david naughton judie aronson kevin mccarthy jeff conaway dani minnick ernestine mercer john carl buechler gary brockette steve lundquist billy stevenson michael scott bicknell david coburn nicole hansen tiffany million robert ruth douglas curtis jason david naughton move abandon train car resurrect vicious ghost landlady dead husband mister near fatal encounter comedy horror'])\r\n\r\npartial_x_train_plot=np.array([b'treasure hunt adventure',\r\n b'young englishman marry glamorous american brings home meet parent arrive like blast future blow entrenched british stuffiness window',\r\n b'psychiatrist probe mind traumatized soldier attempt unlock secret drove gentle deeply disturbed world war veteran edge insanity',\r\n b'small finnish lapland community milka innocent year old girl live mother miss dead father prays god love haymaking employ',\r\n b'jason david naughton move abandon train car resurrect vicious ghost landlady dead husband mister near fatal encounter'])\r\n\r\npartial_x_train_actors_array=np.array([np.array([b'victor mclaglen', b'jon hall', b'frances farmer',\r\n       b'olympe bradna', b'gene lockhart', b'douglass dumbrille',\r\n       b'francis ford', b'ben welden', b'abner biberman',\r\n       b'pedro de cordoba', b'rudy robles', b'bobby stone',\r\n       b'nellie duran', b'james flavin', b'nina campana'], dtype='|S18'),\r\nnp.array([b'jessica biel', b'ben barnes', b'kristin scott thomas',\r\n       b'colin firth', b'kimberley nixon', b'katherine parkinson',\r\n       b'kris marshall', b'christian brassington', b'charlotte riley',\r\n       b'jim mcmanus', b'pip torrens', b'jeremy hooton', b'joanna bacon',\r\n       b'maggie hickey', b'georgie glen'], dtype='|S21'),\r\nnp.array([b'gregori derangere', b'anouk grinberg', b'aurelien recoing',\r\n       b'niels arestrup', b'yann collette', b'laure duthilleul',\r\n       b'david assaraf', b'pascal demolon', b'jean-baptiste iera',\r\n       b'richard sammel', b'vincent crouzet', b'fred epaud',\r\n       b'pascal elso', b'nicolas giraud', b'michael abiteboul'],\r\n      dtype='|S18'),\r\nnp.array([b'irma huntus', b'leena suomu', b'matti turunen',\r\n       b'eikka lehtonen', b'esa niemela', b'sirkka metsasaari',\r\n       b'tauno lehtihalmes', b'ulla tapaninen', b'toivo tuomainen',\r\n       b'hellin auvinen-salmi'], dtype='|S20'),\r\nnp.array([b'david naughton', b'judie aronson', b'kevin mccarthy',\r\n       b'jeff conaway', b'dani minnick', b'ernestine mercer',\r\n       b'john carl buechler', b'gary brockette', b'steve lundquist',\r\n       b'billy stevenson', b'michael scott-bicknell', b'david coburn',\r\n       b'nicole hansen', b'tiffany million', b'robert ruth'], dtype='|S22')], dtype=object)\r\n\r\npartial_x_train_reviews=np.array([b'edward small take director alfred e green cast crew uncommonly attractive brilliant assemblage south sea majority curiously undersung piece location far stylize date goldwyn hurricane admittedly riddle cliche formula package visual technical excellence scarcely matter scene stop heart chiseled adonis jon hall porcelain idol frances farmer outline profile s steam background volcano romantic closeup level defies comparison edward small film typically string frame individual work art say outdid do workhorse composer edward ward song score year prior work universal stun phantom opera',\r\n b'jessica biel probably best know virtuous good girl preacher kid mary camden heaven get tackle classic noel coward role early play easy virtue american interloper english aristocratic family unsettle family matriarch kristin scott thomas noel coward write upper class twit pretension wit keep come kind adopt way adopt oscar wilde george bernard shaw kid grow poverty way talent entertain upper class take coward heart felt modern progressive generally term social trend whittakers easy virtue kind aristocrat anybody like hang party invite noel entertain amelia earhart aviation jessica biel character auto race young widow detroit area course area motor car auto race fresh win monte carlo win young ben barnes heir whittaker estates lot land debt barnes bring biel home family mortify classless american way sense recognize class distinction thing get rid title nobility aristocrats story scott thomas dominate family try desperately estate husband colin firth serve world war horror do probably horror trench war slaughter fact class distinction tend melt combat biel kind like wife rule whittaker roost scandal past threatens disrupt barnes biel marriage form crux story turn fact end really viewer figure eventually happen second film adaption easy virtue silent film direct young alfred hitchcock easy virtue actually premier america london star great american stage actress jane cowl guess coward figure american heroine best american theatergoer british one version easy virtue direct flawlessly stephen elliot fine use period music noel coward cole porter end credit really mock upper class coward tradition play going gets tough tough going believe elliott try say class especially one right stuff course obligatory fox hunt upper class indulge oscar wilde say unspeakable uneatable chance younger generation expose noel coward worth see',\r\n b'saw night eurocine event movie european country show day european city hear le bomin barely hear derangere la chambre des officiers fortunately surprise discover great talent unknown large audience derangere absolutely astonish play character antonin verset victim post wwi trauma live trouble scene endure month war cast excellent great work cinematography offer really nice shot great landscape stun face edit really subtile bit memory make sense story minute movie show real chill ww archive action flick like sensitive psychologic movie really think absolutely recommend les fragments d antonin let le bomin',\r\n b'rauni mollberg earth sinful song favorite foreign film establish director major talent film festival circuit get amazing followup milka base work novelist timo mukka till worthy major dvd exposure unlike kaurismaki bros follow double handedly create tongue cheek deadpan finnish film style fan world mollberg commit naturalistic approach film overflow nature life lust earthiness find scandi cinema mainly work famous talent swede vilgot sjoman curious yellow fame director film tabu title imply mollberg effort quite effective sidestep fully treat screen theme incest making adult character father figure real blood relate daddy applies usual merely step father gimmick use countless time american movie incest work matti turunen kristus perkele translate christ devil really common law step dad underage milka beautiful offbeat fashion young girl portray shot irma huntus bring screen sexiness bergman harriet andersson decade earlier create international success summer monika sawdust tinsel imagine actress milka role shame do pursue act career afterward completing strong line leena suomu earth mother type confines act narrow emotional range prove solid rock crucial role bookended spectacularly beautiful shot birch wood winter virtually black white visually color presence milka film quickly develop nature theme presence strange click beak bird talisman early scene milka handyman turunen frolicking naked lake emerge oh natural sex play year old milka man result tastefully shoot intimacy imply ejaculation set trouble come religious aspect remote farm community heavily stress especially enjoy motif spiritual guidance cantor malmstrom quality anti stereotypical play eikka lehtonen instead rigid cruel turn care milka illegitimate baby bear strong romance turunen stud continue service mom woman neighborhood present utterly natural viewer position watch ethnographic exercise moralistic tale powerful technique milka frequently speak directly camera viewer forceful monologue bear crisp sound record sound nature include rain constant motif make milka engross experience view film subtitle knowledge finnish lapp recall best silent era classic direction strong convey dramatic content theme way transcend language kudos mollberg talented cinematographer job work remain obscurity ripe rediscovery',\r\n b'wonder horror film write woody allen wannabe come like check imaginatively direct typical enjoyable haunt place premise solid makeup effect good job major flaw dialogue overload cheeky wisecrack witticisms sample want scary shopping ex wife hit mark deliver inappropriate moment hero battle evil ghost'])\r\n\r\npartial_y_train=[[0,1,0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\r\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]] #multilabel classification\r\npartial_y_train=np.asarray(partial_y_train)\r\n```\r\n```python\r\n# Test variables\r\nx_val_features=np.array([b'corman world exploits hollywood rebel paul w s anderson allan arkush eric balfour paul bartel peter bogdanovich bob burns david carradine gene corman julie corman roger corman joe dante jonathan demme robert niro bruce dern frances doel alex stapleton documentary diy producer director roger corman alternative approach make movie hollywood documentary',\r\n b'blood bone michael jai white julian sands eamonn walker dante basco nona gaye michelle belegrin bob sapp dick anthony williams francis capra ron yuan kevin kimbo slice ferguson gina carano maurice smith ernest miller kevin phillips ben ramsey los angeles ex take underground fight world storm quest fulfill promise dead friend action drama',\r\n b'slender man joey king julia goldani telles jaz sinclair annalise basso alex fitzalan taylor richardson javier botet jessica blank michael reilly burke kevin chapman miguel nascimento eddie frateschi oscar wahlberg danny beaton gabrielle lorthe sylvain white small town massachusetts group friend fascinate internet lore slender man attempt prove do actually exist mysteriously go miss horror',\r\n b'friend ivan lapshin moy drug ivan lapshin andrei boltnev nina ruslanova andrey mironov aleksey zharkov zinaida adamovich aleksandr filippenko yuriy kuznetsov valeriy filonov anatoly slivnikov andrey dudarenko semyon farada nina usatova valeri kuzin lidiya volkova yuri aroyan aleksey german russian provincial town middle stalin great purge ivan lapshin head local police do do drama',\r\n b'noon till charles bronson jill ireland douglas fowley stan haze damon douglas hector morales bert williams davis roberts betty cole william lanteau larry french michael leclair anne ramsey howard brunner don red barry frank d gilroy spending unforgettable hour outlaw beautiful young widow turn story worldwide famous comedy romance western'])\r\n\r\nx_val_plot=np.array([b'documentary diy producer director roger corman alternative approach make movie hollywood',\r\n b'los angeles ex take underground fight world storm quest fulfill promise dead friend',\r\n b'small town massachusetts group friend fascinate internet lore slender man attempt prove do actually exist mysteriously go miss',\r\n b'russian provincial town middle stalin great purge ivan lapshin head local police do do',\r\n b'spending unforgettable hour outlaw beautiful young widow turn story worldwide famous'])\r\n\r\nx_val_actors_array=np.array([np.array([b'paul w.s. anderson', b'allan arkush', b'eric balfour',\r\n       b'paul bartel', b'peter bogdanovich', b'bob burns',\r\n       b'david carradine', b'gene corman', b'julie corman',\r\n       b'roger corman', b'joe dante', b'jonathan demme',\r\n       b'robert de niro', b'bruce dern', b'frances doel'], dtype='|S18'),\r\n np.array([b'michael jai white', b'julian sands', b'eamonn walker',\r\n       b'dante basco', b'nona gaye', b'michelle belegrin', b'bob sapp',\r\n       b'dick anthony williams', b'francis capra', b'ron yuan',\r\n       b\"kevin 'kimbo slice' ferguson\", b'gina carano', b'maurice smith',\r\n       b'ernest miller', b'kevin phillips'], dtype='|S28'),\r\n np.array([b'joey king', b'julia goldani telles', b'jaz sinclair',\r\n       b'annalise basso', b'alex fitzalan', b'taylor richardson',\r\n       b'javier botet', b'jessica blank', b'michael reilly burke',\r\n       b'kevin chapman', b'miguel nascimento', b'eddie frateschi',\r\n       b'oscar wahlberg', b'danny beaton', b'gabrielle lorthe'],\r\n      dtype='|S20'),\r\n np.array([b'andrei boltnev', b'nina ruslanova', b'andrey mironov',\r\n       b'aleksey zharkov', b'zinaida adamovich', b'aleksandr filippenko',\r\n       b'yuriy kuznetsov', b'valeriy filonov', b'anatoly slivnikov',\r\n       b'andrey dudarenko', b'semyon farada', b'nina usatova',\r\n       b'valeri kuzin', b'lidiya volkova', b'yuri aroyan'], dtype='|S20'),\r\n np.array([b'charles bronson', b'jill ireland', b'douglas fowley',\r\n       b'stan haze', b'damon douglas', b'hector morales',\r\n       b'bert williams', b'davis roberts', b'betty cole',\r\n       b'william lanteau', b'larry french', b'michael leclair',\r\n       b'anne ramsey', b'howard brunner', b\"don 'red' barry\"],\r\n      dtype='|S15')], dtype=object)\r\n\r\nx_val_reviews=np.array([b'sam kinison brilliant vulgar obscene use x rated material verbiage express comedic commentary variety topic funny thing tell truth superb laugh film win award best direction best documentary deservedly larry carroll do commendable job interweave live performance peer commentary narrative beverly d angelo richard pryor particularly effective brother kinison executive producer partial host insightful film man finally place let rip',\r\n b'theme movie tracks dennis hopper rolling thunder devane american home public general idea horror viet nam war bring war home people home understand violence nam strong stuff film depicts homecoming combat weary u s army green berets rent car travel country meet different people pick accidentally kill girl watch high school basketball game totally disillusion come home end similar dennis hopper film tracks tracks freeze frame violent end welcome home soldier boys take graphic conclusion end scene blood craze vet freeze frame leave lasting impact raw brutal beat act intense fan symbolism joe don baker viet nam era movie movie',\r\n b'loved great comedy know movie guy watch think funny dark performance great think write looked variey review say vibrant snappy surprisingly fresh better living breathe little life increasingly number genre dysfunctional family comedy check variety review want great opinion credible source industry p s archive retrieve review',\r\n b'longtime classic film buff great come worthwhile film hollywood golden age know exist see doubly nice don ameche film year immediately follow departure fox think better light comedian movie expensively mount romantic comedy family comedy show beautiful new print tcm sets cinematography elaborate idiom life father myrna loy despite reviewer say lubitsch heaven wait good ameche loy masterful job light comedy role ignore old part play loy easily manged sexy charm beautiful despite handicap overly heavy make used entire film obviously hide probably time',\r\n b'walked movie expect completely different get people use excuse hate movie like act excellent justin chatwin margarita levieva incredibly believable really enjoy material understand people mad people expect teenage horror flick glad depth beauty opinion do like do understand horror obsess teen soundtrack amaze love movie promotion mean trailers lot differently better strongly encourage movie love deep thought provoke beautiful emotional movie'])\r\n\r\ny_val=[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]]\r\ny_val=np.asarray(y_val)\r\n```\r\nAs you can see my data are composed of 4 input arrays. The first array contains movie content about a movie, the second array contains the plot summary of movies, the third array is an numpy array of arrays with actor names and the fourth array contains data about movie reviews. \r\nWhat I am trying to do is to fit a pre-trained neural network from tensorflow hub (specifically [this neural network](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1))\r\n\r\nThe process of fitting is the following:\r\n```python\r\nclass Callback_Configurations():\r\n    \r\n    MONITOR_METRIC = 'val_loss'\r\n    MINIMUM_DELTA = 1\r\n    PATIENCE = 5\r\n    VERBOSE = 0\r\n    MODE = 'min'\r\n    \r\ndef callback(saved_model, model):\r\n    \r\n    weights_fname='{}.h5'.format(saved_model)\r\n\r\n    try:\r\n        with open('{}.json'.format(save_model),'r') as f:\r\n            model_json = json.load(f)\r\n        \r\n        model = model_from_json(model_json)\r\n        \r\n        model.load_weights('{}').format(weights_fname)\r\n\r\n    except:\r\n        print('\\nPre-trained weights not found. Fitting from start')\r\n        pass\r\n\r\n    monitor_metric = Callback_Configurations.MONITOR_METRIC\r\n    \r\n    callbacks = [\r\n        tfmodel.EpochDots(),\r\n        \r\n        EarlyStopping(monitor=monitor_metric,\r\n                      min_delta=Callback_Configurations.MINIMUM_DELTA,\r\n                      patience=Callback_Configurations.PATIENCE,\r\n                      verbose=Callback_Configurations.VERBOSE,\r\n                      mode=Callback_Configurations.MODE,\r\n                      restore_best_weights=True), # I get the error here: TypeError: object of type 'NoneType' has no len()\r\n\r\n        ModelCheckpoint(filepath=weights_fname,\r\n                        monitor=monitor_metric,\r\n                        verbose=Callback_Configurations.VERBOSE,\r\n                        save_best_only=True,\r\n                        save_weights_only=True), #True, False      \r\n]\r\n    return callbacks\r\n\r\n# import the pre-trained model\r\nmodel = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\r\nhub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], dtype=tf.string, trainable=True)\r\n\r\n# create the neural network structure\r\nmodel = tf.keras.Sequential(name=\"English_Google_News_130GB_witout_OOV_tokens\")\r\nmodel.add(hub_layer)\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(16, kernel_regularizer=regularizers.l2(0.01),\r\n                                activation='relu'))\r\nmodel.add(tf.keras.layers.Dropout(0.0))\r\nmodel.add(tf.keras.layers.Dense(y_val.shape[1],  activation='sigmoid'))\r\n\r\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\r\n    0.01,\r\n    decay_steps=int(np.ceil((len(partial_x_train_actors_array)*0.8)//16))*1000,\r\n    decay_rate=1,\r\n    staircase=False)\r\n\r\ndef optimizer_adam_v2():\r\n    return keras.optimizers.Adam(lr_schedule)\r\n\r\noptimizer = optimizer_adam_v2()\r\n\r\nmodel.compile(optimizer=optimizer,\r\n              loss=\"binary_crossentropy\",\r\n              metrics=[\"accuracy\"])\r\n\r\nhistory = model.fit([partial_x_train_features, partial_x_train_plot, partial_x_train_actors_array, partial_x_train_reviews],\r\n                    partial_y_train,\r\n                    steps_per_epoch=int(np.ceil((len(partial_x_train_actors_array)*0.8)//16)),\r\n                    epochs=100,\r\n                    batch_size=16,\r\n                    validation_split=0.2,\r\n                    verbose=2,\r\n                    callbacks=callback(\"english_google_news_without_oovtokens\", model))\r\n```\r\n\r\nThe above code seems to run correctly up to the 5th epoch where I get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-74-ec4463fe97aa> in <module>\r\n     34                     validation_split=0.2,\r\n     35                     verbose=0,\r\n---> 36                     callbacks=callback(\"english_google_news_without_oovtokens\", model))\r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    395                       total_epochs=1)\r\n    396                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\r\n--> 397                                  prefix='val_')\r\n    398 \r\n    399     return model.history\r\n\r\n~\\Documents\\anaconda\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n    117         if type is None:\r\n    118             try:\r\n--> 119                 next(self.gen)\r\n    120             except StopIteration:\r\n    121                 return False\r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in on_epoch(self, epoch, mode)\r\n    769       if mode == ModeKeys.TRAIN:\r\n    770         # Epochs only apply to `fit`.\r\n--> 771         self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n    772       self.progbar.on_epoch_end(epoch, epoch_logs)\r\n    773 \r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py in on_epoch_end(self, epoch, logs)\r\n    300     logs = logs or {}\r\n    301     for callback in self.callbacks:\r\n--> 302       callback.on_epoch_end(epoch, logs)\r\n    303 \r\n    304   def on_train_batch_begin(self, batch, logs=None):\r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py in on_epoch_end(self, epoch, logs)\r\n   1272           if self.verbose > 0:\r\n   1273             print('Restoring model weights from the end of the best epoch.')\r\n-> 1274           self.model.set_weights(self.best_weights)\r\n   1275 \r\n   1276   def on_train_end(self, logs=None):\r\n\r\n~\\Documents\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in set_weights(self, weights)\r\n   1282         expected_num_weights += 1\r\n   1283 \r\n-> 1284     if expected_num_weights != len(weights):\r\n   1285       raise ValueError(\r\n   1286           'You called `set_weights(weights)` on layer \"%s\" '\r\n\r\nTypeError: object of type 'NoneType' has no len()\r\n```\r\n", "comments": []}, {"number": 41108, "title": "GPU significantly slower than CPU on WSL 2 & nvidia-docker2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows Subsystem For Linux 2 (WSL 2) with Ubuntu 20 LTS, Kernel 4.19.121-microsoft-standard**\r\n- TensorFlow installed from (source or binary): **binary** (unsure, via pip install)\r\n- TensorFlow version (use command below): **v1.15.2-30-g4386a66 1.15.3**\r\n- Python version: **3.7.8**\r\n- CUDA/cuDNN version: **libcudnn7-dev/now 7.6.4.38-1+cuda10.1 amd64**\r\n- GPU model and memory: **RTX 2070, 8GB**\r\n\r\n**Describe the current behavior**\r\n\r\nTraining is significantly slower on GPU compared to CPU (Intel Xeon E3-1230 v3, 3.30 GHz, 4 Cores)\r\n\r\n**Describe the expected behavior**\r\n\r\nTraining is significantly faster on GPU\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI'm using nvidia-docker2 with the tensorflow docker containers, I've verified that the GPU is in use when it's configured.\r\n\r\n| python | container  | tensorflow | gpu | comment                                   | time      |\r\n| ------ | ---------- | ---------- | --- | ----------------------------------------- | --------- |\r\n| 3.7.8  | latest     | 1.15.3     | no  | desktop                                   | 7m24.035s |\r\n| 3.7.8  | 1.15.2-gpu | 1.15.3     | yes | desktop, tf-gpu package                   | ~166m     |\r\n| 3.7.8  | latest-gpu | 1.15.3     | no  | desktop, tf-gpu package                   | 6m30.067s |\r\n| 3.7.8  | latest-gpu | 2.2.0      | yes | desktop, keras 2.4.x                      | ~175m     | \r\n\r\nI'm using keras with a sequential model (see below), doing reinforcement learning with 180 memory replays (model.fit) per episode.\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nreshape (Reshape)            (None, 40, 1)             0         \r\n_________________________________________________________________\r\nconv1d (Conv1D)              (None, 38, 16)            64        \r\n_________________________________________________________________\r\nmax_pooling1d (MaxPooling1D) (None, 19, 16)            0         \r\n_________________________________________________________________\r\nconv1d_1 (Conv1D)            (None, 17, 16)            784       \r\n_________________________________________________________________\r\nmax_pooling1d_1 (MaxPooling1 (None, 8, 16)             0         \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 128)               0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 48)                6192      \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 24)                1176      \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 3)                 75        \r\n=================================================================\r\nTotal params: 8,291\r\nTrainable params: 8,291\r\nNon-trainable params: 0\r\n```\r\n\r\nI'm going to try and provide a minimal python example ASAP.\r\n", "comments": ["@Scarysize \r\nCan you please share a simple stand alone code such that we can replicate the issue faced.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I'm gonna close this for now, currently don't have the time to provide a script for reproduction.", "I know that this ticket is closed, but if you could follow up with any other findings you had - I ran into the same thing on CUDA on WSL2. Albeit with torch, my calls made for operations on the GPU are incredibly slow, slower even than CPU ops. It's very odd. A backpropagation call on a batch size of 20 took 60 seconds (on the model Tacotron 2) ", "Apparently this is because CUDA is being run on a VM, according to these discussions.  I wish I had found this before installing WSL2 and cuda the past few hours.  It seemed too good to be true, and I guess it is.  :)  At least at this point.  I guess it's dual boot Debian for me now.\r\n\r\nhttps://www.phoronix.com/scan.php?page=news_item&px=WSL2-CUDA-Perf-Early-Look", "Ah - that's disappointing - but I'm not sure that's the sole reason given that VM performance overall is not much slower than bare-metal linux.\r\n\r\nThat said, I updated to the latest version of WSL and saw a decreates from about 60 seconds per iteration to 30 which is confidence building, but still painfully slow given the usual 2 seconds per iteration on this gpu.", "It shouldn't be.  Passthrough of single GPU on VM seems to have been no-go till very recently, but seems like it's doable: https://www.youtube.com/watch?v=3BxAaaRDEEw\r\nCaveat is to avoid conflict between host and VM using gpu at the same time; but given that WSL2 is such a tightly controlled env, and NVIDIA installs the driver on windows only, with only the CUDA toolkit installed in linux, I imagine it should be theoretically possible to get 100% of gpu compute on WSL2.  But, looking at redis, MS does have a track record of not following through on supporting linux projects, so I would not hold my breath on this.", "Yeah I all but gave up on GPU on WSL until they just cold announced it. I think cuda internal performance hinges more on NVidia now though. Regarding memory: what i ended up doing was using my intel graphics card plugged into my monitor to prevent windows from using any GPU memory, and then having Tensorflow and torch train on the main GPU as usual. The biggest offenders, though, are apps like Firefox which took up for GB(!) of VRAM when allowed. ", "I am reading how-to dual boot into Debian 10, I just want to get on with the coding and serving.  Hoping I wont miss windows too much.  I just need multi-gpu support easily setup for serving, without the 'freeze_support' headache and lack of native redis for streamers.  After many all-nighters, and with ridiculously puffy eyes, I just want things to work.  I'm looking forward to trying linux, it seems ready for prime time on home desktops (last time i tried it was ~2005), so, let's see.", "I am also seeing a significant reduction in speed on WSL2 with CUDA/CUDNN. 6 seconds per epoch vs 2 seconds on Windows.", "Can confirm. CUDA on WSL is painfully slow with Jax and Pytorch."]}, {"number": 41107, "title": "UnimplementedError: Fused conv implementation does not support grouped convolutions for now.", "body": "I follow the TensorFlow tutorial [(https://www.tensorflow.org/tutorials/images/classification)] for image classification when I try to compile the model, it gave me an error like this\r\n\r\n> Epoch 1/100\r\n> ---------------------------------------------------------------------------\r\n> UnimplementedError                        Traceback (most recent call last)\r\n> <ipython-input-117-7335ac61164f> in <module>()\r\n>       4     epochs=epochs,\r\n>       5     validation_data=validation_data_gen,\r\n> ----> 6     validation_steps=total_val // batch_size,\r\n>       7 )\r\n> \r\n> 8 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      58     ctx.ensure_initialized()\r\n>      59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n> ---> 60                                         inputs, attrs, num_outputs)\r\n>      61   except core._NotOkStatusException as e:\r\n>      62     if name is not None:\r\n> \r\n> UnimplementedError:  Fused conv implementation does not support grouped convolutions for now.\r\n> \t [[node sequential_5/conv2d_33/Relu (defined at <ipython-input-115-4d151b570f4c>:6) ]] [Op:__inference_train_function_6419]\r\n> \r\n> Function call stack:\r\n> train_function\r\n\r\nI use my own data and follow the same code as the post, but still got an error like that.\r\n", "comments": ["@kelingkece \r\n\r\nRequest you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram its solved", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41107\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41107\">No</a>\n", "@kelingkece can you share how you solved the problem. I have the same issue ", "Thanks, I found the solution. The problem was due to the difference in the number of channels in the image and the model", "@Karamya glad that u found the solutions, I did the same thing as u did", "@bhack they haven't mentioned the steps they took or the code that they changed", "> @Karamya glad that u found the solutions, I did the same thing as u did\r\n\r\ncould u please share the changing method?", "> @ravikyram its solved\r\n\r\ncan you share how you solved the problem. I have the same issue\r\n"]}, {"number": 41106, "title": "Socket closed when \"LayerNormalization\" was used for tensors of 3 or more dimensions with TPU in colab.", "body": "When I used `LayerNormalization` on tensors of 3 or more dimensions in the colab with TPU, I encountered the following error:\r\n> UnavailableError: Socket closed\r\n> Additional GRPC error information:\r\n> {\"created\":\"@1593962551.753581454\",\"description\":\"Error received from peer ipv4:10.10.67.202:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\r\n  \r\nPlease find the gist [here](https://colab.research.google.com/gist/gdhy9064/19ac8fafc46bdaa647a8b71bc31c3d2b/-pianist-ipynb.ipynb), thanks.\r\n\r\n\r\n", "comments": ["Was able to reproduce the issue with TF v2.2. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/df608a021b57ed4f897a5aeb7fb0cc64/41106.ipynb). Thanks!", "Any news here? I am getting the same error with TF2.3rc2.", "Sorry for the delay. Just saw this issue, will fix soon. ", "@yunxing Same issue here https://github.com/tensorflow/tensorflow/issues/42228, will we get notified when it gets fixed and will it get fixed on the nightly version before the 2.4.0 release? ", "Issue still persists in TensorFlow 2.4.1 ", "I tried to run  the code on colab with TF v2.5 & the issue seems to be fixed,please find the gist [here ](https://colab.research.google.com/gist/sushreebarsa/b1840e425c670d6bf83cff4ba43a72b3/untitled284.ipynb)..Thanks!", "@sushreebarsa Yes, it have been fixed in TF v2.5, thanks for your kind reminder. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41106\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41106\">No</a>\n"]}, {"number": 41105, "title": "Comparing tensor dimension in add_loss and \"standard\" (mse) loss", "body": "**System information**\r\n- OS Platform and Distribution: Linux, Fedora 30\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: Cuda version is 10.2\r\n- GPU model and memory: GeForce GTX 1080 Ti, amount global memory: 11178 MBytes\r\n\r\n\r\n**Current error**\r\nThe sample code below gives me this error:\r\n```\r\nValueError: Shapes must be equal rank, but are 0 and 1\r\n        From merging shape 0 with other shapes. for '{{node AddN}} = AddN[N=2, T=DT_FLOAT](loss/weighted_loss/value, model/new_layer/mul_1)' with input shapes: [], [100].\r\n```\r\nwhere 100 is the batch size I am using and when I try to add two different loss functions, one coming from the `add_loss` instruction and one defined in the `compile` of Keras (tf-Keras 2.3.0).\r\n\r\n**Expected behavior**\r\nIf I print the tensors inside the losses, it seems to me that they have the same shape (one entry for each sample of the mini-batch). But then these don't get summed. Is it possible that the 2 losses are summed only after the loss from the compile has been turned to a scalar? So, should I also return a scalar in the `add_loss` function?\r\nI actually wanted to sum the vectors coming from the two losses.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Dense, Input\r\n\r\ndef rate_mse(rate=1e5):\r\n    @tf.function # also needed for printing\r\n    def loss(y_true, y_pred):\r\n        tmp = rate*K.mean(K.square(y_pred - y_true), axis=-1)\r\n#        tf.print('shape %s and rank %s output in mse'%(K.shape(tmp), tf.rank(tmp)))\r\n        tf.print('shape and rank output in mse',[K.shape(tmp), tf.rank(tmp)])\r\n        tf.print('mse loss:',tmp) # print when I put tf.function\r\n        return tmp\r\n    return loss\r\n\r\nclass newLayer(tf.keras.layers.Layer):\r\n    def __init__(self, rate=5e-2, **kwargs):\r\n        super(newLayer, self).__init__(**kwargs)\r\n        self.rate = rate\r\n        \r\n#    @tf.function # to be commented for NN training\r\n    def call(self, inputs):\r\n        tmp = self.rate*K.mean(inputs*inputs, axis=-1)\r\n        tf.print('shape and rank output in regularizer',[K.shape(tmp), tf.rank(tmp)])\r\n        tf.print('regularizer loss:',tmp)\r\n        self.add_loss(tmp, inputs=True)\r\n        return inputs\r\n\r\ntot_n = 10000\r\nxx = np.random.rand(tot_n,1)\r\nyy = np.pi*xx\r\n\r\ntrain_size = int(0.9*tot_n)\r\nxx_train = xx[:train_size]; xx_val = xx[train_size:]\r\nyy_train = yy[:train_size]; yy_val = yy[train_size:]\r\n\r\nreg_layer = newLayer()\r\n\r\ninput_layer = Input(shape=(1,))                                      # input\r\nhidden = Dense(20, activation='relu', input_shape=(2,))(input_layer) # hidden layer\r\nhidden = reg_layer(hidden)\r\noutput_layer = Dense(1, activation='linear')(hidden) \r\n\r\nmodel = Model(inputs=[input_layer], outputs=[output_layer])\r\nmodel.compile(optimizer='Adam', loss=rate_mse(), experimental_run_tf_function=False)\r\n#model.compile(optimizer='Adam', loss=None, experimental_run_tf_function=False)\r\nhistory = model.fit(xx_train, yy_train, epochs=50, batch_size = 100, \r\n                    validation_data=(xx_val,yy_val), verbose=2)\r\n\r\nprint(model.predict(np.array([[1]]))) # sanity check\r\n```\r\n\r\nI would also have a secondary question: why is it necessary to comment the decorator `@tf.function` of the `call` method in `newLayer` in order that this is actually taken into consideration during training? On the other hand, if I remove it from inside function `rate_mse`, this doesn't print anything. Are the two things related between them and with the different possible tensor representations?\r\n\r\nThanks in advance to whoever can help.", "comments": ["@MattGam3 \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/1d5c62038e3c89c4c594b1c02a8be727/untitled259.ipynb).", "Hi @Saduf2019! I think I see the same `ValueError` at the end of your colab. Or am I wrong?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n", "Hi @ymodak! Why couldn't it be a bug? In the end, one would expect another behavoir, than the one presented here.", "@MattGam3 Have you figured it out? It looks like nobody responded to your StackOverflow question https://stackoverflow.com/questions/62728659/mse-loss-function-not-compatible-with-regularization-loss-add-loss-on-hidden-l", "@ymodak I think we should re-open this as a bug. At the very least, the error message is not helpful. Clearly you're not able to answer it either and you're a maintainer, so I think that proves that this is a bug.\r\nIt's not a support question because there's no way for anyone to answer it who isn't a maintainer. This error is completely undocumented and there's no information that would help resolve it, so it's not a good fit for Q&A style forums like StackOverflow.\r\nIt's a bug and we should re-open it and re-add the bug label.", "The bug in the code is that `K.mean()` sums here only over one (last) axis of a (likely) 2-D tensor. The error message provide a quite clear clue to that.\r\n\r\n```\r\nK.mean(inputs * inputs, axis=-1)\r\n```\r\n\r\nIn order to sum over all axis into a scalar, remove the axis argument:\r\n\r\n```\r\nK.mean(inputs * inputs)\r\n```\r\n\r\nRegularizers provide scalar values and the other losses must also be scalar in order to sum with the regularizer losses. In case the loss is alone it can have higher rank shape."]}, {"number": 41104, "title": "[-Wsign-compare] warning fixes batch 7", "body": "In resolution of indexed [-Wsign-compare] warnings with ids: \r\n[\r\n200, 201, 202, 211, \r\n120, 227, 226, 406, \r\n476, 477, 437, 402,\r\n 396, 386, 403, 404, \r\n405, 2019\r\n]\r\n\r\n@mihaimaruseac ", "comments": ["Closing as it has been handled by new PRs."]}, {"number": 41103, "title": "get error when runing python captcha_train.py", "body": "hi\r\nTime to run the following code : \r\n`python captcha_train.py`\r\nim using the flow library:\r\nhttps://github.com/PatrickLib/captcha_recognize\r\nim installation : \r\n\r\n- python 2.7\r\n- Anaconda2 4.3.1\r\n- TensorFlow 1.1\r\n\r\nget this erros :((\r\n\r\n`Traceback (most recent call last):\r\n  File \"captcha_train.py\", line 89, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"captcha_train.py\", line 65, in main\r\n    run_train()\r\n  File \"captcha_train.py\", line 57, in run_train\r\n    coord.join(threads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run\r\n    sess.run(enqueue_op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 778, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 982, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1032, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1052, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: ./data/train.tfrecords\r\n         [[Node: input/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/TFRecordReaderV2, input/input_producer)]]`\r\n`Caused by op u'input/ReaderReadV2', defined at:\r\n  File \"captcha_train.py\", line 89, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"captcha_train.py\", line 65, in main\r\n    run_train()\r\n  File \"captcha_train.py\", line 19, in run_train\r\n    images, labels = captcha.inputs(train=True, batch_size=FLAGS.batch_size)\r\n  File \"/app/captcha/captcha_model.py\", line 15, in inputs\r\n    return captcha_input.inputs(train, batch_size=batch_size)\r\n  File \"/app/captcha/captcha_input.py\", line 44, in inputs\r\n    image, label = read_and_decode(filename_queue)\r\n  File \"/app/captcha/captcha_input.py\", line 21, in read_and_decode\r\n    _, serialized_example = reader.read(filename_queue)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 193, in read\r\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 411, in _reader_read_v2\r\n    queue_handle=queue_handle, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in init\r\n    self._traceback = _extract_stack()`\r\n`NotFoundError (see above for traceback): ./data/train.tfrecords\r\n         [[Node: input/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/TFRecordReaderV2, input/input_producer)]]\r\n2020-07-02 07:33:55.821848: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2020-07-02 07:33:55.822614: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2020-07-02 07:33:55.823256: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2020-07-02 07:33:55.823711: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.`\r\n\r\nplease help me", "comments": ["TF 1.1 is very old version .Request you try with latest TF versions such as 1.15 or 2.3-rc0 and let me know if the issue still persists.\r\nPlease, provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41103\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41103\">No</a>\n"]}, {"number": 41102, "title": "GPU is not running", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (on Azure VM)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.8.3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA - 10.1, cuDNN - 7.6.4\r\n- GPU model and memory: NVIDIA Tesla k80\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen I'm running  \"tf.test.is_gpu_available()\" I got False.\r\n\r\n**Any other info / logs**\r\nI installed c++ redistributable, cuda, cudnn and set the path environments as shown on the tensorflow gpu support.\r\n", "comments": ["@Itzikwa,\r\nCould you please run the below code and share the output with us\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n```\r\nThanks!", "Thank you for your response! I run the code and that what that came out:\r\n\r\n`Num GPUs Available:  0` ", "Hi, I just run the command on the cmd, and I noticed that for some reason tf couldn't open the cudnn64_7.dll file (it wasn't show up  when I run this command on the jupyter notebook), although I set it in the path as I mentioned above. So I move the file manually to a folder which I were sure tf could open successfully. \r\n\r\nThanks a lot, and I'm sorry about my confusion... "]}]