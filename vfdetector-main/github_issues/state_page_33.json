[{"number": 48170, "title": "Difference between android and iOS inference result", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, no example code found\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 11.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 6 & iPhone8\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): TensorflowLite Objective C\r\n\r\n**Context**\r\n\r\nI'm currently working on an object detection on mobile project.\r\nI have good result with tensorflowlite on android but we are facing a problem on ios.\r\n\r\nI am using the objective-c version of tensorflow lite because I get the images from[ react-natice-camera](https://github.com/react-native-camera/react-native-camera) which is also coded in objective-c.\r\n\r\n**Expected behavior**\r\n\r\nI expect to have same inference result on iOS and android detection (classname, confidence and bbox location) but the results are very different on iOS. \r\nIn fact 50% of the detections are the same but the other 50% are different. The locations of the bbox reaches very high values (> 1.56^31 e.g.) while the value must be between 0 and 1.\r\n\r\nSome example of result:\r\n\r\n| Android bbox (x1,y1,x2,y2) |  iOS bbox (x1,y1,x2,y2)| Notes|  \r\n|---|---|---|\r\n| 0.291 - 0.328 - 0.325 - 0.445  |  0.29 - 0.331 - 0.3257- 0.445 | same |  \r\n| 0.295 - 0.509 - 0.327 - 0.600  |  0.292 - 0.511 - 0.327- 0.600 | same |  \r\n| 0.295 - 0.493 - 0.550 - 0.582   |  0.0- 0.0 - 0.0- 0.0 |  different, but almost same classe & confidence | \r\n| 0.311 - 0.423 - 0.511 - 0.542   |  0.0- 5.56e^10 - 0.0- 0.0 |  overflow ?, but almost same classe & confidence | \r\n\r\n## Some part of the objective C code\r\n\r\nSame images are used in android and objective c\r\nImages are in rgb converted in grayscaled\r\n\r\nImages are ing RGBA format\r\n\r\nI don't use quantisized model so pixel are stored in float32 array\r\n\r\n\r\n**Pre processing the image**\r\n\r\n```\r\n    float* array = malloc((320*320*3) * sizeof(float));\r\n    int count = 0;\r\n    for (int i = 0 ; i < height*width ; ++i)\r\n    {\r\n       \r\n        int r   = ((int) rawData[byteIndex] );\r\n        int g = ((int) rawData[byteIndex + 1] );\r\n        int b  = ((int) rawData[byteIndex + 2] );\r\n\r\n        byteIndex += 4; //passing to next rgba tuple\r\n        \r\n        float gray = r * 0.3f + g *0.59f + b*0.11f;\r\n        gray = (gray - 127.5)/127.5;\r\n\r\n        array[count++]=gray;\r\n        array[count++]=gray;\r\n        array[count++]=gray;\r\n    }\r\n```\r\n\r\nThis code is ok, I've done a lot of test with custom image.\r\n\r\nI've already check this [issue](https://github.com/tensorflow/tensorflow/issues/40442) but nothing change\r\n\r\n\r\n**Get inference result**\r\n\r\nI use a SSDMobileNetV2 with [mnasFPN ](https://arxiv.org/pdf/1912.01106.pdf)network so I have 4 tensors output (classe, confidence, bbox locations, nb detections)\r\n\r\nI retrieve the inference data with this code:\r\n\r\n```\r\n    //Getting input tensor\r\n    TFLTensor *inputTensor = [interpreter inputTensorAtIndex:0 error:&error];\r\n\r\n    //Copying input data into input tensor\r\n    [inputTensor copyData:dataIm error:&error];\r\n\r\n    //Executing model\r\n    [interpreter invokeWithError:&error];\r\n    \r\n    //Getting the 4 output tensors\r\n    TFLTensor *outputLocations = [interpreter outputTensorAtIndex:0 error:&error];\r\n    TFLTensor *outputClasses = [interpreter outputTensorAtIndex:1 error:&error];\r\n    TFLTensor *outputScore = [interpreter outputTensorAtIndex:2 error:&error];\r\n    TFLTensor *outputNumDetections = [interpreter outputTensorAtIndex:3 error:&error];\r\n    \r\n    //Converting to NSData\r\n    NSData* dataOutputLocations = [outputLocations dataWithError:&error];\r\n    NSData* dataOutputClasses = [outputClasses dataWithError:&error];\r\n    NSData* dataOutputScore = [outputScore dataWithError:&error];\r\n    NSData* dataOutputNumDetections = [outputNumDetections dataWithError:&error];\r\n\r\n    //Converting NSData to float array\r\n\r\n    float numDetections;\r\n    [dataOutputNumDetections getBytes:&numDetections length:(sizeof(float))];\r\n    \r\n    float outputLocArray[(int)numDetections * 4];\r\n    float outputClassArray[(int)numDetections];\r\n    float outputScoreArray[(int)numDetections];\r\n    \r\n    [dataOutputLocations getBytes:&outputLocArray length:(sizeof(float))*numDetections];\r\n    [dataOutputClasses getBytes:&outputClassArray length:(sizeof(float))*numDetections];\r\n    [dataOutputScore getBytes:&outputScoreArray length:(sizeof(float))*numDetections];\r\n\r\n    //store final result into Dictionnary\r\n    NSMutableArray* results = [NSMutableArray array];\r\n    for(int i = 0; i < (int) numDetections; i++)\r\n    {\r\n        \r\n        int detected_class = (int) outputClassArray[i];\r\n        float score = outputScoreArray[i];\r\n        float ymin = fmax(0,outputLocArray[i*4]);\r\n        float xmin = fmax(0,outputLocArray[i*4+1]);\r\n        float ymax = outputLocArray[i*4+2];\r\n        float xmax = outputLocArray[i*4+3];\r\n        \r\n        if(score > 0.0f)\r\n        {\r\n            NSMutableDictionary* res = [NSMutableDictionary dictionary];\r\n            NSString* classname = [@(detected_class) stringValue];\r\n            \r\n            [res setObject:classname forKey:@\"classname\"];\r\n            [res setObject:@(score) forKey:@\"confidence\"];\r\n            [res setObject:@(xmin) forKey:@\"xmin\"];\r\n            [res setObject:@(xmax) forKey:@\"xmax\"];\r\n            [res setObject:@(ymin) forKey:@\"ymin\"];\r\n            [res setObject:@(ymax) forKey:@\"ymax\"];\r\n  \r\n            \r\n\r\n            [results addObject:res];\r\n        }\r\n    }\r\n```\r\n\r\nBy doing this I have the strange result above, with float value which seems to overflow.\r\n\r\nI couldn't find an example code in objective-c so I'm not sure what is wrong.\r\nMaybe a conversion error?", "comments": ["@yyoon could you take a look?"]}, {"number": 48167, "title": "Running L-BFGS-B optimizer in TF2", "body": "\r\n### System information\r\n\r\n-   This concerns a customized script applying PINN\r\n-   Runs both (quite well) on Jupyter Notebooks, and Colab\r\n-   TF2 (and T1 in other environment) installed using Anaconda, and Colab\r\n-   TF 2.4.1\r\n-   Python 3.8.2 (3.7 in Colab)\r\n-   \r\n-   No CUDA used on local host (yet), automatically assigned on Colab\r\n-   NVIDIA 1070 (local host, not yet used), automatically assigned on Colab\r\n\r\nIssue at hand:\r\n_______________________________________________________________________________________________\r\n\r\nOriginally the optimizer based on L-BFGS-B only runs on TF1 via\r\n\r\nself.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \r\n                                                                        method = 'L-BFGS-B', \r\n                                                                        options = {'maxiter': 50000,\r\n                                                                                   'maxfun': 50000,\r\n                                                                                   'maxcor': 50,\r\n                                                                                   'maxls': 50,\r\n                                                                                   'ftol' : 1.0 * np.finfo(float).eps})\r\n\r\n\r\nThe '.contrib' module has been left out of TF2, and so far no straightforward solution found anywhere that works well.\r\n\r\nReason for request:\r\nPINN is a significant and growing development for science / engineering applications. Hence not having \r\nthis functionality implemented in a usable and accessible way in TF2 is an issue.\r\n\r\nHence in short, this is a feature request:\r\n\r\nPlease enable straightforward to use implementation of the Broyden - Fletcher - Goldfarb - Shanno optimization into TF2.\r\nIdeally, accessible through the Keras framework (be it functional API or not).\r\n\r\n\r\nThanks and best regards,\r\n\r\nJan van de Mortel\r\n\r\n\r\n", "comments": ["Adding the contributions welcome label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!", "@nikitamaia Probably we could route this in the ecosystem (TF probability). See https://github.com/tensorflow/probability/issues/565", "Hi, can I contribute to this issue ?", "It looks like that this issue don't have any repo.I am creating one ", "Any news here? @vulkomilev Are you still active on this?", "yes\n\n\u041d\u0430 \u043f\u043d, 14.06.2021 \u0433. \u0432 22:08 \u0447. bhack ***@***.***> \u043d\u0430\u043f\u0438\u0441\u0430:\n\n> Any news here? @vulkomilev <https://github.com/vulkomilev> Are you still\n> active on this?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/48167#issuecomment-860924436>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ATA3WEP6FXW42OYBBMR4YX3TSZHRFANCNFSM42AIDTMQ>\n> .\n>\n", "@bhack  can you help with me with the organization of the project? ", "Any update on this? I am also looking forward to L-BFGS in TF2.", "I have a problem with the organization of the project. The Tensorflow\nproject is huge and very complex and I am waiting for help\n", "Hi @vulkomilev , how about the progress of LBFGS on TF2.x? Look forward to your contriubtion.", "For those who needs L-BFGS in TF 2.x, I implemented a TensorFlow interface for tfp.optimizer.lbfgs_minimize:\r\nhttps://github.com/lululxvi/deepxde/blob/9f0d86dea2230478d8735615e2ad518c62efe6e2/deepxde/optimizers/tensorflow/tfp_optimizer.py#L103", "@lululxvi , thanks a lot Lu, great job!", "@lululxvi How to use this interface for tfp.optimizer.lbfgs_minimize in my own code with TF 2.x?\r\nCould you give me some examples?", "@lwkobe \r\n- Install DeepXDE: https://deepxde.readthedocs.io/en/latest/user/installation.html#installation\r\n- Set TensorFlow 2.x as the backend: https://deepxde.readthedocs.io/en/latest/user/installation.html#tensorflow-2-x-backend\r\n- Use the following code:\r\n\r\n```python\r\nimport deepxde as dde\r\n\r\nnet = ...  # your tf.keras.Model\r\ntrainable_variables = net.trainable_variables  # the network weights and biases\r\n\r\ndef build_loss():  # no arguments\r\n    loss = ... # compute the loss for the network\r\n    return loss\r\n\r\ndde.optimizers.tfp_optimizer.lbfgs_minimize(trainable_variables, build_loss)\r\n```\r\n\r\n- You can also set the L-BFGS parameters: https://deepxde.readthedocs.io/en/latest/modules/deepxde.optimizers.html#deepxde.optimizers.config.set_LBFGS_options", "@JHvdM1959 Is this still an issue?\r\nCould you please refer  this [link](https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize) and let us know if it helps?\r\nThanks!", "@sushreebarsa Yes, it is still an issue. L-BFGS in tfp helps, but it is not convenient to use, and we have to add an interface, as I discussed above https://github.com/tensorflow/tensorflow/issues/48167#issuecomment-941741493\r\n\r\nIdeally, a direct support would be better, something like L-BFGS in PyTorch https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html", "Probably we could a TF counterpart like:\n\nhttps://pytorch.org/docs/stable/_modules/torch/optim/lbfgs.html#LBFGS\n\nBut I think it Is better to open a new ticket in Keras directly.\n\nYou could ask to reopen this or open a new one:\n\nhttps://github.com/keras-team/keras/issues/5085"]}, {"number": 48157, "title": "`SignatureDef` of saved Keras models should match the Keras input and output `dict`", "body": "**System information**\r\n- TensorFlow version (you are using): 2.6.0-dev20210329\r\n- Are you willing to contribute it (Yes/No): Yes (although I'd need some pointers to where to look for this particular issue)\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently when saving Keras models using the saved model format, the input and output names in the `SignatureDef` refer to the names of the tensors of the model. Unfortunately these names are not fixes since they depend on implementation details like the number of times the model has been built (this might be problematic during fine tuning). This makes it hard to construct multi input and output models that are intended to be used with saved models during serving or with TFLite.\r\nIn contrast to Keras the saved model format and therefore also the TFLite converter do not preserve the output ordering, which makes using a list as output of the Keras model not a valid use. For more information why this leads to problems please see #47927.\r\n\r\nIt would be great if the `SignatureDef` of the saved model would match the dictionary keys of the input and output of the Keras model or if saved models would preserve the order of inputs and outputs matching Python and Keras:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef build_model():\r\n    input_tensor = tf.keras.layers.Input((32, 32, 128))\r\n    x = input_tensor\r\n\r\n    boxes = tf.keras.layers.Conv2D(4, (3, 3))(x)\r\n    boxes = tf.reshape(boxes, (-1, 4))\r\n\r\n    scores = tf.keras.layers.Conv2D(1, (3, 3))(x)\r\n    scores = tf.reshape(scores, (-1,))\r\n\r\n    return  tf.keras.Model({\"inputs\": input_tensor}, {\"boxes\": boxes, \"scores\": scores})\r\n\r\nmodel = build_model()\r\nmodel = build_model()\r\n\r\nmodel.save(\"/tmp/model\")\r\n\r\nrestored_fn = tf.saved_model.load(\"/tmp/model\")\r\nconcrete_fn = restored_fn.signatures[\"serving_default\"]\r\n\r\n# Would be great if these would match the Keras model:\r\n# signature_wrapper(*, input_6)\r\n# Args:\r\n#   input: float32 Tensor, shape=(None, 32, 32, 128)\r\n# Returns:\r\n#   {'boxes': <1>, 'scores': <2>}\r\n#     <1>: float32 Tensor, shape=(None, 4)\r\n#     <2>: float32 Tensor, shape=(None,)\r\n\r\n# Instead the keys are layer names which depends on implementation details and on how often the model\r\n# was instantiated: (e.g input_6, tf.reshape_8, tf.reshape_9)\r\nprint(concrete_fn.pretty_printed_signature())\r\n```\r\n\r\nTo make this work currently one needs to use the following workaround which requires users to learn about the low-level `tf.function` API despite that all the information was already present in the Keras model:\r\n```python\r\n@tf.function(input_signature=[tf.TensorSpec([None, 32, 32, 128], dtype=tf.float32, name=\"input\")])\r\ndef override_output_signatures(input_tensor):\r\n   outputs = model(input_tensor)\r\n   return {\"boxes\": outputs[\"boxes\"], \"scores\": outputs[\"scores\"]}\r\n\r\nsignatures = override_output_signatures.get_concrete_function()\r\ntf.saved_model.save(model, export_dir=\"/tmp/saved_model\", signatures=signatures)\r\n```\r\n\r\nFor a complete reproducible example please see [this notebook](https://colab.research.google.com/drive/1CtZ0O7vNN6ODCQfSlon92JDNzfN9FQPe?usp=sharing).\r\n\r\n**Will this change the current api? How?**\r\nThis proposal wouldn't require any the API changes on the Python side since this usage is already supported in Keras, however it might change the names of serialized multi input/output models. However, I don't think this is a problem in general since currently Keras saved models do not have deterministic output naming either.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nPeople working with multi input and output models that require serialization to saved models would greatly benefit from a way to easily set function signatures when saving Keras models. For more motivation for TFLite users, please see #47927.\r\n", "comments": ["I think this is a problem of exporting the given keras model to the corresponding saved model, which means that this is not related to TFLite."]}, {"number": 48149, "title": "Keras `predict_step` is not preserved across save and restore", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 and macOS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0-dev20210329\r\n- Python version: 3.7 and 3.8\r\n\r\n**Describe the current behavior**\r\n\r\nWhen implementing custom prediction logic for Keras models using [`predict_step`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict_step) as explained [here](https://keras.io/guides/customizing_what_happens_in_fit/), saving and restoring the Keras model with the saved model format ignores the custom prediction logic. Unfortunately the code silently fails and doesn't inform the user that this is not supported, which could lead to detrimental bugs.\r\n\r\nThe issue is explained in detail with a minimal example in [this colab notebook](https://colab.research.google.com/drive/1q2f1tXS3fUaO4WH1TJYmEYFO7QQoh8Z9?usp=sharing).\r\n\r\nI know I can save a custom serving function using\r\n```python\r\nclass MyModel(tf.keras.Model):\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string)])\r\n    def serve(self, data):\r\n        ...\r\n```\r\nas described [here](https://www.tensorflow.org/api_docs/python/tf/saved_model/save).\r\nBut I feel the current behaviour breaks with user expectations since the saved model format is now the default saving format but doesn't support all of the features and might silently fail resulting in unexpected behaviour.\r\nThis makes it necessary for users to break the abstraction and start using low level TF APIs instead, which I think doesn't fit well with the progressive disclosure of complexity that Keras tends to strive for.\r\n\r\n**Describe the expected behavior**\r\n\r\nKeras models should preserve custom `predict_step` logic when saving and restoring models.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass FullyConnectedModel(tf.keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dense = tf.keras.layers.Dense(10)\r\n\r\n    def predict_step(self, data):\r\n        logits = self(data, training=False)\r\n        return tf.argmax(logits, axis=-1)\r\n\r\n    def call(self, inputs):\r\n        return self.dense(inputs)\r\n\r\nx, y = np.random.uniform(size=(128, 20)).astype(np.float32), np.random.randint(0, 10, size=(128))\r\n\r\nmodel = FullyConnectedModel()\r\nmodel.compile(optimizer=\"sgd\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\r\nmodel.fit(x, y, epochs=2, batch_size=32)\r\n\r\nmodel.save(\"/tmp/model\", save_traces=True)\r\nreloaded_model = tf.keras.models.load_model(\"/tmp/model\")\r\n\r\ny_pred = model.predict(x)\r\nreloaded_y_pred = reloaded_model.predict(x)\r\n\r\nnp.testing.assert_allclose(reloaded_y_pred, y_pred)\r\n```\r\nSee [this notebook](https://colab.research.google.com/drive/1q2f1tXS3fUaO4WH1TJYmEYFO7QQoh8Z9?usp=sharing) for more information.", "comments": ["@lgeiger,\r\nThe way you load the model should be some thing like, \r\n\r\n`loaded_1 = keras.models.load_model(\"my_model\", custom_objects={\"CustomModel\": CustomModel})`\r\n\r\nPlease refer the Documentation of [Saved Model for Custom Objects](https://www.tensorflow.org/guide/keras/save_and_serialize#how_savedmodel_handles_custom_objects) and check if the issue persists? \r\n\r\nAlso, the error that you got, **`AssertionError: Not equal to tolerance rtol=1e-07, atol=0`** looks fine to me because the `Shape` of `Data` (`y_test`) and the `Shape` of `Prediction` will not be the same.\r\n\r\n```python\r\nprint(y_test.shape, y_test.dtype)\r\nprint(y_pred.shape, y_pred.dtype)\r\n```\r\n\r\nOutput:\r\n\r\n```python\r\n(1, 10) float32\r\n(1,) int64\r\n```\r\n\r\nPlease let me know if I'm missing something. Thanks!", "@rmothukuru Thanks for the fast response. Reloading with custom objects still does not work in this case.\r\n\r\nI updated the [notebook](https://colab.research.google.com/drive/1q2f1tXS3fUaO4WH1TJYmEYFO7QQoh8Z9?usp=sharing) to make the issue more clear and test your suggestion.\r\n\r\nAlso in general I thought the idea behind the saved model format is that models can be reloaded without the code. Which also works for custom functions (see [this example](https://www.tensorflow.org/api_docs/python/tf/saved_model/save#example_usage_2)) so me as a user would expect that this is also true for custom train, predict and test functions.\r\n\r\nWhat is the reason that they are [explicitly ignored during serialization](https://github.com/tensorflow/tensorflow/blob/b89cf1454b4fd8a536425e220c124df09f13cfe5/tensorflow/python/keras/engine/training.py#L2707-L2720)? To me the only reason for this could be that they include information about the `steps_per_execution` since this is set during `model.compile` (and not during `model.fit`), but I think this could be worked around or moved to `model.fit` to allow proper saving of custom models.\r\n\r\nFor now it looks like the only valid workaround is not to use the `{predict, train, test}_step` features at all and rather rely on completely custom functions that are serialized properly which seems inconsistent to me and might not be possible for cases other than predictions:\r\n```python\r\nclass ServingFullyConnectedModel(tf.keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dense = tf.keras.layers.Dense(10)\r\n\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 20], dtype=tf.float32)])\r\n    def serve(self, data):\r\n        logits = self(data, training=False)\r\n        return tf.argmax(logits, axis=-1)\r\n\r\n    def call(self, inputs):\r\n        return self.dense(inputs)\r\n```\r\n\r\n> Also, the error that you got, AssertionError: Not equal to tolerance rtol=1e-07, atol=0 looks fine to me because the Shape of Data (y_test) and the Shape of Prediction will not be the same.\r\n\r\nIt is correct that the shape of `y_test` and `y_pred` are not the same, but the shapes and dtypes of `y_pred` before and after reloading should be the same which isn't the case. I updated the notebook to make this more clear.", "Was able to replicate the issue in TF nightly-2.6.0.dev20210603,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/b82573c3191313593e387d35652f5425/untitled209.ipynb)..Thanks !", "I'm having the same problem here."]}, {"number": 48147, "title": "\"CancelledError:  [_Derived_]RecvAsync is cancelled.  Function call stack: train_function\" persists for some code", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): PIP\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.0\r\n- CUDA/cuDNN version: 11.0 (TF was installed by following the procedure in https://www.tensorflow.org/install/gpu)\r\n- GPU model and memory:  3080 RTX 8GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nAfter setting up a new rig, I ran two different LSTM models. Initially both models failed to initiate training by giving the error below:\r\n     \r\n\r\n     CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\n\t [[gradient_tape/sequential_1/embedding/embedding_lookup/Reshape/_38]] [Op:__inference_train_function_3172]\r\n    Function call stack:\r\n    train_function\r\n\r\nI was able to fix one model by adding `import os ; os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"`, but another model still fails to run. Here is the whole error message from the model:\r\n\r\n    Epoch 1/15\r\n    ---------------------------------------------------------------------------\r\n    CancelledError                            Traceback (most recent call last)\r\n    <ipython-input-96-9b266da78330> in <module>\r\n          1 es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 4, verbose =1)\r\n          2 mc = ModelCheckpoint('best_model_naver.h5', monitor = 'val_acc', mode = 'max', save_best_only = True)\r\n    ----> 3 history = model.fit(X_train, y_train, batch_size = 128, callbacks = [es, mc], epochs = 15, validation_split = .2)\r\n    \r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n       1098                 _r=1):\r\n       1099               callbacks.on_train_batch_begin(step)\r\n    -> 1100               tmp_logs = self.train_function(iterator)\r\n       1101               if data_handler.should_sync:\r\n       1102                 context.async_wait()\r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n        826     tracing_count = self.experimental_get_tracing_count()\r\n        827     with trace.Trace(self._name) as tm:\r\n    --> 828       result = self._call(*args, **kwds)\r\n        829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n        830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n        886         # Lifting succeeded, so variables are initialized and we can run the\r\n        887         # stateless function.\r\n    --> 888         return self._stateless_fn(*args, **kwds)\r\n        889     else:\r\n        890       _, _, _, filtered_flat_args = \\\r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n       2940       (graph_function,\r\n       2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n    -> 2942     return graph_function._call_flat(\r\n       2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n       2944 \r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n       1916         and executing_eagerly):\r\n       1917       # No tape is watching; skip to running the function.\r\n    -> 1918       return self._build_call_outputs(self._inference_function.call(\r\n       1919           ctx, args, cancellation_manager=cancellation_manager))\r\n       1920     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n        553       with _InterpolateFunctionError(self):\r\n        554         if cancellation_manager is None:\r\n    --> 555           outputs = execute.execute(\r\n        556               str(self.signature.name),\r\n    557               num_outputs=self._num_outputs,\r\n\r\n    ~/anaconda3/envs/dl_learn/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n         57   try:\r\n         58     ctx.ensure_initialized()\r\n    ---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n             60                                         inputs, attrs, num_outputs)\r\n             61   except core._NotOkStatusException as e:\r\n\r\n    CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\n\t [[gradient_tape/sequential_1/embedding/embedding_lookup/Reshape/_38]] [Op:__inference_train_function_3172]\r\n\r\n    Function call stack:\r\n    train_function'\r\n\r\nError message on console:\r\n\r\n    2021-03-29 05:37:44.895392: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_EXECUTION_FAILED in tensorflow/stream_executor/cuda/cuda_dnn.cc(1859): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\r\n\r\n    2021-03-29 05:37:44.895639: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1521 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 30, 128, 1, 30, 128, 0] \r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nI expected the issue to be resolved by adding `import os ; os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nBelow is the code that produces the error messages:\r\n\r\n    %config Completer.use_jedi = False\r\n    import pandas as pd\r\n    import numpy as np\r\n    import urllib.request \r\n    from tensorflow.keras.preprocessing.text import Tokenizer\r\n    from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n    from konlpy.tag import Okt\r\n    import re\r\n    import matplotlib.pyplot as plt\r\n    import os\r\n    os.environ[\"TF_FORCE_ALLOW_GPU_GROWTH\"] = 'true'\r\n    from tensorflow.keras.models import Sequential, load_model\r\n    from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU\r\n    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n\r\n    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename = 'ratings_train.txt')\r\n    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename = 'ratings_test.txt')\r\n\r\n    train = pd.read_table('ratings_train.txt')\r\n    train.drop_duplicates(subset = 'document', inplace = True)\r\n    train.dropna(inplace = True)   \r\n    train['document'] = train['document'].str.replace(r\"[^\u3131-\u314e\u314f-\u3163\uac00-\ud7a3 ]\", \"\")\r\n    train[train['document'] == ''] = np.nan\r\n    train.dropna(inplace = True)\r\n    stopwords = ['\uc758','\uac00','\uc774','\uc740','\ub4e4','\ub294','\uc880','\uc798','\uac4d','\uacfc','\ub3c4','\ub97c','\uc73c\ub85c','\uc790','\uc5d0','\uc640','\ud55c','\ud558\ub2e4']\r\n    okt = Okt()\r\n    X_train = [[word for word in okt.morphs(sentence, stem = True) if word not in stopwords] for sentence in train['document']]\r\n    vocab_size = 19417\r\n    t = Tokenizer(vocab_size, oov_token = \"OOV\")\r\n    t.fit_on_texts(X_train)\r\n    X_train_sequences = t.texts_to_sequences(X_train)\r\n    y_train = np.array(train['label'])\r\n    empty_sample_idx = [index for index, sequence in enumerate(X_train_sequences) if len(sequence) < 1]\r\n    X_train = np.delete(X_train_sequences, empty_sample_idx, axis = 0)\r\n    y_train = np.delete(y_train, empty_sample_idx, axis = 0)\r\n    maxlen = 30\r\n    X_train = pad_sequences(X_train, maxlen = maxlen, padding = 'pre')\r\n\r\n    model = Sequential()\r\n    model.add(Embedding(vocab_size, 30))\r\n    model.add(LSTM(128))\r\n    model.add(Dense(1, activation = 'sigmoid'))\r\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\r\n    es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 4, verbose =1)\r\n    mc = ModelCheckpoint('best_model_naver.h5', monitor = 'val_acc', mode = 'max', save_best_only = True)\r\n    history = model.fit(X_train, y_train, batch_size = 128, callbacks = [es, mc], epochs = 15, validation_split = .2)\r\n\r\n\r\n\r\n\r\n\r\nBelow is the code I was able to run successfully after adding `import os ; os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"` :\r\n\r\n    import os\r\n    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n    import numpy as np\r\n    import matplotlib.pyplot as plt\r\n    from tensorflow.keras.datasets import imdb\r\n    import re\r\n    from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n    from tensorflow.keras.models import Sequential\r\n    from tensorflow.keras.layers import Embedding, GRU, Dense, LSTM\r\n    from tensorflow.keras.utils import to_categorical\r\n    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n\r\n    vocab_size = 10000\r\n    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\r\n\r\n    maxlen = 500\r\n    X_train = pad_sequences(X_train, maxlen = maxlen)\r\n    X_test = pad_sequences(X_test, maxlen = maxlen)\r\n\r\n    model = Sequential()\r\n    model.add(Embedding(vocab_size, 100))\r\n    model.add(LSTM(128))\r\n    model.add(Dense(1, activation = 'sigmoid'))\r\n    es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 4, verbose = 1)\r\n    mc = ModelCheckpoint('best_model_imdb.h5', monitor = 'val_acc', mode = 'max', save_best_only = True)\r\n    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\r\n\r\n    history = model.fit(X_train, y_train, callbacks = [es, mc], epochs = 15, batch_size = 128, validation_split = .2)\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I was able to get both codes working by downgrading TF from 2.4.1 to 2.3.0. But the performance dropped dramatically. TF 2.3 didn't seem to utilize GPU (Fan: 0% and no python process showing up on `nvidia-smi`). When the 2nd code (i.e., shorter one using imdb data) was on TF 2.4.1, it took about 5 seconds to run an epoch. But the same code run with TF 2.3.0 took about 65 seconds for an epoch. ", "I am able to replicate the issue reported on the version mentioned, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/ca0005488f81dc618a5dc8b9137c59e1/untitled577.ipynb)", "I just learned that the exactly same results occur on Win10 with NVIDIA Driver 461.33, CUDA 11.2.109, Python 3.8.3.", "I got the same error message when I ran the code from Tensorflow container, which I built with the \"tensorflow/tensorflow:latest-gpu-jupyter\" image. ", "Was able to replicate the issue with TF nightly-2.6.0.dev20210603,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/c7d0721ec452f9f8cc306dcd796aa893/untitled208.ipynb)..Thanks !", "@kaixih On the surface this looks like an error reported by cuDNN from a `cudnnRNNForwardTraining` call.  Can you PTAL to see if this rings a bell?", "Can we have the cudnn logs: https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#api-logging.\r\n\r\nAlso if possible, can we have a repro with synthetic data? I have some trouble resolving the dependencies of these data processing tools when running the script on my machine.", "Any solution to this Multi GPU?\r\n\r\n```\r\nW tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at cudnn_rnn_ops.cc:1562 : UNKNOWN: CUDNN_STATUS_BAD_PARAM in tensorflow/stream_executor/cuda/cuda_dnn.cc(1588): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)' Traceback (most recent call last):\r\n\r\n tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node div_no_nan_1/ReadVariableOp_3/_40}}]] [Op:__inference_test_function_29082]\r\n```\r\n\r\nI am using \r\n\r\n``` tf.keras.utils.timeseries_dataset_from_array ```\r\nfrom [this link](https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array)\r\n\r\n"]}, {"number": 48130, "title": "error: aliases are not supported on darwin In MacOS Big Sur", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.2.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 2.4.1/master branch\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.29) (XCode 12+)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHi, I got this error while building TensorFlow from source using master branch/v2.4.1 branch from latest version of MacOS Big Sur (11+):\r\n\r\n```\r\nbazelisk build --config=mkl -c opt --copt=-march=native //tensorflow/tools/lib_package:libtensorflow\r\n\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=178\r\nINFO: Reading rc options for 'build' from /Users/mania25/Downloads/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/mania25/Downloads/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /Users/mania25/Downloads/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/opt/intel/oneapi/intelpython/latest/bin/python3 --action_env PYTHON_LIB_PATH=/opt/intel/oneapi/intelpython/latest/lib/python3.7/site-packages --python_path=/opt/intel/oneapi/intelpython/latest/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /Users/mania25/Downloads/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/mania25/Downloads/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:mkl in file /Users/mania25/Downloads/tensorflow/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_openmp=true -c opt\r\nINFO: Found applicable config definition build:macos in file /Users/mania25/Downloads/tensorflow/.bazelrc: --apple_platform_type=macos --copt=-DGRPC_BAZEL_BUILD --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/mania25/Downloads/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /Users/mania25/Downloads/tensorflow/tensorflow/workspace0.bzl:105:34: in workspace\r\n  /private/var/tmp/_bazel_mania25/2fa4938439e248c63b3c0f49ddc6c271/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_mania25/2fa4938439e248c63b3c0f49ddc6c271/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Analyzed target //tensorflow/tools/lib_package:libtensorflow (227 packages loaded, 20983 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /private/var/tmp/_bazel_mania25/2fa4938439e248c63b3c0f49ddc6c271/sandbox\r\nERROR: /private/var/tmp/_bazel_mania25/2fa4938439e248c63b3c0f49ddc6c271/external/llvm_openmp/BUILD.bazel:192:10: C++ compilation of rule '@llvm_openmp//:libiomp5.dylib' failed (Exit 1): wrapped_clang failed: error executing command external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 42 argument(s) skipped)\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1397:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_SET_NUM_THREADS, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1398:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_NUM_THREADS, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1399:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_MAX_THREADS, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1400:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_THREAD_NUM, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1401:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_NUM_PROCS, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1402:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_IN_PARALLEL, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1403:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_SET_DYNAMIC, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1404:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_DYNAMIC, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1405:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_SET_NESTED, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1406:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_GET_NESTED, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1407:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_INIT_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1408:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_INIT_NEST_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1409:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_DESTROY_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1410:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_DESTROY_NEST_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1411:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_SET_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1412:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_SET_NEST_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1413:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_UNSET_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1414:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_UNSET_NEST_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nIn file included from external/llvm_openmp/runtime/src/kmp_ftn_cdecl.cpp:31:\r\nexternal/llvm_openmp/runtime/src/kmp_ftn_entry.h:1415:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(FTN_TEST_LOCK, 10, \"OMP_1.0\");\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:362:22: note: expanded from macro '_KMP_VERSION_SYMBOL'\r\n      __attribute__((alias(KMP_STR(__kmp_api_##api_name))));                    \\\r\n                     ^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nTarget //tensorflow/tools/lib_package:libtensorflow failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1726.530s, Critical Path: 245.91s\r\nINFO: 4331 processes: 148 internal, 4183 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Intel\u00ae oneAPI Base Toolkit (https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit/download.html?operatingsystem=mac&distributions=webdownload&options=offline).\r\n2. source /opt/intel/oneapi/setvars.sh\r\n3. pip install pip numpy wheel\r\n4. pip install keras_preprocessing --no-deps\r\n5. git clone https://github.com/tensorflow/tensorflow.git\r\n6. ./configure\r\n7. bazelisk build --config=mkl -c opt --copt=-march=native //tensorflow/tools/lib_package:libtensorflow\r\n\r\n**Any other info / logs**\r\nNone\r\n", "comments": ["@mania25 \r\nCould you please try on virtual env and let us know if you still face the issue.", "hmm okay i'll try it", "@Saduf2019 it still the same, I still got the same error in virtual env", "@Saduf2019 is there any way I could run Bazel with custom clang? I think the issue is within default XCode clang compiler and only happen when Bazel trying to compile llvm_openmp.", "I have the same issue on Catalina with clang verson 12.0.0\r\n```\r\n$ c++ --version\r\nApple clang version 12.0.0 (clang-1200.0.32.29)\r\nTarget: x86_64-apple-darwin19.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n```", "seems like the problem came from LLVM_OpenMP package, I tried to downgrade the version to the old one and still got the error, CMIIW", "any update on this @ymodak @Saduf2019 ?", "@mania25, are you looking to get tensorflow with mkl for 2.4? Anaconda ships with mkl optimizations but the latest version available is 2.0. `conda install -c anaconda tensorflow`", "@preethivenkatesh yes, but i think in the mean time, I will downgrade the version to 2.3.2, I tried that version and it compiled successfully", "I tried building r2.3 and got errors.\n\nhttps://github.com/tensorflow/tensorflow/pull/40654 <https://github.com/tensorflow/tensorflow/pull/40654>\n\nDid you run into this issue?\n\ntensorflow/python/lib/core/bfloat16.cc:667:8: error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)'\n  if (!register_ufunc(\"not_equal\", CompareUFunc<Bfloat16NeFunctor>,\n       ^~~~~~~~~~~~~~\ntensorflow/python/lib/core/bfloat16.cc:637:25: note: candidate function not viable: no overload of 'CompareUFunc' matching 'PyUFuncGenericFunction' (aka 'void (*)(char **, const long *, const long *, void *)') for 2nd argument\n  auto register_ufunc = [&](const char* name, PyUFuncGenericFunction fn,\n\n> On Apr 6, 2021, at 11:21 PM, Abdurrahman ***@***.***> wrote:\n> \n> \n> @preethivenkatesh <https://github.com/preethivenkatesh> yes, but i think in the mean time, I will downgrade the version to 2.3.2, I tried that version and it compiled successfully\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/48130#issuecomment-814636763>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAXWFW66FSME2H3C43WWTUTTHP2YHANCNFSM4Z6DDXYA>.\n> \n\n", "@dbl001 nope, i dont run into that issues", "I cloned branch r2.3. How did you get 2.3.3?\n\n> On Apr 10, 2021, at 7:10 AM, Abdurrahman ***@***.***> wrote:\n> \n> \n> @dbl001 <https://github.com/dbl001> nope, i dont run into that issues\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/48130#issuecomment-817142640>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAXWFW7GHLVRZ2N46CWXZ63TIBL5TANCNFSM4Z6DDXYA>.\n> \n\n", "i am not using the 2.3.3, i am using 2.3.2", "Big Sur 11.3 with XCode 12.5 has exactly same issues that do not seem to be addressed yet.", "FYR. I guess mkl on macOS is not tested. I was able to build ` //tensorflow/tools/lib_package:libtensorflow` and `//tensorflow/tools/pip_package:build_pip_package` on a MBP x86_64 with the following dirty patch,\r\n\r\n```diff\r\ndiff --git a/third_party/llvm_openmp/BUILD b/third_party/llvm_openmp/BUILD\r\nindex 975d40fb728..81fa8d18ee0 100644\r\n--- a/third_party/llvm_openmp/BUILD\r\n+++ b/third_party/llvm_openmp/BUILD\r\n@@ -80,7 +80,18 @@ omp_vars_win = {\r\n     \"MSVC\": 1,\r\n }\r\n\r\n+#macOS doesn't support symbol versioning\r\n+omp_vars_macos = {\r\n+    \"LIBOMP_USE_VERSION_SYMBOLS\": 0,\r\n+}\r\n+\r\n omp_all_cmake_vars = select({\r\n+    \"@org_tensorflow//tensorflow:macos\": cmake_var_string(\r\n+        dict_add(\r\n+            omp_vars,\r\n+            omp_vars_macos,\r\n+        ),\r\n+    ),\r\n     \"@org_tensorflow//tensorflow:windows\": cmake_var_string(\r\n         dict_add(\r\n             omp_vars,\r\n@@ -205,7 +216,7 @@ cc_binary(\r\n     ] + srcdeps,\r\n     copts = [\"-Domp_EXPORTS -D_GNU_SOURCE -D_REENTRANT\"],\r\n     includes = common_includes,\r\n-    linkopts = [\"-lpthread -ldl -Wl,--version-script=$(location :ldscript)\"],\r\n+    linkopts = [\"-lpthread -ldl\"],\r\n     linkshared = True,\r\n     visibility = [\"//visibility:public\"],\r\n )\r\ndiff --git a/third_party/mkl/build_defs.bzl b/third_party/mkl/build_defs.bzl\r\nindex 806b157bad6..130d80ac654 100644\r\n--- a/third_party/mkl/build_defs.bzl\r\n+++ b/third_party/mkl/build_defs.bzl\r\n@@ -34,6 +34,7 @@ def if_mkl(if_true, if_false = []):\r\n     return select({\r\n         \"@org_tensorflow//third_party/mkl:build_with_mkl_aarch64\": if_true,\r\n         \"@org_tensorflow//tensorflow:linux_x86_64\": if_true,\r\n+        \"@org_tensorflow//tensorflow:macos\": if_true,\r\n         \"@org_tensorflow//tensorflow:windows\": if_true,\r\n         \"//conditions:default\": if_false,\r\n     })\r\n@@ -103,6 +104,7 @@ def mkl_deps():\r\n     return select({\r\n         \"@org_tensorflow//third_party/mkl:build_with_mkl_aarch64\": [\"@mkl_dnn_acl_compatible//:mkl_dnn_acl\"],\r\n         \"@org_tensorflow//tensorflow:linux_x86_64\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n+        \"@org_tensorflow//tensorflow:macos\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"@org_tensorflow//tensorflow:windows\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"//conditions:default\": [],\r\n     })\r\ndiff --git a/third_party/mkl_dnn/mkldnn_v1.BUILD b/third_party/mkl_dnn/mkldnn_v1.BUILD\r\nindex ee1ee26ae94..f80cfcc85a9 100644\r\n--- a/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n+++ b/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n@@ -87,6 +87,7 @@ _INCLUDES_LIST = [\r\n     \"src/cpu\",\r\n     \"src/cpu/gemm\",\r\n     \"src/cpu/x64/xbyak\",\r\n+    \"../llvm_openmp/include\",\r\n ]\r\n\r\n _TEXTUAL_HDRS_LIST = glob([\r\n@ -114,6 +115,10 @@ cc_library(\r\n     }) + [\"-U_FORTIFY_SOURCE\"] + _COPTS_LIST,\r\n     includes = _INCLUDES_LIST,\r\n     textual_hdrs = _TEXTUAL_HDRS_LIST,\r\n+    deps = if_mkl_ml(\r\n+        [\"@org_tensorflow//third_party/mkl:intel_binary_blob\"],\r\n+        [],\r\n+    ),\r\n     visibility = [\"//visibility:public\"],\r\n )\r\n```", "Any update on this thread please?\r\nI am on Macbook pro 2017, Big Sur Version 11.4. Do I need to install oneDNN via Intel\u00ae oneAPI Base Toolkit (https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit/download.html?operatingsystem=mac&distributions=webdownload&options=offline)? I thought this is already supported.", "> Any update on this thread please?\r\n> I am on Macbook pro 2017, Big Sur Version 11.4. Do I need to install oneDNN via Intel\u00ae oneAPI Base Toolkit (https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit/download.html?operatingsystem=mac&distributions=webdownload&options=offline)? I thought this is already supported.\r\n\r\nWhat do you want? MKL/oneAPI or mkl_dnn/oneDNN only? The former, yes, you have to download it. And I don't think it's well-tested and supported. The latter, something like `bazel build --config opt //tensorflow/tools/pip_package:build_pip_package` should download necessary mkldnn source code for you.", "Thank you, this answers my question. I only need the latter. \r\nHowever, I am still getting an error. I followed the steps listed at https://www.tensorflow.org/install/source for MacOS.\r\n error: aliases are not supported on darwin. \r\nI started thinking maybe Conda is a better way to setup my environment. \r\n\r\nMy env:\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.4\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version: 2.4/master branch\r\nPython version: 3.8.6\r\nInstalled using virtualenv? pip? conda?: pip\r\nBazel version (if compiling from source):3.1.0\r\nGCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.29) (XCode 12+)\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\n\r\n", "@entargo hmm, maybe you added `--config mkl`? `--config mkl` means the former one I mentioned. Anyway, you may want to `bazel clean --expunge` before `bazel build --config opt //tensorflow/tools/pip_package:build_pip_package`. Yes, simply `bazel build --config opt //tensorflow/tools/pip_package:build_pip_package`, it will be built with mkl_dnn/oneDNN on macOS.", "I'm getting the same errors building tensorflow on Big Sur 11.5\r\nE.g \r\n```\r\n % clang --version\r\nApple clang version 12.0.5 (clang-1205.0.22.11)\r\nTarget: x86_64-apple-darwin20.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n% bazelisk build --config=mkl //tensorflow/tools/pip_package:build_pip_package \r\n...\r\nexternal/llvm_openmp/runtime/src/kmp_gsupport.cpp:1864:1: error: aliases are not supported on darwin\r\nKMP_VERSION_SYMBOL(KMP_API_NAME_GOMP_LOOP_ORDERED_RUNTIME_START, 10,\r\n^\r\nexternal/llvm_openmp/runtime/src/kmp_os.h:359:3: note: expanded from macro 'KMP_VERSION_SYMBOL'\r\n  _KMP_VERSION_SYMBOL(api_name, ver_num, ver_str, \"VERSION\")\r\n  ^\r\n```\r\nThe patch is getting an error:\r\n```\r\n% patch --backup-if-mismatch  third_party/llvm_openmp/BUILD b/third_party/llvm_openmp/BUILD patch.txt\r\npatch: patch.txt: extra operand\r\npatch: Try `patch --help' for more information.\r\n\r\n% diff --git a/third_party/llvm_openmp/BUILD b/third_party/llvm_openmp/BUILD\r\ndiff: unrecognized option `--git'\r\ndiff: Try `diff --help' for more information.\r\n```", "@dbieber this is a moving target :-) \r\n\r\nyou may want to try this. Note that I didn't test it.\r\n\r\n```diff\r\ndiff --git a/third_party/llvm_openmp/BUILD b/third_party/llvm_openmp/BUILD\r\nindex 1450b47fce9..56b6036fcce 100644\r\n--- a/third_party/llvm_openmp/BUILD\r\n+++ b/third_party/llvm_openmp/BUILD\r\n@@ -113,7 +113,18 @@ omp_vars_win = {\r\n     \"MSVC\": 1,\r\n }\r\n \r\n+#macOS doesn't support symbol versioning\r\n+omp_vars_macos = {\r\n+    \"LIBOMP_USE_VERSION_SYMBOLS\": 0,\r\n+}\r\n+\r\n omp_all_cmake_vars = select({\r\n+    \"@org_tensorflow//tensorflow:macos\": cmake_var_string(\r\n+        dict_add(\r\n+            omp_vars,\r\n+            omp_vars_macos,\r\n+        ),\r\n+    ),\r\n     \"@org_tensorflow//tensorflow:windows\": cmake_var_string(\r\n         dict_add(\r\n             omp_vars,\r\ndiff --git a/third_party/llvm_openmp/openmp.bzl b/third_party/llvm_openmp/openmp.bzl\r\nindex e2ced9284df..f283ee5034d 100644\r\n--- a/third_party/llvm_openmp/openmp.bzl\r\n+++ b/third_party/llvm_openmp/openmp.bzl\r\n@@ -83,7 +83,7 @@ def libiomp5_cc_binary(name, cppsources, srcdeps, common_includes):\r\n         ),\r\n         includes = common_includes,\r\n         linkopts = select_os_specific_2(\r\n-            LM = [\"-lpthread -ldl -Wl,--version-script=$(location :ldscript)\"],\r\n+            LM = [\"-lpthread -ldl\"],\r\n             W = [\"/MACHINE:X64\"],\r\n         ),\r\n         linkshared = True,\r\ndiff --git a/third_party/mkl/build_defs.bzl b/third_party/mkl/build_defs.bzl\r\nindex 806b157bad6..130d80ac654 100644\r\n--- a/third_party/mkl/build_defs.bzl\r\n+++ b/third_party/mkl/build_defs.bzl\r\n@@ -34,6 +34,7 @@ def if_mkl(if_true, if_false = []):\r\n     return select({\r\n         \"@org_tensorflow//third_party/mkl:build_with_mkl_aarch64\": if_true,\r\n         \"@org_tensorflow//tensorflow:linux_x86_64\": if_true,\r\n+        \"@org_tensorflow//tensorflow:macos\": if_true,\r\n         \"@org_tensorflow//tensorflow:windows\": if_true,\r\n         \"//conditions:default\": if_false,\r\n     })\r\n@@ -103,6 +104,7 @@ def mkl_deps():\r\n     return select({\r\n         \"@org_tensorflow//third_party/mkl:build_with_mkl_aarch64\": [\"@mkl_dnn_acl_compatible//:mkl_dnn_acl\"],\r\n         \"@org_tensorflow//tensorflow:linux_x86_64\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n+        \"@org_tensorflow//tensorflow:macos\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"@org_tensorflow//tensorflow:windows\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"//conditions:default\": [],\r\n     })\r\ndiff --git a/third_party/mkl_dnn/mkldnn_v1.BUILD b/third_party/mkl_dnn/mkldnn_v1.BUILD\r\nindex 6fcfd9878f4..f48077c7cba 100644\r\n--- a/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n+++ b/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n@@ -87,6 +87,7 @@ _INCLUDES_LIST = [\r\n     \"src/cpu\",\r\n     \"src/cpu/gemm\",\r\n     \"src/cpu/x64/xbyak\",\r\n+    \"../llvm_openmp/include\",\r\n ]\r\n \r\n _TEXTUAL_HDRS_LIST = glob([\r\n\r\n```", "You probably meant to tag @dbl001 rather than myself :)", "I downloaded oneDNN 2.3.2, built it from source, ran 'ctest' and installed it with no issues.\r\n```  \r\n-- Found Git: /opt/local/bin/git (found version \"2.32.0\") \r\n-- Primitive cache is enabled\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /Users/davidlaxer/oneDNN/build\r\n...\r\n% bazelisk --version\r\nbazel 4.1.0\r\n```\r\n\r\nEdited your proposed git diff's, then\r\n```\r\n$ bazel clean --expunge\r\n$ ./configure\r\n$ bazelisk build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n...\r\nERROR: /Users/davidlaxer/tensorflow/tensorflow/core/platform/default/BUILD:273:11: C++ compilation of rule '//tensorflow/core/platform/default:platform_port' failed (Exit 1): wrapped_clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_davidlaxer/f9fe21ec5c09226e5ca0dce9376abe82/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=11.3 \\\r\n    PATH=/Users/davidlaxer/Library/Caches/bazelisk/downloads/bazelbuild/bazel-3.7.2-darwin-x86_64/bin:/Users/davidlaxer/.opam/_coq-platform_.2021.02.1/bin:/Users/davidlaxer/anaconda3/envs/ai/bin:/Users/davidlaxer/anaconda3/condabin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin:/Users/davidlaxer/go/bin \\\r\n    XCODE_VERSION_OVERRIDE=12.5.1.12E507 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-DNS_BLOCK_ASSERTIONS=1' '-std=c++11' -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/snappy -iquote bazel-out/host/bin/external/snappy -isystem third_party/eigen3/@mkl_dnn_v1/:mkl_dnn -isystem bazel-out/host/bin/third_party/eigen3/@mkl_dnn_v1/:mkl_dnn -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -MD -MF bazel-out/host/bin/tensorflow/core/platform/default/_objs/platform_port/cpu_info.d -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DHAVE_SYS_UIO_H -DTF_USE_SNAPPY '-frandom-seed=bazel-out/host/bin/tensorflow/core/platform/default/_objs/platform_port/cpu_info.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=11.3' -g0 -Wno-sign-compare -g0 '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' @mkl_dnn_v1//:mkl_dnn -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/platform/cpu_info.cc -o bazel-out/host/bin/tensorflow/core/platform/default/_objs/platform_port/cpu_info.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nclang: error: no such file or directory: '@mkl_dnn_v1//:mkl_dnn'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 83.353s, Critical Path: 78.12s\r\nINFO: 437 processes: 27 internal, 410 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\nbut, my ~/tensorflow/tensorflow/workspace2.bzl shows:\r\n```\r\ntf_http_archive(\r\n        name = \"mkl_dnn\",\r\n        build_file = \"//third_party/mkl_dnn:mkldnn.BUILD\",\r\n        sha256 = \"a0211aeb5e7dad50b97fa5dffc1a2fe2fe732572d4164e1ee8750a2ede43fbec\",\r\n        strip_prefix = \"oneDNN-0.21.3\",\r\n        urls = [\r\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/oneapi-src/oneDNN/archive/v0.21.3.tar.gz\",\r\n            \"https://github.com/oneapi-src/oneDNN/archive/v0.21.3.tar.gz\",\r\n        ],\r\n    )\r\n    \r\n    tf_http_archive(\r\n        name = \"mkl_dnn_v1\",\r\n        build_file = \"//third_party/mkl_dnn:mkldnn_v1.BUILD\",\r\n        sha256 = \"82795714f11649b2a3f797d99bd07d117cde97215f55654b028ca00f3b33e0cb\",\r\n        strip_prefix = \"oneDNN-2.3-rc2\",\r\n        urls = [ \r\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/oneapi-src/oneDNN/archive/v2.3-rc2.tar.gz\",\r\n            \"https://github.com/oneapi-src/oneDNN/archive/v2.3-rc2.tar.gz\",\r\n        ],  \r\n    )       \r\n\r\n```\r\nHmmm ...\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/48035", "https://oneapi-src.github.io/oneDNN/dev_guide_transition_to_dnnl.html\r\n\r\nIs this rule the problem? (e.g. dependent upon mlc_dnn)?\r\n```\r\n\"@org_tensorflow//tensorflow:macos\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n```\r\n", "@dbieber oops, sorry\r\n\r\n@dbl001: I don't know what you want to do. You tried both w/ and w/o `--config mkl`. Let's start from some things I think I knew, to see if we can make it clear\r\n\r\n0. there are oneDNN (formerly mkldnn) and mkl part of oneAPI \r\n1. oneDNN, which is open source one, seems to be tested and integrated with macOS well (no need to add `--config mkl`). `bazel build //tensorflow/tools/pip_package:build_pip_package` is supposed to download the oneDNN source code, build it, and use it. If it doesn't work, then you hit a bug. \r\n2. oneAPI (--config mkl) is not really tested on macOS. It doesn't build. That's what my dirty patch was for. If you don't use things other than oneDNN, you don't need the dirty patch.\r\n3. So what does my dirty patch do. To use oneAPI, OpenMP is kinda needed. But the clang shipped with Xcode doesn't support OpenMP, there are some clever bazel build rules to build clang/llvm with OpenMP support from source code in TensorFlow. What I did was to enable it on macOS.\r\n\r\nin short, if you don't need things other than oneDNN, **don't** use my dirty patch.", "Thanks for your clarification.\r\n1. I was able to build tensorflow without MKL \r\nE.g. bazelisk build //tensorflow/tools/pip_package:build_pip_package\r\n2. I still can't build a wheel, but that's a separate issue:\r\n```\r\n ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n...\r\nAssertionError: would build wheel with unsupported tag ('cp38', 'cp38', 'macosx_11_3_x86_64')\r\n```\r\n3. My Mac had libomp (from Macports) and openmp from Anaconda:\r\n```\r\n% clang --version\r\nApple clang version 12.0.5 (clang-1205.0.22.11)\r\nTarget: x86_64-apple-darwin20.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n% port list libomp\r\nlibomp                         @12.0.1         lang/libomp\r\n% conda list openmp\r\n# packages in environment at /Users/davidlaxer/anaconda3:\r\n#\r\n# Name                    Version                   Build  Channel\r\nintel-openmp              2020.2                      258    anaconda\r\nllvm-openmp               10.0.0               h28b9765_0    anaconda\r\n```\r\nAny idea why your patch didn't work?\r\nE.g \r\n```\r\nclang: error: no such file or directory: '@mkl_dnn_v1//:mkl_dnn'\r\n```"]}, {"number": 48118, "title": "tensorflowlite.dll is huge (compared to other platforms)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 5d6cc7bf97a226c1e6a73ad4fc391c154dd622ac\r\n- Python version: n/a\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): MSVC 2019 (cl: 19.28.29334)\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nbazel build -c opt //tensorflow/lite/tensorflowlite.dll\r\n```\r\n\r\nThis yields a 15MB statically linked binary when compiled for 32-bit windows (i.e. the 64-bit version will be even larger). Compared to other platforms, this is a 5x increase that is difficult to explain, especially in lieu of tools like bloaty on Windows. Unfortunately I don't know where to start poking this at all - but I do believe that even accounting for platform differences, a 5x size difference is unexpected. The same issue was noted here: https://github.com/tensorflow/tensorflow/issues/33634#issuecomment-620645664 (with a suggestion to use the C API *instead*, but the C API is a binding that cannot be used independent from the C++ binary).\r\n\r\n**Any other info / logs**\r\nLet me know if I can include any more info.\r\n", "comments": ["Interestingly, it compresses down to just 1.3MB with lzma. That tells me it's probably not all code taking up that much size.", "After some poking, it appears the size is due to the export table being 12MB. This is due to the `windows_export_all_symbols` feature added here: https://github.com/tensorflow/tensorflow/commit/fa32891c6f30add2338b4833ad32f593ec6610a6 \r\n\r\nThere is a def file filtering script, but that is only used for the non-lite version. I think that could be a reasonable solution to this. https://github.com/tensorflow/tensorflow/issues/43367", "After further investigation I found that the CMake build produces a 1.4MB DLL that is missing lots of symbols. However, with the CMake build, I'm able to build a static library that solves this problem for our use-case because ultimately it allows the linker to sort out which symbols to use (we are using the C++ API directly). The bazel build hardcodes the shared library, maybe it would be useful to make that optional. I don't have any bazel expertise unfortunately to do that (not that I would prefer bazel).  "]}, {"number": 48113, "title": "Please help Conda package tensorflow for OSX", "body": "(I get that this is a weird thing to put in an issue)\r\n\r\nRight now it's hard for the Anaconda people to make conda packages of Tensorflow for OSX because of gcc-versus-clang issues: \r\nhttps://github.com/ContinuumIO/anaconda-issues/issues/11697\r\n\r\nThis is impacting downstream packages that want to use tensorflow, as we can't specify conda environments that come with tensorflow included; installing it with pip afterwards severely limits our ability to sanely package it.\r\n\r\nIf you can spare the time to work this out with them, a lot of us who maintain downstream packages would really appreciate it.", "comments": ["Probably the necessary information needed here is how to build the correct Bazel compiler toolchain. You can have a look at https://github.com/conda-forge/tensorflow-feedstock/blob/40db5f43756877bea9e0dd2685cd5683b6527904/recipe/gen-bazel-toolchain.sh#L1 how we did this for conda-forge."]}, {"number": 48105, "title": "Incorrect ZeroPadding before MaxPool2D in keras' resnet", "body": "Hi,\r\n\r\nI've noticed that the implementation of resnet networks in keras introduces a ZeroPadding layer before the initial MaxPool2D 3x3 stride 2:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/204082475214b3f08d1301998780592b53076951/tensorflow/python/keras/applications/resnet.py#L161\r\n\r\nI don't think this is correct. Zero is not a neutral element for a MaxPool2D operation. The input values at the edges could be negative.\r\n\r\nI believe the intention of that zero padding layer is what would be correctly represented as SAME padding for the MaxPool2D directly. Note that the padding layer is also adding padding elements to the right and bottom edges of the input that the 3x3 stride 2 MaxPool2D operation won't ever use if the input is even size as I believe it commonly is.", "comments": []}, {"number": 48104, "title": "Tensorflow_xla model inference crash on Jetson AGX xavier", "body": "\r\nI met tensorflow_xla crash issue for model inference on Nvidia Jetson AGX Xavier aarch64 system.\r\n\r\n**System information**\r\n- Have I written custom code: Yes, I have some CPU computing custom ops, they are in different places in the middle of the network\r\n- OS Platform and Distribution):  Linux Ubuntu18.04\r\n- device: Nvidia Jetson AGX Xavier\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): tensorflow-2.4.1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):  7.5.0\r\n- CUDA/cuDNN version: cuda10.2, cudnn8.0\r\n- GPU model and memory:  GPU model with cpu custom ops, device memory 32GB (including cpu mem and gpu mem)\r\n\r\n[crash.log](https://github.com/tensorflow/tensorflow/files/6211738/crash.log)\r\n[gdb.log](https://github.com/tensorflow/tensorflow/files/6211740/gdb.log)\r\n\r\nIssues\uff1a\r\n1, When do model inference with xla enable, this crash can be reproduced almost every time  (xavier aarch64 system)\r\n2, When I turn off some of custom ops (CPU compute op), crash can happen about 7 times after 10 runs  (xavier aarch64 system)\r\n3, When I run same code, same tensorflow-2.4.1 version on V100 GPU and x86 system, it can run successful without crash  (x86 + v100 gpu system)", "comments": ["@lcx2017,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here and the dataset you are using. Thanks!", "Also, **TensorFlow v2.4.1** is compatible with **CUDA 11.0** and **cuDNN 8.0**. Please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu) for more information. \r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 7.6 | 10.1\r\ntensorflow-2.2.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 2.0.0 | 7.6 | 10.1\r\n\r\nCould you please update CUDA to **v11.0** and check if you are still facing the same error. Thanks!", "> Also, **TensorFlow v2.4.1** is compatible with **CUDA 11.0** and **cuDNN 8.0**. Please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu) for more information.\r\n> \r\n> Version\tPython version\tCompiler\tBuild tools\tcuDNN\tCUDA\r\n> tensorflow-2.4.0\t3.6-3.8\tGCC 7.3.1\tBazel 3.1.0\t8.0\t11.0\r\n> tensorflow-2.3.0\t3.5-3.8\tGCC 7.3.1\tBazel 3.1.0\t7.6\t10.1\r\n> tensorflow-2.2.0\t3.5-3.8\tGCC 7.3.1\tBazel 2.0.0\t7.6\t10.1\r\n> Could you please update CUDA to **v11.0** and check if you are still facing the same error. Thanks!\r\n\r\nFor Jetson AGX Xavier platform, it only support Nvidia Jetpack SDK to update system AI tool chain, now I'm using Jetpack4.4, and Jetpack does not support CUDA 11.0 yet.  https://developer.nvidia.com/jetpack-sdk-44-archive", "> @lcx2017,\r\n> In order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here and the dataset you are using. Thanks!\r\n\r\nDo you have Jetson AGX Xavier platform to reproduce this issue? ", "@lcx2017,\r\nThank you for the update. \r\n\r\nCurrently, I do not have the NVIDIA Jetson AGX Xavier Developer Kit. But a minimal code snippet would help us debug the issue and determine the source of the error easily.", "> @lcx2017,\r\n> Thank you for the update.\r\n> \r\n> Currently, I do not have the NVIDIA Jetson AGX Xavier Developer Kit. But a minimal code snippet would help us debug the issue and determine the source of the error easily.\r\n\r\nThanks a lot! \r\nOn Jetpack 4.4 (cuda 10.2, cudnn 8.0, tensorrt 7.1.3.0, Tensorflow 2.4.1)\r\n1, The code can not share because of Trade secret, sorry for that! \r\n2, The custom op is common pixel level computing method, some if/else logic in it so we didn't code it by CUDA kernel.\r\n3, After close xla compilation for all the custom ops, crash issue still exists, crashed 6 times after 20 runs. \r\n4, After enable xla compilation for the whole network, crashed 20 times after 20 runs.\r\n5, After disable xla for the whole network, prue tensorflow model can run successful without crash\r\n\r\nhave also tested Jetpack 4.3 on Jetson AGX Xavier, find there is no crash issue on Jetpack4.3 (Tensorflow 2.2)(https://developer.nvidia.com/jetpack-43-archive), \r\nOn Jetpack 4.3 (cuda 10.0, cudnn 7.6.3, Tensorrt 6.0.1.10, Tensorflow 2.2)\r\n1, After enable xla for the whole network, tensorflow xla model can run successful without crash, the latency is good.\r\n\r\nAfter compare the Jetpack4.4 with Tensorflow 2.4 and Jetpack4.3 with Tensorflow2.2, found new latency slow issue for op of tf.math.unsorted_segment_max:\r\nJetpack4.3 with tensorflow 2.2: latency of \"tf.math.unsorted_segment_max\" op on Jetson AGX Xavier: 2~3ms\r\nJetpack4.3 with tensorflow 2.4: latency of \"tf.math.unsorted_segment_max\" op on Jetson AGX Xavier: 120ms\r\n\r\n<img width=\"613\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31198852/113114950-7a27fa00-923e-11eb-8268-5512dc2a177c.png\">\r\n"]}, {"number": 48086, "title": "tf.io.gfile.walk broken on Windows", "body": "It seems that the path isn't split correctly. Filenames come with an extra `\\` prefix. Minimal reproducible example:\r\n\r\n```python3\r\nimport os\r\nimport tensorflow as tf\r\n\r\n\r\ntf.io.gfile.makedirs(\"ram://folder\")\r\nwith tf.io.gfile.GFile(\"ram://folder/file.txt\", mode=\"w\") as f:\r\n    f.write(\"data\")\r\n\r\nfor root, _, filenames in tf.io.gfile.walk(\"ram://folder\"):\r\n    for filename in filenames:\r\n        assert tf.io.gfile.exists(os.path.join(root, filename))\r\n```\r\n\r\nThis passes on *nix but not on Windows. Here is a quick CI run in GitHub actions showing this: https://github.com/adriangb/tensorflow-test/actions/runs/688190284\r\n\r\nccing @mihaimaruseac @bhack ", "comments": ["Some relevant discussion: https://github.com/tensorflow/tensorflow/pull/39609#discussion_r600667357", "Thanks", "The problem in this specific example is that you could not use `os.path.join` cause it will add in python `\\` native separator on Windows that is not the ram filesystem separator `/`.\r\nSee https://github.com/bhack/tensorflow-test/blob/master/test.py", "Hmm good point, I was trying to simplify the example to not include model saving, but maybe that's the source of the problem? I reverted to [8c3dae](https://github.com/adriangb/tensorflow-test/blob/8c3dae59efbbf62e746b24ab2227307fad072466/test.py), which [does reproduce the issue](https://github.com/adriangb/tensorflow-test/runs/2198176548?check_suite_focus=true).", "Yes I suppose that the issue is more in the pythoh native join in model save and load. E.g. see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/saving/saved_model/save.py#L96.\r\n\r\nX filesystem separator in c++ is here but I don't think it is exposed in pyhton:\r\nhttps://github.com/tensorflow/tensorflow/blob/343cb03f21c73cfe84e47ab2974a6faa1ad80972/tensorflow/core/platform/file_system.h#L394-L399", "I have a reproducible version without model saving (although of course these two could be unrelated, you make a good point above):\r\n\r\n[Test passing on *nix](https://github.com/adriangb/tensorflow-test/runs/2198281295?check_suite_focus=true)\r\n[Test failing on Windows](https://github.com/adriangb/tensorflow-test/runs/2198281305?check_suite_focus=true)\r\n\r\nSource (also [here](https://github.com/adriangb/tensorflow-test/blob/02a7cdb7dbb386366573b775a8231ac64dfacd85/test.py)):\r\n\r\n```python3\r\nimport tensorflow as tf\r\n\r\n\r\ntf.io.gfile.makedirs(\"ram://test/inner\")\r\n\r\nwith tf.io.gfile.GFile(\"ram://test/inner/file.txt\", mode=\"w\") as f:\r\n    f.write(\"data\")\r\n\r\nfor root, _, filenames in tf.io.gfile.walk(\"ram://test\"):\r\n    for filename in filenames:\r\n        path = root + \"/\" + filename\r\n        print(f\"root: {root}\")\r\n        print(f\"filename: {filename}\")\r\n        print(f\"path: {path}\")\r\n        assert path == \"ram://test/inner/file.txt\"\r\n```", "I suspect this is another problem. \r\nI don't know if you can patch on the fly in you repo action  https://github.com/tensorflow/tensorflow/blob/306904197c95cc01cdcd30462fd62984329f5cef/tensorflow/python/lib/io/file_io.py#L838-L839\r\nTo print `_make_full_path` and `is_directory` result in Ubuntu/Win ", "I should be able to. I'll give it a try tomorrow.", "> This passes on *nix but not on Windows\r\n\r\n@adriangb,\r\nWith [TF v2.4](https://colab.research.google.com/gist/amahendrakar/244269ccabf4e7b5f175ce5eaf662264/48086.ipynb), I was able to reproduce the `AssertionError` on Linux as well. \r\n\r\nHowever, I did not face any error while running the code with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6fcf1ad6081f233913593481a765c7b8/48086-tf-nightly.ipynb). Please check the linked gist for reference. \r\n\r\nCould you please check if you are facing the same error with TF-nightly as well? Thanks!", "@amahendrakar We was always working to debug this with nightly. See https://github.com/adriangb/tensorflow-test/blob/master/.github/workflows/test.yml#L14", "@adriangb Ok I've Win emulated your last example on Linux with Docker+Wine. \r\n\r\nYou can test yourself with\r\n\r\n```\r\ndocker run -it --rm tobix/pywine /bin/bash\r\nwine pip install tf-nighlty-cpu\r\nwine python <your_code_stub>.py\r\n```\r\nYou can add debug prints to `/opt/wineprefix/drive_c/Python39/Lib/site-packages/tensorflow/python/lib/io/file_io.py` in `def _make_full_path(parent, item):`\r\n\r\nJust for your last **specific test case** you could replace `return os.path.join(parent, item)` with `return os.path.join(parent, item).replace(\"\\\\\",\"/\")` and run your last example in the Win emulated Docker.\r\n\r\n\r\n\r\n", "@frankchn @mihaimaruseac  As I see in your ram filesystem [tests](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/ram_file_system_test.py) do you expect an universal \"/\" for the ram filesystem and not an OS dependent one right?", "I was able to test using docker and wine, thanks for the tip @bhack !\r\n\r\nIt looks like what is happening is that this `os.path.join`:\r\nhttps://github.com/tensorflow/tensorflow/blob/204082475214b3f08d1301998780592b53076951/tensorflow/python/lib/io/file_io.py#L824\r\nIs joining `parent=\"ram://test\"` and `item=\"inner\"` -> `path=\"ram://test\\inner`, which then cascades into `is_directory(path) == False`, so `\\inner` gets returned as a file, etc (btw, returning `False` for a non-existing dir/file is the same behavior as `os.path.isdir`, so that's fine)\r\n\r\nIt seems to me like generally the problem stems from the fact that, on windows, `os.path.join(\"a\", \"b\") == \"a\\b\"` but you are using `\"/\"` as the path separator for ram filesystems regardless of the platform.", "So it seems like 2 things are needed to solve this:\r\n1. Some way to determine what the path separator is given the full path.\r\n2. An implementation of `os.path.join` that accepts a path separator.", "If you see the ram filesystem tests I mentioned above you see that it is only tested with \"/\" separator.\r\n\r\nBut OS dep separator is not illegal. E.g. run in your Wine environment:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ntf.io.gfile.makedirs(\"ram://test\\\\inner\")\r\n\r\nwith tf.io.gfile.GFile(\"ram://test\\\\inner\\\\file.txt\", mode=\"w\") as f:\r\n    f.write(\"data\")\r\n\r\nassert tf.io.gfile.exists(\"ram://test\\\\inner\\\\file.txt\")\r\n\r\n```\r\n", "Perhaps. But those files wouldn't exist since they are saved with `/`. For example:\r\n\r\n```python3\r\ntf.io.gfile.makedirs(\"ram://test/inner\")\r\n\r\nwith tf.io.gfile.GFile(\"ram://test/inner/file.txt\", mode=\"w\") as f:\r\n    f.write(\"data\")  # this is what save model does\r\n\r\nprint(tf.io.gfile.exists(\"ram://test\\\\inner\\\\file.txt\"))\r\n```\r\n\r\nThat is, the files are saved with `/`, but when `walk` calls `os.path.join` they end up with `\\`, so they are different files.", "I see in your old debug print with save `listing (L832) =  ['\\\\assets', '\\\\keras_metadata.pb', '\\\\saved_model.pb', '\\\\variables']`\r\nAs we told above `save` is using the native Os separator at save time right?\r\nhttps://github.com/tensorflow/tensorflow/blob/94f92c9949c2dc6afe1db959e25631520602c6ea/tensorflow/python/keras/saving/saved_model/save.py#L96\r\n", "Maybe? It's very much possible that there is more than one issue at play here. Well, I think it's the same issue, just different places in the codebase that it's occurring. The end result is the same: the `ram://` filesystem (and presumably other non-native filesystems) are not fully functional on Windows.", "Let's wait to understand what the original design scope was. If `ram://` works only with `/` but it isn't enforced or it needs to work on native Sep by design.", "So the original design for the RAM file system is quite limited -- it was originally just for Cloud TPUs to have a place to write temporary files to (since Cloud TPUs don't have access to local file systems and writing to GCS is slow). \r\n\r\nI think if someone wants to get `ram://` working with Windows-style separators etc, we are happy to accept the controbution.", "@adriangb As `test_savedmodel` test was passing on Win and Linux is this enough for your use case at https://github.com/tensorflow/tensorflow/pull/39609#discussion_r600667357?\r\nhttps://github.com/tensorflow/tensorflow/blob/3c16284eb619732b69948f0200ee06c5dd7312d0/tensorflow/core/platform/ram_file_system_test.py#L146-L156", "@bhack that test is not enough for #39609.\r\n\r\nWe need to load all of `ram://my_module,` into a single contagious string of bytes so that it can be serialized. There is no other way to do this other than iterating over each file, which is exactly what `walk` is for. I don't see any way to do this without fixing `walk` or re-implementing it using `listdir`, `isdir`, etc.\r\n\r\n@frankchn so I take it that support (or explicitly not supporting) `\\` for `ram://` on Windows was not part of the original design? Does this mean that if I were to implement fixes that enabled the use case in #39609 but possibly broke other use cases involving `\\` on Windows, that would be okay? Assuming it doesn't break any exisiting tests. I do not have the bandwidth to fully implement support for `ram://test\\other` on Windows (or alternatively explicit lack of support), especially if that includes submitting RFCs or editing source on the C++ side. I may however be able to find a way in which we can edit 1-2 lines of Python to at least make #39609 work.", "@adriangb Can you extend that test or a new one in the same file with a new PR just to cover your case. If I have time to explore a C++ fix I need to use the CI cause Wine is too slow to compile a large source code like TF without an available cache produced in the same environment.", "We have tests in #39609 . Why do we need new tests or a new PR?\r\n\r\nThanks for looking into a fix.", "I meant that we need a new test (with a new PR) in `ram_filesystem_test.py` to test the isolated feature that you need in the ram_file_system.", "I don't think this is necessarily a feature. Depending on whether it was intentional for `\\` to be supported on `ram://` or not (it sounds like it was neither), it is either a design oversight or a bug. Adding a minimal explicit test (i.e. not including savemodel or anything) is likely to (1) force a design decision (2) require multiple PRs/tests since the use of `os.path.join` evidently exists outside of `walk` (eg. in `save` like you point out in  https://github.com/tensorflow/tensorflow/issues/48086#issuecomment-808403294)\r\n\r\nBut let me do a bit of testing to see what needs to be fixed to get #39609 working and go from there. It may be simple or it may indeed require a new feature.", "I think the easiest solution here is to implement a TensorFlow specific `os.path.join`, maybe `tf.io.gfile.join`:\r\n\r\n```python\r\nimport os\r\nfrom posixpath import join as urljoin\r\n\r\ndef join(*paths):\r\n    root = str(paths[0])\r\n    if root.startswith(\"ram://\") or root.startswith(\"gs://\"):\r\n        return urljoin(*paths)\r\n    return os.path.join(*paths)\r\n```\r\n\r\nI'm not sure if `root.startswith(\"ram://\")` is the best we can do here, that will be up to your team to decide.\r\n\r\nThe more difficult part of this will be replacing `os.path.join` with `tf.python.io.file_io.join` all around the codebase.\r\n\r\nThen finally comes the issue of testing, features and backwards compatibility. I suppose this might break things for anyone relying on `ram://test\\other` like behavior on Windows. But since this was never documented (or intentional) I think that should be okay. We can/should add a small test for this, but I think the test should focus on `tf.python.io.file_io.join`, not on the behavior of other things like `walk` or `SavedModel` (i.e. let's not make any promises about those).\r\n\r\nDoes this sound reasonable?", "I don't know if `model.save` it is supported on GCS  see https://github.com/tensorflow/tensorflow/issues/36453. \r\nProbably `tf.saved_model.save` is going to work cause it use c++ impl with `io::JoinPath`.\r\nBut if you still need `model.save` in your case and `model.save` is using os native join at the Python level probably it is easier to let r`ram://` to support Win native separator as `ram://` is currently not opinionated. \r\nLet me know if you have a test for `tensorflow/tensorflow/core/platform/ram_file_system_test.py`\r\n ", "My use cases don't require saving anything to gcs. I only threw `root.startswith(\"gs://\")` in there because I thought you'd want it implemented (and since it's only a couple extra characters).\r\n\r\nI also don't care about `tf.saved_model.save` vs `model.save` vs. any other way to save things using SaveModel, they would all be equally fine for #39609. But I tested `tf.saved_model.save`  and it does not solve the problems surrounding the use of `os.path.join` on `ram://` in Windows. For example, see here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3c16284eb619732b69948f0200ee06c5dd7312d0/tensorflow/python/saved_model/save.py#L878\r\n\r\nThe simplest solution I see here is what I proposed above, implementing a version of `os.path.join` that is aware of using `/` and not `\\` for the `ram://` filesystem on Windows. We can write a test for this and put it wherever you deem best (I would suggest it live with the rest of the tests that correspond to `tf.python.io.file_io` since it is not specific to `ram://`). I tested this solution via monkey patching and indeed it does fix all problems related to #39609 . I have a branch and test for it, I'm waiting for bazel to compile and run tests on my machine to at least make sure they run on linux, but this takes >10 hours on my machine so I probably won't push the branch / make a PR until tomorrow.\r\n\r\nAlternatively, you would have to modify all of the tooling surrounding the `ram://` filesystem to support both `\\` and `/`, eg. I think you'd have to make changes here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3c16284eb619732b69948f0200ee06c5dd7312d0/tensorflow/core/platform/ram_file_system.h#L178", "What I meant is that using  the ticket info and if a test like this will pass also on GCS I suppose that it is not using `os.join` at the python level cause GCS doesn't work with `\\`. \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3c16284eb619732b69948f0200ee06c5dd7312d0/tensorflow/core/platform/ram_file_system_test.py#L146-L156\r\n\r\nAnd probably it is why `model.save` doesn't work also with GCS (I've not tested this case so it is just a reference to the mentioned ticket ticket).\r\n\r\nYour mentioned `os.path.join` is only for the extra debug info case so probably it could now work on GCS but the default value is `save_debug_info=False`.\r\n\r\nI think that we need to separate Walk fix vs if different save methods add os native sep in python.\r\n\r\nMy hypothesis In the case we don't have the os native separator at python level we could make a specific test and fix only the Walk case.\r\n\r\nThis is why I want to have an addition test to fail for `ram_filesystem_test.py`\r\n", "So you want a test that explicitly checks for support of the `ram://folder\\subfolder` pattern? Eg. that `walk` can traverse that correctly.", "I suppose that we could have more candidate workarounds with `ram://folder\\subfolder`, as I don't see a specific `IsDirectory` in `ram_file_system.h` I suppose it rely on Posix and Window fs `isDirectory`.", "I don't see any way to write specific tests for that that don't explicitly suggest support for that pattern.\r\n\r\nThat is why my proposal focuses on the limiting the use of that pattern within the rest of the ecosystem. That way no decision needs to be made on explicit support of that pattern and no fixes need to be applied to existing functionality (which I think would be backwards incompatible).\r\n\r\nIn other words, the behavior is currently undefined. Instead of trying to define it and test for it, I would instead make sure that TensorFlow itself does not create files/folder structures which have undefined behavior.", "> Your mentioned os.path.join is only for the extra debug info case\r\n\r\nI think there may be more:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/b221f78a300a6e50564acfd94dae6b608008474d/tensorflow/python/saved_model/save.py#L1131-L1133", "Check if this test extension is enough for your case https://github.com/tensorflow/tensorflow/pull/48124 \r\nBut it seems to me from the logs that ramfs tests are excluded on Windows CI."]}, {"number": 48084, "title": "Cleanup for more consistent use of c_api_macros.h, throughout tensorflow C APIs.", "body": "Scattering in different tensorflow C API headers, there is really no need for including the following macro definitions, given there is already a dedicated header c_api_macros.h\n\nTherefore the following lines are removed, while c_api_macros.h is added accordingly to the front of each relevant header file.\n\n// Macro to control visibility of exported symbols in the shared library (.so,\n// .dylib, .dll).\n// This duplicates the TF_EXPORT macro definition in\n// tensorflow/core/platform/macros.h in order to keep this .h file independent\n// of any other includes.\n#ifdef SWIG\n#define TF_CAPI_EXPORT\n#else\n#if defined(_WIN32)\n#ifdef TF_COMPILE_LIBRARY\n#define TF_CAPI_EXPORT __declspec(dllexport)\n#else\n#define TF_CAPI_EXPORT __declspec(dllimport)\n#endif  // TF_COMPILE_LIBRARY\n#else\n#define TF_CAPI_EXPORT __attribute__((visibility(\"default\")))\n#endif  // _WIN32\n#endif  // SWIG", "comments": ["@wxinix  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "Apology - I am not very familiar with the Build system, and how to update it for Ubuntu.", "@mihaimaruseac Can you please assist on above comments from @wxinix. Thanks!", "@wxinix  Can you please resolve conflicts? Thanks!", "@mihaimaruseac Can you please review this PR ? Thanks!", "@mihaimaruseac Can you please review this PR ? Thanks!", "@mihaimaruseac Can you please review this PR ? Thank you!", "https://github.com/tensorflow/tensorflow/pull/48084#pullrequestreview-679861204 is still not addressed. Reviewing it now means giving the exact same comment and just wasting time."]}, {"number": 48081, "title": "Performance of NNAPI Delegate on Snapdragon 888", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 7t and Xiaomi Mi 11\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): nightly\r\n- Python version: -\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\n\r\nThe two models attached were created by post-training quantization. I ran them with the android benchmark binary from the tensorflow web page. The results were:\r\n\r\nsample1.tflite on Oneplus 7t (Snapdragon 855+):\r\non CPU, 8 threads: avg 36261 us\r\nwith NNAPI: avg 6734 us\r\n\r\nsample1.tflite on Xiaomi Mi 11 (Snapdragon 888):\r\non CPU, 8 threads: avg 20330 us\r\nwith NNAPI: avg **61303** us\r\n\r\nsample2.tflite on Oneplus 7t (Snapdragon 855+):\r\non CPU, 8 threads: avg 51679 us\r\nwith NNAPI: avg 15921 us\r\n\r\nsample2.tflite on Xiaomi Mi 11 (Snapdragon 888):\r\non CPU, 8 threads: avg 39352 us\r\nwith NNAPI: avg **34375** us\r\n\r\nSo, with NNAPI sample1.tflite is about 9 times faster on the older hardware, sample2.tflite is more than twice as fast on the older hardware. It seems, that there is a performance bug.\r\n\r\n**Describe the expected behavior**\r\nThe models should be faster on the newer hardware.\r\n\r\n**Standalone code to reproduce the issue**\r\nunzip sample1.zip      yields sample1.tflite\r\ncat sample2_part1.zip sample2_part2.zip > s2.zip; unzip s2.zip     yields sample2.tflite\r\nthen run benchmark binary\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n[sample2_part2.zip](https://github.com/tensorflow/tensorflow/files/6207391/sample2_part2.zip)\r\n[sample2_part1.zip](https://github.com/tensorflow/tensorflow/files/6207392/sample2_part1.zip)\r\n[sample1.zip](https://github.com/tensorflow/tensorflow/files/6207393/sample1.zip)\r\n\r\n\r\n", "comments": ["@miaowang14 could you take a look?", "Interesting, @aki65 do you have any logcat that you can share. I suspect that somehow the NNAPI driver on Mi11 is not properly configured.\r\n\r\nCould you also try \"adb shell lshal | grep neural\" and share the output?", "@miaowang14, I attached the logs:\r\nsamples.txt comes from \"adb logcat\" while running first sample1, then sample2. lshal.txt is the output of \"adb shell lshal | grep neural\"\r\n\r\n[lshal.txt](https://github.com/tensorflow/tensorflow/files/6252692/lshal.txt)\r\n[samples.txt](https://github.com/tensorflow/tensorflow/files/6252693/samples.txt)\r\n", "@aki65 , from the logcat, it does show that the model is running on the qti-dsp driver.\r\n\r\nHowever, there are lots of error messages and selinux denial related to the driver, which indicates that there might be something wrong with the driver configuration. I'll forward the issue to our partner at Qualcomm and ask them to take a look.", "Also, if you could get root permission through \"adb root\", could you try \"adb shell setenforce 0\" to set SELinux to permissive mode and see if the performance get back to normal?", "@miaowang14, I don't have root access, so I can't try permissive mode.", "@miaowang14, what did your partner at Qualcomm say about this ?", "@aki Can you share some knowledge on how to make use of the snapdragon hexagon dsp ? The hexagon delegate 1.21 does not seem to support the snapdragon 888. Do you use nnapi ?", "Yes, I use NNAPI, but as you can judge from this issue, it wasn't a roaring success either.\r\n\r\nStandard INT8 models (like the ones used in AI benchmark) are handled quite well by NNAPI. The benchmark results are fine and I can reproduce them on my Mi 11. So it's extremely unlikely, that the terrible performance in this issue is caused by a wrong SELinux configuration.\r\nInstead, it seems that the type of models, which is created by tensorflow's post-training quantization, is not handled well by Qualcomm's NNAPI driver. This makes tensorflow lite pretty useless on android. Nonetheless, judging from the responses to this issue, nobody at google cares ...", "@aki65 sorry for replying late as I haven't got a concrete answer from our partners at Qualcomm.\r\n\r\nOne of the potential reason is that Mi11 was the first device with SnapDragon888, and used early versions of the NNAPI driver. I'll update here once I hear more. ", "Hello @aki65 ,\r\nIs there any update on this issue? Are we able to run tflite models faster on SD 888 DSP?", "On my Mi11, I'm still stuck with the driver version from my first post, so nothing has changed there. But Qualcomm has published several driver updates since then, so one of them may have resolved the issue. But as Xiaomi never integrated them, I can't tell ...", "I have the same issue. I have been trying to run few quantized models on a Motorola moto G200 and a One Plus 9 pro and the model is very slow on both phones. I guess I cannot really use the DSP of the phones."]}, {"number": 48058, "title": "Resource lookup errors when using shared libraries", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): bug occurs with both\r\n- TensorFlow version (use command below): 2.3.2 CPU\r\n- Python version: 3.10\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nUsing the C API (`libtensorflow.so` and `libtensorflow_framework.so`) in conjunction with tensorflow-text (or any library loading custom ops) throws errors like:\r\n`Invalid argument: Trying to access resource using the wrong type. Expected N10tensorflow6lookup15LookupInterfaceE got N10tensorflow6lookup15LookupInterfaceE`\r\nThis is caused by the same bug as issue #44209.  In `tensorflow/core/framework/type_index.h`, the address of a static variable is used as a hash, leading to a false mismatch when called from a shared library.  That poster suggested that the bug did not occur on Linux because of the GNU unique symbol extension.  In my case, it still happens even on Linux.\r\n\r\nLooking at the shared libraries, I think I can see why:\r\n```\r\n$ nm -C /usr/local/lib/libtensorflow.so | grep LookupInterface.*hash_bit\r\n0000000008e091ac b tensorflow::TypeIndex::Make<tensorflow::lookup::LookupInterface>()::hash_bit\r\n                 ^ BSS symbol\r\n\r\n$ nm -C /usr/local/lib/libtensorflow_framework.so | grep LookupInterface.*hash_bit\r\n0000000001c656ec u tensorflow::TypeIndex::Make<tensorflow::lookup::LookupInterface>()::hash_bit\r\n                 ^ UNIQUE symbol\r\n```\r\nIn libtensorflow_framework.so, the hash_bit is a unique symbol, but in libtensorflow.so, it is not.  I wondered why this problem was not happening when running Tensorflow from Python, so I checked the Python shared library:\r\n```\r\n$ nm -C ./_pywrap_tensorflow_internal.so | grep LookupInterface.*hash_bit\r\n000000001de2842c u tensorflow::TypeIndex::Make<tensorflow::lookup::LookupInterface>()::hash_bit\r\n                 ^ UNIQUE symbol\r\n```\r\nSure enough, unique symbol.  So the question is why does libtensorflow.so get this symbol in BSS when every other library has it as unique?  I don't know enough about Bazel to inspect how these libraries are being linked, so I'm hoping someone here can help.\r\n\r\n\r\n**Describe the expected behavior**\r\nThis error should not be thrown.\r\n", "comments": ["I was able to hack my way around this by taking the fix in `tensorflow/core/framework/type_index.h` that was done for MacOS and removing the `#ifdef` guard (enabling it on all platforms), then rebuilding the library with `bazel build --config=opt --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 tensorflow:libtensorflow.so`.  But this kind of hack really shouldn't be necessary.", "@bplevin36,\r\nTensorFlow v2.3 is not compatible with Python 3.10. Please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#cpu) for more information. \r\n\r\nVersion | Python version | Compiler | Build tools\r\n-- | -- | -- | --\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0\r\ntensorflow-2.2.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 2.0.0\r\n\r\nCould you please check if you are facing the same issue with Python 3.8 as well? Thanks!", "@amahendrakar Thanks for the quick response.  I included my Python version just in case Python was somehow being used by the build process, but my actual program is written in Rust and includes **no** Python.  It only uses the shared libraries.", "@amahendrakar  Just in case, I reran the entire process using Python 3.8, but the issue remains.", "@bplevin36 @jvishnuvardhan, I've run into this issue with TensorFlow 2.4. Is this fixed in later versions?", "For me this is fixed in TF 2.6 via this PR https://github.com/tensorflow/tensorflow/pull/47072"]}, {"number": 48057, "title": "Crash when using tf.nn.local_response_normalization across multiple GPUs", "body": "Model using `tf.nn.local_response_normalization` trains OK but crashes upon evaluation when parallelizing over multiple GPUs. Same model does not crash when running on a single GPU. \r\n\r\nReplacing `tf.nn.local_response_normalization` with `keras.layers.BatchNormalization` model trains OK and evaluates OK on single or multiple GPUs. So it seems to me the problem is with `tf.nn.local_response_normalization` over multiple GPUs.\r\n\r\nNumber of GPUs allocated via Slurm, _e.g._,\r\n\r\n    #SBATCH --nodes=1\r\n    #SBATCH --ntasks=2\r\n    #SBATCH --gres=gpu:2    << Here I allocate 2 GPUs\r\n    #SBATCH --mem=16G\r\n\r\n**System information**\r\n\r\n* Red Hat Enterprise Linux Server 7.6 (Maipo)\r\n* Slurm 19.05.4\r\n* TensorFlow 2.4.1, installed via Conda\r\n* Python 3.7.10\r\n* Cuda compilation tools, release 10.1, V10.1.168\r\n* Multiple NVIDIA Tesla V100 with 32GB RAM\r\n\r\n**Describe the current behavior**\r\n\r\nWhen training on two GPUs, code below trains OK, but crashes when evaluating and dumps core. \r\n\r\n`50/51 [============================>.] - ETA: 0s - loss: 1.6090 - accuracy: 0.21062021-03-24 17:11:41.834444: F tensorflow/stream_executor/cuda/cuda_dnn.cc:535] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 0 feature_map_count: 1 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}` Aborting (core dumped)\r\n\r\nIf I train on only one GPU, code below trains OK and evaluates OK.\r\n\r\n**Describe the expected behavior**\r\n\r\nTrains and evaluates OK on two GPUs.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n    def create_model():\r\n        inputs = keras.Input(shape=(224, 224, 3))\r\n        x = tf.cast(inputs, tf.float32)\r\n        x = keras.layers.Conv2D(1, (2, 2), strides=(1, 1), padding='same')(x)\r\n        x = keras.layers.Lambda(tf.nn.local_response_normalization)(x)\r\n        # if I use x = keras.layers.BatchNormalization()(x) then OK\r\n        x = keras.layers.Activation('relu')(x)\r\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n        x = tf.keras.layers.Dense(5, activation='softmax')(x)\r\n        return keras.Model(inputs=inputs, outputs=x, name=\"toy\")\r\n    \r\n    if __name__ == '__main__':\r\n        training_data, validation_data, testing_data = \\\r\n            load_img_datasets(\"path/to/data\", (224, 224))\r\n        # These ^ are tensorflow.python.data.ops.dataset_ops.BatchDataset\r\n    \r\n        strategy = tf.distribute.MirroredStrategy()\r\n        with strategy.scope():\r\n            model = create_model()\r\n            optimizer = tf.keras.optimizers.Adam()\r\n            metrics = ['accuracy']\r\n            model.compile(loss='categorical_crossentropy',\r\n                          optimizer=optimizer,\r\n                          metrics=metrics)\r\n    \r\n        history = model.fit(training_data, epochs=1,\r\n                            validation_data=validation_data)\r\n    \r\n        loss, accuracy = model.evaluate(testing_data)\r\n        # Crashes here ^", "comments": ["@cbcafiero the standalone reproducer you shared above is not complete (`load_img_datasets` is not defined, for instance, and I also don't know what to put in `path/to/data`).\r\n\r\nCan you share an isolated reproducer that I can run as `python reproducer.py` on TF nightly?\r\n\r\nThanks!", "@sanjoy Here is complete code, per your request\r\n\r\n```\r\n\"\"\"\r\nReproducer for #48057\r\n\r\nRun on single GPU OK. Run on two GPUs and it fails during evaluation.\r\n\"\"\"\r\nimport os\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\r\n\r\n\r\nINPUT_SHAPE = (224, 224, 3)\r\nIMAGE_SIZE = (224, 224)\r\nNUM_CLASSES = 5\r\nEPOCHS = 1\r\n\r\n\r\ndef load_img_datasets(folder, image_size, batch_size=32):\r\n    training_dataset = image_dataset_from_directory(os.path.join(folder,\r\n                                                                 \"train\"),\r\n                                                    labels=\"inferred\",\r\n                                                    label_mode=\"categorical\",\r\n                                                    batch_size=batch_size,\r\n                                                    image_size=image_size)\r\n    validation_dataset = image_dataset_from_directory(os.path.join(folder,\r\n                                                                   \"val\"),\r\n                                                      labels=\"inferred\",\r\n                                                      label_mode=\"categorical\",\r\n                                                      batch_size=batch_size,\r\n                                                      image_size=image_size)\r\n    testing_dataset = image_dataset_from_directory(os.path.join(folder,\r\n                                                                \"test\"),\r\n                                                   labels=\"inferred\",\r\n                                                   label_mode=\"categorical\",\r\n                                                   batch_size=batch_size,\r\n                                                   image_size=image_size)\r\n    return training_dataset, validation_dataset, testing_dataset\r\n\r\n\r\ndef create_model():\r\n    inputs = keras.Input(shape=INPUT_SHAPE)\r\n    x = tf.cast(inputs, tf.float32)\r\n    x = keras.layers.Conv2D(1, (2, 2), strides=(1, 1), padding='same')(x)\r\n    x = keras.layers.Lambda(tf.nn.local_response_normalization)(x)\r\n    # if I use x = keras.layers.BatchNormalization()(x) then OK\r\n    x = keras.layers.Activation('relu')(x)\r\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n    x = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\r\n    return keras.Model(inputs=inputs, outputs=x, name=\"toy\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    training_data, validation_data, testing_data = \\\r\n        load_img_datasets(\"./data/lms/224_split\", IMAGE_SIZE)\r\n    # These ^ are tensorflow.python.data.ops.dataset_ops.BatchDataset\r\n\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    with strategy.scope():\r\n        model = create_model()\r\n        optimizer = tf.keras.optimizers.Adam()\r\n        metrics = ['accuracy']\r\n        model.compile(loss='categorical_crossentropy',\r\n                      optimizer=optimizer,\r\n                      metrics=metrics)\r\n\r\n    history = model.fit(training_data, epochs=EPOCHS,\r\n                        validation_data=validation_data)\r\n\r\n    loss, accuracy = model.evaluate(testing_data)\r\n    # Crashes here ^\r\n\r\n```\r\n\r\nHere is complete output of running this code on two GPUs:\r\n\r\n```\r\n2021-03-26 08:12:43.428933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-26 08:13:18.222153: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-26 08:13:18.225390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-26 08:13:18.387123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:1f:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-26 08:13:18.390933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:20:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-26 08:13:18.390999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-26 08:13:20.903702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-03-26 08:13:20.903856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-03-26 08:13:22.376347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-03-26 08:13:22.511851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-03-26 08:13:24.241047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-03-26 08:13:24.628874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-03-26 08:13:28.805616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-03-26 08:13:28.820219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\r\n2021-03-26 08:13:28.822806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-26 08:13:29.263198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:1f:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-26 08:13:29.266252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:20:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-26 08:13:29.266293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-26 08:13:29.266329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-03-26 08:13:29.266350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-03-26 08:13:29.266370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-03-26 08:13:29.266390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-03-26 08:13:29.266410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-03-26 08:13:29.266430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-03-26 08:13:29.266451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-03-26 08:13:29.278173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\r\n2021-03-26 08:13:29.308911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-26 08:13:36.871739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-03-26 08:13:36.871863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \r\n2021-03-26 08:13:36.871939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \r\n2021-03-26 08:13:36.871954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \r\n2021-03-26 08:13:36.904481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30094 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1f:00.0, compute capability: 7.0)\r\n2021-03-26 08:13:36.917187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30094 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:20:00.0, compute capability: 7.0)\r\n2021-03-26 08:13:36.917617: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-26 08:13:38.723354: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\r\nop: \"TensorSliceDataset\"\r\ninput: \"Placeholder/_0\"\r\nattr {\r\n  key: \"Toutput_types\"\r\n  value {\r\n    list {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n2021-03-26 08:13:38.889650: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-03-26 08:13:38.891294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\r\n2021-03-26 08:13:40.565241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-03-26 08:13:52.741637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\nFound 5119 files belonging to 5 classes.\r\nFound 1279 files belonging to 5 classes.\r\nFound 1601 files belonging to 5 classes.\r\n\r\n  1/160 [..............................] - ETA: 2:02:42 - loss: 1.6098 - accuracy: 0.0938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  2/160 [..............................] - ETA: 1:06 - loss: 1.6096 - accuracy: 0.1094   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  3/160 [..............................] - ETA: 53s - loss: 1.6095 - accuracy: 0.1181 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  4/160 [..............................] - ETA: 47s - loss: 1.6094 - accuracy: 0.1374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  5/160 [..............................] - ETA: 44s - loss: 1.6094 - accuracy: 0.1499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  6/160 [>.............................] - ETA: 46s - loss: 1.6093 - accuracy: 0.1631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  7/160 [>.............................] - ETA: 43s - loss: 1.6092 - accuracy: 0.1711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  8/160 [>.............................] - ETA: 42s - loss: 1.6092 - accuracy: 0.1780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n  9/160 [>.............................] - ETA: 42s - loss: 1.6092 - accuracy: 0.1829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 10/160 [>.............................] - ETA: 41s - loss: 1.6091 - accuracy: 0.1862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 11/160 [=>............................] - ETA: 41s - loss: 1.6091 - accuracy: 0.1884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 12/160 [=>............................] - ETA: 40s - loss: 1.6091 - accuracy: 0.1909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 13/160 [=>............................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 14/160 [=>............................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1954\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 15/160 [=>............................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 16/160 [==>...........................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1979\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 17/160 [==>...........................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 18/160 [==>...........................] - ETA: 40s - loss: 1.6090 - accuracy: 0.1995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 19/160 [==>...........................] - ETA: 39s - loss: 1.6090 - accuracy: 0.2004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 20/160 [==>...........................] - ETA: 39s - loss: 1.6090 - accuracy: 0.2012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 21/160 [==>...........................] - ETA: 38s - loss: 1.6090 - accuracy: 0.2020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 22/160 [===>..........................] - ETA: 38s - loss: 1.6090 - accuracy: 0.2027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 23/160 [===>..........................] - ETA: 38s - loss: 1.6090 - accuracy: 0.2034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 24/160 [===>..........................] - ETA: 37s - loss: 1.6090 - accuracy: 0.2041\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 25/160 [===>..........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 26/160 [===>..........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2049\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 27/160 [====>.........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 28/160 [====>.........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 29/160 [====>.........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 30/160 [====>.........................] - ETA: 37s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 31/160 [====>.........................] - ETA: 37s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 32/160 [=====>........................] - ETA: 37s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 33/160 [=====>........................] - ETA: 37s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 34/160 [=====>........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 35/160 [=====>........................] - ETA: 36s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 36/160 [=====>........................] - ETA: 35s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 37/160 [=====>........................] - ETA: 35s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 38/160 [======>.......................] - ETA: 35s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 39/160 [======>.......................] - ETA: 34s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 40/160 [======>.......................] - ETA: 35s - loss: 1.6090 - accuracy: 0.2053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 41/160 [======>.......................] - ETA: 35s - loss: 1.6090 - accuracy: 0.2053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 42/160 [======>.......................] - ETA: 34s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 43/160 [=======>......................] - ETA: 34s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 44/160 [=======>......................] - ETA: 33s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 45/160 [=======>......................] - ETA: 33s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 46/160 [=======>......................] - ETA: 32s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 47/160 [=======>......................] - ETA: 32s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 48/160 [========>.....................] - ETA: 32s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 49/160 [========>.....................] - ETA: 31s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 50/160 [========>.....................] - ETA: 31s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 51/160 [========>.....................] - ETA: 30s - loss: 1.6090 - accuracy: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 52/160 [========>.....................] - ETA: 30s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 53/160 [========>.....................] - ETA: 30s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 54/160 [=========>....................] - ETA: 30s - loss: 1.6090 - accuracy: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 55/160 [=========>....................] - ETA: 30s - loss: 1.6090 - accuracy: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 56/160 [=========>....................] - ETA: 29s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 57/160 [=========>....................] - ETA: 29s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 58/160 [=========>....................] - ETA: 29s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 59/160 [==========>...................] - ETA: 28s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 60/160 [==========>...................] - ETA: 28s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 61/160 [==========>...................] - ETA: 28s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 62/160 [==========>...................] - ETA: 27s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 63/160 [==========>...................] - ETA: 27s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 64/160 [===========>..................] - ETA: 27s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 65/160 [===========>..................] - ETA: 26s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 66/160 [===========>..................] - ETA: 26s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 67/160 [===========>..................] - ETA: 26s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 68/160 [===========>..................] - ETA: 25s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 69/160 [===========>..................] - ETA: 25s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 70/160 [============>.................] - ETA: 25s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 71/160 [============>.................] - ETA: 24s - loss: 1.6090 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 72/160 [============>.................] - ETA: 24s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 73/160 [============>.................] - ETA: 24s - loss: 1.6090 - accuracy: 0.2055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 74/160 [============>.................] - ETA: 23s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 75/160 [=============>................] - ETA: 23s - loss: 1.6090 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 76/160 [=============>................] - ETA: 23s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 77/160 [=============>................] - ETA: 22s - loss: 1.6090 - accuracy: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 78/160 [=============>................] - ETA: 22s - loss: 1.6090 - accuracy: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 79/160 [=============>................] - ETA: 22s - loss: 1.6090 - accuracy: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 80/160 [==============>...............] - ETA: 22s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 81/160 [==============>...............] - ETA: 21s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 82/160 [==============>...............] - ETA: 21s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 83/160 [==============>...............] - ETA: 21s - loss: 1.6090 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 84/160 [==============>...............] - ETA: 20s - loss: 1.6090 - accuracy: 0.2060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 85/160 [==============>...............] - ETA: 20s - loss: 1.6090 - accuracy: 0.2060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 86/160 [===============>..............] - ETA: 20s - loss: 1.6090 - accuracy: 0.2060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 87/160 [===============>..............] - ETA: 20s - loss: 1.6090 - accuracy: 0.2061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 88/160 [===============>..............] - ETA: 19s - loss: 1.6090 - accuracy: 0.2061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 89/160 [===============>..............] - ETA: 19s - loss: 1.6090 - accuracy: 0.2062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 90/160 [===============>..............] - ETA: 19s - loss: 1.6090 - accuracy: 0.2062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 91/160 [================>.............] - ETA: 19s - loss: 1.6090 - accuracy: 0.2063\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 92/160 [================>.............] - ETA: 18s - loss: 1.6090 - accuracy: 0.2063\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 93/160 [================>.............] - ETA: 18s - loss: 1.6090 - accuracy: 0.2064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 94/160 [================>.............] - ETA: 18s - loss: 1.6090 - accuracy: 0.2064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 95/160 [================>.............] - ETA: 17s - loss: 1.6090 - accuracy: 0.2065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 96/160 [=================>............] - ETA: 17s - loss: 1.6090 - accuracy: 0.2066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 97/160 [=================>............] - ETA: 17s - loss: 1.6090 - accuracy: 0.2067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 98/160 [=================>............] - ETA: 17s - loss: 1.6090 - accuracy: 0.2068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 99/160 [=================>............] - ETA: 16s - loss: 1.6090 - accuracy: 0.2069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n100/160 [=================>............] - ETA: 16s - loss: 1.6090 - accuracy: 0.2070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n101/160 [=================>............] - ETA: 16s - loss: 1.6090 - accuracy: 0.2071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n102/160 [==================>...........] - ETA: 16s - loss: 1.6090 - accuracy: 0.2072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n103/160 [==================>...........] - ETA: 15s - loss: 1.6090 - accuracy: 0.2072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n104/160 [==================>...........] - ETA: 15s - loss: 1.6090 - accuracy: 0.2073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n105/160 [==================>...........] - ETA: 15s - loss: 1.6090 - accuracy: 0.2074\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n106/160 [==================>...........] - ETA: 14s - loss: 1.6090 - accuracy: 0.2075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n107/160 [===================>..........] - ETA: 14s - loss: 1.6090 - accuracy: 0.2076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n108/160 [===================>..........] - ETA: 14s - loss: 1.6090 - accuracy: 0.2076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n109/160 [===================>..........] - ETA: 14s - loss: 1.6090 - accuracy: 0.2077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n110/160 [===================>..........] - ETA: 13s - loss: 1.6090 - accuracy: 0.2078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n111/160 [===================>..........] - ETA: 13s - loss: 1.6090 - accuracy: 0.2078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n112/160 [====================>.........] - ETA: 13s - loss: 1.6090 - accuracy: 0.2079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n113/160 [====================>.........] - ETA: 13s - loss: 1.6090 - accuracy: 0.2079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n114/160 [====================>.........] - ETA: 12s - loss: 1.6090 - accuracy: 0.2080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n115/160 [====================>.........] - ETA: 12s - loss: 1.6090 - accuracy: 0.2080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n116/160 [====================>.........] - ETA: 12s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n117/160 [====================>.........] - ETA: 12s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n118/160 [=====================>........] - ETA: 11s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n119/160 [=====================>........] - ETA: 11s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n120/160 [=====================>........] - ETA: 11s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n121/160 [=====================>........] - ETA: 10s - loss: 1.6090 - accuracy: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n122/160 [=====================>........] - ETA: 10s - loss: 1.6090 - accuracy: 0.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n123/160 [======================>.......] - ETA: 10s - loss: 1.6090 - accuracy: 0.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n124/160 [======================>.......] - ETA: 10s - loss: 1.6090 - accuracy: 0.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n125/160 [======================>.......] - ETA: 9s - loss: 1.6090 - accuracy: 0.2082 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n126/160 [======================>.......] - ETA: 9s - loss: 1.6090 - accuracy: 0.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n127/160 [======================>.......] - ETA: 9s - loss: 1.6090 - accuracy: 0.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n128/160 [=======================>......] - ETA: 8s - loss: 1.6090 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n129/160 [=======================>......] - ETA: 8s - loss: 1.6090 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n130/160 [=======================>......] - ETA: 8s - loss: 1.6090 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n131/160 [=======================>......] - ETA: 8s - loss: 1.6090 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n132/160 [=======================>......] - ETA: 7s - loss: 1.6090 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n133/160 [=======================>......] - ETA: 7s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n134/160 [========================>.....] - ETA: 7s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n135/160 [========================>.....] - ETA: 7s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n136/160 [========================>.....] - ETA: 6s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n137/160 [========================>.....] - ETA: 6s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n138/160 [========================>.....] - ETA: 6s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n139/160 [=========================>....] - ETA: 5s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n140/160 [=========================>....] - ETA: 5s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n141/160 [=========================>....] - ETA: 5s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n142/160 [=========================>....] - ETA: 5s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n143/160 [=========================>....] - ETA: 4s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n144/160 [==========================>...] - ETA: 4s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n145/160 [==========================>...] - ETA: 4s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n146/160 [==========================>...] - ETA: 3s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n147/160 [==========================>...] - ETA: 3s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n148/160 [==========================>...] - ETA: 3s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n149/160 [==========================>...] - ETA: 3s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n150/160 [===========================>..] - ETA: 2s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n151/160 [===========================>..] - ETA: 2s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n152/160 [===========================>..] - ETA: 2s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n154/160 [===========================>..] - ETA: 1s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n156/160 [============================>.] - ETA: 1s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n158/160 [============================>.] - ETA: 0s - loss: 1.6090 - accuracy: 0.2084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n160/160 [==============================] - ETA: 0s - loss: 1.6090 - accuracy: 0.20832021-03-26 08:15:09.631418: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\r\nop: \"TensorSliceDataset\"\r\ninput: \"Placeholder/_0\"\r\nattr {\r\n  key: \"Toutput_types\"\r\n  value {\r\n    list {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n160/160 [==============================] - 103s 354ms/step - loss: 1.6090 - accuracy: 0.2083 - val_loss: 1.6086 - val_accuracy: 0.1986\r\n2021-03-26 08:15:21.762829: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\r\nop: \"TensorSliceDataset\"\r\ninput: \"Placeholder/_0\"\r\nattr {\r\n  key: \"Toutput_types\"\r\n  value {\r\n    list {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n\r\n 1/51 [..............................] - ETA: 2:12 - loss: 1.6083 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 2/51 [>.............................] - ETA: 11s - loss: 1.6084 - accuracy: 0.2500 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 3/51 [>.............................] - ETA: 10s - loss: 1.6087 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 4/51 [=>............................] - ETA: 11s - loss: 1.6088 - accuracy: 0.1797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 5/51 [=>............................] - ETA: 11s - loss: 1.6086 - accuracy: 0.2000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 6/51 [==>...........................] - ETA: 10s - loss: 1.6083 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 7/51 [===>..........................] - ETA: 10s - loss: 1.6082 - accuracy: 0.2143\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 8/51 [===>..........................] - ETA: 10s - loss: 1.6084 - accuracy: 0.2227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n 9/51 [====>.........................] - ETA: 10s - loss: 1.6084 - accuracy: 0.2153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n10/51 [====>.........................] - ETA: 10s - loss: 1.6086 - accuracy: 0.2094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n11/51 [=====>........................] - ETA: 9s - loss: 1.6085 - accuracy: 0.2188 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n12/51 [======>.......................] - ETA: 9s - loss: 1.6085 - accuracy: 0.2135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n13/51 [======>.......................] - ETA: 9s - loss: 1.6085 - accuracy: 0.2091\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n14/51 [=======>......................] - ETA: 8s - loss: 1.6086 - accuracy: 0.2054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n15/51 [=======>......................] - ETA: 8s - loss: 1.6085 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n16/51 [========>.....................] - ETA: 8s - loss: 1.6085 - accuracy: 0.2070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n17/51 [=========>....................] - ETA: 8s - loss: 1.6085 - accuracy: 0.2077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n18/51 [=========>....................] - ETA: 8s - loss: 1.6085 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n19/51 [==========>...................] - ETA: 8s - loss: 1.6085 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n20/51 [==========>...................] - ETA: 7s - loss: 1.6086 - accuracy: 0.2031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n21/51 [===========>..................] - ETA: 7s - loss: 1.6086 - accuracy: 0.2009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n22/51 [===========>..................] - ETA: 7s - loss: 1.6086 - accuracy: 0.2045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n23/51 [============>.................] - ETA: 6s - loss: 1.6086 - accuracy: 0.2052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n24/51 [=============>................] - ETA: 6s - loss: 1.6086 - accuracy: 0.2005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n25/51 [=============>................] - ETA: 6s - loss: 1.6086 - accuracy: 0.1975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n26/51 [==============>...............] - ETA: 6s - loss: 1.6086 - accuracy: 0.1983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n27/51 [==============>...............] - ETA: 6s - loss: 1.6085 - accuracy: 0.2014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n28/51 [===============>..............] - ETA: 6s - loss: 1.6085 - accuracy: 0.2020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n29/51 [================>.............] - ETA: 5s - loss: 1.6085 - accuracy: 0.2047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n30/51 [================>.............] - ETA: 5s - loss: 1.6085 - accuracy: 0.2094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n31/51 [=================>............] - ETA: 5s - loss: 1.6084 - accuracy: 0.2137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n32/51 [=================>............] - ETA: 4s - loss: 1.6084 - accuracy: 0.2119\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n33/51 [==================>...........] - ETA: 4s - loss: 1.6085 - accuracy: 0.2083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n34/51 [===================>..........] - ETA: 4s - loss: 1.6085 - accuracy: 0.2068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n35/51 [===================>..........] - ETA: 4s - loss: 1.6086 - accuracy: 0.2045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n36/51 [====================>.........] - ETA: 3s - loss: 1.6086 - accuracy: 0.2101\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n37/51 [====================>.........] - ETA: 3s - loss: 1.6086 - accuracy: 0.2086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n38/51 [=====================>........] - ETA: 3s - loss: 1.6086 - accuracy: 0.2056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n39/51 [=====================>........] - ETA: 3s - loss: 1.6086 - accuracy: 0.2027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n40/51 [======================>.......] - ETA: 2s - loss: 1.6086 - accuracy: 0.2008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n41/51 [=======================>......] - ETA: 2s - loss: 1.6086 - accuracy: 0.2020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n42/51 [=======================>......] - ETA: 2s - loss: 1.6086 - accuracy: 0.1994\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n44/51 [========================>.....] - ETA: 1s - loss: 1.6086 - accuracy: 0.1989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n46/51 [==========================>...] - ETA: 1s - loss: 1.6086 - accuracy: 0.2038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n49/51 [===========================>..] - ETA: 0s - loss: 1.6086 - accuracy: 0.20342021-03-26 08:15:35.239305: F tensorflow/stream_executor/cuda/cuda_dnn.cc:535] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 0 feature_map_count: 1 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}\r\n/var/spool/slurm/d/job226970/slurm_script: line 24: 379912 Aborted                 (core dumped) python reproducer.py\r\n\r\nreal\t3m10.859s\r\nuser\t0m50.679s\r\nsys\t0m21.118s\r\n```\r\n\r\nMy data are in directories (relative to `reproducer.py`):\r\n\r\n```\r\ndata\r\n    |- lms\r\n         |- 224_split\r\n               |- train\r\n                     |- class1\r\n                     |- class2\r\n                     ...\r\n               |- val\r\n                     |- class1\r\n                     |- class2\r\n                     ...\r\n               |- test\r\n                     |- class1\r\n                     |- class2\r\n                     ...\r\n```\r\n\r\nI can make these data available to you if it's necessary, but I think any set of PNGs that are 224x224 should suffice. Please let me know how you'd like to proceed on this point. Sample image attached.\r\n\r\nThanks very much!\r\n\r\n![0a8c3cebe61137a6e8c7cf0a3d827046](https://user-images.githubusercontent.com/421699/112631214-f8366c00-8e0c-11eb-868c-3c6047693698.png)\r\n", "Any news?", "> I can make these data available to you if it's necessary, but I think any set of PNGs that are 224x224 should suffice. Please let me know how you'd like to proceed on this point.\r\n\r\nIt would be ideal if you could stub out the dataset using random tensors or shared some sample data here on this issue.\r\n\r\nCan you also please gather & share the cuDNN API log from a failing run? Instructions [here](https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html#api-logging)."]}, {"number": 48056, "title": "[INTEL MKL] - Adding 'oneDNN' partials and Dockerfiles for 'RedHat 8'", "body": "\r\nThis PR introduces:\r\n\r\n- Partials and Dockerfiles for oneDNN based on `RedHat 8` \r\n- Misc updates for existing oneDNN partials\r\n\r\nLike before this is how you generate the new Docker files and build the images:\r\n\r\n```bash\r\n$ export DOCKER_BUILD_ARGS=<extra docker build args specific to your environment, like proxies>\r\n$ alias db=\"docker build ${DOCKER_BUILD_ARGS}\"\r\n$ export DOCKER_RUN_ENVS=\"extra docker run environment variables specific to your environment, like proxies\"\r\n$ alias dr=\"docker run --disable-content-trust ${DOCKER_RUN_ENVS}\"\r\n```\r\n\r\nFinally start building containers:\r\n\r\n```bash\r\n$ cd tensorflow/tools/dockerfiles\r\n$ db -t tf-tools -f tools.Dockerfile .\r\n\r\n$ alias asm_dockerfiles=\"dr --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py \"\r\n$ alias asm_images=\"dr --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py \"\r\n$ asm_dockerfiles --release dockerfiles --construct_dockerfiles\r\n\r\n$ TF_VERSION=2.4.0 HOROVOD_VERSION=v0.21.1 && \\\r\n    asm_images ${PARTIALS_BUILD_ARGS} \\\r\n    --release onednn \\\r\n    --repository intel/intel-optimized-tensorflow \\\r\n    --arg BAZEL_VERSION=3.1.0 \\\r\n    --arg TF_BRANCH=v${TF_VERSION} \\\r\n    --arg TF_PACKAGE_VERSION=${TF_VERSION} \\\r\n    --arg _TAG_PREFIX=${TF_VERSION} \\\r\n    --arg REDHAT_VERSION=latest \\\r\n    --arg --network=host \\\r\n    --only_tags_matching '.*redhat-8' \\\r\n    -build_images\r\n```\r\n\r\nand this will produce the following images:\r\n```bash\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-devel-mpi-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-redhat-8-mpi-horovod-jupyter\r\n```\r\n", "comments": ["@sub-mod Can you take a look at this?", "@angerson would you also review and provide us with feedback?\r\n\r\nThanks.", "> @sub-mod Can you take a look at this?\r\n\r\ntaking a look", "Hi @sub-mod were you able to review this? Any feedback for me?\r\n\r\nThanks.", "@sub-mod  Any update on this PR? Please. Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!\r\n", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thanks!", "@angerson /@penpornk Can you please review this PR ? Thank you!"]}, {"number": 48051, "title": "[GO] Memory leak when loading in a string source in encodeTensorWithSlices", "body": "I noticed my GO application memory usage was growing very quickly when I was feeding in tensor with my webcam's data. In a couple of minutes my app grows about a few gigs per minute and my system started to swap memory.Finally the application terminated with OOM.\r\n\r\nI could narrow down the origin of the memory leak to:\r\n```go\r\ntensor, err := tf.NewTensor(string(img))\r\n```\r\n\r\nThe problem is not on the GO side but in the C++ side where a string buffer is created and not released from memory.\r\n\r\nIn the specific function `encodeTensorWithSlices`. There is a TF_TString being allocated and initialized. But is never deallocated. I created a new macro for it to deallocate when the used buffer is finalized/garbage collected.\r\n\r\nI'm not 100% confident that this is the right object to register the finalizer on. If someone could check and explain to me if this is correct.\r\n\r\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48051) for more info**.\n\n<!-- need_author_cla -->", "A finalizer for strings is already set on lines 101-107.  Can you provide a working example where that finalizer isn't being called to clear out a string Tensor?", "@michaelboke  Can you please check @gharibian's comments and keep us posted ? Thanks!", "@gharibian I don't think that finalizer on line 101-107 is finalizing the temporary C.TF_TString on line 503.\r\nBecause the contents of that string are later being copied to the buffer on line 509. That newly allocated TF_TString on line 503 is nowhere finalized. That is why I created a finalizer for that. \r\n\r\nWhat do you think?... ", "@gharibian  Can you please assist on above comments from @michaelboke. Thanks!", "@gharibian Any update on this PR? Please. Thanks!", "@michaelboke Can you please fix build failures ? Thanks!", "@michaelboke Any update on this PR? Please. Thanks!", "@gbaned I wish I could help, but looking at the failed test results. I could only say something went wrong during downloading\r\n\r\n```\r\nERROR: An error occurred during the fetch of repository 'local_config_rocm':\r\n```\r\n\r\nThe other artifacts give similar result or give a 404 error. So no i cannot find any thing related with the few go lines i changed would couse these errors. Also it has been a while now since i put this PR here. Maybe a rebase from master will solve it. Otherwise... this pr is lost", "I believe this was fixed by #49925", "@michaelboke Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!\r\n", "@michaelboke Any update on this PR? Please. Thanks!", "@michaelboke Any update on this PR? Please. Thanks!", "@michaelboke Any update on this PR? Please. Thanks!", "@michaelboke Any update on this PR? Please. Thanks!"]}, {"number": 48043, "title": "Accuracy of resnet50/vgg16 after tfmot.quantization.keras.quantize_model is really low", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): v2.4\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAccuracy of resnet50/vgg16 after tfmot.quantization.keras.quantize_model is really low\r\nI tested them with imagenet2012_subset validation portion. For resnet50, the pretrained model imported from keras.applications has top-1 accuracy: 70% before quantization and 0.1% after quantization. \r\n\r\n**Describe the expected behavior**\r\n\r\nI expected the accuracy drop only slightly.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1nSG7fqYidwBSbeMTyDEQ_Sr6NATov2ik?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@fredrec could you take a look?", "Any updates on this? Thanks! @abattery @fredrec ", "Any updates on this? Thanks! @abattery @fredrec", "Was able to replicate the issue in TF 2.6.0-dev20210603,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/5e81214099271eaefd68d5d513b21ff0/untitled217.ipynb#scrollTo=aniwPbuVMtlY)..Thanks !"]}, {"number": 48036, "title": "Is tensorflow Java interface support Mac M1 slices ? Problematic frame: C [libtensorflow_framework.2.dylib+0x14c15] tensorflow::monitoring::MetricDef", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **MacOs Big Sur ver11.0.1,  M1 slices** \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  Maven\r\n- TensorFlow version (use command below): Old tensorflow version(1.4.0/1.5.0), and new  tensorflow Java Version 0.2.0\r\n- JVM version:  1.8.0_162\r\n-  No GPU\r\n\r\n**Describe the current behavior**\r\nI just try to run tensorflow java offical example, and get tensorflow version for test. but It dosen't work. \r\nI have test different versions of tensorflow java interface, and only ver 1.13.1 works well. \r\nAnd all other versions can not work,  for example old tensorflow version(1.4.0/1.5.0), and new  tensorflow Java Version 0.2.0/0.3.0(tensorflow ver2.3.1/2.4.1) .\r\n\r\nThe Error shows below:\r\n\r\n> A fatal error has been detected by the Java Runtime Environment:\r\n> \r\n> SIGILL (0x4) at pc=0x00000001290edc15, pid=6333, tid=0x0000000000001a03\r\n> \r\n> JRE version: Java(TM) SE Runtime Environment (8.0_162-b12) (build 1.8.0_162-b12)\r\n> Java VM: Java HotSpot(TM) 64-Bit Server VM (25.162-b12 mixed mode bsd-amd64 compressed oops)\r\n> Problematic frame:\r\n> **C  [libtensorflow_framework.2.dylib+0x14c15]  tensorflow::monitoring::MetricDef<(tensorflow::monitoring::MetricKind)1, long long, 2>::MetricDef<char [11], char [7]>(absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, char const (&) [11], char const (&) [7])+0x125**\r\n> \r\n> Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n> \r\n> An error report file with more information is saved as:\r\n>  /***/tf_test/hs_err_pid6333.log\r\n> \r\n> If you would like to submit a bug report, please visit:\r\n> http://bugreport.java.com/bugreport/crash.jsp\r\n> The crash happened outside the Java Virtual Machine in native code.\r\n> See problematic frame for where to report the bug.\r\n> \r\n\r\n**Code to reproduce the issue**\r\nJava code:\r\n```\r\n\r\nimport org.tensorflow.TensorFlow;\r\npublic class HelloTensorFlow {\r\n    public static void main(String[] args) throws Exception {\r\n        System.out.println(\"Hello TensorFlow \" +TensorFlow.version());\r\n    }\r\n}\r\n```\r\n\r\npom.xml\r\n```\r\n<project>\r\n    <modelVersion>4.0.0</modelVersion>\r\n    <groupId>org.myorg</groupId>\r\n    <artifactId>hellotensorflow</artifactId>\r\n    <version>1.0-SNAPSHOT</version>\r\n\r\n    <properties>\r\n        <exec.mainClass>HelloTensorFlow</exec.mainClass>\r\n    <!-- Minimal version for compiling TensorFlow Java is JDK 8 -->\r\n        <maven.compiler.source>1.8</maven.compiler.source>\r\n        <maven.compiler.target>1.8</maven.compiler.target>\r\n    </properties>\r\n\r\n    <dependencies>\r\n    <!-- Include TensorFlow (pure CPU only) for all supported platforms -->\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>tensorflow-core-platform</artifactId>\r\n            <version>0.2.0</version>\r\n        </dependency>\r\n    </dependencies>\r\n</project>\r\n```", "comments": ["have you solved this problem, i meet the same bug."]}, {"number": 48027, "title": "Float16 TFLite models with multiple interpreters doesn't share weights but bloats memory", "body": "**System information**\r\n- Linux 5.11.4-arch1-1 #1 SMP PREEMPT Sun, 07 Mar 2021 18:00:49 +0000 x86_64 GNU/Linux\r\n- TensorFlow 2.4.1 from `tensorflow-opt-cuda` package (https://archlinux.org/packages/community/x86_64/tensorflow-opt-cuda)\r\n\r\n**Describe the current behavior**\r\n\r\nWhen we create multiple interpreters per single model (e.g. for thread-safety reasons) the expected behavior is that all interpreters share model weights. And that's statement is true when the model is `float32` model:\r\n\r\n```\r\n$ ./minimal mem-bloat-float32.tflite        \r\ninitial mem 1 MB\r\ninterpreter #1, mem 139 MB\r\ninterpreter #2, mem 141 MB\r\ninterpreter #3, mem 144 MB\r\ninterpreter #4, mem 146 MB\r\ninterpreter #5, mem 148 MB\r\ninterpreter #6, mem 150 MB\r\ninterpreter #7, mem 152 MB\r\ninterpreter #8, mem 154 MB\r\ninterpreter #9, mem 156 MB\r\n```\r\n\r\nBut when the same model had been converted to be `float16` the weights are not shared anymore and memory is bloated so that each interpreter has its own copy of model weights:\r\n\r\n```\r\n$ ./minimal mem-bloat-float16.tflite\r\ninitial mem 1 MB\r\ninterpreter #1, mem 206 MB\r\ninterpreter #2, mem 341 MB\r\ninterpreter #3, mem 476 MB\r\ninterpreter #4, mem 610 MB\r\ninterpreter #5, mem 745 MB\r\ninterpreter #6, mem 880 MB\r\ninterpreter #7, mem 1015 MB\r\ninterpreter #8, mem 1149 MB\r\ninterpreter #9, mem 1284 MB\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior is that multiple interpreters share weights for the same model, whenever it's `float16` or `float32` model.\r\n\r\n**Standalone code to reproduce the issue**\r\n- unzip TFLite models: [mem-bloat-tflite.zip](https://github.com/tensorflow/tensorflow/files/6192575/mem-bloat-tflite.zip)\r\n- build TFLite `minimal` example with the following code within `tensorflow/tensorflow/lite/examples/minimal.cc`:\r\n```c++\r\n#include <cstdio>\r\n\r\n#include \"tensorflow/lite/interpreter.h\"\r\n#include \"tensorflow/lite/kernels/register.h\"\r\n#include \"tensorflow/lite/model.h\"\r\n#include \"tensorflow/lite/optional_debug_tools.h\"\r\n\r\n#if defined(_WIN32)\r\n#include <windows.h>\r\n#include <psapi.h>\r\n\r\n#elif defined(__unix__) || defined(__unix) || defined(unix) || (defined(__APPLE__) && defined(__MACH__))\r\n#include <unistd.h>\r\n#include <sys/resource.h>\r\n\r\n#if defined(__APPLE__) && defined(__MACH__)\r\n#include <mach/mach.h>\r\n\r\n#elif (defined(_AIX) || defined(__TOS__AIX__)) || (defined(__sun__) || defined(__sun) || defined(sun) && (defined(__SVR4) || defined(__svr4__)))\r\n#include <fcntl.h>\r\n#include <procfs.h>\r\n\r\n#elif defined(__linux__) || defined(__linux) || defined(linux) || defined(__gnu_linux__)\r\n#include <stdio.h>\r\n\r\n#endif\r\n\r\n#else\r\n#error \"Cannot define getCurrentRSS( ) for an unknown OS.\"\r\n#endif\r\n\r\n\r\n/**\r\n * Returns the current resident set size (physical memory use) measured\r\n * in bytes, or zero if the value cannot be determined on this OS.\r\n */\r\nsize_t getCurrentRSS( )\r\n{\r\n#if defined(_WIN32)\r\n    /* Windows -------------------------------------------------- */\r\n    PROCESS_MEMORY_COUNTERS info;\r\n    GetProcessMemoryInfo( GetCurrentProcess( ), &info, sizeof(info) );\r\n    return (size_t)info.WorkingSetSize;\r\n\r\n#elif defined(__APPLE__) && defined(__MACH__)\r\n    /* OSX ------------------------------------------------------ */\r\n    struct mach_task_basic_info info;\r\n    mach_msg_type_number_t infoCount = MACH_TASK_BASIC_INFO_COUNT;\r\n    if ( task_info( mach_task_self( ), MACH_TASK_BASIC_INFO,\r\n        (task_info_t)&info, &infoCount ) != KERN_SUCCESS )\r\n        return (size_t)0L;      /* Can't access? */\r\n    return (size_t)info.resident_size;\r\n\r\n#elif defined(__linux__) || defined(__linux) || defined(linux) || defined(__gnu_linux__)\r\n    /* Linux ---------------------------------------------------- */\r\n    long rss = 0L;\r\n    FILE* fp = NULL;\r\n    if ( (fp = fopen( \"/proc/self/statm\", \"r\" )) == NULL )\r\n        return (size_t)0L;      /* Can't open? */\r\n    if ( fscanf( fp, \"%*s%ld\", &rss ) != 1 )\r\n    {\r\n        fclose( fp );\r\n        return (size_t)0L;      /* Can't read? */\r\n    }\r\n    fclose( fp );\r\n    return (size_t)rss * (size_t)sysconf( _SC_PAGESIZE);\r\n\r\n#else\r\n    /* AIX, BSD, Solaris, and Unknown OS ------------------------ */\r\n    return (size_t)0L;          /* Unsupported. */\r\n#endif\r\n}\r\n\r\n\r\n#define TFLITE_MINIMAL_CHECK(x)                              \\\r\n  if (!(x)) {                                                \\\r\n    fprintf(stderr, \"Error at %s:%d\\n\", __FILE__, __LINE__); \\\r\n    exit(1);                                                 \\\r\n  }\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n  if (argc != 2) {\r\n    fprintf(stderr, \"minimal <tflite model>\\n\");\r\n    return 1;\r\n  }\r\n  const char* filename = argv[1];\r\n\r\n  printf(\"initial mem %d MB\\n\", getCurrentRSS() >> 20);\r\n\r\n  // Load model\r\n  std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(filename);\r\n  TFLITE_MINIMAL_CHECK(model != nullptr);\r\n\r\n  tflite::ops::builtin::BuiltinOpResolver resolver;\r\n  tflite::InterpreterBuilder builder(*model, resolver);\r\n\r\n  std::unique_ptr<tflite::Interpreter> interpreter_list[9];\r\n  for (auto &interpreter : interpreter_list) {\r\n\r\n    builder(&interpreter, 1);\r\n    TFLITE_MINIMAL_CHECK(interpreter != nullptr);\r\n    TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);\r\n    interpreter->Invoke();\r\n\r\n    printf(\"interpreter #%d, mem %d MB\\n\", &interpreter - &interpreter_list[0] + 1, getCurrentRSS() >> 20);\r\n  }\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\n**Other info / logs**\r\nBoth versions of model had been converted from this protobuf file: [mem-bloat-protobuf.zip](https://github.com/tensorflow/tensorflow/files/6192621/mem-bloat-protobuf.zip)\r\n", "comments": ["Thanks for your valuable feedback. Currently, each TensorFlow Lite interpreter owns each memory space by design. We will consider this as a feature request for increasing memory sharing across the multiple interpreter interfaces.\r\n\r\n@daverim @terryheo any thoughts on this?", "Interpreter can share data in flatbuffer file which contains constant tensors.\r\nBut each interpreter needs its own memory to store intermediate tensors. so it's natural to see a certain amount of memory increasement.\r\n\r\nRegarding your testing, I have few comments.\r\n1. Could you check /proc/self/statm shared pages?\r\nAccording to https://www.kernel.org/doc/html/latest/filesystems/proc.html, VmRSS = RssAnon + RssFile + RssShmem  \r\nwhich means VmRSS contains RssFile size. So you need to check it separately.\r\n2. If RssFile is zero, please confirm your model is using MMAPAllocation() https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/model_builder.cc#L50", "@terryheo \r\n> Interpreter can share data in flatbuffer file which contains constant tensors. But each interpreter needs its own memory to store intermediate tensors. so it's natural to see a certain amount of memory increasement.\r\n\r\nThat's right, but the difference between models is datatype (`float32` vs `float16`), so it's counter-intuitive to see that `float32` version do share weights and `float16` does not.\r\n\r\nThe memory usage gives insights of what's going on with memory usage.\r\n\r\nFor `float32` we've got: 1, 139, 141, 144, 146 etc.\r\nThat means 137 MB of shared constant tensors in `float32` + 2 MB for intermediate tensors per interpreter.\r\nSo model of the memory usage is (roughly): `137 + 2 * interpreters_count` MB\r\n\r\nFor `float16` we've got: 1, 206, 341, 476, 610 etc.\r\nThat means 69 MB of constant tensors in `float16` + 137 MB for intermediate tensors per interpreter\r\nSo model of the memory usage is (roughly): `69 + 137 * interpreters_count` MB\r\n..and 137 MB for intermediate tensors looks very similar to 137 MB of the `float32` model, so I assume there's conversion of `float16` constant tensors to `float32` constant tensors within each interpreter.\r\n\r\n> Could you check /proc/self/statm shared pages?\r\nplease confirm your model is using MMAPAllocation()\r\n\r\nI modified both the program and TFLite sources to show `/proc/self/statm` and `MMAPAllocation::IsSupported()` (at the location you pointed)\r\n```\r\n$ ./minimal mem-bloat-float32.tflite                        \r\ninitial mem 1 MB              [/proc/self/statm -> 2289 486 432 726 0 105 0]\r\nMMAPAllocation::IsSupported() is false\r\ninterpreter #1, mem  140 MB   [/proc/self/statm -> 36798 35848 1341 726 0 34614 0]\r\ninterpreter #2, mem  142 MB   [/proc/self/statm -> 37329 36442 1341 726 0 35145 0]\r\ninterpreter #3, mem  144 MB   [/proc/self/statm -> 37893 36970 1341 726 0 35709 0]\r\ninterpreter #4, mem  146 MB   [/proc/self/statm -> 38424 37498 1341 726 0 36240 0]\r\ninterpreter #5, mem  148 MB   [/proc/self/statm -> 38988 38026 1341 726 0 36804 0]\r\ninterpreter #6, mem  150 MB   [/proc/self/statm -> 39519 38554 1341 726 0 37335 0]\r\ninterpreter #7, mem  152 MB   [/proc/self/statm -> 40083 39148 1341 726 0 37899 0]\r\ninterpreter #8, mem  154 MB   [/proc/self/statm -> 40614 39676 1341 726 0 38430 0]\r\ninterpreter #9, mem  157 MB   [/proc/self/statm -> 41178 40204 1341 726 0 38994 0]\r\n$ ./minimal mem-bloat-float16.tflite                        \r\ninitial mem 1 MB              [/proc/self/statm -> 2289 501 447 726 0 105 0]\r\nMMAPAllocation::IsSupported() is false\r\ninterpreter #1, mem  206 MB   [/proc/self/statm -> 53770 52848 1301 726 0 51586 0]\r\ninterpreter #2, mem  341 MB   [/proc/self/statm -> 88268 87352 1301 726 0 86084 0]\r\ninterpreter #3, mem  476 MB   [/proc/self/statm -> 122811 121863 1301 726 0 120627 0]\r\ninterpreter #4, mem  610 MB   [/proc/self/statm -> 157284 156354 1301 726 0 155100 0]\r\ninterpreter #5, mem  745 MB   [/proc/self/statm -> 191790 190842 1301 726 0 189606 0]\r\ninterpreter #6, mem  880 MB   [/proc/self/statm -> 226263 225332 1301 726 0 224079 0]\r\ninterpreter #7, mem 1014 MB   [/proc/self/statm -> 260736 259820 1301 726 0 258552 0]\r\ninterpreter #8, mem 1149 MB   [/proc/self/statm -> 295202 294286 1301 726 0 293018 0]\r\ninterpreter #9, mem 1284 MB   [/proc/self/statm -> 329746 328798 1301 726 0 327562 0]\r\n```", "@terryheo\r\nI rebuilt the example with `-DTFLITE_ENABLE_MMAP=ON` and now `MMAPAllocation::IsSupported() is true`, but memory bloat for `float16` is still here:\r\n\r\n```\r\n$ ./minimal mem-bloat-float32.tflite                   \r\ninitial mem 1 MB              [/proc/self/statm -> 2291 486 432 727 0 105 0]\r\nMMAPAllocation::IsSupported() is true\r\ninterpreter #1, mem   10 MB   [/proc/self/statm -> 36800 2583 1974 727 0 670 0]\r\ninterpreter #2, mem   12 MB   [/proc/self/statm -> 37331 3111 1974 727 0 1201 0]\r\ninterpreter #3, mem   14 MB   [/proc/self/statm -> 37895 3639 1974 727 0 1765 0]\r\ninterpreter #4, mem   16 MB   [/proc/self/statm -> 38426 4167 1974 727 0 2296 0]\r\ninterpreter #5, mem   18 MB   [/proc/self/statm -> 38990 4761 1974 727 0 2860 0]\r\ninterpreter #6, mem   20 MB   [/proc/self/statm -> 39521 5289 1974 727 0 3391 0]\r\ninterpreter #7, mem   22 MB   [/proc/self/statm -> 40085 5817 1974 727 0 3955 0]\r\ninterpreter #8, mem   24 MB   [/proc/self/statm -> 40616 6345 1974 727 0 4486 0]\r\ninterpreter #9, mem   26 MB   [/proc/self/statm -> 41180 6873 1974 727 0 5050 0]\r\n$ ./minimal mem-bloat-float16.tflite\r\ninitial mem 1 MB              [/proc/self/statm -> 2291 501 447 727 0 105 0]\r\nMMAPAllocation::IsSupported() is true\r\ninterpreter #1, mem  206 MB   [/proc/self/statm -> 53772 52834 18263 727 0 34612 0]\r\ninterpreter #2, mem  341 MB   [/proc/self/statm -> 88269 87354 18279 727 0 69109 0]\r\ninterpreter #3, mem  476 MB   [/proc/self/statm -> 122813 121866 18279 727 0 103653 0]\r\ninterpreter #4, mem  610 MB   [/proc/self/statm -> 157286 156357 18279 727 0 138126 0]\r\ninterpreter #5, mem  745 MB   [/proc/self/statm -> 191792 190845 18279 727 0 172632 0]\r\ninterpreter #6, mem  880 MB   [/proc/self/statm -> 226265 225335 18279 727 0 207105 0]\r\ninterpreter #7, mem 1014 MB   [/proc/self/statm -> 260738 259823 18279 727 0 241578 0]\r\ninterpreter #8, mem 1149 MB   [/proc/self/statm -> 295204 294289 18279 727 0 276044 0]\r\ninterpreter #9, mem 1284 MB   [/proc/self/statm -> 329748 328801 18279 727 0 310588 0]\r\n```", "Let me humbly emphasize that weights sharing between interpreters is very important. With our runtime environment we're running up to eight threads of realtime inferences with precomputed ~130 MB of float32 weights. It's counter-productive to copy ~130 MB of weights per each interpreter. And also it would be better to have ~65 MB of float16 weights shared between eight interpreters/threads.", "> ..and 137 MB for intermediate tensors looks very similar to 137 MB of the float32 model, so I assume there's conversion of float16 constant tensors to float32 constant tensors within each interpreter.\r\n\r\nI think this is the case since there is no float16 native kernels. @jdduke, @daverim FYI,\r\n\r\nI wonder if you tried full integer quantization which saves more memory. https://www.tensorflow.org/lite/performance/post_training_quantization\r\nI guess it also allows to share constant tensors. ", "@terryheo \r\n>I wonder if you tried full integer quantization which saves more memory\r\n\r\nAt some point I will, but I'd split the whole graph into preparation (`float32`), inference (int quantization) and postprocessing (`float32`) parts. Currently it would be very beneficial to have just `float16`. More to say, it's shame that previous implementation of the same model had been done manually with `float16` arithmetic (== two times less memory) and the same performance. Also, for a single thread there was no need to have 2 MB of intermediate tensors per interpreter. So I hope TFLite will improve in this direction.\r\n\r\nAlthough TFLite has no native `float16` kernels why not introduce shared memory manager to each model instance? When the first interpreter converts `float16` into `float32` constant tensors they are registered within the shared memory manager. When the next interpreter requires `float32` constants it gets its smart pointer from the manager. (For example, by unique name of tensor or node ID).", "Hi @barabanus . Your request is quite reasonable, though there would be quite a bit of complexity involved to make this work properly, due to the lazy manner in which float16 weights are currently \"inflated\" at runtime. Terry's suggestion to try int8 quantization is probably the best approach to both reduce the model size but also enable weight sharing.\r\n\r\nThat said, for Q2 we are looking into supporting native float16 execution paths that operate natively on float16 weights for ARM devices. There are some issues involved as it relates to accuracy (the most widely available float16 ARM intrinsics do not accumulate into float32, though the latest devices to support this), but we'll also be working on tooling to validate that the relaxed runtime precision doesn't significantly degrade accuracy.\r\n", "@jdduke @terryheo Thank you for the explanation. Well, I wish TFLite will implement native float16 kernels. What shall we do with the issue?", "It's up to you whether you'd like to leave this issue open. We can file an external issue tracking native float16 computation, and when we've done so link to that here (and potentially close this issue).", "@jdduke Thanks, it would be wonderful to track float16 task. Also I would double check it with the program I wrote."]}, {"number": 48026, "title": "Unexpected rank of mask computed by tf.keras.layers.Masking", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.8\r\n\r\n**Describe the current behavior**\r\nI have batch tensors of the shape `(batch_size, n_time_steps, n_features, n_channels)`. They arise from tensors of the shape `(n_time_steps, n_features, n_channels)`, where `n_time_steps` is *not constant*. When constructing the batches, the tensors are padded to the maximum value of `n_time_steps`.\r\n\r\nThese tensors should be fed into a neural network of the following architecture:\r\n- The inputs are masked due to the padding.\r\n- The tensors for each timestep are fed to a time distributed convolutional block. The mask is propagated.\r\n- The extracted features are fed to an RNN layer.\r\n\r\nIn the last layer, I run into an error due to the fact that the mask has the shape `(batch_size, n_time_steps, n_features)`, but the RNN layer expects it to have shape `(batch_size, n_time_steps)`.\r\n\r\n**Describe the expected behavior**\r\nAccording to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking):\r\n> For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking).\r\n\r\nSo I expect the mask to have shape `(batch_size, n_time_steps)` and, in particular, tensor rank 2, regardless of the tensor rank of the input tensor.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere is a minimal example:\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass TimeDistributedMaskPropagating(tf.keras.layers.TimeDistributed):\r\n    \"\"\"TimeDistributed layer that propagates mask.\"\"\"\r\n    \r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.supports_masking = True\r\n        \r\n    def compute_mask(self, inputs, mask=None):\r\n        return mask\r\n\r\nn_features = 3\r\nn_channels = 1\r\n\r\ncnn_block = tf.keras.layers.Flatten()\r\nestimator = tf.keras.Sequential([\r\n    tf.keras.layers.Input(shape=(None, n_features, n_channels)),\r\n    tf.keras.layers.Masking(),\r\n    TimeDistributedMaskPropagating(cnn_block),\r\n    # tf.keras.layers.LSTM(10)\r\n    # yields ValueError: Dimensions must be equal, but are 3 and 10\r\n])\r\n\r\nx1 = tf.random.uniform((4, 3, 1))       # shape: 4, 3, 1\r\nx2 = tf.random.uniform((3, 3, 1))       # shape: 3, 3, 1\r\n\r\npaddings = tf.constant([[0, 1], [0, 0], [0, 0]])\r\npadded_x2 = tf.pad(x2, paddings)        # shape: 4, 3, 1\r\nmini_batch = tf.stack((x1, padded_x2))  # shape: 2, 4, 3, 1\r\n\r\nlogits = estimator(mini_batch)          # shape: 2, 4, 3\r\nprint(logits._keras_mask)               # shape: 2, 4, 3\r\n# mask has shape 2, 4, 3 with values\r\n# [[[ True  True  True]\r\n#   [ True  True  True]\r\n#   [ True  True  True]\r\n#   [ True  True  True]]\r\n# \r\n#  [[ True  True  True]\r\n#   [ True  True  True]\r\n#   [ True  True  True]\r\n#   [False False False]]]\r\n\r\n# mask should have shape 2, 4 with values\r\n# [[ True  True  True  True]\r\n#  [ True  True  True False]]\r\n```\r\n\r\n**Other info / logs**\r\nI have solved the problem for my use case by defining a custom masking layer, where `axis=-1` from the [original code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/core.py) in the methods `compute_mask` and `call` is replaced by `axis=[2, 3]` (in my case) or, more generally, by `axis=list(range(2, len(inputs.shape)))` ([full code](https://stackoverflow.com/a/66769283/10816965)).\r\n\r\nIf the TensorFlow team agrees with me that the current behavior of the `Masking` layer is unexpected and unintended, I would love to contribute with a pull request.", "comments": ["Just a quick note: I provided a pull request (#48168), but I do not know how to link this issue to the pull request.", "@SebastianThomas1   The PR which you have submitted was closed already. Please go ahead and close the issue if you don't have any concern. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@saikumarchalla Sorry for the late reply.\r\n\r\nThe issue still persists.\r\n\r\nYes, the PR was closed, but the only explanation given was that the data I provided is not the data the masked layer was expecting (at least to the opinion of the reviewer of the PR). However, the documentation still has no reference to this restriction.\r\n\r\nIf I understand the documentation correctly, the behavior of the implementation still is not what the documentation describes\u2026 The [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking#used-in-the-notebooks) says that \"[...] if all values in the input tensor at that timestep are equal to `mask_value`, then the timestep will be masked [\u2026]\". Moreover, the [tutorial](https://www.tensorflow.org/guide/keras/masking_and_padding?hl=en#mask-generating_layers_embedding_and_masking]) says: \"Under the hood, these layers will create a mask tensor (2D tensor with shape (batch, sequence_length))\". This is only true for input tensors of rank 3.\r\n\r\nMy proposed solution should work for every tensor (of rank at least 3). I do not know whether there is another reason why the PR was rejected, but I suggest that at least the documentation should be extended in order to inform the user that a mask layer expects input tensors of rank 3.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48026\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48026\">No</a>\n"]}, {"number": 48021, "title": "CMake config for TensorFlow Lite C API for Windows builds debug target (not release target as expected)", "body": "**System information**\r\n- Microsoft Windows 10 Pro Insider Preview 10.0.21337 Build 21337\r\n- Microsoft Visual Studio Community 2019 Version 16.9.1\r\n- TensorFlow master 42d9939623f7792ef01b9750df4cd91e5a4b26fa\r\n\r\n**Describe the problem**\r\nWhen I try to build TensorFlow Lite C API dynamic library for Windows using MSVC 2019 compiler with CMake config I get debug target compiled (not release target as expected).\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- install Microsoft Visual Studio Community 2019 with CMake, git and command prompt tools components\r\n- run `x86 Native Tools Command Prompt for VS 2019`\r\n- run the following commands within the terminal:\r\n```\r\ngit clone --depth 1 https://github.com/tensorflow/tensorflow.git\r\ncmake tensorflow/tensorflow/lite/c -DTFLITE_C_BUILD_SHARED_LIBS=ON -Bbuild\r\ncmake --build build -j 8\r\n```\r\nAfter the compilation there's `build/Debug/tensorflowlite_c.dll` which is built as debug target. It doesn't help to provide `-DCMAKE_BUILD_TYPE=Release` - CMake still builds debug target.\r\n\r\nExpected behavior is that CMake builds release target.\r\n\r\n**Any other info / logs**\r\nHere's full log from the commands above: [cmake-msvc-win.txt](https://github.com/tensorflow/tensorflow/files/6191359/cmake-msvc-win.txt)\r\n", "comments": ["Hi Terry, \r\n\r\nCould you help on this CMake issue?\r\n\r\nThanks,\r\nTiezhen", "@barabanus \r\ncould you please let us know if this is still an issue.", "@Saduf2019 \r\nSorry for the delay. I confirm that this's still an issue for **v2.7.0**\r\nAfter compilation we've got `build/Debug/tensorflowlite_c.dll`\r\n(unfortunately, I failed to compile the library from master branch because of compilation errors)"]}, {"number": 48016, "title": "XLA CPU CNN compilation SegFault", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 / macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 3da7b09556355b54d324238ea99c376c9713a414\r\n- Python version: n/a\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nWe're working on XLA bindings over at [Nx](https://github.com/elixir-nx/nx). We're currently working on a high-level API for writing Neural networks. We have a CNN that basically looks like:\r\n\r\n```elixir\r\ninput({32, 3, 32, 32})\r\n|> conv(32, kernel_size: {3, 3}, activation: :relu)\r\n|> batch_norm()\r\n|> avg_pool(kernel_size: {2, 2})\r\n|> conv(64, kernel_size: {3, 3}, activation: :relu)\r\n|> batch_norm()\r\n|> avg_pool(kernel_size: {2, 2})\r\n|> conv(64, kernel_size: {3, 3}, activation: :relu)\r\n|> batch_norm()\r\n|> flatten()\r\n|> dense(64, activation: :relu)\r\n|> dropout()\r\n|> dense(10, activation: :log_softmax)\r\n```\r\n\r\nUnfortunately, the program SegFaults during compilation when using XLA CPU. We have previously successfully compiled and run the same network using XLA GPU. GDB Backtrace indicates this happens somewhere in LLVM. I can provide HLO Dumps as well.\r\n\r\n**Other info / logs**\r\n\r\n<details><summary>GDB Backtrace</summary>\r\n<pre>\r\n#0  0x00007f68bb04ee09 in llvm::MemorySSA::getOrCreateAccessList(llvm::BasicBlock const*) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#1  0x00007f68bb04f4af in llvm::MemorySSA::insertIntoListsForBlock(llvm::MemoryAccess*, llvm::BasicBlock const*, llvm::MemorySSA::InsertionPlace) ()\r\n   from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#2  0x00007f68bb050033 in llvm::MemorySSA::createMemoryPhi(llvm::BasicBlock*) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#3  0x00007f68bb061876 in llvm::MemorySSAUpdater::getPreviousDefRecursive(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#4  0x00007f68bb0628f6 in llvm::MemorySSAUpdater::getPreviousDefFromEnd(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#5  0x00007f68bb0617db in llvm::MemorySSAUpdater::getPreviousDefRecursive(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#6  0x00007f68bb0628f6 in llvm::MemorySSAUpdater::getPreviousDefFromEnd(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#7  0x00007f68bb0617db in llvm::MemorySSAUpdater::getPreviousDefRecursive(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#8  0x00007f68bb0628f6 in llvm::MemorySSAUpdater::getPreviousDefFromEnd(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#9  0x00007f68bb0619ab in llvm::MemorySSAUpdater::getPreviousDefRecursive(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n#10 0x00007f68bb0628f6 in llvm::MemorySSAUpdater::getPreviousDefFromEnd(llvm::BasicBlock*, llvm::DenseMap<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess>, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::TrackingVH<llvm::MemoryAccess> > >&) () from /home/sean/projects/axon/_build/dev/lib/exla/priv/libexla.so\r\n</pre>\r\n</details>\r\n", "comments": ["@seanmor5 \r\nPlease share a simple stand alone code such that we could reproduce the issue reported or a colab gist with the code an error for us to analyse.", "Hi @Saduf2019 thank you for your response. Here is a [gist](https://gist.github.com/seanmor5/ecbb996e0498ccd4ad8bc09bce2828e1); however, it requires installing Elixir and Erlang/OTP as well as building our XLA Client from source. I can try to make this process a little easier by providing a Dockerfile. I was hoping the HLO Dumps might have been useful here to reproduce the compilation SegFault. Please let me know what else I can do to make this easier to debug.", "Just to provide some (hopefully) more helpful information. I ran everything through valgrind:\r\n\r\n```\r\n==1948032== \r\n==1948032== Process terminating with default action of signal 11 (SIGSEGV)\r\n==1948032==  Bad permissions for mapped region at address 0x48B5AFF8\r\n==1948032==    at 0x6A0E407B: llvm::DenseMapBase<llvm::DenseMap<llvm::BasicBlock*, std::unique_ptr<llvm::DomTreeNodeBase<llvm::BasicBlock>, std::default_delete<llvm::DomTreeNodeBase<llvm::BasicBlock> > >, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, std::unique_ptr<llvm::DomTreeNodeBase<llvm::BasicBlock>, std::default_delete<llvm::DomTreeNodeBase<llvm::BasicBlock> > > > >, llvm::BasicBlock*, std::unique_ptr<llvm::DomTreeNodeBase<llvm::BasicBlock>, std::default_delete<llvm::DomTreeNodeBase<llvm::BasicBlock> > >, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, std::unique_ptr<llvm::DomTreeNodeBase<llvm::BasicBlock>, std::default_delete<llvm::DomTreeNodeBase<llvm::BasicBlock> > > > >::find(llvm::BasicBlock const*) const (in /home/sean/projects/axon/deps/exla/exla/priv/libexla.so)\r\n==1948032== \r\n==1948032== Process terminating with default action of signal 11 (SIGSEGV)\r\n==1948032==  Bad permissions for mapped region at address 0x48B5AFF0\r\n==1948032==    at 0x4831134: _vgnU_freeres (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_core-amd64-linux.so)\r\n==1948032== \r\n==1948032== HEAP SUMMARY:\r\n==1948032==     in use at exit: 9,331,477,455 bytes in 1,335,643 blocks\r\n==1948032==   total heap usage: 17,604,332 allocs, 16,268,689 frees, 606,006,962,608 bytes allocated\r\n==1948032== \r\n==1948032== LEAK SUMMARY:\r\n==1948032==    definitely lost: 1,136 bytes in 3 blocks\r\n==1948032==    indirectly lost: 7,936 bytes in 2 blocks\r\n==1948032==      possibly lost: 8,601,228 bytes in 152,054 blocks\r\n==1948032==    still reachable: 9,322,436,784 bytes in 1,183,258 blocks\r\n==1948032==                       of which reachable via heuristic:\r\n==1948032==                         newarray           : 8,920 bytes in 5 blocks\r\n==1948032==                         multipleinheritance: 6,776 bytes in 43 blocks\r\n==1948032==         suppressed: 430,371 bytes in 326 blocks\r\n==1948032== Rerun with --leak-check=full to see details of leaked memory\r\n==1948032== \r\n==1948032== For lists of detected and suppressed errors, rerun with: -s\r\n==1948032== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\r\nSegmentation fault\r\n```\r\n\r\nAdditionally, the segmentation fault no longer occurs when running with `XLA_FLAGS=--xla_backend_optimization_level=1`. The segmentation fault always occurs after a call to `createMemoryPhi` in LLVM. "]}, {"number": 48014, "title": "Couldn't build android C++ .so libs with bazel and tensorflow as a remote dependency.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Source, current master branch (23.03.2021)\r\n- TensorFlow version: Current master branch(23.03.2021), latest tag v2.4.1\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 4.0.0\r\n- GCC/Compiler version (if compiling from source):  7.5.0\r\n- CUDA/cuDNN version: Not Used\r\n- GPU model and memory: Not Used\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to build on C++ .so on top of tensorflow with bazel. I am trying to add tensorflow as a remote repository just like tensorflow_serving ( https://github.com/tensorflow/serving ).\r\nI can build for native targets(linux x86_64) all fine, when I tried to build for **--config android** I got errors that android is not defined, so I copy/pasted the .bazelrc file from tensorflow, and updated .tf_configure.bazelrc. Than the build started but it is failing \r\nfor this target: \r\n\r\n``` \r\nERROR: /home/flamur/.cache/bazel/_bazel_flamur/8aff49c09e177f51e03fa24b3bf8aaa8/external/org_tensorflow/tensorflow/lite/delegates/gpu/cl/BUILD:486:22: Generating flatbuffer files for serialization_cc_fbs_srcs: @org_tensorflow//tensorflow/lite/delegates/gpu/cl:serialization_cc_fbs_srcs failed: (Exit 1): bash failed: error executing command \r\n  (cd /home/flamur/.cache/bazel/_bazel_flamur/8aff49c09e177f51e03fa24b3bf8aaa8/execroot/this_repo && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=30.0.0-rc4 \\\r\n    ANDROID_NDK_API_LEVEL=24 \\\r\n    ANDROID_NDK_HOME=/home/flamur/Android/Sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=30 \\\r\n    ANDROID_SDK_HOME=/home/flamur/Android/Sdk \\\r\n    PATH=/home/flamur/anaconda3/envs/flamxi/bin:/home/flamur/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/flamur/bin:/home/flamur/.cargo/bin:/snap/bin:/home/flamur/anaconda3/envs/flamxi/bin:/home/flamur/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/flamur/bin:/snap/bin:/home/flamur/Documents/CLion-2020.2.4/clion-2020.2.4/bin:/home/flamur/Documents/CLion-2020.2.4/clion-2020.2.4/bin \\\r\n    PYTHON_BIN_PATH=/home/flamur/anaconda3/envs/flamxi/bin/python3 \\\r\n    PYTHON_LIB_PATH=/home/flamur/anaconda3/envs/flamxi/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in external/org_tensorflow/tensorflow/lite/delegates/gpu/cl/serialization.fbs; do bazel-out/host/bin/external/flatbuffers/flatc --scoped-enums -I ./  -c -o bazel-out/armeabi-v7a-opt/bin/external/org_tensorflow/tensorflow/lite/delegates/gpu/cl $f; done')\r\nExecution platform: @local_execution_config_platform//:platform\r\nerror: /home/flamur/.cache/bazel/_bazel_flamur/8aff49c09e177f51e03fa24b3bf8aaa8/external/org_tensorflow/tensorflow/lite/delegates/gpu/cl/serialization.fbs:15: 75: error: unable to load include file: tensorflow/lite/delegates/gpu/common/task/serialization_base.fbs\r\nTarget //skeleton:centernet failed to build\r\nINFO: Elapsed time: 0.131s, Critical Path: 0.01s\r\nINFO: 2 processes: 2 internal.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\nI checked that file **serialization.fbs** and it seems like having a relative path for this include:\r\n```\r\ninclude \"tensorflow/lite/delegates/gpu/common/task/serialization_base.fbs\";\r\n```\r\nI am guessing this could be the problem! As the error says that cannot find this file.\r\n\r\nIf you want more files like WORKSPACE or .bazelrc please mention that, I don't know if they are required at this state! \r\n\r\nFor the target that I get this error I tested it with tensorflow as local dependency it works all fine, also with the remote dependency the non android targets are builded succesfully! \r\n", "comments": ["Hi Flamur,\r\n\r\nIt would be great if you can provide more information on how the BUILD file was written and how your .tf_configure.bazelrc looks like.\r\n\r\nReading the error message above, it seems that bazel can find `tensorflow/lite/delegates/gpu/cl/serialization.fbs` but not `tensorflow/lite/delegates/gpu/common/task/serialization_base.fbs` ? \r\n\r\n\r\nHi Juhyun,\r\n\r\nAny thoughts on this or could you help re-assign to someone with more context?\r\n\r\nThanks,\r\nTiezhen", "Hi @wangtz \r\nThanks for your reply.\r\nThis is my BUILD file content:\r\n``` bazel\r\npackage(default_visibility = [\"//visibility:public\"])\r\n#load(\"@org_tensorflow//tensorflow:tensorflow.bzl\", \"tflite_cc_shared_object\", \"tflite_copts\", \"tflite_linkopts\")\r\n\r\ncc_library(\r\n    name = \"centernet\",\r\n    srcs = glob([\r\n        \"foo.cpp\",\r\n    ]),\r\n    hdrs = glob([\r\n        \"foo.hpp\",\r\n    ]),\r\n    copts = [\r\n        \"-std=c++14\",\r\n    ] + select({\r\n        \"@org_tensorflow//tensorflow:android\": [\r\n            \"-D__ANDROID__\",\r\n        ],\r\n        \"@org_tensorflow//tensorflow:android_arm64\": [\r\n            \"-D__ANDROID__\",\r\n        ],\r\n        \"//conditions:default\": [\r\n        ]\r\n    }),\r\n    linkopts = [\r\n\r\n    ] + select({\r\n        \"@org_tensorflow//tensorflow:android\": [\r\n            \"-lEGL\",\r\n            \"-lGLESv3\",\r\n            \"-pie\",\r\n            \"-lm\",\r\n        ],\r\n        \"//conditions:default\": [],\r\n    }),\r\n    deps = [\r\n        \"@org_tensorflow//tensorflow/lite/delegates/nnapi:nnapi_delegate\",\r\n        \"@org_tensorflow//tensorflow/lite:framework\",\r\n        \"@org_tensorflow//tensorflow/lite:string_util\",\r\n        \"@org_tensorflow//tensorflow/lite/kernels:builtin_ops\",\r\n        \"@org_tensorflow//tensorflow/lite/tools/evaluation:utils\",\r\n        \"@com_google_absl//absl/memory\",\r\n    ] + select({\r\n        \"@org_tensorflow//tensorflow:android_arm\": [\r\n            \"@org_tensorflow//tensorflow/lite/delegates/gpu:gl_delegate\",\r\n             \"@opencv//:opencv_arm\",\r\n        ],\r\n        \"@org_tensorflow//tensorflow:android_arm64\": [\r\n            \"@org_tensorflow//tensorflow/lite/delegates/gpu:gl_delegate\",\r\n             \"@opencv//:opencv_arm64\",\r\n        ],\r\n        \"//conditions:default\": [\r\n            \"@native_opencv//:opencv\",\r\n        ],\r\n    }),\r\n)\r\n\r\n```\r\n\r\nAnd my tf_configure.bazelrc is:\r\n``` bazel\r\nbuild --action_env PYTHON_BIN_PATH=\"/home/$USER/anaconda3/envs/$USER/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/home/$USER/anaconda3/envs/$USER/lib/python3.7/site-packages\"\r\nbuild --python_path=\"/home/$USER/anaconda3/envs/$USER/bin/python3\"\r\nbuild --config=xla\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --action_env ANDROID_NDK_HOME=\"/home/$USER/Android/Sdk/ndk-bundle\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"24\"\r\nbuild --action_env ANDROID_BUILD_TOOLS_VERSION=\"30.0.0-rc4\"\r\nbuild --action_env ANDROID_SDK_API_LEVEL=\"30\"\r\nbuild --action_env ANDROID_SDK_HOME=\"/home/$USER/Android/Sdk\"\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```", "For my case, I have to configure the Bazel build process to specify Android SDK and NDK path before running the `bazel build ...` commands. \r\nMore detailed https://github.com/cuongvng/TF-Lite-Cpp-API-for-Android", "I guess the problem can be fixed by modifying the following file.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/cl/BUILD\r\n```\r\nflatbuffer_cc_library(\r\n    name = \"serialization_cc_fbs\",\r\n    srcs = [\"serialization.fbs\"],\r\n    flatc_args = [\r\n        \"--scoped-enums\",\r\n        \"-I ./\",\r\n    ],\r\n    includes = [\r\n        \"//tensorflow/lite/delegates/gpu/common/task:serialization_base_cc_fbs_includes\",\r\n    ],\r\n)\r\n```\r\nflatc_args need to have additional \"-I\" option to find `serialization_base.fbs` file. Could you try?", "hey @terryheo, thank you for your reply!\r\n\r\nI tried a lot of combination to pass that flag as you mentioned @terryheo but since I am not familiar with flatbuffer bazel macros, I can not find a proper way that should work, what I tried is to update the -I with just the first directory of the repository meaning ```-I //tensorflow, -I //``` but that seems like a syntax error, also tried to find and check this content: ``` \"//tensorflow/lite/delegates/gpu/common/task:serialization_base_cc_fbs_includes\"``` but could not find it, in current master I cannot find a lib name of that package, only ```serialization_base_cc_fbs``` at this point I don't know if  flatbuffers bazel defs, have this \"feature\" to include only by adding ```_includes``` at the end of package or not! Can I expect more guides from you in this area? Thanks", "@cuongvng thanks for your suggestions, but I already mentioned that when it comes to clone the repo locally I managed to add as a local_repository and than build against it, I am trying to build with tensorflow repo directly cloned from bazel! Thanks", "It worth to provide absolute path to the serialization_base.fbs with \"-I\" option. (later we could find proper relative path)\r\nFYI, \"//\" path only works Bazel and flatc_args is directly used by flatbuffer compiler.", "exactly, // works only for bazel, and thats why I don't know how to begin writing the absolute path, since the repository comes from remote !", "Did you search $HOME/.cache/bazel ?\r\n\r\nhttps://docs.bazel.build/versions/master/output_directories.html", "uh nice, so there will be the repository, I'll try it asap! thanks ;) ", "It works all flawlessly now! @terryheo  thanks!\r\nEven though I got to type hard-coded absolute paths, since $HOME and $USER were not recognized there :S.\r\nMay I ask if you have any idea how would the proper solution be, I would gladly contribute that!", "That's good to hear.\r\nCould you try if the following also works for you?\r\n\r\n```\r\nflatbuffer_cc_library(\r\n    name = \"serialization_cc_fbs\",\r\n    srcs = [\"serialization.fbs\"],\r\n    flatc_args = [\r\n        \"--scoped-enums\",\r\n        \"-I $(location //tensorflow/lite/delegates/gpu/common/task:serialization_base_cc_fbs_includes)\",\r\n    ],\r\n    includes = [\r\n        \"//tensorflow/lite/delegates/gpu/common/task:serialization_base_cc_fbs_includes\",\r\n    ],\r\n)\r\n```\r\nPlease let me know if it works.\r\n\r\nBTW, you can check the actual build command with \"-s\" option to Bazel. It will help to debug build issues.\r\n```\r\n$ bazel build -s //target\r\n```", "I tried, and no it doesn't work, still the error message for the missing include!\r\nAlso wanted to ask, I couldn't find this package declaration ``` serialization_base_cc_fbs_includes ``` anywhere inside the repository, it is only used in this file we are changing! ", "I see. I also thought it's strange.\r\n\r\nIt looks bit dirty... but could you try the following?\r\n```\r\nflatbuffer_cc_library(\r\n    name = \"serialization_cc_fbs\",\r\n    srcs = [\"serialization.fbs\"],\r\n    flatc_args = [\r\n        \"--scoped-enums\",\r\n        \"-I $$(dirname $(location //tensorflow/lite/delegates/gpu/common/task:serialization_base.fbs))/../../../../../..\",\r\n    ],\r\n    includes = [\r\n        \"//tensorflow/lite/delegates/gpu/common/task:serialization_base.fbs\",\r\n    ],\r\n)\r\n\r\n```\r\n\r\n", "@terryheo \r\nI tried, I got this error:\r\n```\r\nERROR: /home/flamxi/.cache/bazel/_bazel_flamur/8aff49c09e177f51e03fa24b3bf8aaa8/external/org_tensorflow/tensorflow/lite/delegates/gpu/cl/BUILD:490:22: \r\nin cmd attribute of genrule rule @org_tensorflow//tensorflow/lite/delegates/gpu/cl:serialization_cc_fbs_srcs: label '@org_tensorflow//tensorflow/lite/delegates/gpu/common/task:serialization_base.fbs' \r\nin $(location) expression is not a declared prerequisite of this rule. \r\nSince this rule was created by the macro 'flatbuffer_cc_library', the error might have been caused by the macro implementation.\r\n```\r\n", "@terryheo Do you have any other idea we can try here! ", "@flamxi I believe this issue has been fixed in r2.6 by using `workspace_root`.\r\nHere is the patch.\r\nhttps://github.com/heeh/tensorflow/commit/bbdafc9f7e2a2564d8412dd1df7c1f0e5c3c0c05"]}, {"number": 48005, "title": "gradient wrt input not working after applying tfmot.quantization.keras.quantize_model", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAfter applying tfmot.quantization.keras.quantize_model to VGG16 model imported from keras:\r\n1. If I do tf.gradient(loss, input_tensor) directly, it will give me None which implies no relationship between input and the loss which is not expected.\r\n2. After I do  tf.gradient(loss, q_model.get_layer('quant_block1_conv1').input), things seem working fine. But after I pass an input with valid shape and dtype. it will give me an error complaining about the input.\r\n\r\n**Describe the expected behavior**\r\n\r\nAll of these mentioned above did not happen to the original model.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/drive/1_UAEoZDamfmtnyiMEkMVlbdzwf9qCbwm?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n: ---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-11-dac3dfc084ae> in <module>\r\n----> 1 _,l,grads_value = my_func2(img)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)\r\n   3822       self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\r\n   3823 \r\n-> 3824     fetched = self._callable_fn(*array_vals,\r\n   3825                                 run_metadata=self.run_metadata)\r\n   3826     self._call_fetch_callbacks(fetched[-len(self._fetches):])\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)\r\n   1468       try:\r\n   1469         run_metadata_ptr = tf_session.TF_NewBuffer() if run_metadata else None\r\n-> 1470         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1471                                                self._handle, args,\r\n   1472                                                run_metadata_ptr)\r\n\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\r\n\t [[{{node input_1_5}}]]\r\n\t [[Func/gradients/quant_block2_conv1/cond_1_grad/StatelessIf/then/_1388/input/_3903/_1395]]\r\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\r\n\t [[{{node input_1_5}}]]\r\n", "comments": ["i am able to replicate this error on tf 2.3,2.4 and nightly, please find the [gist here.](https://colab.research.google.com/gist/Saduf2019/22e6ba2b809da57124a2ccf1286e4ea1/untitled572.ipynb)", "Any updates on this? Thanks! @jvishnuvardhan @Saduf2019 ", "Any updates on this? Thanks! @jvishnuvardhan @Saduf2019", "Was able to replicate the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/bfca66f6c76b63367db818a314008654/untitled177.ipynb)..Thanks !", "Was able to replicate the issue with TF 2.6.0-dev20210606,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/88d533c6bd4d49433cecf26be10214d7/untitled249.ipynb) ..Thanks!"]}, {"number": 48001, "title": "No OpenCL for GPU delegate on Android 12", "body": "* Device: Google Pixel 4\r\n* OS: Android 12 developer preview 2\r\n* TensorFlow Lite: 2.4.0\r\n* TensorFlow Lite GPU delegate: 2.4.0\r\n* TensorFlow Lite support: 0.1.0\r\n\r\nCalling `Interpreter.runForMultipleInputsOutputs` with pre-configured GPU delegate results in the following message:\r\n\r\n```\r\nCUSTOM TFLite_Detection_PostProcess: Operation is not supported.\r\nDEQUANTIZE: \r\n310 operations will run on the GPU, and the remaining 2 operations will run on the CPU.\r\nCan not open OpenCL library on this device - dlopen failed: library \"libOpenCL.so\" not found\r\nFalling back to OpenGL\r\n```\r\n\r\nThere is no such message on Android 11 (and the same device). As a result, the executing time is higher than it was before (with OpenCL available).", "comments": ["@impjdi could you take a look at this report?", "@arturdryomov FYR. On my Pixel 4 running Android 12 DP 2, I could find /vendor/lib64/libOpenCL.so and I can use `benchmark_model --use_gpu=1 ...` without problems.", "True, for some reason the native benchmark binary with `--use_gpu=true` is fine. Investigating further what happens during regular APK execution.\r\n\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: Following operations are not supported by GPU delegate:\r\nCUSTOM TFLite_Detection_PostProcess: TFLite_Detection_PostProcess\r\nDEQUANTIZE: \r\n310 operations will run on the GPU, and the remaining 2 operations will run on the CPU.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nExplicitly applied GPU delegate, and the model graph will be partially executed by the delegate w/ 1 delegate kernels.\r\n```", "I just flashed my Pixel 4 with Android 12 and I get:\r\n\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\n64 operations will run on the GPU, and the remaining 0 operations will run on the CPU.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\n```\r\n\r\nso it looks like it's able to find the OpenCL libraries.\r\n\r\n```\r\n$ adb shell\r\n$ find . -name \"libOpenCL*.so\" 2> /dev/null\r\n./vendor/lib/libOpenCL-pixel.so\r\n./vendor/lib/libOpenCL.so\r\n./vendor/lib64/libOpenCL-pixel.so\r\n./vendor/lib64/libOpenCL.so\r\n```", "Seems like we\u2019ve found the issue. The target SDK changes the behavior.\r\n\r\n```kotlin\r\ntargetSdkVersion(30)\r\n```\r\n```\r\nI/tflite: Created TensorFlow Lite delegate for GPU.\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nI/tflite: Initialized OpenCL-based API.\r\nI/tflite: Created 1 GPU delegate kernels.\r\n```\r\nvs.\r\n```kotlin\r\ntargetSdkVersion(\"S\")\r\n```\r\n```\r\nI/tflite: Created TensorFlow Lite delegate for GPU.\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nI/tflite: Initialized OpenGL-based API.\r\nI/tflite: Created 1 GPU delegate kernels.\r\n```", "FYI \u2014\u00a0I\u2019ve created [an Android 12 issue](https://issuetracker.google.com/issues/183419289) for this, not sure if it will produce useful results though. Can I ask some internal Google folks to reach out to the internal platform team? Might be more productive.", "YAFYI \u2014\u00a0attached a sample project and described steps to reproduce in the Android issue mentioned above.", "Can I ask where you set targetsdkversion 30?\r\nThere's nothing in https://github.com/tensorflow/tensorflow/search?q=targetsdkversion&type=code\r\n\r\nI suspect something got to do with targetsdkversion > 24 behaviour in https://developer.android.com/about/versions/nougat/android-7.0-changes#ndk", "It\u2019s not about the TensorFlow target SDK. TensorFlow dependencies are used as-is but the client application declares the `S` target SDK. PTAL at the Google issue linked above \u2014\u00a0it has a sample project.", "@impjdi, hey, do you have ideas what might go wrong with the target SDK version? Maybe there are some internal Google folks who can elaborate on this. The Android issue is pretty much silent.", "We have an internal bug system and this is being investigated, but personally, I'm clueless as I don't go through any code path that does something like setting the SDK version (i.e. I have no idea when you talk about `targetSdkVersion()`).  I'll report back when I find something =/", "My current guess is that using Android 12 as a target SDK prevents applications (which are TF consumers) from linking to system binaries. As a result, OpenCL exists but cannot be linked to. When Android detects lower target SDK, rules are relaxed and the linking is allowed.", "Quoting some internal thread (sorry, I don't understand what these mean):\r\n\r\n> For Android 12 target sdk the developer must use <uses-native-library> with libOpenCL-pixel.so and libOpenCL.so.\r\n> See ENFORCE_NATIVE_SHARED_LIBRARY_DEPENDENCIES section in https://developer.android.com/about/versions/12/reference/compat-framework-changes", "Yep, got the same thing on the public tracker. Thanks! Gonna check if it helps.", "@arturdryomov Could you please let us know if you still need help on this ? if it is resolved then please feel free to move this issue to close status ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@kumariko, according [to the Google issue](https://issuetracker.google.com/issues/183419289) conversation \u2014\u00a0a manifest declaration is required to use OpenCL. It would be great if the TF AAR included such declarations so the manifest merger could propagate them to consumer applications."]}, {"number": 47998, "title": "attr.s decorated keras Layers broken in keras.Sequential", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.4.1  (installed with miniconda)\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GTX1660, 6GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nIf a custom layer implementation uses the `@attr.s` decorated (e.g. for parameter validation), it will break its use in `Sequential`. It otherwise seems to function correctly in other usages.\r\n\r\nWithin `Sequential`, the decorated custom layer is flattened into its attributes used for creation instead of a Layer object.\r\n\r\n**Describe the expected behavior**\r\n\r\nUsing the `@attr.s` should not break its use in `Sequential`.\r\n`nest.flatten` in utils should keep the custom layer as a `Layer` object.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport attr\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import Model, Sequential\r\n\r\n@attr.s(eq=False)\r\nclass TestLayer(layers.Layer):\r\n    _n_out: int = attr.ib(validator=lambda i, a, x: x>=8)\r\n    \r\n    def __attrs_post_init__(self):\r\n        super().__init__()\r\n        self.fn = layers.Conv2D(self._n_out, 3, activation='relu')\r\n    \r\n    def call(self, x, **kwargs):\r\n        return self.fn(x, **kwargs)\r\n    \r\n\r\nm = Sequential([TestLayer(8), layers.Dense(1)])\r\n\r\nm.build([None, 128, 128, 3])\r\n```\r\n\r\nPossible cause of issue from within `Sequential` implementation:\r\n```\r\nfrom tensorflow.python.util import nest\r\n\r\nnest.flatten(TestLayer(8)) # returns [8], should be [ TestLayer at <0x???????>]\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-9c0118781b91> in <module>\r\n     13 m = Sequential([TestLayer(8), layers.GlobalMaxPooling2D(), layers.Dense(1)])\r\n     14 \r\n---> 15 m.build([None, 128, 128, 3])\r\n\r\n~/miniconda3/envs/genesis_dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in build(self, input_shape)\r\n    345       if input_shape is None:\r\n    346         raise ValueError('You must provide an `input_shape` argument.')\r\n--> 347       self._build_graph_network_for_inferred_shape(input_shape)\r\n    348       if not self.built:\r\n    349         input_shape = tuple(input_shape)\r\n\r\n~/miniconda3/envs/genesis_dev/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    515     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    516     try:\r\n--> 517       result = method(self, *args, **kwargs)\r\n    518     finally:\r\n    519       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/miniconda3/envs/genesis_dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in _build_graph_network_for_inferred_shape(self, input_shape, input_dtype)\r\n    320               raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\r\n    321             # Keep track of nodes just created above\r\n--> 322             track_nodes_created_by_last_call(layer, created_nodes)\r\n    323             layer_input = layer_output\r\n    324             outputs = layer_output\r\n\r\n~/miniconda3/envs/genesis_dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in track_nodes_created_by_last_call(layer, created_nodes)\r\n    566   prev_layers = layer._inbound_nodes[-1].inbound_layers\r\n    567   for prev_layer in nest.flatten(prev_layers):\r\n--> 568     if prev_layer._outbound_nodes:\r\n    569       created_nodes.add(prev_layer._outbound_nodes[-1])\r\n\r\nAttributeError: 'int' object has no attribute '_outbound_nodes'\r\n```\r\n", "comments": ["@moodoki \r\nCan you please refer to similar issues and let us know: [link](https://stackoverflow.com/questions/51181754/keras-tensorflow-convlstm2d-object-has-no-attribute-outbound-nodes)", "@Saduf2019 Linked issue seems unrelated, it's referring to a problem with Keras layer implementation differences but this is not the case here. I'm only using `tf.keras`. \r\n\r\nFurthermore, the problem is due to a different `flatten`. \r\nThe issue with `tensorflow.python.util.nest.flatten` here is not the similarly named `tf.keras.layers.Flatten()`\r\n\r\n`nest.flatten` is something that's internal to TensorFlow and used internally by `Sequential` to unpack dictionaries and nested lists to flat lists. From its name and implementation, it appears to be purely a python wrapper utility function. \r\n\r\n`layers.Flatten()` is a Keras layer that reshapes tensors. ", "I am able to replicate the issue on [tf 2.4 and nightly](https://colab.research.google.com/gist/Saduf2019/4cb28eafacf7cd460672aafc490cdfc5/untitled574.ipynb) but the issue is not reproducible on tf 2.3, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/61c2cdd0a4792dd073d68ce7f802a0ea/untitled572.ipynb).", "Was able to replicate the issue in TF 2.6.0-dev20210601,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/8db11e7912a9e3084e22ff13d9b0cd0b/untitled178.ipynb)..Thanks !"]}, {"number": 47996, "title": "Segmentation fault for tflite Interpreter", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): nightly pypi\r\n- TensorFlow version (use command below): v1.12.1-53437-g58a2aa4a353 2.5.0-dev20210322\r\n- Python version: 3.7.6\r\n\r\n**Describe the current behavior**\r\n\r\nGetting `Segmentation fault (core dumped)`\r\n\r\n**Describe the expected behavior**\r\n\r\nNo segmentation faults so I can figure out what's wrong with my script, e.g. how do I pass it a base64 image, like this with serving:\r\n\r\n```python\r\nimport json\r\nfrom base64 import b64encode\r\n\r\n# encode img\r\nwith img.open(\"rb\") as image_file:\r\n    img_data = b64encode(image_file.read())\r\n    data = json.dumps({\r\n        \"signature_name\": \"serving_default\",\r\n        \"inputs\": {\r\n            \"input\": {\r\n                \"b64\": img_data.decode('utf-8')\r\n            }\r\n        }\r\n    })\r\n# make request\r\nres = requests.post(url, data=data)\r\nresponse = res.json()\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport argparse\r\nimport time\r\nfrom io import BytesIO\r\nfrom pprint import pprint\r\nfrom pathlib import Path\r\nfrom base64 import b64encode\r\n\r\nimport numpy as np\r\nimport tensorflow as tf # TF2\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '-i',\r\n      '--image',\r\n      default='captchas/captcha-0b81fccb-85e3-4ae4-8da5-f090b9dc7ada.jpg',\r\n      help='image to be classified')\r\n  parser.add_argument(\r\n      '-m',\r\n      '--model_file',\r\n      default='model.tflite',\r\n      help='.tflite model to be executed')\r\n  parser.add_argument(\r\n      '--num_threads', default=1, type=int, help='number of threads')\r\n  args = parser.parse_args()\r\n\r\n  interpreter = tf.lite.Interpreter(\r\n      model_path=args.model_file\r\n  )\r\n  interpreter.allocate_tensors()\r\n\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n\r\n  with Path(args.image).open(\"rb\") as image_file:\r\n      img_data = b64encode(image_file.read())\r\n      img_tensor = img_data.decode('utf-8')\r\n\r\n  interpreter.set_tensor(input_details[0]['index'], img_tensor)\r\n\r\n  start_time = time.time()\r\n  interpreter.invoke()\r\n  stop_time = time.time()\r\n\r\n  output_data = interpreter.get_tensor(output_details[0]['index'])\r\n  results = np.squeeze(output_data)\r\n\r\n  print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))\r\n```\r\n\r\n**Other info / logs**\r\n\r\nScript output:\r\n\r\n```\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n2021-03-23 03:00:54.956373: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nINFO: TfLiteFlexDelegate delegate: 17 nodes delegated out of 1614 nodes with 10 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 2 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 4 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 4 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 1 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 14 nodes delegated out of 30 nodes with 3 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 6 nodes with 2 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 7 nodes with 2 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 6 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 7 nodes with 2 partitions.\r\n\r\nSegmentation fault (core dumped)\r\n```\r\n", "comments": ["@thijstriemstra  Could you share reproducible steps?", "I can post the model that I converted using your help in #47050 @abattery. When you try the above script I'm 99% it will segfault with the converted tflite model. I'm not sure what to do to debug the segfault.", "Could you provide reproducible minimal steps for your problem from creating a TF model to executing inferences in a form of the gist? Or could you share the converted model with the tf-nightly version?\r\n\r\nCould you make sure the given above input is valid for the TF model as well? If it is not valid for the TF model, the TFLite model won't work as well.", "I have a model that was trained using tensorflow 1. I am using it with `tensorflow-model-server` to serve it using a REST API. To illustrate what arguments I pass to that server:\r\n\r\n```python\r\nimport requests\r\nfrom base64 import b64encode\r\n\r\nurl = 'url of tensorflow-model-server'\r\n\r\n# encode img\r\nwith captcha.open(\"rb\") as image_file:\r\n    img_data = b64encode(image_file.read())\r\n    data = json.dumps({\r\n        \"signature_name\": \"serving_default\",\r\n        \"inputs\": {\r\n            \"input\": {\r\n                \"b64\": img_data.decode('utf-8')\r\n            }\r\n        }\r\n    })\r\n\r\n# make request\r\nres = requests.post(url, data=data)\r\nresponse = res.json()\r\n```\r\n\r\nso I have a single tensor (?) that expects a base64 encoded string of the image.\r\n\r\nNow that the model has been converted to tensorflow lite 2.x (with your help in #47050) using this script:\r\n\r\n```python\r\nimport sys\r\nfrom pathlib import Path\r\n\r\nimport tensorflow as tf\r\n\r\n# Specify the model.\r\nsaved_model_dir = Path('training/Model/admin/test2/1/exported-model/1/')\r\n\r\nif saved_model_dir.exists():\r\n    print(f'Converting model: {str(saved_model_dir)}')\r\nelse:\r\n    print(f'Could not find model: {str(saved_model_dir)}')\r\n    sys.exit(1)\r\n\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\r\n]\r\nmodel = converter.convert()\r\n\r\n# Save the model.\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(model)\r\n\r\nprint('Ready.')\r\n```\r\n\r\nI eventually want to use tensorflow lite on a raspberry pi with this `model.tflite` file (download file [here](https://we.tl/t-1hj8zgHfjj)).\r\n\r\nSo I created a script to test the model. Problem is, I don't know how to supply the base64 image data to the model. After testing several things the script started to throw a segmentation fault.\r\n\r\nSo simply running this basic script (I commented out my attempt to pass the image) results in a segfault. This is a bug isn't it?\r\n\r\n```python\r\nimport argparse\r\nimport time\r\nfrom io import BytesIO\r\nfrom pprint import pprint\r\nfrom pathlib import Path\r\nfrom base64 import b64encode\r\n\r\nimport numpy as np\r\nimport tensorflow as tf # TF2\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '-i',\r\n      '--image',\r\n      default='captchas/captcha-0b81fccb-85e3-4ae4-8da5-f090b9dc7ada.jpg',\r\n      help='image to be classified')\r\n  parser.add_argument(\r\n      '-m',\r\n      '--model_file',\r\n      default='model.tflite',\r\n      help='.tflite model to be executed')\r\n  args = parser.parse_args()\r\n\r\n  interpreter = tf.lite.Interpreter(\r\n      model_path=args.model_file\r\n  )\r\n  interpreter.allocate_tensors()\r\n\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n\r\n  #with Path(args.image).open(\"rb\") as image_file:\r\n  #    img_data = b64encode(image_file.read())\r\n  #    img_tensor = img_data.decode('utf-8')\r\n  #\r\n  #interpreter.set_tensor(input_details[0]['index'], img_tensor)\r\n\r\n  start_time = time.time()\r\n  interpreter.invoke()\r\n  stop_time = time.time()\r\n\r\n  output_data = interpreter.get_tensor(output_details[0]['index'])\r\n  results = np.squeeze(output_data)\r\n\r\n  print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))\r\n```", "Hi @thijstriemstra ! 1.x versions are not supported any more. Can you check this [thread ](https://github.com/tensorflow/hub/issues/192#issuecomment-608397532)on serving b64 images though?  Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 47994, "title": "tf.data.experimental.snapshot should allow providing custom hash", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.0\r\n- Are you willing to contribute it (Yes/No): Ues\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nUsers may want to specify a custom hash_code to control the behavior of when snapshot enters read vs. write mode.\r\nAs an example: If snapshot is generated outside of training, and the dataset call-chain/graph is guaranteed to be unchanged,\r\nthen a simple hash function can checksum all the input files and generate a hash_code.\r\n\r\nAs long as the input dataset remains the same during training, the hash function can generate the same hash_code, and the\r\ngenerated snapshots would be read. If the input dataset is different, the hash function would generate a new hash_code,\r\nand therefore the SnapshotDataset op would generate new snapshots.\r\n**Will this change the current api? How?**\r\nIt will expose a new optional parameter `hash_code` in the current `tf.data.experimental.snapshot` api.\r\n**Who will benefit with this feature?**\r\nAll users of `tf.data.experimental.snapshot` who\r\n**Any Other info.**\r\nThis extends the capability exposed in the C++ API: https://github.com/tensorflow/tensorflow/commit/cbc7f31b7d6aac81158be084201d3b3e8e346907\r\n", "comments": []}, {"number": 47989, "title": "DOC: CONTRIBUTING.md Sanity Check guide not working", "body": "If I try running the [instructions in CONTRIBUTING.md](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-sanity-check):\r\n\r\n```bash\r\ntensorflow/tools/ci_build/ci_build.sh CPU tensorflow/tools/ci_build/ci_sanity.sh\r\n```\r\n\r\nI get:\r\n\r\n```\r\n#10 1.118 /install/install_pip_packages.sh: line 21: python3.6: command not found\r\n```\r\n\r\nHowever, if I instead use the `cpu-py3.6` image, I get a bit further:\r\n\r\n```bash\r\naddgroup: Please enter a username matching the regular expression configured via the NAME_REGEX[_SYSTEM] configuration variable.\r\n Use the `--force-badname' option to relax this check or reconfigure NAME_REGEX.\r\n```\r\n\r\nI don't see any way for users to fix this without diving into the plethora of different Dockerfiles and scripts-calling scripts that exist in the repo.", "comments": ["We are trying to simplify/unify Dockerfiles at https://github.com/tensorflow/build/pull/21\r\nWe are also trying to improve linting integration. See https://github.com/tensorflow/tensorflow/issues/41396\r\n\r\nI the meantime I see:\r\n> /install/install_pip_packages.sh: line 21: python3.6: \r\n\r\nwhich branch/commit are you on? Cause on master we are on `python 3.8` as https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh#L126\r\n", "Just in case, I tested on the master (as of today at f1497fc92) and got the same thing. In fact, here is the call to `python3.6`:\r\nhttps://github.com/tensorflow/tensorflow/blob/f1497fc92ed09a2c2bd03c586c72019d4c97dca6/tensorflow/tools/ci_build/install/install_pip_packages.sh#L21", "Ok so it is in the image building phase. Yes this need to be fixed cause the image was still on python 3.5.\r\n\r\nAs an additional note `tensorflow/tools/ci_build/ci_sanity.sh` currently couldn't run also in our official devel image `tensorflow/tensorflow:devel`", "/cc @theadactyl ", "Until this is resolved, is there any way for contributors to run tests?", "Maybe not directly at the moment, but \"Ubuntu Sanity\" on the PR status runs the same tests.", "Yes but someone working at Google has to manually trigger that AFAIK, which introduces several days of lag every time tests need to be run. And as we all know you can be trying to fix one issue only to create another, etc. Something that should take hours ends up taking weeks.\r\n\r\nTesting, especially \"sanity\"/linting but arguably unit tests as well, should be easy and fast to run so that developers can get feedback on their changes ASAP and iterate.", "@angerson Just a reminder. If we are working in a Docker container these scripts require Docker in Docker and I it is not the best experience.", "@adriangb In the meantime I will discuss this with @angerson you can look at https://github.com/tensorflow/tensorflow/pull/48291"]}]