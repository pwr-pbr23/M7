[{"number": 51440, "title": "tf.identity cannot support a tuple value", "body": "I have recently use v1.13 of Tensorflow.\r\nIn my code:\r\n```\r\ntopk = tf.nn.top_k(out_softmax, k=100)\r\nwith tf.control_dependencies([some ops]):\r\n      topk = tf.identity(topk)\r\n      # topk[0] = tf.identity(topk[0])\r\n      # topk[1] = tf.identity(topk[1])\r\n```\r\nit shows \uff1a \r\n```\r\nTypeError: Cannot convert a list containing a tensor of dtype <dtype: 'int32'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'Xpredict__scope__/TopKV2:1' shape=(?, 100) dtype=int32>)\r\n````\r\n\r\nor \r\n\r\n```\r\nTypeError: 'TopKV2' object does not support item assignment\r\n```\r\nhow can i fix it ?", "comments": ["@sddi ,\r\nCan you please elaborate about your Feature. Also, please specify the Use Cases for this feature. Thanks!\r\n", "Also We can see you are using tf v1.13, can you please update to latest stable tensorflow version(v2.5) and let us know if the issue still persists.Thanks!", "> Also We can see you are using tf v1.13, can you please update to latest stable tensorflow version(v2.5) and let us know if the issue still persists.Thanks!\r\n\r\nIn my team, it just support v1.13. \r\ncases:\r\n```\r\nlogits = tf.add(tf.matmul(hidden_out, weights[\"layer_1\"]), weights[\"layer_1_bias\"])\r\nout_softmax = tf.nn.softmax(logits)\r\ntopk = tf.nn.top_k(out_softmax, k=100)\r\nwith tf.control_dependencies(user_define_ops): # user_define_ops: just like some assign ops (using tf.assign ):\r\n        topk = tf.identity(topk)\r\n...\r\nres = sess.run([topk])\r\n```\r\nthen  when i run my code, is shows the errors.", "@sddi ,\r\nAs  mentioned can you please update to latest stable tensorflow version(v2.5) as v1.x is not actively supported and let us know if the issue still persists.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51437, "title": "AUC in the Classification on imbalanced data tutorial ", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/structured_data/imbalanced_data#check_training_history_2\r\n\r\n## Description of issue (what needs changing):\r\nIn the documentation, the resampled model has the highest AUC, as shown below, but [the chart](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#plot_the_roc_3) shows that the baseline AUC is the highest. I think the AUC calculated by model.evaluate method may be incorrect.\r\n\r\n>Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives.\r\n\r\n```\r\n# AUC calculated by model.evaluate method\r\n\r\n# baseline\r\n0.9296237826347351\r\n\r\n# weighted\r\n0.9428448677062988\r\n\r\n# resampled\r\n0.9575912952423096\r\n```\r\n\r\nI have tried other methods to check the correct value. The result of calculating the AUC using the sklearn.metrics.roc_auc_score method is as follows. As expected, it can be confirmed that the AUC of the baseline is the highest.\r\n\r\n```\r\n# AUC calculated by sklearn.metrics.roc_auc_score method\r\n\r\nbaseline_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_baseline) \r\nweighted_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_weighted)  \r\nresampled_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_resampled) \r\n\r\n# baseline\r\n0.9685415795364084\r\n\r\n# weighted\r\n0.9387766618590307\r\n\r\n# resampled\r\n0.9665411665226982\r\n```\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAfter confirming this issue with other people, I will make a pull request.\r\n\r\n", "comments": ["@yoheimiyamoto In order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!\r\n", "@sushreebarsa \r\n>In order to expedite the trouble-shooting process here,Could you please fill the issue template\r\n\r\nDone. Thanks.", "Thanks for your issue. The tutorial discusses model training with imbalanced dataset ; Baseline model is trained on imbalanced data which shows low auc and is attempted to improve by using techniques such as oversampling.\r\nThe resampled dataset shows higher auc since the model is trained on oversampled dataset which eliminates the class imbalance.\r\nTherefore I think the higher auc value in resampled than the baseline model is correct.\r\nHope this helps. Thanks!", "@ymodak \r\nThank you for your reply.\r\n\r\n>I think the higher auc value in resampled than the baseline model is correct.\r\n\r\nAUC value in resampled is not higher than baseline model.\r\n\r\n```\r\n# baseline\r\n0.9296237826347351\r\n\r\n# weighted\r\n0.9428448677062988\r\n\r\n# resampled\r\n0.9575912952423096\r\n```\r\n## ROC Curve in TensorFlow Blog\r\n![ROC Curve](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data_files/output_fye_CiuYrZ1U_1.png)"]}, {"number": 51436, "title": "Karen/r2.6", "body": "Adding LEGAL-NOTICE and third-party-programs.txt for the release.", "comments": []}, {"number": 51435, "title": "(TF-TRT) Refactor \"convert_nodes_test.cc\" by breaking out major GTest fixture interfaces + other cleanup.", "body": "Builds upon this [PR](https://github.com/tensorflow/tensorflow/pull/51235). Only commits from `TF-TRT: Elide dangerous absl::string_view...` are relevant here.\r\n\r\nThis PR's changes are:\r\n\r\nLarger changes:\r\n1. It breaks out the operation conversion GTest test fixture classes into a sub-folder `tf2tensorrt/convert/fixtures`. The actual test instantiations `TEST_F(..., ...)` remain in place in `convert_nodes_test.cc`. The purpose of this is to improve clarity of the unit tests, as currently `convert_nodes_test.cc` has a mess of utility functions, and the test fixture classes chained via inheritance further add to the confusion. By breaking out the fixtures (and separating their definition/implementations), it's easier to understand and assess further improvements for the test infrastructure.\r\n\r\nMedium:\r\n1. Change unit tests for Converter::PrepareTensorForShape into a\r\nvalue-parameterized test suite.\r\n2. Change unit tests for Converter quantization helpers into\r\ntype-parameterized test suite.\r\n3. Create `nvinfer_factory` namespace with utility methods as appropriate under `common/util.h`. This replaces various \"CreateDimsFromX\" functions.\r\n4. Pulled methods out of the OpConverter test fixtures for creating `tensorflow::Tensor` objects with ManagedGpuAllocator and bundled into class `TensorFactory` under `utils/`. \r\n\r\nSmall:\r\n1. Add `ostream<<(ostream, TRT_ShapedWeights)` printing operator so GTest prints reasonable values for TRT_ShapedWeights.\r\n2. Remove incorrect string_view usage in Converter\r\n3. Rearrange utility functions for InputOutputData and nvinfer1::Dims", "comments": ["@bixia1 \r\n@tfeher ", "@christopherbate  Can you please resolve conflicts? Thanks!\r\n", "Closing this in favor of a  more structured refactor later", "Closing this in favor of a more structured refactor later"]}, {"number": 51432, "title": "Update release notes for 2.6.0 release and patch releases", "body": null, "comments": []}, {"number": 51431, "title": "AutoGraph warning when using auto-keras", "body": "I was running auto-keras StructuredDataRegressor in Kaggle notebook, when this warning appeared:\r\n\r\nWARNING: AutoGraph could not transform function <function Model.make_train_function.<locals>.train_function at ... and will run it as-is.\r\nPlease report this to the TensorFlow team.\r\nCause: closure mismatch, requested ('self', 'step_function'), but source function had ()\r\n\r\nThe search for regression model seams to be working, but the warning appears at every trial.\r\n\r\nThis is the dataset I was using: https://www.kaggle.com/c/tabular-playground-series-aug-2021\r\n\r\nAnd this is the code:\r\n\r\n!pip install autokeras\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.preprocessing import QuantileTransformer\r\nfrom sklearn.model_selection import train_test_split\r\nimport tensorflow as tf\r\nimport autokeras as ak\r\n\r\nTRAIN_PATH = '../input/tabular-playground-series-aug-2021/train.csv'\r\nTARGET_NAME = 'loss'\r\nVAL_SIZE = 0.2\r\n\r\ndata_train = pd.read_csv(TRAIN_PATH)\r\n\r\nX = data_train.drop('id', axis='columns')\r\ny = X.pop(TARGET_NAME)\r\n\r\nscaler = QuantileTransformer(output_distribution='normal')\r\nX = scaler.fit_transform(X)\r\n\r\ngroups = pd.cut(\r\n    y, bins=10, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\r\n\r\nx_train, x_valid, y_train, y_valid = train_test_split(\r\n    X, y, stratify=groups, test_size=VAL_SIZE,\r\n    shuffle=True, random_state=0)\r\n\r\nmodel = ak.StructuredDataRegressor(\r\n    overwrite=False, max_trials=100)\r\n\r\nmodel.fit(x_train, y_train, epochs=1,\r\n          validation_data=(x_valid, y_valid))", "comments": ["@D-Katt Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Posted there.", "@D-Katt Thank you for the update! Could you please move this issue to closed status as you have posted it in Keras repo , you will get the right help there.Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51431\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51431\">No</a>\n"]}, {"number": 51430, "title": "Conversion fails at model loading", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.7\r\n- TensorFlow installation (pip package or built from source): pip package\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): v2.6.0-rc2\r\n\r\n### 2. Code\r\n\r\n`converter = tf.lite.TFLiteConverter.from_saved_model(str(SAVED_MODEL_DIR))`\r\n\r\nWhere `SAVED_MODEL_DIR` is a path which contains an efficientnet-b4 in the expected `SavedModel` format.\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nN.A\r\n\r\n### 4. (optional) RNN conversion support\r\n\r\nN.A\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n[output.log](https://github.com/tensorflow/tensorflow/files/6969158/output.log)\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"convert_to_tflite.py\", line 92, in <module>\r\n    main()\r\n  File \"convert_to_tflite.py\", line 74, in main\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(str(SAVED_MODEL_DIR))\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1348, in from_saved_model\r\n    saved_model = _load(saved_model_dir, tags)\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 864, in load\r\n    result = load_internal(export_dir, tags, options)[\"root\"]\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 903, in load_internal\r\n    ckpt_options, options, filters)\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 162, in __init__\r\n    self._load_all()\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 259, in _load_all\r\n    self._load_nodes()\r\n  File \"/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 448, in _load_nodes\r\n    slot_variable = optimizer_object.add_slot(\r\nAttributeError: '_UserObject' object has no attribute 'add_slot'\r\n```", "comments": ["Can you please provide a colab gist that reproduces the issue reported? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51430\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51430\">No</a>\n"]}, {"number": 51427, "title": "tensorflow distribute trainning error", "body": "I just follow mnist_replica.py to write distribution code,when there is bug when run programs.It always report that RuntimeError: Init operations did not make model ready. How to fix it ?\r\nIt seemed when it call prepare_or_wait_for_session and failed\r\nCodes as such below:\r\n ```\r\n if FLAGS.sync_replicas:\r\n            if FLAGS.replicas_to_aggregate is None:\r\n                replicas_to_aggregate = self.num_workers\r\n            else:\r\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\r\n            self.opt = tf.train.SyncReplicasOptimizer(\r\n                self.opt,\r\n                replicas_to_aggregate=replicas_to_aggregate,\r\n                total_num_replicas=self.num_workers,\r\n                name=\"sync\")\r\n\r\n        self.optimizer = self.opt.minimize(self.loss, global_step=self.global_step)\r\n\r\n        # init\r\n        if FLAGS.sync_replicas:\r\n            self.local_init_op = self.opt.local_step_init_op  \r\n            if self.is_chief:\r\n                self.local_init_op = self.opt.chief_init_op  \r\n\r\n            self.ready_for_local_init_op = self.opt.ready_for_local_init_op \r\n            self.chief_queue_runner = self.opt.get_chief_queue_runner()  \r\n            self.sync_init_op = self.opt.get_init_tokens_op()  \r\n\r\n        self.global_var_init_op = tf.global_variables_initializer()\r\n        self.train_auc_value, self.train_auc_op = tf.metrics.auc(self.label, self.out, name=\"train_auc\" + str(FLAGS.task_index))\r\n        self.valid_auc_value, self.valid_auc_op = tf.metrics.auc(self.label, self.out, name=\"valid_auc\" + str(FLAGS.task_index))\r\n        self.local_var_init_op = tf.local_variables_initializer()\r\nif FLAGS.sync_replicas:\r\n            sv = tf.train.Supervisor(\r\n                is_chief=is_chief,\r\n                logdir=train_dir,\r\n                init_op=deepfm.global_var_init_op,\r\n                local_init_op=deepfm.local_init_op,\r\n                ready_for_local_init_op=deepfm.ready_for_local_init_op,\r\n                recovery_wait_secs=1,\r\n                global_step=deepfm.global_step)\r\nsess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\r\n\r\n```", "comments": ["@liumilan ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset , tensorflow version you are using. Thanks!", "Also please take a look at this [comment](https://stackoverflow.com/questions/48017748/in-tensorflow-when-graph-is-modified-how-to-use-monitoredtrainingsession-to-r/48071975#48071975) and [link](https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables) with the similar error.It helps.Thanks", "> Also please take a look at this [comment](https://stackoverflow.com/questions/48017748/in-tensorflow-when-graph-is-modified-how-to-use-monitoredtrainingsession-to-r/48071975#48071975) and [link](https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables) with the similar error.It helps.Thanks\r\n\r\nIt seemed a bit differences. local_init_op , ready_for_local_init_op is got from SyncReplicasOptimizer .And it failed", "```python\r\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\n\r\n\"\"\"Distributed MNIST training and validation, with model replicas.\r\nA simple softmax model with one hidden layer is defined. The parameters\r\n(weights and biases) are located on two parameter servers (ps), while the\r\nops are defined on a worker node. The TF sessions also run on the worker\r\nnode.\r\nMultiple invocations of this script can be done in parallel, with different\r\nvalues for --task_index. There should be exactly one invocation with\r\n--task_index, which will create a master session that carries out variable\r\ninitialization. The other, non-master, sessions will wait for the master\r\nsession to finish the initialization before proceeding to the training stage.\r\nThe coordination between the multiple worker invocations occurs due to\r\nthe definition of the parameters on the same ps devices. The parameter updates\r\nfrom one worker is visible to all other workers. As such, the workers can\r\nperform forward computation and gradient calculation in parallel, which\r\nshould lead to increased training speed for the simple model.\r\n\"\"\"\r\n\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport math\r\nimport sys\r\nimport tempfile\r\nimport time\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\n\r\n\r\n\r\nflags = tf.app.flags\r\nflags.DEFINE_string(\"train_dir\", None, \"Directory for checkpoint file, \"\r\n                    \"please use the HDFS path, expample: hdfs://default/$path\")\r\nflags.DEFINE_string(\"exporter_dir\", None, \"Directory for save model, \"\r\n                    \"please use the HDFS path, expample: hdfs://default/$path\")\r\nflags.DEFINE_string(\"data_dir\", \"/tmp/mnist-data\",\r\n                    \"Directory for storing mnist data\")\r\nflags.DEFINE_boolean(\"download_only\", False,\r\n                     \"Only perform downloading of data; Do not proceed to \"\r\n                     \"session preparation, model definition or training\")\r\nflags.DEFINE_integer(\"task_index\", None,\r\n                     \"Worker task index, should be >= 0. task_index=0 is \"\r\n                     \"the master worker task the performs the variable \"\r\n                     \"initialization \")\r\nflags.DEFINE_integer(\"num_gpus\", 1,\r\n                     \"Total number of gpus for each machine.\"\r\n                     \"If you don't use GPU, please set it to '0'\")\r\nflags.DEFINE_integer(\"replicas_to_aggregate\", None,\r\n                     \"Number of replicas to aggregate before parameter update\"\r\n                     \"is applied (For sync_replicas mode only; default: \"\r\n                     \"num_workers)\")\r\nflags.DEFINE_integer(\"hidden_units\", 100,\r\n                     \"Number of units in the hidden layer of the NN\")\r\nflags.DEFINE_integer(\"train_steps\", 200,\r\n                     \"Number of (global) training steps to perform\")\r\nflags.DEFINE_integer(\"batch_size\", 100, \"Training batch size\")\r\nflags.DEFINE_float(\"learning_rate\", 0.01, \"Learning rate\")\r\nflags.DEFINE_boolean(\"sync_replicas\", False,\r\n                     \"Use the sync_replicas (synchronized replicas) mode, \"\r\n                     \"wherein the parameter updates from workers are aggregated \"\r\n                     \"before applied to avoid stale gradients\")\r\nflags.DEFINE_boolean(\"existing_servers\", False, \r\n                     \"Whether servers already exists. If True, \"\r\n                     \"will use the worker hosts via their GRPC URLs (one client process \"\r\n                     \"per worker host). Otherwise, will create an in-process TensorFlow \"\r\n                     \"server.\")\r\nflags.DEFINE_string(\"ps_hosts\",\"localhost:2222\",\r\n                    \"Comma-separated list of hostname:port pairs\")\r\nflags.DEFINE_string(\"worker_hosts\", \"localhost:2223,localhost:2224\",\r\n                    \"Comma-separated list of hostname:port pairs\")\r\nflags.DEFINE_string(\"job_name\", None,\"job name: worker or ps\")\r\n\r\nFLAGS = flags.FLAGS\r\n\r\n\r\nIMAGE_PIXELS = 28\r\n\r\n\r\ndef main(unused_argv):\r\n  print(FLAGS.flags_into_string())\r\n  mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\r\n  if FLAGS.download_only:\r\n    sys.exit(0)\r\n\r\n  if FLAGS.job_name is None or FLAGS.job_name == \"\":\r\n    raise ValueError(\"Must specify an explicit `job_name`\")\r\n  if FLAGS.task_index is None or FLAGS.task_index == \"\":\r\n    raise ValueError(\"Must specify an explicit `task_index`\")\r\n  if FLAGS.train_dir is not None and not FLAGS.train_dir.startswith(\"hdfs://default\"):\r\n    raise ValueError(\"`train_dir` Must begin with hdfs://default\")\r\n  if FLAGS.exporter_dir is not None and not FLAGS.exporter_dir.startswith(\"hdfs://default\"):\r\n    raise ValueError(\"`exporter_dir` Must begin with hdfs://default\")\r\n\r\n  print(\"job name = %s\" % FLAGS.job_name)\r\n  print(\"task index = %d\" % FLAGS.task_index)\r\n\r\n  #Construct the cluster and start the server\r\n  ps_spec = FLAGS.ps_hosts.split(\",\")\r\n  worker_spec = FLAGS.worker_hosts.split(\",\")\r\n\r\n  # Get the number of workers.\r\n  num_workers = len(worker_spec)\r\n\r\n  cluster = tf.train.ClusterSpec({\r\n      \"ps\": ps_spec,\r\n      \"worker\": worker_spec})\r\n\r\n  if not FLAGS.existing_servers:\r\n    # Not using existing servers. Create an in-process server.\r\n    server = tf.train.Server(\r\n        cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\r\n    if FLAGS.job_name == \"ps\":\r\n      server.join()\r\n\r\n  is_chief = (FLAGS.task_index == 0)\r\n\r\n  if FLAGS.num_gpus > 0:\r\n    #if FLAGS.num_gpus < num_workers:\r\n    #  raise ValueError(\"number of gpus is less than number of workers\")\r\n    # Avoid gpu allocation conflict: now allocate task_num -> #gpu \r\n    # for each worker in the corresponding machine\r\n    gpu = (FLAGS.task_index % FLAGS.num_gpus)\r\n    worker_device = \"/job:worker/task:%d/gpu:%d\" % (FLAGS.task_index, gpu)\r\n  elif FLAGS.num_gpus == 0:\r\n    # Just allocate the CPU to worker server\r\n    cpu = 0\r\n    worker_device = \"/job:worker/task:%d/cpu:%d\" % (FLAGS.task_index, cpu)\r\n  # The device setter will automatically place Variables ops on separate\r\n  # parameter servers (ps). The non-Variable ops will be placed on the workers.\r\n  # The ps use CPU and workers use corresponding GPU\r\n  with tf.device(\r\n      tf.train.replica_device_setter(\r\n          worker_device=worker_device,\r\n          ps_device=\"/job:ps/cpu:0\",\r\n          cluster=cluster)):\r\n   \r\n    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\r\n\r\n    # Variables of the hidden layer\r\n    hid_w = tf.Variable(\r\n        tf.truncated_normal(\r\n            [IMAGE_PIXELS * IMAGE_PIXELS, FLAGS.hidden_units],\r\n            stddev=1.0 / IMAGE_PIXELS),\r\n        name=\"hid_w\")\r\n    hid_b = tf.Variable(tf.zeros([FLAGS.hidden_units]), name=\"hid_b\")\r\n\r\n    # Variables of the softmax layer\r\n    sm_w = tf.Variable(\r\n        tf.truncated_normal(\r\n            [FLAGS.hidden_units, 10],\r\n            stddev=1.0 / math.sqrt(FLAGS.hidden_units)),\r\n        name=\"sm_w\")\r\n    sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\r\n\r\n    # Ops: located on the worker specified with FLAGS.task_index\r\n    x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\r\n    y_ = tf.placeholder(tf.float32, [None, 10])\r\n\r\n    hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\r\n    hid = tf.nn.relu(hid_lin)\r\n\r\n    y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\r\n    cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\r\n\r\n    opt = tf.train.AdamOptimizer(FLAGS.learning_rate)\r\n\r\n    if FLAGS.sync_replicas:\r\n      if FLAGS.replicas_to_aggregate is None:\r\n        replicas_to_aggregate = num_workers\r\n      else:\r\n        replicas_to_aggregate = FLAGS.replicas_to_aggregate\r\n      opt = tf.train.SyncReplicasOptimizer(\r\n          opt,\r\n          replicas_to_aggregate=replicas_to_aggregate,\r\n          total_num_replicas=num_workers,\r\n          name=\"mnist_sync_replicas\")\r\n\r\n    train_step = opt.minimize(cross_entropy, global_step=global_step)\r\n\r\n    \r\n    if FLAGS.sync_replicas:\r\n      local_init_op = opt.local_step_init_op\r\n      if is_chief:\r\n        local_init_op = opt.chief_init_op\r\n\r\n      ready_for_local_init_op = opt.ready_for_local_init_op\r\n\r\n      # Initial token and chief queue runners required by the sync_replicas mode\r\n      chief_queue_runner = opt.get_chief_queue_runner()\r\n      sync_init_op = opt.get_init_tokens_op()\r\n    init_op = tf.global_variables_initializer()\r\n    if FLAGS.train_dir is not None:\r\n      train_dir = FLAGS.train_dir\r\n    else:\r\n      train_dir = tempfile.mkdtemp()\r\n\r\n    if FLAGS.sync_replicas:\r\n      sv = tf.train.Supervisor(\r\n          is_chief=is_chief,\r\n          logdir=train_dir,\r\n          init_op=init_op,\r\n          local_init_op=local_init_op,\r\n          ready_for_local_init_op=ready_for_local_init_op,\r\n          recovery_wait_secs=1,\r\n          global_step=global_step)\r\n    else:\r\n      sv = tf.train.Supervisor(\r\n          is_chief=is_chief,\r\n          logdir=train_dir,\r\n          init_op=init_op,\r\n          recovery_wait_secs=1,\r\n          global_step=global_step)\r\n\r\n    sess_config = tf.ConfigProto(\r\n        allow_soft_placement=True,\r\n        log_device_placement=False,\r\n        device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\r\n\r\n    # The chief worker (task_index==0) session will prepare the session,\r\n    # while the remaining workers will wait for the preparation to complete.\r\n    if is_chief:\r\n      print(\"Worker %d: Initializing session...\" % FLAGS.task_index)\r\n    else:\r\n      print(\"Worker %d: Waiting for session to be initialized...\" %\r\n            FLAGS.task_index)\r\n\r\n    if FLAGS.existing_servers:\r\n      server_grpc_url = \"grpc://\" + worker_spec[FLAGS.task_index]\r\n      print(\"Using existing server at: %s\" % server_grpc_url)\r\n\r\n      sess = sv.prepare_or_wait_for_session(server_grpc_url,\r\n                                            config=sess_config)\r\n    else:\r\n      sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\r\n\r\n    print(\"Worker %d: Session initialization complete.\" % FLAGS.task_index)\r\n\r\n    if FLAGS.sync_replicas and is_chief:\r\n      # Chief worker will start the chief queue runner and call the init op.\r\n      sess.run(sync_init_op)\r\n      sv.start_queue_runners(sess, [chief_queue_runner])\r\n\r\n    time_begin = time.time()\r\n    print(\"Training begins @ %f\" % time_begin)\r\n\r\n    local_step = 0\r\n\r\n    while True:\r\n      # Training feed\r\n      batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)\r\n      train_feed = {x: batch_xs, y_: batch_ys}\r\n\r\n      _, step = sess.run([train_step, global_step], feed_dict=train_feed)\r\n      local_step += 1\r\n\r\n      now = time.time()\r\n      print(\"%f: Worker %d: training step %d done (global step: %d)\" %\r\n            (now, FLAGS.task_index, local_step, step))\r\n\r\n      if step >= FLAGS.train_steps:\r\n        break\r\n\r\n    time_end = time.time()\r\n    print(\"Training ends @ %f\" % time_end)\r\n    training_time = time_end - time_begin\r\n    print(\"Training elapsed time: %f s\" % training_time)\r\n\r\n    # Validation feed\r\n    val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\r\n    val_xent = sess.run(cross_entropy, feed_dict=val_feed)\r\n    print(\"After %d training step(s), validation cross entropy = %g\" %\r\n          (FLAGS.train_steps, val_xent))\r\n    print(y)\r\n    if FLAGS.exporter_dir is not None and is_chief:\r\n      print(\"start exporter model...\")\r\n      exporter_dir = FLAGS.exporter_dir\r\n      builder = tf.saved_model.builder.SavedModelBuilder(exporter_dir)\r\n      tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\r\n      tensor_info_y_ = tf.saved_model.utils.build_tensor_info(y_)\r\n      tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\r\n      signature_def_map = {\r\n        \"predict_image\": tf.saved_model.signature_def_utils.build_signature_def(\r\n          inputs={\"x\": tensor_info_x, \"y_\": tensor_info_y_},\r\n          outputs={\r\n            \"y\": tensor_info_y,\r\n          },\r\n          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\r\n        )}\r\n      sess.graph._unsafe_unfinalize()\r\n      builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING],\r\n        signature_def_map=signature_def_map, clear_devices=True)\r\n      builder.save()\r\n      print(\"end exporter model...\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  tf.app.run()\r\n`````\r\nThis is code i just follow,and tf version is 1.12.0", "> @liumilan ,\r\n> \r\n> In order to reproduce the issue reported here, could you please provide the complete code and the dataset , tensorflow version you are using. Thanks!\r\n\r\ntf version is 1.12.0", "@liumilan ,\r\n\r\nWe see that you are using tf version 1.12, 1.x is not actively supported, please update to tf stable version 2.5 or 2.6 and let us know if you are using same issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51427\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51427\">No</a>\n"]}, {"number": 51426, "title": "Can MLIR be disabled ?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.4\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nWe compile tensorflow2.4 from source on our new architecture. Bus Error is reported while compiling MLIR. Is MLIR architecture related, and can it be disabled ?\r\n\r\nError log:\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -I/home/loongson/.cache/bazel/_bazel_loongson/1cc7edea620980ed4eb3fa576dab960a/external/local_config_cc -I/usr/opencv3/include -I/usr/caffe/include -MD -MF bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.d '-frandom-seed=bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquote external/llvm-project -iquote bazel-out/loongarch64-opt/bin/external/llvm-project -iquote external/zlib -iquote bazel-out/loongarch64-opt/bin/external/zlib -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVAvailabilityIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVCanonicalizationIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpUtilsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVSerializationGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/loongarch64-opt/bin/external/zlib -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=native' -Wno-sign-compare '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/llvm-project/mlir/lib/Dialect/SPIRV/SPIRVDialect.cpp -o bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\n/tmp/ccHVDr8f.s: Assembler messages:\r\n/tmp/ccHVDr8f.s:203387: Internal error (Bus error).\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["$ gcc --version\r\ngcc (Debian 8.3.0-6.lnd.vec.20) 8.3.0\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n$ ld --version\r\nGNU ld (GNU Binutils for Debian) 2.31.1.20190122\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\n", "How are you compiling it? Does this repro with clean cache and bazelrc set to /dev/null? I see std=c++0x and c++14 specified above which is confusing to see in same build and also c++14 is minimum requirement to build either TensorFlow or MLIR/LLVM. I've not seen that message and we have been testing it on multiple platforms. One can check also in isolation (https://mlir.llvm.org/getting_started/ for instructions to build alone) if this is cause. ", "This does look like a bug in the toolchain you're using to build TF, specifically `gas` from binutils. It might be possible to find a source workaround but that's really hard without knowing what the bug is.\r\n\r\nIs it possible to update your compiler?", "> We compile tensorflow2.4 from source on our new architecture.\r\n\r\nIs `loongarch64-opt` your new architecture? It seems like the assembler for this architecture has a bug and is crashing. As @d0k said, it will be hard for us to help find a workaround without being able to reproduce ourselves.\r\n", "@d0k, @joker-eph,\r\nthanks, it seems our AS has a bug and we are debugging.\r\n\r\ni want to know that could MLIR be disabled. We found with_mlir_support option but it seems not work.\r\nor Can we not use LLVM  on tensorflow2.4 \uff1f We found LLVM is not used when we compile tensorflow1.14 from source. \r\n\r\nthanks a lot.\r\n", "Unfortunately not anymore: MLIR is increasingly used in TensorFlow and won't be optional moving forward. I need to look into what the `with_mlir_support` option controls at the moment, and possibly rename it to be more representative of what it is doing.", "I think it is leftover from when we started and probably hasn't had any effect in OSS in quite some time (was used for an internal round tripping test)", "Thank you very much", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51426\">No</a>\n"]}, {"number": 51425, "title": "import error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10\r\n- TensorFlow version: 1.15\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: conda\r\n- GPU model and memory: CPU\r\n\r\n\r\n\r\n**Describe the problem**\r\nGetting error while importing tensorflow\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n\r\n![Capture](https://user-images.githubusercontent.com/43055935/128979222-c29efaba-82db-451e-aef0-134e16b9a7d2.PNG)\r\n\r\n", "comments": ["@skj092 We see that you are using older version of tensorflow 1.15 which is officially considered as end of life , We recommend that you upgrade to 2.5 and let us know if the issue still persists in newer versions.Thanks!", "Yes, I am able to install and import the latest version successfully. ", "@skj092 Thank you for the update! Could you please confirm if the issue is resolved and feel free to move this issue to closed status ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51425\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51425\">No</a>\n"]}, {"number": 51424, "title": "Stateless mhlo rng_uniform to linalg lowering", "body": "Added lowering from mhlo rng_uniform to linalg.\r\nBased off modified LCG Algorithm from linalg dialect\r\nthat takes into account the element's indices.", "comments": []}, {"number": 51423, "title": "[ROCm]: Updating Matrix Solve Op to use rocSolver", "body": "Changes in this PR:\r\n\r\n1. Adding rocSolver functions to be used in matrix solve op\r\n              CudaSolver and ROCmSolver classes -> GpuSolver class\r\n2.  Merged cuda_solvers.h and rocm_solvers.h into gpu_solvers.h \r\n", "comments": ["@penpornk Can you take a look? ", "@chsigg @cheshire gentle ping", "@chsigg @cheshire @penpornk ping. ", "@chsigg @cheshire @penpornk ping", "@gbaned Any updates on this PR?", "@cheshire can you re-approve to get the ball rolling again?", "@gbaned can we rerun the Ubuntu-CPU test? I did not touch any CPU code in this PR, and I believe the failures to be transient. ", "@stevenireeves  Can you please resolve conflicts? Thanks!", "@gbaned conflicts resolved. ", "@chsigg @cheshire gentle ping.\r\n\r\ncommits to resolve merge conflicts, are invalidating prior approvals and hence the request to approve yet again...thanks", "@cheshire can you please re-review this PR?", "The change got reverted because some internal target included cusolver.h and thus got broken by this change. But I will roll forward with the fix.", "@akuegel can you post on this PR when it is fully integrated?", "Will do, but probably will happen tomorrow because I am waiting for internal approval of the modified change.", "Your change has now been rolled forward again."]}, {"number": 51422, "title": "TfLiteGpuDelegate Init: CONCATENATION: Node 2 is already a consumer of the value 0", "body": "2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Following operations are not supported by GPU delegate:\r\n    DEPTH_TO_SPACE: Operation is not supported.\r\n    DEQUANTIZE: \r\n    13 operations will run on the GPU, and the remaining 23 operations will run on the CPU.\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: TfLiteGpuDelegate Init: CONCATENATION: Node 2 is already a consumer of the value 0\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution I/tflite: Created 0 GPU delegate kernels.\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: TfLiteGpuDelegate Prepare: delegate is not initialized\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Node number 36 (TfLiteGpuDelegateV2) failed to prepare.\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Restored original execution plan after delegate application failure.\r\n2021-08-10 20:31:39.969 15740-15740/org.tensorflow.lite.examples.superresolution E/super_resolution::: Failed to create TFLite interpreter\r\n", "comments": ["@impjdi could you take a look?", "Please attach a tflite model.", "[demo_model.tflite.zip](https://github.com/tensorflow/tensorflow/files/6972604/demo_model.tflite.zip)\r\n@impjdi ", "Yeah, the `CONCAT` node is taking the input 4 times to stitch it together.  This doesn't work on the GPU.  From the shader's point of view, if a shader program takes in input A and input B, they have to be distinct GPU objects.\r\n\r\n@renjie-liu I think TAC could mitigate this use case?  This i s applicable to any op that takes in the same intermediate tensor twice or more.", "@impjdi  I am sorry, my delayed reply.Thank you very much for your reply\r\n\r\n and  now what should i do for this case?\r\n", "Can you elaborate what's happening in that network?  Why do you replicate the input 4 times and then add it with the output of your convolutions?\r\n\r\nAnyway, one obvious trick is to do the replication of input_1 outside the network and then feed 2 input tensors to the network.  This might be the easiest.\r\n\r\nThe other trick is to enforce creation of other textures by `ADD 0` or `MUL 1` and feed that 4 times to a concat, so that the concat reads from 4 different locations rather than the same location 4 times.  However, I'm not sure whether tflite_convert would prune out that sort of trick...", "\r\nThanks for your reply, I will try to do as your recommendation\r\n\r\nI want to train a model about image super-resolution. I am trying to combine residual and depth_to_space ops.\r\n3 channels and 2x up-scale need 12 channels, so I replicate the input 4 times(outputs: 12channels)\r\nthen add with 12 feature channels , and as the final input of depth_to_space\r\n\r\nI am a beginner of tf and don't know if there is something wrong\uff0cAny good suggestions? \r\n\r\n", "Hm, I haven't worked with superres models in the past and can't say what's a good architecture =/\r\n\r\nOne thing to note is that `DEPTH_TO_SPACE` (and any kind of `CONCAT`, `RESHAPE`, `TRANSPOSE`) is bad for GPU performance.  It's generally okay on the CPU side, but GPU is often bounded by memory bandwidth, and those operations are not desired for GPU execution, and we typically ask our neural net architects to design networks around it if they are planning to use GPU primarily.", "It seems impossible to achieve real-time superres on the CPU\uff08>24fps or 30\u300160fps\uff09. so I think GPU should be a good choice\r\nHowever, I feel that TF\u2019s support for mobile SR currently has many limitations. \r\nThank you very much for your reply\u3002\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51422\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51422\">No</a>\n", "@hongye007 I have the same problem when deploy super-resolution model on android device"]}, {"number": 51421, "title": "Depth_to_space", "body": "**System information**\r\n- OS Platform and Distribution (e.g., mac):\r\n- TensorFlow installed from (tensorflow 2.5):\r\n- TFLite: 2.5.0\r\n\r\n2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Following operations are not supported by GPU delegate:\r\n    DEPTH_TO_SPACE: Operation is not supported.\r\n    DEQUANTIZE: \r\n    13 operations will run on the GPU, and the remaining 23 operations will run on the CPU.\r\n\r\n\r\n", "comments": ["How can I use DEPTH_TO_SPACE with GPU support (tflite)?", "@hongye007,\r\n\r\nTensorFlow Lite supports `depth_to_space`. For more details please refer [here](https://www.tensorflow.org/mlir/tfl_ops#tfldepth_to_space_mlirtfldepthtospaceop). \r\n\r\nCurrently TensorFlow Lite on GPU supports only [these](https://www.tensorflow.org/lite/performance/gpu_advanced#supported_ops) ops in 16-bit and 32-bit float precision. Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51420, "title": "Loading checkpoint by skipping the head layer", "body": "Hi all!\r\n\r\nI am using a model (SimCLR) to learn representations from images. While pre-training, the model was trained against a single dummy label. Now I want to fine-tune the model with 8-class data. \r\nWhile loading the pre-trained model checkpoint to the yet to be fine-tuned model with 8-class head I am encountering a ValueError.\r\n\r\n```\r\nValueError: Tensor's shape (2048, 1) is not compatible with supplied shape [2048, 8]\r\n```\r\n\r\nIs there a solution to exclude the last head layer weights before loading to the checkpoint for fine-tuning the model?\r\nIf not, this would be a feature request.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **TensorFlow version**: 2.5.0\r\n-   **Python version**: 3.7.3\r\n\r\n------------------------\r\n\r\nDetailed error log:\r\n```\r\nrun.py:581 single_step  *\r\n        projection_head_outputs, supervised_head_outputs = model(\r\n    /home/uil139/code/simclr/tf2/model.py:269 __call__  *\r\n        supervised_head_outputs = self.supervised_head(supervised_head_inputs,\r\n    /home/uil139/code/simclr/tf2/model.py:224 call  *\r\n        inputs = self.linear_layer(inputs, training)\r\n    /home/uil139/code/simclr/tf2/model.py:152 call  *\r\n        inputs = self.dense(inputs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1023 __call__  **\r\n        self._maybe_build(inputs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2625 _maybe_build\r\n        self.build(input_shapes)  # pylint:disable=not-callable\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:1198 build\r\n        trainable=True)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:655 add_weight\r\n        caching_device=caching_device)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:815 _add_variable_with_custom_getter\r\n        **kwargs_for_getter)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:139 make_variable\r\n        shape=variable_shape if variable_shape else None)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:260 __call__\r\n        return cls._variable_v1_call(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\r\n        shape=shape)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/shared_variable_creator.py:69 create_new_variable\r\n        v = next_creator(**kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2111 creator_with_resource_vars\r\n        created = self._create_variable(next_creator, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:538 _create_variable\r\n        distribute_utils.VARIABLE_POLICY_MAPPING, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_utils.py:306 create_mirrored_variable\r\n        value_list = real_mirrored_creator(**kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:530 _real_mirrored_creator\r\n        v = next_creator(**kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:752 variable_capturing_scope\r\n        lifted_initializer_graph=lifted_initializer_graph, **kwds)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:264 __call__\r\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:293 __init__\r\n        initial_value = initial_value()\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:87 __call__\r\n        self._checkpoint_position, shape, shard_info=shard_info)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:122 __init__\r\n        self.wrapped_value.set_shape(shape)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1240 set_shape\r\n        (self.shape, shape))\r\n\r\n    ValueError: Tensor's shape (2048, 1) is not compatible with supplied shape [2048, 8]\r\n```", "comments": ["@Sdhir In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51420\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51420\">No</a>\n"]}, {"number": 51418, "title": "Cannot properly install packages inside container ", "body": "So I can run the Tensorflow Docker image without issue. However, I have one issue, I know that I am not suppose to run it as root so I run it under my user. When I do this and then try to install packages I get the following message:\r\n\r\n`WARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.`\r\n\r\nThe packages seem to install fine but when I go to import them they are not found. \r\n\r\nHowever, if I run the image as root, there is absolutely no issue and it works fine. \r\nIve searched and I can't seem to find an answer for this issue, I am running the latest stable version. \r\n", "comments": ["@choff5507 ,\r\n\r\nCan you please take a look at this [issue](https://stackoverflow.com/questions/27870003/pip-install-please-check-the-permissions-and-owner-of-that-directory) and [comment](https://github.com/mkdocs/mkdocs/issues/1188#issuecomment-291138434) with similar error.It helps.Thanks!", "The error at that link you provided seems to be similar to what Im encountering. I have not tried running `sudo pip` because `sudo` is not found when I go to run it. When I run the container it's always a new instance and Ive checked my folder permissions in my directory as well and they're under my user so I am not sure what the issue is. I could have missed something as I am relatively new to Linux and Docker. ", "@choff5507 ,\r\n\r\nCan you please try the comment mentioned above and also please follow the steps mentioned in this installation [link](https://www.tensorflow.org/install/docker).It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51418\">No</a>\n"]}, {"number": 51416, "title": "[tf.data] graduate sample_from_datasets API from experimental to tf.data.Dataset", "body": "This PR graduates the `tf.data.experimental.sample_from_datasets` API into `tf.data.Dataset.sample_from_datasets`  by making the following changes:\r\n\r\n- [x] Adds the deprecation decorator for the experimental API.\r\n- [x] Add the sample_from_datasets() method to DatasetV2 class.\r\n- [x] Updates example in documentation with new API.\r\n- [x] Regenerate golden API's.\r\n- [x] Updated the `sample_from_datasets` usage in tests.\r\n- [x] Updated the RELEASE.md file\r\n\r\nTEST LOG\r\n```\r\nINFO: Elapsed time: 13.473s, Critical Path: 12.85s\r\nINFO: 54 processes: 16 internal, 38 local.\r\nINFO: Build completed successfully, 54 total actions\r\n//tensorflow/python/data/experimental/kernel_tests/service:dynamic_sharding_test PASSED in 9.0s\r\n  Stats over 16 runs: max = 9.0s, min = 7.5s, avg = 8.2s, dev = 0.5s\r\n\r\nINFO: Elapsed time: 0.751s, Critical Path: 0.00s\r\nINFO: 1 process: 1 internal.\r\nINFO: Build completed successfully, 1 total action\r\n//tensorflow/python/data/experimental/kernel_tests:directed_interleave_dataset_test (cached) PASSED in 8.3s\r\n  Stats over 24 runs: max = 8.3s, min = 1.9s, avg = 3.6s, dev = 1.9s\r\n\r\nINFO: Elapsed time: 6.299s, Critical Path: 5.75s\r\nINFO: 13 processes: 3 internal, 10 local.\r\nINFO: Build completed successfully, 13 total actions\r\n//tensorflow/python/data/kernel_tests:rejection_resample_test            PASSED in 5.7s\r\n  Stats over 10 runs: max = 5.7s, min = 2.8s, avg = 4.2s, dev = 1.2s\r\n\r\n```\r\n\r\n@aaudiber The lazy import of `interleave_ops` in `dataset_ops.py` is still applicable as `choose_from_datasets_v2` is still experimental. I can work on promoting `choose_from_datasets` after this PR so that we can proceed with refactoring `dataset_ops`.\r\ncc: @jsimsa ", "comments": ["@aaudiber any updates on this?", "Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/51416\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51416) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "@gbaned can you please remove the review request for all reviewers other than @aaudiber. Thanks!", "closing the PR as the commit has been made internally.", "Thanks @kvignesh1420! Sorry for the delay, it took some time to get through internal review.", "@aaudiber no problem at all. Thanks for the help!"]}, {"number": 51415, "title": "inference while recording video is possible in camera2 api? ", "body": "I made tflite model and it infer quite well as I intended,\r\nnow , I want to record video but once video recorded, inference is stopped.  and once infer is done, video recored is not playable. \r\n\r\nI assume that rear camera is used to infer, and also I'm trying to record video with rear camera . that is the problem? \r\n\r\non app, top right fab is to record video \r\nand bottom right fab is to take picture. \r\n\r\nmy relevant github link is as below\r\n\r\nhttps://github.com/kotran88/cameraapi8", "comments": ["This question is better asked on [TensorFlow Forum](https://discuss.tensorflow.org/) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 51414, "title": "Amazon SageMaker Debugger - 'RuleEvaluationStatus': 'Error'", "body": "I'm facing the following error while running Overfit built-in rule in tensorflow\r\n\r\n'RuleConfigurationName': 'Overfit',\r\n 'RuleEvaluationStatus': 'Error',\r\n 'StatusDetails': 'ClientError: No debugging data was saved by the training '\r\n                  'job. Check that the debugger hook was configured correctly '\r\n                  'before starting the training job. Exception: Training job '\r\n                  'has ended. All the collection files could not be loaded\\n'\r\n                  'Traceback (most recent call last):\\n'\r\n\r\nBelow is my code,\r\n\r\nimport boto3\r\nimport sagemaker\r\nfrom time import gmtime, strftime\r\nfrom sagemaker.tensorflow import TensorFlow\r\nfrom sagemaker.debugger import ProfilerConfig, DebuggerHookConfig, Rule, ProfilerRule, rule_configs, CollectionConfig\r\n\r\nbase_job_name_prefix= 'SDK-SMDebug-built-in-rules-'+ strftime(\"%d-%H-%M-%S\", gmtime())\r\n\r\ncollection_config_biases = CollectionConfig(name='biases')\r\ncollection_config_weights = CollectionConfig(name='weights')\r\ncollection_config_metrics = CollectionConfig(name='metrics')\r\n\r\ndebugger_hook_config = DebuggerHookConfig(\r\n    s3_output_path=f\"s3://bgt-lensxraymodeling/URPM/MajorModel/SageMakerOutput/debug-output\",\r\n    collection_configs=[\r\n        collection_config_biases,\r\n        collection_config_weights,\r\n        collection_config_metrics\r\n    ]\r\n)\r\n\r\nestimator = TensorFlow(\r\n    entry_point='SCNN_custom_v1/sagemaker_train_v1.py',\r\n    instance_type='ml.p2.xlarge',\r\n    instance_count=1,\r\n    image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:1.15.5-gpu-py36-cu100-ubuntu18.04',\r\n    #script_mode=True,\r\n    framework_version=\"1.15\",\r\n    py_version=\"py3\",\r\n    role=role,\r\n    base_job_name=base_job_name_prefix, \r\n    **debugger_hook_config=debugger_hook_config,\r\n    rules=[\r\n        Rule.sagemaker(rule_configs.overfit()),\r\n        Rule.sagemaker(rule_configs.loss_not_decreasing())\r\n    ],**\r\n)\r\nestimator.fit()\r\n\r\nCould someone please suggest me a solution for this? I don't find any issue with regard to debugger hook configuration in the above code", "comments": ["@Raisa06 Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.We see that you are using older version of tensorflow (1.x) which is not actively supported. We recommend that you upgrade to latest stable version of tensorflow 2.6.0 and let us know if the issue still persists in newer versions .Thanks!\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51413, "title": "Amazon SageMaker Debugger - 'RuleEvaluationStatus': 'Error',", "body": null, "comments": ["@Raisa06 ,\r\n\r\nLooks like this is duplicate of issue #51414.Can you please close this issue, since it is already being tracked there? Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51412, "title": "Outer dimensions of indices and update must match", "body": "```python\r\nx     = tf.random.normal((128, 4096))\r\nx_slc = tf.random.normal((128, 1023))\r\nslc = list(range(x_slc.shape[-1]))\r\ntf.tensor_scatter_nd_update(x, slc, x_slc)\r\n```\r\nI cannot find any shape of `slc` that doesn't make the command fail, and the error message is inaccurate: the inner (non-assignment) dimensions do match:\r\n\r\n```python\r\nInvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape. \r\nOutput: [128,4096] updates: [128,1023] [Op:TensorScatterUpdate]\r\n```\r\n\r\nEither a bug or a documentation issue. The intended behavior is to emulate `x[:, :1023] = x_slc`.", "comments": ["@OverLordGoldDragon ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/models/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue and tersorflow version you are using.Thanks!", "@tilakrayal [TensorFlow 2.5.0](https://anaconda.org/anaconda/tensorflow) (no GPU), Windows 10, Python 3.9.6, [tf_scatter_nd_update](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update), no existing Issues.", "@sanatmpa1  ,\r\nI was able to reproduce the issue in tf v2.4,v2.5 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/0d7291d364d89edc48c9610f6ea1149b/41512.ipynb).", "@OverLordGoldDragon,\r\n\r\n> I cannot find any shape of slc that doesn't make the command fail\r\n\r\nYou've created `slc` which is a list of range of values  `[0,1,2,...,1022]` with length 1023, \r\nwhereas the ideal values should have been a list of indices, with the shape `(128, 1023, 2)` as shown below.\r\n` array([[[0,0],[ 0,1], ...[0, 1022]],\r\n   ......,\r\n       [[ 127,0],[ 127,    1],...,[ 127, 1022]]])`\r\n\r\nThe solution is to change the second line of your code from, `slc = list(range(x_slc.shape[-1]))` to `slc = tf.where(tf.math.logical_not(tf.math.is_nan(x_slc))).numpy().reshape([128,1023,2])`.\r\n\r\nPlease take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/2e2fd0e69cd6049ee7789b693c550a48/51412.ipynb#scrollTo=aSBaShDTtY9w), for the working solution and the validation. let me know if it answers your question. Thanks!\r\n\r\n", "@sanatmpa1 This works ... sort of: it makes a copy (set `result = x`) despite the indexing being contiguous. That's a deal-breaker for performance; can a copy be avoided?", "@OverLordGoldDragon \r\n\r\nGlad that it worked! To answer your question, as per TensorFlow [documentation](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update) of `tensor_scatter_nd_update` , it clearly states that a new tensor will be created and we don't have inplace option implemented at this point of time.\r\n\r\nAs the solution that I proposed has worked for you, please confirm if we are good to close this issue. Thanks!", "@sanatmpa1 The documentation reads:\r\n\r\n> This operation is very similar to tf.scatter_nd, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.\r\n\r\nso while a new tensor is created, a new memory storage isn't necessarily. How do I tell when latter happens, and is there a way to access storage (like in PyTorch)? Can tensors be allocated to in-place like in numpy, to change values without changing reference?", "@OverLordGoldDragon,\r\n\r\nThanks for pointing that out. I mentioned in-place operation is not implemented yet, as per the below line in the document.\r\n\r\n> #Not implemented: tensors cannot be updated inplace.\r\n> tensor[indices] = updates\r\n\r\nIf you feel that it can be a potential performance problem, can you kindly create a new issue/feature request specifically for the same. Thanks! ", "@sanatmpa1 Thanks for the help.\r\n\r\nHard to imagine a big data library not having a basic performant operation. Regardless, below implements arbitrary indexing and more efficiently, assuming `x_slc` has no NaNs.\r\n\r\n<details>\r\n  <summary><b>code</b></summary>\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# generate data\r\nx     = tf.random.normal((128, 5, 4096))\r\nx_slc = tf.random.normal((*x.shape[:-1], 1023))\r\n\r\n# generate arbitrary indexing\r\nseq = np.random.randint(0, 4096, 20000)\r\nix = np.unique(seq, return_index=True)[1][:x_slc.shape[-1]]\r\nidxs = seq[np.sort(ix)]\r\n\r\n# index last dimension\r\nslc0 = tf.ones(x_slc.shape)\r\nslc = tf.where(slc0).numpy().reshape([*x_slc.shape, x_slc.ndim])\r\nslc[..., -1] = idxs\r\n\r\n# update\r\nout = tf.tensor_scatter_nd_update(x, slc, x_slc)\r\n\r\n# validate\r\nxn, xsn = out.numpy(), x_slc.numpy()\r\nd = np.abs(xn[..., idxs] - xsn)\r\nassert np.allclose(xn[..., idxs], x_slc), np.abs(d).mean()\r\n```\r\n</details>", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51412\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51412\">No</a>\n"]}, {"number": 51411, "title": "Add TF-TRT Python integration tests in dynamic shape mode", "body": "This PR updates TF-TRT Python unit test to run both implicit batch and dynamic shape tests. \r\n\r\nSome of the test have to be adjusted because the conversion rate is different in dynamic shape mode. Comments that explain the difference are added to the tests.\r\n\r\nApart from updating the test, this PR also removes the requirement to run build mode in dynamic shape mode. The necessary changes in trt_engine_op were implemented already in dynamic shape phase 3, but the Python side error message was not removed at that time.\r\n\r\nTagging @bixia1 for review. Tracker #45481 ", "comments": ["I see these test failure\r\n![tf_function_test](https://user-images.githubusercontent.com/35820639/129977578-2fa61518-209f-456d-9fc8-857b78c667b2.png)\r\n![gpu_int32](https://user-images.githubusercontent.com/35820639/129977586-1f9c213c-df3f-4063-98a4-15a7151f25c3.png)\r\n![gpu_cast_test](https://user-images.githubusercontent.com/35820639/129977591-6d5e8f0e-6459-46be-a018-24102fc9454f.png)\r\n", "@tfeher  Can you please check @bixia1's comments and keep us posted ? Thanks!", "@bixia1 I have fixed the failing tests. Sorry for the delay."]}, {"number": 51410, "title": "Tensorflow 2.5: Segmentation Fault", "body": "I am trying to run a large 3D U-net and my dataset size is 55GB. It doesn't finish more than 6 epochs and then I get a segmentation fault. \r\n\r\nSystem information: TF 2.5 / CUDA 11.2 / cuDNN 8.1\r\nGPU : 10GB\r\nServer has 32GB of RAM.\r\n\r\nThe code for my data generator is as follows: \r\n\r\n```\r\ndef open_data_file(filename, readwrite=\"r\"):\r\n    return tables.open_file(filename, readwrite)\r\n\r\ndata_file_opened = open_data_file(os.path.abspath(\"../data/data.h5\"))\r\n\r\ntrain_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\r\n        data_file_opened,\r\n        ......)\r\n```\r\n\r\nwhere:\r\n\r\n```\r\ndef get_training_and_validation_generators(data_file, batch_size, ...):\r\n    training_generator = data_generator(data_file, training_list,....)\r\n```\r\ndata_generator function is as follows:\r\n\r\n```\r\ndef data_generator(data_file, index_list,....):\r\n      orig_index_list = index_list\r\n    while True:\r\n        x_list = list()\r\n        y_list = list()\r\n        if patch_shape:\r\n            index_list = create_patch_index_list(orig_index_list, data_file, patch_shape,\r\n                                                 patch_overlap, patch_start_offset,pred_specific=pred_specific)\r\n        else:\r\n            index_list = copy.copy(orig_index_list)\r\n\r\n        while len(index_list) > 0:\r\n            index = index_list.pop()\r\n            add_data(x_list, y_list, data_file, index, augment=augment, augment_flip=augment_flip,\r\n                     augment_distortion_factor=augment_distortion_factor, patch_shape=patch_shape,\r\n                     skip_blank=skip_blank, permute=permute)\r\n            if len(x_list) == batch_size or (len(index_list) == 0 and len(x_list) > 0):\r\n                yield convert_data(x_list, y_list, n_labels=n_labels, labels=labels, num_model=num_model,overlap_label=overlap_label)\r\n                x_list = list()\r\n                y_list = list()\r\n\r\n```\r\n\r\nCan someone please tell me how to solve this issue? What causes the segmentation fault? Also, training is very slow. It takes about 7000s to complete one epoch.\r\n\r\n", "comments": ["@shifdz,\r\n\r\nPlease take a look on the links [ref_1](https://stackoverflow.com/questions/54333809/how-to-remedy-segmentation-fault-core-dumped-error-when-trying-to-fit-a-kera), [ref_2](https://stackoverflow.com/questions/53302958/how-to-debug-tensorflow-segmentation-fault-in-model-fit). For your question on what causes segmentation fault, one of the answer in this [thread](https://stackoverflow.com/questions/54333809/how-to-remedy-segmentation-fault-core-dumped-error-when-trying-to-fit-a-kera) mentions that `\"Segmentation fault error stands for a failure of the parallelization of your training process on the GPU\"` \r\n\r\nWe may need a simple reproducible code and sample data to trouble shoot the issue from our end. But I suggest you can try out the solutions mentioned in the links provided and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51409, "title": "Add pre-load CPU feature guard check", "body": "Follow-up from #48024: building the library and Python code loading it.", "comments": ["Thanks for the review. The MacOS failures look unrelated?", "Any input @penpornk?", "@hakos Thank you for checking! Yes, the `MacOS CPU Python` build is unrelated. The PR has already been pulled inside and is just stuck with internal test failures. I'll try to get to it soon. ", "@penpornk Thanks, should I try rebasing to see if it can get rid of the `MacOS CPU Python` build failure?", "@hakos You don't need to. They are unrelated. :)", "@hakos The PR is merged! Thank you very much for your patience! :)\r\nWhat changed: I ended up moving the `.so` to `//tensorflow/core/platform` to fix the test segfaults.", "Thanks @penpornk!"]}, {"number": 51408, "title": "1.15.4", "body": "We found vulnerabilities about tensorflow on the website \uff08https://nvd.nist.gov/vuln/search/results?form_type=Basic&results_type=overview&query=tensorflow&search_type=all&isCpeNameSearch=false\uff09. These vulnerabilities are basically fixed in versions greater than 2.0. But how are these vulnerabilities fixed in version 1.15.4? Thank you.", "comments": ["@van-68 \r\ncan you please provide with more information and details when you say about vulnerabilities, as there is no active support for tf 1.x,  can you upgrade to 2.x and let us know.", "> @van-68\r\n> can you please provide with more information and details when you say about vulnerabilities, as there is no active support for tf 1.x, can you upgrade to 2.x and let us know.\r\n\r\nThank you for your reply. If upgrade, the previous model in version 1. X and the subsequent Quantization Compression need to be reconstructed.\r\nDo you have a good way\r\nthanks\u3002", "@van-68 \r\nYou will have to reconstruct in later versions, in case you still have queries please post this in tf discussion forum as it has a larger community who could respond there.", "1.15 is EOL. We no longer patch it.\r\n\r\nYou will have to convert to TF 2.4 or above.", "> 1.15 is EOL. We no longer patch it.\r\n> \r\n> You will have to convert to TF 2.4 or above.\r\n\r\nThank you for your reply. The latest version is 1.15.5 of tensorflow 1.x\uff0cWill maintenance and upgrade be performed on version 1.15.5 in the future.\r\nIf convert to TF 2.4 or above, Do the previous models have to be reconstructed and modified from training, compression, quantization and integration.\r\nThanks\r\n\r\n", "> 1.15 is EOL. We no longer patch it.\r\n> \r\n> You will have to convert to TF 2.4 or above.\r\n\r\nThank you for your reply. The latest version is 1.15.5 of tensorflow 1.x\uff0cWill maintenance and upgrade be performed on version 1.15.5 in the future.\r\nIf convert to TF 2.4 or above, Do the previous models have to be reconstructed and modified from training, compression, quantization and integration.\r\nThanks", "No. TF 1.x will not be updated at all.\r\n\r\nIn theory, most models should still work.", "> No. TF 1.x will not be updated at all.\r\n> \r\n> In theory, most models should still work.\r\n\r\nIn you mean, The current version is 1.15.5, and there will be no later version?\r\nWon't the following vulnerabilities be fixed in version 1. X\u3002\r\nIf used, be must upgrade to 2. X\uff1f\r\n\r\n", "You must upgrade to TF 2.x if you want fixes for vulnerabilities.\r\n\r\nTF 1.x will not be updated at all. Use it at own risk"]}, {"number": 51407, "title": "Question about tf.compat.v1.metrics.auc", "body": "I try to migrate my code from tf1.* to tf2, while in [tf2 doc](https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/auc) it says that `tf.compat.v1.metrics.auc` is deprecated because \"**The value of AUC returned by this may race with the update**\". This statement is vague to me. Does it mean that it can't be used in multithreading context? If not, in what situation can I use this function?", "comments": ["@jiqiujia ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please fill and the tensorflow version you are using, as it helps us analyse the issue.Thanks!", "> @jiqiujia ,\r\n> \r\n> We see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please fill and the tensorflow version you are using, as it helps us analyse the issue.Thanks!\r\n\r\n@tilakrayal Thanks for you reply. I am using tf2.4. ", "@jiqiujia I am not sure about the words used in `deprecation` warning. But, as mentioned in that deprecation warning, please use `tf.keras.metrics.AUC` in place of `tf.compat.v1.metrics.auc`. It is always best not to mix `v1` (related to TF1.x) and `v2` (related to TF2.x) modules. \r\n\r\nThat warning will be removed soon when next auto update cycle runs to update TF webpages. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51407\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51407\">No</a>\n"]}, {"number": 51406, "title": "TF Lite unit (kernel) tests CMake build fix", "body": "The recent changes in the TF Lite kernel tests architecture were reflected in Bazel build system **but not in CMake**, leading to runtime failure when built using this platform.\r\n\r\nThis change **updates the TF Lite kernel tests CMake build configuration** and adds a minor check for easier future debugging. ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51406) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "Merged already as part of https://github.com/tensorflow/tensorflow/pull/52110."]}, {"number": 51405, "title": "Add track_times=False to Model.save_weights('.h5')", "body": "**System information**\r\n- TensorFlow version: 2.4.1\r\n- Are you willing to contribute it: Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, when calling `keras.models.Model.save_weights()` in hdf5 format, the weights are saved using `h5py.Group.create_dataset` with the argument `track_times` set to the default value `True`. The effect of this is following: even when the weights are exactly the same, the resulting saved files will not be the same (see for example this [stack overflow question](https://stackoverflow.com/questions/16019656/hdf5-file-h5py-with-version-control-hash-changes-on-every-save)). This is a problem when one has a replicable model pipeline and uses some version control system (like [DVC](https://dvc.org/)). \r\nThe proposed feature is adding `h5_track_times` argument to the `Model.save_weights()` function and pass it down to h5py. \r\n\r\n**Will this change the current api? How?**\r\nYes, the `Model.save_weights()` would get an additional optional `h5_track_times` argument. \r\n\r\n**Who will benefit with this feature?**\r\nEveryone who needs to have replicable model pipeline and needs to version the model weights in hdf5 format.", "comments": ["@josefondrej \r\n\r\nThis looks like a feature request that should go to `Keras` repo. Can you post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see; [https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "Moved to: [https://github.com/keras-team/keras/issues/15143](https://github.com/keras-team/keras/issues/15143)", "@josefondrej,\r\n\r\nCan you confirm if I can close the issue, as you've already submitted one in `Keras` repo. Thanks!"]}, {"number": 51403, "title": "Problems setting up Tensorflow on M1 Mac", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOC Big Sur 11.4, Apple M1 2020\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a?\r\n- GPU model and memory: Apple Silicon M1 Chip\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHey! I've been trying to set up Tensorflow on my M1 Mac but have been unsuccessful in doing so. Any help would be appreciated! As a note, I was following [this installation guide](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb) as well as using other resources as well since I am relatively new to this. I also have a lot of logs, so I attached my terminal code as a [txt file](https://github.com/tensorflow/tensorflow/files/6959610/pain.txt).\r\n\r\n\r\n<br>\r\n\r\nI first set up `Miniforge` and `Jupyter Notebook`, which I believed worked out just fine.\r\n\r\n<details> \r\n<summary>Here's the output (really long, added just in case)</summary>\r\n\r\n```\r\n(base) Anshul@Anshuls-MacBook-Pro ~ % xcode-select --install\r\n\r\nxcode-select: error: command line tools are already installed, use \"Software Update\" to install updates\r\n(base) Anshul@Anshuls-MacBook-Pro ~ % brew install miniforge\r\n\r\nUpdating Homebrew...\r\n==> Auto-updated Homebrew!\r\nUpdated 5 taps (heroku/brew, homebrew/core, homebrew/cask, homebrew/services and mongodb/brew).\r\n==> New Formulae\r\nalda                                  demumble                              himalaya                              mapcidr                               openmama                              qt-mysql                              stp\r\nalerter                               detect-secrets                        hubble                                marcli                                openmodelica                          qt-percona-server                     stylua\r\namfora                                djl-serving                           i2c-tools                             mariadb@10.5                          opensearch                            qt-postgresql                         svgbob\r\narchey4                               doc8                                  iconsur                               marp-cli                              oras                                  qt-unixodbc                           sysstat\r\nargocd-autopilot                      docuum                                imath                                 mathlibtools                          orgalorg                              qthreads                              systemd\r\nargocd-vault-plugin                   dory                                  influxdb-cli                          matterbridge                          organize-tool                         range2cidr                            tbb@2020\r\nas-tree                               dua-cli                               influxdb@1                            maturin                               osinfo-db                             rdkit                                 terminator\r\nat-spi2-atk                           ehco                                  ipinfo-cli                            mbedtls@2                             osinfo-db-tools                       revive                                threemux\r\nat-spi2-core                          elan-init                             iredis                                minisat                               pandoc-plot                           rhit                                  timg\r\natuin                                 elfutils                              jello                                 moar                                  parquet-cli                           rmw                                   tmuxp\r\nautoconf@2.69                         enkits                                jrsonnet                              mongocli                              pcalc                                 ronn                                  tomcat@9\r\nautorestic                            enzyme                                julia                                 mongodb/brew/mongodb-community@4.4    pcp                                   rosa-cli                              tracker\r\navahi                                 epr                                   kalker                                mongodb/brew/mongodb-mongocryptd      pgxnclient                            rover                                 trojan-go\r\nbaidupcs-go                           erlang@23                             kertish-dfs                           mongodb/brew/mongodb-mongocryptd@4.2  php-cs-fixer@2                        rpg-cli                               tssh\r\nbas55                                 fabric-installer                      ki                                    mongodb/brew/mongodb-mongocryptd@4.4  phpbrew                               rsc_2fa                               tz\r\nbash_unit                             fanyi                                 kickstart                             mongosh                               pillow                                rtl_433                               umple\r\nbgpq4                                 fcp                                   klee                                  moto                                  plow                                  s4cmd                                 universal-ctags\r\nbosh-cli                              fluid-synth@2.1                       kotlin-language-server                mr2                                   poppler-qt5                           samba                                 vala-language-server\r\nbrook                                 frum                                  kubeconform                           multi-git-status                      principalmapper                       saml2aws                              virtualenv\r\nbuildpulse-test-reporter              func-e                                kubergrunt                            multitime                             proj@7                                scorecard                             virtualenvwrapper\r\nbupstash                              fuse-overlayfs                        latino                                mx                                    projectm                              scotch                                waffle\r\ncadence-workflow                      gcc@10                                leaf-proxy                            name-that-hash                        psalm                                 scry                                  wasmtime\r\ncadical                               geph4                                 lefthook                              nbsdgames                             pure                                  search-that-hash                      waypoint\r\ncaire                                 ghc@9                                 lexbor                                ncc                                   px                                    seqkit                                webhook\r\ncidr2range                            git-xargs                             libfuse@2                             neovim-remote                         py-spy                                simde                                 wildmidi\r\nciphey                                gitbackup                             libmd                                 net-tools                             pydocstyle                            six                                   wllvm\r\nclarinet                              gitwatch                              libmobi                               nomino                                pyflow                                slides                                xcprojectlint\r\nclazy                                 glibc                                 libpipeline                           notcurses                             pyqt-3d                               slirp4netns                           xfig\r\nclusterctl                            gnupg@2.2                             libunwind                             nox                                   pyqt-builder                          smu                                   xplr\r\ncode-minimap                          go-boring                             licensefinder                         ns-3                                  pyqt-networkauth                      snowpack                              xray\r\nconftest                              go@1.15                               lima                                  numactl                               pyright                               soapyrtlsdr                           yubikey-agent\r\nconmon                                gopass-jsonapi                        linux-headers@4.15                    obfs4proxy                            pyside@2                              soapysdr                              zellij\r\ncrackpkcs                             gpg-tui                               linux-pam                             oksh                                  python-launcher                       spaceship                             zet\r\ncrispy-doom                           gradle@6                              llvm@11                               open-adventure                        python-tabulate                       spectra                               zinit\r\ncrun                                  graphqurl                             lm-sensors                            openexr@2                             python-tk@3.9                         sql-lint                              zlib-ng\r\ncsvtk                                 grepip                                lsix                                  openfpgaloader                        pythran                               sqlancer                              zsh-vi-mode\r\ndarglint                              gtksourceview5                        lttng-ust                             openj9                                pywhat                                sqlbench\r\ndatalad                               haruhi-dl                             lychee                                openliberty-jakartaee8                qodem                                 sqlx-cli\r\nddcctl                                haskell-language-server               macchina                              openliberty-microprofile4             qt-libiodbc                           sqsmover\r\ndelve                                 hcl2json                              macos-term-size                       openliberty-webprofile8               qt-mariadb                            storj-uplink\r\n==> Updated Formulae\r\nUpdated 5048 formulae.\r\n==> Renamed Formulae\r\nbadtouch -> authoscope                                ht-rust -> xh                                         kde-ki18n -> ki18n                                    minizip2 -> minizip-ng                                weboob -> woob\r\nenvoy@1.17 -> envoy@1.18                              kde-extra-cmake-modules -> extra-cmake-modules        kde-threadweaver -> threadweaver                      parallelstl -> onedpl                                 wxmac -> wxwidgets\r\nfcct -> butane                                        kde-karchive -> karchive                              libsasl2 -> cyrus-sasl                                pyqt5 -> pyqt@5                                       wxmac@3.0 -> wxwidgets@3.0\r\ngrakn -> typedb                                       kde-kdoctools -> kdoctools                            linux-headers -> linux-headers@4.4                    qt5 -> qt@5\r\n==> Deleted Formulae\r\natlassian-cli                                avian                                        geant4                                       libinfinity                                  protobuf-swift                               terraform-provisioner-ansible\r\naurora-cli                                   erlang@20                                    giter8                                       osquery                                      protobuf@3.7                                 tj\r\n==> New Casks\r\n8x8-work                          chatterino                        evkey                             futurerestore-gui                 kubenav                           neat-reader                       safe-multisig                     uniflash\r\nadrive                            chia                              fabfilter-micro                   goldenpassport                    kyokan-bob                        nordlocker                        samsung-dex                       universal-battle\r\naffinity-designer                 cinc-workstation                  fabfilter-one                     goneovim                          lagrange                          nordpass                          sbarex-qlmarkdown                 usbimager\r\naffinity-photo                    cinco                             fabfilter-pro-c                   google-drive                      landrop                           northernspysoftware-colorpicker   shield                            usr-sse2-rdm\r\naffinity-publisher                cinderella                        fabfilter-pro-ds                  gosign                            librewolf                         nuage                             shimonote                         utterly\r\nairbuddy                          classroom-mode-for-minecraft      fabfilter-pro-g                   guilded                           lightform                         odbc-manager                      shortcutor                        vamiga\r\nalipay-development-assistant      clicker-for-netflix               fabfilter-pro-l                   hancom-word                       lightwright                       offset-explorer                   shottr                            veepn\r\nandroid-commandlinetools          clicker-for-youtube               fabfilter-pro-mb                  hightop                           logseq                            old-school-runescape              simplelink-msp432-sdk             vial\r\narkiwi                            clock-signal                      fabfilter-pro-q                   hook                              maccleaner-pro                    openloco                          simplelink-msp432e4-sdk           vitals\r\naround                            code-composer-studio              fabfilter-pro-r                   hush                              macstroke                         opgg                              simtoolkitpro                     vitalsigns\r\nasana                             cog                               fabfilter-saturn                  hyperkey                          maestral                          optimus-player                    siyuan                            volanta\r\nassinador-serpro                  coinomi-wallet                    fabfilter-simplon                 iconscout                         magicplot                         p4                                skychart                          vsd-viewer\r\nastah-uml                         command-pad                       fabfilter-timeless                ilspy                             mailtrackerblocker                parsify                           sleek                             vsdx-annotator\r\natomic-wallet                     crescendo                         fabfilter-twin                    imdone                            mambaforge                        physics-101                       slidepilot                        waltr-pro\r\naudacity                          cryptonomic-galleon               fabfilter-volcano                 infinity                          maxon                             pika                              sonic-robo-blast-2                wannianli\r\naudiogridder-plugin               curseforge                        fawkes                            instatus-out                      megax                             pktriot                           sonic-robo-blast-2-kart           webull\r\naudiogridder-server               daedalus-testnet                  final-fantasy-xiv-online          internxt-drive                    mem                               plasticscm-cloud-edition          sonobus                           wezterm\r\naudius                            depthmapx                         finisher-fluxx                    invoker                           memory-cleaner                    polkadot-js                       sparrow                           wifi-explorer-pro\r\nbanksiagui                        devbook                           finisher-micro                    irpf2021                          menu-bar-splitter                 pop                               specter                           wolfram-player\r\nbattery-buddy                     devilutionx                       finisher-neo                      isyncer                           menuwhere                         portx                             sqlight                           wxmacmolplt\r\nbeeper                            devkinsta                         finisher-voodoo                   itraffic                          micro-sniff                       prisma-studio                     suuntodm5                         xbar\r\nbetelguese                        devutils                          firefly                           jamkazam                          microsoft-openjdk                 privileges                        swiftbar                          xournal-plus-plus\r\nbit-fiddle                        diagnostics                       flameshot                         jandi-statusbar                   microsoft-remote-desktop          pronterface                       tabby                             yippy\r\nblackhole-64ch                    dingtalk-lite                     flomo                             jellyfin-media-player             midiview                          pulse                             tabtopus                          youtube-dl-gui\r\nbleunlock                         disk-expert                       fluent-reader                     jgrennison-openttd                millie                            qudedup-extract-tool              textbuddy                         zecwallet-lite\r\nblobsaver                         dmidiplayer                       font-smoothing-adjuster           jidusm                            mixed-in-key                      radar                             the-archive                       zulufx\r\nbluesnooze                        dnagedcom                         foobar2000                        jiohome                           moebius                           recut                             tint\r\nbrooklite                         dropzone                          forticlient-vpn                   jpadilla-rabbitmq                 mouse-fix                         redis-pro                         touch-portal\r\nburp-suite-professional           drovio                            fpc-laz                           jpadilla-redis                    mubu                              redream                           touchosc\r\ncakebrewjs                        duplicate-file-finder             fpc-src-laz                       katrain                           mutesync                          remnote                           transfer\r\ncalmly-writer                     ears                              free42-binary                     kdocs                             mxsrvs                            rhino                             trezor-suite\r\ncastr                             elpki                             free42-decimal                    keyboardholder                    n1ghtshade                        runelite                          ubports-installer\r\ncelestia                          enclave                           fspy                              kiwi-for-gmail                    nault                             safe-exam-browser                 unexpectedly\r\n==> Updated Casks\r\nUpdated 2625 casks.\r\n==> Deleted Casks\r\nableton-live                  beautune                      daedalus-catalyst             fpcsrc                        kode54-cog                    netbeans-java-ee              protonmail-unofficial         shoes                         wakeonlan\r\nadafruit-arduino              beoplay-software-update       duckstation                   gitbox                        lingo                         netbeans-java-se              psequel                       spideroak-share               wraparound\r\nadobe-air-sdk                 blue-jeans-browser-plugin     family-tree-builder           hex                           magicplotpro                  netbeans-php                  rabbitmq                      swift-explorer                xamarin\r\nadobe-lens-profile-creator    caramba-switcher              filedrop                      hubic                         magicplotstudent              nndd                          racket-cs                     terminus                      yyets\r\nadventure                     cellery                       flash-npapi                   imazing-mini                  mapillary-uploader            omniweb                       raven                         todos\r\nadware-removal-tool           clipbuddy                     flash-player                  insomnia-designer             mega                          opennx                        redis                         touch-bar-pong\r\nappstudio                     cliqz                         flash-player-debugger         iograph                       meshcommander                 opera-mail                    resxtreme                     tracks-live\r\naudiobookbinder               craft                         flash-player-debugger-npapi   itrash                        mist                          pdftotext                     revisions                     transmit-disk\r\nauristor-client               cricut-design-space           flash-player-debugger-ppapi   jira-client                   monitorearth                  pibakery                      rhinoceros                    use-engine\r\nbattery-guardian              crypt                         flash-ppapi                   kafka-tool                    mp3tag                        pins                          rss                           veonim\r\nbeatport-pro                  cuteclips                     foreman                       kk7ds-python-runtime          netbeans-cpp                  printrun                      screen                        vrep\r\n\r\n==> Caveats\r\nPlease run the following to setup your shell:\r\n  conda init \"$(basename \"${SHELL}\")\"\r\n\r\n==> Downloading https://github.com/conda-forge/miniforge/releases/download/4.10.3-4/Miniforge3-4.10.3-4-MacOSX-arm64.sh\r\n==> Downloading from https://github-releases.githubusercontent.com/221584272/b4e53ae3-f8ef-4279-8dab-e8402c705255?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210810T045003Z&X-Amz-Expires=\r\n######################################################################## 100.0%\r\n==> Installing Cask miniforge\r\n==> Running installer script 'Miniforge3-4.10.3-4-MacOSX-arm64.sh'\r\nPREFIX=/usr/local/Caskroom/miniforge/base\r\nUnpacking payload ...\r\nExtracting \"pycparser-2.20-pyh9f0ad1d_2.tar.bz2\"\r\nExtracting \"pyopenssl-20.0.1-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"python_abi-3.9-2_cp39.tar.bz2\"\r\nExtracting \"pysocks-1.7.1-py39h2804cbe_3.tar.bz2\"\r\nExtracting \"urllib3-1.26.6-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"six-1.16.0-pyh6c4a22f_0.tar.bz2\"\r\nExtracting \"tzdata-2021a-he74cb21_1.tar.bz2\"\r\nExtracting \"yaml-0.2.5-h642e427_0.tar.bz2\"\r\nExtracting \"sqlite-3.36.0-h72a2b83_0.tar.bz2\"\r\nExtracting \"xz-5.2.5-h642e427_1.tar.bz2\"\r\nExtracting \"ca-certificates-2021.5.30-h4653dfc_0.tar.bz2\"\r\nExtracting \"setuptools-49.6.0-py39h2804cbe_3.tar.bz2\"\r\nExtracting \"cryptography-3.4.7-py39h73257c9_0.tar.bz2\"\r\nExtracting \"colorama-0.4.4-pyh9f0ad1d_0.tar.bz2\"\r\nExtracting \"tqdm-4.62.0-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"cffi-1.14.6-py39hda8b47f_0.tar.bz2\"\r\nExtracting \"zlib-1.2.11-h31e879b_1009.tar.bz2\"\r\nExtracting \"idna-3.1-pyhd3deb0d_0.tar.bz2\"\r\nExtracting \"wheel-0.36.2-pyhd3deb0d_0.tar.bz2\"\r\nExtracting \"conda-package-handling-1.7.3-py39h5161555_0.tar.bz2\"\r\nExtracting \"chardet-4.0.0-py39h2804cbe_1.tar.bz2\"\r\nExtracting \"requests-2.26.0-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"libffi-3.3-h9f76cd9_2.tar.bz2\"\r\nExtracting \"brotlipy-0.7.0-py39h5161555_1001.tar.bz2\"\r\nExtracting \"libcxx-12.0.1-h168391b_0.tar.bz2\"\r\nExtracting \"tk-8.6.10-hf7e6567_1.tar.bz2\"\r\nExtracting \"readline-8.1-hedafd6a_0.tar.bz2\"\r\nExtracting \"charset-normalizer-2.0.0-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"openssl-1.1.1k-h27ca646_0.tar.bz2\"\r\nExtracting \"conda-4.10.3-py39h2804cbe_0.tar.bz2\"\r\nExtracting \"pycosat-0.6.3-py39h5161555_1006.tar.bz2\"\r\nExtracting \"pip-21.2.2-pyhd8ed1ab_0.tar.bz2\"\r\nExtracting \"ruamel_yaml-0.15.80-py39h5161555_1004.tar.bz2\"\r\nExtracting \"certifi-2021.5.30-py39h2804cbe_0.tar.bz2\"\r\nExtracting \"python-3.9.6-h54d631c_1_cpython.tar.bz2\"\r\nExtracting \"ncurses-6.2-h9aa5885_4.tar.bz2\"\r\n\r\n                                           __\r\n          __  ______ ___  ____ _____ ___  / /_  ____ _\r\n         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\r\n        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\r\n       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\r\n      /_/\r\n\r\n\r\nTransaction\r\n\r\n  Prefix: /usr/local/Caskroom/miniforge/base\r\n\r\n  Updating specs:\r\n\r\n   - python==3.9.6=h54d631c_1_cpython\r\n   - ca-certificates==2021.5.30=h4653dfc_0\r\n   - libcxx==12.0.1=h168391b_0\r\n   - ncurses==6.2=h9aa5885_4\r\n   - tzdata==2021a=he74cb21_1\r\n   - xz==5.2.5=h642e427_1\r\n   - yaml==0.2.5=h642e427_0\r\n   - zlib==1.2.11=h31e879b_1009\r\n   - libffi==3.3=h9f76cd9_2\r\n   - openssl==1.1.1k=h27ca646_0\r\n   - readline==8.1=hedafd6a_0\r\n   - tk==8.6.10=hf7e6567_1\r\n   - sqlite==3.36.0=h72a2b83_0\r\n   - charset-normalizer==2.0.0=pyhd8ed1ab_0\r\n   - colorama==0.4.4=pyh9f0ad1d_0\r\n   - idna==3.1=pyhd3deb0d_0\r\n   - pycparser==2.20=pyh9f0ad1d_2\r\n   - python_abi==3.9=2_cp39\r\n   - six==1.16.0=pyh6c4a22f_0\r\n   - wheel==0.36.2=pyhd3deb0d_0\r\n   - certifi==2021.5.30=py39h2804cbe_0\r\n   - cffi==1.14.6=py39hda8b47f_0\r\n   - chardet==4.0.0=py39h2804cbe_1\r\n   - pycosat==0.6.3=py39h5161555_1006\r\n   - pysocks==1.7.1=py39h2804cbe_3\r\n   - ruamel_yaml==0.15.80=py39h5161555_1004\r\n   - tqdm==4.62.0=pyhd8ed1ab_0\r\n   - brotlipy==0.7.0=py39h5161555_1001\r\n   - conda-package-handling==1.7.3=py39h5161555_0\r\n   - cryptography==3.4.7=py39h73257c9_0\r\n   - setuptools==49.6.0=py39h2804cbe_3\r\n   - pip==21.2.2=pyhd8ed1ab_0\r\n   - pyopenssl==20.0.1=pyhd8ed1ab_0\r\n   - urllib3==1.26.6=pyhd8ed1ab_0\r\n   - requests==2.26.0=pyhd8ed1ab_0\r\n   - conda==4.10.3=py39h2804cbe_0\r\n\r\n\r\n  Package                   Version  Build               Channel                                                                         Size\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n  Install:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n\r\n  brotlipy                    0.7.0  py39h5161555_1001   conda-forge/osx-arm64/brotlipy-0.7.0-py39h5161555_1001.tar.bz2                Cached\r\n  ca-certificates         2021.5.30  h4653dfc_0          conda-forge/osx-arm64/ca-certificates-2021.5.30-h4653dfc_0.tar.bz2            Cached\r\n  certifi                 2021.5.30  py39h2804cbe_0      conda-forge/osx-arm64/certifi-2021.5.30-py39h2804cbe_0.tar.bz2                Cached\r\n  cffi                       1.14.6  py39hda8b47f_0      conda-forge/osx-arm64/cffi-1.14.6-py39hda8b47f_0.tar.bz2                      Cached\r\n  chardet                     4.0.0  py39h2804cbe_1      conda-forge/osx-arm64/chardet-4.0.0-py39h2804cbe_1.tar.bz2                    Cached\r\n  charset-normalizer          2.0.0  pyhd8ed1ab_0        conda-forge/noarch/charset-normalizer-2.0.0-pyhd8ed1ab_0.tar.bz2              Cached\r\n  colorama                    0.4.4  pyh9f0ad1d_0        conda-forge/noarch/colorama-0.4.4-pyh9f0ad1d_0.tar.bz2                        Cached\r\n  conda                      4.10.3  py39h2804cbe_0      conda-forge/osx-arm64/conda-4.10.3-py39h2804cbe_0.tar.bz2                     Cached\r\n  conda-package-handling      1.7.3  py39h5161555_0      conda-forge/osx-arm64/conda-package-handling-1.7.3-py39h5161555_0.tar.bz2     Cached\r\n  cryptography                3.4.7  py39h73257c9_0      conda-forge/osx-arm64/cryptography-3.4.7-py39h73257c9_0.tar.bz2               Cached\r\n  idna                          3.1  pyhd3deb0d_0        conda-forge/noarch/idna-3.1-pyhd3deb0d_0.tar.bz2                              Cached\r\n  libcxx                     12.0.1  h168391b_0          conda-forge/osx-arm64/libcxx-12.0.1-h168391b_0.tar.bz2                        Cached\r\n  libffi                        3.3  h9f76cd9_2          conda-forge/osx-arm64/libffi-3.3-h9f76cd9_2.tar.bz2                           Cached\r\n  ncurses                       6.2  h9aa5885_4          conda-forge/osx-arm64/ncurses-6.2-h9aa5885_4.tar.bz2                          Cached\r\n  openssl                    1.1.1k  h27ca646_0          conda-forge/osx-arm64/openssl-1.1.1k-h27ca646_0.tar.bz2                       Cached\r\n  pip                        21.2.2  pyhd8ed1ab_0        conda-forge/noarch/pip-21.2.2-pyhd8ed1ab_0.tar.bz2                            Cached\r\n  pycosat                     0.6.3  py39h5161555_1006   conda-forge/osx-arm64/pycosat-0.6.3-py39h5161555_1006.tar.bz2                 Cached\r\n  pycparser                    2.20  pyh9f0ad1d_2        conda-forge/noarch/pycparser-2.20-pyh9f0ad1d_2.tar.bz2                        Cached\r\n  pyopenssl                  20.0.1  pyhd8ed1ab_0        conda-forge/noarch/pyopenssl-20.0.1-pyhd8ed1ab_0.tar.bz2                      Cached\r\n  pysocks                     1.7.1  py39h2804cbe_3      conda-forge/osx-arm64/pysocks-1.7.1-py39h2804cbe_3.tar.bz2                    Cached\r\n  python                      3.9.6  h54d631c_1_cpython  conda-forge/osx-arm64/python-3.9.6-h54d631c_1_cpython.tar.bz2                 Cached\r\n  python_abi                    3.9  2_cp39              conda-forge/osx-arm64/python_abi-3.9-2_cp39.tar.bz2                           Cached\r\n  readline                      8.1  hedafd6a_0          conda-forge/osx-arm64/readline-8.1-hedafd6a_0.tar.bz2                         Cached\r\n  requests                   2.26.0  pyhd8ed1ab_0        conda-forge/noarch/requests-2.26.0-pyhd8ed1ab_0.tar.bz2                       Cached\r\n  ruamel_yaml               0.15.80  py39h5161555_1004   conda-forge/osx-arm64/ruamel_yaml-0.15.80-py39h5161555_1004.tar.bz2           Cached\r\n  setuptools                 49.6.0  py39h2804cbe_3      conda-forge/osx-arm64/setuptools-49.6.0-py39h2804cbe_3.tar.bz2                Cached\r\n  six                        1.16.0  pyh6c4a22f_0        conda-forge/noarch/six-1.16.0-pyh6c4a22f_0.tar.bz2                            Cached\r\n  sqlite                     3.36.0  h72a2b83_0          conda-forge/osx-arm64/sqlite-3.36.0-h72a2b83_0.tar.bz2                        Cached\r\n  tk                         8.6.10  hf7e6567_1          conda-forge/osx-arm64/tk-8.6.10-hf7e6567_1.tar.bz2                            Cached\r\n  tqdm                       4.62.0  pyhd8ed1ab_0        conda-forge/noarch/tqdm-4.62.0-pyhd8ed1ab_0.tar.bz2                           Cached\r\n  tzdata                      2021a  he74cb21_1          conda-forge/noarch/tzdata-2021a-he74cb21_1.tar.bz2                            Cached\r\n  urllib3                    1.26.6  pyhd8ed1ab_0        conda-forge/noarch/urllib3-1.26.6-pyhd8ed1ab_0.tar.bz2                        Cached\r\n  wheel                      0.36.2  pyhd3deb0d_0        conda-forge/noarch/wheel-0.36.2-pyhd3deb0d_0.tar.bz2                          Cached\r\n  xz                          5.2.5  h642e427_1          conda-forge/osx-arm64/xz-5.2.5-h642e427_1.tar.bz2                             Cached\r\n  yaml                        0.2.5  h642e427_0          conda-forge/osx-arm64/yaml-0.2.5-h642e427_0.tar.bz2                           Cached\r\n  zlib                       1.2.11  h31e879b_1009       conda-forge/osx-arm64/zlib-1.2.11-h31e879b_1009.tar.bz2                       Cached\r\n\r\n  Summary:\r\n\r\n  Install: 36 packages\r\n\r\n  Total download: 0  B\r\n\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n\r\n\r\n\r\nTransaction starting\r\nLinking ca-certificates-2021.5.30-h4653dfc_0\r\nLinking libcxx-12.0.1-h168391b_0\r\nLinking ncurses-6.2-h9aa5885_4\r\nLinking tzdata-2021a-he74cb21_1\r\nLinking xz-5.2.5-h642e427_1\r\nLinking yaml-0.2.5-h642e427_0\r\nLinking zlib-1.2.11-h31e879b_1009\r\nLinking openssl-1.1.1k-h27ca646_0\r\nLinking libffi-3.3-h9f76cd9_2\r\nLinking readline-8.1-hedafd6a_0\r\nLinking tk-8.6.10-hf7e6567_1\r\nLinking sqlite-3.36.0-h72a2b83_0\r\nLinking python-3.9.6-h54d631c_1_cpython\r\nLinking wheel-0.36.2-pyhd3deb0d_0\r\nLinking six-1.16.0-pyh6c4a22f_0\r\nLinking python_abi-3.9-2_cp39\r\nLinking pycparser-2.20-pyh9f0ad1d_2\r\nLinking idna-3.1-pyhd3deb0d_0\r\nLinking colorama-0.4.4-pyh9f0ad1d_0\r\nLinking charset-normalizer-2.0.0-pyhd8ed1ab_0\r\nLinking ruamel_yaml-0.15.80-py39h5161555_1004\r\nLinking pysocks-1.7.1-py39h2804cbe_3\r\nLinking pycosat-0.6.3-py39h5161555_1006\r\nLinking chardet-4.0.0-py39h2804cbe_1\r\nLinking certifi-2021.5.30-py39h2804cbe_0\r\nLinking cffi-1.14.6-py39hda8b47f_0\r\nLinking tqdm-4.62.0-pyhd8ed1ab_0\r\nLinking setuptools-49.6.0-py39h2804cbe_3\r\nLinking cryptography-3.4.7-py39h73257c9_0\r\nLinking brotlipy-0.7.0-py39h5161555_1001\r\nLinking conda-package-handling-1.7.3-py39h5161555_0\r\nLinking pip-21.2.2-pyhd8ed1ab_0\r\nLinking pyopenssl-20.0.1-pyhd8ed1ab_0\r\nLinking urllib3-1.26.6-pyhd8ed1ab_0\r\nLinking requests-2.26.0-pyhd8ed1ab_0\r\nLinking conda-4.10.3-py39h2804cbe_0\r\nTransaction finished\r\ninstallation finished.\r\n==> Linking Binary 'conda' to '/usr/local/bin/conda'\r\n\ud83c\udf7a  miniforge was successfully installed!\r\n\r\n(base) Anshul@Anshuls-MacBook-Pro ~ % conda install -y jupyter\r\n\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: done\r\n\r\n# All requested packages already installed.\r\n\r\n```\r\n</details>\r\n\r\nFrom there, I tried to set up an environment, where things started to go wrong. \r\n\r\n<details open>\r\n<summary>I had a problem installing dependencies from a file called `tensorflow-apple-metal.yml` with this content:</summary>\r\n<br>\r\n\r\n```\r\nname: tensorflow\r\n \r\ndependencies:\r\n    - python=3.9\r\n    - pip>=19.0\r\n    - jupyter\r\n    - apple::tensorflow-deps\r\n    - scikit-learn\r\n    - scipy\r\n    - pandas\r\n    - pandas-datareader\r\n    - matplotlib\r\n    - pillow\r\n    - tqdm\r\n    - requests\r\n    - h5py\r\n    - pyyaml\r\n    - flask\r\n    - boto3\r\n    - pip:\r\n        - tensorflow-macos\r\n        - tensorflow-metal\r\n        - bayesian-optimization\r\n        - gym\r\n        - kaggle\r\n```\r\n\r\n</details>\r\n\r\n\r\nThis was installed in the `ML` directory (from the guide I linked above) and I ran the following code afterwards:\r\n\r\n```\r\n(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow\r\n\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed\r\n\r\nResolvePackageNotFound: \r\n  - apple::tensorflow-deps\r\n```\r\n\r\nAfter some googling with this error, I moved `- apple::tensorflow-deps`  below `pip`, and reran this line of code. It installed all the dependencies and displayed *another* error at the bottom: \r\n<details>\r\n<summary>Here's what my terminal displayed (very long, scroll to bottom of output)</summary>\r\n<br>\r\n\r\n```\r\n(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed\r\n\r\nResolvePackageNotFound: \r\n  - apple::tensorflow-deps\r\n\r\n(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n\r\nDownloading and Extracting Packages\r\nscikit-learn-0.24.2  | 5.0 MB    | ################################################################################################################################################################################################################################### | 100% \r\npillow-8.3.1         | 602 KB    | ################################################################################################################################################################################################################################### | 100% \r\nnumpy-1.20.3         | 23 KB     | ################################################################################################################################################################################################################################### | 100% \r\njupyter-1.0.0        | 8 KB      | ################################################################################################################################################################################################################################### | 100% \r\npyzmq-20.0.0         | 405 KB    | ################################################################################################################################################################################################################################### | 100% \r\npackaging-21.0       | 36 KB     | ################################################################################################################################################################################################################################### | 100% \r\nbrotlipy-0.7.0       | 333 KB    | ################################################################################################################################################################################################################################### | 100% \r\npyrsistent-0.18.0    | 89 KB     | ################################################################################################################################################################################################################################### | 100% \r\nscipy-1.6.2          | 14.7 MB   | ################################################################################################################################################################################################################################### | 100% \r\nhdf5-1.10.6          | 3.0 MB    | ################################################################################################################################################################################################################################### | 100% \r\njupyter_core-4.7.1   | 68 KB     | ################################################################################################################################################################################################################################### | 100% \r\npandas-datareader-0. | 71 KB     | ################################################################################################################################################################################################################################### | 100% \r\nsetuptools-52.0.0    | 724 KB    | ################################################################################################################################################################################################################################### | 100% \r\nprometheus_client-0. | 47 KB     | ################################################################################################################################################################################################################################### | 100% \r\npyqt-5.9.2           | 3.7 MB    | ################################################################################################################################################################################################################################### | 100% \r\npysocks-1.7.1        | 31 KB     | ################################################################################################################################################################################################################################### | 100% \r\nipykernel-5.3.4      | 180 KB    | ################################################################################################################################################################################################################################### | 100% \r\nlz4-c-1.9.3          | 140 KB    | ################################################################################################################################################################################################################################### | 100% \r\nlibxml2-2.9.12       | 1.1 MB    | ################################################################################################################################################################################################################################### | 100% \r\ncryptography-3.4.7   | 693 KB    | ################################################################################################################################################################################################################################### | 100% \r\nintel-openmp-2021.3. | 950 KB    | ################################################################################################################################################################################################################################### | 100% \r\nwidgetsnbextension-3 | 863 KB    | ################################################################################################################################################################################################################################### | 100% \r\nterminado-0.9.4      | 25 KB     | ################################################################################################################################################################################################################################### | 100% \r\nattrs-21.2.0         | 46 KB     | ################################################################################################################################################################################################################################### | 100% \r\nbotocore-1.20.109    | 3.8 MB    | ################################################################################################################################################################################################################################### | 100% \r\nsix-1.16.0           | 18 KB     | ################################################################################################################################################################################################################################### | 100% \r\nh5py-3.2.1           | 946 KB    | ################################################################################################################################################################################################################################### | 100% \r\nboto3-1.17.109       | 70 KB     | ################################################################################################################################################################################################################################### | 100% \r\npygments-2.9.0       | 721 KB    | ################################################################################################################################################################################################################################### | 100% \r\nmarkupsafe-2.0.1     | 20 KB     | ################################################################################################################################################################################################################################### | 100% \r\nbottleneck-1.3.2     | 111 KB    | ################################################################################################################################################################################################################################### | 100% \r\nmistune-0.8.4        | 57 KB     | ################################################################################################################################################################################################################################### | 100% \r\npyyaml-5.4.1         | 170 KB    | ################################################################################################################################################################################################################################### | 100% \r\npandocfilters-1.4.3  | 14 KB     | ################################################################################################################################################################################################################################### | 100% \r\nchardet-4.0.0        | 195 KB    | ################################################################################################################################################################################################################################### | 100% \r\nbleach-4.0.0         | 113 KB    | ################################################################################################################################################################################################################################### | 100% \r\nclick-8.0.1          | 79 KB     | ################################################################################################################################################################################################################################### | 100% \r\ns3transfer-0.4.2     | 62 KB     | ################################################################################################################################################################################################################################### | 100% \r\nzstd-1.4.9           | 476 KB    | ################################################################################################################################################################################################################################### | 100% \r\nparso-0.8.2          | 69 KB     | ################################################################################################################################################################################################################################### | 100% \r\nbrotli-1.0.9         | 398 KB    | ################################################################################################################################################################################################################################### | 100% \r\nmkl_fft-1.3.0        | 167 KB    | ################################################################################################################################################################################################################################### | 100% \r\ntestpath-0.5.0       | 81 KB     | ################################################################################################################################################################################################################################### | 100% \r\nwebencodings-0.5.1   | 20 KB     | ################################################################################################################################################################################################################################### | 100% \r\nnumexpr-2.7.3        | 124 KB    | ################################################################################################################################################################################################################################### | 100% \r\ncertifi-2021.5.30    | 138 KB    | ################################################################################################################################################################################################################################### | 100% \r\nzipp-3.5.0           | 13 KB     | ################################################################################################################################################################################################################################### | 100% \r\npip-21.2.2           | 1.8 MB    | ################################################################################################################################################################################################################################### | 100% \r\nmkl-2021.3.0         | 100.4 MB  | ################################################################################################################################################################################################################################### | 100% \r\ntzdata-2021a         | 108 KB    | ################################################################################################################################################################################################################################### | 100% \r\nsqlite-3.36.0        | 1.1 MB    | ################################################################################################################################################################################################################################### | 100% \r\nmkl_random-1.2.2     | 285 KB    | ################################################################################################################################################################################################################################### | 100% \r\ncycler-0.10.0        | 16 KB     | ################################################################################################################################################################################################################################### | 100% \r\nmatplotlib-3.4.2     | 26 KB     | ################################################################################################################################################################################################################################### | 100% \r\nca-certificates-2021 | 113 KB    | ################################################################################################################################################################################################################################### | 100% \r\ncached-property-1.5. | 11 KB     | ################################################################################################################################################################################################################################### | 100% \r\nthreadpoolctl-2.2.0  | 16 KB     | ################################################################################################################################################################################################################################### | 100% \r\nnumpy-base-1.20.3    | 4.3 MB    | ################################################################################################################################################################################################################################### | 100% \r\nitsdangerous-2.0.1   | 18 KB     | ################################################################################################################################################################################################################################### | 100% \r\npython-3.9.6         | 9.7 MB    | ################################################################################################################################################################################################################################### | 100% \r\nnbconvert-6.1.0      | 484 KB    | ################################################################################################################################################################################################################################### | 100% \r\ntornado-6.1          | 587 KB    | ################################################################################################################################################################################################################################### | 100% \r\nmkl-service-2.4.0    | 45 KB     | ################################################################################################################################################################################################################################### | 100% \r\nmunkres-1.1.4        | 13 KB     | ################################################################################################################################################################################################################################### | 100% \r\nmatplotlib-inline-0. | 12 KB     | ################################################################################################################################################################################################################################### | 100% \r\njinja2-3.0.1         | 110 KB    | ################################################################################################################################################################################################################################### | 100% \r\njedi-0.18.0          | 909 KB    | ################################################################################################################################################################################################################################### | 100% \r\nlxml-4.6.3           | 1.2 MB    | ################################################################################################################################################################################################################################### | 100% \r\npandas-1.3.1         | 9.2 MB    | ################################################################################################################################################################################################################################### | 100% \r\nfonttools-4.25.0     | 632 KB    | ################################################################################################################################################################################################################################### | 100% \r\ntqdm-4.62.0          | 83 KB     | ################################################################################################################################################################################################################################### | 100% \r\nmatplotlib-base-3.4. | 5.6 MB    | ################################################################################################################################################################################################################################### | 100% \r\nsip-4.19.13          | 243 KB    | ################################################################################################################################################################################################################################### | 100% \r\ncffi-1.14.6          | 215 KB    | ################################################################################################################################################################################################################################### | 100% \r\nopenjpeg-2.3.0       | 281 KB    | ################################################################################################################################################################################################################################### | 100% \r\npython-dateutil-2.8. | 233 KB    | ################################################################################################################################################################################################################################### | 100% \r\nqtconsole-5.1.0      | 98 KB     | ################################################################################################################################################################################################################################### | 100% \r\nnotebook-6.4.1       | 4.1 MB    | ################################################################################################################################################################################################################################### | 100% \r\nimportlib-metadata-3 | 33 KB     | ################################################################################################################################################################################################################################### | 100% \r\njmespath-0.10.0      | 23 KB     | ################################################################################################################################################################################################################################### | 100% \r\nurllib3-1.26.6       | 112 KB    | ################################################################################################################################################################################################################################### | 100% \r\ndecorator-5.0.9      | 12 KB     | ################################################################################################################################################################################################################################### | 100% \r\nentrypoints-0.3      | 12 KB     | ################################################################################################################################################################################################################################### | 100% \r\nappnope-0.1.2        | 10 KB     | ################################################################################################################################################################################################################################### | 100% \r\nipython-7.26.0       | 996 KB    | ################################################################################################################################################################################################################################### | 100% \r\nargon2-cffi-20.1.0   | 44 KB     | ################################################################################################################################################################################################################################### | 100% \r\nkiwisolver-1.3.1     | 53 KB     | ################################################################################################################################################################################################################################### | 100% \r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: | \r\n\r\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\r\n    More details are available here: https://intel.github.io/scikit-learn-intelex\r\n\r\n    For example:\r\n\r\n        $ conda install scikit-learn-intelex\r\n        $ python -m sklearnex my_application.py\r\n\r\n    \r\n\r\ndone\r\nInstalling pip dependencies: / Ran pip subprocess with arguments:\r\n['/opt/anaconda3/envs/tensorflow/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/Anshul/Documents/ML/condaenv.u702ztn8.requirements.txt']\r\nPip subprocess output:\r\n\r\nPip subprocess error:\r\n  ERROR: Invalid requirement: 'apple::tensorflow-deps' (from line 6 of /Users/Anshul/Documents/ML/condaenv.u702ztn8.requirements.txt)\r\n\r\nfailed\r\n\r\nCondaEnvException: Pip failed\r\n```\r\n</details>\r\n<br>\r\n\r\nAfter installing this, I ignored the error and went along with the rest of the installation process, and had a few *more* errors along the way. Here's my terminal input and output directly after the terminal output from above:\r\n<br>\r\n```\r\n(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow\r\n\r\nCondaValueError: prefix already exists: /opt/anaconda3/envs/tensorflow\r\n\r\n(base) Anshul@Anshuls-MacBook-Pro ML % conda activate tensorflow\r\n(tensorflow) Anshul@Anshuls-MacBook-Pro ML % conda install nb_conda\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: / \r\nFound conflicts! Looking for incompatible packages.\r\nThis can take several minutes.  Press CTRL-C to abort.\r\nfailed                                                                                                                                                                                                                                                                        \r\n\r\nUnsatisfiableError: The following specifications were found\r\nto be incompatible with the existing python installation in your environment:\r\n\r\nSpecifications:\r\n\r\n  - nb_conda -> python[version='>=2.7,<2.8.0a0|>=3.6,<3.7.0a0|>=3.7,<3.8.0a0|>=3.8,<3.9.0a0|>=3.5,<3.6.0a0']\r\n\r\nYour python: python=3.9\r\n\r\nIf python is on the left-most side of the chain, that's the version you've asked for.\r\nWhen python appears to the right, that indicates that the thing on the left is somehow\r\nnot available for the python version you are constrained to. Note that conda will not\r\nchange your python version to a different minor version unless you explicitly specify\r\nthat.\r\n\r\n\r\n\r\n(tensorflow) Anshul@Anshuls-MacBook-Pro ML % python -m ipykernel install --user --name tensorflow --display-name \"Python 3.9 (tensorflow)\"\r\n\r\nInstalled kernelspec tensorflow in /Users/Anshul/Library/Jupyter/kernels/tensorflow\r\n(tensorflow) Anshul@Anshuls-MacBook-Pro ML % jupyter notebook\r\n```\r\n\r\nJupyter Notebook is able to run, but once I create a new tensorflow notebook and run `import tensorflow`, I get the error `ModuleNotFoundError: No module named 'tensorflow'`. \r\n\r\nI've spent half the day trying to set up Tensorflow on my M1 Mac but keep falling into loops of errors, hence I spent over an hour writing this issue. Anything I seem to alter always causes another issue, and it's a little frustrating given that I haven't been able to even start using ML on my local machine yet. Any help at all would be really appreciated. Thanks!\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nAttached a [txt file](https://github.com/tensorflow/tensorflow/files/6959610/pain.txt).", "comments": ["@theAnshulGupta ,\r\n\r\nPlease refer to similar issues #44751,#47782 and for installation please take a look at this [link](https://github.com/apple/tensorflow_macos). It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi, thanks for the help! Unfortunately, those two issues weren't too helpful, however I followed the [guide](https://developer.apple.com/metal/tensorflow-plugin/) linked in [Apple's TF Repository](https://github.com/apple/tensorflow_macos) to set up tensorflow-metal. The installation did not present any problems however whenever I start a notebook and import tensorflow, it keeps giving the callback `ModuleNotFoundError: No module named 'tensorflow'` or says `The kernel appears to have died. It will restart automatically.`", "@theAnshulGupta ,\r\nPlease take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/50541#issuecomment-890051213) from the issue with similar error.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51403\">No</a>\n", "if you trying installing tensorflow from [this video](https://www.youtube.com/watch?v=_CO-ND1FTOU&ab_channel=JeffHeaton) then  you need to read his [documentation](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb)  carefully\r\n![image](https://user-images.githubusercontent.com/43084057/141109557-92f554b1-0892-403e-8610-56fec46cda1d.png)\r\n"]}, {"number": 51402, "title": "Gather not working as expected in TFLite", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIn TFLite, gather over a tensor of string types fails.\r\n\r\n**Describe the expected behavior**\r\nI expect it to behave in the same way gather over integer types does\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnames = tf.keras.Input(shape=(2,), dtype=tf.string)\r\nmodel = tf.keras.Model(\r\n    inputs=names,\r\n    outputs=tf.gather(names, tf.constant([0])),\r\n)\r\n\r\nmodel.save('./export')\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('./export')\r\ntflite_model = converter.convert()\r\nwith open('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_path='model.tflite')\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninterpreter.set_tensor(input_details[0]['index'], np.array([[1, 2]], dtype=np.string))\r\ninterpreter.invoke()\r\ninterpreter.get_tensor(output_details[0]['index'])\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-19-533b631ac475> in <module>\r\n     15 \r\n     16 interpreter = tf.lite.Interpreter(model_path='model.tflite')\r\n---> 17 interpreter.allocate_tensors()\r\n     18 input_details = interpreter.get_input_details()\r\n     19 output_details = interpreter.get_output_details()\r\n\r\n/code/venvs/venv/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)\r\n    406   def allocate_tensors(self):\r\n    407     self._ensure_safe()\r\n--> 408     return self._interpreter.AllocateTensors()\r\n    409 \r\n    410   def _safe_to_run(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/gather.cc:76 NumDimensions(input) != 1 (2 != 1)Node number 0 (GATHER) failed to prepare.\r\n```\r\n\r\nChanging the types from `string` to `int64` returns `array([[1, 2]])`, though I don't totally understand why it doesn't return `array([1, 2])`\r\n", "comments": ["Does the keras model work with the above input given to the TensorFlow Lite as well? If not, it might be an intended behavior.", "The keras model works as intended\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnames = tf.keras.Input(shape=(2,), dtype=tf.string)\r\nmodel = tf.keras.Model(\r\n    inputs=names,\r\n    outputs=tf.gather(names, tf.constant([0])),\r\n)\r\n\r\nmodel(np.array([1, 2], dtype=np.str))\r\n```\r\n\r\n```\r\n<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>\r\n```", "TFLite's Gather kernel does not support >1 dimensions in its inputs. So, assuming you want to run single-batch inference, this code works (Note the `reshape` to 1-dim tensor before `tf.gather`):\r\n\r\n```\r\n  names = tf.keras.Input(shape=(2,), dtype=tf.string, batch_size=1)\r\n  model = tf.keras.Model(\r\n      inputs=names,\r\n      outputs=tf.gather(tf.reshape(names, [2]), tf.constant([0])),\r\n  )\r\n\r\n  print(\"KERAS OUTPUT IS\", model(np.array([1, 2], dtype=np.str)))\r\n\r\n  model.save('./output')\r\n  converter = tf.lite.TFLiteConverter.from_saved_model('./output')\r\n  tflite_model = converter.convert()\r\n  with open('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n  interpreter = tf.lite.Interpreter(model_path='model.tflite')\r\n  interpreter.allocate_tensors()\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n  interpreter.set_tensor(input_details[0]['index'], np.array([[1, 2]], dtype=np.str))\r\n  interpreter.invoke()\r\n  print(\"TFLITE OUTPUT IS\", interpreter.get_tensor(output_details[0]['index']))\r\n```", "@srjoglekar246 thanks, this works for me. In regards to not supporting >1 dimensions, is using `batch_dims=1` in the gather call also not supported in TFLite?", "Yeah, any two-dimensional tensor is rejected by the TFLite op (unfortunately). But reshaping the input as suggested above should do the trick. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51402\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51402\">No</a>\n", "https://github.com/tensorflow/tensorflow/commit/d76fbad66d84c5e051a0f90c4d73278856f2e22a fixes the converter issue.\r\n\r\nNow, the above original model will require the Select TF op since TFLite gather op can not handle the 2D string inputs."]}]