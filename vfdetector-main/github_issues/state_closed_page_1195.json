[{"number": 17333, "title": "map_fn produces inconsistent results when using numpy vs. tf constants", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Nope\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 9, cudnn 7\r\n- **GPU model and memory**: Quadro M1200 4GB\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nAccording to the map_fn docs, second example https://www.tensorflow.org/api_docs/python/tf/map_fn\r\n\r\n```\r\nelems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\r\nalternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\r\n## alternate == [-1, 2, -3]\r\n```\r\n\r\nI ran this\r\n\r\n```\r\nelems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\r\noutput = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\r\nsess = tf.Session()\r\nprint(sess.run(output))\r\n```\r\n\r\nwhich returns `[-1  2 -3]` as expected\r\n\r\nBut if I run\r\n\r\n```\r\nelems = tf.constant(((1, 2, 3), (-1, 1, -1)), dtype=tf.int64)\r\noutput = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\r\nsess = tf.Session()\r\nprint(sess.run(output))\r\n```\r\n\r\nThe output is `[2 -1]`, which is not what I expected since the input is the same numbers with the same shape.\r\n\r\nThe output should be the same? Is there something special going on with numpy arrays?\r\n\r\nInteresting read: https://stackoverflow.com/questions/45905601/how-does-tf-map-fn-work", "comments": ["No, if you replace the values you'll understand what's happening. \r\nFor example, try this:  `elems = tf.constant(((10, 2, 3), (-10, 2, -1)), dtype=tf.int64)`\r\nIt will output `[ 20 -20]`.\r\nAs you can see, when using constants `map_fn` thinks you want to apply the lambda function to the vectors, not the matrix.  Not sure it's an expected behavior though.\r\n", "Hmm, I read the source code and it checks if the input is a sequence. But this behaviour seems to be vaguely documented though."]}, {"number": 17332, "title": "Feature request: fft support for complex128 ", "body": "Tensorflow fft only supports complex64 types at the moment. I have a physics application that could make great use of tensorflow's architecture, which is not machine learning related but needs greater precision.\r\n\r\nSince [pyculib](http://pyculib.readthedocs.io/en/latest/cufft.html) supports complex128, it should be available from nvidia. \r\n\r\nIs there support planned in the future?", "comments": ["@rmlarsen Is this on a roadmap of ours?", "Assigning to @rmlarsen because fft support for complex128 sounds like something we should have.", "I think complex128 for FFT  has been introduced in 8f0a90b7114. ", "Nagging Assignee @rmlarsen: It has been 151 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing since complex128 for fat has been added in 8f0a90b, but feel free to reopen if the issue still exists. Thanks for the contribution!", "I'll test it at some point in the future, may take some time.\r\nThe documentation is a bit misleading:\r\n[tf.spectral.fft](https://www.tensorflow.org/api_docs/python/tf/spectral/fft)\r\ninput: A Tensor. Must be one of the following types: complex64, complex128. A complex64 tensor.\r\n\r\nThis is probably not intentional?", "@mmlanger I think the documentation was unintentional. I have created the PR #23000 for the doc fix."]}, {"number": 17331, "title": "C++ gradients: Fractional*Pool, Soft{Plus,Sign}", "body": "I also ran the newly added tests multiple times to check for flakes, seems ok.\r\n\r\n```\r\n$ bazel test --runs_per_test=1000 tensorflow/cc:gradients_nn_grad_test\r\n...\r\n//tensorflow/cc:gradients_nn_grad_test                                   PASSED in 0.5s\r\n  Stats over 1000 runs: max = 0.5s, min = 0.3s, avg = 0.4s, dev = 0.0s\r\n```\r\n\r\nResolves https://github.com/tensorflow/tensorflow/issues/17330", "comments": ["Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @suharshs: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?"]}, {"number": 17330, "title": "C++ gradients: fractional{agv,max}pool, soft{plus,sign}", "body": "Adding gradients to the C++ API for these look straightforward, as there are existing kernel ops for their gradients. If nobody has already started, I can sign up for these.\r\n\r\n/cc @bpiel @suharshs ", "comments": ["@kbsriram Go for it! "]}, {"number": 17329, "title": "fix a typo", "body": "should be tf.zeros_initializer()", "comments": ["Using `zeros_initializer` without calling it actually works. See the logic at: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variable_scope.py#L781", "Thank you again, sq! I tested TensorFlow 1.0 and current version, and check the codes.  In TF 1.0, using `zeros_initializer` won't work because the codes are different, but `zeros_initializer()` has no problem. For consistency's sake within the [Vafiables](https://tensorflow.google.cn/programmers_guide/variables) document, I still believe it would be a good thing to point out both circumstances works or use either. "]}, {"number": 17328, "title": "Feature Request: Training on device", "body": "Hi Tensorflow,\r\n\r\nI would like to know whether Tensorflow does support on-device training i.e creation of model on Android device. Right now Tensorflow provides Python script to generate model in the Native system and only inference we can execute on Android device. Obviously i cannot execute the Python to create the model in Android, does Tensorflow provides any Example/Feature in C++ to train the model on-device (Android)  ? \r\n\r\nFeature Request \r\n\r\n1. A Standalone C++ Application which can be cross compiled for Android to train the model from dataset. \r\n\r\n2. Training the model might be time consuming process if done on Android, but at least some minimal support for smaller data set would be helpful.\r\n\r\n\r\nRegards,\r\nSenthil\r\n", "comments": ["@aselle This seems TF Lite related, can you take a look?", "[TensorFlow mobile](https://www.tensorflow.org/mobile/mobile_intro) runs on Android and iOS and does support training as well. One way you could do this is to create the model using the Python libraries and then load and train it on Android, using the C++ APIs.\r\n\r\nHere's [a blog](https://tebesu.github.io/posts/Training-a-TensorFlow-graph-in-C++-API) that does something similar (although not on mobile). \r\n\r\nIn the future [TensorFlow Lite](https://www.tensorflow.org/mobile/tflite/) will also support training. ", "@rajatmonga Thanks for the inputs!\r\nBut, tensorflow still needs to be cross compiled for that device before being used. In case of Android, the libtensroflow_inference.so is just the inference only library, whereas for training we would need the complete library. Is there a ready build to cross compile tensorflow using NDK toolchain for complete library? ", "@milinddeore The builds with JavaCPP contain pretty much all that we can get working on Android. It's not the inference-only and/or lite version or anything:\r\nhttps://github.com/bytedeco/javacpp-presets/tree/master/tensorflow\r\nhttp://bytedeco.org/builds/\r\nPlease let me know if there's anything missing though!", "Adding @aselle and @petewarden who may have more pointers for building TensorFlow for Android for training your model. ", "Is there anybody who tried that on Android? I've seen this piece: https://tebesu.github.io/posts/Training-a-TensorFlow-graph-in-C++-API and here https://github.com/chelexa/tensorflow-on-android \r\n\r\nIs Androids Tensorflow Lite capable to do the training job and if so how? \r\n\r\nHelp much appreciated! ", "The tensorflow mobile link just redirects to tensorflow lite now, and it seems impossible to actually find any official page for tensorflow mobile anymore. This and the tf lite roadmap are the only places where training on device is mentioned. What gives? Where can we track work on this? Why is this issue closed, is there an equivalent tf lite issue? ", "Is training on device already possible (iOS)?", "TensorFlow Lite now supports training your models on-device, in addition to running inference. On-device training enables interesting personalization use cases where models can be fine-tuned based on user needs\r\n\r\nCheck this: https://blog.tensorflow.org/2021/11/on-device-training-in-tensorflow-lite.html"]}, {"number": 17327, "title": "tf.data.Dataset.padded_batch() should support padding to nearest N bytes", "body": "### System information\r\nTF 1.5\r\nPython 3.6.4 (Anaconda)\r\n\r\n### Problem description\r\nIf using `tf.data.Dataset.padded_batch()` on input with variable size, it looks like there is significant overhead first time a batch with examples of size X is used on GPU. If batch with examples of size X is used second time, the execution is approx. 4x faster. (I suppose it is due to a way tensorflow handles data.)\r\n\r\nIn case the input size varies a lot, this slows the computation enormously. It could be solved by padding the batch to nearest N bytes so that there is only limited number of sizes pushed onto GPU and overhead thus becomes negligible.\r\n\r\n### Solution\r\nIt would be great if `padded_batch` supported argument `pad_to_nearest_bytes` or/and `allowed_batch_sizes` for enumeration of possible sizes.\r\n\r\nProof:\r\n```\r\nTIME    BATCH_SIZE (2nd dimension = the data size)\r\n0.15205 20480\r\n0.06180 20480\r\n0.80608 147456\r\n0.24141 147456\r\n0.74360 135168\r\n0.21659 135168\r\n0.58724 98304\r\n0.16206 98304\r\n0.05387 20480\r\n0.05694 20480\r\n0.53993 90112\r\n0.15452 90112\r\n0.23547 147456\r\n0.23576 147456\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This can already be done with more flexibility using `Dataset.map(lambda x: tf.pad(...))`, so I don't think there's any need at the present time to extend `Dataset.padded_batch()` to support it."]}, {"number": 17326, "title": "Fix batch input in TFLite multithreaded 1x1 conv", "body": "Fix the issue that batch size is hard-coded as 1 in TFLite\r\nmultithreaded_ops::Conv() when filter size is 1x1 or filter and\r\ninput have the same size.", "comments": ["Hi @aselle , this might be a blocking issue if one need to run batch inference for model with 1x1 conv (e.g. mobilenet). Hope to get some feedback about this PR sooner :smile: ", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 152 days with no activity and the `awaiting review` label has been applied.", "Looks like the issues have been fixed and related test cases have been added. After all, almost 7 months has passed since this PR was created.  Related commits are as follows:\r\n- 645291feb9455c20c8d7296455403e895b5e0d1c : Fix TfLite Convolution handle input_bacthe incorrectly for 1*1 kernel, and improve test coverage for conv ops.\r\n- 4902db818664b62f60c0f9572cc939f596d1c8bc : Fixes to hybrid conv. Add additional tests for pointwise conv.\r\n- 6995d2b9be0e398f11a17348eb5b4745aee0af0d : Fix convolution bug when input and filter dimensions match.\r\n\r\nI will close this outdated PR. @aselle \r\n\r\n"]}, {"number": 17325, "title": "Resource exhausted: OOM when allocating tensor with shape, even when batch_size is 1.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI've registered a new problem for translating English to Swedish, the code is pretty similar to TranslateEndeWmtBpe32k, with Europarl data. I'm able to train with hidden_size: 128, anything over 128 and I get Resource exhausted error, even when batch size is 1. (I'm using hparams: transformer_big).\r\n\r\nI notice that previous posts on this issue were solved by reducing the batch size. I'm posting this because reducing batch size wasn't helpful and I'm hoping if someone encountered a similar issue.\r\n\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux deepnlp01 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n  4 VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\ntf.VERSION = 1.4.1 (Installed from source)\r\n\r\n- **Python version**: \r\n2.7.6\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.2\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n\r\n- **CUDA/cuDNN version**:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCuda compilation tools, release 8.0, V8.0.61\r\n\r\n- **GPU model and memory**:\r\nNVIDIA TITAN X (12GB)\r\n\r\n- **Exact command to reproduce**:\r\nUSR_DIR=<path>/python2.7/site-packages/tensor2tensor/<new_module>\r\n\r\nt2t-trainer \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problems=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n  --t2t_usr_dir=$USR_DIR\r\n\r\n### Describe the problem\r\n\r\nThe data I'm using is parallel corpus English-Swedish, available on http://www.statmt.org/europarl/ . I've created a dictionary myself of about 1,400,000 (1.4 million) words. [The problem persists even if I use a smaller vocab of about 10k words]\r\n\r\nI'm able to train with batch_size=1024 and hidden_size=128, if I increase the hidden size to 256, even with batch_size=1, it runs out of memory. I get the following error.\r\n\r\n### Source code / logs\r\nThis is the error I'm encountering:\r\n\r\n```\r\n2018-02-28 05:48:52.977027: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[90993,256]\r\n\r\nTraceback (most recent call last):\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\r\n    tf.app.run()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\r\n    execute_schedule(exp)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\r\n    hooks=self._train_monitors)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[90992,256]\r\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\r\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'training/gradients/AddN_96', defined at:\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\r\n    tf.app.run()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\r\n    execute_schedule(exp)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\r\n    hooks=self._train_monitors)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 711, in _train_model\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 694, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 829, in wrapping_model_fn\r\n    use_tpu=use_tpu)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 923, in estimator_model_fn\r\n    loss, num_async_replicas=num_async_replicas)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 927, in estimator_spec_train\r\n    train_op = self.optimize(loss, num_async_replicas=num_async_replicas)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 351, in optimize\r\n    loss, lr, self.hparams, use_tpu=common_layers.is_on_tpu())\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 67, in optimize\r\n    colocate_gradients_with_ops=True)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 241, in optimize_loss\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 109, in compute_gradients\r\n    return self._opt.compute_gradients(loss, var_list, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 533, in gradients\r\n    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 872, in _AggregatedGrads\r\n    out_grads[i] = _MultiDeviceAddN(out_grad)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 767, in _MultiDeviceAddN\r\n    summands.append(math_ops.add_n(tensors))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2000, in add_n\r\n    return gen_math_ops._add_n(inputs, name=name)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 220, in _add_n\r\n    \"AddN\", inputs=inputs, name=name)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[90992,256]\r\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\r\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n```\r\nThis is the code that I've modified:\r\n\r\n```\r\ndef _get_europarl_ensv_dataset(directory, filename):\r\n    \"\"\"Extract the EuroParl en-sv corpus `filename` to directory unless it's there.\"\"\"\r\n\r\n    train_path = os.path.join(directory, filename)\r\n\r\n    return train_path\r\n\r\n\r\n@registry.register_problem\r\nclass TranslateEnsvEuroparl(translate.TranslateProblem):\r\n    \"\"\"Problem spec for EuroParl En-Sv translation, BPE version.\"\"\"\r\n\r\n    @property\r\n    def approx_vocab_size(self):\r\n        return 1455877\r\n\r\n    @property\r\n    def vocab_filename(self):\r\n        return \"vocab.europarl.ensv.txt\"\r\n\r\n    def get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):\r\n        vocab_filename = os.path.join(data_dir, self.vocab_filename)\r\n        if not tf.gfile.Exists(vocab_filename) and force_get:\r\n            raise ValueError(\"Vocab %s not found\" % vocab_filename)\r\n        return text_encoder.TokenTextEncoder(vocab_filename, replace_oov=\"UNK\")\r\n\r\n    def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n        \"\"\"Instance of token generator for the WMT en->de task, training set.\"\"\"\r\n        train = dataset_split == problem.DatasetSplit.TRAIN\r\n        dataset_path = (\"europarl-v7.train.sv-en\"\r\n                        if train else \"europarl-v7.test.sv-en\")\r\n        train_path = _get_europarl_ensv_dataset(tmp_dir, dataset_path)\r\n\r\n        # Vocab\r\n        token_path = os.path.join(data_dir, self.vocab_filename)\r\n        if not tf.gfile.Exists(token_path):\r\n            token_tmp_path = os.path.join(tmp_dir, self.vocab_filename)\r\n            tf.gfile.Copy(token_tmp_path, token_path)\r\n            with tf.gfile.GFile(token_path, mode=\"r\") as f:\r\n                vocab_data = \"<pad>\\n<EOS>\\n\" + f.read() + \"UNK\\n\"\r\n            with tf.gfile.GFile(token_path, mode=\"w\") as f:\r\n                f.write(vocab_data)\r\n\r\n        return text_problems.text2text_txt_iterator(train_path + \".en\",\r\n                                                    train_path + \".sv\")\r\n\r\n```", "comments": []}, {"number": 17324, "title": "tensorflow lite build issue", "body": "Build fails because of LICENSE is not available inside lite dir. Need to remove a small line of code to keep it running. File location is tensorflow/tensorflow/contrib/lite/BUILD\r\n\r\n", "comments": []}, {"number": 17323, "title": "Save activation map for a specific convnet in the process of tf.train.MonitoredTrainingSession()", "body": "ADDING FEATURES\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9', '1.4.1')\r\n- **Python version**:  2.7 anaconda\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: Quadro K400\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI followed this tutorial from the source code of TF: **model/tutorials/image/cifar10/**, in the tutorial, you used tf.train.MonitoredTrainingSession() to log the checkpoint or tensor for future usage with TensorBoard, my question is to display the activation maps of my convnet during training process. But inside the:\r\n`while not mon_sess.should_stop():\r\n             mon_sess.run(train_op)`\r\n\r\nI can not add new tensor because the Graph is finalized. So I want to ask you how to add something like **tf.summary.image**: Pass one example image to a specific convnet  after relu, and save it as png for all the filters???\r\n\r\nI think I can easily implement this in a normal **tf.Session()**, but I am still interested if we can do it in **tf.train.MonitoredTrainingSession()**.\r\n\r\nI think that would be great for the newbie to understand what happened for our CNN.\r\n\r\nThanks in advance\r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\n(That said, to give you some hints -  you can insert summary operations in the definition of your model, for example, in the [`inference()`](https://github.com/tensorflow/models/blob/r1.6.0/tutorials/image/cifar10/cifar10.py#L188) function in the tutorial code, that builds the graph for the forward pass).\r\n\r\nHope that helps."]}, {"number": 17322, "title": "A bug When use kmean and tensorboard", "body": "When I use the tensorboard in kmeans it cause an error, if i remove the merge_summary_op with `_, d, idx = sess.run([train_op, avg_distance, cluster_idx], feed_dict={X: full_data_x})`, it will be ok!!!  I don't know why the merge op will cause the error, could anyone help me with  ?\r\n\r\n```\r\nInvalidArgumentError: Shape [-1,784] has negative dimensions\r\n\t [[Node: Placeholder_28 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'Placeholder_28', defined at:\r\n  File \"/Users/burness/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\r\n    self._handle_recv()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-830a4475ac2c>\", line 26, in <module>\r\n    X = tf.placeholder(tf.float32, shape=[None, num_features])\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\r\n    name=name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Shape [-1,784] has negative dimensions\r\n\t [[Node: Placeholder_28 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n\r\n\r\n\u200b\r\nExtracting /tmp/data/train-images-idx3-ubyte.gz\r\nExtracting /tmp/data/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/data/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/data/t10k-labels-idx1-ubyte.gz\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-5-77f99f84eb11> in <module>()\r\n     54 for i in range(1, num_steps + 1):\r\n     55     _, d, idx, summary = sess.run([train_op, avg_distance, cluster_idx, merged_summary_op],\r\n---> 56                          feed_dict={X: full_data_x})\r\n     57 #     summary_writer.add_summary(summary, i)\r\n     58     if i % 10 == 0 or i == 1:\r\n\r\n/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    787     try:\r\n    788       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 789                          run_metadata_ptr)\r\n    790       if run_metadata:\r\n    791         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    995     if final_fetches or final_targets:\r\n    996       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 997                              feed_dict_string, options, run_metadata)\r\n    998     else:\r\n    999       results = []\r\n\r\n/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1130     if handle is None:\r\n   1131       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1132                            target_list, options, run_metadata)\r\n   1133     else:\r\n   1134       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1150         except KeyError:\r\n   1151           pass\r\n-> 1152       raise type(e)(node_def, op, message)\r\n   1153 \r\n   1154   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Shape [-1,784] has negative dimensions\r\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'Placeholder', defined at:\r\n  File \"/Users/burness/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\r\n    self._handle_recv()\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-b3a44847e28e>\", line 25, in <module>\r\n    X = tf.placeholder(tf.float32, shape=[None, num_features])\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\r\n    name=name)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Shape [-1,784] has negative dimensions\r\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\n\r\n```\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.factorization import KMeans\r\n\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\r\nlogs_path = '/tmp/tensorflow_logs/k-means'\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\r\nfull_data_x = mnist.train.images\r\n\r\nnum_steps = 50 \r\nbatch_size = 1024\r\nk = 25 \r\nnum_classes = 10\r\nnum_features = 784 \r\n\r\nX = tf.placeholder(tf.float32, shape=[None, num_features])\r\n# Labels (for assigning a label to a centroid and testing)\r\nY = tf.placeholder(tf.float32, shape=[None, num_classes])\r\n\r\n# K-Means Parameters\r\nkmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',\r\n                use_mini_batch=True)\r\n\r\ntraining_graph = kmeans.training_graph()\r\n\r\nif len(training_graph) > 6: # Tensorflow 1.4+\r\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\r\n     cluster_centers_var, init_op, train_op) = training_graph\r\nelse:\r\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\r\n     init_op, train_op) = training_graph\r\n\r\ncluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\r\navg_distance = tf.reduce_mean(scores)\r\ntf.summary.scalar(\"avg_distance\", avg_distance)\r\n\r\ninit_vars = tf.initialize_all_variables()\r\nmerged_summary_op = tf.summary.merge_all()\r\n\r\nsess = tf.Session()\r\n\r\nsess.run(init_vars)\r\nsummary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\r\nsess.run(init_op, feed_dict={X: full_data_x})\r\n\r\nfor i in range(1, num_steps + 1):\r\n    _, d, idx, summary = sess.run([train_op, avg_distance, cluster_idx, merged_summary_op],\r\n                         feed_dict={X: full_data_x})\r\n    summary_writer.add_summary(summary, i)\r\n    if i % 10 == 0 or i == 1:\r\n        print(\"Step %i, Avg Distance: %f\" % (i, d))\r\n\r\n\r\ncounts = np.zeros(shape=(k, num_classes))\r\nfor i in range(len(idx)):\r\n    counts[idx[i]] += mnist.train.labels[i]\r\n\r\nlabels_map = [np.argmax(c) for c in counts]\r\nlabels_map = tf.convert_to_tensor(labels_map)\r\n\r\n\r\ncluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\r\ncorrect_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\r\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\ntest_x, test_y = mnist.test.images, mnist.test.labels\r\nprint(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\r\n\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17321, "title": "toco convert to lite model incorrectly with slim.batch_norm not follows after conv.", "body": "### System information\r\n- **OS Platform and Distribution Linux Ubuntu 14.04**:\r\n- **TensorFlow installed from binary**:\r\n- **TensorFlow version 1.6.rc1**:\r\n- **Python version 3.6**: \r\n- **Have I written custom code N/A**:\r\n- **Bazel version N/A**:\r\n- **CUDA/cuDNN version N/A**:\r\n- **GPU model and memory N/A**:\r\n- **Exact command to reproduce N/A**:\r\n\r\nI create simple model with slim and convert lite model using toco\r\n```python\r\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\r\n      net = input\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\r\n      net = slim.batch_norm(net)\r\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\r\n      net = slim.batch_norm(net)\r\n      ...\r\n```\r\nThe converted lite model from it can't allocate tensor with error \r\n`tensorflow\\contrib\\lite\\kernels\\mul.cc:48 NumDimensions(input1) != NumDimensions(input2) (4 != 1)`\r\n\r\nbut if I insert conv2d layer befor batch_norm, the result is ok.\r\n```python\r\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\r\n      net = input\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\r\n      net = slim.batch_norm(net)\r\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv111')\r\n      net = slim.batch_norm(net)\r\n      ...\r\n```\r\nI had try insert relu and the other layers before batch_norm, but it can't allocate tensor when previous layer is not conv.\r\nHow can I create batch_norm after any layer?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "do you solve the problem now?", "@coutner not yet!", "Can you add a trivial 1x1, stride 1 conv at the end so that there is always a conv following every batch norm? Is there a reason you put the bn's after the conv's? The usual idea is that the bn's precondition the batch to have nice statistics before applying conv.\r\n", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 17320, "title": "Require a c++ example or documents about tensorflow lite useage", "body": "because i have my own native and c++ code, if i want to use tensorflow lite feature and put it to my android project, i have to write tensorflow lite code in c++.\r\nbut it is too hard to find out how to get the input and output.\r\ni have look up the ios example because part of the code is written in c++, but it crashed when i have:\r\nfloat* output = interpreter->typed_output_tensor<float>(0);\r\nfor(int i = 0; i < output_size; i++)\r\n        LOGD(\"bkzero jni: , result: %f\", output[i]);\r\ni believe it is not a bug under iOS platform.\r\nthis part of code in android example is written in java, i cannot figure out how to write an implemetation of the tensorhandle like:\r\nlong[] outputsHandles =\r\n        run(interpreterHandle, errorHandle, sizes, dataTypes, numsOfBytes, inputs);\r\n    if (outputsHandles == null || outputsHandles.length == 0) {\r\n      throw new IllegalStateException(\"Interpreter has no outputs.\");\r\n    }\r\n    Tensor[] outputs = new Tensor[outputsHandles.length];\r\n    for (int i = 0; i < outputsHandles.length; ++i) {\r\n      outputs[i] = Tensor.fromHandle(outputsHandles[i]);\r\n      Log.i(\"bkzero: \", \"java: outputs[0] \" + outputs[i]);\r\n    }", "comments": ["You can get output tensor index list by calling interpreter->outputs() after calling to interpreter->Invoke().\r\nAnd you can access the output tensors with the index by calling interpreter->tensor(index).", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17319, "title": "Model trained with `tf.data.Dataset` can not be converted to `dlc` file of snpe", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.4\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n8.0\r\n- **GPU model and memory**:\r\n24G\r\n- **Exact command to reproduce**:\r\n\r\nI trained a model with `estimator` and  `tf.data.Dataset`. But I can not convert the model file to `.dlc` file of snpe.\r\nAs you all know, the following lines are included in input function:\r\n```\r\niterator = dataset.make_one_shot_iterator()\r\nimgs = iterator.get_next()\r\nreturn imgs\r\n```\r\nThen, I converted my checkpoint file with freeze_graph.py and get a `.pb` file. And the first three node names are shown below:\r\n```\r\n['OneShotIterator',\r\n 'IteratorGetNext',\r\n 'holi/conv2d/kernel',\r\n ...]\r\n```\r\nThus, I think the input node is `OneShotIterator`.\r\nAnd I tried to convert the `.pb` file to `.dlc` file of snpe. Lines below are the command I found from the documentation of snpe:\r\n```\r\nsnpe-tensorflow-to-dlc --graph $SNPE_ROOT/models/inception_v3/tensorflow/inception_v3.pb\r\n                       --input_dim Mul 299,299,3 --dlc inception_v3.dlc --out_node softmax\r\n```\r\nThe `Mul` is the input node name, `299,299,3` is the input node shape. \r\nMy input node is `OneShotIterator`, which has no shape however.\r\nI do not think it is a good idea to take an iterator as a model input, any idea to change that? Or any solution to convert my `.pb` file to `.del` file?\r\nLooking forward to your reply.\r\n", "comments": ["Nagging Assignee @tatatodd: It has been 207 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 17318, "title": "Cross ent logits", "body": "practical description for using cross entropy logits loss", "comments": []}, {"number": 17317, "title": "How to Split up/Unstack/Partition a dynamic 3D Tensor into subtensors?", "body": "In this [code from google][1] , sequence loss is being calculated by passing in 3 variables : logits , weights and targets.\r\n\r\nHow logits are defined:\r\n> logits: A Tensor of shape\r\n>       `[batch_size, sequence_length, num_decoder_symbols]` and dtype float.\r\n>       The logits correspond to the prediction across all classes at each\r\n>       timestep.\r\n\r\nMy intentions were to get **3 different tensors of shapes** batch_size , sequence_length and dec_symbols  and then use them in **tf.scan** (using sequence_length as elems)\r\n\r\nIf I print the logits tensor , this is what i get : \r\n> shape=(?, ?, 300) \r\n\r\nWhich means tf.unstack is out of the equation(as it has a variable shape)\r\n\r\nSo my first question is , is it even possible ?\r\n\r\nIf yes , any suggestions ?\r\n\r\nThanks !\r\n\r\nPS: Maybe Google can add a swap_memory parameter to the seq2seq.sequence_loss function ,to avoid OOM errors while calculating losses [which is what we are trying to overcome using an iterator inside]\r\n\r\n  [1]: https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/seq2seq/python/ops/loss.py", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 17316, "title": "ABI for `tensorflow::core::RefCounted` is error-prone", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: tf-nightly\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: (see above)\r\n\r\n### Describe the problem\r\n\r\nFor performance, the implementation of `RefCounted` comprises a set of inline methods. Furthermore, it contains a cunning optimization that avoids updating the refcount when the caller to `Unref()` is the only owner:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3ba1f72f8829c566372208062fcea04ab5695dc6/tensorflow/core/lib/core/refcount.h#L88-L89\r\n\r\nIt also includes some `DCHECK` macros to ensure that various invariants hold:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3ba1f72f8829c566372208062fcea04ab5695dc6/tensorflow/core/lib/core/refcount.h#L79\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3ba1f72f8829c566372208062fcea04ab5695dc6/tensorflow/core/lib/core/refcount.h#L90-L92\r\n\r\nNote that that second `DCHECK` performs a side-effect to make the first one succeed. \r\n\r\nThe release build is built with `NDEBUG` defined, so the `DCHECK` code doesn't execute. However, the default flags you get when following the [Adding an New Op](https://www.tensorflow.org/versions/r1.6/extend/adding_an_op) tutorial to build an extension do not include `-DNDEBUG`. \r\n\r\nRecall that the methods are marked `inline`.  This means that some code in the release binary might call (an inlined version of) `Unref()` and the store to `ref_` will be elided, but some code in an extension (e.g. one that creates a custom `ResourceBase`, which inherits from `RefCounted`) might call `~RefCounted()` and the `DCHECK` will be performed, leading to a failure.\r\n\r\nThe workaround is to add `-DNDEBUG` to the compiler flags when adding a new op. Should we update the documentation, update the `tf.sysconfig.get_compile_flags()` implementation, or modify how `RefCounted` is implemented to avoid this problem altogether? \r\n", "comments": ["@josh11b Any thoughts on this?", "I think updating the documentation and tf.sysconfig.get_compile_flags() would be a quick fix that we should do. Not sure how performance critical the optimization is, measuring that would be the main effort behind really solving this problem.", "@mrry thanks for helping out with this!", "Oh wow this was a subtle and nasty bug for me, thanks for the excellent bugreport.", "Hi, I encounter a similar problem in TF 1.15. \r\nI want to write a custom op and need to use the `mutable_input()`, but get the core dumped because \"Check failed: input_is_ref(index)\".\r\n\r\nAfter tracing the source code, I find that the developer used `CHECK` in  [source code,](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/framework/op_kernel.cc#L407) of TF 1.15 but not `DCHECK` in [source code](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/core/framework/op_kernel.cc#L410) of TF 1.14.\r\n\r\nAnd the `CHECK` is not controlled by the `DNDEBUG` flag. \r\nDo you have any suggestion to handle this problem? ", "@mrry We are checking to see if you still need help on this issue. I can see [**`PR`**](https://github.com/capeprivacy/tf-trusted/pull/27) is merged . We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17316\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17316\">No</a>\n"]}, {"number": 17315, "title": "feed_dict 10x slower on read-only numpy arrays", "body": "There's a significant slowdown when feeding numpy arrays which are read-only. Looking at cpu profile, it looks like time is spent in memcpy (incorrectly reported as __nss_passwd_lookup). This memory copy seems unnnecessary\r\n\r\nIE,\r\n```\r\n# arr=64-byte aligned numpy array\r\nsess.run(some_op, feed_dict={a:arr})  # 12.6 GB/sec\r\narr.flags['WRITEABLE']=False\r\nsess.run(some_op, feed_dict={a:arr})  # 1.2 GB/sec\r\n```\r\n\r\n[tf_numpy_benchmark.py](https://github.com/diux-dev/cluster/blob/ee5c07056a9d1dadb118aaa93e721bc81a962428/yuxin_numpy/tf_numpy_benchmark.py)\r\n\r\n```\r\nwget -N https://raw.githubusercontent.com/diux-dev/cluster/ee5c07056a9d1dadb118aaa93e721bc81a962428/yuxin_numpy/tf_numpy_benchmark.py\r\npython tf_numpy_benchmark.py --benchmark=feed_cpu_tensor --allocator=tf --num-iters=51\r\nfeed_cpu_tensor               :  12.9 GB/sec, min:  7.75, median:  8.98, mean:  9.01\r\n\r\npython tf_numpy_benchmark.py --benchmark=feed_cpu_tensor --allocator=tf_readonly --num-iters=51\r\nfeed_cpu_tensor               :   1.1 GB/sec, min: 88.48, median: 91.55, mean: 93.30\r\n```\r\ncc @alextp", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes, still an issue.", "cc @tatianashp ", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 46 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issue is fixed in https://github.com/tensorflow/tensorflow/commit/7bb79ee219d4efbd92d1ef4e0dbe45f4aee26654"]}, {"number": 17314, "title": "Pull request for fixing warm-starting device placement (#17312)", "body": "* Update checkpoint_utils.py\r\n\r\nFix device allocation bug for warm-starting op\r\n\r\n* Update checkpoint_utils_test.py\r\n\r\nFix test", "comments": []}, {"number": 17313, "title": "Include cstring in logging.cc for use of strrchr()", "body": "I'm working on Bazel's NDK support for r15 and r16. While building `//tensorflow/examples/android:tensorflow_demo` at v1.5.0 and v1.6.0rc1 with NDK r16, I ran into the following error:\r\n\r\n```\r\n/usr/local/google/home/jingwen/code/tensorflow/tensorflow/core/BUILD:1019:1: C++ compilation of rule '//tensorflow/core:android_tensorflow_lib_lite' failed (Exit 1)\r\ntensorflow/core/platform/default/logging.cc:61:36: error: use of undeclared identifier 'strrchr'\r\n  const char* const partial_name = strrchr(fname_, '/');\r\n                                   ^\r\n1 error generated.\r\n```\r\n\r\nI added an include for `<cstring>` and that fixed the build. Please let me know if this is incorrect or if there's a better way to do this.", "comments": ["ping, PTAL?\r\n", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @aselle: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?"]}, {"number": 17312, "title": "Pull request for fixing warm-starting device placement", "body": "", "comments": []}, {"number": 17311, "title": "Shape inference with dynamic shapes", "body": "I was wondering whether it is possible to use a variable as a placeholder for underspecified/dynamic shapes. Let's say the `batch_size` is dynamic (e.g. as a result from using `tf.Dataset.batch` which may produce an incomplete batch at the end of the dataset), so we have an input of images of shape `[?, h, w, c]`. Couldn't the shape inference procedure create an internal variable for `?` such that it would be able to infer the other variables at least, e.g. for functions like `tf.zeros_like`. Sorry, if this is off-topic.", "comments": []}, {"number": 17310, "title": "Bump the version of CUB in cmake build.", "body": "", "comments": []}, {"number": 17309, "title": "Scaffolding for int8 calibration in TF-TRT", "body": "This PR prepares scaffolding for Int8 calibration pass for creating int8 TRTEngineOps.\r\nIt introduces \r\n- TRTCalibOp which is used for collecting calibration information\r\n- TRTInt8Calibratior implementing TRT calibration interface and forwards TF data to TRT engine\r\n- TRTResourceManager and various simple resource constructs to keep data throughout op and session executions as well as steer TRT Calibration.\r\nSome of these will be updated in subsequent PRs when calibration infrastructure matures.\r\nThis PR is intentionally kept minimal to reduce changes in upcoming PRs.", "comments": ["Tagging @aaroey @zheng-xq @benbarsdell @jjsjann123 \r\n", "Hi @samikama,\r\n\r\nRenaming the files hides all the comments in TRTInt8Calibrator.h/cc and other files automatically, so please help to make sure they're addressed correspondingly. Thanks.", "Hi @samikama, the internal build is failing and produces lot's of errors, some are related to the GOOGLE_TENSORRT macro and the others are for other reasons. When you've done editing, please let me know, so I can fix the rest and minimize the conflicts.\r\n\r\nThanks.", "@aaroey , Sorry. When I looked at your comments and started working on it, others weren't showing up yet. I saw them too late and checking them now. ", "@aaroey I tried to address all comments, Please let me know if I missed some."]}, {"number": 17308, "title": "relaxed_onehot_categorical.py: keep_dims is depreciated", "body": "keep_dims is deprecated, use keepdims instead", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Please avoid PRs to release branches, I will close this PR."]}, {"number": 17307, "title": "Dataset map KeyError from external tensors", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Arch 15 Feb 2018\r\n- **TensorFlow installed from (source or binary)**: binary - `tensorflow-gpu` via `pip`\r\n- **TensorFlow version (use command below)**: `v1.5.0-0-g37aa430d84 1.5.0`\r\n- **Python version**: `3.6.4`\r\n- **CUDA/cuDNN version**: `9.0.176`, `7.0.5-2`\r\n- **GPU model and memory**: NVIDIA GeForce GTX 860M, 4GB\r\n- **Exact command to reproduce**: `python dataset-map.py`\r\n\r\n### Describe the problem\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nThe following script raises the subsequent `KeyError`. I don't see anything obvious in the documentation that indicates that referencing tensors not defined in the callback function is invalid, though perhaps this is a common feature/limitation of library functions that call user functions to generate subgraphs, such as `Dataset#map` and `tf.cond`.\r\n\r\nThis exact issue has an obvious workaround, but it gets a little trickier when you're referencing something more complex than a simple `tf.zeros` tensor.\r\n\r\nThe type of `Dataset` doesn't matter - I'm just using `from_generator` for brevity.\r\n\r\n### Source code / logs\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n#### Source ([permalink](https://gist.github.com/skeggse/1da719766772da217451a64fc20b1983))\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\ndataset = tf.data.Dataset.from_generator(lambda: None, tf.float32)\r\n\r\n# raises no errors\r\ndataset.map(lambda i: (i, tf.zeros(tf.float32)))\r\n\r\nzeros = tf.zeros(tf.float32)\r\n# raises KeyError: 'zeros:0' (see below)\r\ndataset.map(lambda i: (i, zeros))\r\n```\r\n\r\n#### Traceback\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"dataset-map.py\", line 10, in <module>\r\n    dataset.map(lambda i: (i, zeros))\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 780, in map\r\n    return MapDataset(self, map_func)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1591, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 486, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 321, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 376, in _create_definition_if_needed_impl\r\n    out_names=self._out_names)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/graph_to_function_def.py\", line 185, in graph_to_function_def\r\n    func.ret[k] = input_dict[o.name]\r\nKeyError: 'zeros:0'\r\n```", "comments": ["This should be fixed by 8852be3ed15e11071d6807b61294d36168be693c. The fix will appear in TF 1.7; in the meantime unfortunately you'll have to add a `tf.identity(zeros)` around any tensors that are (i) captured from an external scope, and (ii) returned directly from a TF function (in `Dataset.map()`, `Dataset.filter()`, etc.)."]}, {"number": 17306, "title": "CudnnRNN TensorCore Support", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.1/7.0\r\n- **GPU model and memory**: V100\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nFeature/Status Request: Enable use of NVIDIA's TensorCores in CudnnRNN, CudnnLSTM. The requirements specified by NVIDIA are currently detailed at [1].\r\n\r\n[1] http://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor_ops\r\n", "comments": ["@protoget Do you have any timeline for adding TensorCore support for CudnnRNN?", "The support for CudnnRNN is on our roadmap. We don't yet have a delivery date, but it's one of the high priority things we will do next.", "@protoget What does `high priority` usually mean? i.e. week, weeks, months? I'll need to switch to another library if it's more the latter than the former :-( ", "It's now supported in TF. You should be able to use from the nightly build. (https://github.com/tensorflow/tensorflow/pull/17367)\r\nAlthough we're trying to add more autotune logic s.t. TF would automatically choose between regular RNN and persistent RNN based on history. But without that you should still be able to use tensor_op."]}, {"number": 17305, "title": "Bump the version of CUB in cmake build.", "body": "We made the same upgrade for bazel build, but forgot about cmake.", "comments": []}, {"number": 17304, "title": "Update 1_notmnist.ipynb for clarity", "body": "This adds some comments to the command %matplotlib to prevent severe confusion for those of us who are familiar with python but not familiar with iron python, since this page makes absolutely no mention of the fact that is the only interpreter that will work with this code.", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "I have never used IronPython AFAIK, or ever heard of anyone having to specifically use IronPython, in the years that two years that this notebook has been available publicly."]}]