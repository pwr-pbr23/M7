[{"number": 45211, "title": "Tensor data is stored in BE format on s390x in flatbuffer model in a certain scenario", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\n`tfl_while_op.mlir.test` test is failing on s390x.\r\nOn debugging a little, I found that during the building of flatbuffer model, the data is first represented in Big Endian format, then we flat it to a `absl::string_view` in [flatbuffer_export.cc](https://github.com/tensorflow/tensorflow/blob/d5b2156e4e5367cc336d26fbbac3a6e76781de05/tensorflow/compiler/mlir/lite/flatbuffer_export.cc#L638). \r\nThis data , in some cases, is directly stored in a vector of bytes and inserted into a flatbuffer in `CreateVector`. As flatbuffer only support Little Endian format, this TC fails as FileCheck on mlir file expects the data in LE format.\r\n\r\nThe code that is causing the issue in `CreateVector` function is:\r\n```\r\n      if (sizeof(T) == 1) {\r\n        PushBytes(reinterpret_cast<const uint8_t *>(v), len);\r\n```\r\n\r\nIf the `sizeof(T)` is greater than 1, then the data is reversed before storing it into a vector of bytes, i.e., the data gets stored in LE format in flatbuffer model. \r\n```\r\n      } else {\r\n        for (auto i = len; i > 0; ) {\r\n          PushElement(v[--i]);\r\n        }\r\n```\r\n\r\nAs the flatbuffer only support LE format, it seems that the data must be byte-swapped into LE format from BE before storing is into the vector of bytes. But, since I am not sure of the functionality being tested here, maybe we can update the expected result in mlir file from ```// CHECK-NEXT:     data: [ 1, 0, 0, 0 ]``` to ```// CHECK-NEXT:     data: [ 0, 0, 0, 1 ]```. \r\nPlease suggest what would be the best way to proceed here. There are multiple compiler related test cases which have similar failure errors.\r\n\r\n**Describe the expected behavior**\r\nThe tensor data must be stored in LE format in flatbuffer model.\r\n\r\n**Standalone code to reproduce the issue**\r\nTo reproduce the issue, please use this command:\r\n```bazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" test --host_javabase=\"@local_jdk//:jdk\" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only  -c dbg --copt=-O -c opt --copt=-g --strip never --color=yes --curses=yes --test_output=errors --verbose_failures -- //tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer:tfl_while_op.mlir.test```\r\n\r\n**Other info / logs** ", "comments": ["@skribm9 \r\nPlease share a simple stand alone code or if possible share a colab gist with error reported.", "Hi @Saduf2019 There is no separate code change done. The issue can be reproduced by compiling Tensorflow 2.3.1 code on s390x. I came across this issue on running bazel test for ```tfl_while_op.mlir.test```. \r\n\r\nSimple stand-alone code to reproduce the issue:\r\n```\r\nbazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" test --host_javabase=\"@local_jdk//:jdk\" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only --test_output=errors --verbose_failures -- //tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer:tfl_while_op.mlir.test\r\n```\r\n\r\nOn running this test,  I found that this is where issue is introduced:\r\n` if (sizeof(T) == 1) {` condition of `CreateVector` function(mentioned below).\r\nThe function causing the issue is in ```bazel-bin/external/flatbuffers/_virtual_includes/flatbuffers/flatbuffers/flatbuffers.h``` file. \r\n\r\n```\r\n  /// @brief Serialize an array into a FlatBuffer `vector`.\r\n  /// @tparam T The data type of the array elements.\r\n  /// @param[in] v A pointer to the array of type `T` to serialize into the\r\n  /// buffer as a `vector`.\r\n  /// @param[in] len The number of elements to serialize.\r\n  /// @return Returns a typed `Offset` into the serialized data indicating\r\n  /// where the vector is stored.\r\n  template<typename T> Offset<Vector<T>> CreateVector(const T *v, size_t len) {\r\n    // If this assert hits, you're specifying a template argument that is\r\n    // causing the wrong overload to be selected, remove it.\r\n    AssertScalarT<T>();\r\n    StartVector(len, sizeof(T));\r\n    // clang-format off\r\n    #if FLATBUFFERS_LITTLEENDIAN\r\n      PushBytes(reinterpret_cast<const uint8_t *>(v), len * sizeof(T));\r\n    #else\r\n      if (sizeof(T) == 1) {\r\n        **PushBytes(reinterpret_cast<const uint8_t *>(v), len);**\r\n       } else {\r\n        for (auto i = len; i > 0; ) {\r\n          PushElement(v[--i]);\r\n        }\r\n\r\n      }\r\n    #endif\r\n    // clang-format on\r\n    return Offset<Vector<T>>(EndVector(len));\r\n  }\r\n```\r\n\r\nIf I check further in `PushBytes` function, I can see that data is being directly copied using:\r\n```\r\n  void push(const uint8_t *bytes, size_t num) {\r\n    if (num > 0) { memcpy(make_space(num), bytes, num); }\r\n  }\r\n``` \r\nI tried using `PushElement` function instead of `PushBytes` but it corrupts the flatbuffer model. I also tried some other ways to convert data in LE format before pushing in vector but I couldn't come up with a proper and safe solution.", "Please find the log file attached for reference. I have deleted additional logs that I added for debugging purpose.\r\n[tfl_while_op.log](https://github.com/tensorflow/tensorflow/files/5608225/tfl_while_op.log)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45211\">No</a>\n", "Issue is a duplicate to #https://github.com/tensorflow/tensorflow/issues/45009. It seems that `buffers` in general are not converted to LE format while storing in flatbuffer vector and this is affecting multiple Test cases."]}, {"number": 45210, "title": "Tensor shape signature is not parsed safely with `ParseTensors` of TF Lite InterpreterBuilder on Big Endian machines", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nCurrently, `InterpreterBuilder` is retrieving the `shape_signature` field of a flatbuffer tensor in the following way:\r\n```\r\n    size_t dims_signature_rank = 0;\r\n    const int* dims_signature_data = nullptr;\r\n    if (tensor->shape_signature()) {\r\n      dims_signature_rank = tensor->shape_signature()->size();\r\n      dims_signature_data = tensor->shape_signature()->data();\r\n    }\r\n```\r\nThe type of `tensor->shape_signature()` is a flatbuffer int array (`flatbuffers::Vector`), and accessing it using `data()` method is not safe as the data is always stored in Little Endian format, which will break for Big Endian machines. So whenever this optional `shape_signature` field is set in a TF Lite model, the interpreter will break on Big Endian machines.\r\n\r\nTo access the data correctly, we should use the `Get()` method of the flatbuffer array. There actually is a handy function defined in `InterpreterBuilder` already, `FlatBufferIntArrayToVector`, which is used for retrieving the `tensor->shape()` field as follow:\r\n```\r\nstd::vector<int> dims = FlatBufferIntArrayToVector(tensor->shape());\r\n```\r\nThis helper function definitely could work for `tensor->shape_signature()` as well because they both are integer array fields. The only issue is that currently, we are expecting two variables `dims_signature_rank` and `dims_signature_data` in the `SetTensorParametersReadWrite` function that we need to call later rather than an `std::vector`.\r\n\r\nI have also tried some other methods to use `Get()` to retrieve the data, but it is a bit tricky as we need the shape signature data to live long enough for the `SetTensorParametersReadWrite` to finish writing the data into `tensor.dims_signature` field. To avoid making lot of changes and introducing new variables, I wonder if we could change the `SetTensorParametersReadWrite` function signature to make it accept one `dims_signature` vector instead of one size variable and one data variable. This could work because in `tensorflow/lite/core/subgraph.h`, the expected input arguement is like this:\r\n```\r\ninline TfLiteStatus SetTensorParametersReadWrite(\r\n      int tensor_index, TfLiteType type, const char* name,\r\n      const std::vector<int>& dims, TfLiteQuantization quantization,\r\n      bool is_variable = false, const size_t rank_dims_signature = 0,\r\n      const int* dims_signature = nullptr) {\r\n    return SetTensorParametersReadWrite(tensor_index, type, name, dims.size(),\r\n                                        dims.data(), quantization, is_variable,\r\n                                        rank_dims_signature, dims_signature);\r\n  }\r\n  TfLiteStatus SetTensorParametersReadWrite(\r\n      int tensor_index, TfLiteType type, const char* name, const size_t rank,\r\n      const int* dims, TfLiteQuantization quantization,\r\n      bool is_variable = false, const size_t rank_dims_signature = 0,\r\n      const int* dims_signature = nullptr);\r\n```\r\nHere we are using a reference to the `dims` vector and pass its size and data respectively to the function so that it will outlive the function call - the exact same thing could be done for `dims_signature` as well. If we get rid of `dims_signature_rank` and `dims_signature_data` and pass on a vector of `dims_signature`, we only need to make changes to these two places.\r\n\r\nIf such solution could work I will likely start a PR to it. Otherwise, please let me know if there are some other convenient ways to fix the parsing of `shape_signature`, thanks.\r\n\r\n**Describe the expected behavior**\r\nThe `shape_signature` field should be parsed correctly on Big Endian machine.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nbazel test --host_javabase=\"@local_jdk//:jdk\" --cache_test_results=no --build_tests_only --test_output=errors -- //tensorflow/lite/python:lite_v2_test\r\n```\r\nThis test will fail on Big Endian machines.\r\n\r\n**Other info / logs** \r\n", "comments": ["It's tricky to fix it here since I can't find Big Endian machines.\r\nPlease feel free to send a PR. I can review it.", "Thanks for the reply, I will test it using the approach I mentioned and send a PR shortly.", "Maybe we'd better use https://github.com/tensorflow/tensorflow/issues/45009 for further discussion.", "Close issue as PR has been merged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45210\">No</a>\n"]}, {"number": 45209, "title": "Pretrained Xception takes more memory than an InceptionResNetV2, despite having half of the parameters", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): with pip\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.8\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Nvidia Quadro T2000 \r\n\r\n**Describe the current behavior**\r\nI'll attach the script below. \r\nSo, the problem is that if i am using pre-trained InceptionResNetV2 and Xception from keras, turns out that with allow_memory_growth, Inception takes ~ 1GB of my GPU memory when predictiong and Xception takes ~2.8GB, despite being 2x smaller than inception. Is this an expected behaviour?\r\n\r\n**Describe the expected behavior**\r\nXception should be less memory consuming compared to InceptionResNetV2 \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nCode for Inception:\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\r\nfrom tensorflow.keras.models import load_model\r\nimport numpy as np\r\n\r\ngpu_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu_devices[0], True)\r\nlogical_gpu_devices = tf.config.list_logical_devices('GPU')\r\n\r\nmodel = InceptionResNetV2()\r\nimg = np.zeros([299,299,3],dtype=np.uint8)\r\n\r\nprint(model.predict(np.array([tf.keras.applications.inception_resnet_v2.preprocess_input(img)])))\r\n\r\n```\r\n\r\nCode for Xception:\r\n\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.xception import Xception\r\nfrom tensorflow.keras.models import load_model\r\nimport numpy as np\r\n\r\n\r\ngpu_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu_devices[0], True)\r\nlogical_gpu_devices = tf.config.list_logical_devices('GPU')\r\n\r\nmodel = Xception()\r\nimg = np.zeros([299,299,3],dtype=np.uint8)\r\n\r\nprint(model.predict(np.array([tf.keras.applications.xception.preprocess_input(img)])))\r\n\r\n```\r\n\r\n\r\n**Other info / logs** \r\nScreenshots for memory consumption:\r\nInception:\r\n![image](https://user-images.githubusercontent.com/9899064/100369665-dfa87780-300d-11eb-8989-4f4e9e34888d.png)\r\nXception\r\n![image](https://user-images.githubusercontent.com/9899064/100369597-c30c3f80-300d-11eb-9399-0fe7866f1603.png)\r\n\r\n", "comments": ["@Moldoteck,\r\nPlease use the memory profile tool as show in [this guide](https://www.tensorflow.org/guide/profiler#gpu_kernel_stats) to monitor and compare the GPU usage.\r\n\r\nAlso, go through [this debugging guide](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#debug_performance_bottlenecks) and let us know if it helps. Thanks!", "@amahendrakar I don't know how to use this tool, especially for prediction-only use-case. I tried to make a colab with tensorboard profiler, but i don't know how to measure the GPU performance:\r\nhttps://colab.research.google.com/drive/1NQWpSzXD2_dbkPh0HHTxBKHwoUnsrw2M?usp=sharing\r\n\r\nThe thing is that with this code, if i run locally on my PC, InceptionResNetV2 will consume 1GB for prediction, but Xception will use~ 2.8GB\r\nHere is the image for Inception\r\n![image](https://user-images.githubusercontent.com/9899064/100456123-86514e80-30c8-11eb-9865-09fec4990021.png)\r\n\r\n\r\nHere is the image for Xception\r\n![image](https://user-images.githubusercontent.com/9899064/100455669-c19f4d80-30c7-11eb-8738-d9daa0290b65.png)\r\n", "Also, if i add this line:\r\n`tf.config.experimental.set_virtual_device_configuration(\r\n        gpu_devices[0],\r\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=128)])`\r\n\r\nThe Xception will consume only 0.6 GB, so the model certainly can run with smaller amount of memory", "@Moldoteck,\r\nCould you please update TensorFlow to v2.3 or v2.4.0rc3 and check if you are facing the same issue? Thanks!", "@amahendrakar just tested with tf 2.3.1 and nothing have changed", "Hello,\r\nI have the same GPU model \"Nvidia Quadro T2000\" and have another issue. If I run the code above:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.applications.xception import Xception\r\nfrom tensorflow.keras.models import load_model\r\nimport numpy as np\r\n\r\n\r\ngpu_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu_devices[0], True)\r\nlogical_gpu_devices = tf.config.list_logical_devices('GPU')\r\n\r\nmodel = Xception()\r\nimg = np.zeros([299,299,3],dtype=np.uint8)\r\n\r\nprint(model.predict(np.array([tf.keras.applications.xception.preprocess_input(img)])))\r\n```\r\nI will get this output:\r\n```\r\n2020-12-04 10:48:24.193552: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-12-04 10:48:24.877442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-12-04 10:48:24.881036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.881216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro T2000 computeCapability: 7.5\r\ncoreClock: 1.785GHz coreCount: 16 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 119.24GiB/s\r\n2020-12-04 10:48:24.881230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-12-04 10:48:24.882154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-12-04 10:48:24.883150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-12-04 10:48:24.883338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-12-04 10:48:24.884305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-04 10:48:24.884879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-04 10:48:24.887016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-12-04 10:48:24.887124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.887341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.887497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-04 10:48:24.887753: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-04 10:48:24.892969: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\r\n2020-12-04 10:48:24.894302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d6ef60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-04 10:48:24.894335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-12-04 10:48:24.949224: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 4093444096\r\n2020-12-04 10:48:24.949357: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Internal: no supported devices found for platform CUDA\r\n2020-12-04 10:48:24.949616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.949811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro T2000 computeCapability: 7.5\r\ncoreClock: 1.785GHz coreCount: 16 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 119.24GiB/s\r\n2020-12-04 10:48:24.949846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-12-04 10:48:24.949896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-12-04 10:48:24.949924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-12-04 10:48:24.949946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-12-04 10:48:24.949974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-04 10:48:24.949981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-04 10:48:24.950002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-12-04 10:48:24.950073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.950241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-04 10:48:24.950392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-04 10:48:24.950427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"test3.py\", line 9, in <module>\r\n    logical_gpu_devices = tf.config.list_logical_devices('GPU')\r\n  File \"/home/david/.local/lib/python3.7/site-packages/tensorflow/python/framework/config.py\", line 403, in list_logical_devices\r\n    return context.context().list_logical_devices(device_type=device_type)\r\n  File \"/home/david/.local/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 1344, in list_logical_devices\r\n    self.ensure_initialized()\r\n  File \"/home/david/.local/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory\r\n```\r\n**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10\r\n- TensorFlow installed from (source or binary): with pip\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.7.3\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Nvidia Quadro T2000\r\n\r\n**Question**\r\nIs this issue because of the GPU model \"Nvidia Quadro T2000\" ?\r\n\r\ncheers\r\nDavid", "@DDoIt i have exactly same GPU and it works, so i think the problem for you is either bad drivers or bad tf environment. I think the root should be in drivers, since i am using Windows 10 and you are using Debian 10, which rely on different drivers\r\nAlso, i see out of memory. Maybe you didn't deallocate memory from previous runs/ other models?", "@Moldoteck You are right. I didn't deallocate memory from previous runs.Sorry.", "I'm able to see less memory consumption in `Xception` model than the `InceptionResNetV2`, please find the gist reference for [Xception](https://colab.research.google.com/gist/sachinprasadhs/27cbf439a4d8c603f4372e612b689b4e/xception.ipynb) and [InceptionResNetV2](https://colab.research.google.com/gist/sachinprasadhs/64c8fdbd966e46a9ea18a662b817bde4/inception.ipynb)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45208, "title": "Delete entire systems everywhere then copy all and merge store and share", "body": "It's boss... Go see her on her phone. Like a face time.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45208) for more info**.\n\n<!-- need_sender_cla -->", "@KhaosNKO  Can you please sign CLA. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 45207, "title": "ResizeBilinear op with half_pixel_centers true not support by nnapi", "body": "**System information**android 11\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- TensorFlow installed from (source or binary):pip\r\n- TensorFlow version (or github SHA if from source):2.3-2.4\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n   kerasmodel=tf.keras.models.load_model('./log',compile=False)\r\n    input_name = kerasmodel.input_names[0]\r\n    index = kerasmodel.input_names.index(input_name)\r\n    kerasmodel.inputs[index].set_shape([1, 320, 320,1])\r\n    ind =0\r\n    for layer in kerasmodel.layers:\r\n        print(layer.name)\r\n        if layer.name==\"up_p3\" or layer.name==\"up_p4\":\r\n            print(\"###############################\")\r\n            \r\n            kerasmodel.layers[ind].half_pixel_centers=False\r\n            print(kerasmodel.layers[ind].half_pixel_centers)\r\n         \r\n        ind+=1\r\n    \r\n  \r\n#     kerasmodel.summary()\r\n#     exit()\r\n    \r\n    converter = tf.lite.TFLiteConverter.from_keras_model(kerasmodel)   \r\n    #converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"./log\")\r\n    converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]#tf.lite.OpsSet.SELECT_TF_OPS]\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen) \r\n    converter.inference_input_type = tf.int8\r\n    converter.inference_output_type = tf.int8\r\n    converter.experimental_new_converter = True\r\n    tflite_model_quant = converter.convert()\r\n    import pathlib\r\n    tflite_model_quant_file = pathlib.Path(\"./\")/\"test2.4.tflite\"\r\n    tflite_model_quant_file.write_bytes(tflite_model_quant)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n![image](https://user-images.githubusercontent.com/30410113/100355529-e692b280-302c-11eb-8f54-1f49c3646d90.png)\r\nwhen i test it with benchmark abort occur!so i find the log with:\r\n11-26 19:53:25.830  1061 27513 E hta-unnhal: {PAD, TENSOR_QUANT8} is not supported.\r\n11-26 19:53:25.830  1061 27513 E hta-unnhal: Doesn't support half pixel centers for RESIZE_BILINEAR\r\n11-26 19:53:25.830  1061 27513 E hta-unnhal: {RESIZE_BILINEAR, TENSOR_QUANT8} is not supported.\r\n11-26 19:53:25.830  1061 27513 E hta-unnhal: Doesn't support half pixel centers for RESIZE_BILINEAR\r\n11-26 19:53:25.830  1061 27513 E hta-unnhal: {RESIZE_BILINEAR, TENSOR_QUANT8} is not supported.\r\n![image](https://user-images.githubusercontent.com/30410113/100355495-d7136980-302c-11eb-88cf-5002c60428f9.png)\r\nI set the half_pixel_centers with False before convert but when i get tflite it is still true\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n![image](https://user-images.githubusercontent.com/30410113/100355786-5143ee00-302d-11eb-88ae-c1804ddabf10.png)\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sunzhe09 \r\nCode shared is not indented and incomplete,please share a colab gist with the error reported.", "@Saduf2019 I just want to edit the attribute half_pixel_centers to false,is there any way to do this?you can compare my model,the left is tf1.15 converted,the right is tf2.3 converted\r\n![image](https://user-images.githubusercontent.com/30410113/100400119-49696580-3090-11eb-9352-c15308066ae3.png)\r\n", "@Saduf2019 I\u2018m sorry\uff0cI have test the model crash is not about with half_pixel_centers attrbute\u3002I just test the model with android_aarch64_benchmark_model but after initialized  it crashed\u3002there is the  log\uff1a\r\n01-26 07:15:10.172 32429 32429 I tflite  : Initialized TensorFlow Lite runtime.\r\n01-26 07:15:10.172 32429 32429 I tflite  : Created TensorFlow Lite delegate for NNAPI.\r\n01-26 07:15:10.173 32429 32429 F libc    : Fatal signal 6 (SIGABRT), code -1 (SI_QUEUE) in tid 32429 (android_aarch64), pid 32429 (android_aarch64)\r\n01-26 07:15:10.195 32433 32433 I crash_dump64: obtaining output fd from tombstoned, type: kDebuggerdTombstone\r\n01-26 07:15:10.196   609   609 I tombstoned: received crash request for pid 32429\r\n01-26 07:15:10.197 32433 32433 I crash_dump64: performing dump of process 32429 (target tid = 32429)\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : Process name is ./android_aarch64_benchmark_model, not key_process\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : Build fingerprint: 'OPPO/CPH2125/OP4C51L1:11/RP1A.200709.001/1600212156653:user/release-keys'\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : Revision: '0'\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : ABI: 'arm64'\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : Timestamp: 2010-01-26 07:15:10+0800\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : pid: 32429, tid: 32429, name: android_aarch64  >>> ./android_aarch64_benchmark_model <<<\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : uid: 0\r\n01-26 07:15:10.200 32433 32433 F DEBUG   : signal 6 (SIGABRT), code -1 (SI_QUEUE), fault addr --------\r\n01-26 07:15:10.200 32433 32433 F DEBUG   :     x0  0000000000000000  x1  0000000000007ead  x2  0000000000000006  x3  0000007fe0631a60\r\n01-26 07:15:10.200 32433 32433 F DEBUG   :     x4  0000000000000001  x5  0000000000000001  x6  0000000000000001  x7  0000000000000001\r\n01-26 07:15:10.200 32433 32433 F DEBUG   :     x8  00000000000000f0  x9  00000070a9f6c898  x10 ffffff80ffffffdf  x11 0000000000000001\r\n01-26 07:15:10.200 32433 32433 F DEBUG   :     x12 0000000000000001  x13 0000000000000091  x14 000000000000000d  x15 0000000000000000\r\n01-26 07:15:10.200 32433 32433 F DEBUG   :     x16 00000070aa02b7e0  x17 00000070aa00b330  x18 0000000000000028  x19 0000000000007ead\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :     x20 0000000000007ead  x21 00000000ffffffff  x22 0000000000000001  x23 b4000070a92fe3d0\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :     x24 b4000070a924d0ac  x25 b4000070a92fc610  x26 b4000070a92fb5e0  x27 00000070aa892008\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :     x28 b4000070a922b8f0  x29 0000007fe0631ae0\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :     lr  00000070a9fbf088  sp  0000007fe0631a40  pc  00000070a9fbf0b8  pst 0000000000000000\r\n01-26 07:15:10.201 32433 32433 F DEBUG   : backtrace:\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #00 pc 00000000000780b8  /apex/com.android.runtime/lib64/bionic/libc.so (abort+168) (BuildId: ca36996e33db72a01a11b53184a66bac)\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #01 pc 0000000000367b58  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #02 pc 00000000003670b4  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #03 pc 00000000000b1ebc  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #04 pc 00000000001bb5f8  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #05 pc 00000000001bc708  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #06 pc 00000000001bf9f0  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #07 pc 0000000000048e94  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #08 pc 0000000000054a94  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #09 pc 00000000000549e4  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #10 pc 000000000003fe64  /data/local/tmp/android_aarch64_benchmark_model\r\n01-26 07:15:10.201 32433 32433 F DEBUG   :       #11 pc 0000000000073658  /apex/com.android.runtime/lib64/bionic/libc.so (__libc_init+108) (BuildId: ca36996e33db72a01a11b53184a66bac)\r\n01-26 07:15:10.833   518   518 D AEE_AED : $===AEE===AEE===AEE===$\r\n01-26 07:15:10.833   518   518 D AEE_AED : p 2 poll events 1 revents 1\r\n01-26 07:15:10.833   518   518 D AEE_AED : PPM cpu cores:8, online:8\r\n01-26 07:15:10.835   518   518 D AEE_AED : aed_main_fork_worker: generator 0xb400007ca82380a0, worker 0x7ff146d040, recv_fd 11\r\n01-26 07:15:10.838 32440 32440 D AEE_AED : u:r:su:s0\r\n01-26 07:15:10.838 32440 32440 V AEE_AED : dashboard_record_update() : rec->module = ./android_aarch64_benchmark_model \r\n01-26 07:15:10.838 32440 32440 D AEE_AED : Skip duplicated exception ! \r\n01-26 07:15:10.838 32440 32440 D AEE_AED : Exception Class: 3 \r\n01-26 07:15:10.838 32440 32440 D AEE_AED : Module: ./android_aarch64_benchmark_model \r\n01-26 07:15:10.838 32440 32440 D AEE_AED : Count: 5 \r\n01-26 07:15:10.838 32440 32440 D AEE_AED : Last exception time: 1264461296 \r\n01-26 07:15:10.838 32440 32440 D AEE_AED :  \r\n01-26 07:15:10.838 32440 32440 V AEE_AED : aed_crash_dump_session - skipped \r\n01-26 07:15:10.839 32433 32433 I crash_dump: crash_mini_dump_notify exit\r\n01-26 07:15:10.840   518   518 D AEE_AED : clear ppm settings\r\n01-26 07:15:10.841   750  2002 W NativeCrashListener: Couldn't find ProcessRecord for pid 32429\r\n01-26 07:15:10.841   518   518 D AEE_AED : $===AEE===AEE===AEE===$\r\n01-26 07:15:10.842   609   609 E tombstoned: Tombstone written to: /data/tombstones/tombstone_45\r\n01-26 07:15:10.850   750  1329 I BootReceiver: Copying /data/tombstones/tombstone_45 to DropBox (SYSTEM_TOMBSTONE)\r\n01-26 07:15:10.857 32441 32441 I aee_core_forwarder: Core forwarder(0) executable pid 32429 signo 6\r\n01-26 07:15:10.862   750  1329 I DropBoxManagerService: add tag=SYSTEM_TOMBSTONE isTagEnabled=true flags=0x2\r\n01-26 07:15:10.863 32441 32441 E aee_core_forwarder: Acquire(32429) wake lock in core forwarder failed(0)\r\n01-26 07:15:10.863 32441 32441 E aee_core_forwarder: Cannot connect to aed coredump receiver, Connection refused\r\n01-26 07:15:10.866 32441 32441 D aee_core_forwarder: process_coredump: process:32429 is 64 bit preread:1048576\r\n01-26 07:15:10.866 32441 32441 I aee_core_forwarder: Parser thread for aarch64 case\r\n01-26 07:15:10.866 32441 32441 I aee_core_forwarder: Parser result thread id: 32429\r\n01-26 07:15:10.867   518   518 D AEE_AED : $===AEE===AEE===AEE===$\r\n01-26 07:15:10.867   518   518 D AEE_AED : p 2 poll events 1 revents 1\r\n01-26 07:15:10.867   518   518 D AEE_AED : PPM cpu cores:8, online:8\r\n01-26 07:15:10.868   518   518 D AEE_AED : aed_main_fork_worker: generator 0xb400007ca82380a0, worker 0x7ff146d040, recv_fd 11\r\n01-26 07:15:10.870 32442 32442 I AEE_AED : pid: 32429, tid: 32429, >>> ./android_aarch64_benchmark_model <<<\r\n01-26 07:15:10.870  3810 32330 E CrashBox: failed to get version code, \r\n01-26 07:15:10.870  3810 32330 E CrashBox: android.content.pm.PackageManager$NameNotFoundException: ./android_aarch64_benchmark_model\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat android.app.ApplicationPackageManager.getPackageInfoAsUser(ApplicationPackageManager.java:238)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.e.f.b(SourceFile:91)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.collector.a.c.b(SourceFile:75)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.collector.a.d.c(SourceFile:79)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.collector.b.c(SourceFile:120)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.collector.b.a(SourceFile:93)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat com.oplus.crashbox.collector.b.call(SourceFile:42)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n01-26 07:15:10.870  3810 32330 E CrashBox: \tat java.lang.Thread.run(Thread.java:923)\r\n01-26 07:15:10.870 32442 32442 D AEE_AED : u:r:su:s0\r\n01-26 07:15:10.870 32442 32442 V AEE_AED : dashboard_record_update() : rec->module = ./android_aarch64_benchmark_model \r\n01-26 07:15:10.870 32442 32442 D AEE_AED : Skip duplicated exception ! \r\n01-26 07:15:10.870 32442 32442 D AEE_AED : Exception Class: 3 \r\n01-26 07:15:10.870 32442 32442 D AEE_AED : Module: ./android_aarch64_benchmark_model \r\n01-26 07:15:10.870 32442 32442 D AEE_AED : Count: 6 \r\n01-26 07:15:10.870 32442 32442 D AEE_AED : Last exception time: 1264461310 \r\n01-26 07:15:10.870 32442 32442 D AEE_AED :  \r\n01-26 07:15:10.870 32442 32442 I AEE_AED : aed_ne_core_session: skip duplicated exception \r\n01-26 07:15:10.870 32441 32441 I aee_core_forwarder: process_coredump: skip process NE\r\n01-26 07:15:10.870 32441 32441 I aee_core_forwarder: process_coredump: exit\r\n01-26 07:15:10.871   750  2528 E Process : get_ion_cache_memory: Unable to open /d/ion/system_stats\r\n01-26 07:15:10.871   518   518 D AEE_AED : clear ppm settings\r\n01-26 07:15:10.872   518   518 D AEE_AED : $===AEE===AEE===AEE===$\r\n01-26 07:15:10.883   750  1181 V ActivityManager: Broadcast: Intent { act=android.intent.action.DROPBOX_ENTRY_ADDED flg=0x10 (has extras) } ordered=false userid=0 resultTo null\r\n01-26 07:15:10.883   750  1181 V ActivityManager: broadcastIntentLocked callingPid: 750 callingUid=1000\r\n01-26 07:15:10.885   750  1329 D DropBoxManagerService: file :: /data/system/dropbox/SYSTEM_TOMBSTONE@1264461310882.txt.gz\r\n01-26 07:15:10.885   750  1330 D ColorAppStartupManager:  callingUid: 1000 topUid: 10243\r\n01-26 07:15:10.885   750  1330 W BroadcastQueue: Background execution not allowed: receiving Intent { act=android.intent.action.DROPBOX_ENTRY_ADDED flg=0x10 (has extras) } to com.google.android.gms/.stats.service.DropBoxEntryAddedReceiver\r\n01-26 07:15:10.885   750  1329 V java.lang.ASSERT: in copyTombstone\r\n01-26 07:15:10.885   750  1330 D ColorAppStartupManager:  callingUid: 1000 topUid: 10243\r\n01-26 07:15:10.885   750  1330 W BroadcastQueue: Background execution not allowed: receiving Intent { act=android.intent.action.DROPBOX_ENTRY_ADDED flg=0x10 (has extras) } to com.google.android.gms/.chimera.GmsIntentOperationService$PersistentTrustedReceiver\r\n01-26 07:15:10.888   750  2528 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.889   750  2528 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 0: service\r\n01-26 07:15:10.894   750  2528 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 100: service\r\n01-26 07:15:10.901   750  2528 D ActivityManager: Set 4531 com.google.android.gms adj 0: service\r\n01-26 07:15:10.900   750  2528 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.903   750  2216 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.904   750  2216 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 0: service\r\n01-26 07:15:10.905   750  3450 D ActivityManager: Set 4531 com.google.android.gms adj 100: service\r\n01-26 07:15:10.905   750  3450 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.906   750  3450 D ActivityManager: Set 4531 com.google.android.gms adj 0: service\r\n01-26 07:15:10.907   750  2216 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.909   750  2216 D ActivityManager: Set 4531 com.google.android.gms adj 100: service\r\n01-26 07:15:10.911   750  3450 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 100: service\r\n01-26 07:15:10.913   750  2528 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 0: service\r\n01-26 07:15:10.913   750  3962 D ColorAppStartupManager:  callingUid: 10181 topUid: 10243\r\n01-26 07:15:10.915   750  3962 D ActivityManager: Set 3077 com.google.android.gms.persistent adj 100: service\r\n01-26 07:15:11.461   750  2683 D BatteryLed: getLightInColorState, oppoLightMgr empty!\r\n01-26 07:15:11.462   750   750 V ActivityManager: Broadcast sticky: Intent { act=android.intent.action.BATTERY_CHANGED flg=0x60000010 (has extras) } ordered=false userid=-1 resultTo null\r\n01-26 07:15:11.462   750   750 V ActivityManager: broadcastIntentLocked callingPid: 750 callingUid=1000\r\n01-26 07:15:11.465   750   750 D OppoPowerMonitor_Utils: getBatteryFcc readLine :4000\r\n01-26 07:15:11.465  2325  2325 D DCS-BatteryData: onReceive()--action=android.intent.action.BATTERY_CHANGED\r\n01-26 07:15:11.465   750   750 D OppoPowerMonitor_Utils: getBatteryLevel readLine :80\r\n01-26 07:15:11.465   750   750 V UiModeManager: updateLocked: null action, mDockState=0, category=null\r\n01-26 07:15:11.465   750   750 D UiModeManager: updateConfigurationLocked: mDockState=0; mCarMode=false; mNightMode=1; uiMode=17", "@jvishnuvardhan   can you help me\uff1fI don\u2018t know why it carshed when  it init the nnapidelegate", "I converted compat v1 successfully\uff0cso I will close it", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45207\">No</a>\n"]}, {"number": 45206, "title": "How can i increase number of timeseries feature when building Encoder-Decoder model(seq2seq) using ConvLSTM2D", "body": "- TensorFlow version: 2.1.0\r\n- Python version: 3.7.4\r\n\r\nI could build one timeseries feature input , one time series predict using Encoder-Decoder model like below\r\n```python\r\ndef build_model(input_timesteps, output_timesteps, num_links):\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 1, 1)))\r\n    \r\n    #Encoder\r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_1',\r\n                         filters = num_filters, kernel_size = (kernel_size[0], 1),                       \r\n                         padding = 'same', \r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_1'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_1'))\r\n\r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_2',\r\n                         filters = num_filters, kernel_size = (kernel_size[1], 1), \r\n                         padding='same',\r\n                         return_sequences = False))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_2'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_2'))\r\n    \r\n    model.add(tf.keras.layers.Flatten())\r\n    \r\n    #Decoder\r\n    model.add(tf.keras.layers.RepeatVector(output_timesteps))\r\n    model.add(tf.keras.layers.Reshape((output_timesteps, num_links, 1, 64)))\r\n    \r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_3',\r\n                         filters = num_filters, kernel_size = (kernel_size[0], 1), \r\n                         padding='same',\r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_3'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_3'))\r\n    \r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_4',\r\n                         filters = num_filters, kernel_size = (kernel_size[1], 1), \r\n                         padding='same',\r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1, name = 'dense_1', activation = 'relu')))\r\n    #model.add(Dense(units=1, name = 'dense_2'))\r\n\r\n    optimizer = tf.keras.optimizers.RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)\r\n    model.compile(loss = \"mse\", optimizer = optimizer)\r\n    return model\r\n\r\n\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nbatch_norm_0 (BatchNormaliza (None, 8, 4, 1, 1)        4         \r\n_________________________________________________________________\r\nconv_lstm_1 (ConvLSTM2D)     (None, 8, 4, 1, 64)       166656    \r\n_________________________________________________________________\r\ndropout_1 (Dropout)          (None, 8, 4, 1, 64)       0         \r\n_________________________________________________________________\r\nbatch_norm_1 (BatchNormaliza (None, 8, 4, 1, 64)       256       \r\n_________________________________________________________________\r\nconv_lstm_2 (ConvLSTM2D)     (None, 4, 1, 64)          164096    \r\n_________________________________________________________________\r\ndropout_2 (Dropout)          (None, 4, 1, 64)          0         \r\n_________________________________________________________________\r\nbatch_norm_2 (BatchNormaliza (None, 4, 1, 64)          256       \r\n_________________________________________________________________\r\nflatten_2 (Flatten)          (None, 256)               0         \r\n_________________________________________________________________\r\nrepeat_vector_2 (RepeatVecto (None, 3, 256)            0         \r\n_________________________________________________________________\r\nreshape_2 (Reshape)          (None, 3, 4, 1, 64)       0         \r\n_________________________________________________________________\r\nconv_lstm_3 (ConvLSTM2D)     (None, 3, 4, 1, 64)       327936    \r\n_________________________________________________________________\r\ndropout_3 (Dropout)          (None, 3, 4, 1, 64)       0         \r\n_________________________________________________________________\r\nbatch_norm_3 (BatchNormaliza (None, 3, 4, 1, 64)       256       \r\n_________________________________________________________________\r\nconv_lstm_4 (ConvLSTM2D)     (None, 3, 4, 1, 64)       164096    \r\n_________________________________________________________________\r\ntime_distributed_2 (TimeDist (None, 3, 4, 1, 1)        65        \r\n=================================================================\r\n```\r\nAbout train data and test data shape.\r\nThis shape means each 8 time steps have one time series feature of length 4.\r\nPredict is next 3 time step.\r\n```python\r\n- X_train shape : (198, 8, 4, 1, 1)    X_test shape : (150, 8, 4, 1, 1)\r\n- Y_train shape : (198, 3, 4, 1, 1)    Y_test shape : (150, 3, 4, 1, 1)\r\n```\r\nI want to increase number of timeseries feature of length 4 like below.\r\n```python\r\n- multi_X_train shape : (198, 8, 2, 4, 1)   multi_X_test shape : (150, 8, 2, 4, 1)\r\n- Y_train shape : (198, 3, 4, 1, 1)    Y_test shape : (150, 3, 4, 1, 1)\r\n```\r\n```python\r\ndef build_multi_model(input_timesteps, output_timesteps, num_links):\r\n    model = tf.keras.Sequential()\r\n#     model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 2, 1)))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, 2, 4 ,1)))\r\n    \r\n    #Encoder\r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_1',\r\n                         filters = num_filters, kernel_size = (kernel_size[0], 2),                       \r\n                         padding = 'same', \r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_1'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_1'))\r\n\r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_2',\r\n                         filters = num_filters, kernel_size = (kernel_size[1], 2),\r\n                         padding='same',\r\n                         return_sequences = False))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_2'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_2'))\r\n    \r\n    model.add(tf.keras.layers.Flatten())\r\n    \r\n    #Decoder\r\n    model.add(tf.keras.layers.RepeatVector(output_timesteps))\r\n    model.add(tf.keras.layers.Reshape((output_timesteps, num_links, 1, 64)))\r\n    \r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_3',\r\n                         filters = num_filters, kernel_size = (kernel_size[0], 2),\r\n                         padding='same',\r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_3'))\r\n    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_3'))\r\n    \r\n    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_4',\r\n                         filters = num_filters, kernel_size = (kernel_size[1], 2),\r\n                         padding='same',\r\n                         return_sequences = True))\r\n    \r\n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1, name = 'dense_1', activation = 'relu')))\r\n    #model.add(Dense(units=1, name = 'dense_2'))\r\n\r\n    optimizer = tf.keras.optimizers.RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)\r\n    model.compile(loss = \"mse\", optimizer = optimizer)\r\n    return model\r\n\r\nModel: \"sequential_23\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nbatch_norm_0 (BatchNormaliza (None, 8, 2, 4, 1)        4         \r\n_________________________________________________________________\r\nconv_lstm_1 (ConvLSTM2D)     (None, 8, 2, 4, 64)       333056    \r\n_________________________________________________________________\r\ndropout_1 (Dropout)          (None, 8, 2, 4, 64)       0         \r\n_________________________________________________________________\r\nbatch_norm_1 (BatchNormaliza (None, 8, 2, 4, 64)       256       \r\n_________________________________________________________________\r\nconv_lstm_2 (ConvLSTM2D)     (None, 2, 4, 64)          327936    \r\n_________________________________________________________________\r\ndropout_2 (Dropout)          (None, 2, 4, 64)          0         \r\n_________________________________________________________________\r\nbatch_norm_2 (BatchNormaliza (None, 2, 4, 64)          256       \r\n_________________________________________________________________\r\nflatten_22 (Flatten)         (None, 512)               0         \r\n_________________________________________________________________\r\nrepeat_vector_22 (RepeatVect (None, 3, 512)            0         \r\n_________________________________________________________________\r\nreshape_22 (Reshape)         (None, 3, 4, 1, 64)       0         \r\n_________________________________________________________________\r\nconv_lstm_3 (ConvLSTM2D)     (None, 3, 4, 1, 64)       655616    \r\n_________________________________________________________________\r\ndropout_3 (Dropout)          (None, 3, 4, 1, 64)       0         \r\n_________________________________________________________________\r\nbatch_norm_3 (BatchNormaliza (None, 3, 4, 1, 64)       256       \r\n_________________________________________________________________\r\nconv_lstm_4 (ConvLSTM2D)     (None, 3, 4, 1, 64)       327936    \r\n_________________________________________________________________\r\ntime_distributed_22 (TimeDis (None, 3, 4, 1, 1)        65        \r\n=================================================================\r\n```\r\nI could't understand why below error occurred when i tried model fit.\r\n```python\r\nmodel = build_multi_model(8, 3, 4)\r\nhistory = model.fit(multi_X_train, Y_train,\r\n                    batch_size = batch_size, epochs = epoch,\r\n                    shuffle = False, validation_data = (multi_X_test, Y_test),\r\n                    verbose = 2, callbacks = [call_back])\r\n```\r\n```sh\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-559-7b082bf34abc> in <module>\r\n      6                     batch_size = batch_size, epochs = epoch,\r\n      7                     shuffle = False, validation_data = (multi_X_test, Y_test),\r\n----> 8                     verbose = 2, callbacks = [call_back])\r\n      9 \r\n     10 print(\"early_stopping\")\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    340                 mode=ModeKeys.TRAIN,\r\n    341                 training_context=training_context,\r\n--> 342                 total_epochs=epochs)\r\n    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    344 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    126         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    127       try:\r\n--> 128         batch_outs = execution_function(iterator)\r\n    129       except (StopIteration, errors.OutOfRangeError):\r\n    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     96     # `numpy` translates Tensors to values in Eager mode.\r\n     97     return nest.map_structure(_non_none_constant_value,\r\n---> 98                               distributed_function(input_fn))\r\n     99 \r\n    100   return execution_function\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    630         # Lifting succeeded, so variables are initialized and we can run the\r\n    631         # stateless function.\r\n--> 632         return self._stateless_fn(*args, **kwds)\r\n    633     else:\r\n    634       canon_args, canon_kwds = \\\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2361     with self._lock:\r\n   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2364 \r\n   2365   @property\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1609          if isinstance(t, (ops.Tensor,\r\n   1610                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1611         self.captured_inputs)\r\n   1612 \r\n   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1690       # No tape is watching; skip to running the function.\r\n   1691       return self._build_call_outputs(self._inference_function.call(\r\n-> 1692           ctx, args, cancellation_manager=cancellation_manager))\r\n   1693     forward_backward = self._select_forward_and_backward_functions(\r\n   1694         args,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    543               inputs=args,\r\n    544               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 545               ctx=ctx)\r\n    546         else:\r\n    547           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n~/.local/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError:  Input to reshape is a tensor with 98304 values, but the requested shape has 49152\r\n\t [[node sequential_23/reshape_22/Reshape (defined at <ipython-input-559-7b082bf34abc>:8) ]] [Op:__inference_distributed_function_126239]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```\r\n\r\n\r\n", "comments": ["@swkky \r\n\r\nLooks like code is incomplete. Request you to share colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45205, "title": "Tensorflow 2.3.0 Bazel 3.1.0 compile ERROR", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform: Ubuntu 16.04:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.3.0\r\n- Python version:3.5\r\n- Bazel version (if compiling from source):3.1.0\r\n- GCC/Compiler version (if compiling from source):5.4.0 / 7.3.0 / 7.5.0\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:V100\r\n- cudnn version:7.6.5\r\n\r\nCompile Config:\r\nbuild --action_env PYTHON_BIN_PATH=\"/home/anaconda3/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/home/anaconda3/lib/python3.5/site-packages\"\r\nbuild --python_path=\"/home/anaconda3/bin/python3\"\r\nbuild --config=xla\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda-10.1\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,7.0\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/home/install/gcc-7.3.0/lib\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/home/install/gcc-7.3.0/bin/gcc\"\r\nbuild --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_env=LD_LIBRARY_PATH\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n\r\n**Describe the problem**\r\nI tried to build tensorflow 2.3.0 from source using bazel. I also checked the requirements of GCC, CUDA, and CUDNN. \r\nBut the error still occured:\r\n\r\nERROR: /home/code/release/tensorflow-2.3.0/tensorflow/stream_executor/cuda/BUILD:457:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:21: error: 'cusparseSpVecDescr_t' was not declared in this scope\r\n cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,\r\n                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:43: error: 'spVecDescr' was not declared in this scope\r\n cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,\r\n                                           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:63: error: expected primary-expression before 'size'\r\n cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,\r\n                                                               ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:77: error: expected primary-expression before 'nnz'\r\n cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,\r\n                                                                             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:21: error: expected primary-expression before 'void'\r\n                     void *indices, void *values, cusparseIndexType_t idxType,\r\n                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:36: error: expected primary-expression before 'void'\r\n                     void *indices, void *values, cusparseIndexType_t idxType,\r\n                                    ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:70: error: expected primary-expression before 'idxType'\r\n                     void *indices, void *values, cusparseIndexType_t idxType,\r\n                                                                      ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:41: error: expected primary-expression before 'idxBase'\r\n                     cusparseIndexBase_t idxBase, cudaDataType valueType) {\r\n                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:63: error: expected primary-expression before 'valueType'\r\n                     cusparseIndexBase_t idxBase, cudaDataType valueType) {\r\n                                                               ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:72: error: expression list treated as compound expression in initializer [-fpermissive]\r\n                     cusparseIndexBase_t idxBase, cudaDataType valueType) {\r\n                                                                        ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:74: error: expected ',' or ';' before '{' token\r\n                     cusparseIndexBase_t idxBase, cudaDataType valueType) {\r\n                                                                          ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:22: error: 'cusparseSpVecDescr_t' was not declared in this scope\r\n cusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {\r\n                      ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:55: error: expected ',' or ';' before '{' token\r\n cusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {\r\n                                                       ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7807:11: error: 'cusparseSpVecDescr_t' does not name a type\r\n     const cusparseSpVecDescr_t spVecDescr, int64_t *size, int64_t *nnz,\r\n           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGet(int, int64_t*, int64_t*, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7811:13: error: 'cusparseSpVecDescr_t' does not name a type\r\n       const cusparseSpVecDescr_t, int64_t *, int64_t *, void **, void **,\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7820:11: error: 'cusparseSpVecDescr_t' does not name a type\r\n     const cusparseSpVecDescr_t spVecDescr, cusparseIndexBase_t *idxBase) {\r\n           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGetIndexBase(int, cusparseIndexBase_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7821:57: error: 'cusparseSpVecDescr_t' does not name a type\r\n   using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(const cusparseSpVecDescr_t,\r\n                                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7829:30: error: 'cusparseSpVecDescr_t' does not name a type\r\n cusparseSpVecGetValues(const cusparseSpVecDescr_t spVecDescr, void **values) {\r\n                              ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGetValues(int, void**)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7831:45: error: 'cusparseSpVecDescr_t' does not name a type\r\n       cusparseStatus_t(CUSPARSEAPI *)(const cusparseSpVecDescr_t, void **);\r\n                                             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:24: error: 'cusparseSpVecDescr_t' was not declared in this scope\r\n cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {\r\n                        ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:57: error: expected primary-expression before 'void'\r\n cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {\r\n                                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:69: error: expression list treated as compound expression in initializer [-fpermissive]\r\n cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {\r\n                                                                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:71: error: expected ',' or ';' before '{' token\r\n cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {\r\n                                                                       ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:21: error: 'cusparseDnVecDescr_t' was not declared in this scope\r\n cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,\r\n                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:43: error: 'dnVecDescr' was not declared in this scope\r\n cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,\r\n                                           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:63: error: expected primary-expression before 'size'\r\n cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,\r\n                                                               ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:21: error: expected primary-expression before 'void'\r\n                     void *values, cudaDataType valueType) {\r\n                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:48: error: expected primary-expression before 'valueType'\r\n                     void *values, cudaDataType valueType) {\r\n                                                ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:57: error: expression list treated as compound expression in initializer [-fpermissive]\r\n                     void *values, cudaDataType valueType) {\r\n                                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:59: error: expected ',' or ';' before '{' token\r\n                     void *values, cudaDataType valueType) {\r\n                                                           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7856:22: error: 'cusparseDnVecDescr_t' was not declared in this scope\r\n cusparseDestroyDnVec(cusparseDnVecDescr_t dnVecDescr) {\r\n                      ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7856:55: error: expected ',' or ';' before '{' token\r\n cusparseDestroyDnVec(cusparseDnVecDescr_t dnVecDescr) {\r\n                                                       ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7864:24: error: 'cusparseDnVecDescr_t' does not name a type\r\n cusparseDnVecGet(const cusparseDnVecDescr_t dnVecDescr, int64_t *size,\r\n                        ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnVecGet(int, int64_t*, void**, cudaDataType*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7867:13: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseDnVecDescr_t, int64_t *, void **, cudaDataType *);\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7874:30: error: 'cusparseDnVecDescr_t' does not name a type\r\n cusparseDnVecGetValues(const cusparseDnVecDescr_t dnVecDescr, void **values) {\r\n                              ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnVecGetValues(int, void**)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7876:45: error: 'cusparseDnVecDescr_t' does not name a type\r\n       cusparseStatus_t(CUSPARSEAPI *)(const cusparseDnVecDescr_t, void **);\r\n                                             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:24: error: 'cusparseDnVecDescr_t' was not declared in this scope\r\n cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {\r\n                        ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:57: error: expected primary-expression before 'void'\r\n cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {\r\n                                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:69: error: expression list treated as compound expression in initializer [-fpermissive]\r\n cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {\r\n                                                                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:71: error: expected ',' or ';' before '{' token\r\n cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {\r\n                                                                       ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int64_t, int64_t, int64_t, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7896:70: error: conflicting declaration of C function 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int64_t, int64_t, int64_t, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)'\r\n                                                cudaDataType valueType) {\r\n                                                                      ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6971:1: note: previous declaration 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int, int, int, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)'\r\n cusparseCreateCoo(cusparseSpMatDescr_t* spMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int64_t*, int64_t*, int64_t*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7950:39: error: conflicting declaration of C function 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int64_t*, int64_t*, int64_t*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)'\r\n                cudaDataType *valueType) {\r\n                                       ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6986:1: note: previous declaration 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int*, int*, int*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)'\r\n cusparseCooGet(const cusparseSpMatDescr_t spMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, int64_t, int64_t, int64_t, void*, cudaDataType, cusparseOrder_t)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8047:64: error: conflicting declaration of C function 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, int64_t, int64_t, int64_t, void*, cudaDataType, cusparseOrder_t)'\r\n     void *values, cudaDataType valueType, cusparseOrder_t order) {\r\n                                                                ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7017:1: note: previous declaration 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, size_t, size_t, int64_t, void*, cudaDataType, cusparseOrder_t)'\r\n cusparseCreateDnMat(cusparseDnMatDescr_t* dnMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, int64_t*, int64_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8066:75: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, int64_t*, int64_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)'\r\n     int64_t *ld, void **values, cudaDataType *type, cusparseOrder_t *order) {\r\n                                                                           ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7029:1: note: previous declaration 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, size_t*, size_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)'\r\n cusparseDnMatGet(const cusparseDnMatDescr_t dnMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, int64_t)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8093:73: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, int64_t)'\r\n     cusparseDnMatDescr_t dnMatDescr, int batchCount, int64_t batchStride) {\r\n                                                                         ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7038:1: note: previous declaration 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, size_t)'\r\n cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t dnMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8103:67: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)'\r\n                              int *batchCount, int64_t *batchStride) {\r\n                                                                   ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7043:1: note: previous declaration 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, size_t*)'\r\n cusparseDnMatGetStridedBatch(const cusparseDnMatDescr_t dnMatDescr,\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8113:20: error: 'cusparseSpVecDescr_t' does not name a type\r\n              const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,\r\n                    ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8113:53: error: 'cusparseDnVecDescr_t' does not name a type\r\n              const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,\r\n                                                     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVV(cusparseHandle_t, cusparseOperation_t, int, int, void*, cudaDataType, void*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8116:52: error: 'cusparseSpVecDescr_t' does not name a type\r\n       cusparseHandle_t, cusparseOperation_t, const cusparseSpVecDescr_t,\r\n                                                    ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8117:13: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseDnVecDescr_t, void *, cudaDataType, void *);\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8125:11: error: 'cusparseSpVecDescr_t' does not name a type\r\n     const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,\r\n           ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8125:44: error: 'cusparseDnVecDescr_t' does not name a type\r\n     const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,\r\n                                            ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVV_bufferSize(cusparseHandle_t, cusparseOperation_t, int, int, const void*, cudaDataType, size_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8128:52: error: 'cusparseSpVecDescr_t' does not name a type\r\n       cusparseHandle_t, cusparseOperation_t, const cusparseSpVecDescr_t,\r\n                                                    ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8129:13: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseDnVecDescr_t, const void *, cudaDataType, size_t *);\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8137:44: error: 'cusparseDnVecDescr_t' does not name a type\r\n     const cusparseSpMatDescr_t matA, const cusparseDnVecDescr_t vecX,\r\n                                            ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8138:29: error: 'cusparseDnVecDescr_t' does not name a type\r\n     const void *beta, const cusparseDnVecDescr_t vecY, cudaDataType computeType,\r\n                             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8139:5: error: 'cusparseSpMVAlg_t' has not been declared\r\n     cusparseSpMVAlg_t alg, void *externalBuffer) {\r\n     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpMV(cusparseHandle_t, cusparseOperation_t, const void*, cusparseSpMatDescr_t, int, const void*, int, cudaDataType, int, void*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8142:41: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseSpMatDescr_t, const cusparseDnVecDescr_t, const void *,\r\n                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8143:13: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, void *);\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8143:49: error: 'cusparseSpMVAlg_t' has not been declared\r\n       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, void *);\r\n                                                 ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8152:44: error: 'cusparseDnVecDescr_t' does not name a type\r\n     const cusparseSpMatDescr_t matA, const cusparseDnVecDescr_t vecX,\r\n                                            ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8153:29: error: 'cusparseDnVecDescr_t' does not name a type\r\n     const void *beta, const cusparseDnVecDescr_t vecY, cudaDataType computeType,\r\n                             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8154:5: error: 'cusparseSpMVAlg_t' has not been declared\r\n     cusparseSpMVAlg_t alg, size_t *bufferSize) {\r\n     ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpMV_bufferSize(cusparseHandle_t, cusparseOperation_t, const void*, cusparseSpMatDescr_t, int, const void*, int, cudaDataType, int, size_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8157:41: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseSpMatDescr_t, const cusparseDnVecDescr_t, const void *,\r\n                                         ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8158:13: error: 'cusparseDnVecDescr_t' does not name a type\r\n       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, size_t *);\r\n             ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8158:49: error: 'cusparseSpMVAlg_t' has not been declared\r\n       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, size_t *);\r\n                                                 ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/code/release/tensorflow-2.3.0/tensorflow/tools/pip_package/BUILD:66:1 C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)\r\nINFO: Elapsed time: 678.697s, Critical Path: 218.52s\r\nINFO: 11196 processes: 11196 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt --config=cuda --copt=-fstack-protector-strong --copt=-fPIC --copt=-U_FORTIFY_SOURCE --copt=-D_FORTIFY_SOURCE=2 --copt=-O3 --linkopt=-Wl,-z,relro --linkopt=-Wl,-z,now --linkopt=-Wl,-z,noexecstack --linkopt=-Wl,--strip-all --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\nAnd I also tried:\r\nbazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\nThank you.\r\n\r\n\r\n", "comments": ["@iamweiweishi,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/40260#issuecomment-644477690) from a similar issue and let us know if you are still facing the same issue. Thanks!", "I added the '--action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH' cmd, but the error is still the same. \r\n\r\nI also tried to upgrade CUDA to 10.2, but the error become:\r\n\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h: In function 'constexpr absl::lts_2020_02_25::time_internal::cctz::detail::civil_day absl::lts_2020_02_25::time_internal::cctz::detail::prev_weekday(absl::lts_2020_02_25::time_internal::cctz::detail::civil_day, absl::lts_2020_02_25::time_internal::cctz::detail::weekday)':\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h:587:20: error: call to non-constexpr function 'absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag> absl::lts_2020_02_25::time_internal::cctz::detail::operator-(absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag>, absl::lts_2020_02_25::time_internal::cctz::diff_t)'\r\n           return cd - (j - i);\r\n                    ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/code/release/tensorflow/tensorflow/python/tools/BUILD:314:1 C++ compilation of rule '//tensorflow/core/kernels:sparse_tensor_dense_matmul_op_gpu' failed (Exit 1)\r\nINFO: Elapsed time: 683.897s, Critical Path: 179.57s\r\nINFO: 11495 processes: 11495 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\nI have no idea how to solve this issure.\r\n\r\nThank you. \r\n\r\n\r\n> @iamweiweishi,\r\n> Please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/40260#issuecomment-644477690) from a similar issue and let us know if you are still facing the same issue. Thanks!\r\n\r\n", "I would suggest using the [Docker build process](https://www.tensorflow.org/install/source#docker_linux_builds), which is a lot less error-prone. Builds often fail because of unlucky combinations of build-tool versions. The docker images handle that for you.", "I experienced the same errors with tensorflow 2.3.0 on Ubuntu 20.04, GCC 8 and cuda 10.1. Note however that I am building the C++ library and not the pip package: //tensorflow:libtensorflow_cc.so, still the errors I get are the same. I had installed cuda using the open source nvidia-cuda-toolkit package (sudo apt install nvidia-cuda-toolkit). I read somewhere on github (can't find the source now), that building TF from source was not compatible with this package. Thus, I removed this package, and instead installed cuda version 10.1 243 for Ubuntu 18.04: \r\n```bash\r\nsudo apt remove --purge nvidia-cuda-toolkit\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-get update\r\nsudo apt install cuda\r\n```\r\n\r\nThen I installed cudnn 7.6.5 for cuda 10.1 from the deb packages on nvidia's webpage.\r\n\r\nIf you try to rebuild now, you will get the same error, this is because bazel has a cache. Delete this cache:\r\n```bash\r\nrm -Rf /home/<your username>/.cache/bazel/\r\n```\r\nI also deleted the whole build folder and started all over.\r\nThese errors where then gone.\r\n\r\nHope this helps others, and I hope that someday nvidia will clean up their software distribution methodology which currently, in my opinion, is a complete mess.", "@iamweiweishi,\r\n\r\nCan you try installing the latest stable version of tensorflow i.e `2.6.0` using this [guide](https://www.tensorflow.org/install/source#tested_build_configurations) to build from source. Also make sure that you have the supported version of CUDA,CUDNN,compiler as per the [tested build configurations](https://www.tensorflow.org/install/source#gpu) section. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45205\">No</a>\n"]}, {"number": 45204, "title": "Keras TB callback: Fix write_steps_per_second when profile_batch=0", "body": "cef7da10e1e944e11961f4d18978f611358023b2 introduced a bug where setting `write_steps_per_second` had no effect in cases where `profile_batch=0`.\r\nThis is due to an optimisation in the TensorBoard callback that disables calling batch hooks when not necessary.\r\n\r\nThis PR fixes it by making sure that batch level hooks are always called when `write_steps_per_second` is `True`.", "comments": []}, {"number": 45203, "title": "tf.linalg.diag_part does not use matrix_diag_part_v2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.15.3-68-gdf8c55c 1.15.4\r\n- Python version: 3.6.12\r\n\r\n**Describe the current behavior**\r\n\r\nIn tensorflow v1, `tf.linalg.diag_part` does not use `matrix_diag_part_v2`, making impossible to get sub-diagonal or a superdiagonal. \r\n\r\n**Describe the expected behavior**\r\n\r\n`tf.linalg.diag_part` should call `matrix_diag_part_v2` for the argument `k` to be considered. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.ops.gen_array_ops import matrix_diag_part_v2\r\n\r\na = tf.reshape(tf.range(1,10),(3,3))\r\ndiag =  tf.linalg.diag_part(a,k=0,padding_value=0)\r\nsuperdiag = tf.linalg.diag_part(a,k=1,padding_value=0)\r\nwith tf.Session() as sess:\r\n    d = sess.run(diag)\r\n    sd = sess.run(superdiag)\r\n    assert (d == np.array([1,5,9])).all()\r\n    assert (sd == np.array([2,6])), f\"sd:{sd} != [2,6]\"\r\n```\r\n\r\nUsing directly `matrix_diag_part_v2` produces the correct behavior : \r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.ops.gen_array_ops import matrix_diag_part_v2\r\n\r\na = tf.reshape(tf.range(1,10),(3,3))\r\ndiag =  matrix_diag_part_v2(a,k=0,padding_value=0)\r\nsuperdiag = matrix_diag_part_v2(a,k=1,padding_value=0)\r\nwith tf.Session() as sess:\r\n    d = sess.run(diag)\r\n    sd = sess.run(superdiag)\r\n    assert (d == np.array([1,5,9])).all()\r\n    assert (sd == np.array([2,6])).all(), f\"sd:{sd} != [2,6]\"\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\n`matrix_diag_v2` seems to be disabled by this line : https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/array_ops.py#L2174\r\n\r\nIs it intentional to disable that behavior? If yes, the doc should be updated accordingly. \r\n\r\n", "comments": ["@Lescurel \r\nI ran the code shared please refer to [the gist](https://colab.research.google.com/gist/Saduf2019/fde372015083ad49bb5897296ee33aff/untitled474.ipynb) and confirm.", "@Saduf2019 Yes, I confirm. ", "@Lescurel \r\nIs there any particular reason for using 1.x, as here is no support for it now, can you upgrade to 2.x and see if you face any issues.", "@Saduf2019  I can upgrade to 2.x, and there is no issue with `tf.linalg.diag_part` in TF2. \r\n\r\nI just think that the doc of TF1.x could be updated to reflect the real behavior. If my understanding is correct, with the current behavior, the parameter `k` and `padding_value` of `tf.linalg.diag_part` does nothing.  \r\n\r\nIf this behavior is not to be fixed, then close the issue. ", "> with the current behavior, the parameter k and padding_value of tf.linalg.diag_part does nothing.\r\n\r\nYes. This is clearly  a bug in 1.15. But It's definitely not something significant enough that we'd make a patch release for it, we only do patch releases for major bugs or security fixes. So I'm closing this.\r\n\r\n"]}, {"number": 45201, "title": "Is there a tool for XLA to convert XLA-HLO-IR to a graph (such as dot for graphviz, or html)?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): TF-2.3rc2\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI have noticed that in the path (tensorflow/compiler/xla/tools), many tools are available for debugging the system.\r\nIs there a tool for XLA to convert XLA-HLO-IR to a graph (such as dot for graphviz, or html)? \r\n\r\n**What we have:** I have dumped a XLA-HLO, in the format of text;\r\n**What We want:** I want to convert it to a visualized format, such as dot, and html.\r\nIt was noted that I have just found that there is an  interactive tool, namely \"interactive_graphviz\", but it can not convert the data to a dot or html format as we expected.\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n**Who will benefit with this feature?**\r\nhelpful to profile the runtime feature of XLA optimizations\r\n**Any Other info.**\r\n", "comments": []}, {"number": 45200, "title": "Could not load dynamic library 'libcudnn.so.8'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.9\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tf-nightly-gpu 2.5.0.dev20201125\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): ---\r\n- GCC/Compiler version (if compiling from source): ---\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: 10 x 1080Ti 11GB\r\n\r\n\r\nI want to create keras model using multiple GPUs.\r\n\r\nI have prepared simple code to display visible devices:\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7, 8, 9\"\r\ntf.config.experimental.list_logical_devices('GPU')\r\n```\r\n\r\n\r\nBut my output is:\r\n\r\n\r\n```\r\n2020-11-26 10:23:19.183104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-26 10:23:22.087731: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-26 10:23:22.089534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-26 10:23:22.894765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties:\r\npciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-11-26 10:23:22.901688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 1 with properties:\r\npciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-11-26 10:23:22.908844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 2 with properties:\r\npciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-11-26 10:23:22.908893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-26 10:23:22.913327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-26 10:23:22.913376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-26 10:23:22.914897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-26 10:23:22.915190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-26 10:23:22.917940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-26 10:23:22.918885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-26 10:23:22.919011: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\r\n2020-11-26 10:23:22.919038: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1764] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\n", "comments": ["Same happens for Ubuntu WSL 2 after following https://docs.nvidia.com/cuda/wsl-user-guide/index.html#installing-wsl2 and not using docker. TF 2.4.0.rc3\r\n```\r\n>>> import tensorflow_text as text\r\n2020-11-26 14:56:59.928177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n>>> import tensorflow as tf\r\n>>> import tensorflow_hub as hub\r\n>>> text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\r\nrocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\")>>> preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\")\r\n2020-11-26 14:57:22.940593: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-26 14:57:22.952421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-26 14:57:23.213309: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\nYour kernel may have been built without NUMA support.\r\n2020-11-26 14:57:23.213654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1\r\ncoreClock: 1.683GHz coreCount: 15 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-11-26 14:57:23.213728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-26 14:57:23.253183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-26 14:57:23.253310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-26 14:57:23.282988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-26 14:57:23.290707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-26 14:57:23.309221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-26 14:57:23.313288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-26 14:57:23.313511: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\r\n```", "Solved using Anaconda.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45200\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45200\">No</a>\n", "Same issue with \"tensorflow==2.4.0rc\" on WSL 2 Ubuntu with Cuda 11", "Same issue with Ubuntu 20.04, tensorflow 2.4.1 and cuda 11.2.\r\n\r\nEDIT:\r\nIn my case the issue was, that I needed to install `libcudnn8`. I did so downloading and executing the debian package from [here](https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/).", "Vanilla tensorflow doesn't work with cuda out of the box. Just follow Nvidia's instructions and use containerized special tensorflow-nvidia with pre-set up environment around.", "@ValleZ \r\nPlease create a new issue as this issue is in closed status.", "> Vanilla tensorflow doesn't work with cuda out of the box. Just follow Nvidia's instructions and use containerized special tensorflow-nvidia with pre-set up environment around.\r\n\r\nFaced the same error. Can point me to any specific link which gives the necessary packages and installation instruction? Also, does it mean all my development efforts will have to be inside a docker container? ", "> Same issue with Ubuntu 20.04, tensorflow 2.4.1 and cuda 11.2.\r\n> \r\n> EDIT:\r\n> In my case the issue was, that I needed to install `libcudnn8`. I did so downloading and executing the debian package from [here](https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/).\r\n\r\nIt helps me a lot!\r\nMy env is Ubuntu 20.04 kernel 5.8.0-45-generic,nvidia-460.67,cuda 11.0,cudnn v8.0.5,tensorflow 2.4.1.\r\nI downloaded and installed \"libcudnn8_8.0.5.39-1+cuda11.0_amd64.deb\", and the question was solved.", "I got same situation when using my school's GPU farm, and I ran \"conda install -c nvidia cudnn\", then the problem is gone(The machine had already install CUDA10.1 and cudnn8.0.4)", "> I got same situation when using my school's GPU farm, and I ran \"conda install -c nvidia cudnn\", then the problem is gone(The machine had already install CUDA10.1 and cudnn8.0.4)\r\n\r\nWorked for me as well", "You can also use `conda install -c conda-forge cudnn`, if it would not start download after using `conda install -c nvidia cudnn` (as it was in my case). It helped me solve the problem.\r\n\r\nUbuntu 18.04; TensorFlow 2.5.0;\r\n\r\n[conda-forge cudnn](https://anaconda.org/conda-forge/cudnn)", "I solved it by adding the link of my lib to .bashrc and then `source .bashrc`. ", "> I solved it by adding the link of my lib to .bashrc and then `source .bashrc`.\r\n\r\nCan you please explain elaborately what exactly you did? Thank you!", "> Same issue with Ubuntu 20.04, tensorflow 2.4.1 and cuda 11.2.\r\n> \r\n> EDIT: In my case the issue was, that I needed to install `libcudnn8`. I did so downloading and executing the debian package from [here](https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/).\r\n\r\n**Thank you so much**. This seem to have fixed the problem for me. \r\nMy setup details -\r\nOperating System: Ubuntu 20.04.3 LTS\r\nKernel: Linux 5.11.0-43-generic\r\nArchitecture: x86-64\r\n\r\nNvidia driver: 470.86 \r\nCuda toolkit: 11.2, V11.2.67\r\nTensorflow: 2.5.2\r\n"]}, {"number": 45199, "title": "maskrcnn convert error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (or github SHA if from source):2.3.1\r\n\r\n**tflite_convert code**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n# Convert the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"./saved/\")\r\n\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n    tf.lite.OpsSet.SELECT_TF_OPS] # enable TensorFlow ops.\r\n\r\nconverter.experimental_new_converter = True\r\n#converter.allow_custom_ops=True\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\n**the issue information** \r\n```\r\n2020-11-26 00:41:12.251078: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./saved/\r\n2020-11-26 00:41:12.272903: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\r\n2020-11-26 00:41:12.272975: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./saved/\r\n2020-11-26 00:41:12.273052: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-26 00:41:12.342434: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:252] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n2020-11-26 00:41:12.432545: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2020-11-26 00:41:12.978910: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 727829 microseconds.\r\n2020-11-26 00:41:13.202547: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2020-11-26 00:41:13.703742: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nloc(\"mrcnn_detection/DenseToDenseSetOperation\"): error: 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\nloc(\"mrcnn_detection/DenseToDenseSetOperation_1\"): error: 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\n2020-11-26 00:41:21.116517: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1670] Graph contains TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3 op(s), that use(s) resource type. Currently, the resource type is not natively supported in TFLite. Please consider not using the resource type if there are issues with either TFLite converter or TFLite runtime.\r\nerror: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.DenseToDenseSetOperation {T = i64, device = \"\", set_operation = \"intersection\", validate_indices = true}\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py\", line 210, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: <unknown>:0: error: loc(\"mrcnn_detection/DenseToDenseSetOperation\"): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"mrcnn_detection/DenseToDenseSetOperation_1\"): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.DenseToDenseSetOperation {T = i64, device = \"\", set_operation = \"intersection\", validate_indices = true}\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"convert.py\", line 13, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/lite.py\", line 745, in convert\r\n    result = _convert_saved_model(**converter_kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py\", line 636, in convert_saved_model\r\n    data = toco_convert_protos(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py\", line 216, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(\"mrcnn_detection/DenseToDenseSetOperation\"): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"mrcnn_detection/DenseToDenseSetOperation_1\"): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.DenseToDenseSetOperation {T = i64, device = \"\", set_operation = \"intersection\", validate_indices = true}\r\n\r\n```\r\n\r\nLooking forward to your prompt reply\uff0cthanks\uff01", "comments": ["@chuqnzhao \r\n\r\nWill it be possible to share the model file which helps us to reproduce the issue.\r\nAlso, please try with nightly version and see if the issue still persists. Thanks!", "> @chuqnzhao\r\n> \r\n> Will it be possible to share the model file which helps us to reproduce the issue.\r\n> Also, please try with nightly version and see if the issue still persists. Thanks!\r\n\r\nI've already tried nightly version and  have encountered the same problem.\r\nthe model file link:  https://pan.baidu.com/s/1QbeUVM13tnQHG60Bv5faeg\r\nthanks!", "I have tried in colab with TF version 2.3 and was able to reproduce the issue. With TF nightly version it crashes.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ca5af72d7f99aec5ffdc48ef377ae07d/untitled540.ipynb).\r\n@chuqnzhao\r\n\r\nI am not able to access the link you have provided.\r\n\r\nThanks!", "> I have tried in colab with TF version 2.3 and was able to reproduce the issue. With TF nightly version it crashes.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ca5af72d7f99aec5ffdc48ef377ae07d/untitled540.ipynb).\r\n> @chuqnzhao\r\n> \r\n> I am not able to access the link you have provided.\r\n> \r\n> Thanks!\r\n\r\nI'm terribly sorry about that. Please visit this link\uff1ahttps://github.com/chuqnzhao/maskrcnn.git\r\n\r\nLooking forward to your prompt reply\uff0cthanks\uff01", "@chuqnzhao I am seeing lot of warnings (before `OutOfRangeError:  Read less bytes than requested`) the as shown below. Looks like while loading model, it was not able to access `tf.Variable`). Please check below.\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/e63a664c1df8181acb3dcb1e98ae3d56/untitled540.ipynb) is a gist for our reference. Thanks!\r\n\r\nCan you please share model building code? Thanks! \r\n\r\n```\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\nWARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n```", "> @chuqnzhao I am seeing lot of warnings (before `OutOfRangeError: Read less bytes than requested`) the as shown below. Looks like while loading model, it was not able to access `tf.Variable`). Please check below.\r\n> \r\n> [Here](https://colab.research.google.com/gist/jvishnuvardhan/e63a664c1df8181acb3dcb1e98ae3d56/untitled540.ipynb) is a gist for our reference. Thanks!\r\n> \r\n> Can you please share model building code? Thanks!\r\n> \r\n> ```\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> ```\r\n\r\n@jvishnuvardhan \r\nThank you for your reply\uff0cI used the following link to generate the TensorFlow model, and then used the TensorFlow tool to convert the model to the savedModel type.\r\nhttps://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py", "> > @chuqnzhao I am seeing lot of warnings (before `OutOfRangeError: Read less bytes than requested`) the as shown below. Looks like while loading model, it was not able to access `tf.Variable`). Please check below.\r\n> > [Here](https://colab.research.google.com/gist/jvishnuvardhan/e63a664c1df8181acb3dcb1e98ae3d56/untitled540.ipynb) is a gist for our reference. Thanks!\r\n> > Can you please share model building code? Thanks!\r\n> > ```\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\r\n> > ```\r\n> \r\n> @jvishnuvardhan\r\n> Thank you for your reply\uff0cI used the following link to generate the TensorFlow model, and then used the TensorFlow tool to convert the model to the savedModel type.\r\n> https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py\r\nI use your conversion code to prompt for the following error\r\n ```\r\nTraceback (most recent call last):\r\n  File \"convert.py\", line 13, in <module>\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved/\", signature_keys=['serving_default'])\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/lite.py\", line 1101, in from_saved_model\r\n    raise ValueError(\"Invalid signature key '{}' found. Valid keys are \"\r\nValueError: Invalid signature key 'serving_default' found. Valid keys are 'predict'.\r\n\r\n ```\r\nPlease use the following code\uff1a\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"./saved/\", signature_keys=['predict'])", "@chuqnzhao When I made the change from `serving_defaullt` to 'predict`, the error and warnings remain same. \r\n\r\n`If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().` based on this warning, can you rebuild the SavedModel and try the conversion? Thanks!", "> @chuqnzhao When I made the change from `serving_defaullt` to 'predict`, the error and warnings remain same.\r\n> \r\n> `If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().` based on this warning, can you rebuild the SavedModel and try the conversion? Thanks!\r\n\r\n@jvishnuvardhan \r\nFirst of all, thank you for your reply and answer.  Could you please share the code of how to convert the meta model file to savedModel to avoid the above error and warnings, thank you!", "> @chuqnzhao When I made the change from `serving_defaullt` to 'predict`, the error and warnings remain same.\r\n> \r\n> `If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().` based on this warning, can you rebuild the SavedModel and try the conversion? Thanks!\r\n\r\n@jvishnuvardhan \r\nFirst of all, thank you for your reply and answer. Could you please share the code of how to convert the meta model file to savedModel to avoid the above error and warnings, thank you!\r\nI use the following code transformation model, please correct me.\r\n```\r\ndef save_pb(export_path_base, model):\r\n    export_path = get_export_path(export_path_base,VERSIONCONTROLL)\r\n\r\n    print('Exporting trained model to', export_path)\r\n    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\r\n\r\n    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n    signature = predict_signature_def(\r\n                                inputs = {'images': model.keras_model.input[0],\r\n                                            'meta':model.keras_model.input[1],\r\n                                            'anchor':model.keras_model.input[2]},\r\n                                outputs={'detection': model.keras_model.outputs[0],\r\n                                         'mask':model.keras_model.outputs[3]}\r\n                                )\r\n    with K.get_session() as sess:\r\n        builder.add_meta_graph_and_variables(sess=sess,\r\n                                             tags=[tag_constants.SERVING],\r\n                                             signature_def_map={'predict': signature},\r\n                                             #legacy_init_op=legacy_init_op,\r\n                                             clear_devices=True,\r\n                                             )\r\n        builder.save()\r\n        print ('build done!')\r\n    DESTINATION = export_path + '/category.json'\r\n    copyfile(LABELS_FILE, DESTINATION)\r\n```", "> > @chuqnzhao When I made the change from `serving_defaullt` to 'predict`, the error and warnings remain same.\r\n> > `If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().` based on this warning, can you rebuild the SavedModel and try the conversion? Thanks!\r\n> \r\n> @jvishnuvardhan\r\n> First of all, thank you for your reply and answer. Could you please share the code of how to convert the meta model file to savedModel to avoid the above error and warnings, thank you!\r\n> I use the following code transformation model, please correct me.\r\n> \r\n> ```\r\n> def save_pb(export_path_base, model):\r\n>     export_path = get_export_path(export_path_base,VERSIONCONTROLL)\r\n> \r\n>     print('Exporting trained model to', export_path)\r\n>     builder = tf.saved_model.builder.SavedModelBuilder(export_path)\r\n> \r\n>     legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n>     signature = predict_signature_def(\r\n>                                 inputs = {'images': model.keras_model.input[0],\r\n>                                             'meta':model.keras_model.input[1],\r\n>                                             'anchor':model.keras_model.input[2]},\r\n>                                 outputs={'detection': model.keras_model.outputs[0],\r\n>                                          'mask':model.keras_model.outputs[3]}\r\n>                                 )\r\n>     with K.get_session() as sess:\r\n>         builder.add_meta_graph_and_variables(sess=sess,\r\n>                                              tags=[tag_constants.SERVING],\r\n>                                              signature_def_map={'predict': signature},\r\n>                                              #legacy_init_op=legacy_init_op,\r\n>                                              clear_devices=True,\r\n>                                              )\r\n>         builder.save()\r\n>         print ('build done!')\r\n>     DESTINATION = export_path + '/category.json'\r\n>     copyfile(LABELS_FILE, DESTINATION)\r\n> ```\r\n\r\nUse the following code to remove the warning message, Is the DenseToDenseSetOperation operation not currently supported?\r\n```\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(\"./\",input_arrays=['input_image',\"input_image_meta\",\"input_anchors\"],input_shapes={'input_image' : [1, 1024, 1024, 3],'input_image_meta' : [1, 93],'input_anchors' : [1, 261888, 4]},output_arrays=[\"mrcnn_detection/Reshape_1\", \"mrcnn_mask/Reshape_1\"],signature_key='predict')\r\n```", "DenseToDenseSetOperation will be supported through Flex. Please use tf-nightly once the necessary change is merged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45199\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45199\">No</a>\n", "You can try the tomorrow's tf-nightly version. That will have the Flex delegate, which can support the DenseToDenseSetOperation op.", "> You can try the tomorrow's tf-nightly version. That will have the Flex delegate, which can support the DenseToDenseSetOperation op.\r\n@abattery \r\nOk, I will try. Thanks for your reply."]}, {"number": 45198, "title": "Tflite pod lint error", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 10.15.7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0 rc3\r\n- Python version: \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nExecute:\r\n1. git checkout v2.4.0-rc3\r\n2. pod lib lint tensorflow/lite/experimental/ios/TensorFlowLiteC.podspec\r\n\r\nError Message:\r\n    - ERROR | [TensorFlowLiteC/Core, TensorFlowLiteC/CoreML, TensorFlowLiteC/Metal, and more...] file patterns: The `vendored_frameworks` pattern did not match any file.\r\n\r\n**Describe the expected behavior**\r\nLinter should not have any errors. \r\n\r\nWhen working on my private podspec, I saw the same error and went back to check the original source code and found this issues. \r\n\r\nI also downloaded the source file `TensorFlowLiteC.tar.gz` specified in the podspec. The root folder of the unzipped data is not `Frameworks` but `TensorFlowLiteC-2.3.0`.\r\n\r\nThe document [here](https://www.tensorflow.org/lite/guide/build_ios) is outdated. The process of combining `TensorFlowLiteC.framework`, `TensorFlowLiteCCoreML.framework` and `TensorflowLiteCMetal.framework` is not documented. Definitely need some help.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n1. git checkout v2.4.0-rc3\r\n2. pod lib lint tensorflow/lite/experimental/ios/TensorFlowLiteC.podspec\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I found that this issue actually happens in 2.3.0 as well. ", "@yyoon could you check the pod lint error?", "Sorry for the late reply. As of e8b6278a88939b5f2004dd7ebc2f8eb150f9841b, you should be able to run `pod spec lint TensorFlowLiteC.podspec --allow-warnings` and see it pass. There are a few things to note.\r\n\r\nFirst, when a new TF stable release is published (e.g., `v2.4.0` tag which just got released), we update the `.podspec` files on `master` branch *after* the release branch is published. It's unfortunate and confusing, but the main reason for doing this is that we need to build the static framework from the release branch, host the prebuilt binary on our download server, and then use the new URL in the `.podspec` file to be used as the source of the `TensorFlowLiteC` pod.\r\n\r\nIn that sense, I guess it would be awkward to use `pod lib lint` command in a release tag checkout as is. You might want to copy over the `.podspec` files from the following master version and run `pod lib lint` if you need to.\r\n\r\nSecond, there is a known issue with Xcode 12 and CocoaPod CLI's lint feature. Our default Xcode version used for these prebuilts is currently 11, which is confirmed to work, but with Xcode 12 you might be hitting issues like (e.g., https://github.com/CocoaPods/CocoaPods/issues/10104). In that case, you could either use the `--skip-import-validation` or, add the `s.user_target_xcconfig = { 'EXCLUDED_ARCHS[sdk=iphonesimulator*]' => 'arm64' }` line in the `.podspec` and run the lint again.", "No luck. I did the following steps:\r\n\r\n1. checkout `e8b6278`\r\n2. run `pod lib lint TensorFlowLiteC.podspec --allow-warnings`\r\n\r\n> - ERROR | [TensorFlowLiteC/Core, TensorFlowLiteC/CoreML, TensorFlowLiteC/Metal, and more...] file patterns: The `vendored_frameworks` pattern did not match any file.\r\n\r\nIt seems to me that the option `--allow-warnings` doesn't help with errors. I also tried the other two solutions you mentioned, but still got the same error message complaining about the file patterns. \r\n\r\nxcode: Version 12.2 (12B45b)\r\npod version: 1.10.0", "For `TensorFlowLiteC` and its subspecs, we rely on prebuilt static framework archives hosted on Google's download server, as you can see in the `.podspec` files.\r\n\r\nI was referring to `pod spec lint` command, which downloads these prebuilt files and runs verification steps for the downloaded prebuilt archive, and this should work, as I mentioned above.\r\n\r\nOn the other hand, `pod lib lint` is expected to not work AFAIK, because it ignores all the download URLs, etc. and uses the current local directory as the source. The tensorflow checkout directory does not contain the prebuilt binaries (as it only contains source files), and thus it is failing as expected.\r\n\r\nCan you share what you actually want to achieve? What makes you want to run `pod lib lint` command?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45198\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45198\">No</a>\n"]}, {"number": 45197, "title": "model doesn't learn when using shuffle='batch'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): pip install tf-nightly-gpu==2.5.0.dev20201108\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version:3.8\r\n- GCC/Compiler version (if compiling from source):9.3.0\r\n- CUDA/cuDNN version:11.1.1/8.0.5\r\n- GPU model and memory:RTX 3090 (24GMiB) driver 455.38\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nBecasue I train my model with data from HDF5 files, so I used model.fit(, , , shuffle='batch'). \r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Sequential: \r\n\"shuffle | Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). This argument is ignored when x is a generator. 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None.\"\r\n\r\nBefore I upgrade my hardware, I used tensorflow 1.x as Keras 2.x's backend. My model used shuffle='batch' without any problems. Now, I have a new machine, so I need to transfer my codes. However, the new code doesn't work anymore. \r\n\r\n**Describe the expected behavior**\r\nI used MNIST dataset to show what happended: Code from (https://www.machinecurve.com/index.php/2020/04/13/how-to-use-h5py-and-keras-to-train-with-data-from-hdf5-files/)\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport h5py\r\nfrom tensorflow.keras.datasets import cifar10\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\r\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\n# Model configuration\r\nbatch_size = 50\r\nimg_width, img_height, img_num_channels = 28, 28, 1\r\nloss_function = sparse_categorical_crossentropy\r\nno_classes = 10\r\nno_epochs = 25\r\noptimizer = Adam()\r\nvalidation_split = 0.2\r\nverbosity = 1\r\n\r\n# Load MNIST data\r\nf = h5py.File('train.hdf5', 'r')\r\ninput_train = f['image'][...]\r\nlabel_train = f['label'][...]\r\nf.close()\r\nf = h5py.File('test.hdf5', 'r')\r\ninput_test = f['image'][...]\r\nlabel_test = f['label'][...]\r\nf.close()\r\n\r\n# Reshape data\r\ninput_train = input_train.reshape((len(input_train), img_width, img_height, img_num_channels))\r\ninput_test  = input_test.reshape((len(input_test), img_width, img_height, img_num_channels))\r\n\r\n# Determine shape of the data\r\ninput_shape = (img_width, img_height, img_num_channels)\r\n\r\n# Create the model\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\r\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\r\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(128, activation='relu'))\r\nmodel.add(Dense(no_classes, activation='softmax'))\r\n\r\n# Display a model summary\r\nmodel.summary()\r\n\r\n# Compile the model\r\nmodel.compile(loss=loss_function,\r\n              optimizer=optimizer,\r\n              metrics=['accuracy'])\r\n\r\n# Fit data to model\r\nhistory = model.fit(input_train, label_train,\r\n            batch_size=batch_size,\r\n            epochs=no_epochs,\r\n            verbose=verbosity,shuffle='batch',\r\n            validation_split=validation_split)\r\n\r\n# Generate generalization metrics\r\nscore = model.evaluate(input_test, label_test, verbose=0)\r\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nThe output is like this \r\nModel: \"sequential_3\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \r\n_________________________________________________________________\r\nconv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \r\n_________________________________________________________________\r\nconv2d_11 (Conv2D)           (None, 22, 22, 128)       73856     \r\n_________________________________________________________________\r\nflatten_3 (Flatten)          (None, 61952)             0         \r\n_________________________________________________________________\r\ndense_6 (Dense)              (None, 128)               7929984   \r\n_________________________________________________________________\r\ndense_7 (Dense)              (None, 10)                1290      \r\n=================================================================\r\nTotal params: 8,023,946\r\nTrainable params: 8,023,946\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 6.4279 - accuracy: 0.1099 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 2/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1141 - val_loss: 2.3012 - val_accuracy: 0.1060\r\nEpoch 3/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 4/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 5/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060\r\nEpoch 6/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1162 - val_loss: 2.3019 - val_accuracy: 0.1060\r\nEpoch 7/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 8/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3025 - val_accuracy: 0.1060\r\nEpoch 9/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 10/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 11/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1127 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 12/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3024 - val_accuracy: 0.1060\r\nEpoch 13/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1131 - val_loss: 2.3025 - val_accuracy: 0.1060\r\nEpoch 14/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060\r\nEpoch 15/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\r\nEpoch 16/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 17/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 18/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 19/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1147 - val_loss: 2.3019 - val_accuracy: 0.1060\r\nEpoch 20/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\r\nEpoch 21/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 22/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1122 - val_loss: 2.3024 - val_accuracy: 0.1060\r\nEpoch 23/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3003 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 24/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 25/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1131 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nTest loss: 2.3010358810424805 / Test accuracy: 0.11349999904632568\r\n\r\n\r\nIf I changed shuffle='batch' to shuffle=True or shuffle=False\r\nI got convergent results like this\r\n\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 22, 22, 128)       73856     \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 61952)             0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 128)               7929984   \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 10)                1290      \r\n=================================================================\r\nTotal params: 8,023,946\r\nTrainable params: 8,023,946\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/25\r\n960/960 [==============================] - 5s 3ms/step - loss: 2.3020 - accuracy: 0.9032 - val_loss: 0.0738 - val_accuracy: 0.9786\r\nEpoch 2/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0502 - accuracy: 0.9853 - val_loss: 0.0621 - val_accuracy: 0.9824\r\nEpoch 3/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0811 - val_accuracy: 0.9792\r\nEpoch 4/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0851 - val_accuracy: 0.9805\r\nEpoch 5/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0757 - val_accuracy: 0.9832\r\nEpoch 6/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1344 - val_accuracy: 0.9752\r\nEpoch 7/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.1379 - val_accuracy: 0.9779\r\nEpoch 8/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0919 - val_accuracy: 0.9818\r\nEpoch 9/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.1184 - val_accuracy: 0.9811\r\nEpoch 10/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.1157 - val_accuracy: 0.9832\r\nEpoch 11/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.1221 - val_accuracy: 0.9803\r\nEpoch 12/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1170 - val_accuracy: 0.9822\r\nEpoch 13/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1216 - val_accuracy: 0.9846\r\nEpoch 14/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.1048 - val_accuracy: 0.9848\r\nEpoch 15/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1130 - val_accuracy: 0.9835\r\nEpoch 16/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1463 - val_accuracy: 0.9835\r\nEpoch 17/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1685 - val_accuracy: 0.9833\r\nEpoch 18/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.1224 - val_accuracy: 0.9840\r\nEpoch 19/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1733 - val_accuracy: 0.9838\r\nEpoch 20/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.1539 - val_accuracy: 0.9859\r\nEpoch 21/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1791 - val_accuracy: 0.9826\r\nEpoch 22/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.2264 - val_accuracy: 0.9830\r\nEpoch 23/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.1722 - val_accuracy: 0.9840\r\nEpoch 24/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.1472 - val_accuracy: 0.9851\r\nEpoch 25/25\r\n960/960 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2005 - val_accuracy: 0.9847\r\nTest loss: 0.18761441111564636 / Test accuracy: 0.9829999804496765\r\n```", "comments": ["@xuzhang5788 \r\nI ran the code shared and face a different error, please refer to [this gist](https://colab.research.google.com/gist/Saduf2019/5c932f4aeccde525d60a87eb3959def0/untitled471.ipynb).\r\nPlease share a colab gist with the error reported.", "I rerun the code, colab's link is here:\r\nhttps://colab.research.google.com/gist/xuzhang5788/269ada412449fe2007ae0460aa329f47/untitled471.ipynb", "https://colab.research.google.com/gist/Saduf2019/5c932f4aeccde525d60a87eb3959def0/untitled471.ipynb", "The input data is from Kaggle (https://www.kaggle.com/benedictwilkinsai/mnist-hd5f). \r\n\r\nBy the way, I don't know why training was so unbelievably slow. I chose GPU for runtime setting\r\n960/960 [==============================] - 340s 354ms/step - loss: 2.3013 - accuracy: 0.1134 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 20/25\r\n960/960 [==============================] - 355s 370ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 21/25\r\n960/960 [==============================] - 343s 357ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 22/25\r\n960/960 [==============================] - 328s 341ms/step - loss: 2.3011 - accuracy: 0.1141 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 23/25\r\n960/960 [==============================] - 331s 345ms/step - loss: 2.3008 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 24/25\r\n960/960 [==============================] - 376s 392ms/step - loss: 2.3005 - accuracy: 0.1170 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 25/25\r\n960/960 [==============================] - 384s 400ms/step - loss: 2.3006 - accuracy: 0.1168 - val_loss: 2.3020 - val_accuracy: 0.1060\r\n\r\n", "I rerun my code with tensorflow 2.3.0, but I got the same results. please see the link:\r\nhttps://colab.research.google.com/gist/xuzhang5788/c5ce687ff4b7e26d9b26b7f67c30439c/untitled471.ipynb\r\n\r\nHowever, the training process is far faster than tensorflow 2.5.0\r\n960/960 [==============================] - 8s 9ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 20/25\r\n960/960 [==============================] - 8s 8ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 21/25\r\n960/960 [==============================] - 8s 8ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 22/25\r\n960/960 [==============================] - 8s 8ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 23/25\r\n960/960 [==============================] - 8s 8ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\r\nEpoch 24/25\r\n960/960 [==============================] - 8s 8ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\r\nEpoch 25/25\r\n960/960 [==============================] - 8s 9ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060", "@xuzhang5788 \r\nI am unable to access the \"train.hdf5\" file, please refer to this [gist here](https://colab.research.google.com/gist/Saduf2019/86ec75f95ef12e8ffcd199a438162d6c/untitled472.ipynb).", "@Saduf2019 \r\nI am sorry that I don't know how to let you access train.hdf5 file. Could you please download the files from kaggle? Link is here.\r\nThe input data is from Kaggle (https://www.kaggle.com/benedictwilkinsai/mnist-hd5f).", "I tried different versions of tensorflow. \r\nworks version: 1.15.0, 2.0.0\r\ndoes not work version: 2.1.0, 2.2.0, 2.3.0, 2.5.0\r\nSo the bugs appeared after version 2.0.0. please fix it!!\r\n", "I tried your example with `shuffle='batch', False, True` options and found that model is not converging for either of them. See the [gist](https://colab.research.google.com/gist/ymodak/60734b0a444a9f19b038e76d50be5906/untitled471.ipynb)\r\nI noticed that `shuffle` arg takes any string other than 'batch' right now which is confusing.\r\nI will dig deeper and refactor it.\r\n", "@ymodak \r\nI think there are critical bugs when keras became tensorflow 2's API. Because many people's datasets are too large to fit into memory, so they chose to use hdf5 files. I don't know when it can be fixed. It is been here for almost one month, but I didn't get any response for this.  ", "Lower the learning rate?", "@tensorflowbutler @ymodak @Saduf2019 \r\nThe problems are still there. When will they be solved?  ", "This issue still exists in Tensorflow [2.7](https://colab.research.google.com/gist/sachinprasadhs/2f321a7e1cbf83b54e84b9a0a228f8a3/untitled471.ipynb), could you please open this issue in keras-team/keras repo.\r\n\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing the issue here since it is moved to keras-team/keras repo, you can track the issue in the above link.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45197\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45197\">No</a>\n"]}, {"number": 45196, "title": "Didn't find op for builtin opcode 'GATHER' version '1'", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu Linux 20.04\r\n- TensorFlow installed from (source or binary): binary python3 pip3\r\n- Tensorflow version (commit SHA if source): 2.4-rc3\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): arm mbed-os disco_f746ng \r\n\r\n**Describe the problem**\r\n```\r\n  TfLiteStatus allocate_status = interpreter->AllocateTensors();\r\n```\r\nfails with\r\n```\r\nDidn't find op for builtin opcode 'GATHER' version '1'                                                \r\nFailed to get registration from op code GATHER                                               \r\nFailed starting model allocation.\r\nAllocateTensors() failed\r\n```\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nAll attachments can be found at: [https://github.com/crumpf-sdsu/gath-op-bug-report](https://github.com/crumpf-sdsu/gath-op-bug-report)\r\nBasically, I used https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb to create a split window single step (+1hr predictive) linear model using the NOAA dataset (a weather data localized to my zip code).  The model performs adequately for my needs in Jupyter.  The model is successfully converted to tflite (no quant).   Standard tflite micro interpreter setup() (from hello world) fails to AllocateTensors with  missing GATHER op using AllOpsResolver.  \r\n\r\n```\r\nvoid setup() {\r\n...\r\n  // This pulls in all the operation implementations we need.\r\n  // NOLINTNEXTLINE(runtime-global-variables)\r\n  static tflite::AllOpsResolver resolver;\r\n\r\n  // Build an interpreter to run the model with.\r\n  static tflite::MicroInterpreter static_interpreter(\r\n      model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\r\n  interpreter = &static_interpreter;\r\n\r\n  // Allocate memory from the tensor_arena for the model's tensors.\r\n  TfLiteStatus allocate_status = interpreter->AllocateTensors();\r\n  if (allocate_status != kTfLiteOk) {\r\n    TF_LITE_REPORT_ERROR(error_reporter, \"AllocateTensors() failed\");\r\n    return;\r\n  }\r\n```\r\nAside from AllOpsResolver documentation/customizations, I didn't find much information about missing ops such as this and figured I'd ask to triple check my approach and get some advice here.", "comments": ["I will start porting the GATHER operator from TFLite to TFLite Micro now.", "The merging of PR #49495 should solve the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45196\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45196\">No</a>\n"]}, {"number": 45195, "title": "//tensorflow/lite/python:lite_v2_test failed", "body": "\r\nWith current master branch (commit 38d042b105bf06c89cfc2a5c0412983215b4faf3), TEST //tensorflow/lite/python:lite_v2_test failed.\r\n\r\n> bazelisk test //tensorflow/lite/python:lite_v2_test\r\n\r\n> ERROR: /mirror-tensorflow/tensorflow/lite/python/BUILD:205:1: in deps attribute of py_test rule //tensorflow/lite/python:lite_v2_test: '//tenso\r\nrflow/lite/kernels/hashtable:hashtable_op_kernels' does not have mandatory providers: 'py' or 'PyInfo'\r\nERROR: Analysis of target '//tensorflow/lite/python:lite_v2_test' failed; build aborted: Analysis of target '//tensorflow/lite/python:lite_v2_test' failed\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45195\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45195\">No</a>\n"]}, {"number": 45194, "title": "tf.data.experimental.make_csv_dataset changes list of column names if it is not hard coded", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS release 6.10\r\n- TensorFlow version (use command below): Version: 2.2.0\r\n- Python version: Python 3.8.3 (default, Jul  2 2020, 16:21:59)\r\n- GPU model and memory: NVIDIA, 64 GB RAM\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to use tf.data.experimental.make_csv_dataset to read data from a very large csv file (million rows and million columns). If I hard code select_columns in the following sample code with select_columns=['col1','col2','col3']) then tf.data.experimental.make_csv_dataset works fine. But, when I extract column names and put them in a python list, My_Variables in the following line of code, then tf.data.experimental.make_csv_dataset changes My_Variables python list and it can not find label_name anymore:\r\n\r\n    def get_dataset(file_path):\r\n      dataset = tf.data.experimental.make_csv_dataset(\r\n          file_path,\r\n          batch_size=64, # Artificially small to make examples easier to show.\r\n          select_columns=My_Variables,\r\n          label_name= 'outcome',\r\n          na_value=\"?\",\r\n          num_epochs=1,\r\n          num_rows_for_inference=64,\r\n         ignore_errors=True)\r\n      return dataset\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behavior after running tf.data.experimental.make_csv_dataset: \r\n\r\n    My_Variables=['col1','col2','col3',...,'outcome']\r\n\r\ncurrent behavior after running tf.data.experimental.make_csv_dataset: \r\n\r\n    My_Variables=[1,2,3,4,5,6,7,...,10345]\r\n\r\nError message:\r\n\r\n    raise ValueError(\"`label_name` provided must be one of the columns.\")\r\n    ValueError: `label_name` provided must be one of the columns.\r\n\r\n\r\nI can not hard code variables in tf.data.experimental.make_csv_dataset function. I need to extract column names, put them in a python list and then used it inside tf.data.experimental.make_csv_dataset but this method breaks tf.data.experimental.make_csv_dataset", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45194\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45194\">No</a>\n", "@hosseinece \r\nPlease share complete code to replicate the issue faced or if possible share a colab gist with the issue reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The fact that variables changes after the call to make_csv_dataset seems indeed like an unwanted border effect. For the border effect, I used a simple workaround by copying the variable before making the call to make_csv_dataset and it solved my issue. ", "@hosseinece \r\nPlease move this issue to closed status if resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45194\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45194\">No</a>\n"]}, {"number": 45193, "title": "Add uint8_t -> int8_t requant method", "body": "This is required when input to the model is in uint8_t format.\r\nWe need this quant op as a first layer.\r\nOne of such example is image data.\r\n\r\nRelated MR: https://github.com/tensorflow/tensorflow/pull/44580\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain PTAL\r\n", "Ran into this issue today..\r\n\r\nIt looks like converting to .tflite networks that support uint8 input, as seen in the person-detector example, is not possible anymore. In other words, with the current TFLite converter, it is impossible to create a network that the ESP32 can natively use with its uint8 camera frames. I think the only other option, besides this PR, is to convert the camera frames before sending to network.", "Hi @EliZucker right. UInt8 input case needs to be enabled.\r\n\r\nThe code/checks around these lines(`Prepare` from `quantize.cc`) will look like this:\r\n```\r\n  if (input->type == kTfLiteFloat32) {\r\n    // Quantize use case.\r\n    TF_LITE_ENSURE(context, output->type == kTfLiteInt8 ||\r\n                                output->type == kTfLiteInt16);\r\n  } else {\r\n    // Requantize use case.\r\n    // We allow Int16, UInt8 and Int8 inputs.\r\n    TF_LITE_ENSURE(context, input->type == kTfLiteInt16 ||\r\n                                input->type == kTfLiteUInt8 ||\r\n                                input->type == kTfLiteInt8);\r\n\r\n    // Output is restricted to Int8.\r\n    TF_LITE_ENSURE(context, output->type == kTfLiteInt8);\r\n\r\n    double effective_scale = static_cast<double>(input->params.scale) /\r\n                             static_cast<double>(output->params.scale);\r\n\r\n    QuantizeMultiplier(effective_scale, &data->output_multiplier,\r\n                       &data->output_shift);\r\n  }\r\n\r\n```\r\n\r\nSome of the checks are inspired from classic tflite's quantize.cc above.\r\nKept Float32 in above change. Shall I remove Float32 support completely?\r\n\r\nAlso, this line from my code:\r\n```\r\n    // Output is restricted to Int8.\r\n    TF_LITE_ENSURE(context, output->type == kTfLiteInt8);\r\n```\r\n\r\nrestricts output to `Int8`. Since we want to deprecate all other OPS to just keep Int8 OPS.\r\n\r\ncc @advaitjain ", "Adding to the discussion between @EliZucker and @vikramdattu:\r\n\r\nThese lines should also be updated (I would hope that a unit test would catch this case):\r\nhttps://github.com/tensorflow/tensorflow/blob/107b96da1ca5f0db752a11c4fae85ef1272ee175/tensorflow/lite/micro/kernels/quantize.cc#L73-L76\r\n\r\nAdditionally, since the TF_LITE_ENSURE checks that @EliZucker pointed out in the Prepare function are basically a repeat of the checks in Eval, I would be fine with removing this code block completely:\r\nhttps://github.com/tensorflow/tensorflow/blob/107b96da1ca5f0db752a11c4fae85ef1272ee175/tensorflow/lite/micro/kernels/quantize.cc#L65-L71\r\n", "Just want to say that I recommend at least trying a manual E2E before merging. I ran these changes myself and behavior did not match a Tf lite interpreter on my computer. \r\n\r\nI didn't have time to debug so just manually converted the esp32 camera values to int8 range and it worked fine with a model not requiring uint8 quantization. Can post more details if you're curious; it could also be an error from my side as I'm new to this project.", "@advaitjain \r\n\r\nI get error when I run test for x86 (OS: MacOS Catalina 10.15.07)\r\n\r\n```\r\ntensorflow/lite/micro/tools/ci_build/test_x86.sh\r\n```\r\n\r\n```\r\n.\r\n.\r\n.\r\n.\r\ntensorflow/lite/micro/examples/person_detection/person_detection_test.cc:30:24: error: argument to 'section' attribute is not valid for this target: mach-o section specifier requires a segment and section separated by a comma\r\n__attribute__((section(\".bss.NoInit\"), aligned(16)))\r\n                       ^\r\n1 error generated.\r\nmake: *** [tensorflow/lite/micro/tools/make/Makefile:488: tensorflow/lite/micro/tools/make/gen/osx_x86_64/obj/tensorflow/lite/micro/examples/person_detection/person_detection_test.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n```\r\n\r\nCan you please help get pass the issue?\r\n", "@vikramdattu I fixed some errors by using ESP-IDF Toolchain v4.0 for that example project. Might be the issue.\r\n\r\nEdit: Also, that example project contains a model that I think was created with a deprecated TFLite converter. So there is no uint8_t quantization that the model requires, it just natively uses uint8_t throughout.", "@EliZucker thanks for quick reply.\r\n\r\nI got past this error by simply commenting out that attribute.\r\n\r\nI now get one test fail even without UInt8 quant addition.\r\n\r\n```\r\ntensorflow/lite/micro/tools/make/gen/osx_x86_64/bin/person_detection_test_int8: FAIL - '~~~ALL TESTS PASSED~~~' not found in logs.\r\nTesting TestInvoke\r\nperson data.  person score: -4, no person score: 4\r\n\r\nperson_score > no_person_score failed at tensorflow/lite/micro/examples/person_detection_experimental/person_detection_test.cc:103\r\nno person data.  person score: -72, no person score: 72\r\n```", "@advaitjain @EliZucker \r\nOne more question:\r\n\r\nI have added few more tests: `QuantizeOpTestUInt8toInt8` and `QuantizeOpTestUInt8toInt8NoZeroPoint`.\r\nHow do I know if these are getting called? Is running x86 tests does this already?\r\n", "@advaitjain @EliZucker manually tested this with a custom example I have created here: https://github.com/vikramdattu/tensorflow/commits/master \r\n\r\nPlease refer [this](https://github.com/vikramdattu/tensorflow/blob/master/tensorflow/lite/micro/examples/cats_and_dogs/esp/README_ESP.md#generate-the-examples) README to build and run example on ESP32. [Please do ignore some of the unclean code] ", "@vikramdattu Can you please resolve conflicts? Thanks!", "> @vikramdattu Can you please resolve conflicts? Thanks!\r\n\r\n@gbaned done! Please take a look again.", "@advaitjain please take a look. Tests are added.\r\n\r\nPlease take a look at choice of values:\r\n```\r\nconst float values[] = {64, 66, 68, 70, 72, 182, 184, 186, 188, 190};\r\n```\r\n\r\nThese are values used for int8 test+128\r\n```\r\nconst float values[] = {-64, -62, -60, -58, -56, 54, 56, 58, 60, 62};\r\n```", "@vikramdattu Can you please resolve conflicts? Thanks!", "@gbaned conflicts are resolved. PTAL.", "@vikramdattu Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@vikramdattu  Any update on this PR? Please. Thanks!", "Hi @gbaned the PR raised is 4-5 months old and I have done multiple merges to update it.\r\n\r\nDo you mind if I reconsider it for new PR OR force push?\r\n", "@advaitjain Can you please assist on above comments from @vikramdattu. Thanks!", "@advaitjain Any update on this PR? Please. Thanks!", "With TFLM moving to its own GitHub repository, we are not going to be merging any TFLM specific pull requests in the TensorFlow repository starting today.\r\n\r\nI am closing the current PR but please feel free to open a new PR in https://github.com/tensorflow/tflite-micro/.\r\n\r\nhttps://groups.google.com/a/tensorflow.org/g/micro/c/W4DACgjPmOE\r\n"]}, {"number": 45192, "title": "Migrating from TF1 to TF2, loss not going down using F-RCNN Resnet50", "body": "So I've been trying to migrate from Tensorflow Version 1.14 to 2.3.0. My work usually involves performing transfer learning on Faster R-CNN Resnet 50 Coco Trained Models for object detection. When I used to train on Tensorflow 1.14 using the adam optimizer, I would see the loss go down after 30k steps of training. However, on TF2, the loss seems to be more of a straight line. \r\n\r\n\r\nIt would help me greatly if someone could help me figure out why the loss is not going down. Thanks in advance. :)\r\n\r\nTF2 Tensorboard Total Loss on [faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\r\n![image](https://user-images.githubusercontent.com/32026314/100305789-6e000780-2fd4-11eb-8c23-2599a735b480.png)\r\n\r\n\r\n\r\nTF1 Tensorboard Total Loss on [faster_rcnn_resnet50_coco_2018_01_28](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)\r\n![Screenshot from 2020-11-23 10-49-57](https://user-images.githubusercontent.com/32026314/100306629-6c374380-2fd6-11eb-9279-a75a8f01c5b5.png)\r\n\r\n\r\n\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\r\n- TensorFlow installed from (source or binary): PIP3\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 980 Ti, 6GB\r\n\r\n", "comments": ["My Pipleline Config\r\n\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    num_classes: 1\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 100\r\n        width: 100\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'faster_rcnn_resnet50_keras'\r\n      batch_norm_trainable: true\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 14\r\n    maxpool_kernel_size: 2\r\n    maxpool_stride: 2\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n        share_box_across_classes: true\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 300\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n    use_static_shapes: true\r\n    use_matmul_crop_and_resize: true\r\n    clip_anchors_to_image: true\r\n    use_static_balanced_label_sampler: true\r\n    use_matmul_gather_in_matcher: true\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 1\r\n  sync_replicas: true\r\n  startup_delay_steps: 0\r\n  replicas_to_aggregate: 8\r\n  num_steps: 150000\r\n  optimizer {\r\n   adam_optimizer {\r\n      learning_rate {\r\n        manual_step_learning_rate {\r\n          initial_learning_rate: 0.0002\r\n          schedule {\r\n            step: 50000\r\n            learning_rate: 0.0002\r\n          }\r\n          schedule {\r\n            step: 100000\r\n            learning_rate: 0.0002\r\n          }\r\n        }\r\n      }\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  fine_tune_checkpoint_version: V2\r\n  fine_tune_checkpoint: \"\"\r\n  fine_tune_checkpoint_type: \"detection\"\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n\r\n  data_augmentation_options {\r\n    random_adjust_hue {\r\n    }\r\n  }\r\n\r\n  data_augmentation_options {\r\n    random_adjust_contrast {\r\n    }\r\n  }\r\n\r\n  data_augmentation_options {\r\n    random_adjust_saturation {\r\n    }\r\n  }\r\n\r\n\r\n  max_number_of_boxes: 100\r\n  unpad_groundtruth_tensors: false\r\n  use_bfloat16: true  # works only on TPUs\r\n}\r\ntrain_input_reader {\r\n  label_map_path: \"\"\r\n  tf_record_input_reader {\r\n    input_path: \"\"\r\n  }\r\n}\r\neval_config {\r\n  metrics_set: \"coco_detection_metrics\"\r\n  use_moving_averages: false\r\n  batch_size: 1\r\n}\r\neval_input_reader {\r\n  label_map_path: \"\"\r\n  shuffle: false\r\n  num_epochs: 1\r\n  tf_record_input_reader {\r\n    input_path: \"\"\r\n  }\r\n}\r\n", "@Mustavi \r\n\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here.](https://github.com/tensorflow/models/issues/new/choose) Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45191, "title": "TFLite Interpreter crashes with null TfLiteDelegatePtr", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): r2.3 but consistent with latter versions\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tflite::Interpreter` does not check nullity of `TfLiteDelegate*`.\r\nIt would be better to check it and return ErrorCode for `null`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/core/subgraph.cc#L1486-L1513\r\n\r\n**Will this change the current api? How?**\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/core/subgraph.cc#L1486\r\n\r\nor\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/interpreter.cc#L385\r\n\r\nor (for r2.3 I am using)\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/interpreter.cc#L358\r\n\r\nreturns `TfLiteError` for `null` input.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nApp developers who are using TensorflowLite SDK would find bugs more quickly.\r\nThanks!\r\n\r\n**Any Other info.**\r\n", "comments": ["Hmm. This should be the behavior, yes. However, I may not get to this very soon, since such behavior will probably only occur if the user is using a non-recommended way of initializing delegates.\r\n\r\nOut of curiosity, how did you encounter a seg-fault because of an invalid `TfLiteDelegate*`? Our language bindings usually initialize delegates in a safe way. For C++, the recommended ways of initializing delegates should avoid this using Create/DeleteDelegate methods (found in individual delegate documentation) OR using `std::unique_ptr` like [here](https://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/tools/evaluation/utils.h#L79).\r\n\r\nFeel free to send a PR :-).", "Thanks for your reply \ud83d\udc4d \r\nI agree with you about the impact of this change. I'll send a small PR.\r\n\r\nAnswer: I found the issue when dealing with cross-platform code similar to below pseudo code.\r\nIt was hard to find because it works correctly for most of the cases!\r\n(I wrote macros just for giving intuitions here)\r\n\r\n```cpp\r\n...\r\nusing TfLiteDelegatePtr = std::unique_ptr<TfLiteDelegate, void (*)(TfLiteDelegate*)>;\r\n\r\nTfLiteDelegatePtr AcquireDelegate() {\r\n#if defined(OUTPUT_LINKED_WITH_OPENCL_OR_OPENGL)\r\n  ...\r\n  TfLiteDelegatePtr delegate(TfLiteGpuDelegateV2Create(&opts), TfLiteGpuDelegateV2Delete);\r\n#elif defined(OUTPUT_LINKED_WITH_METAL)\r\n  ...\r\n  TfLiteDelegatePtr delegate(TFLGpuDelegateCreate(&opts), TFLGpuDelegateDelete);\r\n#elif defined(OUTPUT_LINKED_WITH_XNNPACK)\r\n  ...\r\n  TfLiteDelegatePtr delegate(TfLiteXNNPackDelegateCreate(&opts), TfLiteXNNPackDelegateDelete);\r\n#else  // OUTPUT_CANNOT_BE_LINKED_WITH_ANY_DELEGATES_BECAUSE_THE_TARGET_PLATFORM_SUPPORTS_NOTHING\r\n  /* Cannot use any delegate-related symbols that may require other dependencies. */\r\n  /* Of course to use `DummyDelegate` with default option may be more elegant way to do this. */\r\n  TfLiteDelegatePtr delegate(nullptr, [](TfLiteDelegate*) {});\r\n#endif\r\n  return delegate;\r\n}\r\n```", "I think this is solved at d22d31b"]}, {"number": 45190, "title": "Disable _FusedConv2D generation in grappler if XLA is on (GPU only).", "body": "XLA does not recognize the _FusedConv2D node, resulting in multiple\r\nclusters during auto clustering. Furthermore, XLA performs this\r\nparticular optimization as part of the fused convolution rewriter", "comments": ["@bas-aarts  Can you please resolve conflicts? Thanks!", "@bas-aarts  Can you please check @cheshire's comments and keep us posted ? Thanks!\r\n", "@bas-aarts  Any update on this PR? Please. Thanks!", "It has been 24 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@cheshire, per @sanjoy this will not work for auto-clustering.", "Just noticed this change has not yet been merged. Any reason for this?", "> Just noticed this change has not yet been merged. Any reason for this?\r\n\r\nFailing a lint check internally (struct field name cannot end with underscore), will shepherd this manually."]}, {"number": 45189, "title": "Always build libtensorflow in a manylinux2010 compatible way", "body": "Previously, only the CUDA builds of `libtensorflow` for TF 2.x would be built in a manylinux2010 sysroot.\r\n\r\nThis PR builds the CPU version in a manylinux2010 sysroot as well.\r\n\r\nCloses #45092", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45189) for more info**.\n\n<!-- need_sender_cla -->", "@VivekPanyam  Can you please sign CLA. Thanks!", "@gbaned Fixed!\r\n\r\n(cc @mihaimaruseac who offered to review this PR as well)\r\n\r\nAlso, any chance we can get this in as part of the 2.4 release? I know it's a little late since we're already on 2.4.0-rc3, but it would be great if we could use the official 2.4 binaries in `manylinux2010` environments instead of having to build TF from source.\r\n\r\nThanks!"]}, {"number": 45188, "title": "443", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": []}, {"number": 45187, "title": "EarlyStopping with baseline doesn't set weights", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Manjaro latest\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.8.6\r\n\r\n**Describe the current behavior**\r\n\r\nWhen passing an `EarlyStopping` callback to `model.fit()` with `baseline` parameter set and `restore_best_weights=True`, if the monitored quantity doesn't reach the baseline, best weights are never set and an exception is thrown when trying to restore them.\r\n\r\n**Describe the expected behavior**\r\n\r\nSomething a bit more sensible like not trying to restore best weights if those are `None`, or throwing an exception that explicitly indicates the problem.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nfrom tensorflow.keras.optimizers import SGD\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import Dense, Softmax\r\n\r\nfrom tensorflow.keras.callbacks import EarlyStopping\r\n\r\nx_train = np.array([[0, 0],\r\n                    [0, 1],\r\n                    [1, 0],\r\n                    [1, 1]])\r\ny_train = np.array([0, 1, 1, 0])\r\n\r\nx_val = np.array([[0, 0], [0, 1]])\r\ny_val = np.array([1, 0])\r\n\r\nmodel = keras.Sequential([\r\n    Dense(20),\r\n    Dense(1),\r\n    Softmax()\r\n])\r\n\r\nmodel.compile(optimizer=SGD(), loss='mse')\r\nmodel.fit(x_train, y_train,\r\n          validation_data=(x_val, y_val),\r\n          epochs=5,\r\n          callbacks=[\r\n              EarlyStopping(monitor='val_loss',\r\n                            baseline=0.5,\r\n                            patience=3,\r\n                            restore_best_weights=True)\r\n          ])\r\n```\r\n\r\n**Other info / logs**\r\nTraceback:\r\n``` File \"early_stopping.py\", line 24, in <module>\r\n    model.fit(x_train, y_train,\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1137, in fit\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\", line 416, in on_epoch_end\r\n    callback.on_epoch_end(epoch, numpy_logs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\", line 1677, in on_epoch_end\r\n    self.model.set_weights(self.best_weights)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1805, in set_weights\r\n    if expected_num_weights != len(weights):\r\nTypeError: object of type 'NoneType' has no len()\r\n```", "comments": ["I have tried in colan with TF version 2.2, 2.3, nightly version(`2.5.0-dev20201125`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ab13806714eba31316a64845fac90669/untitled539.ipynb). Thanks!", "Thanks for the report, looks like a bug.", "@danipozo Looks like this was resolve in recent `tf-nightly`. I couldn't reproduce the error with `tf-nightly`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/4fca1ef51b17c570d8d34da0d5faae44/untitled539.ipynb).\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "I can see that this has been fixed, I guess in these [two](https://github.com/tensorflow/tensorflow/commit/c5f8604fedb0f82c6966a1d692b76eb5d7ce6d0e) [commits](https://github.com/tensorflow/tensorflow/commit/abcabe12666d064da4710d965c36a59c937eab12).\r\n\r\nHowever, I wonder if this a good design, since as far as I can tell, the `baseline` argument is ignored with respect to deciding which weights to return if `restore_best_weights=True` is passed. This way, weights that underperform the specified baseline  can be returned without warning.\r\n\r\nAlthough the docs don't specify that the returned weights should outperform the baseline, I see this as confusing and think a warning could help, specially given that past behavior tried to enforce this by not restoring weights when they didn't meet the baseline.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45187\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45187\">No</a>\n"]}, {"number": 45186, "title": "Optimizing a custom loss in TF1 vs TF2", "body": "I'm trying to migrate from TF1 to TF2 and encountering performance issues. The plan is to optimize a custom loss function (without neural networks), but it is much faster on TF1 compared to TF2. Am I doing something wrong?\r\n\r\nBelow I tried to include a minimum reproducible example. On Colab TF1 takes 0.061 seconds, while TF2 takes 0.277 seconds.\r\n\r\n[TF1 colab notebook](https://colab.research.google.com/drive/1H0bPxIrSvD9V0IHppNpeQRwzHP4qbal9?usp=sharing)\r\n\r\n[TF2 colab notebook](https://colab.research.google.com/drive/1tZ9aHXc9EA6otTyRIVBFhK8ez3yjXaA2?usp=sharing)\r\n\r\n\r\n(Adding the actual code for future reference)\r\n\r\n```\r\n#TF1 version\r\n%tensorflow_version 1.x\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\n\r\nimport time\r\n\r\nvocabulary_size = int(1e3) #must be bigger than 8\r\n\r\n\r\ndef calculateloss(in1, in2):\r\n  vectors1 = tf.nn.embedding_lookup(embeddings, in1)\r\n  vectors2 = tf.nn.embedding_lookup(embeddings, in2)\r\n  #\r\n  rep1 = tf.reduce_mean(vectors1, axis=0)\r\n  rep2 = tf.reduce_mean(vectors2, axis=0)\r\n  #\r\n  return tf.norm(rep1-rep2)\r\n  \r\n \r\ngraph = tf.Graph()\r\n\r\nwith graph.as_default():\r\n  with tf.name_scope('MainVariable') as scope:\r\n    embeddings = tf.Variable(   \r\n    tf.random_uniform([vocabulary_size, 100], -1, 1),\r\n    dtype=tf.float32)\r\n  #\r\n  with tf.name_scope('CalculateLoss') as scope:\r\n    inputdata1 = [1,2,3,4]\r\n    inputdata2 = [5,6,7,8]\r\n    #\r\n    loss = calculateloss(inputdata1, inputdata2)\r\n    optimizer = tf.train.AdagradOptimizer(1).minimize(loss)\r\n\r\n\r\n#Training\r\n\r\n\r\nniter = 100\r\n\r\nwith tf.Session(graph=graph) as sess: #\r\n  sess.run(tf.global_variables_initializer())\r\n  start_time = time.time()\r\n  for i in range(niter):\r\n    _, new_loss  = sess.run([optimizer, loss])\r\n    #print(i, \"\\t\", new_loss)\r\n\r\n\r\nprint('Elapsed time: ' + str(time.time() - start_time))\r\n```\r\n\r\n```\r\n#TF2 version\r\n\r\nimport tensorflow as tf\r\nimport time\r\n\r\n\r\nvocabulary_size = int(1e3) #must be bigger than 8\r\nniter = 100\r\n\r\n\r\n@tf.function\r\ndef calculateloss(in1, in2):\r\n  vectors1 = tf.nn.embedding_lookup(embeddings, in1)\r\n  vectors2 = tf.nn.embedding_lookup(embeddings, in2)\r\n  #\r\n  rep1 = tf.reduce_mean(vectors1, axis=0)\r\n  rep2 = tf.reduce_mean(vectors2, axis=0)\r\n  #\r\n  return tf.norm(rep1-rep2)\r\n  \r\n  \r\nwith tf.name_scope('MainVariable') as scope:\r\n  embeddings = tf.Variable( \r\n    tf.random.uniform([vocabulary_size, 100], -1, 1),\r\n    dtype=tf.float32)\r\n\r\n\r\n\r\n@tf.function\r\ndef train_step(inputdata1, inputdata2, inputvars, optimizer):\r\n  with tf.GradientTape() as tape:\r\n    loss = calculateloss(inputdata1, inputdata2)\r\n  gradients = tape.gradient(loss, inputvars)\r\n  opt.apply_gradients(zip(gradients, inputvars))\r\n  return loss\r\n\r\n\r\ntrainable_variables = [embeddings]\r\nopt = tf.keras.optimizers.Adagrad(learning_rate=1)\r\n\r\n\r\n\r\n#Start Training run\r\nstart_time = time.time()\r\n\r\ninputdata1 = [1,2,3,4]\r\ninputdata2 = [5,6,7,8]\r\n\r\nfor i in range(niter):\r\n  loss = train_step(inputdata1, inputdata2, trainable_variables, opt)\r\n  #tf.print(i, \" loss:\", loss)\r\n\r\n\r\nprint('Elapsed time: ' + str(time.time() - start_time))\r\n```", "comments": ["Was able to reproduce the issue. Running the code with [TF v1.15](https://colab.research.google.com/gist/amahendrakar/5cc50d9204aee1439972b3a54af56707/45186-1-15.ipynb#scrollTo=q4UqYm-4qcWH) takes 0.12 seconds. \r\n\r\nWhereas, running with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/2563b517066b7b8acfa32944a1dc87e5/45186-2-x.ipynb#scrollTo=XPz3p-ubqldR) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/75014533bda0cb2ef1ab1d4dd807262b/45186-2-5.ipynb#scrollTo=XPz3p-ubqldR) takes 0.52 and 0.41 seconds respectively. Please find the attached gist. Thanks!", "@osotsia, \r\nThe Colab notebook you've linked contains the custom loss, back propagation and optimizer. Could you isolate the performance differences into one of them, for example only custom loss itself? Having an xprof of TF1 vs TF2 would also help analysis. Thanks.", "@amahendrakar\r\nPlease be more clear. Are you asking me to find out exactly where the TF2 performance hit is coming from (loss, backprop, or adagrad)? Any suggestions where to begin? I suppose it's easy to benchmark just the loss function (and it's unlikely to be the issue), but for the other two I'm not at all familiar with the TF code bases. I don't know what xpof is either, and [google](https://www.google.com/search?channel=fs&q=xpof+tensorflow) is not very helpful.", "@osotsia,\r\nIt looks like you have written equivalent code of `Tensorflow Version 1.x`, in `2.x`. Can you migrate your `1.x` code to `2.x` using [Upgrade Script](https://www.tensorflow.org/guide/upgrade) and [Migration Guide](https://www.tensorflow.org/guide/migrate) and see if the issue persists. Thanks!", "@rmothukuru\r\nHi, thanks for that. It works without the performance hit basically by adding a lot of tf.compat.v1's. If this is a long-term solution then I'm happy to close this issue.", "@osotsia,\r\nYes, following [Upgrade Script](https://www.tensorflow.org/guide/upgrade) and [Migration Guide](https://www.tensorflow.org/guide/migrate) is the recommended if we have to migrate the code from `TF Version` `1.x` to `2.x`.  Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45186\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45186\">No</a>\n"]}, {"number": 45185, "title": "ESP32 LyraT: Audio data/I2S issue", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): 2.x\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32 LyraT v4.3\r\n\r\nHello :) \r\n\r\nI try to get the micro_speech example running on the LyraT v4.3. The esp toolchain is set up and running. The model works (at least if I feed it the `g_yes_micro_f2e59fea_nohash_1_data`) and I was able to replace the model and use my own with different words and stuff. But I can't get it to work using a microphone.\r\n\r\nI printed the `GenerateMicroFeatures`-function results to the console. Most of the time, all frequencies are 0 (or -128). When I printed the absolute sum of the `g_audio_output_buffer` (printing the entire buffer would be too slow), this is also often times 0. \r\n\r\nThe only thing I really tried to change was the `pin_config` of the `audio_provider`:\r\n```\r\n  i2s_pin_config_t pin_config = {\r\n      // .bck_io_num = 26,    // IIS_SCLK\r\n      // .ws_io_num = 32,     // IIS_LCLK\r\n      // .data_out_num = -1,  // IIS_DSIN\r\n      // .data_in_num = 33,   // IIS_DOUT\r\n      .bck_io_num = GPIO_NUM_5,\r\n      .ws_io_num = GPIO_NUM_25,\r\n      .data_out_num = GPIO_NUM_26,\r\n      .data_in_num = GPIO_NUM_35,\r\n  };\r\n```\r\nThese should be the pins for the LyraT v4.3 but it resulted the warning \"No new slices\".\r\nI also tried to change the `I2S_NUM` from 1 to 0, which made no difference either.\r\n\r\nAny idea on what's going wrong or how to check the incoming audio data?\r\n\r\nI hope I provided some useful information. If there's anything else of interest, please let me know!\r\n\r\nThanks in advance :)", "comments": ["I do not understand what happened. I received an email which said there was an answer to my issue but I can't see it.\r\n\r\nHowever, it contains a link to a \"gist\" (I had never heard about that before). This gist contains an error that I had some time ago when training a model in colab. But restarting the training solved the issue for that moment", "@nixmeer what you are doing is on right direction.\r\n\r\nSelecting I2S port as 0 and changing pin config etc.\r\n\r\nAdditionally,\r\nLyraT boards come with es8388 codec, which you need to initialize first.\r\nPlease find reference [here](https://github.com/espressif/esp-va-sdk/tree/master/board_support_pkgs/lyrat/esp_codec/es8388/components/codec_es8388) for the same.\r\n\r\n/* Include all the files from \r\n[here](https://github.com/espressif/esp-va-sdk/tree/master/board_support_pkgs/lyrat/esp_codec/es8388/components/codec_es8388) and [this](https://github.com/espressif/esp-va-sdk/blob/master/components/audio_hal/include/media_hal.h), \r\n[this](https://github.com/espressif/esp-va-sdk/blob/master/components/audio_hal/include/esxxx_common.h) header as sources */\r\n\r\nIf you have added all the needed files in your project, here is how your initialization code should look like:\r\n```\r\nTfLiteStatus InitAudioRecording(tflite::ErrorReporter *error_reporter) {\r\n  g_audio_capture_buffer = rb_init(\"tf_ringbuffer\", kAudioCaptureBufferSize);\r\n  if (!g_audio_capture_buffer) {\r\n    ESP_LOGE(TAG, \"Error creating ring buffer\");\r\n    return kTfLiteError;\r\n  }\r\n\r\n  /* Initialize codec */\r\n\r\n#define MEDIA_HAL_DEFAULT()     \\\r\n    {   \\\r\n        .op_mode    = MEDIA_HAL_MODE_SLAVE,              \\\r\n        .adc_input  = MEDIA_HAL_ADC_INPUT_LINE1,         \\\r\n        .dac_output = MEDIA_HAL_DAC_OUTPUT_ALL,          \\\r\n        .codec_mode = MEDIA_HAL_CODEC_MODE_BOTH,         \\\r\n        .bit_length = MEDIA_HAL_BIT_LENGTH_16BITS,       \\\r\n        .format     = MEDIA_HAL_I2S_NORMAL,              \\\r\n        .port_num = 0,                          \\\r\n    };\r\n\r\n    static media_hal_config_t media_hal_conf = MEDIA_HAL_DEFAULT();\r\n    media_hal_init(&media_hal_conf);\r\n\r\n  /* create CaptureSamples Task which will get the i2s_data from mic and fill it\r\n   * in the ring buffer */\r\n  xTaskCreate(CaptureSamples, \"CaptureSamples\", 1024 * 32, NULL, 10, NULL);\r\n  while (!g_latest_audio_timestamp) {\r\n  }\r\n  ESP_LOGI(TAG, \"Audio Recording started\");\r\n  return kTfLiteOk;\r\n}\r\n\r\n```\r\npardon the code formatting.\r\n", "how do I include these `component.mk` makefiles to the `cmakelists`? ", "Hey @nixmeer\r\ntfmicro's build system is bit different and it needs sources added in Makefile.inc which is used to generate CMakeList.txt\r\n\r\nWhat you can do is simply add these files under esp [directory](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/esp) and make changes in [Makefile.in](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/esp/Makefile.inc) it contains.\r\n", "Hello,\r\n\r\nthanks for your help!\r\n\r\nso first I tried to somehow get the files included by somehow creating a `CMakeLists.txt` in the va-sdk but could get this to work. I do not understand why espressos uses different build systems themselves. I think I used a `make` command to create the esp-idf-project, but within this project I use the `idf.py build` command to build it. For my understanding, this uses CMake and is the reason I can't use the `component.mk`, right? Since there are `*.mk` files all over the idf, I guess they changed it at some point.\r\n\r\nThen I tried copying the files as @vikramdattu suggested and added them to the esp directory and added them to the `CMakeLists.txt` there. After adding some files that where not mentioned, I got it to build. \r\n\r\nHowever, the example does not work, or at least does not recognize my voice. The \"unknown\" tag is at a high value most of the time (140-240) no matter if there is silence or noise or spoken words. Previously I got the exact same results when trying to implement an audio provider myself using only stuff from the idf and the adf. \r\n\r\nI guess I'll have to build a little application that uses the audio provider to record a little snippet and then replay it. This is the only way for me to confirm that sound recording is working properly", "@nixmeer the build system are different because of the fact that Espressif now supports CMake build system which previous IDF releases didn't have.\n\nThe project I referred you is based on older IDF version and hence the confusion!\n\nHope you get your project working...", "Hello again,\r\nI got it to work finally. I created my own audio_provider.cc which uses the Audio Codec Chip on the LyraT. My audio_provider has been working for some days now, but I ran into another issue where the audio_provider had been blocked.\r\n\r\nIn the main function, `LatestAudioTimestamp()` is being called. At the first run, this returns 0. But the `feature_provider` requests `kFeatureSliceCount` from the `audio_provider` that and which are then fed to the neural network. However, `previous_time = current_time;` now set `previous_time` to 0, so in the next call, the `feature_provider` expects audio data from 0 to whatever values `current_time` is now, but since `kFeatureSliceCount` packages are already read, the `GetAudioSamples()` has to wait for the `Capture_Samples()` task to fill the expected data. This causes the network to be executed only every second or so. \r\n\r\nThere are 3 possible solutions I can think of:\r\n1st: my `audio_provider` learns to handle this behavior, for example by decreasing `g_latest_audio_timestamp` by `kFeatureSliceCount*kFeatureSliceStrideMs` ms when it's being initialized. This avoids the loop function to expect more audio samples than there actually are.\r\n2nd: `previous_time` is not being calculated by `current_time`, but by `+= how_many_new_slices*kFeatureSliceStrideMs`\r\n3rd: when initializing, the `feature_provider` just let's the slices_needed being 0 instead of `kFeatureSliceCount `, which results in cancelling the `loop()` functions first run and the 2nd loop call will be fine.\r\n\r\nSo, all in all, I'm a greenhorn and got a couple of questions since there are 2 issues now:\r\n- 1st: I doubt that the current version of the `audio_provider.cc` for ESP32 here on GitHub will work on any board since the ESP32 has an i2s bus initialized but no audio codec chip is being initialized to feed this i2s bus (which is in my case the audio codec chip es8388). I'd like to provide my code that initializes the ES8388 found on the LyraT but I don't know the correct way to do so. Whats the best way to include code for one specific board?\r\n- 2nd: Depending on the implementation of the other `audio_providers`, the behavior described above affects them all. Should I open a new issue for that since it does not belong this issue?\r\n\r\nAnd why am I the only one to stumble into these issues? Like the wrong number of `slices_needed` should literally affect any one running this example and the other one affects everyone using an ESP... \r\n\r\nI hope my findings can help others who run into these issues", "hi I'm new to this lyra board and presently I wish to use my tflite.cc file but not finding references can you please help. Or if anyone has any repository from which I can refer, I am having esp32 lyraT v4.3. Please tell if it is not possible, at present .", "How do I use esp-va-sdk in windows? Because whenever I try to build the project we are not having Cmakefile.txt so please help , if you can share any file or repository, \r\nWe are trying to build wake word model using ESP32 lyraT v4.3 , but still confused how to use tfmicro file.\r\nplease help..", "@petewarden @advaitjain @nixmeer can you help me with my project, i am trying to use tflite.cc model using esp32 lyraT v4.3 but not able to use it.\r\nWe are trying to build wake word model using ESP32 lyraT v4.3 , but still confused how to use tfmicro file.\r\nplease help.\r\nHow do I use esp-va-sdk in windows? Because whenever I try to build the project we are not having Cmakefile.txt so please help , if you can share any file or repository.", "@nixmeer \r\nCould you please try on latest stable version of tf 2.5 and let us know if this is still an issue.Thanks!", "@priyansh-shankhdhar we are working on newer release of `esp-va-sdk`, which will have support for newer IDF along with cmake build support.\r\n\r\nIt should be easier to integrate tflite-micro to use it as a WW module.\r\nBTW, tflite-micro has been moved to this repo: https://github.com/tensorflow/tflite-micro ", "I found a way to work around this issue. By now, my project is done and I am no longer working on it. But thanks for taking care!", "@nixmeer Thank you for the update!Could you please move this issue to closed status ?Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45185\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45185\">No</a>\n"]}, {"number": 45184, "title": "how to modify the input shape of existing model file again\uff1f", "body": "tensorflow version: 2.3.0\r\n\r\nWhen there is an existing model file, how to modify its input shape again?\r\nSometimes an existing pre-trained language model has a fixed input final dimension, but changing the final dimension has no effect.\r\nan example in this link\uff1a\r\nhttps://colab.research.google.com/drive/1BtOSLKYbElZ2EUEtLW3ahTZWeGN8QC3r?usp=sharing", "comments": ["@SmileTM \r\n\r\nPlease, have a look at similar [SO query](https://datascience.stackexchange.com/a/27391) and see if it helps you.Thanks!", "> @SmileTM\r\n> \r\n> Please, have a look at similar [SO query](https://datascience.stackexchange.com/a/27391) and see if it helps you.Thanks!\r\n\r\nI read the SO, there are probably two solutions in SO:\r\n1.  delete input_layer then add a new input_layer , but there is no input_layer in my model.\r\n2.  By rebuilding the model, and then importing the weights from the old model. This is feasible. \r\n     **But I don't have the model source code, only the saved model file, what should I do?**\r\n", "@SmileTM \r\nCould you please let us know if this is still an issue in latest stable TF v2.6.0 ?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45184\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45184\">No</a>\n"]}, {"number": 45183, "title": "Added useful C++ symbols missing from the tensorflow DLL on windows", "body": "On Windows, there is tool for selecting which symbols get exported to the tensorflow DLL.\r\nHowever, this filter does not include the symbols needed to use SessionOptions and SavedModel. It is also missing symbols for accessing shapes of a given node in the graph and creating a default instance of GraphDef.\r\n\r\nThis fix adds these symbols manually, thus not an elegant fix, and there are most likely several other symbols that should be included, but these are symbols which I find essential to: load a SavedModel, determine shapes and run inference with specific SessionOptions in C++.", "comments": []}, {"number": 45182, "title": "Serializing EagerTensors in model.save()", "body": "\r\n* This commit fixes problems when saving tf.keras.models coming from tensorflow 1.x\r\n* If there are any EagerTensors in the graph, they are converted to numpy objects that can be serialized\r\n* This fix has been tested and it works\r\n", "comments": ["@stratomaster31  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "@stratomaster31 Any update on this PR? Please. Thanks!", "It has been 24 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@stratomaster31 Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 45181, "title": "Possible problematic example in the guide \"Automatic Differentiation\"", "body": "## URL(s) with the issue: \r\n\r\nhttps://www.tensorflow.org/guide/autodiff\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn the calculation of gradient by passing a dictionary of variables, \r\n\r\n```python\r\nmy_vars = {\r\n    'w': tf.Variable(tf.random.normal((3, 2)), name='w'),\r\n    'b': tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\r\n}\r\n\r\ngrad = tape.gradient(loss, my_vars)\r\ngrad['b']\r\n```\r\n\r\nIt seems inappropriate since `my_vars` creates two new variables, but the pre-defined `loss` is not calculated from these two variables, and it turns out that no output from `grab['b']`. \r\n\r\nI think there might be two possible modifications,\r\n\r\n- use the pre-define `w` and `b` in the dictionary\r\n\r\n```python\r\nmy_vars = {\r\n    'w': w,\r\n    'b': b\r\n}\r\ngrad = tape.gradient(loss, my_vars)\r\ngrad['b']\r\n```\r\n\r\n- define a new loss using `my_vars`\r\n\r\n```python\r\nwith tf.GradientTape(persistent=True) as tape:\r\n    y = x @ my_vars['w'] + my_vars['b']\r\n    loss = tf.reduce_mean(y**2)\r\ngrad = tape.gradient(loss, my_vars)\r\ngrad['b']\r\n```\r\n\r\nNote that `persistent=True` is particularly specified, so I guess the first choice might more agree with the author's initial purpose.\r\n", "comments": ["@szcf-weiya,\r\nCan we close this issue as the linked PR is merged? Thanks!", "@amahendrakar OK, thanks!"]}]