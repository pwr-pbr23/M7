[{"number": 37800, "title": "typo in https://www.tensorflow.org/guide/upgrade", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/upgrade#recommended_upgrade_process\r\n\r\n\r\n## Description of issue (what needs changing):\r\nthere is two consecutive \"will\" in the point `Run the upgrade script`. \r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\nYes. I'll be opening a PR soon.", "comments": ["rushabh-v \r\nplease confirm if we may close this issue as its been monitored in pr #1509"]}, {"number": 37799, "title": "Progress bar with tensorflow.keras.load_model", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):1.15\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen loading larger multiple models it is taking too much time. It will be better to have a progress bar to know current status of model loading.\r\n**Will this change the current api? How?**\r\nI do not know.\r\n**Who will benefit with this feature?**\r\nThose working with models trained using transfer learning or using very learge models on a CPU.\r\n**Any Other info.**\r\nI checked on progressbar2 and tqdm. But both requires an iterable to work with.", "comments": ["Hello, I would love to work on this issue! Can you plz give me some pointers so I can start working on it...", "Most of the current python libraries I checked works on an iterable. I don't know we have such an iterable in this case. If there's one, then a separate thread may be used to monitor this. This is my initial guess. May be wrong.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 37798, "title": "Fix: Misleading convert error when no concrete functions are given", "body": "resolves #37086 ", "comments": ["should I add the test for this?", "@rushabh-v Can you please check @ashutosh1919's comments and keep us posted. Thanks!", "Sorry for taking too long, @ashutosh1919 . I have edited the docstring and added the test. Can you review again, please?"]}, {"number": 37797, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "**\r\n\r\n> SOLVED ===>  I installed Visual Studio 2009.  The root of the problem is that I need clean C++ redistributable files available.  WHEW!\r\n\r\n**\r\n\r\nThanks Sreerag-ibtl for jumping into my issue.  I tried reinstall using pip, conda then use anaconda interface several times.  ", "comments": ["I am learning how to use NLP.  One of the package, tensorflow is required to be used for my activity.   I have uninstall and install tensorflow repeatedly with no success.\r\n\r\nI am trying to learn how to tokenization using Keras.\r\n\r\n== check python ===================================================\r\npython version: 3.7.6\r\npython branch:\r\npython build version: ('default', 'Jan  8 2020 20:23:39')\r\npython compiler version: MSC v.1916 64 bit (AMD64)\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Windows\r\nos kernel version: 10.0.18362\r\nos release version: 10\r\nos platform: Windows-10-10.0.18362-SP0\r\nlinux distribution: ('', '', '')\r\nlinux os distribution: ('', '', '')\r\nmac version: ('', ('', '', ''), '')\r\nuname: uname_result(system='Windows', node='Karen8700', release='10', version='10.0.18362', machine='AMD64', processor='Intel64 Family 6 Model 60 Stepping 3, GenuineIntel')\r\narchitecture: ('64bit', 'WindowsPE')\r\nmachine: AMD64\r\n\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\n/c/Users/karen/anaconda3/envs/pythondata/lib/tf_env_collect.sh: line 100: c++: command not found\r\n\r\n== check pips ===================================================\r\nnumpy                              1.18.2\r\nnumpydoc                           0.9.2\r\nprotobuf                           3.11.3\r\ntensorflow                         2.1.0\r\ntensorflow-estimator               2.1.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\karen\\anaconda3\\envs\\pythondata\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\karen\\anaconda3\\envs\\pythondata\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\karen\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\karen\\anaconda3\\envs\\pythondata\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\karen\\anaconda3\\envs\\pythondata\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n/c/Users/karen/anaconda3/envs/pythondata/lib/tf_env_collect.sh: line 145: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.1.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: c:\\users\\karen\\anaconda3\\lib\\site-packages\r\nRequired-by:\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 7, 6, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n\r\nkaren@Karen8700 MINGW64 ~/anaconda3/envs/pythondata/lib\r\n$ ^C\r\n\r\n", "I had similar issue with `pip install tensorflow`. Resolved with a fresh `conda install tensorflow`.", "closing and locking as this just duplicates a resolved issue only to say \"works\"/\"thanks\"", "If it is a new issue, please fill in issue template in a new issue"]}, {"number": 37796, "title": "Problem with Custom Metrics Even for H5 models", "body": "These are how I defined and saved the custom metric fbeta and vgg model on colab:\r\n\r\n```\r\nfrom sklearn.model_selection import train_test_split\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.models import Sequential, Model\r\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\r\nfrom keras.layers import Dropout\r\nfrom keras.optimizers import SGD\r\nfrom keras import backend\r\n```\r\n```\r\ndef fbeta(y_true, y_pred, beta=2):\r\n    y_pred = backend.clip(y_pred, 0, 1)\r\n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\r\n    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\r\n    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\r\n    p = tp / (tp + fp + backend.epsilon())\r\n    r = tp / (tp + fn + backend.epsilon())\r\n    # calculate fbeta, averaged across each class\r\n    fbeta_score = backend.mean((1 + beta ** 2) * (p * r) / ((beta ** 2) * p + r + backend.epsilon()))\r\n    return fbeta_score\r\n```\r\n\r\n \r\n```\r\ndef vgg16_model(in_shape=(128, 128, 3), out_shape=17):\r\n    # load model\r\n    model = VGG16(include_top=False, input_shape=in_shape)\r\n    # mark loaded layers as not trainable\r\n    for layer in model.layers:\r\n        layer.trainable = False\r\n    # allow last vgg block to be trainable\r\n    model.get_layer('block5_conv1').trainable = True\r\n    model.get_layer('block5_conv2').trainable = True\r\n    model.get_layer('block5_conv3').trainable = True\r\n    model.get_layer('block5_pool').trainable = True\r\n    # add new classifier layers\r\n    flat1 = Flatten()(model.layers[-1].output)\r\n    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\r\n    output = Dense(out_shape, activation='sigmoid')(class1)\r\n    # define new model\r\n    model = Model(inputs=model.inputs, outputs=output)\r\n    # compile model\r\n    opt = SGD(lr=0.01, momentum=0.9)\r\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\r\n    return model\r\n```\r\n\r\n\r\nCreate model and save in google drive:\r\n```\r\nmodel.save('model.h5')\r\nmodel_file = drive.CreateFile({'title' : 'model.h5'})\r\nmodel_file.SetContentFile('model.h5')\r\nmodel_file.Upload()\r\nprint(\"Model is saved.\")\r\ndrive.CreateFile({'id': model_file.get('id')})\r\nprint(\"Model downloaded to google drive.\")\r\n```\r\n\r\nThe error happened when I load the model with the following:\r\n\r\n```\r\nfrom pandas import read_csv\r\nfrom keras.preprocessing.image import load_img\r\nfrom keras.preprocessing.image import img_to_array\r\nfrom keras.models import load_model\r\nmodel = load_model('path/')  # i also tried \"model = load_model('path/', {'F-Beta': fbeta})\"\r\nresult = model.predict(img)\r\nprint(result[0])\r\n```\r\n\r\nGot this error:\r\nValueError: Unknown metric function:fbeta\r\n\r\nI believe all packages and paths are imported and defined correctly. Models were saved correctly on google drive as well. I tried all 3 other posts (#33646, #33648, #36390 ) regarding similar customized metric issues, and tried all the potential fixes and get-arounds, unfortunately none of them worked. I am surprised that some community members claimed that .h5 models should not have this issue though. ", "comments": ["@ZhiliWang , Keras does not save custom object while saving model. So you need to pass `custom_objects` parameter to `load_model`. Before that you need to define custom metrics.\r\n\r\n```\r\n def fbeta(y_true, y_pred, beta=2):\r\n    y_pred = backend.clip(y_pred, 0, 1)\r\n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\r\n    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\r\n    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\r\n    p = tp / (tp + fp + backend.epsilon())\r\n    r = tp / (tp + fn + backend.epsilon())\r\n    # calculate fbeta, averaged across each class\r\n    fbeta_score = backend.mean((1 + beta ** 2) * (p * r) / ((beta ** 2) * p + r + backend.epsilon()))\r\n    return fbeta_score\r\n\r\n from keras.models import load_model\r\n model = load_model('/content/drive/My Drive/model.h5',custom_objects={'fbeta':fbeta})\r\n```\r\n ", "> @ZhiliWang , Keras does not save custom object while saving model. So you need to pass `custom_objects` parameter to `load_model`. Before that you need to define custom metrics.\r\n> \r\n> ```\r\n>  def fbeta(y_true, y_pred, beta=2):\r\n>     y_pred = backend.clip(y_pred, 0, 1)\r\n>     tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\r\n>     fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\r\n>     fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\r\n>     p = tp / (tp + fp + backend.epsilon())\r\n>     r = tp / (tp + fn + backend.epsilon())\r\n>     # calculate fbeta, averaged across each class\r\n>     fbeta_score = backend.mean((1 + beta ** 2) * (p * r) / ((beta ** 2) * p + r + backend.epsilon()))\r\n>     return fbeta_score\r\n> \r\n>  from keras.models import load_model\r\n>  model = load_model('/content/drive/My Drive/model.h5',custom_objects={'fbeta':fbeta})\r\n> ```\r\n\r\nThank you! I tried that and it did not work (and i posted definition of fbeta as well). Do I have to define custom metrics as a class?", "I figured it out. Thank you everyone!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37796\">No</a>\n", "@ZhiliWang, I have successfully saved and loaded model as i mentioned above. For your reference link of gist is [here](https://gist.github.com/khimraj/8741a7012ac9bbd675ef0ea2fb9b778b)"]}, {"number": 37794, "title": "Problem with tf.train.FloatList", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:  /\r\n- TensorFlow installed from (source or\r\nbinary): Source, 2.1 - TensorFlow version (use command below): \r\n- Python version: 3.6.9 - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory: 10.2\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nI have been trying to convert my Pascal VOC annotations (xml files + jpg) to TFRecords for training and validation datasets but I seem to be running into problems.\r\nMy bounding boxes are correct in the xml files (as in they don't go out of bounds) but whenever I start converting them to TFRecords they suddenly change value mid through. I have narrowed the specific code down to one line:\r\nfloat_list=tf.train.FloatList(value=ymax)\r\nAfter this line (the same for xmin, xmax and ymin) the values that I've calculated beforehand suddenly change. For example when I have 2 values in my ymax list and then generate the float_list I get the following:\r\n[0.7670886848546281, 0.8025317614591573]\r\nvalue: 0.7670887112617493\r\nvalue: 0.8025317788124084\r\n\r\nI don't really understand why they change but in some circumstances it makes the value go to 1.0 which makes my loss keep going to nan. \r\n\r\nMy question is: is there any way to fix this or am i somehow doing this all wrong? I have provided the conversion script below.\r\n\r\nColab link:\r\nhttps://colab.research.google.com/drive/1hKXjsgWdKUIAAeQHM5KiRL2iRhxKWSRu\r\n\r\n\r\n```Python\r\n'''\r\nThis program is meant for transforming .xml files to TFRecords.\r\nIn the program itself there is no need for changes. The only things\r\none has to change are the AIBASEMAP and IMAGEMAP locations when \r\nnecessary!\r\n\r\nIf needed one could also change some settings in the FLAGS, although\r\nthis is not deemed necessary if the folder structure stays the same.\r\n'''\r\nimport time\r\nimport os\r\nfrom os import listdir\r\nfrom os.path import isdir, isfile, join\r\n\r\nimport hashlib\r\n\r\nfrom absl import app, flags, logging\r\nfrom absl.flags import FLAGS\r\nimport tensorflow as tf\r\nimport lxml.etree\r\nimport tqdm\r\nimport time\r\n\r\n# Set the basemap from which we're working \r\n# This is different for each device! Change accordingly!\r\nAIBASEMAP = '/Code/yolov3-tf2-master/'                         #XXX JupyterLab\r\n\r\n# Set the image map from which we're working\r\nIMAGEBASEMAP = '/Images/Trash2_updated'\r\n\r\n\r\nflags.DEFINE_string('data_dir', 'Directory with images and annotations',\r\n                    'Directory with images and annotations')\r\nflags.DEFINE_enum('split', 'train', [\r\n                  'train', 'val'], 'train') #'specify train or val spit')\r\nflags.DEFINE_string('output_file_train', 'Path to output train.tfrecord', 'Path to output train.tfrecord')\r\nflags.DEFINE_string('output_file_val', 'Path to output val.tfrecord', 'Path to output val.tfrecord')\r\nflags.DEFINE_string('classes', 'Path to .names file with labels', 'Class names record')\r\n\r\ndef build_example(annotation, class_map, path, i):\r\n    check = True\r\n    img_path = path + '.jpg'\r\n    img_raw = open(img_path, 'rb').read()\r\n    key = hashlib.sha256(img_raw).hexdigest()\r\n\r\n    width = int(annotation['size']['width'])\r\n    height = int(annotation['size']['height'])\r\n\r\n    xmin = []\r\n    ymin = []\r\n    xmax = []\r\n    ymax = []\r\n    classes = []\r\n    classes_text = []\r\n    truncated = []\r\n    views = []\r\n    difficult_obj = []\r\n    if 'object' in annotation:\r\n        for obj in annotation['object']:\r\n            difficult = bool(int(obj['difficult']))\r\n            difficult_obj.append(int(difficult))\r\n\r\n            xmin.append(float(obj['bndbox']['xmin']) / width)\r\n            ymin.append(float(obj['bndbox']['ymin']) / height)\r\n            xmax.append(float(obj['bndbox']['xmax']) / width)\r\n            ymax.append(float(obj['bndbox']['ymax']) / height)\r\n            classes_text.append(obj['name'].encode('utf8'))\r\n            classes.append(class_map[obj['name']])\r\n            truncated.append(int(obj['truncated']))\r\n            views.append(obj['pose'].encode('utf8'))\r\n\r\n    example = tf.train.Example(features=tf.train.Features(feature={\r\n        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\r\n        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\r\n        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\r\n            annotation['filename'].encode('utf8')])),\r\n        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\r\n            annotation['filename'].encode('utf8')])),\r\n        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf8')])),\r\n        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\r\n        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['jpeg'.encode('utf8')])),\r\n        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\r\n        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\r\n        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\r\n        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\r\n        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\r\n        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\r\n        'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult_obj)),\r\n        'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\r\n        'image/object/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=views)),\r\n    }))\r\n    return example\r\n\r\n\r\ndef parse_xml(xml):\r\n    if not len(xml):\r\n        return {xml.tag: xml.text}\r\n    result = {}\r\n    for child in xml:\r\n        child_result = parse_xml(child)\r\n        if child.tag != 'object':\r\n            result[child.tag] = child_result[child.tag]\r\n        else:\r\n            if child.tag not in result:\r\n                result[child.tag] = []\r\n            result[child.tag].append(child_result[child.tag])\r\n    return {xml.tag: result}\r\n\r\ndef conversion(image_list, writer, class_map):\r\n    i = 0\r\n    for image in tqdm.tqdm(image_list):\r\n        i += 1\r\n        temp = image\r\n        try:\r\n            image = image.split('.')[0]\r\n            path_name = image.replace('.', '')\r\n            annotation_xml = path_name + '.xml'\r\n            annotation_xml = lxml.etree.fromstring(open(annotation_xml, 'rb').read())\r\n            annotation = parse_xml(annotation_xml)['annotation']\r\n            tf_example = build_example(annotation, class_map, path_name, i)\r\n            writer.write(tf_example.SerializeToString())\r\n        except Exception as exception:\r\n            print('Er is een fout bij: ', path_name)\r\n            with open('exception.log', '+w') as error_log_file:\r\n                error_log_file.write(str(exception))\r\n            quit()\r\n            # check for XML syntax errors\r\n        except etree.XMLSyntaxError as err:\r\n            print('XML Syntax Error, see error_syntax.log, Error in: ', path_name)\r\n            with open('error_syntax.log', '+a') as error_log_file:\r\n                error_log_file.write('\\nEr is een Fout in: ', path_name)\r\n                error_log_file.write(str(err.error_log))\r\n            quit()\r\n\r\n\r\ndef main(_argv):\r\n    class_map = {name: idx for idx, name in enumerate(\r\n        open(FLAGS.classes).read().splitlines())}\r\n    logging.info(\"Class mapping loaded: %s\", class_map)\r\n\r\n    directories = [f for f in listdir(FLAGS.data_dir) if isdir(join(FLAGS.data_dir, f))]\r\n    print('Start trainingsdata conversion.')\r\n    writer = tf.io.TFRecordWriter(FLAGS.output_file_train)\r\n    image_list = open(os.path.join(\r\n        FLAGS.data_dir, 'Trash', 'solutions_%s.txt' % FLAGS.split)).read().splitlines()\r\n    logging.info(\"Image list loaded: %d\", len(image_list))\r\n    conversion(image_list, writer, class_map)\r\n    writer.close()\r\n    print('Done')\r\n    print('Start validationdata conversion.')\r\n    writer = tf.io.TFRecordWriter(FLAGS.output_file_val)\r\n    image_list = open(os.path.join(\r\n        FLAGS.data_dir, 'Trash', 'validation_data.txt' )).read().splitlines()\r\n    logging.info(\"Image list loaded: %d\", len(image_list))\r\n    conversion(image_list, writer, class_map)\r\n    writer.close()\r\n    logging.info(\"Done\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    app.run(main)\r\n```", "comments": ["@mcbe1985 , Please provide colab link here. The code given is not structured and well indented.", "The colab link is; https://colab.research.google.com/drive/1hKXjsgWdKUIAAeQHM5KiRL2iRhxKWSRu\r\n\r\nI've added the colab to the opening post as well.", "@mcbe1985 Is it still an issue or did you resolve it. Thanks!", "Fixed it during my research, was a mistake in the annotations which made it do weird stuff.", "@mcbe1985 How do you solved it?\r\n\r\nI have the same issue", "> @mcbe1985 How do you solved it?\r\n> \r\n> I have the same issue\r\n\r\nIn most cases there's a mistake in your annotations (as was the case here). For the github issue and repo where I figured it out check https://github.com/zzh8829/yolov3-tf2/issues/214\r\n\r\nHope that helps.", "Hi @mcbe1985,\r\n\r\nSorry I am not describe clear my issue.\r\nI already open a new issue #42088"]}, {"number": 37793, "title": "how to use tf.train.Checkpoint to restore only part of the model", "body": "https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/training/tracking/util.py#L1692-L1989\r\n\r\nI found it a little confusing when I use tf 2.x to restore part of the model (like decoder) to perform transfer learning. I found the code styles like this:\r\n`checkpoint = tf.train.Checkpoint(model=autoencoder, optimizer=optimizer)`\r\nif I want to use the pretrained decoder and write a new encoder different from the old_model, I know how to load the pretrained decoder's weights by explicitly using the decoder's name. But now it seems the restoration operation is through tf.train.Checkpoint. I don't know how to load part of the model's weight using tf.train.Checkpoint or change the model's encoder after restore the model. Is it correct to add a new line after `checkpoint = tf.train.Checkpoint(model=old_model, optimizer=optimizer)` like `autoencoder.encoder = new_encoder`?\r\n", "comments": ["you can get access to each variable in checkpoint using\r\n`inside_checkpoint=tf.train.list_variables(tf.train.latest_checkpoint('./tf_ckpts/'))`\r\nand initialize the values(weights,kernel,etc) as an array to your model.\r\nFor more reference visit https://www.tensorflow.org/guide/checkpoint#manual_checkpointing\r\n", "thanks for the help! I use the `tf.train.list_variables` and I can get a list of variables. But I am not sure how to get all the values which includes 'decoder' in it:\r\n![image](https://user-images.githubusercontent.com/14315324/77261820-cc1b6480-6c67-11ea-8a03-1ae1d762144c.png)\r\nCan I get the weights of decoder here and feed it to my model.decoder?", "This can be done manually so suppose I have a layer whose weights are basically kernel and bias which could be set using kernel initializer and bias initializer by accessing the values using `tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"net/l1/bias/.ATTRIBUTES/VARIABLE_VALUE\")` and `tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE\")` which will return a tensor of values of bais and kernel if you want optimizers you can go for it ex-`tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE\")`  if you are training the same model architecture only so in you case you can access the kenel and bias values of dense_out,f_stack and so on.", "if your problem is solved please reply or close this issue", "> This can be done manually so suppose I have a layer whose weights are basically kernel and bias which could be set using kernel initializer and bias initializer by accessing the values using `tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"net/l1/bias/.ATTRIBUTES/VARIABLE_VALUE\")` and `tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE\")` which will return a tensor of values of bais and kernel if you want optimizers you can go for it ex-`tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE\")` if you are training the same model architecture only so in you case you can access the kenel and bias values of dense_out,f_stack and so on.\r\n\r\nHey, thanks for your answer! I am not sure if I understand you correctly, so in your answer I should load the submodules in my decoder one by one, is it right? So should I write some code like:\r\n```\r\ntf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"model/decoder/dense_out\")\r\ntf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"model/decoder/f_stack\")\r\n```\r\nor maybe this it not enough, I should write something like:\r\n```\r\ntf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"model/decoder/dense_out/bias/.ATTRIBUTES/VARIABLE_VALUE\")\r\n......\r\n```\r\nIf I should write codes using the latter fashion, it means I should write a lot of codes to make sure I loaded everything in my decoder. I wonder could I write some simple code like `tf.train.load_variable(tf.train.latest_checkpoint('./tf_ckpts/'),\"model/decoder/\")` to load everything easily? Or, maybe I could loop over all the keys discovered using tf.train.list_variables to load the weights?", "See https://www.tensorflow.org/guide/checkpoint#loading_mechanics (example of only loading a bias variable from a larger checkpoint, but the same pattern works for \"only\" loading a whole model/layer)", "@allenlavoie I have a further question. Given that there are multiple ckpts stored in a folder, how can I restore a specific model by using ckpt.restore(...). The doc seems unclear about it. Thanks\r\n![\u6355\u83b7](https://user-images.githubusercontent.com/51472988/81532895-c56fba80-9397-11ea-876f-c0fde1dbef39.JPG)\r\n\r\n", "Specify the prefix for the one you want to restore (the number is part of the prefix).", "@allenlavoie Say I would like to restore ckpt-12 shown in the picture above, would you mind of giving me a line of example code? Sorry for any inconvenience caused.", "```\r\nckpt = tf.train.Checkpoint(...)\r\nstatus = ckpt.restore('path/to/that/directory/ckpt-12')\r\n# ... make sure the variables are created\r\nstatus.assert_consumed()  # lets you know if anything wasn't restored\r\n```", "@allenlavoie Great, thanks a lot!", "@allenlavoie  I am working on a very similar thread as @ james20141606, so i have custom build transformer encoder and decoder layers that are added together in a keras model object. I want to train or fine tune only the encoder on a new dataset, so was wondering if you there is a simple straight forward way to load all encoder variables in a single shot.\r\nI looked at the loading mechanics as described on https://www.tensorflow.org/guide/checkpoint page, but doing it for all the encoder layers with multiple attention heads with that mechanism requires extensive lines of code for each layer likee reconstructing the entire architecture.\r\nAny suggestions or recommendations for a smarter work around", "> @allenlavoie I am working on a very similar thread as @ james20141606, so i have custom build transformer encoder and decoder layers that are added together in a keras model object. I want to train or fine tune only the encoder on a new dataset, so was wondering if you there is a simple straight forward way to load all encoder variables in a single shot.\r\n> I looked at the loading mechanics as described on https://www.tensorflow.org/guide/checkpoint page, but doing it for all the encoder layers with multiple attention heads with that mechanism requires extensive lines of code for each layer likee reconstructing the entire architecture.\r\n> Any suggestions or recommendations for a smarter work around\r\n\r\nExactly what lots of us needed. For Keras it was as simple as load the weight and \"skip_name\" to skip the mismatches as we have to replace the top layers for examples for different classification.\r\n\r\nThanks for your solution.\r\nSteve", "> you can get access to each variable in checkpoint using\r\n> `inside_checkpoint=tf.train.list_variables(tf.train.latest_checkpoint('./tf_ckpts/'))`\r\n> and initialize the values(weights,kernel,etc) as an array to your model.\r\n> For more reference visit https://www.tensorflow.org/guide/checkpoint#manual_checkpointing\r\n\r\nHow can we initialize the values(weights,kernel,etc) as an array to the model? Sharing a code snippet will be helpful.", "anyone found a smart way to load weights using checkpoint, I want to skip last layers while loading the weights.", "Found a solution to this problem that worked in my case (load pretrained model weights except for the last Dense layer):\r\n\r\n```python\r\ncheckpoint_directory = os.path.join(train_dir, \"restore/\")\r\ncheckpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\r\n# Use for save new checkpoints:\r\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)  # model - new model with +1 class\r\n\r\ndef get_variables_to_restore(variables, vars_to_exclude):\r\n    variables_to_restore = []\r\n    for v in variables:\r\n        if v.name.split(\":\")[0] not in vars_to_exclude:\r\n            print(\"Variables restored: %s\" % v.name)\r\n            variables_to_restore.append(v)\r\n    return variables_to_restore\r\n\r\nckpt = tf.train.get_checkpoint_state(checkpoint_directory)\r\npretrained_model = ckpt.model_checkpoint_path\r\n\r\nvariables = tf.global_variables()\r\nsess.run(tf.variables_initializer(variables, name=\"init\"))\r\n\r\nvars_to_exclude = set([\"dense/bias\", \"dense/kernel\"])\r\nvariable_to_restore = get_variables_to_restore(variables, vars_to_exclude)\r\n\r\nrestorer = tf.train.Saver(variable_to_restore)\r\nrestorer.restore(sess, pretrained_model)\r\n\r\n# some train or finetune\r\n\r\ncheckpoint.save(file_prefix=checkpoint_prefix, session=sess)\r\n```\r\n\r\nSource: \r\nhttps://innerpeace-wu.github.io/2017/12/13/Tensorflow-Restore-partial-weights/", "@ArtyomZemlyak works with TF1, but is there a solution for TF2? This seems like a common enough use case...", "Hi, can this issue please be reopened. The solution @ArtyomZemlyak posted only works for TF1 (if you look at his source, it was posted in Posted on 2017-12-13, years before TF2 was released). Can we have a solution for TF2?"]}, {"number": 37792, "title": "Does Keras disable regularization (dropout, noise) layers when evaluating the validation data during Model.fit()?", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI can't find a clear statement whether or not the regularization layers (noise, dropout) are bypassed when the validation data is processed (to calculate the validation loss) when calling `Model.fit()` provided with validation data. I can see that in the source code of the Dropout Layer that it is branched based on the `training` argument of `call()`. https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/core.py#L181\r\n\r\nBut it is completely unclear to me whether or not the validation pass is considered \"training\" or not. After all, I'm calling the \"fit\" function.", "comments": ["@mcourteaux, first of all validation pass is not considered as training and during training of network actually dropout layer is not bypassed instead of that all neuron's weight of dropout layer is multiplied by probability p of its existence. \r\n![Screenshot from 2020-03-22 09-45-00](https://user-images.githubusercontent.com/36735394/77242230-5c36bb00-6c22-11ea-9633-92394b501149.png)\r\nFor more detail you can refer [this](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) paper.\r\n", "So, based on your statement \"validation pass is not considered as training\", all types of noise and dropout do not affect validation loss computations.", "Yes validation pass is not considered as training and dropout layer doesn't affect validation loss.", "> Yes validation pass is not considered as training and dropout layer doesn't affect validation loss.\r\n\r\nHi. I can clearly see that dropout is not considered during validation from your answer. But I was wondering if this is also true for weight regularization. That is, will the weight regularization loss be considered during validation? Thank you.", "Me now being a little more familiar with the code, I would say: Yes, it will be considered. The loss function never changes, not in training or validation, or evaluation. Just the noise/dropout layer is bypassed, and the network produces a prediction in the fullest \"quality\" (ie: without the distortions from those layers)."]}, {"number": 37791, "title": "[Feature Request] Keras backend support jax", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nLet ```tensorflow.keras``` support ```jax``` so developers could use ```keras``` as ```jax``` high level api.\r\nTensorflow keras only support tensorflow backend now.\r\n**Will this change the current api? How?**\r\nMaybe\r\n**Who will benefit with this feature?**\r\nDeveloper who is interested in ```keras``` and ```jax```\r\n**Any Other info.**\r\nKeras could support numpy backend so it's easy to support jax as backend.", "comments": []}, {"number": 37790, "title": "Add get_tracing_count feature", "body": "This PR solved #37323.", "comments": ["> Seems like there are 2 different fixes here. Could you please file separate PRs?\r\n\r\nNo problem. Should I close this PR and file two other new PRs, or just move one-issue related commits to another new pr?", "@djdongjin: Code looks good. It might just look cleaner to setup some new PRs, but I'll leave that up to you.", "> @djdongjin: Code looks good. It might just look cleaner to setup some new PRs, but I'll leave that up to you.\r\n\r\nThanks for review :). Given the size of this PR, I just revert a commit and move it to another pr #37820.", "@djdongjin Can you please resolve conflicts? Thanks!"]}, {"number": 37789, "title": "add convex hull cpu implmentation", "body": "@alextp,  I wrote the cpu version of convex hull to address the issue #31067, tfxla version will be implemented later.  Can someone review my PR?", "comments": ["Hi, @rmlarsen\uff0c @penpornk, how is this PR review going?", "@musikisomorphie I'll get to this by the end of this week. Sorry for the delay!", "@penpornk, @rmlarsen hi guys, how is the review going?", "@musikisomorphie Can you please resolve conflicts? Thanks!\r\n", "Hi @penpornk, thank you for your feedback. Please take a look at my update, which I addressed most of your reviews.", "@penpornk, thank you for your feedback. I addressed your reviews. \r\nHowever, when I run\r\n `bazel run tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True`\r\nI got the following errors. and I tried compiling tf from scratch several times with different configurations and run the api test, this error remains. Based on the error information, It does not seem to be related to my convexhull implementation. Could you please help me with it? Thank you\r\n\r\n```\r\nRunning tests under Python 3.7.7: /home/miashan/Applications/miniconda3/envs/torch_test/bin/python3\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibility\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibility): 0.0s\r\nI0531 20:55:54.395447 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibility): 0.0s\r\n[  FAILED  ] ApiCompatibilityTest.testAPIBackwardsCompatibility\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV1\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV1): 0.01s\r\nI0531 20:55:54.402081 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV1): 0.01s\r\n[  FAILED  ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV1\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV2\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV2): 0.0s\r\nI0531 20:55:54.405161 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV2): 0.0s\r\n[  FAILED  ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV2\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessage\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessage): 0.03s\r\nI0531 20:55:54.431433 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessage): 0.03s\r\n[  FAILED  ] ApiCompatibilityTest.testNoSubclassOfMessage\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessageV1\r\nWARNING:tensorflow:From /home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.GraphKeys.GLOBAL_VARIABLES` instead.\r\nW0531 20:55:54.438971 140217385260864 deprecation.py:323] From /home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.GraphKeys.GLOBAL_VARIABLES` instead.\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\r\n\r\nW0531 20:55:54.493530 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\r\n\r\nW0531 20:55:54.493923 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\r\n\r\nW0531 20:55:54.504908 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\r\n\r\nW0531 20:55:54.505028 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\r\n\r\nW0531 20:55:54.505102 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\r\n\r\nW0531 20:55:54.505240 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.he_uniform is deprecated. Please use tf.compat.v1.keras.initializers.he_uniform instead.\r\n\r\nW0531 20:55:54.505301 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.he_uniform is deprecated. Please use tf.compat.v1.keras.initializers.he_uniform instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.lecun_normal is deprecated. Please use tf.compat.v1.keras.initializers.lecun_normal instead.\r\n\r\nW0531 20:55:54.505368 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.lecun_normal is deprecated. Please use tf.compat.v1.keras.initializers.lecun_normal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.lecun_uniform is deprecated. Please use tf.compat.v1.keras.initializers.lecun_uniform instead.\r\n\r\nW0531 20:55:54.505424 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.lecun_uniform is deprecated. Please use tf.compat.v1.keras.initializers.lecun_uniform instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.normal is deprecated. Please use tf.compat.v1.keras.initializers.normal instead.\r\n\r\nW0531 20:55:54.505477 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.normal is deprecated. Please use tf.compat.v1.keras.initializers.normal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.random_normal is deprecated. Please use tf.compat.v1.keras.initializers.random_normal instead.\r\n\r\nW0531 20:55:54.505549 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.random_normal is deprecated. Please use tf.compat.v1.keras.initializers.random_normal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.random_uniform is deprecated. Please use tf.compat.v1.keras.initializers.random_uniform instead.\r\n\r\nW0531 20:55:54.505603 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.random_uniform is deprecated. Please use tf.compat.v1.keras.initializers.random_uniform instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.truncated_normal is deprecated. Please use tf.compat.v1.keras.initializers.truncated_normal instead.\r\n\r\nW0531 20:55:54.505664 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.truncated_normal is deprecated. Please use tf.compat.v1.keras.initializers.truncated_normal instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.uniform is deprecated. Please use tf.compat.v1.keras.initializers.uniform instead.\r\n\r\nW0531 20:55:54.505716 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.initializers.uniform is deprecated. Please use tf.compat.v1.keras.initializers.uniform instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\r\n\r\nW0531 20:55:54.510276 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\r\n\r\nW0531 20:55:54.510368 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.disable_v2_dtype_behavior is deprecated. Please use tf.compat.v1.keras.layers.disable_v2_dtype_behavior instead.\r\n\r\nW0531 20:55:54.510708 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.disable_v2_dtype_behavior is deprecated. Please use tf.compat.v1.keras.layers.disable_v2_dtype_behavior instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.enable_v2_dtype_behavior is deprecated. Please use tf.compat.v1.keras.layers.enable_v2_dtype_behavior instead.\r\n\r\nW0531 20:55:54.510774 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.layers.enable_v2_dtype_behavior is deprecated. Please use tf.compat.v1.keras.layers.enable_v2_dtype_behavior instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.losses.cosine is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nW0531 20:55:54.585864 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.losses.cosine is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.losses.cosine_proximity is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nW0531 20:55:54.586018 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.losses.cosine_proximity is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.metrics.cosine is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nW0531 20:55:54.589288 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.metrics.cosine is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nWARNING:tensorflow:From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.metrics.cosine_proximity is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nW0531 20:55:54.589395 140217385260864 module_wrapper.py:138] From /home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/inspect.py:341: The name tf.keras.metrics.cosine_proximity is deprecated. Please use tf.keras.losses.cosine_similarity instead.\r\n\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV1): 0.27s\r\nI0531 20:55:54.703651 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV1): 0.27s\r\n[       OK ] ApiCompatibilityTest.testNoSubclassOfMessageV1\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessageV2\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV2): 0.23s\r\nI0531 20:55:54.936919 140217385260864 test_util.py:1970] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV2): 0.23s\r\n[       OK ] ApiCompatibilityTest.testNoSubclassOfMessageV2\r\n[ RUN      ] ApiCompatibilityTest.test_session\r\n[  SKIPPED ] ApiCompatibilityTest.test_session\r\n======================================================================\r\nERROR: testAPIBackwardsCompatibility (__main__.ApiCompatibilityTest)\r\ntestAPIBackwardsCompatibility (__main__.ApiCompatibilityTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 410, in testAPIBackwardsCompatibility\r\n    omit_golden_symbols_map=omit_golden_symbols_map)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 359, in _checkBackwardsCompatibility\r\n    traverse.traverse(root, public_api_visitor)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 104, in traverse\r\n    _traverse_internal(root, visit, [], '')\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 54, in _traverse_internal\r\n    visit(path, root, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/public_api.py\", line 140, in __call__\r\n    self._visitor(path, parent, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 242, in __call__\r\n    _AddMember(name, child, module_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 207, in _AddMember\r\n    _, member_obj = tf_decorator.unwrap(member_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 219, in unwrap\r\n    elif _has_tf_decorator_attr(cur):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 124, in _has_tf_decorator_attr\r\n    hasattr(obj, '_tf_decorator') and\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features' from 'tensorflow.python.feature_column' (/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/feature_column/__init__.py)\r\n\r\n======================================================================\r\nERROR: testAPIBackwardsCompatibilityV1 (__main__.ApiCompatibilityTest)\r\ntestAPIBackwardsCompatibilityV1 (__main__.ApiCompatibilityTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 426, in testAPIBackwardsCompatibilityV1\r\n    omit_golden_symbols_map={'tensorflow': ['pywrap_tensorflow']})\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 359, in _checkBackwardsCompatibility\r\n    traverse.traverse(root, public_api_visitor)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 104, in traverse\r\n    _traverse_internal(root, visit, [], '')\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 54, in _traverse_internal\r\n    visit(path, root, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/public_api.py\", line 140, in __call__\r\n    self._visitor(path, parent, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 242, in __call__\r\n    _AddMember(name, child, module_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 207, in _AddMember\r\n    _, member_obj = tf_decorator.unwrap(member_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 219, in unwrap\r\n    elif _has_tf_decorator_attr(cur):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 124, in _has_tf_decorator_attr\r\n    hasattr(obj, '_tf_decorator') and\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1.estimator import experimental\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features' from 'tensorflow.python.feature_column' (/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/feature_column/__init__.py)\r\n\r\n======================================================================\r\nERROR: testAPIBackwardsCompatibilityV2 (__main__.ApiCompatibilityTest)\r\ntestAPIBackwardsCompatibilityV2 (__main__.ApiCompatibilityTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 443, in testAPIBackwardsCompatibilityV2\r\n    omit_golden_symbols_map=omit_golden_symbols_map)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 359, in _checkBackwardsCompatibility\r\n    traverse.traverse(root, public_api_visitor)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 104, in traverse\r\n    _traverse_internal(root, visit, [], '')\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 54, in _traverse_internal\r\n    visit(path, root, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/public_api.py\", line 140, in __call__\r\n    self._visitor(path, parent, children)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 242, in __call__\r\n    _AddMember(name, child, module_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py\", line 207, in _AddMember\r\n    _, member_obj = tf_decorator.unwrap(member_obj)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 219, in unwrap\r\n    elif _has_tf_decorator_attr(cur):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 124, in _has_tf_decorator_attr\r\n    hasattr(obj, '_tf_decorator') and\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1.estimator import experimental\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features' from 'tensorflow.python.feature_column' (/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/feature_column/__init__.py)\r\n\r\n======================================================================\r\nERROR: testNoSubclassOfMessage (__main__.ApiCompatibilityTest)\r\ntestNoSubclassOfMessage (__main__.ApiCompatibilityTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 317, in testNoSubclassOfMessage\r\n    traverse.traverse(tf, visitor)\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 104, in traverse\r\n    _traverse_internal(root, visit, [], '')\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/common/traverse.py\", line 58, in _traverse_internal\r\n    child) and child.__name__ in sys.builtin_module_names:\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_inspect.py\", line 397, in ismodule\r\n    return _inspect.ismodule(tf_decorator.unwrap(object)[1])\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 219, in unwrap\r\n    elif _has_tf_decorator_attr(cur):\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py\", line 124, in _has_tf_decorator_attr\r\n    hasattr(obj, '_tf_decorator') and\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1.estimator import experimental\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/miashan/Applications/miniconda3/envs/torch_test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features' from 'tensorflow.python.feature_column' (/home/miashan/.cache/bazel/_bazel_miashan/7f08cea0e8cec4ae4ded56090269931f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/python/feature_column/__init__.py)\r\n\r\n----------------------------------------------------------------------\r\nRan 7 tests in 0.546s\r\n\r\nFAILED (errors=4, skipped=1)\r\n```", "@pengchongjin, thanks for the answer. I updated the API golden files, fixed the empty line issues. You could take a look.", "On the face of it, this looks like tensorflow/graphics might be the best fit. \r\n\r\n@sofienbouaziz WDYT?", "> On the face of it, this looks like tensorflow/graphics might be the best fit.\r\n> \r\n> @sofienbouaziz WDYT?\r\n\r\nThis function is originally implemented in opencv, I am not sure if we should migrate it to tfg. ", "hi @penpornk, @martinwicke guys, what is the next step of this PR?", "@musikisomorphie I think we are waiting to hear from @sofienbouaziz and then @martinwicke will decide the next step. Sorry for the inconvenience and thank you for your patience!", "Sorry for the late reply, we have been discussing this PR quite a bit internally. In general I think having a convex hull functionality is a great match for TensorFlow Graphics. This is a great PR, though I have a few concerns:\r\n1) It implements Sklansky's algorithm (same than OpenCV) which is fairly simple but to the best of my knowledge can in some cases result in wrong outputs\r\n2) The current PR only provides a C++ implementation (and no gradient as it is not differentiable out of the box). I am wondering what do we gain over using tf.numpy_function with OpenCV (or SciPy) as we will need to maintain the code and make sure it is bug free. \r\n3) There is a mention of a future tfxla implementation which seems quite hard to implement due to the dynamic shapes. It seems also not easy to parallelize.", "> Sorry for the late reply, we have been discussing this PR quite a bit internally. In general I think having a convex hull functionality is a great match for TensorFlow Graphics. This is a great PR, though I have a few concerns:\r\n> \r\n> 1. It implements Sklansky's algorithm (same than OpenCV) which is fairly simple but to the best of my knowledge can in some cases result in wrong outputs\r\n> 2. The current PR only provides a C++ implementation (and no gradient as it is not differentiable out of the box). I am wondering what do we gain over using tf.numpy_function with OpenCV (or SciPy) as we will need to maintain the code and make sure it is bug free.\r\n> 3. There is a mention of a future tfxla implementation which seems quite hard to implement due to the dynamic shapes. It seems also not easy to parallelize.\r\n\r\n@sofienbouaziz, thanks for the feedback. I am open to different options, just let me know what the final decision is.", "@musikisomorphie I discussed a bit with @taiya and he mentioned that maybe a better option could be to provide a frontend for QHull's C API instead of reimplementing. The main question for me is what do we get over using tf.numpy_function and directly calling scipy which seem to use QHull internally? Maintaining C++ code has a non negligible cost and I am trying to understand the opportunity cost tradeoff.", "@sofienbouaziz if you can use scipy's API that would of course be lovely. Some caveats / comments:\r\n\r\n 1. you only need to expose it as a TF op if you want to use it in the middle of a TF model; using it before or after the part you want to put inside a tf.function or differentiate doesn't require any work as you can transparently convert back and forth between TF tensors and numpy ndarrays\r\n 2. if you do want to use tf.numpy_function bear in mind that it won't be serializable in a savedmodel and it won't be differentiable; implementing convex hull as a TF op in C++ will allow both things to be supported\r\n 3. an option is maybe to just call some C++ implementation somewhere?\r\n\r\nI also like the idea of writing an implementation of a simple graham scan algorithm using tf.sort and tf.TensorArray to implement the stack and a tf.while_loop to drive the loop; this would perform abysmally when interpreted but if we can XLA compile it we can probably get pretty nice performance (most likely close to but not exceeding a straightforward hand coded implementation like you have here but with the potential of TPU support).", "@musikisomorphie, @sofienbouaziz Any update on this PR? Please. Thanks!", "> @musikisomorphie, @sofienbouaziz Any update on this PR? Please. Thanks!\r\n\r\n\r\n\r\n> @musikisomorphie, @sofienbouaziz Any update on this PR? Please. Thanks!\r\n\r\nhi guys @sofienbouaziz @alextp , I feel most likely you are going for an alternative approach rather than my implementation. I guess I am going to focus on something else instead.  feel free to take my implementation as a reference.", "Apologies, unless we know this would be better than what is already\navailable in python... it is a hard sell.\nWould you mind closing the PR? THanks\n", "> Apologies, unless we know this would be better than what is already available in python... it is a hard sell. Would you mind closing the PR? THanks\r\n\r\nSure, no problem."]}, {"number": 37788, "title": "Change the author of PR #37400 to original contributor", "body": "", "comments": ["@gbaned how do I create an internal copy of this CL for review? thanks.", "```\r\nINFO: Effect: NOOP -  Cannot migrate revisions [d82a2ba2018499a014a13a4213ecaf34e021f25f, 6fd74c7ea03005ed35a158393a8a5e8a4e88f91f]: Import of '6fc5f09a36c4f9b1d13c37c1671a16bb21070577' revision resulted in an empty change. Is the change already migrated?. Affected origin_refs: 2\r\n```\r\n\r\nUnfortunately, we cannot create an empty change internally.\r\n\r\nNevertheless, your commit is [still included in the history](https://github.com/tensorflow/tensorflow/commit/b76202fbf029b6d53c25c85d9916072aae430373) and your name will still be mentioned in the release notes on the next release which includes it.", "![Screenshot from 2020-03-23 16-33-13](https://user-images.githubusercontent.com/323199/77372907-0e09e080-6d24-11ea-90ff-c8cabf06ef45.png)\r\n", "Based on #37400, can we close this / reuse this to fix broken test and resubmit?", "@mihaimaruseac This PR was opened by me completely because of misunderstanding about the merging process and further changes. I guess it can be closed. For further fixes I could either open another proper PR or use the original PR.", "Let's use original PR. Closing this one"]}, {"number": 37787, "title": "Tensorflow Java API in Scala with scala-reflect runtime compilation", "body": "**System information** \r\n\r\nI am using the [HelloWorld](https://www.tensorflow.org/install/lang_java) example from Java API. I am using Scala to execute it without any problems if I compile the code at \"compile time. Instead with I run that using the scala-reflect and therefore runtime compilation, the Session.Runner is not found.\r\n\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- JDK: \r\n```\r\nopenjdk version \"1.8.0_242\"\r\nOpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)\r\nOpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\r\n```\r\n- TensorFlow: from `build.sbt`\r\n\r\n```\r\nlazy val commonSettings = Seq(\r\n    scalaVersion := \"2.12.10\",\r\n\r\n    libraryDependencies ++= {\r\n      Seq(\r\n                  // To support runtime compilation\r\n        \"org.scala-lang\" % \"scala-reflect\" % scalaVersion.value,\r\n        \"org.scala-lang\" % \"scala-compiler\" % scalaVersion.value,\r\n\r\n        // for tensorflow4java\r\n        \"org.tensorflow\" % \"tensorflow\" % \"1.15.0\",\r\n        \"org.tensorflow\" % \"proto\" % \"1.15.0\",\r\n        \"org.tensorflow\" % \"libtensorflow_jni\" % \"1.15.0\"\r\n\r\n      )\r\n    }\r\n)\r\n\r\nlazy val `test-proj` = project\r\n  .in(file(\".\"))\r\n  .settings(commonSettings)\r\n```\r\n\r\n**Describe the current behavior**\r\nBasically, when compiling at runtime the Runner does not gets executed. It compiles properly, but when executing, the runner does not exists. Here is the short stacktrace.\r\n\r\njava.lang.NoSuchMethodError: org.tensorflow.Session.runner()Lorg/tensorflow/Session$$Runner;\r\n  at __wrapper$1$f093d26a3c504d4381a37ef78b6c3d54.__wrapper$1$f093d26a3c504d4381a37ef78b6c3d54$.$anonfun$wrapper$1(<no source file>:15)\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect that both pre-compiled or runtime compilation code will have the same behavior.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nHere is what WORKS:\r\n```\r\nimport org.tensorflow.Graph\r\nimport org.tensorflow.Session\r\nimport org.tensorflow.Tensor\r\nimport org.tensorflow.TensorFlow\r\n\r\n\r\nval g = new Graph()\r\nval value = \"Hello from \" + TensorFlow.version()\r\nval t = Tensor.create(value.getBytes(\"UTF-8\"))\r\n// The Java API doesn't yet include convenience functions for adding operations.\r\ng.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\r\n\r\nval s = new Session(g)\r\nval output = s.runner().fetch(\"MyConst\").run().get(0)\r\n```\r\n\r\nAnd here, what DOES NOT work:\r\n```\r\nimport scala.reflect.runtime.{universe => ru}\r\nimport scala.tools.reflect.ToolBox\r\nval fnStr = \"\"\"\r\n    {() =>\r\n      import org.tensorflow.Graph\r\n      import org.tensorflow.Session\r\n      import org.tensorflow.Tensor\r\n      import org.tensorflow.TensorFlow\r\n\r\n      val g = new Graph()\r\n      val value = \"Hello from \" + TensorFlow.version()\r\n      val t = Tensor.create(value.getBytes(\"UTF-8\"))\r\n      g.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\r\n\r\n      val s = new Session(g)\r\n\r\n      s.runner().fetch(\"MyConst\").run().get(0)\r\n    }\r\n    \"\"\"\r\nval mirror = ru.runtimeMirror(getClass.getClassLoader)\r\nval tb = mirror.mkToolBox()\r\nvar t = tb.parse(fnStr)\r\nval fn = tb.eval(t).asInstanceOf[() => Any]\r\n// and finally, executing the function\r\nfn()\r\n```\r\n\r\nBefore, submitting this issue I posted a Question on stackoverflow: https://stackoverflow.com/questions/60783153/tensorflow-in-scala-reflection\r\n\r\nI will try the Scala API provided by https://github.com/eaplatanios/tensorflow_scala", "comments": ["Did you make it work?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37787\">No</a>\n"]}, {"number": 37786, "title": "Missing link.", "body": "\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/federated/blob/master/docs/deployment.md\r\n```tf.backends``` link is missing .\r\n##Pull request\r\n[#812](https://github.com/tensorflow/federated/pull/812) by sucessfully merging this PR will closw this issue.\r\n\r\n\r\n", "comments": []}, {"number": 37785, "title": "[INTEL MKL] Compiler Bug Fix :  Typing problem in TF 2.2.0 With Visual Studio 2019", "body": "https://github.com/tensorflow/tensorflow/issues/37430\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37785) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37785) for more info**.\n\n<!-- ok -->", "@TensorFlow-MKL  Any update on this PR? Please. Thanks!"]}, {"number": 37784, "title": "[INTEL MKL] ", "body": "Vi", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37784) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 37783, "title": "Broken links", "body": "\r\n## URL(s) with the issue:\r\nIn this repo the ```tf.framework.Executor``` link is broken.\r\n### Pull Request\r\nSuccessfully merging of [#811](https://github.com/tensorflow/federated/pull/811) will close this issue.\r\nHey, @MarkDaoust , @lamberta, and @mihaimaruseac would you please review this pull request.", "comments": ["@abhinavsp0730 Thanks for the issue and PR to update the docs. Closing this issue as the corresponding https://github.com/tensorflow/federated/pull/811 was merged already. Thanks!", "@abhinavsp0730 \r\n\r\nOne good trick is top put a `fixes: tensorflow/tensorflow#37783` in the PR description, that will auto-close the bug when the PR is merged."]}, {"number": 37782, "title": "Broken link in community/forums.md", "body": "\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/community/forums.md\r\n\r\n## Description of the issue (what needs changing):\r\nIn forums.ms  [how to get help](https://github.com/tensorflow/docs/blob/master/community/#get_help) is broken and while clicking it's showing 404 error.\r\n\r\n### submit a pull request\r\nHey, @MarkDaoust and @lamberta would you please assign me this issue and please provide details to fix this issue I'll love to fix this issue.", "comments": ["I think you have to open a PR against https://github.com/tensorflow/docs", "Hey, @mihaimaruseac  thank you for your quick reply. I've searched through github repo to find the correct *how to get help* link but I'm unable to find it. So, my question is does *how to get help* exist or not, If not then we must have to change it for more help mail it to ```tensorflow.org``` or we will link Tensorflow google group link. ", "Maybe this should be the link https://www.tensorflow.org/community ?\r\n\r\nLetting @MarkDaoust / @lamberta add more details", "Hey, @MarkDaoust  / @lamberta kindly check the link provided by @mihaimaruseac  is the correct link for \"how to get help\" or not.", "Hey, @mihaimaruseac this one is offtopic, I've been participating this year GSOC. And I've completed\r\nmy 1st proposal, It'll be very helpful for me if you look at it once and give your feedbacks. So, that it'll come in a more good shape.\r\nThankyou", "Hmmm ... It looks like the only relevant part is the github and SO links, which are already on the forums page.\r\n\r\nI's just delete that sentence.", "Hey, @MarkDaoust  [#1520](https://github.com/tensorflow/docs/pull/1520) kindly see this PR."]}, {"number": 37781, "title": "Expose eager c_api_experimental to other language binding.", "body": "", "comments": ["I thought the experimental C API is private only, shouldn't be dependent on.\r\n\r\nAdding @gunan to confirm", "It's exposed for non-eager mode. https://github.com/tensorflow/tensorflow/blob/874adafd91b0719b89ed1b77cfc472251a82d36b/tensorflow/BUILD#L701\r\n\r\nThe point is the [tf.net](https://github.com/SciSharp/TensorFlow.NET) need some of them.\r\n\r\n![image](https://user-images.githubusercontent.com/1705364/77252474-02ce8c00-6c22-11ea-8cba-6f4e682704f4.png)\r\n", "Connect to https://github.com/tensorflow/tensorflow/pull/37803 on `master`.", "You guys are efficient. @mihaimaruseac ", "> I thought the experimental C API is private only, shouldn't be dependent on.\r\n> \r\n> Adding @gunan to confirm\r\n\r\n@mihaimaruseac: Experimental APIs are fine to call with the caveat that they have no stability guarantees."]}, {"number": 37780, "title": "Missing interpreter initialization code in the codelab", "body": "The codelab in question is [Build a handwritten digit classifier app with TensorFlow Lite\r\n](https://codelabs.developers.google.com/codelabs/digit-classifier-tflite/index.html?index=..%2F..index#3).\r\n\r\nStep 4.6 introduces the following snippet of code:\r\n\r\n```kotlin\r\n// Read input shape from model file\r\nval inputShape = interpreter.getInputTensor(0).shape()\r\ninputImageWidth = inputShape[1]\r\ninputImageHeight = inputShape[2]\r\nmodelInputSize = FLOAT_TYPE_SIZE * inputImageWidth * inputImageHeight * PIXEL_SIZE\r\n\r\n// Finish interpreter initialization\r\nthis.interpreter = interpreter\r\n```\r\n\r\n`interpreter` is a class field that has not been initialized in any previous code snippets and the code fails to compile.\r\n\r\nLooking at the finalized code in the `finish` directory of the downloadable sample, 4.6 should've probably included this code snippet to initialize `interpreter`:\r\n\r\n```kotlin\r\n// Initialize TF Lite Interpreter with NNAPI enabled.\r\nval options = Interpreter.Options()\r\noptions.setUseNNAPI(true)\r\nval interpreter = Interpreter(model, options)\r\n```", "comments": ["@Egorand and @jvishnuvardhan , Please close this issue since My PR [#178](https://github.com/tensorflow/examples/pull/178) is merged and the codelab will be updated soon.", "@Egorand Thanks for the issue and Thanks to @ashutosh1919 for fixing it. Closing this issue as this was resolved. Thanks!\r\n\r\nPlease note that this change may reflect in the codelab later. Thanks!"]}, {"number": 37779, "title": "UnavailableError: Socket closed while using custom training loop", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- Tensorflow version: `2.1.0`\r\n\r\nAbout hardware and software system information I'm using Kaggle kernels so more information can be found here: https://github.com/Kaggle/docker-python\r\n\r\n**Describe the current behavior**\r\nI'm getting errors like the one below, this happens during the training loop.\r\n\r\n![Screenshot from 2020-03-21 09-41-52](https://user-images.githubusercontent.com/16668746/77226592-4b217780-6b58-11ea-8d38-eedea01ca32a.png)\r\n\r\n**Describe the expected behavior**\r\nThe model was supposed to train normally.\r\n\r\n**Standalone code to reproduce the issue** \r\nLink for the Kaggle kernel: https://www.kaggle.com/dimitreoliveira/bug-report-unavailableerror-socket-closed\r\n\r\n**Other info / logs** \r\nAs described on the notebook linked above usually happens when using some combination of the below:\r\n- Long epochs\r\n- Heavy models\r\n- Some loops using too much memory\r\n", "comments": ["@dimitreOliveira,\r\nI tried to reproduce the issue, but am facing an error stating `NameError: name 'KaggleDatasets' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5abc237bc2d480af07cf57edf4aacd1c/37779-2-1.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported along with all the supporting files. Thanks!", "@amahendrakar, you have to run the code on Kaggle.\r\nIf you prefer running it in a different place, you can copy the data to your own GCS bucket. That's the only thing KaggleDatasets().get_gcs_path() does: it copies the data to a GCS bucket close to the TPU and returns the GCS path.", "@amahendrakar as @martin-gorner said to reproduce the same code that I used you would need the lib `KaggleDatasets` and I don't think you would be able to use it on Google colab.\r\n\r\nAnother thing as I mentioned [here](https://www.kaggle.com/c/flower-classification-with-tpus/discussion/135443#783021), this issue seems to be related to memory allocation, I was able to run the code doing some modifications that would reduce memory usage, like removing `dataset.cache()` and reducing iteration count on the validation set. Maybe this can shed some light on solving the problem. Maybe if the problem is really related to memory just a more appropriate error message would do the work.", "@dimitreOliveira where is the `get_validation_dataset` method defined? I couldn't find it in the shared notebook.\r\nWhy are you using dataset.cache() in the dataset? That could cause memory issues. Is it too slow to read the dataset everytime? ", "Also - are you able to run with latest TF nightly on kaggle? Or is 2.1 the only option? ", "Hi @dimitreOliveira, when investigating the set of TPU stability issues reported on Kaggle, we found at least one that goes away with TF 2.2. I need to try this one.", "@guptapriya the `get_validation_dataset` was hidden but I will copy it here for you\r\n```\r\ndef get_validation_dataset(filenames, ordered=True, repeated=False):\r\n    dataset = load_dataset(filenames, labeled=True, ordered=ordered)\r\n    if repeated:\r\n        dataset = dataset.repeat()\r\n        dataset = dataset.shuffle(2048)\r\n    dataset = dataset.batch(BATCH_SIZE)\r\n    dataset = dataset.cache()\r\n    dataset = dataset.prefetch(AUTO)\r\n    return dataset\r\n```\r\n\r\nThe `dataset.cache()` was just to make things a little faster, but I was not using `TF nightly` but I guess it is possible to install and run it.\r\n", "@martin-gorner What TF 2.2 has that solves the issue? and is it stable, if it is I can start experimenting with it as well.", "Just finished testing. TF 2.2 resolves two out of the three reported stability issues I am tracking. Yours is the third one. Your model errors out immediately with this error under TF2.2:\r\n\r\nInvalidArgumentError: {{function_node __inference_train_step_137283}} Compilation failure: Output shapes of then and else branches do not match", "@martin-gorner do you think this might be because of the custom augmentation functions where I use `if` and `else` statements?", "Probably but also probably not your fault. This was working in TF 2.1, it\nshould still work in TF 2.2.\n\nOn Mon, 6 Apr 2020 at 15:33, Dimitre Oliveira <notifications@github.com>\nwrote:\n\n> @martin-gorner <https://github.com/martin-gorner> do you think this might\n> be because of the custom augmentation functions where I use if and else\n> statements?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37779#issuecomment-610071495>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAHKKZ43LATTIIENFRSNQC3RLJKCJANCNFSM4LQ5DTCA>\n> .\n>\n\n\n-- \n\nMartin G\u00f6rner | ML Product Manager, TPU | mgorner@google.com | +1 425 273\n0605\n", "@dimitreOliveira I have been able to confirm that the \"then and else branches do not match\" is a horrible bug deep down in the XLA compiler. It is not related to your data augmentation code. It has now been fixed. The next release of Tensorflow (TF2.2rc3 or TF2.2 release) will make your model work. Thank you for helping us find this.", "That is very nice to hear @martin-gorner , I'm glad I could help and the pleasure is mine!", "I'm closing this issue since it will be solved by future a TensorFlow version.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37779\">No</a>\n"]}, {"number": 37778, "title": "Missing arguments when the inputs of concrete function contain list", "body": "**System information** \r\n- TensorFlow version: v2.1.0\r\n\r\n**Describe the current behavior**\r\n```python\r\n@tf.function\r\ndef test(a, b, c):\r\n    pass\r\n\r\n\r\nc_test = test.get_concrete_function(a=[tf.TensorSpec((None, 1)),\r\n                                       tf.TensorSpec((None, 1))],\r\n                                    b=tf.TensorSpec((None, 2)),\r\n                                    c=[tf.TensorSpec((None, 3)),\r\n                                       tf.TensorSpec((None, 3))])\r\n\r\nc_test(a=[tf.random.normal([2, 1]), tf.random.normal([2, 1])],\r\n       b=tf.random.normal([2, 2]),\r\n       c=[tf.random.normal([2, 3]), tf.random.normal([2, 3])])\r\n```\r\nThe function `test` has `a` and `c`  two arguments that should be as the type list. I create a concrete function `c_test` from `test`. But when `c_test` is called like the code above, it will throw\r\n```\r\nExpected argument names ['a', 'a_1', 'b', 'c', 'c_1'] but got values for ['a', 'b', 'c']. Missing: ['c_1', 'a_1'].\r\n```\r\nIt seems that the function only received the first element of the list arguments.", "comments": ["@BlueFisher, I think you need to pass argument like this.\r\n`c_test(a=tf.random.normal([2, 1]), \r\n       a_1 = tf.random.normal([2, 1]),\r\n       b=tf.random.normal([2, 2]),\r\n       c=tf.random.normal([2, 3]),\r\n       c_1 = tf.random.normal([2, 3]))`.\r\nI have checked this and there is no error.", "@khimraj , that works! Thank you so much. But it would be better if I could pass arguments like the way in my question.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37778\">No</a>\n"]}, {"number": 37777, "title": "It seems that Tensorflow needs a check for the unreasonable parameter `input_dim=0` in the layer `Embedding`.", "body": "## System information\r\n\r\n- Have I written custom code (as opposed to using example directory):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 & Linux Ubuntu 18.04\r\n- Tensorflow version\uff1a2.1.0-cpu (using 'pip install TensorFlow' to download directly)\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n## Describe the current behavior\r\nWhen I build the model with an illogical parameter `input_dim = 0`in the layer `Embedding`, **Tensorflow uses this unreasonably parameter to build and even save the model**. The detailed performance in building the model is shown in the following picture\u3002\r\n\r\n![image](https://user-images.githubusercontent.com/46860123/77224293-27355480-6b9f-11ea-9d96-df3e852ca4b3.png)\r\n\r\n## Key insights\r\nTo sum up, `input_dim` or `output_dim = 0` are unreasonable corner cases. ** Tensorflow seems to lack in checking this corner case**. This may lead Tensorflow users to create and even save a wrong model, which will bring potential risks in the subsequent usage.\r\n\r\n## Code to reproduce the issue\r\n\r\n``` python\r\nimport numpy as np\r\nimport tensorflow.keras.layers as L \r\nfrom tensorflow.keras import Model, Input\r\nimport tensorflow\r\nimport os\r\n\r\nprint(tensorflow.__version__) \r\n\r\nkwargs = {\r\n    'input_dim': 0, # you can also set input_dim to 0 to test\r\n\t'output_dim': 18,\r\n\t'mask_zero': True\r\n}\r\ninput = (10 * np.random.random((32,10)))\r\nlayer = L.Embedding(**kwargs)\r\nx = Input(batch_shape=input.shape)\r\ny = layer(x)\r\nbk_model = Model(x, y)\r\nmodel_path = os.path.join('./', 'mode.h5')\r\nbk_model.save(model_path, bk_model)\r\nprint('finish')\r\n```", "comments": ["The code you have written is not correct you are not passing any input to the model.TensorFlow creates a static graph and the checks for the correct dimension during execution\r\nWrite you code then at the end write`bk_model(input)` .You will see some error this is because the dimension of your tensor is (32,10) now change `'input_dim': 0` to `'input_dim': 10` and run again,it will work.", "@shiningrain \r\nCould you please update on the above comment", "> The code you have written is not correct you are not passing any input to the model.TensorFlow creates a static graph and the checks for the correct dimension during execution\r\n> Write you code then at the end write`bk_model(input)` .You will see some error this is because the dimension of your tensor is (32,10) now change `'input_dim': 0` to `'input_dim': 10` and run again,it will work.\r\n\r\nHello! Thank you for your reply!\r\nI have tested the code with the change you said. And when I set the `inputdim=10` ,it did make a normal prediction.  But as I described above, **if I set `inputdim` to 0, I  can still build and save the model, although this model cannot be used for prediction.**\r\nI saw on the TensorFlow document [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding). On this page, it mentions that the inputdim should be greater than zero, but it seems that we can still build the model with `inputdim = 0`. \r\nI want to emphasize that **there seems to be a lack of simple parameter check**, thus the corner case like` inputdim = 0` can be used to build a model by TensorFlow and save a corresponding model----even if this model is just a static graph. This may confuse users.\r\n\r\nAdditionally, adding a check for the illogical parameter is not a difficult job. As shown [here](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe), Tensorflow has previously fixed a similar problem that people can build a model when using `conv2d (kernel_size = 0). `", "Closing this since it has been fixed [here](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37777\">No</a>\n", "> Closing this since it has been fixed [here](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe).\r\n\r\nThank you for your reply! \r\nI wonder if you are using a wrong [link](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe)in your reply, because this link is the same as the one in my comments and it is related to the conv layer, not the Embedding. ", "> > Closing this since it has been fixed [here](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe).\r\n> \r\n> Thank you for your reply!\r\n> I wonder if you are using a wrong [link](https://github.com/tensorflow/tensorflow/commit/1e102f63964365d82d7f22402b7ba21e0e0e64fe)in your reply, because this link is the same as the one in my comments and it is related to the conv layer, not the Embedding.\r\n\r\nOh sorry, I meant to close another issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37777\">No</a>\n"]}, {"number": 37776, "title": "Potential bug in Tensorflow 1 integration with Jupyter notebook", "body": "When running the attached jupyter notebook example from [Manning book \"Tensorflow in action\"](https://www.manning.com/books/machine-learning-with-tensorflow) - I know there are some typos in the code but I correct them to make the code works - , I meet the following condition\r\n\r\n- When I run all steps for the first time, everything works fine \r\n\r\n- When I run the tf placeholder declaration twice\r\n\r\nCode[\r\nalpha = tf.constant(0.05)\r\ncurr_value = tf.placeholder(tf.float32)\r\nprev_avg = tf.Variable(0.)\r\n\r\nupdate_avg = alpha * curr_value + (1 - alpha) * prev_avg\r\n]\r\n\r\nthe session crashes with an error :\r\n\r\nCode[\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    writer.add_graph(sess.graph)\r\n    for i in range(len(raw_data)):\r\n        summary_str, curr_avg = sess.run([merged, update_avg], feed_dict={curr_value: raw_data[i]})\r\n        sess.run(tf.assign(prev_avg, curr_avg))\r\n        print(raw_data[i], curr_avg)\r\n        writer.add_summary(summary_str, i)\r\n]\r\n\r\nError message[\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-13-81676f6fb632> in <module>()\r\n      5     writer.add_graph(sess.graph)\r\n      6     for i in range(len(raw_data)):\r\n----> 7         summary_str, curr_avg = sess.run([merged, update_avg], feed_dict={curr_value: raw_data[i]})\r\n      8         sess.run(tf.assign(prev_avg, curr_avg))\r\n      9         print(raw_data[i], curr_avg)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    958     try:\r\n    959       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 960                          run_metadata_ptr)\r\n    961       if run_metadata:\r\n    962         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1181     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1182       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1183                              feed_dict_tensor, options, run_metadata)\r\n   1184     else:\r\n   1185       results = []\r\n...]\r\n\r\n**Workaround** : I have to restart kernel and clear all outputs to run the session again. \r\n\r\n**Possible cause** : either tensorflow or jupyter doesn't detect that placeholders have already been instantiated and instantiates them twice.\r\n\r\n**Environment** : docker TF container tensorflow/tensorflow:latest-gpu-jupyter\r\n\r\n[ch2Tensorboard.ipynb.txt](https://github.com/tensorflow/tensorflow/files/4362615/ch2Tensorboard.ipynb.txt)\r\n\r\n", "comments": ["@mdautrey, can you please share the full code or link of colab file to reproduce mentioned issue.", "I think that the full code is attached to my initial post https://github.com/tensorflow/tensorflow/files/4362615/ch2Tensorboard.ipynb.txt", "@mdautrey, I have checked this file by running on google colab and i found no issue. for your reference link of gist is [here](https://colab.research.google.com/gist/khimraj/cad75364418c3ea67c2193cca0544e06/ch2tensorboard.ipynb).", "When you run the code twice, you get the attached error, even on google colab\r\n![Capture du 2020-03-23 06-26-54](https://user-images.githubusercontent.com/6020351/77284667-81cdce00-6ccf-11ea-939d-49f5c2faa31a.png)\r\n", "when we run the code twice in colab i am able to reproduce the issue. Thanks!", "Try adding `tf.reset_default_graph()` before creating graph. That should help. Thanks!\r\n```python\r\ntf.reset_default_graph()\r\nalpha = tf.constant(0.05)\r\n...\r\n```", "It works! Thank you\r\nShould the documentation be updated accordingly ? (https://www.tensorflow.org/api_docs/python/tf/compat/v1/summary/FileWriter )", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37776\">No</a>\n"]}, {"number": 37775, "title": "fix a compile error of r2.1 caused by skylib address invalid.", "body": "fix a compile error of r2.1 caused by the invalid link of skylib.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37775) for more info**.\n\n<!-- need_author_cla -->", "@rhdong Can you please sign CLA ? Thanks!", "Please sign CLA and open against master and then cherry-pick here.\r\n\r\nIf master already works, we should cherry-pick the commit fixing there.\r\n\r\nNote that since this is against 2.1 branch we won't merge it until we need to do a patch release (for security reasons)", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37775) for more info**.\n\n<!-- ok -->", "We can only merge this when we do a patch release on the 2.1 release"]}, {"number": 37774, "title": "fix a compile error caused by skylib address invalid.", "body": "fix a compile error caused by Bazel_skylib address invalid.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37774) for more info**.\n\n<!-- need_author_cla -->", "The original link of skylib was invalid:\r\nhttps://github.com/bazelbuild/bazel-skylib/releases/download/0.9.0/bazel-skylib.0.9.0.tar.gz", "@googlebot I fixed it."]}, {"number": 37773, "title": "Fix compile error for r2.1", "body": "fix a compile error caused by the bazel_skylib link invalid.", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37773) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 37772, "title": "Compile error fix for2.1", "body": "fix the compile error caused by the bazel_skylib link invalid.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37772) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 37771, "title": "lite_demo", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37771) for more info**.\n\n<!-- need_sender_cla -->", "@Annonymous844 Can you please sign CLA ? Thanks!"]}, {"number": 37770, "title": "MSE loss computes different values depending on shape", "body": "**System information** \r\n- Have I written custom code:  yes\r\n- OS Platform and Distribution: Linux Ubuntu 19.04\r\n - TensorFlow version: 2.1.0\r\n- Python version: 3.7.5\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GTX Titan X\r\n\r\n**Describe the current behavior**\r\nWhen MSE is calculated on two vectors, if one has an additional dimension, the result is different. For instance if one is [128] and the other is [128,1] the final value is different than what is calculated with vectors containing the same values but both [128.].\r\nMoreover the score computed for the 4 combinations I tried ( `mse([128], [128[)`, `mse([128, 1], [128[)`, `mse([128], [128, 1])`, `mse([128, 1], [128, 1]`)  )are all different, so I don't really trust the computation at all, so there's likely a bug somewhere.\r\n\r\n**Describe the expected behavior**\r\nEither that the computation is performed correctly or that an error is raised about the inouts having different shapes. Silent errors like this are difficult to debug.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntargets = np.array([180.858, -53.000732, 161.95107, 135.10085, -5.4330907, -86.42976, -4.4581985, -32.90381, -153.1223, -78.94036, 190.12129, -157.32057, -8.215049, -17.959564, -21.816954, 40.21217, -50.351727, 38.70819, 52.955853, 213.77878, -142.41376, 127.22313, 164.2927, -74.497314, -74.87329, 14.303827, 164.1599, 190.37862, -63.337723, 74.058975, -70.482285, -40.203323, -47.59432, -17.782892, 70.3338, -127.87029, -12.542, -31.236902, 70.227974, -81.60634, -186.79362, -176.01068, -118.73177, -74.14537, -56.437016, 98.60682, -3.1523242, 9.694114, -11.809049, -16.225067, -4.6299715, -194.44075, -138.53864, -118.06511, -201.88641, -85.310356, 91.92171, 107.94937, -44.26706, -93.79351, -9.981134, 40.544876, 131.26842, 7.305799, -97.13315, 94.43779, 146.48007, -24.092182, 32.081444, 32.98506, 93.73731, 65.58341, 36.74394, 57.02824, -78.452866, -6.0548353, -11.639992, 114.853455, -15.473761, -24.454018, -127.82523, 68.350876, -41.449036, 39.643234, -45.420197, -0.9474962, -111.20463, -10.079266, -79.32773, -93.07437, -111.04116, -47.006187, -68.18549, 36.195724, 100.86029, -74.86413, -13.0117655, 293.18875, 39.411587, 121.270706, -142.66888, 23.961506, 81.58176, -137.42886, 31.068184, 73.448364, -90.646164, 133.64107, 88.79693, -117.37866, 54.3003, -181.60715, 100.147194, 179.99359, 24.455635, 59.38088, 135.56046, 67.400925, 151.78516, 212.14339, -202.64584, 66.06116, 1.9135226, -244.05527, -70.778275, -50.001457, -194.73297, 33.012333])\r\npredictions = np.array([0.12198464, 0.09282801, 0.09430753, 0.06222287, 0.07448876, 0.03799684, 0.02936049, 0.03837839, 0.04432172, 0.01919999, 0.07735521, 0.04389271, 0.09087924, 0.05364547, 0.01343504, 0.04935993, 0.02090639, 0.04636865, 0.06702548, 0.09186736, 0.11273132, 0.0611049 , 0.06820674, 0.07969542, 0.02481739, 0.04868209, 0.08474196, 0.0776654 , 0.03664336, 0.04501346, 0.06626878, 0.03605408, 0.02785883, 0.01698643, 0.09615672, 0.07914701, 0.02611066, 0.0447035 , 0.08619086, 0.04838634, 0.07977191, 0.06319098, 0.04025086, 0.05129454, 0.02673621, 0.05525842, 0.0054835 , 0.04647385, 0.02476176, 0.02783814, 0.11566448, 0.08409265, 0.03792451, 0.03227585, 0.0632838 , 0.08329175, 0.04616582, 0.06513302, 0.07169756, 0.05911999, 0.05913429, 0.01704707, 0.06693612, 0.04886937, 0.02549478, 0.04468452, 0.07630262, 0.05455045, 0.06637821, 0.01789702, 0.11108026, 0.03976684, 0.0171865 , 0.13416564, 0.02845822, 0.05074854, 0.04896633, 0.05221288, 0.03563176, 0.05014472, 0.05413034, 0.0347496 , 0.0645119 , 0.04159546, 0.01868404, 0.0582131 , 0.0336203 , 0.04432501, 0.03495208, 0.02673723, 0.09592278, 0.02579375, 0.01584711, 0.02812203, 0.03840974, 0.02530819, 0.08957738, 0.14304015, 0.03345468, 0.06080145, 0.09284427, 0.04770067, 0.07064755, 0.04004309, 0.02097335, 0.08742893, 0.04389744, 0.0479476 , 0.05911161, 0.0748862 , 0.06840549, 0.0580482 , 0.05427855, 0.10075781, 0.01691986, 0.04473659, 0.0634447 , 0.03176469, 0.05624699, 0.12614223, 0.08688905, 0.02355402, 0.0871409 , 0.0734048 , 0.02676748, 0.02766727, 0.08999605, 0.03465028])\r\n\r\nmse = tf.keras.losses.MeanSquaredError()\r\n\r\ntf.config.experimental_run_functions_eagerly(True)\r\n\r\nprint(mse(targets, predictions))\r\nprint(mse(targets[:, tf.newaxis], predictions))\r\nprint(mse(targets, predictions[:, tf.newaxis]))\r\nprint(mse(targets[:, tf.newaxis], predictions[:, tf.newaxis]))\r\n```\r\nOutput:\r\n```\r\ntf.Tensor(10867.5537109375, shape=(), dtype=float64)\r\ntf.Tensor(10868.94140625, shape=(), dtype=float64)\r\ntf.Tensor(10868.9404296875, shape=(), dtype=float64)\r\ntf.Tensor(10867.552734375, shape=(), dtype=float64)\r\n```", "comments": ["Could this be related to #28225?", "Was able to reproduce the issue with [TF-2.1](https://colab.research.google.com/gist/amahendrakar/1c82e750d3c5d3b46e246180dbef5c3e/37770-2-1.ipynb), [TF-2.2.0-rc1](https://colab.research.google.com/gist/amahendrakar/77905c56ccd5e6c480f82c65a6df1bb7/37770-2-2.ipynb#scrollTo=PIefRvmaYI1k) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/829a6b6b7ab2d88a01d3d89a129bd7fd/37770-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@w4nderlust MSE loss expects inputs with the shape `[batch_size, d0, .. dN]`. The inputs must be atleast 2D. The function computes a mean along all except the batch axis, so the result you get will be one loss value per sample.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE?version=nightly", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37770\">No</a>\n", "It's a silent error, terrible to debug. The mismatch of dimensions should be cought and reported to the user."]}]