[{"number": 45405, "title": "Compilation Problems", "body": "**System information**\r\n- Manjaro 5.9\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 3.2.1\r\n- Python version: 3.8.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.7\r\n- GCC/Compiler version (if compiling from source): 10.2\r\n- CUDA/cuDNN version: 11.1.1\r\n- GPU model and memory: asus radeon 560 4gb\r\n\r\n\r\n\r\n**Describe the problem**\r\nbuild fail\r\nIt's the same issue like  #41362 but it's back. I didn't comment on the other one since it's pretty old now and nobody would notice...\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\npkgname=llvm-amdgpu\r\npkgdesc='Radeon Open Compute - LLVM toolchain (llvm, clang, lld)'\r\npkgver=3.10.0\r\npkgrel=1\r\narch=('x86_64')\r\nurl='https://github.com/RadeonOpenCompute/llvm-project'\r\nlicense=('custom:Apache 2.0 with LLVM Exception')\r\ndepends=(z3)\r\nmakedepends=(cmake python ninja)\r\nsource=(\"${pkgname}-${pkgver}.tar.gz::$url/archive/rocm-$pkgver.tar.gz\")\r\nsha256sums=('8262aff88c1ff6c4deb4da5a4f8cda1bf90668950e2b911f93f73edaee53b370')\r\n_dirname=\"$(basename \"$url\")-$(basename \"${source[0]}\" .tar.gz)\"\r\n\r\nbuild() {\r\n    cmake -GNinja -Wno-dev -S \"$_dirname/llvm\" \\\r\n          -DCMAKE_INSTALL_PREFIX='/opt/rocm/llvm' \\\r\n          -DCMAKE_BUILD_TYPE=Release \\\r\n          -DLLVM_HOST_TRIPLE=$CHOST \\\r\n          -DLLVM_BUILD_UTILS=ON \\\r\n          -DLLVM_ENABLE_BINDINGS=OFF \\\r\n          -DLLVM_ENABLE_OCAMLDOC=OFF \\\r\n          -DLLVM_ENABLE_PROJECTS='llvm;clang;compiler-rt;lld' \\\r\n          -DLLVM_TARGETS_TO_BUILD='AMDGPU;X86' \\\r\n          -DOCAMLFIND=NO\r\n    ninja\r\n}\r\n```\r\nThanks!\r\n\r\n", "comments": ["@UltraBlackLinux,\r\n\r\nCan you try installing the latest stable version of tensorflow i.e `2.6.0` and lets us know if the issue still persists? You can follow this [guide](https://www.tensorflow.org/install/source#tested_build_configurations) to build from source. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45405\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45405\">No</a>\n"]}, {"number": 45404, "title": "Make TensorFlow build on Apple Silicon", "body": "The apple developers gave me the approval to upstream this patch that makes TensorFlow build on Apple Silicon.\r\n\r\nThe build works with the following setup:\r\n\r\nBazel: x86_64 3.7.1 through Rosetta\r\nPython: 3.8.2 You can setup up a Python virtual environment and install all the pip dependencies built for arm64 following the instruction at https://github.com/apple/tensorflow_macos#details\r\nXcode version: 12.3\r\n\r\nthen you can build TensorFlow on Apple Silicon with\r\n```\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nRelated: https://github.com/tensorflow/tensorflow/issues/44751\r\n\r\n", "comments": ["/cc @mihaimaruseac ", "Thanks for sharing the patch. I tried building it, but got this error. I'm using a custom bazel build for aarch64 M1\r\nWhat bazel version did you use exactly? Any idea how to get around the error below?\r\n\r\n~~~~~~~~~~~~~~~~\r\n\r\ngit clone https://github.com/meteorcloudy/tensorflow.git\r\ngit checkout apple_silicon_build\r\nbazel --version\r\nbazel 3.7.1- (@non-git)\r\nfile bazel\r\nbazel: Mach-O 64-bit executable arm64\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/erwincoumans/dev/tensorflow/WORKSPACE:16:10: in <toplevel>\r\n  /Users/erwincoumans/dev/tensorflow/tensorflow/workspace0.bzl:65:34: in workspace\r\n  /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Repository llvm-project instantiated at:\r\n  /Users/erwincoumans/dev/tensorflow/WORKSPACE:12:10: in <toplevel>\r\n  /Users/erwincoumans/dev/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace\r\n  /Users/erwincoumans/dev/tensorflow/tensorflow/workspace.bzl:694:20: in tf_repositories\r\nRepository rule tf_http_archive defined at:\r\n  /Users/erwincoumans/dev/tensorflow/third_party/repo.bzl:131:34: in <toplevel>\r\nERROR: While resolving toolchains for target //tensorflow/tools/build_info:gen_build_info: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.\r\nINFO: Elapsed time: 23.039s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (234 packages loaded, 4212 targets configured)\r\n    Fetching @aws; fetching 17s\r\n    Fetching ...al/aws; Extracting /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/aws/temp70658729637\\\r\n7396577/1.7.336.tar.gz 5s\r\n\r\n~~~~~~~~~~~~~~~~\r\n\r\n", "Interesting, how did you build Bazel for arm64? Maybe you can share your patch and help fixing https://github.com/bazelbuild/bazel/issues/11628? \ud83d\ude03\r\n\r\nI'm running Bazel 3.7.1 built for x86_64 under the emulator on an Apple Silicon DTK. Not sure if it's the custom patch that caused the problem, it would be very helpful if you could share the patch. Also can you add `--announce_rc` and `--debug_toolchain_resolution` to print more info for debugging?", ">> I'm running Bazel 3.7.1 built for x86_64 under the emulator on an Apple Silicon DTK.\r\n\r\nWould it be possible to share a compiled wheel of Tensorflow cpu for python 3.9 for macosx-arm64 / M1?\r\n\r\n> Interesting, how did you build Bazel for arm64? Maybe you can share your patch and help fixing [bazelbuild/bazel#11628](https://github.com/bazelbuild/bazel/issues/11628)? \ud83d\ude03\r\n> \r\n> I'm running Bazel 3.7.1 built for x86_64 under the emulator on an Apple Silicon DTK. Not sure if it's the custom patch that caused the problem, it would be very helpful if you could share the patch. Also can you add `--announce_rc` and `--debug_toolchain_resolution` to print more info for debugging?\r\n\r\nI build bazel from source and used the Zulu Java JDK, download zulu13.35.1017-ca-jdk13.0.5.1-macos_aarch64.dmg from\r\nhttps://www.azul.com/downloads/zulu-community/?package=jdk\r\nThen use this to build bazel from source.\r\n~~~~~~~~~~~~~~\r\nenv EXTRA_BAZEL_ARGS=\"--host_javabase=@local_jdk//:jdk\" bash ./compile.sh\r\n~~~~~~~~~~~~~~\r\n\r\nNo patch needed from the release package, except for a minor one (which is already fixed in master( I downloaded the latest bazel release, instead of using git clone)\r\n\r\n~~~~~~~~~~~~~\r\nprivate FileSystem getJarFileSystem(Path sourceJar) throws IOException {\r\n     FileSystem fs = filesystems.get(sourceJar);\r\n     if (fs == null) {\r\n-      filesystems.put(sourceJar, fs = FileSystems.newFileSystem(sourceJar, null));\r\n+      java.lang.ClassLoader nullClassLoader = null;\r\n+      filesystems.put(sourceJar, fs = FileSystems.newFileSystem(sourceJar, nullClassLoader));\r\n     }\r\n     return fs;\r\n   }\r\n~~~~~~~~~~~~~\r\n\r\nHere is a precompiled binary for macos-arm64:\r\nhttps://github.com/erwincoumans/bazel/releases/tag/bazel-3.7.1-mac-arm64\r\n\r\n", "@erwincoumans I spent some time debugging this issue.\r\n\r\nIt turned out TF detects the execution platform info at \r\nhttps://github.com/tensorflow/tensorflow/blob/b34e7144ed6dd0ab51c03df783aa14009589e800/third_party/remote_config/remote_platform_configure.bzl#L15\r\n\r\n`\"bash\", \"-c\", \"echo $MACHTYPE\"` returns `x86_64-apple-darwin20` for the x86 Bazel binary, but `arm64-apple-darwin20` for the arm64 Bazel binary.\r\n\r\n<del>However, inside Bazel's auto configured cc toolchain, we only currently [only registered the x86_64 toolchain for mac](https://cs.opensource.google/bazel/bazel/+/master:tools/osx/crosstool/BUILD.toolchains;l=5?q=%22OSX_DEVELOPER_PLATFORM_CPUS%22&ss=bazel).</del>\r\n\r\nThis needs some tweaks from both Bazel side and TF's side, I'll send some PRs to make it work. In the meantime, you can use the x86_64 Bazel binary to build TF on Apple Silicon.", "> Would it be possible to share a compiled wheel of Tensorflow cpu for python 3.9 for macosx-arm64 / M1?\r\n\r\nApple released the prebuilt TF artifacts here: https://github.com/apple/tensorflow_macos/releases", "Oh, aarch64 is actually arm64, in this case, we just have to fix TF's  remote_platform_configure.bzl to return `aarch64` when the `MACHTYPE` is `arm64-apple-darwin20`", "> > Would it be possible to share a compiled wheel of Tensorflow cpu for python 3.9 for macosx-arm64 / M1?\r\n> \r\n> Apple released the prebuilt TF artifacts here: https://github.com/apple/tensorflow_macos/releases\r\n\r\nthat artifact is using python 3.8, I am looking for a buid using Python 3.9...", "> that artifact is using python 3.8, I am looking for a buid using Python 3.9...\r\n\r\nSorry, I also only have Python 3.8 installed.\r\n\r\nWith the latest commit, your arm64 Bazel binary should work now, please give it a try!", "> > that artifact is using python 3.8, I am looking for a buid using Python 3.9...\r\n> \r\n> Sorry, I also only have Python 3.8 installed.\r\n> \r\n> With the latest commit, your arm64 Bazel binary should work now, please give it a try!\r\n\r\nThanks for looking into this. Using your branch, I tried it but another error:\r\n\r\n~~~~~~~~\r\n(base) erwincoumans@erwins-mbp tensorflow % bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=187\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/ruy/archive/4790797d11a81f96baf24f3731fd3ca44c2c5f8b.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nERROR: /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'\r\nINFO: Repository llvm-project instantiated at:\r\n  /Users/erwincoumans/dev/tensorflow/WORKSPACE:12:10: in <toplevel>\r\n  /Users/erwincoumans/dev/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace\r\n  /Users/erwincoumans/dev/tensorflow/tensorflow/workspace.bzl:694:20: in tf_repositories\r\nRepository rule tf_http_archive defined at:\r\n  /Users/erwincoumans/dev/tensorflow/third_party/repo.bzl:131:34: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 9.994s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (323 packages loaded, 6526 targets configured)\r\n    currently loading: @ruy//ruy\r\n    Fetching @aws; fetching 6s\r\n    Fetching ...bee05577c94eee86b3d/external/aws; Extracting /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/aws/temp6199003864755386776/1.7.336.tar.gz 6s\r\n    Fetching @local_config_git; fetching\r\n    Fetching @cython; fetching\r\n    Fetching ...05577c94eee86b3d/external/cython; Extracting /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/cython/temp7481483442566961919/0.29.21.tar.gz\r\n~~~~~~~~\r\n\r\nWhen not using any arguments, the following error appears:\r\n~~~~~~~~~~~\r\n(base) erwincoumans@erwins-mbp tensorflow %  bazel build  tensorflow/tools/pip_package:build_pip_package \r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=187\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Build options --cpu and --define have changed, discarding analysis cache.\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/ruy/archive/4790797d11a81f96baf24f3731fd3ca44c2c5f8b.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/db226cdf4cf91f350267da1a5b95dda42dd23413.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (84 packages loaded, 30267 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/cpuinfo/BUILD.bazel:96:11: C++ compilation of rule '@cpuinfo//:cpuinfo_impl' failed (Exit 1): cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 34 argument(s) skipped)\r\nIn file included from external/cpuinfo/src/x86/isa.c:5:\r\nIn file included from external/cpuinfo/src/x86/cpuid.h:5:\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:11:2: error: this header is for x86 only\r\n#error this header is for x86 only\r\n ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:271:5: error: invalid output constraint '=a' in asm\r\n    __cpuid(__leaf, __eax, __ebx, __ecx, __edx);\r\n    ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:286:5: error: invalid output constraint '=a' in asm\r\n    __cpuid(__leaf, *__eax, *__ebx, *__ecx, *__edx);\r\n    ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:300:5: error: invalid output constraint '=a' in asm\r\n    __cpuid_count(__leaf, __subleaf, *__eax, *__ebx, *__ecx, *__edx);\r\n    ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:243:11: note: expanded from macro '__cpuid_count'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/isa.c:5:\r\nexternal/cpuinfo/src/x86/cpuid.h:30:5: error: invalid output constraint '=a' in asm\r\n                                __cpuid(eax, regs.eax, regs.ebx, regs.ecx, regs.edx);\r\n                                ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/isa.c:5:\r\nexternal/cpuinfo/src/x86/cpuid.h:56:5: error: invalid output constraint '=a' in asm\r\n                                __cpuid_count(eax, ecx, regs.eax, regs.ebx, regs.ecx, regs.edx);\r\n                                ^\r\n/Library/Developer/CommandLineTools/usr/lib/clang/12.0.0/include/cpuid.h:243:11: note: expanded from macro '__cpuid_count'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/isa.c:5:\r\nexternal/cpuinfo/src/x86/cpuid.h:75:38: error: invalid output constraint '=a' in asm\r\n                __asm__(\".byte 0x0F, 0x01, 0xD0\" : \"=a\" (lo), \"=d\" (hi) : \"c\" (ext_ctrl_reg));\r\n                                                   ^\r\nexternal/cpuinfo/src/x86/isa.c:38:24: error: incomplete result type 'struct cpuinfo_x86_isa' in function definition\r\nstruct cpuinfo_x86_isa cpuinfo_x86_detect_isa(\r\n                       ^\r\nexternal/cpuinfo/src/x86/api.h:92:25: note: forward declaration of 'struct cpuinfo_x86_isa'\r\nCPUINFO_INTERNAL struct cpuinfo_x86_isa cpuinfo_x86_detect_isa(\r\n                        ^\r\nexternal/cpuinfo/src/x86/isa.c:43:25: error: variable has incomplete type 'struct cpuinfo_x86_isa'\r\n        struct cpuinfo_x86_isa isa = { 0 };\r\n                               ^\r\nexternal/cpuinfo/src/x86/api.h:92:25: note: forward declaration of 'struct cpuinfo_x86_isa'\r\nCPUINFO_INTERNAL struct cpuinfo_x86_isa cpuinfo_x86_detect_isa(\r\n                        ^\r\n9 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /Users/erwincoumans/dev/tensorflow/tensorflow/python/tools/BUILD:99:10 C++ compilation of rule '@cpuinfo//:cpuinfo_impl' failed (Exit 1): cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 34 argument(s) skipped)\r\nINFO: Elapsed time: 329.169s, Critical Path: 47.70s\r\nINFO: 3773 processes: 949 internal, 2824 local.\r\nFAILED: Build did NOT complete successfully\r\n~~~~~~~~~~~\r\n\r\nIt can be reproduced using miniconda3 and python 3.9.\r\n", "> \r\n```\r\nERROR: /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'\r\n```\r\n\r\nThis is weird,, are you sure you're using Bazel 3.7.1?", "> ```\r\n> ERROR: /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'\r\n> ```\r\n> \r\n> \r\n> This is weird,, are you sure you're using Bazel 3.7.1?\r\n\r\nYes, confirmed bazel 3.7.1 arm64 build. I shared the binary, so you can easily reproduce the issue.", "> Yes, confirmed bazel 3.7.1 arm64 build. I shared the binary, so you can easily reproduce the issue.\r\n\r\nI'm using the exactly same binary, but the build is working fine.\r\n\r\n```\r\npcloudy@Yuns-Mac:~/workspace/tensorflow\r\n$ bazel --version\r\nbazel 3.7.1- (@non-git)\r\npcloudy@Yuns-Mac:~\r\n$ lipo -info $(which bazel)\r\nNon-fat file: /Users/pcloudy/bin/bazel is architecture: arm64\r\npcloudy@Yuns-Mac:~/workspace/tensorflow\r\n$ bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: c669f7e5-7f0c-4bbf-a934-466a753d6883\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=167\r\nINFO: Reading rc options for 'build' from /Users/pcloudy/workspace/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/pcloudy/workspace/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /Users/pcloudy/workspace/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/pcloudy/tensorflow_macos_venv/bin/python3 --action_env PYTHON_LIB_PATH=/Users/pcloudy/tensorflow_macos_venv/lib/python3.8/site-packages --python_path=/Users/pcloudy/tensorflow_macos_venv/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Reading rc options for 'build' from /Users/pcloudy/.bazelrc:\r\n  'build' options: --verbose_failures --announce_rc --disk_cache=/tmp/bazel_disk_cache --repository_cache=/tmp/bazel_repository_cache\r\nINFO: Found applicable config definition build:short_logs in file /Users/pcloudy/workspace/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/pcloudy/workspace/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/pcloudy/workspace/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/pcloudy/workspace/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/pcloudy/workspace/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/ruy/archive/4790797d11a81f96baf24f3731fd3ca44c2c5f8b.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/pcloudy/workspace/tensorflow/WORKSPACE:16:10: in <toplevel>\r\n  /Users/pcloudy/workspace/tensorflow/tensorflow/workspace0.bzl:65:34: in workspace\r\n  /private/var/tmp/_bazel_pcloudy/a8de6f5ff515c9bc955ea284e27a7f1e/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_pcloudy/a8de6f5ff515c9bc955ea284e27a7f1e/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nWARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/db226cdf4cf91f350267da1a5b95dda42dd23413.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (411 packages loaded, 31587 targets configured).\r\nINFO: Found 1 target...\r\n[753 / 1,333] 16 actions running\r\n    Compiling tensorflow/core/profiler/convert/xplane_to_tf_data_stats.cc [for host]; 7s local, remote-cache\r\n    Compiling tensorflow/core/profiler/protobuf/pod_viewer.pb.cc [for host]; 3s local, remote-cache\r\n    Compiling tensorflow/core/profiler/convert/op_stats_to_pod_stats.cc [for host]; 2s local, remote-cache\r\n    Compiling tensorflow/core/profiler/utils/xplane_utils.cc [for host]; 2s local, remote-cache\r\n    Compiling tensorflow/core/profiler/protobuf/steps_db.pb.cc [for host]; 2s local, remote-cache\r\n```", "Can you print the content of `/private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD` and `/private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc_toolchains/osx_archs.bzl` ?", "> Can you print the content of `/private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD` and `/private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc_toolchains/osx_archs.bzl` ?\r\n\r\n\r\n[build.zip](https://github.com/tensorflow/tensorflow/files/5660771/build.zip)\r\n\r\nSure, attached is a build.zip\r\n\r\nWhat python version do you use? Any change you could try the combo\r\nminiconda3+python3.9?", "> What python version do you use? Any change you could try the combo\r\nminiconda3+python3.9?\r\n\r\nI'm using the native python installed which is 3.8, however, from the error message, the python version is unlikely the problem.", "Hmm, I suspect you don't have xcode installed?  \r\nWhat is the output of `xcode-select -p`?", "What was happening on your machine is that `should_use_xcode or xcode_toolchains` was false at https://cs.opensource.google/bazel/bazel/+/master:tools/cpp/cc_configure.bzl;l=71 when Bazel tries to auto configure the cc toolchain.", "> Hmm, I suspect you don't have xcode installed?\r\n> What is the output of `xcode-select -p`?\r\n\r\nOnly command-line tools, no full Xcode, why is that required? Output of xcode-select -p is\r\n~~~~~~~~~~~~~~\r\n/Library/Developer/CommandLineTools\r\n~~~~~~~~~~~~~~\r\n\r\n", "Note that we don't yet have a py3.9 supported build.", "Installed Xcode 12.2, using default Python 3.8 and bazel arm64, still the same errors,\r\neither using \r\n~~~~~~~~~~~~~~~~\r\nerwincoumans@erwins-mbp tensorflow % xcode-select -p\r\n/Applications/Xcode.app/Contents/Developer\r\nerwincoumans@erwins-mbp tensorflow % bazel --version\r\nbazel 3.7.1- (@non-git)\r\nerwincoumans@erwins-mbp tensorflow % file $(which bazel)\r\n/opt/homebrew/bin/bazel: Mach-O 64-bit executable arm64\r\nerwincoumans@erwins-mbp tensorflow % bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=183\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/erwincoumans/dev/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Build options --cpu and --define have changed, discarding analysis cache.\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/db226cdf4cf91f350267da1a5b95dda42dd23413.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/ruy/archive/4790797d11a81f96baf24f3731fd3ca44c2c5f8b.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nERROR: /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/local_config_cc/BUILD:\r\n[build2.zip](https://github.com/tensorflow/tensorflow/files/5661752/build2.zip)\r\n48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 0.398s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 3353 targets configured)\r\n\r\n~~~~~~~~~~~~~~~~", "@erwincoumans I finally got my Macbook Air with M1 chip today. I can reproduce the exact issue, and it is fixed after installing Xcode 12.2 from the App Store.\r\nNote that, you have to run `sudo xcodebuild -license` to sign the license to actually enable xcode.\r\n\r\n> Only command-line tools, no full Xcode, why is that required? \r\n\r\nIt's just in Bazel's [auto config logic](https://cs.opensource.google/bazel/bazel/+/master:tools/cpp/cc_configure.bzl;l=71), we use different BUILD files for the cc toolchain depends on the availability of Xcode, and only the BUILD file with Xcode has the correct setup for darwin_arm64 toolchain.. We probably can fix this issue in Bazel. FYI @keith @dmaclach \r\n\r\n", "> @erwincoumans I finally got my Macbook Air with M1 chip today. I can reproduce the exact issue, and it is fixed after installing Xcode 12.2 from the App Store.\r\n> Note that, you have to run `sudo xcodebuild -license` to sign the license to actually enable xcode.\r\n> \r\n> > Only command-line tools, no full Xcode, why is that required?\r\n> \r\n> It's just in Bazel's [auto config logic](https://cs.opensource.google/bazel/bazel/+/master:tools/cpp/cc_configure.bzl;l=71), we use different BUILD files for the cc toolchain depends on the availability of Xcode, and only the BUILD file with Xcode has the correct setup for darwin_arm64 toolchain.. We probably can fix this issue in Bazel. FYI @keith @dmaclach\r\n\r\nI keep on getting build errors, even after installing Xcode 12.2 and running the sudo xcodebuild -license with 'agree' at the end,\r\neither with bazel arm64 or bazel x86_64, with or without the --config=macos_arm64\r\n\r\nCan you create a build on the M1?\r\n\r\n~~~~~~~~~~~~~\r\nerwincoumans@erwins-mbp ~ % which python3\r\n/usr/bin/python3\r\nerwincoumans@erwins-mbp ~ % python3 --version\r\nPython 3.8.2\r\ngit clone https://github.com/meteorcloudy/tensorflow\r\ncd tensorflow\r\ngit checkout apple_silicon_build\r\n~~~~~~~~~~~~~~\r\n\r\n~~~~~~~~~~~~~~\r\ngit log\r\n\r\ncommit f21e391bd9f28f464476bf8d66e823f3b93d5cf9 (HEAD -> apple_silicon_build, origin/apple_silicon_build)\r\nAuthor: Yun Peng <pcloudy@google.com>\r\nDate:   Tue Dec 8 17:13:16 2020 +0100\r\n\r\n    local_execution_config_platform: return correct cpu value for arm64 platform\r\n\r\ncommit 0ce88e87bd726deadf63e7955db3a5e77459afd7\r\nAuthor: Yun Peng <pcloudy@google.com>\r\nDate:   Fri Dec 4 15:17:29 2020 +0100\r\n\r\n    Clean redundant config_setting\r\n\r\ncommit 10491ccc34fad8297bc830fd91a2714a1926d149\r\nAuthor: Yun Peng <pcloudy@google.com>\r\nDate:   Fri Dec 4 15:11:48 2020 +0100\r\n\r\n    Remove config_setting for darwin_arm64e for now\r\n\r\n~~~~~~~~~~~~~~\r\nnow\r\n~~~~~~~~~~~~~~\r\nerwincoumans@erwins-mbp tensorflow % bazel_arm --version\r\nbazel 3.7.1- (@non-git)\r\nerwincoumans@erwins-mbp tensorflow % sudo file $(which bazel_arm)\r\n/opt/homebrew/bin/bazel_arm: Mach-O 64-bit executable arm64\r\n\r\n\r\nerwincoumans@erwins-mbp tensorflow % bazel_arm build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=204\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/erwincoumans/dev/aargh/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Repository local_execution_config_python instantiated at:\r\n  /Users/erwincoumans/dev/aargh/tensorflow/WORKSPACE:12:10: in <toplevel>\r\n  /Users/erwincoumans/dev/aargh/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace\r\n  /Users/erwincoumans/dev/aargh/tensorflow/tensorflow/workspace.bzl:90:27: in tf_repositories\r\n  /Users/erwincoumans/dev/aargh/tensorflow/third_party/toolchains/remote_config/configs.bzl:6:28: in initialize_rbe_configs\r\n  /Users/erwincoumans/dev/aargh/tensorflow/third_party/toolchains/remote_config/rbe_config.bzl:158:27: in _tensorflow_local_config\r\nRepository rule local_python_configure defined at:\r\n  /Users/erwincoumans/dev/aargh/tensorflow/third_party/py/python_configure.bzl:275:41: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_execution_config_python':\r\n   Traceback (most recent call last):\r\n\tFile \"/Users/erwincoumans/dev/aargh/tensorflow/third_party/py/python_configure.bzl\", line 213, column 39, in _create_local_python_repository\r\n\t\tnumpy_include = _get_numpy_include(repository_ctx, python_bin) + \"/numpy\"\r\n\tFile \"/Users/erwincoumans/dev/aargh/tensorflow/third_party/py/python_configure.bzl\", line 187, column 19, in _get_numpy_include\r\n\t\treturn execute(\r\n\tFile \"/Users/erwincoumans/dev/aargh/tensorflow/third_party/remote_config/common.bzl\", line 217, column 13, in execute\r\n\t\tfail(\r\nError in fail: Problem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nINFO: Repository go_sdk instantiated at:\r\n  /Users/erwincoumans/dev/aargh/tensorflow/WORKSPACE:16:10: in <toplevel>\r\n  /Users/erwincoumans/dev/aargh/tensorflow/tensorflow/workspace0.bzl:77:20: in workspace\r\n  /private/var/tmp/_bazel_erwincoumans/16c6b103447f879a3f1d7f55ae96aaff/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps\r\n  /private/var/tmp/_bazel_erwincoumans/16c6b103447f879a3f1d7f55ae96aaff/external/io_bazel_rules_go/go/toolchain/toolchains.bzl:379:28: in go_register_toolchains\r\n  /private/var/tmp/_bazel_erwincoumans/16c6b103447f879a3f1d7f55ae96aaff/external/io_bazel_rules_go/go/private/sdk.bzl:65:21: in go_download_sdk\r\nRepository rule _go_download_sdk defined at:\r\n  /private/var/tmp/_bazel_erwincoumans/16c6b103447f879a3f1d7f55ae96aaff/external/io_bazel_rules_go/go/private/sdk.bzl:53:35: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Problem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nINFO: Elapsed time: 0.480s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (1 packages loaded, 0 targets configured)\r\n    Fetching @local_config_cc_toolchains; fetching\r\n    Fetching @local_config_python; fetching\r\n    Fetching @io_bazel_rules_docker; Cloning 251f6a68b439744094faff800cd029798edf9faa of https://github.com/bazelbuild/rules_docker.git\r\n\r\n~~~~~~~~~~~~~~\r\n\r\nThe system python3.8 has no numpy and running pip3 install numpy results in errors. Can you describe all the steps, what version of python3 and how to install the dependencies (numpy etc) and some version info (output of pip list)?\r\n\r\n", "There are some upstream issues you can track about apple silicon support https://github.com/bazelbuild/bazel/issues/11628 at this point I wouldn't expect you to be able to get a build unless at the very least you're using HEAD bazel. The easiest way to do that would be `USE_BAZEL_VERISON=last_green` with [bazelisk](https://github.com/bazelbuild/bazelisk) but there are still quite a few patches landing upstream to iron out issues", "> The system python3.8 has no numpy and running pip3 install numpy results in errors. Can you describe all the steps, what version of python3 and how to install the dependencies (numpy etc) and some version info (output of pip list)?\r\n\r\n@erwincoumans  Please check the description of this PR:\r\n\r\n> You can setup up a Python virtual environment and install all the pip dependencies built for arm64 following the instruction here: https://github.com/apple/tensorflow_macos#details\r\n\r\n\r\n", "> There are some upstream issues you can track about apple silicon support [bazelbuild/bazel#11628](https://github.com/bazelbuild/bazel/issues/11628) at this point I wouldn't expect you to be able to get a build unless at the very least you're using HEAD bazel. The easiest way to do that would be `USE_BAZEL_VERISON=last_green` with [bazelisk](https://github.com/bazelbuild/bazelisk) but there are still quite a few patches landing upstream to iron out issues\r\n\r\nThanks,I understand this is all work-in-progress, I'm comfortable with that. Yes, I'm building bazel for arm64 from source using Zulu JDK for arm, and it produces a build that works just fine, at least for other projects. As you suggested, I will switch to HEAD.\r\n\r\n> @erwincoumans Please check the description of this PR:\r\n\r\nOK sounds good, I will activate that virtualenv on my M1 machine. I thought you were using native python 3.8, but I suppose that was on an Intel Mac, rather than on M1 Mac (from your previous comment).\r\n\r\n>> I'm using the native python installed which is 3.8", "@erwincoumans I was using native python 3.8 on an Apple DTK with the virtual environment setup provided by Apple.", "even node.js and python are not ready for apple mac with m1 yet\r\n\r\nthis request is totally pointless", "@meteorcloudy  Can you please fix build failures ? Thanks!", "> Thanks for sharing the patch. I tried building it, but got this error. I'm using a custom bazel build for aarch64 M1\r\n> What bazel version did you use exactly? Any idea how to get around the error below?\r\n> \r\n> ```\r\n> \r\n> git clone https://github.com/meteorcloudy/tensorflow.git\r\n> git checkout apple_silicon_build\r\n> bazel --version\r\n> bazel 3.7.1- (@non-git)\r\n> file bazel\r\n> bazel: Mach-O 64-bit executable arm64\r\n> bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n> \r\n> DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\n> DEBUG: Repository io_bazel_rules_docker instantiated at:\r\n>   /Users/erwincoumans/dev/tensorflow/WORKSPACE:16:10: in <toplevel>\r\n>   /Users/erwincoumans/dev/tensorflow/tensorflow/workspace0.bzl:65:34: in workspace\r\n>   /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\n> Repository rule git_repository defined at:\r\n>   /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\n> INFO: Repository llvm-project instantiated at:\r\n>   /Users/erwincoumans/dev/tensorflow/WORKSPACE:12:10: in <toplevel>\r\n>   /Users/erwincoumans/dev/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace\r\n>   /Users/erwincoumans/dev/tensorflow/tensorflow/workspace.bzl:694:20: in tf_repositories\r\n> Repository rule tf_http_archive defined at:\r\n>   /Users/erwincoumans/dev/tensorflow/third_party/repo.bzl:131:34: in <toplevel>\r\n> ERROR: While resolving toolchains for target //tensorflow/tools/build_info:gen_build_info: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.\r\n> ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.\r\n> INFO: Elapsed time: 23.039s\r\n> INFO: 0 processes.\r\n> FAILED: Build did NOT complete successfully (234 packages loaded, 4212 targets configured)\r\n>     Fetching @aws; fetching 17s\r\n>     Fetching ...al/aws; Extracting /private/var/tmp/_bazel_erwincoumans/0233a5588e71ebee05577c94eee86b3d/external/aws/temp70658729637\\\r\n> 7396577/1.7.336.tar.gz 5s\r\n> ```\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nerror:\r\ndyld: Symbol not found: _aes_hw_cbc_encrypt", "Update two findings while trying to get TF up and running on Apple Silicon:\r\n\r\n- After building the pip package, you might run into issues while installing the dependencies since a lot of dependencies are not ported to Apple Silicon yet. But you can still install the pip package with `--no-deps` option.\r\n\r\n- If you got `Symbol not found: _LLVMInitializeAArch64AsmPrinter` error while `import tensorflow` in Python, you probably need to disable XLA support for now. Just remove the `build --config=xla` line in the `.tf_configure.bazelrc` file.", "Hi!\r\n\r\nI'm using bazel 3.7.1 arm to build tensorflow on Apple M1 like this:\r\n\r\n```\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nIt builds for a long time then it stops with this error:\r\n\r\n```INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (412 packages loaded, 30967 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/cpuinfo/BUILD.bazel:98:11: C++ compilation of rule '@cpuinfo//:cpuinfo_impl' failed (Exit 1): wrapped_clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=11.1 \\\r\n    PATH=/opt/homebrew/Caskroom/miniforge/base/envs/tfbuild/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    XCODE_VERSION_OVERRIDE=12.3.0.12C33 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-DNS_BLOCK_ASSERTIONS=1' -iquote external/cpuinfo -iquote bazel-out/host/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/host/bin/external/clog -Ibazel-out/host/bin/external/clog/_virtual_includes/clog -MD -MF bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.d '-DCLOG_VISIBILITY=' '-frandom-seed=bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=11.1' -g0 '-std=gnu99' -Wno-vla '-D_GNU_SOURCE=1' '-DCPUINFO_INTERNAL=' '-DCPUINFO_PRIVATE=' -Iexternal/cpuinfo/include -Iexternal/cpuinfo/src -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/cpuinfo/src/x86/cache/deterministic.c -o bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from external/cpuinfo/src/x86/cache/deterministic.c:4:\r\nIn file included from external/cpuinfo/src/x86/cpuid.h:5:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:11:2: error: this header is for x86 only\r\n#error this header is for x86 only\r\n ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:271:5: error: invalid output constraint '=a' in asm\r\n    __cpuid(__leaf, __eax, __ebx, __ecx, __edx);\r\n    ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:286:5: error: invalid output constraint '=a' in asm\r\n    __cpuid(__leaf, *__eax, *__ebx, *__ecx, *__edx);\r\n    ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:300:5: error: invalid output constraint '=a' in asm\r\n    __cpuid_count(__leaf, __subleaf, *__eax, *__ebx, *__ecx, *__edx);\r\n    ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:243:11: note: expanded from macro '__cpuid_count'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/cache/deterministic.c:4:\r\nexternal/cpuinfo/src/x86/cpuid.h:30:5: error: invalid output constraint '=a' in asm\r\n                                __cpuid(eax, regs.eax, regs.ebx, regs.ecx, regs.edx);\r\n                                ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:236:11: note: expanded from macro '__cpuid'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/cache/deterministic.c:4:\r\nexternal/cpuinfo/src/x86/cpuid.h:56:5: error: invalid output constraint '=a' in asm\r\n                                __cpuid_count(eax, ecx, regs.eax, regs.ebx, regs.ecx, regs.edx);\r\n                                ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include/cpuid.h:243:11: note: expanded from macro '__cpuid_count'\r\n        : \"=a\"(__eax), \"=r\" (__ebx), \"=c\"(__ecx), \"=d\"(__edx) \\\r\n          ^\r\nIn file included from external/cpuinfo/src/x86/cache/deterministic.c:4:\r\nexternal/cpuinfo/src/x86/cpuid.h:75:38: error: invalid output constraint '=a' in asm\r\n                __asm__(\".byte 0x0F, 0x01, 0xD0\" : \"=a\" (lo), \"=d\" (hi) : \"c\" (ext_ctrl_reg));\r\n                                                   ^\r\n7 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/lite/python/BUILD:58:10 C++ compilation of rule '@cpuinfo//:cpuinfo_impl' failed (Exit 1): wrapped_clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=11.1 \\\r\n    PATH=/opt/homebrew/Caskroom/miniforge/base/envs/tfbuild/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    XCODE_VERSION_OVERRIDE=12.3.0.12C33 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-DNS_BLOCK_ASSERTIONS=1' -iquote external/cpuinfo -iquote bazel-out/host/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/host/bin/external/clog -Ibazel-out/host/bin/external/clog/_virtual_includes/clog -MD -MF bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.d '-DCLOG_VISIBILITY=' '-frandom-seed=bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=11.1' -g0 '-std=gnu99' -Wno-vla '-D_GNU_SOURCE=1' '-DCPUINFO_INTERNAL=' '-DCPUINFO_PRIVATE=' -Iexternal/cpuinfo/include -Iexternal/cpuinfo/src -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/cpuinfo/src/x86/cache/deterministic.c -o bazel-out/host/bin/external/cpuinfo/_objs/cpuinfo_impl/deterministic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 142,442s, Critical Path: 44,13s\r\nINFO: 2235 processes: 265 internal, 1970 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\nAny ideas what could be wrong? Seams like it tries to build x86 stuff?\r\n\r\n", "@vashat \r\n\r\nHi, are you using a custom Bazel binary built for arm64? Bazel doesn't provide official Apple Silicon support yet, see https://github.com/bazelbuild/bazel/issues/11628. Can you try with the [x86 Bazel 3.7.1 binary](https://github.com/bazelbuild/bazel/releases/download/3.7.1/bazel_nojdk-3.7.1-darwin-x86_64)? It runs seamlessly with Rosetta 2.", "@meteorcloudy \r\n\r\nHi! I've tried the x86 Bazel 3.7.1. you linked to. It gave me another error when building standard tensorflow:\r\n\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\n../bazel_nojdk-3.7.1-darwin-x86_64 build --verbose_failures --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=173\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/admin/scripts/build_tensorflow/tensorflow/WORKSPACE:23:10: in <toplevel>\r\n  /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/workspace0.bzl:65:34: in workspace\r\n  /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (412 packages loaded, 31004 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/python/keras/api/BUILD:124:19: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1): bash failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/homebrew/Caskroom/miniforge/base/envs/tfbuild/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1  --apidir=bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api_v1/ --apiname=keras --apiversion=1  --loading=default --packages=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v1 --use_relative_imports=True bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/activations/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/densenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/efficientnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/imagenet_utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/inception_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/nasnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet50/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/vgg16/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/vgg19/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/xception/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/backend/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/callbacks/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/callbacks/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/constraints/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/cifar10/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/cifar100/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/imdb/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/reuters/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/estimator/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/initializers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/experimental/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/losses/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/metrics/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/mixed_precision/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/mixed_precision/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/models/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/optimizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/optimizers/schedules/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/premade/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/image/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/text/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/regularizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/wrappers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): no suitable image found.  Did find:\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 26, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): no suitable image found.  Did find:\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/python/tools/BUILD:83:10 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1): bash failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/homebrew/Caskroom/miniforge/base/envs/tfbuild/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1  --apidir=bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api_v1/ --apiname=keras --apiversion=1  --loading=default --packages=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v1 --use_relative_imports=True bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/activations/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/densenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/efficientnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/imagenet_utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/inception_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/mobilenet_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/nasnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/resnet50/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/vgg16/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/vgg19/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/applications/xception/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/backend/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/callbacks/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/callbacks/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/constraints/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/cifar10/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/cifar100/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/imdb/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/datasets/reuters/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/estimator/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/initializers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/layers/experimental/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/losses/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/metrics/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/mixed_precision/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/mixed_precision/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/models/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/optimizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/optimizers/schedules/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/premade/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/image/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/preprocessing/text/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/regularizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/wrappers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/_v1/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 7333,570s, Critical Path: 315,55s\r\nINFO: 18615 processes: 1159 internal, 17456 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nAfter that I tried your fork but it failed another way:\r\n\r\n```\r\ngit clone https://github.com/meteorcloudy/tensorflow.git\r\ncd tensorflow\r\ngit checkout apple_silicon_build\r\n../bazel_nojdk-3.7.1-darwin-x86_64 build --verbose_failures --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=173\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (337 packages loaded, 28815 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/llvm-project/llvm/BUILD:3986:11: C++ compilation of rule '@llvm-project//llvm:Support' failed (Exit 1): wrapped_clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=11.1 \\\r\n    PATH=/opt/homebrew/Caskroom/miniforge/base/envs/tfbuild/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    XCODE_VERSION_OVERRIDE=12.3.0.12C33 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-DNS_BLOCK_ASSERTIONS=1' '-std=c++11' -iquote external/llvm-project -iquote bazel-out/host/bin/external/llvm-project -iquote external/zlib -iquote bazel-out/host/bin/external/zlib -isystem external/llvm-project/llvm/include -isystem bazel-out/host/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -MD -MF bazel-out/host/bin/external/llvm-project/llvm/_objs/Support/ScaledNumber.d -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL '-frandom-seed=bazel-out/host/bin/external/llvm-project/llvm/_objs/Support/ScaledNumber.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=11.1' -g0 -g0 '-std=c++14' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/llvm-project/llvm/lib/Support/ScaledNumber.cpp -o bazel-out/host/bin/external/llvm-project/llvm/_objs/Support/ScaledNumber.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from external/llvm-project/llvm/lib/Support/ScaledNumber.cpp:14:\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:162:61: error: expected ';' at end of declaration list\r\n  static const llvm::fltSemantics &EnumToSgetSgetSgSemantics S);\r\n                                                            ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:822:29: error: use of undeclared identifier 'getSgetSgetSge'\r\n  void makeZero(bool Neg) { APFLOAT_DISPATCH_ON_SEMANTICS(makeZero(Neg)); }\r\n                            ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:822:29: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:824:28: error: use of undeclared identifier 'getSgetSgetSge'\r\n  void makeInf(bool Neg) { APFLOAT_DISPATCH_ON_SEMANTICS(makeInf(Neg)); }\r\n                           ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:824:28: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:827:5: error: use of undeclared identifier 'getSgetSgetSge'\r\n    APFLOAT_DISPATCH_ON_SEMANTICS(makeNaN(SNaN, Neg, fill));\r\n    ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:827:5: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:831:5: error: use of undeclared identifier 'getSgetSgetSge'\r\n    APFLOAT_DISPATCH_ON_SEMANTICS(makeLargest(Neg));\r\n    ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:831:5: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:835:5: error: use of undeclared identifier 'getSgetSgetSge'\r\n    APFLOAT_DISPATCH_ON_SEMANTICS(makeSmallest(Neg));\r\n    ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:835:5: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:839:5: error: use of undeclared identifier 'getSgetSgetSge'\r\n    APFLOAT_DISPATCH_ON_SEMANTICS(makeSmallestNormalized(Neg));\r\n    ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:839:5: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:856:31: error: use of undeclared identifier 'getSgetSgetSge'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:858:35: error: use of undeclared identifier 'getSgetSgetSge'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:881:31: error: use of undeclared identifier 'getSgetSgetSge'\r\n  bool needsCleanup() const { APFLOAT_DISPATCH_ON_SEMANTICS(needsCleanup()); }\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:27:31: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))                                 \\\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:881:31: error: use of undeclared identifier 'getSgetSgetSge'\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:29:35: note: expanded from macro 'APFLOAT_DISPATCH_ON_SEMANTICS'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))                             \\\r\n                                  ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:976:31: error: use of undeclared identifier 'getSgetSgetSge'\r\n    if (usesLayout<IEEEFloat>(getSgetSgetSge))\r\n                              ^\r\nexternal/llvm-project/llvm/include/llvm/ADT/APFloat.h:978:35: error: use of undeclared identifier 'getSgetSgetSge'\r\n    if (usesLayout<DoubleAPFloat>(getSgetSgetSge))\r\n                                  ^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 116,302s, Critical Path: 22,32s\r\nINFO: 514 processes: 190 internal, 324 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@vashat \r\nIt looks like you didn't set the Python virtual environment correctly (check the PR description) and you didn't run the TF ./configure script?", "@meteorcloudy \r\nI followed the instructions here https://github.com/apple/tensorflow_macos#details  to set up a virtual environment. Following these instruction I created a virtual environment (tfbuild2), activated it and let the Apple installation script install everything into it. This also installed Apples version of tensorflow.\r\n\r\nAfter that I cloned your fork, checked out apple_silicon_build and run ./configure:\r\n\r\n```git clone https://github.com/meteorcloudy/tensorflow.git\r\ncd tensorflow\r\ngit checkout apple_silicon_build\r\n./configure\r\n```\r\n\r\n./configure gave me the following questions which I chose the default answers on. Note that it did not list \"macos_arm64\" as an option in the --config part at the end. Maybe that is the problem? It also told me that i can't use bazel 3.7.1, 3.7.2 is needed to build. So I installed the x86 version of 3.7.2.  See the options I got:\r\n\r\n```\r\n./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /Users/admin/scripts/tfbuild2/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /Users/admin/scripts/tfbuild2/lib/python3.8/site-packages\r\nPlease input the desired Python library path to use.  Default is [/Users/admin/scripts/tfbuild2/lib/python3.8/site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nDo you wish to build TensorFlow with iOS support? [y/N]: \r\nNo iOS support will be enabled for TensorFlow.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=mkl_aarch64 \t# Build with oneDNN support for Aarch64.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n```\r\n\r\nAfter then I started building. It built for several hours and ended in this error:\r\n\r\n\r\n```\r\nbazel build --verbose_failures --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=155\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /Users/admin/scripts/build_tensorflow/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/admin/scripts/tfbuild2/bin/python3 --action_env PYTHON_LIB_PATH=/Users/admin/scripts/tfbuild2/lib/python3.8/site-packages --python_path=/Users/admin/scripts/tfbuild2/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:macos_arm64 in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --config=macos --apple_platform_type=macos --cpu=darwin_arm64 --noenable_platform_specific_config\r\nINFO: Found applicable config definition build:macos in file /Users/admin/scripts/build_tensorflow/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nWARNING: Download from http://mirror.tensorflow.org/files.pythonhosted.org/packages/12/59/eaa15ab9710a20e22225efd042cd2d6a0b559a0656d5baba9641a2a4a921/gast-0.4.0.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/admin/scripts/build_tensorflow/tensorflow/WORKSPACE:16:10: in <toplevel>\r\n  /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/workspace0.bzl:65:34: in workspace\r\n  /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/www.sqlite.org/2020/sqlite-amalgamation-3340000.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/d38a0258a5f4c28fd0b0c00705c40e06976ed247.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (416 packages loaded, 31980 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/python/keras/api/BUILD:111:19: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1): bash failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/admin/scripts/tfbuild2/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    PYTHON_BIN_PATH=/Users/admin/scripts/tfbuild2/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/admin/scripts/tfbuild2/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen  --apidir=bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api --apiname=keras --apiversion=1  --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api --use_relative_imports=True bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/activations/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/densenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/efficientnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/imagenet_utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/inception_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/nasnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet50/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/vgg16/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/vgg19/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/xception/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/backend/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/callbacks/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/callbacks/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/constraints/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/boston_housing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/cifar10/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/cifar100/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/imdb/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/reuters/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/estimator/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/initializers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/experimental/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/losses/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/metrics/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/mixed_precision/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/mixed_precision/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/models/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/optimizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/optimizers/schedules/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/premade/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/image/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/sequence/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/text/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/regularizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/wrappers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): no suitable image found.  Did find:\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 26, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): no suitable image found.  Did find:\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\t/private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /Users/admin/scripts/build_tensorflow/tensorflow/tensorflow/lite/python/BUILD:58:10 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1): bash failed: error executing command \r\n  (cd /private/var/tmp/_bazel_admin/4a3fb7046992edc242e946b5f3190932/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/admin/scripts/tfbuild2/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin \\\r\n    PYTHON_BIN_PATH=/Users/admin/scripts/tfbuild2/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/admin/scripts/tfbuild2/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen  --apidir=bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api --apiname=keras --apiversion=1  --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api --use_relative_imports=True bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/activations/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/densenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/efficientnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/imagenet_utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/inception_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/mobilenet_v3/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/nasnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet_v2/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/resnet50/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/vgg16/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/vgg19/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/applications/xception/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/backend/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/callbacks/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/callbacks/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/constraints/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/boston_housing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/cifar10/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/cifar100/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/imdb/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/mnist/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/datasets/reuters/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/estimator/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/initializers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/layers/experimental/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/losses/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/metrics/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/mixed_precision/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/mixed_precision/experimental/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/models/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/optimizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/optimizers/schedules/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/premade/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/image/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/sequence/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/preprocessing/text/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/regularizers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/utils/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/wrappers/__init__.py bazel-out/darwin_arm64-opt/bin/tensorflow/python/keras/api/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 7965,932s, Critical Path: 301,92s\r\nINFO: 19721 processes: 1150 internal, 18571 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@meteorcloudy \r\nGot it to build now. Turns out that the problem was that I was not using apples built in python 3.8 when setting up the virtual environment, I was using a 3.8 from a conda installation. It seam that apples version _must_ be used or it will fail. ", "How could I build a arm64 .whl file\r\nI have build master with\r\n```\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n```\r\nBut it still not seems to work\r\n```\r\nIn [2]: print(tf)\r\n<module 'tensorflow' (namespace)>\r\n\r\nIn [3]: tf.add(1, 2).numpy()\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-a78df43b9eac> in <module>\r\n----> 1 tf.add(1, 2).numpy()\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'add'\r\n```", "@Huibean \r\nMaybe you are missing some steps?\r\nSee https://www.tensorflow.org/install/source#build_the_package", "@meteorcloudy I have build it with \r\n```./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg```\r\nBut it only created a x86 version", "@erwincoumans have you figured out ``cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'`` this error?", "> @erwincoumans have you figured out cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64' this error?\r\n\r\nThis is mostly likely you don't have Xcode installed, please install Xcode then do `bazel clean --expunge` and try again.", "@meteorcloudy Thanks, that indeed fixes my issue.", "does anyone know how to install tensorflow version 2.1.0 on the M1 mac?", "2.1 is too old for that. You should try 2.4/2.5 and later."]}, {"number": 45403, "title": "Support RaggedTensors in Keras losses (at least MSE, CE, SCE)", "body": "**System information**\r\n- TensorFlow version (you are using): **TF 2.4.0rc3**\r\n- Are you willing to contribute it (Yes/No): **Yes**\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, RaggedTensors can be passed as Keras model inputs. Soon, it will be possible to use them as targets (#45060 and #45015). Therefore, it would be great if they could also be passed to standard losses.\r\n\r\nI therefore propose to extend the losses in `tf.keras.losses` to support RaggedTensors as inputs. That is currently (TF 2.4.0rc3) not possible:\r\n```python\r\ntf.keras.losses.mean_squared_error(tf.ragged.constant([[1.],[2.,3.]]), tf.ragged.constant([[1.], [2., 3.]]))\r\n```\r\nfails with an exception `TypeError: object of type 'RaggedTensor' has no len()` because it uses https://github.com/tensorflow/tensorflow/blob/c37b2f11529182853bbf234232b4da4b5ff476d6/tensorflow/python/keras/losses.py#L1196 . Similarly for others like `(sparse_)categorical_crossentropy`, `binary_crossentropy` etc.\r\n\r\n**Will this change the current api? How?**\r\n\r\nRaggedTensors will be supported as arguments of `tf.keras.losses` methods and classes. The change is backward compatible.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone wanting to use RaggedTensors as outputs. There seem to be demand for it, see for example #44988, #44112, #43591, #43093, #42320, #41810.\r\n\r\n**Any Other info.**\r\n\r\nNote that RaggedTensors **can be passed already to `tf.keras.metrics`**, so\r\n```python\r\ntf.keras.metrics.MeanSquaredError()(tf.ragged.constant([[1.],[2.,3.]]), tf.ragged.constant([[1.], [2., 4.]]))\r\n```\r\nreturns correctly `1/3`.\r\n", "comments": ["@foxik \r\n\r\nIf you are looking for a workaround, the following seems to work for me for 2D tensors shape: (batch, [var len]).\r\n```\r\nx1 = tf.ragged.constant([[1.],[2.,3.]])\r\nx2 = tf.ragged.constant([[1.], [2., 4.]])\r\n\r\nlosses = []\r\nfor i in tf.range(x1.nrows()):\r\n    losses.append(keras.losses.mean_squared_error(x1[i], x2[i]))\r\ntf.reduce_mean(losses)\r\n```\r\n\r\nFor 3d tensors where the ragged dimension is the sequence length and the features dimension is constant I use a user defined loss such as.\r\n\r\n```\r\nclass RaggedBinaryCrossentropy(keras.losses.Loss):\r\n    @tf.function\r\n    def call(self, y_true, y_pred):\r\n        losses = tf.ragged.map_flat_values(\r\n            keras.losses.binary_crossentropy, y_true, y_pred)\r\n        return tf.reduce_mean(losses)\r\n```\r\n\r\n\r\n", "@pedro-r-marques Thanks! Once your PRs go though, I plan to use something like `lambda y_true, y_pred: tf.losses.SparseCategoricalCrossentropy()(y_true.values, y_pred.values)` as a loss to `.compile` (I usually work with sequences of variable length on input, so one `.values` is fine for me).\r\n\r\nBut I think basic losses like MSE or CE should support RaggedTensors anyway :-)", "@foxik I agree with the desirability of adding support in the keras library itself.\r\nJust as a note: if I understand correctly using .values would yield slightly different results than doing first the mean of the per batch losses and then the mean of that. For instance if you have very large sequences and very small sequences of values (which is where ragged tensors really helps) then this difference whether to average all the losses independent of batch or on a per batch basis could matter.\r\n\r\nIn terms of the feature request, it would be nice if keras.losses.Loss could understand 2-D RaggedTensors and perform the mean per-batch and then across batches. And also if it could understand N-D RaggedTensors where the 2nd dimension is the ragged dimension and use ```map_flat_values``` to compute the per batch losses.", "@pedro-r-marques Personally I would prefer the other behaviour, i.e., average across all \"words\" (assuming the batch examples are sequences of words). If you consider that the gradients in the network are caused \"by every word\" (because the individual losses are some cross entropies of every word), then to estimate correct second and first moments, I believe you should not average across sentences first.\r\n\r\nIf you look at it from the metrics point of view, in NLP you usually want to compute accuracy \"per word\", not average of \"sentence-level\" accuracies (BTW, this seems to be exactly what the current implementation of `tf.metrics` does); and I would expect the same from the losses.", "Thanks @pedro-r-marques for implementing those:\r\n- https://github.com/tensorflow/tensorflow/pull/45015\r\n- https://github.com/tensorflow/tensorflow/pull/45060\r\n- https://github.com/tensorflow/tensorflow/pull/46875\r\n- https://github.com/tensorflow/tensorflow/pull/46876\r\n- https://github.com/tensorflow/tensorflow/pull/46878\r\n- https://github.com/tensorflow/tensorflow/pull/47045\r\n- https://github.com/tensorflow/tensorflow/pull/47075\r\n- https://github.com/tensorflow/tensorflow/pull/47092\r\n\r\nThis covers all the losses I mentioned in the original PR.\r\n\r\nDo you think @pedro-r-marques that we should keep this open until all `tf.keras.losses` support ragged tensors, or should we close it now that all frequently used ones do? For the record, what is missing are `hinge`, `squared_hinge`, `categorical_hinge`,  `log_cosh`, `kl_divergence`, `poisson`, `cosine_similarity` (note that `huber` seems to work without explicit support, but I am not sure if it works correctly). Also for the record, I do not miss any of the not implemented ones.", "@foxik I believe it would make sense to close this issue. Other, less common metrics, can be added on demand when the need arises.", "@pedro-r-marques Thanks, closing."]}, {"number": 45402, "title": "[RNN] tensorflow/lite/kernels/fully_connected.cc:119 is_optional_bias_int != true error in quantized LSTM model", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (or github SHA if from source): TF2.3, TF '2.5.0-dev20201203'\r\n- Python version: 3.7.5\r\n\r\n\r\nI am trying to convert and fully quantize a model containing LSTM layers. I use unroll = True flag as quantization of while function is not supported yet (see https://github.com/tensorflow/tensorflow/issues/39392). \r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# create a simple lstm model\r\ninput_data = np.random.random_sample([1,2,3]).astype(np.float32)\r\nlstm_model = tf.keras.models.Sequential([tf.keras.layers.LSTM(units = 5, unroll = True)])\r\nlstm_model.build(input_data.shape)\r\n\r\n# create a representative dataset\r\nrepr_dataset = tf.data.Dataset.from_tensor_slices(np.tile(input_data, [10, 1, 1]))\r\nrepr_dataset = repr_dataset.batch(1)\r\ndef representative_data_gen():\r\n    for input_value in repr_dataset.take(1):\r\n        yield [input_value]\r\n    \r\n# convert and quantize the model\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\r\nconverter.optimizations =  [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\ntflite_model = converter.convert()\r\nopen(\"lstm_model.tflite\",\"wb\").write(tflite_model)\r\n\r\n# open interpreter\r\ninterpreter = tf.lite.Interpreter(model_path=\"lstm_model.tflite\")\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\nThe interpreter fails when allocating tensors:\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"test_lstm.py\", line 455, in <module>\r\n    interpreter.allocate_tensors()\r\n\r\n  File \"Anaconda3\\envs\\Automatic-Speech-Recognition\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 259, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n\r\nRuntimeError: tensorflow/lite/kernels/fully_connected.cc:119 is_optional_bias_int != true (0 != 1)Node number 4 (FULLY_CONNECTED) failed to prepare.\r\n```\r\n\r\nI found out that following code is converted into a fully connected node with 8int bias  as h_tm1 is a tf.zeros() tensor during the first rnn step. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent.py#L2461)\r\n```\r\n      z = K.dot(inputs, self.kernel)\r\n      z += K.dot(h_tm1, self.recurrent_kernel)\r\n      if self.use_bias:\r\n        z = K.bias_add(z, self.bias)\r\n```\r\n\r\nIs this an expected behaviour or a bug? How to get around it?\r\n\r\nThank you", "comments": ["Any updates on this? Thanks", "Was able to replicate the issue with TF 2.3 and TF v2.5 In Colab, Issue is not recurring in TF 2.5 ,please find the [gist](https://colab.research.google.com/gist/mohantym/9d620af346622de25aa3a807edc47388/github_45402.ipynb) here ..Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45402\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45402\">No</a>\n"]}, {"number": 45401, "title": "TF 2.4rc3 removes names from ops in Model, unlike TF 2.3.1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**\r\n- TensorFlow installed from (source or binary): **Binary**\r\n- TensorFlow version (use command below): **2.4rc3**\r\n- Python version: **3.8.5**\r\n\r\n**Describe the current behavior**\r\n\r\nIn TF 2.4rc3\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.models import Model\r\n \r\ninputs = Input(shape=(1,), name='input_layer')\r\noutputs = tf.identity(inputs, name='test_layer')\r\nmodel = Model(inputs, outputs)\r\n \r\nprint(model.output_names)\r\n```\r\n\r\n```python\r\n['tf.identity']\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nIn TF 2.3.1 and earlier\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.models import Model\r\n \r\ninputs = Input(shape=(1,), name='input_layer')\r\noutputs = tf.identity(inputs, name='test_layer')\r\nmodel = Model(inputs, outputs)\r\n \r\nprint(model.output_names)\r\n```\r\n\r\n```python\r\n['tf_op_layer_test_layer']\r\n```\r\n\r\nSo you could create a model with a function from Tensorflow as the last layer and name it. If you needed to recover the name you can simply slice off the prefix. \r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\n**Other info / logs**\r\n\r\nIf the output is a layer from Keras it works in both versions:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Dense\r\nfrom tensorflow.keras.models import Model\r\n \r\ninputs = Input(shape=(1,), name='input_layer')\r\noutputs = Dense(1, name='test_layer')(inputs)\r\nmodel = Model(inputs, outputs)\r\n \r\nprint(model.output_names)\r\n```\r\n\r\n```python\r\n['test_layer']\r\n```\r\n\r\nBut that doesn't change that this is a code-breaking behavior change.", "comments": ["I was able to reproduce it. Here is the [gist](https://gist.github.com/geetachavan1/3c6510343e34e18aeae8de9bf7da4e69)", "Hi @grofte, what you're running into is actually covered by this bullet in the release notes:\r\n\"Code that relies on the exact number and names of the op layers that TensorFlow operations were converted into may have changed.\"\r\n\r\nhttps://github.com/tensorflow/tensorflow/releases\r\n\r\nIf you're looking for more context around this, the discussion around\r\nhttps://github.com/tensorflow/tensorflow/pull/43844\r\nand\r\nhttps://github.com/tensorflow/tensorflow/issues/43840\r\n\r\nshould have more info.\r\n\r\nTl;dr: Before 2.4 the process that tried to automatically convert tf ops into keras layers in functional models was extremely problematic for many reasons (memory leaks, bugs, poor support, etc.). The price of improving it was that the names of these autogen'd layers would have to change, and that the `name` arg passed in to the op would not be able to affect the name of the generated layer.\r\n\r\nBecause we never made any API guarantees about *how* tf ops would be implicitly converted into layers, we judged that the very niche usage of relying on their names wasn't worth supporting. It can generally be worked around with slight restructuring of the code. (E.g. you can use a no-op keras lambda layer at the end to explicitly set a name in your case rather than using tf.Identity).\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45401\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45401\">No</a>\n", "Okay, so you prefer something along the lines of this if we are naming things:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Lambda\r\nfrom tensorflow.keras.models import Model\r\n \r\ninputs = Input(shape=(1,), name='input_layer')\r\nx = tf.identity(inputs)\r\noutputs = Lambda(lambda x: x, name='test_layer')(x)\r\nmodel = Model(inputs, outputs)\r\n \r\nprint(model.output_names)\r\n```\r\n\r\n```python\r\n['test_layer']\r\n```\r\n\r\nThen you should remove the name parameter from ops. And since there's a method for getting layers by name in a model (very important in transfer learning) there is an implicit guarantee that layer names can be used as code bearing. \r\n\r\nI will make sure to use the Lambda layer for any ops I want to name explicitly going forward.", "If you are trying to explicitly name an output layer for the purpose of Keras APIs that rely on layer names then that is one option.\r\nIf you are explicitly constructing a `tf.keras.layers` layer as the last layer in your Keras model rather than relying on TF ops then you can use `name=...` there as well, without needing to create an identity lambda layer.\r\n\r\nE.g.:\r\n```\r\ninputs = Input(shape=(1,), name='input_layer')\r\noutputs = tf.keras.layers.Dense(5, name='test_layer')(inputs)\r\nmodel = Model(inputs, outputs)\r\n```\r\n\r\nWe have not changed the naming semantics for any `tf.keras.layers` layers that you explicitly construct, because just as you mention there are APIs that treat layer names as load-bearing.\r\n\r\nWhat you're running into is that the Keras layer/model APIs and the lower-level TF apis are entirely different subsets of the API that have organically grown in different ways to serve different purposes. For a very long time it was completely impossible to use lower-level TF apis to create a Keras functional model, and you could only use `tf.keras.layers`.\r\n\r\nAt some point Keras started hooking into the lower-level TF ops so that if you use them in Keras functional model construction it would try to turn those lower-level tf api calls into keras layers under the hood and let you build Keras models with them. This was always a best-effort approach that tries to match the intent of the lower-level api as closely as possible, but it is not and has never been perfect. So, we can't remove an argument from the lower-level APIs (which specifies the name of the created tf op) just because Keras itself is unable to use that argument to set the name of the generated layer. (Again, the discussion in the bugs linked above explains why)\r\n\r\nOne of the positive side effects of the refactoring of the internals is that the best-effort conversions will work more reliably now and better match the intent of the hooked lower-level apis, with the exception of no longer being able to read the `name` argument to set the layer name.\r\n\r\nGenerally speaking if you're using implicit conversions of lower-level tf ops into Keras layers, you should not be relying on semantics around exactly what layers get auto-generated (e.g. the number of layers created for a specific TF api, their names, etc.), because that is all subject to change. We *will* do our best to make sure that calling the generated layers on concrete inputs will match the behavior of directly calling the low-level api on those same inputs."]}, {"number": 45400, "title": "Update local.py", "body": "Removing redundant line in the documentation for strides argument.\r\n\r\nMaking changes as suggested in issue [#44528](https://github.com/tensorflow/tensorflow/issues/44528).", "comments": []}, {"number": 45399, "title": "Only use site.USER_SITE if ENABLE_USER_SITE is set", "body": "Fixes loading dynamic kernels from user site even in a virtual environment.\r\n\r\nCurrently, the `site.USER_SITE` is unconditionally added to the path used for preloading dynamic kernels. However, when running in a virtual environment, the `site.USER_SITE` should not be added, because a different TF version might be there (and as reported in #42978, it causes a crash for example when TF 2.3 is in user site and TF 2.4 in a virtual environment).\r\n\r\nLuckily, `site.ENABLE_USER_SITE` is a flag indicating if `site.USER_SITE` was added to path, and it is set to False when running in a virtual environment. In this pull request, the `site.ENABLE_USER_SITE` is honored.\r\n\r\nShould fix #42978.", "comments": ["@goldiegadde Please consider backporting for TF 2.4 -- currently it is broken in virtual environments if other TF version is in user site.", "@mihaimaruseac Do you think it makes sense to backport it to TF 2.4? If so, is there something I can do to help?", "Let's make a PR to the branch when this lands. We need to wait for a nightly version to pass to ensure no test gets broken and then it all depends on the release owner. Though if this would require a new RC we cannot take it as that would push final release to next year."]}, {"number": 45398, "title": "Dll load failed error", "body": "ImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\parkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\parkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\parkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\parkar\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\parkar\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "I used colab but in the project which i made is using GUI(tkinter library) so for that colab is not useful", "@Div123chauhan,\r\nYou might be facing this issue because of the following reasons\r\n\r\n- You are running 32-bit Python or 32-bit OS\r\n- You have not installed the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) package\r\n- Your CPU does not support AVX instructions. \r\n\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nAlso, check these similar duplicate issues: #36167 #36138. Thanks!", "Help Getting errors while importing TF\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n     39 \r\n---> 40 from tensorflow.python.eager import context\r\n     41 \r\n     42 # pylint: enable=wildcard-import\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py in <module>\r\n     33 from tensorflow.core.protobuf import config_pb2\r\n     34 from tensorflow.core.protobuf import rewriter_config_pb2\r\n---> 35 from tensorflow.python import pywrap_tfe\r\n     36 from tensorflow.python import tf2\r\n     37 from tensorflow.python.client import pywrap_tf_session\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py in <module>\r\n     26 \r\n     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\r\n---> 28 from tensorflow.python import pywrap_tensorflow\r\n     29 from tensorflow.python._pywrap_tfe import *\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Gaganu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "> Help Getting errors while importing TF\r\n\r\n@Nayanasalur,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45398\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45398\">No</a>\n", "I solve my issue using the making new environment in anaconda and then downloding all the libraries like keras, keras --gpu, etc.\r\nand also installing Microsoft Visual C++ Redistributable package. Now, my tensorflow is working without any error."]}, {"number": 45397, "title": "How to create a Tensorflow Dataset without labels? Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n-Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python 3.8.5\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: RTX 2060 8GB\r\n\r\nI was trying fit my model using instances of the tf.data.Dataset class. I need the **repeat()** method to perform a custom image augmentation for every epoch.\r\n \r\nUsing Tensorflow 2.3.1, I'm trying to create an instance of the class **tf.data.Dataset** without labels, from the images I have stored in  **.png** files in a folder './Folder/'. For creating the minimal working sample, I think the only relevant line is the one where I am calling **tf.keras.preprocessing.image_dataset_from_directory**. \r\nThe class definition is [here](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/preprocessing/image_dataset.py#L34-L206):  \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nAfter storing some PNG files in the folder ./Folder/' , the minimal working sample is just this line:\r\n   ` dataset = tf.keras.preprocessing.image_dataset_from_directory('./Folder/',label_mode=None,batch_size=100)`\r\n\r\nI expected the tf.data.Dataset instance _dataset_ to be created, and a message:\r\n Found 449 files ...\r\n\r\nInstead, I get the message:\r\n`Found 0 files belonging to 0 classes.\r\n`, followed by this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 465, in _apply_op_helper\r\n    values = ops.convert_to_tensor(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1473, in convert_to_tensor\r\n    raise ValueError(\r\nValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"04-vaeAnomalyScores.py\", line 135, in <module>\r\n    historicKLD, encoder, decoder, vae = artVAE_Instance.run_autoencoder()  # Train\r\n  File \"/media/roi/9b168630-3b62-4215-bb7d-fed9ba179dc7/images/largePatches/artvae.py\", line 403, in run_autoencoder\r\n    trainingDataSet = self.loadImages(self.trainingDir)\r\n  File \"/media/roi/9b168630-3b62-4215-bb7d-fed9ba179dc7/images/largePatches/artvae.py\", line 230, in loadImages\r\n    dataset,paths = tf.keras.preprocessing.image_dataset_from_directory(dir[:-1]+'Downscaled',label_mode=None,batch_size=self.BATCH_SIZE, \r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\", line 192, in image_dataset_from_directory\r\n    dataset = paths_and_labels_to_dataset(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\", line 219, in paths_and_labels_to_dataset\r\n    img_ds = path_ds.map(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1695, in map\r\n    return MapDataset(self, map_func, preserve_cardinality=True)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4041, in __init__\r\n    self._map_func = StructuredFunctionWrapper(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3371, in __init__\r\n    self._function = wrapper_fn.get_concrete_function()\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2938, in get_concrete_function\r\n    graph_function = self._get_concrete_function_garbage_collected(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2906, in _get_concrete_function_garbage_collected\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3065, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3364, in wrapper_fn\r\n    ret = _wrapper_helper(*args)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3299, in _wrapper_helper\r\n    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 255, in wrapper\r\n    return converted_call(f, args, kwargs, options=options)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 532, in converted_call\r\n    return _call_unconverted(f, args, kwargs, options)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 339, in _call_unconverted\r\n    return f(*args, **kwargs)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\", line 220, in <lambda>\r\n    lambda x: path_to_image(x, image_size, num_channels, interpolation))\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\", line 228, in path_to_image\r\n    img = io_ops.read_file(path)\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 574, in read_file\r\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n  File \"/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 492, in _apply_op_helper\r\n    raise TypeError(\"%s expected type of %s.\" %\r\nTypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\r\n```\r\n\r\n", "comments": ["@xenon3dfx \r\nPlease share simple indented stand alone code to replicate the issue or if possible share a colab gist with the error.", "```\r\nimport tensorflow as tf\r\ndataset = tf.keras.preprocessing.image_dataset_from_directory('./folder/',label_mode=None,batch_size=100)\r\n```\r\n\r\nJust put png files in the ./folder/ directory", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45397\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45397\">No</a>\n", "Have the same issue. Did you manage to solve the problem @xenon3dfx ?", "By using pdb to step through code in image_dataset_from_directory and underneath it, I realized that filenames are very tied to classes (as they probably should be) and that the relevant message is not \"Op has type float32 that does not match\" but rather \"Found 0 files belonging to 0 classes.\"  The first is, if you will, an artifact of the second.\r\n\r\nI have (to test) three images in three files: a.jpg, b.jpg, and c.jpg - all originally in one subdirectory, picts.  Classes are also tightly tied to (further sub) directories.  My solution was to create subdirectories A, B and C and place the files appropriately.  Also I needed to not take the default value for class_names and my code reads as follows:\r\n\r\n`resultsa=tf.keras.preprocessing.image_dataset_from_directory(\"d:\\\\ML\\\\test\\\\picts\",label_mode=None,class_names=[\"A\",\"B\",\"C\"])`\r\n\r\nAs best I understand (I didn't want to spend forever stuck on this) your directories probably need to have the same names as your classes.", "How was this issue solved? I still have the same issue in Tensorflow 2.4. It looks like label_mode=None is not really recognized by the API."]}, {"number": 45396, "title": "Tensorflow-Python Environment Assertion Error ", "body": "I tried running some Tensorflow-python code inside Graphene-SGX on Ubuntu 18.04. While the specific does not matter much. I would like to better understand what this AssertionError is and what is it trying to check? I am using the latest Tensorflow 2.3.0. \r\n\r\n```\r\n[2020-12-04 05:34:34,839] - INFO - Running development server on: http://0.0.0.0:1236/\r\n[2020-12-04 05:34:34,840] - WARNING - NOTICE! Running development server on production environment is not recommended.\r\n2020-12-04 05:35:01.759068: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-04 05:35:06.357236: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3696010000 Hz\r\n2020-12-04 05:35:06.860466: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe33f4980 initialized for platform Host (this does not guarantee that XLA will be used).\r\n Devices:2020-12-04 05:35:06.864362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n\r\n2020-12-04 05:35:07.218360: F tensorflow/core/platform/env.cc:357] Check failed: -1 != cmd_length (-1 vs. -1)\r\n```\r\n\r\nFrom what I understand, it is caused by line 357 (https://fossies.org/linux/tensorflow/tensorflow/core/platform/env.cc) \r\n \r\n", "comments": ["@kamathhrishi \r\n\r\nPlease provide the exact sequence of commands and code that you executed before running into the problem. Thanks!", "Hello @ravikyram, this was what I tried to run. \r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nimport numpy as np\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(500, input_dim=8, activation=\"sigmoid\"))\r\nmodel.add(Dense(100, activation=\"sigmoid\"))\r\nmodel.add(Dense(2, activation=\"softmax\"))\r\n#model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n#model.fit(x_train, y_train, epochs=100, batch_size=70, validation_data=(x_test, y_test))\r\n#model.save(\"Diabetes_model.h5\")\r\n\r\nprint(model.predict(np.zeros([1,8])))\r\n```\r\n\r\nNote that I ran this using Graphene-SGX (https://github.com/oscarlab/graphene). \r\n\r\nI would be concerned as to what the failing AssertionCheck would mean. \r\n\r\nThank you ", "Was able to run the code on Ubuntu 18.04 without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/06212dc6359e088a0d64c97f1bf79d17/45396.ipynb). Thanks! ", "@kamathhrishi Looks like this is not an issue of Tensorflow as @ravikyram was able to run (but not using Graphene-SGX).\r\nCan you please post the issue in [Graphene-SGX repo](https://github.com/oscarlab/graphene/issues)?\r\n\r\nIf you think the error is related to Tensorflow, Can you please share error log? In the above posts, Assertion error was not shown (hope i didn't miss). Thanks!", "Hey @jvishnuvardhan Sorry for the late reply. Yes, its an error from TF.\r\n\r\nAs you can see from the last line of error statement \r\n\r\n```2020-12-04 05:35:07.218360: F tensorflow/core/platform/env.cc:357] Check failed: -1 != cmd_length (-1 vs. -1)```\r\n\r\nit clearly states that the error is from env.cc line 357. When I check the C file , I noticed it was a check. \r\nFurther, Graphene exits with a return code 134. ", "The [code that leads to the `CHECK` is](https://cs.opensource.google/tensorflow/tensorflow/+/r2.3:tensorflow/core/platform/env.cc;l=355-357;drc=7581d2a338c65086c6c7d0be1c65bd0621dd33c6):\r\n\r\n```cc\r\n    int fd = open(\"/proc/self/cmdline\", O_RDONLY);\r\n    int cmd_length = read(fd, buf, PATH_MAX - 1);\r\n    CHECK_NE(-1, cmd_length);\r\n```\r\n\r\nLikely on your system `/proc/self/cmdline` for the Python interpreter cannot be read.\r\n\r\nPlease provide details about operating system and the way you are running the code.", "@mihaimaruseac Thank you for your response. I will verify this and get back to you in about a week. This was inside a Library OS called Graphene. I will have to check if it has access to \"/proc/self/cmdline\". In Graphene-SGX I had to partition between what resources from OS could be accessible and cannot be accessible.  ", "Any updates?", "Hey, @mihaimaruseac Thanks for following up. I have been using Tf 2.2 temporarily instead. I will use Tf 2.4 and post my update here. Sorry for the delay. ", "Any updates with recent TF versions? Thanks!", "Hello @jvishnuvardhan, it worked fine. We can close this issue. \r\n\r\nThank you. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45396\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45396\">No</a>\n"]}, {"number": 45395, "title": "Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.4.0rc3\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda11.0\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n```python\r\nimport os\r\nimport re\r\nimport shutil\r\nimport string\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import losses\r\nfrom tensorflow.keras import preprocessing\r\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n\r\nprint(tf.__version__)\r\n\r\nurl = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\r\n\r\ndataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\r\n                                    untar=True, cache_dir='.',\r\n                                    cache_subdir='')\r\n\r\ndataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\r\n\r\nos.listdir(dataset_dir)\r\n\r\ntrain_dir = os.path.join(dataset_dir, 'train')\r\nos.listdir(train_dir)\r\n\r\nsample_file = os.path.join(train_dir, 'pos/1181_9.txt')\r\nwith open(sample_file) as f:\r\n  print(f.read())\r\n\r\nremove_dir = os.path.join(train_dir, 'unsup')\r\nshutil.rmtree(remove_dir)\r\n\r\nbatch_size = 32\r\nseed = 42\r\n\r\nraw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n    'aclImdb/train', \r\n    batch_size=batch_size, \r\n    validation_split=0.2, \r\n    subset='training', \r\n    seed=seed)\r\n\r\nfor text_batch, label_batch in raw_train_ds.take(1):\r\n  for i in range(3):\r\n    print(\"Review\", text_batch.numpy()[i])\r\n    print(\"Label\", label_batch.numpy()[i])\r\n\r\nraw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n    'aclImdb/train', \r\n    batch_size=batch_size, \r\n    validation_split=0.2, \r\n    subset='validation', \r\n    seed=seed)\r\n\r\nraw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n    'aclImdb/test', \r\n    batch_size=batch_size)\r\n\r\ndef custom_standardization(input_data):\r\n  lowercase = tf.strings.lower(input_data)\r\n  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\r\n  return tf.strings.regex_replace(stripped_html,\r\n                                  '[%s]' % re.escape(string.punctuation),\r\n                                  '')\r\n\r\nmax_features = 10000\r\nsequence_length = 250\r\n\r\nvectorize_layer = TextVectorization(\r\n    standardize=custom_standardization,\r\n    max_tokens=max_features,\r\n    output_mode='int',\r\n    output_sequence_length=sequence_length)\r\n\r\n# Make a text-only dataset (without labels), then call adapt\r\ntrain_text = raw_train_ds.map(lambda x, y: x)\r\nvectorize_layer.adapt(train_text)\r\n\r\ndef vectorize_text(text, label):\r\n  text = tf.expand_dims(text, -1)\r\n  return text, label\r\n\r\ntrain_ds = raw_train_ds.map(vectorize_text)\r\nval_ds = raw_val_ds.map(vectorize_text)\r\ntest_ds = raw_test_ds.map(vectorize_text)\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\n\r\nembedding_dim = 16\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n  model = tf.keras.Sequential([\r\n    vectorize_layer,\r\n    layers.Embedding(max_features + 1, embedding_dim),\r\n    layers.Dropout(0.2),\r\n    layers.GlobalAveragePooling1D(),\r\n    layers.Dropout(0.2),\r\n    layers.Dense(1)])\r\n  model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\r\n                optimizer=tf.keras.optimizers.Adam(1e-3),\r\n                metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\r\n\r\nepochs = 10\r\nhistory = model.fit(\r\n    train_ds,\r\n    validation_data=val_ds,\r\n    epochs=epochs)\r\n\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\nTraceback (most recent call last):\r\n  File \"official/nlp/bert/fasttext.py\", line 71, in <module>\r\n    tfa.callbacks.AverageModelCheckpoint(update_weights=False, filepath=os.path.join(MODEL_DIR, 'ckpt_moving_average'))])\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 956, in _call\r\n    filtered_flat_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.\r\n  (0) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n         [[{{node RemoteCall}}]]\r\n         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]\r\n         [[ConstantFoldingCtrl/cond/else/_1/cond/StatefulPartitionedCall/cond_2/switch_pred/_432_0/_293]]\r\n  (1) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n         [[{{node RemoteCall}}]]\r\n         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]\r\n         [[cond/else/_1/cond/StatefulPartitionedCall/cond/then/_410/cond/OptionalGetValue/_196]]\r\n  (2) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n         [[{{node RemoteCall}}]]\r\n         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_fn_with_cond_4681]\r\n\r\nFunction call stack:\r\nfn_with_cond -> fn_with_cond -> fn_with_cond\r\n```\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @fsx950223, I ran this code in 2.3 and in nightly and did not face any errors. Additionally, the stack trace you have provided seems to be from a different issue? I don't see where your code is referencing Bert.", "I ran the code in 2.4rc3, the code is not reference bert.", "The first line of the stack trace you have provided says `File \"official/nlp/bert/fasttext.py\", line 71, in <module>`. As I do not see Bert in your code I was wondering why it shows up in the stack trace.\r\n\r\nI did not see an issue in nightly. Can you please try your code with nightly? I will try with 2.4rc3\r\n\r\n[Update: I have tested with 2.4rc3 and do not see any errors there either.]", "I write the code under bert folder.\nI will check again later.", "Unfortunately, I can't reproduce the bug on the public dataset. I met the bug in my dataset pipeline, but I can't open-source it. I avoid the bug by moving vectorize_layer from model to dataset.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45395\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45395\">No</a>\n"]}, {"number": 45394, "title": "nnapi delegate and cpu output with my QAT int8 model got Inconsistent result", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):pip\r\n- TensorFlow version (use command below):2.3.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nQAT my keras model\uff0cgot tflite model\uff0cwhen I test with CPU on my Android phone\uff08R version\uff09\uff0cI got right result\uff0cafter I set useNNapi\uff08true\uff09\uff0cI got a wrong  result\u3002\r\n\r\n**Describe the expected behavior**\r\n\r\ngot the same result with CPU or nnapi\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nnnapi log:\r\n2020-12-04 12:09:34.687 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707\r\n2020-12-04 12:09:34.689 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.003921569\r\n2020-12-04 12:09:34.690 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138\r\n2020-12-04 12:09:34.690 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707\r\n2020-12-04 12:09:34.692 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138\r\n2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707\r\n2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.003921569\r\n2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138\r\n\r\ncpu log:\r\n2020-12-04 12:19:04.204 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.78125\r\n2020-12-04 12:19:04.204 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.78125\r\n2020-12-04 12:19:04.391 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.7734375\r\n2020-12-04 12:19:04.391 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.7734375\r\n2020-12-04 12:19:04.586 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.80859375\r\n2020-12-04 12:19:04.587 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.80859375\r\n2020-12-04 12:19:04.749 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.81640625\r\n2020-12-04 12:19:04.749 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.81640625\r\n2020-12-04 12:19:04.895 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.765625\r\n\r\n\r\nwhen I use nnapi the score is always low\r\n\r\n", "comments": ["@sunzhe09 \r\nPlease share simple indented stand alone code for us to replicate, or a colab gist with the error reported.", "@Saduf2019  is there any comanddline tools\uff0cI can test my model output\uff0cwith nnapi and cpu \uff1fif so I can post my test code for you", "@Saduf2019 Can we loop some one in NNAPI team here?\r\nWe need to know what op and what input data cause the issue.", "@thaink @Saduf2019 I have tested with the latested  tf-nightly aar the nnapi result seems to be the same,thanks", "@sunzhe09 It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest  stable Version of TF 2.6 and let us know if the issue still persists? Please have a look at the [reference](https://www.tensorflow.org/lite/performance/nnapi) and let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45394\">No</a>\n"]}, {"number": 45393, "title": "Is there a tutorial and guide implement with c \uff1f", "body": "Since c is covered in tensorflow version compatibility . Is there any document , book or anything else which is useful to learn tensorflow with c ( or c++ ) ?", "comments": ["@DachuanZhao \r\n\r\nPlease, refer the below links and see if it helps you.\r\n\r\nhttps://www.tensorflow.org/install/lang_c\r\nhttps://www.tensorflow.org/api_docs/cc\r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "> @DachuanZhao\r\n> \r\n> Please, refer the below links and see if it helps you.\r\n> \r\n> https://www.tensorflow.org/install/lang_c\r\n> https://www.tensorflow.org/api_docs/cc\r\n> \r\n> This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!\r\n\r\nHi @ravikyram , what I want is a guide like [https://www.tensorflow.org/guide](https://www.tensorflow.org/guide) or tutorial like  [https://www.tensorflow.org/tutorials](https://www.tensorflow.org/tutorials)", "Unfortunately we do not have such guides for c or c++ yet. I found a guide that talks about usage of c++ api for[ building custom ops](https://www.tensorflow.org/guide/create_op) in TF.\r\nSee https://github.com/tensorflow/custom-op", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 45392, "title": "tf.sparse.reorder crashes Tensorflow if number of possible entries of dense_shape overflows 64 bit int", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v1.12.1-38388-gea6516dcad 2.4.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): using bazelisk\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce RTX 2080Ti, 11G\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.sparse.reorder` crashes if number of possible entries of dense_shape overflows 64 bit int.\r\n\r\n**Describe the expected behavior**\r\n`tf.sparse.reorder` should not crash\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nt = tf.SparseTensor(indices=[[0, 0, 0, 0, 0, 0]], values=[0.0], dense_shape=[4096, 4096, 4096, 4096, 4096, 4096])\r\ntf.sparse.reorder(t)\r\n```\r\n\r\nhttps://colab.research.google.com/drive/1mfRgXxnMwskSTIZ7ctuAXXtYU430s8pg?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@eiennohito,\r\nI was able to run the code without any issues with a smaller value for `dense_shape`. \r\n\r\nIs there any specific reason you are using a tensor of such large dimensions? Thanks! ", "If you decrease dimensions of dense_shape so the number of elements fits into signed 64 bit integer the current implementation works. \r\n\r\nIn my usage (I use sparse tensors to represent graphs with lots of attributes), tensors can have lots of dimensions (e.g. ~30), and it becomes impossible to use `reorder`.", "Was able to reproduce the issue with TF v2.3, TF v2.4.0rc4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8b7f9c89274291823fb12136b89cc827/45392-tf-nightly.ipynb). Thanks!", "Added a PR #45675 to fix the issue, so that it is possible to gracefully return an error with error message.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45392\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45392\">No</a>\n"]}, {"number": 45391, "title": "tflite: Prevent from reallocation of persistent tensors", "body": "After ResetAllocationsAfter() is called, CalculateAllocations() could be called\r\nagain for nodes which have persistent temporary tensors. The logic should\r\nprevent from reallocation of these tensors since they're not going to be\r\ninitialized again.\r\n\r\nThis issue could be reproduced easily with hybrid quantized models since some\r\nhybrid kernels are using persistent temporary tensors.\r\n\r\nThis PR resolves GitHub issue #44520.\r\n\r\nPiperOrigin-RevId: 345569003\r\nChange-Id: I1b9777b33a664ebd0f09df8d3236c7ece0118b1a", "comments": []}, {"number": 45390, "title": "Revert recent SavedModel changes", "body": "Reverts the changes that adds a warning about the deprecated metadata field in the SavedModel proto, and CL with the Keras SavedModel changes. These changes still exist in master, and will be reflected in the next release.", "comments": []}, {"number": 45389, "title": "micro: list test and kernel files explicitly in Makefile", "body": "See issue #45387. We occasionally want to exclude, from the build, test and kernel files that would otherwise match wildcards.\r\n\r\nListing files explicitly, as done in this PR, is one method of achieving the goal. There is an alternative PR #45388 which keeps the wildcards and adds exclusion lists instead. This PR's scheme may be a little cleaner and less prone to merge conflicts when multiple PRs with exclusions are in-flight at the same time. Of course, the tradeoff is a long list of files; however, that's a common trend in build system configuration files these days.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "This is the chosen way to resolve #45387. I've just now rebased this on master as of 5543ed6, to ensure the wildcard-to-list conversion is as fresh as possible. We should merge ASAP to maintain that freshness."]}, {"number": 45388, "title": "micro: add mechanism for excluding sources from Makefile build", "body": "See issue #45387. We occasionally want to exclude, from the build, test and kernel files that would otherwise match wildcards.\r\n\r\nAdding exclude lists, as is done in this PR, is one method of achieving the goal. It's a little messy, however, and may be prone to merge conflicts if there are multiple PRs with exclusions in-flight at the same time. There's an alternative PR coming which explicitly lists all files instead of using wildcards and exclusion lists.\r\n\r\n@tensorflow/micro ", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "This way of accomplishing #45388 was voted down in favor of PR #45389."]}, {"number": 45387, "title": "micro: add a mechanism for excluding test and kernel sources from Makefile build", "body": "@tensorflow/micro\r\n\r\nWhen submitting a change for review which both copies and modifies a file, it's helpful to submit the copy and the modification as two separate PRs. Otherwise the PR's *files changed* tab does not show the modifications, but rather it looks as if the copied and modified file was simply added in its final form. See, for example, the sequence of PRs in the flight plan of issue #45306.\r\n\r\nTo facilitate submitting a PR which adds a file which should not yet be a part of the build (for the copy PR), add to the micro [Makefile](https://github.com/tensorflow/tensorflow/blob/5bd220564ebf66b438f09b119ae9a0bfbf59aa22/tensorflow/lite/micro/tools/make/Makefile#L246) a means to exclude kernel and test sources from the build.", "comments": ["@petewarden @advaitjain, I've associated two competing PRs with this issue, two different ways of solving the problem. I'm concerned the exclusion lists will lead to merge conflicts. And it's a little more straightforward to have a file show up in the list once its ready to be built, rather than appearing and then disappearing from an exclusion list.\r\n\r\nOne last poke at whether copying and modifying a file must be in separate PRs:\r\n\r\nWhat's lost if both steps are in the same PR but as **two separate commits** within the PR? I understand the *Files changed* tab shows the whole diff merged together, which makes it look as if the copied and modified file was simply added in its final form; however, that's simply the default view. Both the *Changes from* dropdown (under *Conversation*) and the *Commits* tab let's you see the commits individually, which makes it easy to see the modifications as distinct from the copying. This seems to achieve the goals cleanly without two separate PRs.\r\n\r\nThe only tradeoff I see to one, joint PR is that both commits must be merged or rejected as one unit; however, in this case, I don't see the value in merging only the copy and having it sit there in the directory as dead code. In fact, it seems preferable to have them show up together or not at all.\r\n\r\nIf the copy and modify can be in the same PR, this exclusion mechanism is less necessary, but still justified perhaps so the copy commit doesn't break the build (and therefore git bisect, etc.). The explicit-list alternative still looks better to me in that case than the exclusion-list alternative.\r\n\r\nThoughts?", "I'm with you that explicitly listing the kernel sources is the path forward here -- let's go with that.\r\n\r\nWhy I'd like to keep two separate PRs:\r\n\r\n * When PRs are imported internally, all the commits are squashed as a single change so to keep the copy and modify separate in the internal google version control system we need them to be separate PRs.\r\n\r\n * Even in github, I view PRs as a unit of change (rather than commits) since these are where reviews happen, are properly documented ... The build is often broken at individual commits and the only guarantee is that the merge commit for a PR is where the build is ok. In an ideal world, I would like to have PRs be merged with [a squash commit](https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/configuring-commit-squashing-for-pull-requests) to keep the git log 1:1 with the PRs.\r\n", "I've rebased the chosen approach, PR #45389, and marked it ready for review.\r\n\r\nThanks for documenting your rational for keeping two separate PRs for copy and modify. Will do.", "With the merger of #45389, this closed.", "> \r\n> One last poke at whether copying and modifying a file must be in separate PRs:\r\n> \r\n> What's lost if both steps are in the same PR but as **two separate commits** within the PR? I understand the _Files changed_ tab shows the whole diff merged together, which makes it look as if the copied and modified file was simply added in its final form; however, that's simply the default view. Both the _Changes from_ dropdown (under _Conversation_) and the _Commits_ tab let's you see the commits individually, which makes it easy to see the modifications as distinct from the copying. This seems to achieve the goals cleanly without two separate PRs.\r\n> \r\n> The only tradeoff I see to one, joint PR is that both commits must be merged or rejected as one unit; however, in this case, I don't see the value in merging only the copy and having it sit there in the directory as dead code. In fact, it seems preferable to have them show up together or not at all.\r\n> \r\n> If the copy and modify can be in the same PR, this exclusion mechanism is less necessary, but still justified perhaps so the copy commit doesn't break the build (and therefore git bisect, etc.). The explicit-list alternative still looks better to me in that case than the exclusion-list alternative.\r\n> \r\n> Thoughts?\r\n\r\nWe revisited this discussion internally again and @njeffrie made exactly the same argument as you did here.\r\n\r\nAnd after seeing the work involved in having the copy and modify be in separate PRs as well as the overhead of having dead code in the repo, I now agree with you guys.\r\n\r\nYour proposed approach is much better. Let's go with having one commit each for:\r\n 1. copy the tflite kernel\r\n 2. remove lite-specific code from copies\r\n 3. port the micro op and test\r\n\r\nThis would mean that PR3-5 in your draft op porting guide (https://github.com/rkuester/tensorflow/blob/f06b3273eb2492ca9a93399a6c6cf1492b3fd569/tensorflow/lite/micro/kernels/PORTING.md) would become 3 commits in the same PR.\r\n\r\n@njeffrie, @rkuester : does that match what you guys think would be a better process?\r\n\r\nWe can still keep the explicit list of kernel sources, even though we may not necessarily need them anymore.", "> @njeffrie, @rkuester : does that match what you guys think would be a better process?\r\n\r\nYes, combining PRs 3\u20135 into one PR with at least those three commits makes a lot of sense to me. I'll update the guide."]}, {"number": 45386, "title": "[ROCm] Re-enabling unit-tests that are now passing on ROCm platform", "body": "\r\n/cc @cheshire @chsigg @nvining-work ", "comments": ["@deven-amd  Can you please check @kkimdev's comments and keep us posted ? Thanks!", "@cheshire @chsigg gentle ping"]}, {"number": 45385, "title": "ValueError: Could not find matching function to call loaded from the SavedModel.", "body": "Code:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\n\r\nmodel = tf.keras.models.load_model(\"Model\")\r\nprint(model) # First line of output.\r\n\r\ninputs = Input(shape=(1, 12, 12))\r\noutputs = model(inputs) # Error appears on this line.\r\n```\r\nOutput:\r\n```\r\n<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7fc5335efd00>\r\n\r\nTraceback (most recent call last):\r\n  File \"example.py\", line 12, in <module>\r\n    outputs = model(inputs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 509, in _call_attribute\r\n    return instance.__call__(*args, **kwargs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\r\n    *args, **kwds))\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 257, in restored_function_body\r\n    \"\\n\\n\".join(signature_descriptions)))\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * Tensor(\"None_0:0\", shape=(None, 1, 12, 12), dtype=float32)\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 1 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (0 total):\r\n    *\r\n  Keyword arguments: {'main_input': TensorSpec(shape=(None, 1, 12, 12), dtype=tf.float32, name='main_input')}\r\n```\r\n\r\n**System information**\r\n- Python 3.6.12\r\n- Tensorflow 2.3.1 (CPU)\r\n- Keras 2.4.3", "comments": ["@ardamavi \r\n\r\nPlease,share `Model` file to reproduce the issue in our environment.It helps us in localizing the issue faster.Please, try with TF nightly versions as well and see if the issue still persists.\r\n\r\nThanks!", "@ravikyram \r\nThe model comes from outside, I cannot make changes on it.\r\n\r\nWhen I try with TF nightly version I got this error:\r\n`Cannot convert a symbolic Tensor to a numpy array. `\r\nI am trying to call `model()` inside of `Lambda Layer` but I got the same error that I share first.", "@ardamavi Can you please share simple standalone code? The current code is incomplete as the saved model is not uploaded. Can you please use any simple model to demonstrate the issue? Thanks!", "I have exactly same problem.\r\nDid you solve it?", "I solved this problem.\r\n\r\nyour code:\r\n<pre><code>\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\n\r\nmodel = tf.keras.models.load_model(\"Model\")\r\nprint(model) # First line of output.\r\n\r\ninputs = Input(shape=(1, 12, 12))\r\noutputs = model(inputs) # Error appears on this line.\r\n</code></pre>\r\n\r\nand change it as below:\r\n\r\n<pre><code>\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\n\r\nmodel = tf.keras.models.load_model(\"Model\")\r\nprint(model) # First line of output.\r\n\r\ninputs = Input(shape=(1, 12, 12))\r\ninference = model.signatures[\"serving_default\"]\r\noutputs = inference(inputs) # Error appears on this line.\r\n</code></pre>\r\n\r\nthen, it might work :)", "> I solved this problem.\r\n> \r\n> your code:\r\n> \r\n> ```\r\n> \r\n> import tensorflow as tf\r\n> from tensorflow.keras.layers import Input\r\n> \r\n> model = tf.keras.models.load_model(\"Model\")\r\n> print(model) # First line of output.\r\n> \r\n> inputs = Input(shape=(1, 12, 12))\r\n> outputs = model(inputs) # Error appears on this line.\r\n> ```\r\n> \r\n> and change it as below:\r\n> \r\n> ```\r\n> \r\n> import tensorflow as tf\r\n> from tensorflow.keras.layers import Input\r\n> \r\n> model = tf.keras.models.load_model(\"Model\")\r\n> print(model) # First line of output.\r\n> \r\n> inputs = Input(shape=(1, 12, 12))\r\n> inference = model.signatures[\"serving_default\"]\r\n> outputs = inference(inputs) # Error appears on this line.\r\n> ```\r\n> \r\n> then, it might work :)\r\n\r\n@seongkyun\r\nI try your suggestion, this time I get another error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: input_1:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1655, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1673, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1722, in _call_with_flat_signature\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 106, in _call_flat\r\n    cancellation_manager)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 550, in call\r\n    ctx=ctx)\r\n  File \"/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 74, in quick_execute\r\n    \"tensors, but found {}\".format(keras_symbolic_tensors))\r\ntensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_1:0' shape=(None, 1, 12, 12) dtype=float32>]\r\n```", "type below at terminal then you can see the I/O shapes of the model:\r\n\r\n$ saved_model_cli show --dir PATH/TO/PB/FILE --tag_set serve --signature_def serving_default\r\n\r\nthe PATH/TO/PB/FILE is the folder including asset, variables folders and saved_model.pb file.\r\n\r\nIs the input shape correct?\r\n\r\n", "> type below at terminal then you can see the I/O shapes of the model:\r\n> \r\n> $ saved_model_cli show --dir PATH/TO/PB/FILE --tag_set serve --signature_def serving_default\r\n> \r\n> the PATH/TO/PB/FILE is the folder including asset, variables folders and saved_model.pb file.\r\n> \r\n> Is the input shape correct?\r\n\r\n@seongkyun \r\nYes, the input shape is correct:\r\n```\r\ndtype: DT_FLOAT\r\nshape: (-1, 1, 12, 12)\r\n```", "@ardamavi Is this Sequential/Functional/Subclass model? \r\n\r\nIs it possible to take a simple public dataset and create a standalone code for us to reproduce your issue. Issue can be resolved faster with a Standalone code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45385\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45385\">No</a>\n"]}, {"number": 45383, "title": "RTX 3070 - CUBLAS_STATUS_ALLOC_FAILED", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/A\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): tf-nightly 2.5.0-dev20201203\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1 / 8.0.4.30\r\n- GPU model and memory: RTX 3070\r\n\r\n```\r\nimport warnings\r\nfrom distutils.version import LooseVersion\r\nimport warnings\r\nimport tensorflow as tf\r\n\r\n# Check TensorFlow Version\r\nassert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\r\nprint('TensorFlow Version: {}'.format(tf.__version__))\r\n\r\n# Check for a GPU\r\nif not tf.test.gpu_device_name():\r\n    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\r\nelse:\r\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\r\n    \r\n    import numpy\r\nimport csv\r\n\r\nfilename = \"jokes_plain_tweet_data.txt\"\r\nraw_text = open(filename).read()\r\nraw_text = raw_text.lower()\r\n\r\n# strip unwanted characters\r\nraw_text = raw_text.replace('\"', '')\r\nraw_text = raw_text.replace('\\n', '')\r\nraw_text = raw_text.replace('#', '')\r\n\r\n# create mapping of unique chars to integers\r\nchars = sorted(list(set(raw_text)))\r\nchar_to_int = dict((c, i) for i, c in enumerate(chars))\r\nprint(char_to_int)\r\n\r\nn_chars = len(raw_text)\r\nn_vocab = len(chars)\r\n\r\n# prepare the dataset of input to output pairs encoded as integers\r\nseq_length = 140\r\n\r\ndataX = []\r\ndataY = []\r\n\r\n# creates a sequence of 100 characters, output contains the corrosponding character that follows.\r\n# window of 'seq_length' that increments across each character.\r\n\r\nfor i in range(0, n_chars - seq_length, 1):\r\n    seq_in = raw_text[i:(i + seq_length)]\r\n    seq_out = raw_text[i + seq_length]\r\n    \r\n    #append to training data\r\n    dataX.append([char_to_int[char] for char in seq_in])\r\n    dataY.append(char_to_int[seq_out])\r\n    \r\n    \r\nn_patterns = len(dataX)\r\nprint(\"Total Patterns: \", n_patterns)\r\n\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Dropout\r\nfrom tensorflow.keras.layers import LSTM\r\nfrom tensorflow.keras.layers import Embedding\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom keras.utils import np_utils\r\n\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\n# reshape X to be [samples, time steps, features]\r\n#X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\r\nX = numpy.reshape(dataX, (n_patterns, seq_length, 1))\r\n\r\n# normalize\r\nX = X / float(n_vocab)\r\n\r\n# one hot encode the output variable\r\ny = np_utils.to_categorical(dataY)\r\n\r\n# define the LSTM model\r\nmodel = Sequential()\r\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(LSTM(128))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(Dense(y.shape[1], activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\r\n\r\n# define the checkpoint\r\nfilepath=\"weights\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\r\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\ncallbacks_list = [checkpoint]\r\n\r\nhistory = model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)\r\n\r\n\r\n\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/101088390-7de59180-3568-11eb-8c73-cc0d47f1b296.png)\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/101091615-41686480-356d-11eb-957f-ddfc5d3c22ef.png)\r\n\r\n\r\n\r\nfiles for code here:\r\n\r\nhttps://ea4269d4-d326-4ad3-8762-3cd36a7b1e50.filesusr.com/archives/d9662a_32aa1694580b4fd698345293e04104b2.rar?dn=tensorflow-gpu-tutorial.rar\r\n\r\n", "comments": ["Based on testing and other models, I believe the bug is in the utils. Any models importing utils cannot run correctly. Any help on this would be greatly appreciated! Code without utils will run.", "@Bchi1994 \r\nCan you please try with CUDA 11.0? TF 2.4 (and nightly) is built and tested against CUDA 11.0, not 11.1.\r\nAlso the code shared is not in format for us to replicate, if possible please share a colab gist with error reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Seems to be a recurring issue that is happening with a lot of Ampere Cards. You need to enable memory growth at the start of the script, just after importing tensorflow to stop it from running out of memory.\r\n\r\n```\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntry:\r\n  tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\nexcept RuntimeError as e:\r\n  print(e)\r\n```\r\n\r\nYou can also skip this step by having the `TF_FORCE_GPU_ALLOW_GROWTH` environment variable set to `TRUE`", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45383\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45383\">No</a>\n"]}, {"number": 45382, "title": "micro: fix null-dereference build warning/error on g++ 10.2", "body": "Without the added ENSURE, g++ flags an:\r\n\r\n    error: potential null pointer dereference [-Werror=null-dereference]\r\n\r\nin both of these locations while building from the Makefile a la:\r\n\r\n    % g++ --version\r\n    g++ (Debian 10.2.0-19) 10.2.0\r\n\r\n    % make -f tensorflow/lite/micro/tools/make/Makefile test\r\n\r\nwhich breaks the build.\r\n\r\nFixes #45381.\r\n\r\n----\r\nNot sure if this is the best way to fix this. The warning-as-error is annoying considering this is a pretty straightforward uses of GetEvalOutput and GetTensorData. Not certain why it isn't triggered on other uses of the return from GetTensorData, perhaps being within control-flow constructs causes g++ to assume the nullptr case is already handled.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "The underlying issue was fixed by a different means. See #45381."]}, {"number": 45381, "title": "micro: null-dereference warning breaks Makefile build on g++ 10.2", "body": "@tensorflow/micro\r\n\r\n### Description\r\n\r\nChanges merged yesterday in 17130a8f trigger a warning treated as an error that breaks a Makefile build on g++10.2:\r\n```\r\n% git describe --all --long\r\nheads/master-0-g34f2adacdbe\r\n\r\n% make -f tensorflow/lite/micro/tools/make/Makefile test\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/Makefile:478: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/Makefile:478: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ng++ -std=c++11 -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter   -DTF_LITE_USE_CTIME -I. -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/kissfft -c tensorflow/lite/micro/kernels/detection_postprocess.cc -o tensorflow/lite/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/micro/kernels/detection_postprocess.o\r\ntensorflow/lite/micro/kernels/detection_postprocess.cc: In function \u2018TfLiteStatus tflite::{anonymous}::Eval(TfLiteContext*, TfLiteNode*)\u2019:\r\ntensorflow/lite/micro/kernels/detection_postprocess.cc:590:58: error: potential null pointer dereference [-Werror=null-dereference]\r\n  590 |   tflite::micro::GetTensorData<float>(num_detections)[0] =\r\n      |   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\n  591 |       size_of_sorted_indices;\r\n      |       ~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/micro/kernels/detection_postprocess.cc:686:58: error: potential null pointer dereference [-Werror=null-dereference]\r\n  686 |   tflite::micro::GetTensorData<float>(num_detections)[0] = output_box_index;\r\n      |   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~\r\ncc1plus: all warnings being treated as errors\r\nmake: *** [tensorflow/lite/micro/tools/make/Makefile:490: tensorflow/lite/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/micro/kernels/detection_postprocess.o] Error 1\r\n```\r\n\r\nThis does not trigger a build error on tests run via `bazel test tensorflow/lite/micro/kernels:all:`. Perhaps that uses a different compiler than the `make`-initiated build.\r\n\r\n### System information\r\n\r\nThis is with the native g++ in Debian bullseye:\r\n```\r\n% g++ --version\r\ng++ (Debian 10.2.0-19) 10.2.0\r\n[....]\r\n```\r\n\r\n\r\n", "comments": ["@mansnils, bringing this to your attention since 17130a8 is attributed to you.", "PR https://github.com/tensorflow/tensorflow/pull/45286 updated the patching to fix the underlying issue but needs the downloaded flatbuffers directory to be removed so that the updated patching can be used.\r\n\r\nThis should hopefully fix your issue:\r\n```\r\nrm -rf tensorflow/lite/micro/tools/make/downloads/flatbuffers\r\nmake -f tensorflow/lite/micro/tools/make/Makefile test\r\n```\r\n\r\nI'm going to close this issue but please reopen if it is not resolved with my suggestion.", "Note that the reason why the error does not show up with bazel is that make and bazel use different versions of the flatbuffers library and only the make version had the patch from https://github.com/tensorflow/tensorflow/pull/45040, which was then fixed with https://github.com/tensorflow/tensorflow/pull/45286. \r\n\r\nSee [this comment](https://github.com/tensorflow/tensorflow/issues/44971#issuecomment-736130061) for additional context.", "I see, it has nothing to do with a change in warnings in g++ 10.2, but rather a diagnostic pragma that was improperly cleared (see fix in 87b03eeb).\r\n\r\nThank you. Your suggestion did indeed fix the build issue. Leaving this issue closed and closing the linked PR #45382."]}, {"number": 45380, "title": "Try to switch to h5py 3.1.0", "body": "", "comments": ["This is the new strings r/w behavior for 3.x series: https://docs.h5py.org/en/latest/strings.html", "Just to reference the original ticket https://github.com/tensorflow/tensorflow/issues/44467", "In the CI logs I see different unicode issues related to https://docs.h5py.org/en/latest/strings.html#what-about-numpy-s-u-type\r\n> TypeError: No conversion path for dtype: dtype\r\n\r\nBut CPU tests don't fail locally inside the official TF devel image `tensorflow/tensorflow:devel`.\r\n\r\nIt is hard to work locally where official devel images are not aligned with the CI. \r\nI think an user can expect to collect the same test result of the CI `Ubuntu CPU` as locally with `tensorflow/tensorflow:devel` if not it will be hard to develop in a local reproducible system.\r\n\r\nI think that probably this is caused unaligned `tensorflow/tensorflow:devel` with `LANG_CTYPE=C.UTF-8` and other image used from the CI that are `LC_CTYPE=\"POSIX\"`", "I've tried to use  `POSIX` locally in `tensorflow/tensorflow:devel` but tests are passing. I cannot reproduce CI fails..\r\n\r\nSo I've just reverted on one of the first commit to let you see that Linux is passing but not Win/Mac", "@mihaimaruseac What was the Win and OSX issue?", "Windows seems to be broken at HEAD due to an MLIR integrate from 12 hours ago.\r\n\r\nMacOS seemed to pass. Probably the environment is different? Hopefully there is no rollback.", "@mihaimaruseac Can you reopen this? Do you have Shell access on a win/MacOS machine?", "I cannot reopen, GitHub does not let me :(\r\n\r\nI can get access to a windows machine, but it will take a while as I have a few P0 items to finish this week/early next week.", "Yes I know it is merged but I meant something like https://github.com/tensorflow/tensorflow/pull/45487"]}, {"number": 45379, "title": "Why use  (tanh(a + b)) instead of  (tanh(a) + tanh(b)) or does it not matter in some cases?", "body": "I am not sure if this is a documentation issue or an actual problem - please advise:\r\n\r\nIn this [machine translation exercise](https://www.tensorflow.org/tutorials/text/nmt_with_attention):\r\n\r\nWhy does this `class BahdanauAttention` (see class definition at end) do the additive attention as:\r\n\r\n`tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values))`\r\n\r\ninstead of:\r\n\r\n`tf.nn.tanh(self.W1(query_with_time_axis) + tf.nn.tanh(self.W2(values)`\r\n\r\nOr, in other words, why does it use: `tanh(a+b)` instead of `tanh(a) + tanh(b)`?\r\n\r\nIf both `self.W1` and `self.W2` are separate neural network layers, why don't they get their own separate activation functions?\r\n\r\n`tanh` restricts the output between `-1` and `+1`, centered at 0 which makes learning gradient descent quicker\r\n\r\n```\r\nclass BahdanauAttention(tf.keras.layers.Layer):\r\n  def __init__(self, units):\r\n    super(BahdanauAttention, self).__init__()\r\n    self.W1 = tf.keras.layers.Dense(units)\r\n    self.W2 = tf.keras.layers.Dense(units)\r\n    self.V = tf.keras.layers.Dense(1)\r\n\r\n  def call(self, query, values):\r\n    # query hidden state shape == (batch_size, hidden size)\r\n    # query_with_time_axis shape == (batch_size, 1, hidden size)\r\n    # values shape == (batch_size, max_len, hidden size)\r\n    # we are doing this to broadcast addition along the time axis to calculate the score\r\n    query_with_time_axis = tf.expand_dims(query, 1)\r\n\r\n    # score shape == (batch_size, max_length, 1)\r\n    # we get 1 at the last axis because we are applying score to self.V\r\n    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n    score = self.V(tf.nn.tanh(\r\n        self.W1(query_with_time_axis) + self.W2(values)))\r\n\r\n    # attention_weights shape == (batch_size, max_length, 1)\r\n    attention_weights = tf.nn.softmax(score, axis=1)\r\n\r\n    # context_vector shape after sum == (batch_size, hidden_size)\r\n    context_vector = attention_weights * values\r\n    context_vector = tf.reduce_sum(context_vector, axis=1)\r\n\r\n    return context_vector, attention_weights\r\n\r\n\r\n```", "comments": ["Questions unrelated to TensorFlow are better suited for general Q&A sites like https://stackoverflow.com/ .\r\n\r\nPersonally, I think that both approaches would result in similar performance; the idea behind the original formulation is that you project both the decoder state and the encoded word to the same space (using a linear transformation), sum them, and then continue with a single representation (so apply bias, non-linearity, and process the result further). But you can also imagine the projection to the shared space to be non-linear (including the tanh).\r\n\r\nMathematically, the biggest difference between the two formulations is when for example a=-4 and b=2; then the individual tanhs are close to -1 and 1, so the sum is 0; but tanh of the sum is close to -1 -- but if the outputs of the previous layers would be small, then tanh(a) is close to a, and tanh(a+b) ~ a + b ~ tanh(a) + tanh(b).", "Yes, thanks for clarifying this. I was curious if this was a possible code change so posted it here as well.\r\n\r\nMakes sense that the difference of the outcome between the two approaches (`tanh(a+b)` VS `tanh(a) + tanh(b)`) will be high when `a` (or `query_with_time_axis`) and `b` (`values` or the encoder output) are each in the plateau portion of the `tanh`. Otherwise, generally similar performance. "]}, {"number": 45378, "title": "Enable use of generators in tf lite model maker", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Using Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version (use command below): 2+\r\n- Python version: Default Colab\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n\r\nThe current api of tensorflow model maker accepts a dataset created using following:\r\n\r\n```\r\nfrom tflite_model_maker import ImageClassifierDataLoader\r\ndata = ImageClassifierDataLoader.from_folder('path')\r\ntrain_data, rest_data = data.split(0.8)\r\nvalidation_data, test_data = rest_data.split(0.5)\r\n\r\nmodel = image_classifier.create(train_data, model_spec=model_spec.efficientnet_lite4_spec, validation_data=validation_data, epochs=75, learning_rate=0.01, dropout_rate=0.3)\r\n```\r\nHowever it does not accept a generator which can be used to provide customized augmentation code. Here is an example of generator from this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_image_retraining#looking_for_a_tool_instead):\r\n\r\n```\r\ndatagen_kwargs = dict(rescale=1./255, validation_split=.20)\r\ndataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\r\n                   interpolation=\"bilinear\")\r\n\r\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n    **datagen_kwargs)\r\nvalid_generator = valid_datagen.flow_from_directory(\r\n    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\r\n\r\ndo_data_augmentation = False\r\nif do_data_augmentation:\r\n  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n      rotation_range=40,\r\n      horizontal_flip=True,\r\n      width_shift_range=0.2, height_shift_range=0.2,\r\n      shear_range=0.2, zoom_range=0.2,\r\n      **datagen_kwargs)\r\nelse:\r\n  train_datagen = valid_datagen\r\ntrain_generator = train_datagen.flow_from_directory(\r\n    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)\r\n\r\n```\r\nPassing train_generator and valid_generator to image_classifier.create throws an exception. \r\n\r\n**Describe the expected behavior**\r\nimage_classifier.create method should accept train_generator and valid_generator as created in the example above or some other method should be provided to customized augmentation code for both train and validation images.\r\n\r\n**Standalone code to reproduce the issue**\r\nUse https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\r\nand use the code provided above to create train_generator and valid_generator then run following:\r\n\r\nmodel = image_classifier.create(train_generator, model_spec=model_spec.mobilenet_v2_spec, validation_data=valid_generator, epochs=75, learning_rate=0.01, dropout_rate=0.3)\r\n\r\n**Other info / logs** \r\n\r\n---------------------------------------------------------------------------\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n\r\n<ipython-input-43-a03b2f96410f> in <module>()\r\n      1 # Train using models available in model maker\r\n----> 2 model = image_classifier.create(original_generator, model_spec=model_spec.mobilenet_v2_spec, validation_data=validation_data, epochs=50, learning_rate=0.01, dropout_rate=0.2)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py in create(train_data, model_spec, validation_data, batch_size, epochs, train_whole_model, dropout_rate, learning_rate, momentum, shuffle, use_augmentation, use_hub_library, warmup_steps, model_dir, do_train)\r\n    116   image_classifier = ImageClassifier(\r\n    117       model_spec,\r\n--> 118       train_data.index_to_label,\r\n    119       train_data.num_classes,\r\n    120       shuffle=shuffle,\r\n\r\nAttributeError: 'DirectoryIterator' object has no attribute 'index_to_label'\r\n", "comments": ["@syeds-git \r\nPlease share a colab gist with the error reported.", "@Saduf2019 please see this link: \r\n\r\nhttps://github.com/syeds-git/TensorflowIssue-45378/blob/main/Colab_for_Tensorflow_Issue_45378.ipynb\r\n\r\nThanks\r\n", "@ymodak \r\nI am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/c6550efa16412758fd4329de083dedab/untitled477.ipynb),gist for [tf 2.4](https://colab.research.google.com/gist/Saduf2019/639bd62dea850cbd36f1ad9e7d852e66/untitled482.ipynb).", "@syeds-git  For enabling augmentation you can set `use_augmentation` flag as True,\r\nhttps://github.com/tensorflow/examples/blob/f6b78e7d8d604ff542dac62432be46d02021ce63/tensorflow_examples/lite/model_maker/core/task/image_classifier.py#L45-L59\r\n```python\r\nmodel = image_classifier.create(train_data, use_augmentation=True)\r\n```\r\nIt performs data augmentation with default values  as `rotation_range=40, horizontal_flip=True, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2`\r\nSee https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier#advanced-usage", "@ymodak the documentation is for the command line tool. Is it possible to provide different values using image_classifier.create method?", "I am afraid not. It simply provides an option to perform data augmentation with default `hparams`.\r\nhttps://github.com/tensorflow/hub/blob/a13500b5465b1ca168e6089104a6dbbd9725219f/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L69-L88", "@ymodak possible to have this capability in future?", "I don't see any conclusive information on the [TF Lite roadmap](https://www.tensorflow.org/lite/guide/roadmap) regarding it.\r\nHowever you may try posting a thread and tagging this issue on [TF Lite discussion group](https://groups.google.com/a/tensorflow.org/g/tflite). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45378\">No</a>\n"]}, {"number": 45377, "title": "tflite RuntimeError: Encountered unresolved custom op: StridedSlice failed to prepare. ", "body": "**System information**\r\n- Ubuntu 18.04\r\n- tensorflow 2.4-rc3 and tf-nightly-2.5.0.dev20201203\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to get tflite to work with a model I trained with keras using the subclassed model api.\r\n\r\n```python\r\nloaded_model = tf.keras.models.load_model(\"foo.ckpt\")\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\r\nconverter.allow_custom_ops = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_quant_model = converter.convert()\r\nmodel_quant_file = Path(\"bar.tflite\")\r\nmodel_quant_file.write_bytes(tflite_quant_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=\"bar.tflite\")\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\nLeads to:\r\n\r\n```python\r\n    257   def allocate_tensors(self):\r\n    258     self._ensure_safe()\r\n--> 259     return self._interpreter.AllocateTensors()\r\n    260 \r\n    261   def _safe_to_run(self):\r\n\r\nRuntimeError: Encountered unresolved custom op: StridedSlice.Node number 0 (StridedSlice) failed to prepare.\r\n```\r\n\r\nSo I guess StridedSlice ops aren't implemented yet for tflite?\r\n", "comments": ["@lminer \r\n\r\nPlease, share simple standalone code with supporting files (foo.ckpt) to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "I think there are unsupported StridedSlice operation inputs by TFLite StridedSlice op. You will be able to run your model with Select TF ops. https://www.tensorflow.org/lite/guide/ops_select", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45377\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45377\">No</a>\n"]}, {"number": 45376, "title": "EfficientNet - Conversion to TFlite", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung S9\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.0\r\n- TensorFlow LITE version (use command below): 2.3.0\r\n- Python version: 3.7.4\r\n\r\n\r\n**Describe the current behavior**\r\nI'm trying to convert the EfficientNet Model to a TFLite model. \r\n\r\n```python\r\nefficientnet = tf.keras.applications.EfficientNetB0(\r\n    include_top=True,\r\n    weights=\"imagenet\",\r\n    input_tensor=None,\r\n    input_shape=None,\r\n    pooling=None,\r\n    classes=1000,\r\n    classifier_activation=\"softmax\",\r\n)\r\n\r\n# Save h5 model to device\r\nefficientnet.save('effnet_b0.h5', compile=False)\r\n# Load h5 model from device\r\neffNetLoaded = tf.keras.models.load_model('effnet_b0.h5')\r\n\r\n# Convert model to .tflite format \r\nconverter = tf.lite.TFLiteConverter.from_keras_model(efficientnet)\r\ntflite_model = converter.convert()\r\nopen('effnet_b0.tflite', \"wb\").write(tflite_model)\r\n```\r\n\r\nWhen using `effnet_b0.tflite` in Android I'm getting the following error (GPU delegate):\r\n\r\n`java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`\r\n\r\nI couldn't find much information about this error. I noticed the input was `[None, 224, 224, 3]`, but after changing to `[1, 224, 224, 3]` problem persisted. \r\n\r\nAppreciate any help or info you could give. I'll be happy to provide additional info.", "comments": ["If you compile the model after model instantiation that can solve the issue.\r\n```python\r\nefficientnet.compile(optimizer='rmsprop', loss=None, metrics=['accuracy'])\r\n# Save h5 model to device\r\nefficientnet.save('effnet_b0.h5')#, compile=False)\r\n...\r\n```", "To run TFLite model with GPU delegate or NNAPI, the model should have a static shape. When you convert your model, could you set a fixed input shape when you are creating a keras model?", "Setting the input size fixed it. I tried it previously but some asset must have been mixed up during tests. This time I was more careful \ud83d\udc53  Thanks guys, problem solved. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45376\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45376\">No</a>\n", "@tgpsantos Hello, sorry for editing questions at this closed issue.\r\nI am facing exactly same issue with you.\r\nCan you please share how you solved this issue?\r\n\r\nDid you fix input shape after training? what I could get from the information here was like below.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.models.load_model('./model_best.h5')\r\nmodel.input.set_shape((1, 224, 224, 3))\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(\"model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nIs it the way you'd tried?\r\nThanks,", "hey @mhyeonsoo\r\nIt's been some months already but I believe I've set the shape in the model creation (before saving it as a .h5). But your snippet _should_ work, not sure why it is not working (tbh I think I had the same problem)"]}, {"number": 45375, "title": "Update README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45375) for more info**.\n\n<!-- need_sender_cla -->"]}]