[{"number": 3226, "title": "Failure to build from source", "body": "Hello,\nI'm trying to build tensorflow with GPU enabled from source using the instructions given here. https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-linux.\n\nThe build for the tutorial_example_trainer fails for me, with no error messages that I can discern. Please advise\n\n```\n215 ____Building complete.\n216 Target //tensorflow/cc:tutorials_example_trainer failed to build\n217 ____Elapsed time: 25.909s, Critical Path: 25.58s\n\n```\n### Environment info\n\nOperating System:\nDebian 3.16.7\n\nInstalled version of CUDA and cuDNN: \nCUDA: 7.5\ncuDNN: 4.0\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n>ls -l ~/local/cuda-7.5/lib/libcud*\n-rw-r--r-- 1 firdaus firdaus 185K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudadevrt.a\nlrwxrwxrwx 1 firdaus firdaus   16 Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5*\nlrwxrwxrwx 1 firdaus firdaus   19 Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18*\n-rwxr-xr-x 1 firdaus firdaus 305K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so.7.5.18*\n-rw-r--r-- 1 firdaus firdaus 545K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart_static.a\n```\n\nIf installed from sources, provide the commit hash:\n`commit 70de76e696c21da617fd2e6435cf7fedab220db8`\n### Steps to reproduce\n1.  bazel build  --verbose_failures -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer \n### What have you tried\n1. I had to patch the build file in third_party/gpus/crosstool/CROSSTOOL to point it to a non-standard gcc path.\n   ![image](https://cloud.githubusercontent.com/assets/923438/16667600/5c4a98fc-445b-11e6-9ff7-ef84f6df971c.png)\n### Logs or other output that would be helpful\n\nAttached.\n[buildlog.txt](https://github.com/tensorflow/tensorflow/files/352935/build.txt)\n", "comments": ["Debian 3.16 is quite an old version of Linux, so it is unsurprising that you need to build custom gcc and hack the build configuration. It's unclear whether you were able to get it to work with your custom changes to the build file or not. Regardless, I would suggest upgrading to a version we support like Ubuntu 16. Unfortunately, we are unable to support older versions of Linux. I am closing for now. Please reopen if a bug is discovered.\n", "I am not able to upgrade since I don't have admin on this machine.\nTherefore, I would appreciate it if you can point me to what the cause of the error / failure is ? \n", "I apologize that I can't tell you what the problem is, and I can't reproduce your problem since we don't have any machines with your operating system. So, if you want to get it working, you will need to go into the bazel build log you attached, search for the word error and discover that. Doing that, it looks like a \"dependency is undeclared\". That usually means the build file has incorrectly declared the dependencies, but since other systems work, it is more likely in this case to be that bazel is not working properly on the older version of Linux. This is probably because it, too, does not support old versions of Linux. You _may_ be able to  hack bazel or the build file to make this work, but it is assuredly going to be difficult. Trying to convince your admin to upgrade Linux is probably a better use of your time. There are not even security patches for that version of Debian, which means it is probably ill-advised to keep running it. Good Luck!\n", "The following error \n\n```\nERROR: /srv/local/1/tmp/tensorflow/tensorflow/core/kernels/BUILD:1478:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':\n  '/srv/home/tsdist/vats_deployments/hzhang-tensorflow-cd5c92d2012f19ea907a9f13a0d99ead1901e82a/ext/public/gnu/gcc/4/9/1/dist/lib/gcc/x86_64-unknown-linux-gnu/4.9.1/include-fixed/limits.h'\n```\n\ncan be solved by adding the line \n\n```\ncxx_builtin_include_directory: \"/srv/home/tsdist/vats_deployments/hzhang-tensorflow-cd5c92d2012f19ea907a9f13a0d99ead1901e82a/ext/public/gnu/gcc/4/9/1/dist/lib/gcc/x86_64-unknown-linux-gnu/4.9.1\"\n```\n\nin `tensorflow/third_party/gpus/crosstool/CROSSTOOL` at around line 64.\n\nBasically, you need to tell bazel the location of the GCC include path.\n\nGood luck, but since you've got gcc 4.9.1 installed, it should be possible.\n\nI've done this successfully with gcc4.8.5, also on an old system.\n", "thanks. that solved it!\nOn Jul 7, 2016 23:18, \"Raingo\" notifications@github.com wrote:\n\n> The following error\n> \n> ERROR: /srv/local/1/tmp/tensorflow/tensorflow/core/kernels/BUILD:1478:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':\n> this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':\n>   '/srv/home/tsdist/vats_deployments/hzhang-tensorflow-cd5c92d2012f19ea907a9f13a0d99ead1901e82a/ext/public/gnu/gcc/4/9/1/dist/lib/gcc/x86_64-unknown-linux-gnu/4.9.1/include-fixed/limits.h'\n> \n> can be solved by adding the line\n> \n> cxx_builtin_include_directory: \"/srv/home/tsdist/vats_deployments/hzhang-tensorflow-cd5c92d2012f19ea907a9f13a0d99ead1901e82a/ext/public/gnu/gcc/4/9/1/dist/lib/gcc/x86_64-unknown-linux-gnu/4.9.1\"\n> \n> in tensorflow/third_party/gpus/crosstool/CROSSTOOL at around line 64.\n> \n> Basically, you need to tell bazel the location of the GCC include path.\n> \n> Good luck, but since you've got gcc 4.9.1 installed, it should be possible.\n> \n> I've done this successfully with gcc4.8.5, also on an old system.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3226#issuecomment-231265717,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AA4XLr1C3J77xGi5clIrb2BT-qB3m7qcks5qTcFzgaJpZM4JHcMZ\n> .\n", "Glad it worked!\n"]}, {"number": 3225, "title": "Make cuDNN compile-time vs. load-time validation use major version only", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n\n```\n\u279c ~ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   322936 Feb 27 11:34 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Feb 27 11:34 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4\nlrwxrwxrwx 1 root root       17 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 61453024 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Pip package: `https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl`\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\n\u279c ~ python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.9.0\n```\n### Steps to reproduce\n1. `git clone https://github.com/soumith/convnet-benchmarks`\n2. Go to `tensorflow` and run `python benchmark_googlenet.py`\n### Logs\n\n```\n\u279c tensorflow git:(master) python benchmark_googlenet.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:8a:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:8a:00.0)\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:346] Loaded cudnn library: 4004 but source was compiled against 4007.  If using a binary install, upgrade your cudnn library to match.  If building from sources, make sure the library loaded matches the version you specified during compile configuration.\nF tensorflow/core/kernels/conv_ops.cc:459] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)\n[1]    18918 abort (core dumped)  python benchmark_googlenet.py\n```\n\nNotice the line: **Loaded cudnn library: 4004 but source was compiled against 4007**.  If using a binary install, upgrade your cudnn library to match.  If building from sources, make sure the library loaded matches the version you specified during compile configuration.\n", "comments": ["The benchmark script ran fine with TF 0.8.\n", "Did doing what the message say, work? I.e. you are using a binary pip so try upgrading cudnn?\n", "As you can see from the `ls -l /usr/local/cuda/lib64/libcud*`, my cuDNN is already 4.0.7. I cannot upgrade cuDNN further.\n", "You probably have both an old and new version of cudnn on your machine and your search path LD_LIBRARY_PATH is finding the old one. Read the manual on LD_DEBUG so you can trace what libraries are loading (use grep with it)\n", "What @aselle suggests is a good short-term diagnosis solution.\n\nWe can probably start thinking about making this check a little less restrictive by comparing only the major version number.  I believe NVidia has been providing ABI compatibility within major versions lately.  I'll try to get to this some time.\n", "@aselle Thanks. There was indeed a hidden cudnn 4.0.4.\n", "Reopening to keep the feature request open\n", "I am having same issue: I am having same issue and tried everything.\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 5004 (compatibility version 5000) but source was compiled with 5103 (compatibility version 5100). If using a binary install, upgrade your CuDNN library to match. If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\nF tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \nAborted (core dumped)\n\nI tried uninstall and install several times with cuda 7.5 and 8. I tried cudann 4, 5, 5.1. NOthing worked. \nWhat else I can do?\n", "I am having exactly the same problem.\r\n\r\n```\r\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\r\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y\r\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y\r\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\r\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)\r\n> E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5103 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\r\n> \r\n```", "Hi @drorhilman I am running Ubuntu 14.04, Cuda 8.0 and received your same error with cuDNN 5.0. I upgraded to cuDNN 5.1 and the error went away."]}, {"number": 3224, "title": "Error polling for event status: failed to query event: CUDA_ERROR_MISALIGNED_ADDRESS", "body": "### Summary:\n\nTrying inceptionv3, was working fine all the way until I downgraded gcc 5+ to gcc4.9 to use Theano with keras: following this example http://deeplearning.net/software/theano/install_ubuntu.html\n\nNow hitting this error before training starts (bottlenecks generate fine) whenever i run \n\nbazel-bin/tensorflow/examples/image_retraining/retrain --image_dir <image dir>\n\n```\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_MISALIGNED_ADDRESS\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n```\n\nCant figure out the problem. Sidenote that might help: bottlenecks generated alot faster when i used gcc 4.9 instead, but now the training crashes and i cant even run.\n### Environment info\n\nOperating System:\nUbuntu 16.04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n`ls: cannot access '/path/to/cuda/lib/libcud*': No such file or directory\n`\nIt's installed in /usr/local/cuda and /usr/local/cuda-7.5 instead.\n\nCUDA 7.5, CuDNN v4.\n\nInstall steps:\nCUDA: \n`bash cuda_7.5.18_linux.run --override\n`\nCUDNN:\nTried both:\n\n```\n\ntar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz\nsudo cp cuda/include/cudnn.h /usr/local/cuda-7.5/include\nsudo cp -r cuda/lib64/. /usr/local/cuda-7.5/lib64\n\n```\n\nand from here:\nhttp://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\n```\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl\npip install --upgrade $TF_BINARY_URL\n```\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.9.0\n```\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain\n2. bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir <direc>\n3. scratch head\n### What have you tried?\n\n1.literally every other stack overflow / github question. eg, https://github.com/tensorflow/tensorflow/issues/2810\n\n2.reinstalling cuda 7.5 and cudnn v4, running ./configure. no luck.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["@Waffleboy, what type of GPU do you have? \n", "@zheng-xq GeForce GTX 860M/PCIe/SSE2, thanks!\n", "Please look at my comment in the other thread, and see if that fixes your problem. Thanks. \n\nhttps://github.com/tensorflow/tensorflow/issues/2810#issuecomment-231197086\n", "Hi, thanks for your reply!\n\nI ran ./configure to do what you said, but now i get this strange error:\n\n```\nPlease specify the location of python. [Default is /storage/programfiles/anaconda3/bin/python]: \nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with GPU support? [y/N] y\nGPU support will be enabled for TensorFlow\nPlease specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: v4\nPlease specify the location where cuDNN v4 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nInvalid path to cuDNN  toolkit. Neither of the following two files can be found:\n/usr/local/cuda-7.5/lib64/libcudnn.so.v4\n/usr/local/cuda-7.5/libcudnn.so.v4\n/usr/local/cuda/lib64/libcudnn.so\n/usr/local/cudnn/lib64/libcudnn.so\n/usr/lib/x86_64-linux-gnu/libcudnn.so.v4\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: \n```\n\nI have double and triple checked that the files are there, and that it was cuDNN v4. Should i ignore this and select default?\n", "Normally the versions are like 4.0.7. You can check the name of the library for the version number. \n\nls /usr/local/cuda-7.5/lib64/libcuda.so.*\n", "libcuda returns nothing, but libcudnn returns 2 files. Running with system default (ie, not manually typing v4) allows me to continue and pick 5.0 for compute capability. is this ok?\n\n```\n\u279c  ~ ls /usr/local/cuda-7.5/lib64/libcuda.so.*\nls: cannot access '/usr/local/cuda-7.5/lib64/libcuda.so.*': No such file or directory\n\u279c  ~ ls /usr/local/cuda-7.5/lib64/libcudnn.so.*\n/usr/local/cuda-7.5/lib64/libcudnn.so.4  /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7\n\u279c  ~ \n\n```\n", "Either system default or 4.0.7 is fine. Please let us know whether that makes a difference for you.\n", "I can't even generate the bottlenecks now.. It instantly fails =/\n\n```\n\u279c  tensorflow git:(master) \u2717 bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ../DSG_2016/data/ORIGINAL/train_group/\nTraceback (most recent call last):\n  File \"/storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 78, in <module>\n    import tensorflow as tf\n  File \"/storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/storage/programfiles/anaconda3/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/storage/programfiles/anaconda3/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: _ZNK6google8protobuf7Message11GetTypeNameEv\n\n```\n", "@martinwicke, @vrv, have you seen this error before, on Ubuntu 16.04? \n\nImportError: /storage/git/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: _ZNK6google8protobuf7Message11GetTypeNameEv\n\nFrom the following link, it seems to be a compiler version related issue. \n\nhttps://github.com/szagoruyko/loadcaffe/issues/45\n\n@Waffleboy, which gcc version do you have?\n", "I dowongraded to 4.9 to use another library. Is there a way to link tensorflow only to gcc5?\n", "In the \"configure\", you should be able to specify which version of gcc you want to use. \n", "Thanks, that worked :)\n", "I also meet this error many times recently. I'm using 4 old titanx cards to run tf benchmark code. I use the version from a patch #11392 . I'm using cuda 8.0 and cudnn 6.0 on ubuntu 16.04. \r\n```\r\n2017-08-04 17:37:51.480269: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n2017-08-04 17:37:51.480350: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n```", "Though I know that Titan X doesn't support GPU Direct RDMA, but could you confirm from your log? Successful GDR initialisation will print a line of log like `Instrumenting GPU allocator with bus_id 2`. Then we will see if we could isolate the problem from GDR.\r\n\r\nReproducing the issue using gRPC will do the same work.", "I have meet same error when using official gRPC protocal.", "I tried gcc-4.9, but still got `CUDA_ERROR_ILLEGAL_ADDRESS` error,  my nvidia driver version is 375.51.", "I have the same error:\r\n\r\n2017-09-06 18:35:49.879762: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n2017-09-06 18:35:49.879768: E tensorflow/stream_executor/cuda/cuda_blas.cc:543] failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_INTERNAL_ERROR\r\n2017-09-06 18:35:49.879809: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n\r\nnvidia driver version: 375.20\r\ncudnn version: 5.0\r\ncompile with gcc4.8.2", "The same issue when running on AWS with DL AMI, python3.6, TF 1.8.0\r\n\r\n\r\n"]}, {"number": 3223, "title": "Update", "body": "no modification\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 3222, "title": "instructions for saving progress using the udacity docker image", "body": "People not used to Docker might be surprised when their \"saved\" changes suddenly disappear.\n\nAdditionally we could add instructions for mounting a local directory at `/notebooks`, but first you have to copy the initial contents into your local directory, so it's a bit complicated.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "[This commit](https://github.com/tensorflow/tensorflow/commit/8ebb0c9b0025fc5cf327a5152ae09df4b6df19b7) commit removed the `--rm` flag making these somewhat confusing.\n", "@pcasaretto indeed. PR #3303 removes this section.\n", "Haha, looks like we were all pouncing on that `--rm` on the same day, from different angles.\n"]}, {"number": 3221, "title": "Distributed tensorflow does not allocate well 'worker' to GPUs", "body": "### Environment info\n\nOperating System: Ubuntu 14.04 desktop\nInstalled version of CUDA and cuDNN: 7.5,  5.0.5\ntensorflow 0.9.0.rc0 is installed from source.\n\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   322936  8 16  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16  8 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192  8 16  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so\n-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rwxr--r-- 1 root root 58775484  6 21 15:39 /usr/local/cuda/lib64/libcudnn_static.a\n\nI'm trying to use distributed tensorflow with 8 Titan-x GPUs in two servers.\n4 GPUs are in one server.\n\nI separate workers to each GPUs as follows.\n\n with tf.device(tf.train.replica_device_setter(\n      worker_device=\"/gpu:%d\" % (FLAGS.task_id%4), cluster=cluster_spec)):\n\nWhen I execute two 'ps' and eight 'worker', nvidia-smi shows next.\n\n((server1)) workers are allocated on GPU 0,1,2,3\n![image](https://cloud.githubusercontent.com/assets/9377459/16659014/75379c00-44a3-11e6-957c-845bed33f492.png)\n\n((server2)) workers are allocated on GPU 0\n![image](https://cloud.githubusercontent.com/assets/9377459/16658977/5748e794-44a3-11e6-94d1-f2eac24639cf.png)\n\nWhy the workers are not allocated to GPU 1,2,3 in server1 ?\n\nplease help me.\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/3234\n"]}, {"number": 3220, "title": "AggregationMethod.EXPERIMENTAL_ACCUMULATE_N gives Already exists error.", "body": "I have used EXPERIMENTAL_ACCUMULATE_N in all my past tensorflow projects since it lets me use larger batch sizes.  I have never had any issues with it until now.  Now I get the following error when I run the train step.\n\n```\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\n     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name=\"\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^gradients/Sub_1)]]\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\n     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name=\"\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^gradients/Sub_1)]]\nW tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\n     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name=\"\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^gradients/Sub_1)]]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 14880 get requests, put_count=3563 evicted_count=1000 eviction_rate=0.280662 and unsatisfied allocation rate=0.834476\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=10010 evicted_count=10000 eviction_rate=0.999001 and unsatisfied allocation rate=0\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 730, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 712, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.AlreadyExistsError: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\n     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name=\"\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^gradients/Sub_1)]]\n     [[Node: Mean/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3391_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chase/workspace/Translator/translator.py\", line 106, in <module>\n    c, _ = sess.run([cost, train_step], feed_dict = {input_tensor: x, expected_output: y})\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.AlreadyExistsError: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE\n     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name=\"\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^gradients/Sub_1)]]\n     [[Node: Mean/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3391_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'gradients/AccumulateN_5/TemporaryVariable', defined at:\n  File \"/home/chase/workspace/Translator/translator.py\", line 79, in <module>\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost, aggregation_method = tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 193, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 250, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients.py\", line 432, in gradients\n    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients.py\", line 692, in _AggregatedGrads\n    out_grads[i] = math_ops.accumulate_n(out_grad)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1497, in accumulate_n\n    var = gen_state_ops._temporary_variable(shape=shape, dtype=tensor_dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 365, in _temporary_variable\n    var_name=var_name, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2297, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1231, in __init__\n    self._traceback = _extract_stack()\n\n```\n\nThis error goes away if I change the aggregation method of ADD_N.  Here is my code.  I am trying to implement a sequence to sequence model to translate english to german.\n\n```\nimport unidecode\nimport tensorflow as tf\nrnn = tf.nn.rnn_cell\nimport numpy as np\nimport string\nimport sys\nimport random\nimport multiprocessing\n\nTIME_STEPS = 128\nBATCH_SIZE = 2\n\ndef ctov(c):\n    v = np.zeros(128)\n    v[ord(c)] = 1\n    return v\n\ndef vtoc(v):\n    return chr(np.argmax(v))\n\ndef stov(s, vlen):\n    null_vec = ctov('\\0')\n    v = np.tile(null_vec, (vlen, 1))\n    if len(s) > vlen: s = s[:vlen]\n    for i, c in enumerate(s):\n        v[i] = ctov(c)\n    return v\n\ndef vtos(v):\n    s = ''\n    for cv in v:\n        c = vtoc(cv)\n        if c == '\\0':\n            break\n        s += c\n    return s\n\ndef clean_text(txt):\n    txt = unidecode.unidecode(txt)\n    txt = ''.join([c for c in txt if c in CHARS])\n    return txt\n\ndef load_training_data():\n    print('Loading English...')\n    en = [e.strip() for e in open('/home/chase/Desktop/de-en/english.txt')]\n    print('Loading German...')\n    de = [d.strip() for d in open('/home/chase/Desktop/de-en/german.txt')]\n    print('Processing...')\n    translations = [(unidecode.unidecode(e), unidecode.unidecode(d)) for e, d in zip(en, de) if len(e) and len(d) and len(e) <= TIME_STEPS and len(d) <= TIME_STEPS]\n    return translations\n\n\ninput_tensor = tf.placeholder(tf.float32, (BATCH_SIZE, TIME_STEPS, 128), 'input_tensor')\nexpected_output = tf.placeholder(tf.float32, (BATCH_SIZE, TIME_STEPS, 128), 'expected_output')\n\ny = input_tensor\nwith tf.variable_scope('encoder'):\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    y = tf.nn.dynamic_rnn(rnn_cell, y, dtype = tf.float32)[0]\n\nwith tf.variable_scope('attn'):\n    W = tf.get_variable('W_attn', shape = (1, TIME_STEPS, TIME_STEPS), initializer = tf.truncated_normal_initializer(0.0, 1 / np.sqrt(TIME_STEPS)))\n    W = tf.tile(W, (BATCH_SIZE, 1, 1))\n    y = tf.batch_matmul(W, y)\n\nwith tf.variable_scope('decoder'):\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    y = tf.nn.dynamic_rnn(rnn_cell, y, dtype = tf.float32)[0]\n\nwith tf.variable_scope('output'):\n    y = tf.split(1, TIME_STEPS, y)\n    y = [tf.reshape(x, (BATCH_SIZE, 1024)) for x in y]\n    W = tf.get_variable('W', shape = (1024, 128), initializer = tf.truncated_normal_initializer(0.0, 1 / np.sqrt(1024)))\n    b = tf.get_variable('b', shape = (128,), initializer = tf.truncated_normal_initializer(0.0, 0.01))\n    y = [tf.nn.softmax(tf.matmul(x, W) + b) for x in y]\n    output = tf.pack(y, 1)\n\ncost = tf.reduce_mean(-tf.reduce_sum(expected_output * tf.log(output), reduction_indices = 2))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cost, aggregation_method = tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.8\nsess = tf.Session(config = config)\nsess.run(tf.initialize_all_variables())\n\nif 'train' in sys.argv or True:\n    translations = load_training_data()\n    validation = translations[:10000]\n    translations = translations[10000:]\n\n    def training_data_generator(data):\n        x = np.zeros((BATCH_SIZE, TIME_STEPS, 128))\n        y = np.zeros_like(x)\n        random.shuffle(data)\n        for i in range(0, len(data) - BATCH_SIZE, BATCH_SIZE):        \n            for b in range(BATCH_SIZE):\n                e, d = data[i + b]\n                x[b] = stov(e, TIME_STEPS)\n                y[b] = stov(d, TIME_STEPS)\n\n            yield (x, y)\n\n    for e in range(50):\n        for b, v in enumerate(training_data_generator(translations)):\n            x, y = v\n            c, _ = sess.run([cost, train_step], feed_dict = {input_tensor: x, expected_output: y})\n            print('Epoch %-6d  Batch %-6d  Cost %-6e' % (e, b, c), end = '\\r')\n```\n\nI am using Python 3.5 on Ubuntu 16.04.  I have the latest tensorflow version 0.9.\n", "comments": ["When I replaced the dynamic_rnn in the encoder scope with something I unrolled my self the issue goes away.\n\n```\nwith tf.variable_scope('encoder') as scope:\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    state = tf.zeros((BATCH_SIZE, rnn_cell.state_size))\n    output = [None] * TIME_STEPS\n    for t in range(TIME_STEPS):\n        y_t = tf.reshape(y[:, t, :], (BATCH_SIZE, -1))\n        output[t], state = rnn_cell(y_t, state)\n        scope.reuse_variables()\n    y = tf.pack(output, 1)\n```\n", "It is a known issue with using EXPERIMENTAL_ACCUMULATE_N with dynamic_rnn. But it really shouldn't be needed for dynamic_rnn's  already accumulates internally. @yuanbyu  or @ebrevdo can elaborate. Closing for now since it is an experimental feature that is technically unsupported.\n"]}, {"number": 3219, "title": "docker exec -it to start the interactive terminal", "body": "As per the current documentation, \n$ docker run -it -p 8888:8888  gcr.io/tensorflow/tensorflow should be used to access the CLI. \nHowever, the previous command starts the Notebook App. The CLI is not available. To access the CLI, we need to access the container by creating a new interactive terminal to it. \nHence, I added a second step using docker exec.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it !\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "@vivekjuneja it looks like this PR has stalled out - my impression is the ball is in your court to resolve the comments from code review. or do we need to take another look?\n", "@danmane - I have changed the documentation based on the feedback from @vrv \n\n@vrv - Kindly review it, and let me know if we can close the request. As discussed I have retained the earlier instruction to start the notebook server, and added another instruction to start a new terminal if needed.\n", "@vrv please review this.\n", "@tensorflow-jenkins test this please\n", "the branch has conflicts, so they need to be resolved first...  otherwise looks fine, but I don't use docker so I'm probably the wrong person to review this :)  \n", "@craigcitro perhaps you'd be kind enough to take a look :)\n", "I'm closing this due to lack of response but comment and we'll reopen after you've addressed these changes.  Thanks!\n"]}, {"number": 3218, "title": "Can not build tf from source - no such package '@grpc//': Error c loning repository", "body": "# description\n\nTry to build&install tf from source. But it does not work with the guide.\nI think it is because I am working in China and it has Great Fire Wall.\n\nBuilt with commit id: 71f6bb336e5e11d6da2cedac6ba1c992ad9992bd\nAnd OS: Mac OSX EI\n\n```\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nWARNING: /private/var/tmp/_bazel_hain/13b9e8642207ccdb0c7f56a5c17d327c/external/protobuf/WORKSPACE:1: Workspace name in /priv\nate/var/tmp/_bazel_hain/13b9e8642207ccdb0c7f56a5c17d327c/external/protobuf/WORKSPACE (@__main__) does not match the name give\nn in the repository's definition (@protobuf); this will cause a build error in future versions.\nERROR: /Users/hain/glory/ai/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:87:1: no such package '@grpc//': Error c\nloning repository: Unexpected end of file from server caused by Unexpected end of file from server caused by Unexpected end o\nf file from server and referenced by '//tensorflow/core/distributed_runtime/rpc:grpc_channel'.\nERROR: Loading failed; build aborted.\nINFO: Elapsed time: 639.082s\n```\n\nOther related issues -\nhttps://github.com/tensorflow/tensorflow/issues/1387\nhttps://github.com/tensorflow/tensorflow/issues/1413\n\n@fayeshine \n@melody-rain \n", "comments": ["Also, I am running Proxy in Global Mode. And I verified, git can clone repo from googlesource.\n", "I dont know why, but after running several times, the problem disappear.\n", "Ok, closing for now since it seems like a network caching issue.\n", "I'm seeing this same behavior three years later. When I run the command again, it finds grpc but then fails on another package. The build command succeeded the fourth time I ran it.\r\n\r\nIf this happens to a lot of people, it might be good idea to add a note to the build guide to let people know that if they get the error it's because of a network caching issue and to just run the command again until they no longer see the error."]}, {"number": 3217, "title": "ImportError: cannot import name pywrap_tensorflow", "body": " I followed the TensorFlow installation instructions for Mac OS X.(Mac OS X, CPU only, Python 2.7):\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py2-none-any.whl\nsudo pip install --upgrade $TF_BINARY_URL\n\nGot this error:\n## In [2]: import tensorflow\n\nImportError                               Traceback (most recent call last)\n<ipython-input-2-a649b509054f> in <module>()\n----> 1 import tensorflow\n\n/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()\n     21 from **future** import print_function\n     22 \n---> 23 from tensorflow.python import *\n\n/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()\n     46 _default_dlopen_flags = sys.getdlopenflags()\n     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\n---> 48 from tensorflow.python import pywrap_tensorflow\n     49 sys.setdlopenflags(_default_dlopen_flags)\n     50 \n\nImportError: cannot import name pywrap_tensorflow\n\nAny help would be appreciated.\n", "comments": ["You're running the script in the same directory as tensorflow. Move it out and you should be fine.\n", "Thanks for the response @Waffleboy. @xinyuwuhenZZ , please close the issue if this resolves installation for you.\n", "Similar problem was asked and addressed in #1013.\n", "@Waffleboy @aselle, Thanks for help! I did run script in other directory rather than installation directory.  \n@XianXing, not exactly the same issue, #1013\n", "Did that resolve the issue @xinyuwuhenZZ. If so, please close the issue.\n", "Not yet.\n", "Can you post the full traceback (in proper code annotation format) after you have moved it to a completely different directory?\n", "## In [1]: import tensorflow as tf\n\nValueError                                Traceback (most recent call last)\n<ipython-input-1-41389fad42b5> in <module>()\n----> 1 import tensorflow as tf\n\n/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()\n     21 from **future** import print_function\n     22 \n---> 23 from tensorflow.python import *\n\n/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()\n     63 from tensorflow.core.util.event_pb2 import *\n     64 # Import things out of contrib\n---> 65 import tensorflow.contrib as contrib\n     66 \n     67 # Framework\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/**init**.py in <module>()\n     26 from tensorflow.contrib import grid_rnn\n     27 from tensorflow.contrib import layers\n---> 28 from tensorflow.contrib import learn\n     29 from tensorflow.contrib import linear_optimizer\n     30 from tensorflow.contrib import lookup\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/**init**.py in <module>()\n     70 \n     71 # pylint: disable=wildcard-import\n---> 72 from tensorflow.contrib.learn.python.learn import *\n     73 from tensorflow.python.util.all_util import make_all\n     74 \n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/**init**.py in <module>()\n     21 \n     22 # pylint: disable=wildcard-import\n---> 23 from tensorflow.contrib.learn.python.learn import *\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/**init**.py in <module>()\n     23 \n     24 from tensorflow.contrib.learn.python.learn import datasets\n---> 25 from tensorflow.contrib.learn.python.learn import estimators\n     26 from tensorflow.contrib.learn.python.learn import graph_actions\n     27 from tensorflow.contrib.learn.python.learn import io\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/**init**.py in <module>()\n     21 \n     22 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n---> 23 from tensorflow.contrib.learn.python.learn.estimators.autoencoder import TensorFlowDNNAutoencoder\n     24 from tensorflow.contrib.learn.python.learn.estimators.base import TensorFlowBaseTransformer\n     25 from tensorflow.contrib.learn.python.learn.estimators.base import TensorFlowEstimator\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/autoencoder.py in <module>()\n     23 \n     24 from tensorflow.contrib.learn.python.learn import models\n---> 25 from tensorflow.contrib.learn.python.learn.estimators.base import TensorFlowBaseTransformer\n     26 from tensorflow.python.ops import nn\n     27 \n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py in <module>()\n     32 from tensorflow.contrib import layers\n     33 from tensorflow.contrib.learn.python.learn.estimators import _sklearn\n---> 34 from tensorflow.contrib.learn.python.learn.estimators import estimator\n     35 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n     36 from tensorflow.contrib.learn.python.learn.io.data_feeder import setup_train_data_feeder\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in <module>()\n     36 from tensorflow.contrib.learn.python.learn.estimators import tensor_signature\n     37 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n---> 38 from tensorflow.contrib.learn.python.learn.io import data_feeder\n     39 from tensorflow.contrib.learn.python.learn.utils import checkpoints\n     40 \n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/**init**.py in <module>()\n     26 from tensorflow.contrib.learn.python.learn.io.graph_io import read_batch_features\n     27 from tensorflow.contrib.learn.python.learn.io.graph_io import read_batch_record_features\n---> 28 from tensorflow.contrib.learn.python.learn.io.pandas_io import extract_pandas_data\n     29 from tensorflow.contrib.learn.python.learn.io.pandas_io import extract_pandas_labels\n     30 from tensorflow.contrib.learn.python.learn.io.pandas_io import extract_pandas_matrix\n\n/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/pandas_io.py in <module>()\n     22 try:\n     23   # pylint: disable=g-import-not-at-top\n---> 24   import pandas as pd\n     25   HAS_PANDAS = True\n     26 except ImportError:\n\n/usr/local/lib/python2.7/site-packages/pandas/**init**.pyc in <module>()\n     37 import pandas.core.config_init\n     38 \n---> 39 from pandas.core.api import *\n     40 from pandas.sparse.api import *\n     41 from pandas.stats.api import *\n\n/usr/local/lib/python2.7/site-packages/pandas/core/api.py in <module>()\n      8 from pandas.core.common import isnull, notnull\n      9 from pandas.core.categorical import Categorical\n---> 10 from pandas.core.groupby import Grouper\n     11 from pandas.formats.format import set_eng_float_format\n     12 from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n\n/usr/local/lib/python2.7/site-packages/pandas/core/groupby.py in <module>()\n     16                               DataError, SpecificationError)\n     17 from pandas.core.categorical import Categorical\n---> 18 from pandas.core.frame import DataFrame\n     19 from pandas.core.generic import NDFrame\n     20 from pandas.core.index import (Index, MultiIndex, CategoricalIndex,\n\n/usr/local/lib/python2.7/site-packages/pandas/core/frame.py in <module>()\n     37                                    create_block_manager_from_arrays,\n     38                                    create_block_manager_from_blocks)\n---> 39 from pandas.core.series import Series\n     40 from pandas.core.categorical import Categorical\n     41 import pandas.computation.expressions as expressions\n\n/usr/local/lib/python2.7/site-packages/pandas/core/series.py in <module>()\n   2942 # Add plotting methods to Series\n   2943 \n-> 2944 import pandas.tools.plotting as _gfx  # noqa\n   2945 \n   2946 Series.plot = base.AccessorProperty(_gfx.SeriesPlotMethods,\n\n/usr/local/lib/python2.7/site-packages/pandas/tools/plotting.py in <module>()\n     25 from pandas.util.decorators import Appender\n     26 try:  # mpl optional\n---> 27     import pandas.tseries.converter as conv\n     28     conv.register()  # needs to override so set_xlim works with str/number\n     29 except ImportError:\n\n/usr/local/lib/python2.7/site-packages/pandas/tseries/converter.py in <module>()\n      5 from dateutil.relativedelta import relativedelta\n      6 \n----> 7 import matplotlib.units as units\n      8 import matplotlib.dates as dates\n      9 \n\n/usr/local/lib/python2.7/site-packages/matplotlib/**init**.py in <module>()\n   1129 \n   1130 # this is the instance used by the matplotlib classes\n-> 1131 rcParams = rc_params()\n   1132 \n   1133 if rcParams['examples.directory']:\n\n/usr/local/lib/python2.7/site-packages/matplotlib/**init**.py in rc_params(fail_on_error)\n    973         return ret\n    974 \n--> 975     return rc_params_from_file(fname, fail_on_error)\n    976 \n    977 \n\n/usr/local/lib/python2.7/site-packages/matplotlib/**init**.py in rc_params_from_file(fname, fail_on_error, use_default_template)\n   1098         parameters specified in the file. (Useful for updating dicts.)\n   1099     \"\"\"\n-> 1100     config_from_file = _rc_params_in_file(fname, fail_on_error)\n   1101 \n   1102     if not use_default_template:\n\n/usr/local/lib/python2.7/site-packages/matplotlib/**init**.py in _rc_params_in_file(fname, fail_on_error)\n   1016     cnt = 0\n   1017     rc_temp = {}\n-> 1018     with _open_file_or_url(fname) as fd:\n   1019         try:\n   1020             for line in fd:\n\n/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.pyc in **enter**(self)\n     15     def **enter**(self):\n     16         try:\n---> 17             return self.gen.next()\n     18         except StopIteration:\n     19             raise RuntimeError(\"generator didn't yield\")\n\n/usr/local/lib/python2.7/site-packages/matplotlib/**init**.py in _open_file_or_url(fname)\n    998     else:\n    999         fname = os.path.expanduser(fname)\n-> 1000         encoding = locale.getdefaultlocale()[1]\n   1001         if encoding is None:\n   1002             encoding = \"utf-8\"\n\n/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/locale.pyc in getdefaultlocale(envvars)\n    541     else:\n    542         localename = 'C'\n--> 543     return _parse_localename(localename)\n    544 \n    545 \n\n/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/locale.pyc in _parse_localename(localename)\n    473     elif code == 'C':\n    474         return None, None\n--> 475     raise ValueError, 'unknown locale: %s' % localename\n    476 \n    477 def _build_localename(localetuple):\n\nValueError: unknown locale: UTF-8\n", "I just followed the official instruction, and run it in other directory.\n", "Maybe it is a little mess up. I can try it in pycharm.\n", "Well now you have a different error, try this.\nhttps://coderwall.com/p/-k_93g/mac-os-x-valueerror-unknown-locale-utf-8-in-python\n\n Also, that's not what i meant by proper annotation\n\nthis is: so it's alot easier to read code\n\n`\nimport tensorflow as tf\n`\n", "https://coderwall.com/p/-k_93g/mac-os-x-valueerror-unknown-locale-utf-8-in-python\nThat's the nub of the matter, thanks for your patience.\n", "It's strange that disallowing a  script to be run in the TF directory were considered a non-bug.", "Had the same issue. Solved by running:\r\n```\r\npip uninstall tensorflow\r\npip install tensorflow\r\n```"]}, {"number": 3216, "title": "after freezing a graph the inference time is slower than when restoring variables from checkpoint ", "body": "I'm using the  freeze_graph.py script that takes a graph definition and the corresponding checkpoint to combine them them into a single file (variables are replaced by constants). On my system (Linux, titanx tensorflow R0.9) I'm measuring aprox 50% slower inference time compared to the same graph running with  variables restored from the checkpoint file. \nIs it normal?\nThanks\nLaurent\n", "comments": ["Freezing graph inlines variable values into Graph definition, while checkpoint restore stores the values in Containers. Graph isn't optimized for storing large tensors so there may be some slowness introduced by this method. I would run under cProfile and visualize using snakeviz to see where the time is going\n", "@yaroslavvb's response seems most plausible. Please let us know if it seems to be some other bug rather than performance implications of the strategy. Thanks!\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3215, "title": "build_pip_package => no such package '@iron_range_behavior//'", "body": "bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nworks (and runs)\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nfails:\n\nERROR: ~/git_clone/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_range_behavior//': Error cloning repository: https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack caused by https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack caused by https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack and referenced by '//tensorflow/tensorboard/bower:bower'.\nERROR: Loading failed; build aborted.\n### Environment info\n\nOperating System: ubuntu 16.04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n/usr/local/cuda/lib64/libcudart.so.8.0.2\n\nIf installed from sources, provide the commit hash:\n71f6bb336e5e11d6da2cedac6ba1c992ad9992bd\n", "comments": ["Make sure you can actually git clone thoise packages manually. \nSee https://github.com/bazelbuild/bazel/issues/587 for information about bazel behind a proxy.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3214, "title": "Make dims of TF_NewTensor immutable", "body": "The pull request addresses issue #3176. Since immutability is a milder requirement than mutability, there should be no serious implications for the existing codes.\n\nRegards,\nIvan\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n", "Looks good to me.\n"]}, {"number": 3213, "title": "Accompany TF_LoadLibrary with TF_DeleteLibrary", "body": "The C API provides the [following function](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/core/public/tensor_c_api.h#L357) for loading libraries:\n\n``` c\nextern TF_Library* TF_LoadLibrary(const char* library_filename, TF_Status* status);\n```\n\nThe documentation says that \u201cthe caller owns the library handle\u201d returned by the function. Unlike other functions allocating memory and returning pointers, `TF_LoadLibrary` doesn\u2019t have a counterpart for properly freeing the memory. Note that it\u2019s not about unloading the library but about deallocating the `TF_Library` struct; although, a function for unloading the library would also be nice. Thanks!\n\nRegards,\nIvan\n", "comments": ["I suppose it is possible that the caller cannot know what free-store the memory of TF_LoadLibrary was allocated from. Unloading libraries is generally unreliable as dlclose isn't really required by POSIX to do much except invalidate the handle.\n"]}, {"number": 3212, "title": "Nan causes writing summary failed", "body": "I find when I try to write some weights or biases into summaries, they cannot be Nan, or it causes the program crashed. When I turn off writing summaries, everything runs normally, unless sometimes the loss could be Nan. \n\nIs it normal that some variables (e.g. weights, biases) be Nans at sometime and the whole training process runs ok? If it is, please modify the writing summary functions to avoid crash at this situation. \n\nThanks!\nBen\n", "comments": ["NaNs usually indicate something wrong with your training. Perhaps your learning rate is too high, perhaps you have invalid data. Maybe you have an invalid operation like a divide by zero. Tensorflow refusing to write any NaNs is giving you a warning that something has gone wrong with your training. \n\nIf you  still suspect there is an underlying bug, you need to provide us a reproducible test case (as small as possible), plus information about what environment (please see the issue submission template).\n", "Thank you for your reply! @aselle \n\nHere is a snapshot of my current training.\n![image](https://cloud.githubusercontent.com/assets/3946864/16645430/77269270-4456-11e6-8a0b-e12b471ebaaf.png)\n![image](https://cloud.githubusercontent.com/assets/3946864/16645457/ae73702c-4456-11e6-97af-4848a62e357d.png)\n\nI turned off the writing summary so that the training can continue. If it is turned on, the program will crash in about 4 or 5 epochs.\n\nThere are many NaNs in val_acc. I agree that the learning rate is too big (I use adadelta(0.1)), because the curve is not smooth, which shows the energy is too high. Although there are many NaNs in val_acc, the process is still going on, the acc is going up and the loss is going down.  I am not sure if it is normal or not.\n\nAnother question is because I use adadelta, I can't get the real learning rate. I read some papers which said that they just use vanilla SGD with a learning rate scheduler. So which one is better, SGD with lr scheduler or other optimizers(Adam, Adadelta, Rmsprop...)?\n", "In my opinion, it would be better if the summary writers didn't crash the program if they get passed a NaN.\nInstead, it would be nice if they were stored and then flagged somehow in tensorboard.\nUsers can then use tensorboard to find the source of the NaNs more easily.\n\nOr alternatively, it should be the optimization ops that complain about NaN values.\nThat seems more natural than having the monitoring ops complain.\n", "Dan, assigning it to you to take a look at the TensorBoard feature request.  \n\n@ibab @benwu232 You could use `tf.check_numerics()` to catch these errors during training.  Would this op work?\n", "I agree that writing a NaN should not crash the program. I am guessing the crash is due to the histogram summary op? We should fix this.\n\nHowever, I am out for the next two weeks, and this sounds like a TensorFlow kernel issue rather than a TensorBoard issue. I'm going to unassign myself. \n", "Yes, the histogram summary op can be expensive and might cause crashes.\n\nClosing this for now - please feel free to refile if there's a more specific bug to look at.\n", "Specifically, @benwu232 if you confirm that the issue is that `tf.histogram_summary` crashes if passed a NaN, please open an issue on that specific problem and we will triage it there. \n"]}, {"number": 3211, "title": "ValueError: Shape (?, ?) must have rank 1", "body": "r9.0\n\ncode:\n\n```\ntensor_shape = tf.reshape(tf.shape(tensor), shape=[2])\nindexes = tf.reshape(sparse_tensor.indices, shape=tensor_shape)\n\ntf.slice(indexes, one, two)\n// Where one and two are tensor constants\nOR\ntf.slice(sparse_tensor.indices, one, two)\n```\n\nStack trace:\n\n```\nminus_1_index = tf.slice(indexes, minus_1, one)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 251, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1634, in _slice\n    name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 2262, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 1702, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1054, in _SliceShape\n    input_shape.assert_has_rank(ndims)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 621, in assert_has_rank\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\nValueError: Shape (?, ?) must have rank 1\n```\n\nObviously it does have a rank of 1 but the dim itself is unknown\n", "comments": ["Are your tensors `one` and `two` scalars?\nIn that case, the error would make sense, as sparse tensor indices have rank 2 (The shape is `[N, ndims]`, where `N` is the number of non-zero elements and `ndims` the rank of the underlying tensor).\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "update tf to 0.10, then fix it\n"]}, {"number": 3210, "title": "Using foldl inside while_loop doesn't seem to work", "body": "### Environment info\n\nOperating System: OSX\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\ntensorflow (0.1.0)       - UNKNOWN\n  INSTALLED: 0.9.0rc0\n  LATEST:    0.1.0\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n0.9.0rc0\n### What have you tried?\n\nI'm trying to use foldl inside while_loop and wrote reduced test case to find what I'm doing wrong. However looks like this might be bug in foldl implementation.\n\n``` python\nimport tensorflow as tf\nfrom tensorflow.python.ops import functional_ops as fops\n\ns = tf.InteractiveSession()\n\nprint(\"Evaluating foldl part\",\n  fops.foldl(\n    lambda x,y: x+y,\n    tf.constant([1,2])\n  ).eval()\n)\n\nprint(\"Evaluating while without fold\",\n  tf.while_loop(\n    lambda i: tf.less(i, 10), \n    lambda i: tf.add(i, 3), \n    [tf.constant(0)]\n  ).eval()\n)\n\n# This one fails for some reason... \nprint(\"Evaluating while with fold inside\",\n  tf.while_loop(\n    lambda i: tf.less(i, 10), \n    lambda i: tf.add(i, \n      fops.foldl(\n        lambda x,y: x+y,\n        tf.constant([1,2])\n      )\n    ), \n    [tf.constant(0)]\n  ).eval()\n)\n```\n\noutput:\n\n```\nEvaluating foldl part 3\nEvaluating while without fold 12\n\nW tensorflow/core/framework/op_kernel.cc:909] Already exists: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE\nTraceback (most recent call last):\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 715, in _do_call\n    return fn(*args)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 697, in _run_fn\n    status, run_metadata)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.AlreadyExistsError: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE\n     [[Node: while_1/foldl/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name=\"\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](while_1/foldl/Squeeze)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"fops_test.py\", line 58, in <module>\n    [tf.constant(0)]\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 555, in eval\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3498, in _eval_using_default_session\n    return session.run(tensors, feed_dict)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 636, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 708, in _do_run\n    target_list, options, run_metadata)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 728, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.AlreadyExistsError: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE\n     [[Node: while_1/foldl/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name=\"\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](while_1/foldl/Squeeze)]]\nCaused by op 'while_1/foldl/TensorArray', defined at:\n  File \"fops_test.py\", line 58, in <module>\n    [tf.constant(0)]\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1873, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1749, in BuildLoop\n    body_result = body(*vars_for_body_with_tensor_arrays)\n  File \"fops_test.py\", line 55, in <lambda>\n    tf.constant([1,2])\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/functional_ops.py\", line 102, in foldl\n    infer_shape=True)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 132, in __init__\n    tensor_array_name=tensor_array_name, name=scope)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 759, in _tensor_array\n    name=name)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n```\n", "comments": ["I see this in r0.8, but in r0.9 I do not see it (at least on the docker containers I was using). Could you give r0.9 or nightly a try.\n", "I thought I was running  r0.9 directly from pip install. I'm using python3 could it cause the difference? Is there way to install nightly with pip?\n\n```\n>>> tensorflow.__version__\n'0.9.0rc0'\n>>> \n```\n", "I ran tensorflow install again, and indeed its not failing anymore \ud83d\udc4d \n\n```\n>>> tensorflow.__version__\n'0.9.0'\n>>> \n```\n\nThanks!\n", "Glad it worked!\n"]}, {"number": 3209, "title": "Problems with Tensorboard on Ubuntu 16.04", "body": "I'm running code from https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf15_tensorboard/full_code.py on my own computer, which is a sample of how to use Tensorboard, however, I see nothing from the Tensor board from my computer: every tab of the Tensorflow is empty, saying no XX data is found.\n\nI tried the '--inspect option':\n\n> zhao@zhao-ubuntu:~/Desktop/samples$ tensorboard --logdir = 'logs' --inspect ====================================================================== Processing event files... (this can take a few minutes) ======================================================================\n> \n> No event files found within logdir =\n\nand the '--debug' option:\n\n> zhao@zhao-ubuntu:~/Desktop/samples$ tensorboard --logdir = 'logs' --debug INFO:tensorflow:TensorBoard is in debug mode. INFO:tensorflow:Starting TensorBoard in directory /home/zhao/Desktop/samples\n> INFO:tensorflow:TensorBoard path_to_run is: {'/home/zhao/Desktop/samples/=': None} \n> INFO:tensorflow:Multiplexer done loading. Load took 0.0 secs INFO:tensorflow:TensorBoard is tag:b'22' \n> Starting TensorBoard b'22' on port 6006 (You can navigate to http://0.0.0.0:6006)\n\nBTW, I'm using python3.5.1 on my ubuntu machine.\n", "comments": ["Just checking, do you have a directory called 'logs' within your ~/Desktop/samples directory?\nIf so, can you try passing a logdir as a full path (eg `logdir=$(pwd)/logs`)\n", "Oh, you can't have a space before the equals. It is looking for `\"/home/zhao/Desktop/samples/=` because you have `logdir = X`, which it parses as `logdir='='`. \n\nPlease use `logdir=X` or `logdir X`, the space is equivalent to an equals sign.\n", "@danmane  Oh, so stupid I am.\nThanks!\n"]}, {"number": 3208, "title": "minimize raises \"ValueError: None values not supported.\" error when tf.while_loop used inside fn() of tf.cond()", "body": "On TF 0.9.0, The following code with tf.while_loop inside tf.cond raises ValueError when minimized. \n\n```\nimport tensorflow as tf\nfrom tensorflow.python.ops import tensor_array_ops\n\nwith tf.Session() as sess:\n    a = tf.constant([[1., 2.], [3.,4.]])\n    w = tf.get_variable('w', [2, 1], tf.float32)\n    c = tf.Variable(1)\n\n    def loss_a(a, w):\n        a_ta = tensor_array_ops.TensorArray(dtype=tf.float32, size=2,\n                                            tensor_array_name=\"a_ta\")\n        a_ta = a_ta.unpack(a)\n\n        b_ta = tensor_array_ops.TensorArray(dtype=tf.float32, size=2,\n                                            tensor_array_name=\"b_ta\")\n\n\n        time = tf.constant(0, dtype=tf.int32, name=\"time\")\n\n        def _time_step(time, a_ta_t, b_ta_t):\n          a = a_ta_t.read(time)\n          b_ta_t = b_ta_t.write(time, a * w)\n          return (time+1, a_ta_t, b_ta_t)\n\n        (_, _, final_b) = tf.while_loop(\n            cond=lambda time, _1, _2: time < 2,\n            body=_time_step,\n            loop_vars=(time, a_ta, b_ta),\n            parallel_iterations=32,\n            swap_memory=True)\n        b = tf.reduce_sum(final_b.pack(), 0)\n        return b\n\n    def loss_b(a, w):\n        return 2 * a * w\n\n    loss = tf.cond(tf.equal(c, 0), lambda: loss_a(a, w), lambda: loss_b(a,w))\n    train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n\n    sess.run(tf.initialize_all_variables())\n\n    sess.run(train_op)\n```\n\n> Traceback (most recent call last):\n>   File \"test.py\", line 39, in <module>\n>     train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n>   File \"/.../tensorflow/python/training/optimizer.py\", line 193, in minimize\n>     grad_loss=grad_loss)\n>   File \"/.../tensorflow/python/training/optimizer.py\", line 250, in compute_gradients\n>     colocate_gradients_with_ops=colocate_gradients_with_ops)\n>   File \"/.../tensorflow/python/ops/gradients.py\", line 481, in gradients\n>     in_grads = _AsList(grad_fn(op, *out_grads))\n>   File \"/.../tensorflow/python/ops/tensor_array_grad.py\", line 115, in _TensorArrayWriteGrad\n>     grad = g.read(index)\n>   File \"/.../tensorflow/python/ops/tensor_array_ops.py\", line 191, in read\n>     dtype=self._dtype, name=name)\n>   File \"/.../tensorflow/python/ops/gen_data_flow_ops.py\", line 905, in _tensor_array_read\n>     flow_in=flow_in, dtype=dtype, name=name)\n>   File \"/.../tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n>     op_def=op_def)\n>   File \"/.../tensorflow/python/framework/ops.py\", line 2260, in create_op\n>     original_op=self._default_original_op, op_def=op_def)\n>   File \"/.../tensorflow/python/framework/ops.py\", line 1234, in __init__\n>     self._control_flow_context.AddOp(self)\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 1479, in AddOp\n>     self._AddOpInternal(op)\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 1499, in _AddOpInternal\n>     self.AddValue(x)\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 1438, in AddValue\n>     real_val = grad_ctxt.grad_state.GetRealValue(val)\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 781, in GetRealValue\n>     real_value = self.AddBackPropAccumulatedValue(h_value, value)\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 731, in AddBackPropAccumulatedValue\n>     history_value = _SwitchRefOrTensor(history_value, pred)[branch]\n>   File \"/.../tensorflow/python/ops/control_flow_ops.py\", line 324, in _SwitchRefOrTensor\n>     return ref_switch(data, pred, name=name)\n>   File \"/.../tensorflow/python/ops/gen_control_flow_ops.py\", line 341, in ref_switch\n>     result = _op_def_lib.apply_op(\"RefSwitch\", data=data, pred=pred, name=name)\n>   File \"/.../tensorflow/python/ops/op_def_library.py\", line 459, in apply_op\n>     as_ref=input_arg.is_ref).dtype.name\n>   File \"/.../tensorflow/python/framework/ops.py\", line 620, in convert_to_tensor\n>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n>   File \"/.../tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n>     return constant(v, dtype=dtype, name=name)\n>   File \"/.../tensorflow/python/ops/constant_op.py\", line 162, in constant\n>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n>   File \"/.../tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n>     raise ValueError(\"None values not supported.\")\n> ValueError: None values not supported.\n\nIt works fine if I add la, lb as follows, although this would force execution of loss_a and loss_b regardless of the pred in tf.cond(). \n\n```\n    la = loss_a(a, w)\n    lb = loss_b(a, w)\n\n    loss = tf.cond(tf.equal(c, 0), lambda: la, lambda: lb)\n    train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n\n    sess.run(tf.initialize_all_variables())\n\n    sess.run(train_op)\n```\n\nIs this a known issue or did I miss something in how to use tf.while_loop within tf.cond? \n", "comments": ["Could you try using the (somewhat experimental) `@Defun` functionality to see if it works?  See `testWhileFuncBasic()` in `control_flow_ops_py_test.py`.\n", "Automatically closing due to lack of recent activity. Please reopen if additional information becomes available.\n", "The error is also occurring when restoring a model trained using layers.stack with a Estimator class(providing as  model directory where the model is saved, and model_fn as the conv_model written in skflow mnist example).\n`File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 394, in predict\n    as_iterable=as_iterable)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 663, in _infer_model\n    predictions = self._get_predict_ops(features)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 897, in _get_predict_ops\n    predictions, _, _ = self._call_model_fn(features, targets, ModeKeys.INFER)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 806, in _call_model_fn\n    return self._model_fn(features, targets)\n  File \"test.py\", line 34, in conv_model\n    return learn.models.logistic_regression(h_fc1, y)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/models.py\", line 137, in logistic_regression\n    logging_ops.histogram_summary('%s.y' % vs.get_variable_scope().name, y)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/logging_ops.py\", line 125, in histogram_summary\n    tag=tag, values=values, name=scope)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 100, in _histogram_summary\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 458, in apply_op\n    as_ref=input_arg.is_ref).dtype.name\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 621, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n    raise ValueError(\"None values not supported.\")\nValueError: None values not supported.\n`\n", "I get a similar error when I have a map_fn modifying a variable, and the map_fn is inside of a cond, but this may not be informative if map_fn uses while (I haven't checked).\n\n```\nTraceback (most recent call last):\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 454, in apply_op\n    as_ref=input_arg.is_ref)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 621, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n    raise ValueError(\"None values not supported.\")\nValueError: None values not supported.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"cifar10_shallow.py\", line 161, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss, global_step=global_step)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 193, in minimize\n    grad_loss=grad_loss)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 250, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py\", line 484, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_grad.py\", line 115, in _TensorArrayWriteGrad\n    grad = g.read(index)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 191, in read\n    dtype=self._dtype, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1344, in _tensor_array_read\n    flow_in=flow_in, dtype=dtype, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2298, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1236, in __init__\n    self._control_flow_context.AddOp(self)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1493, in AddOp\n    self._AddOpInternal(op)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1513, in _AddOpInternal\n    self.AddValue(x)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1452, in AddValue\n    real_val = grad_ctxt.grad_state.GetRealValue(val)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 788, in GetRealValue\n    real_value = self.AddBackPropAccumulatedValue(history_value, value)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 737, in AddBackPropAccumulatedValue\n    history_value = _SwitchRefOrTensor(history_value, pred)[branch]\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 325, in _SwitchRefOrTensor\n    return ref_switch(data, pred, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\", line 341, in ref_switch\n    result = _op_def_lib.apply_op(\"RefSwitch\", data=data, pred=pred, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 458, in apply_op\n    as_ref=input_arg.is_ref).dtype.name\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 621, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/home-nfs/dan/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n    raise ValueError(\"None values not supported.\")\n```\n", "I'm encountering the same error when calling `learn.Estimator.predict` on a restored, already trained model, unless I call `learn.Estimator.fit` beforehand. The following code is largely based on [this example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/text_classification_character_rnn.py). My guess is that some important stuff isn't initialized by calling `predict`. For example, I don't see \"Creating TensorFlow device\" or anything like that when only calling `predict`.\n\nI'm using a tensorflow 0.10.0rc0 nightly from a few days ago.\n\nTo reproduce:\n1. Run `./text_classification_character_rnn.py -m model` to train a model stored in the \"model\" directory\n2. Run `./text_classification_character_rnn.py -m model -t` to load the model and make a prediction only, without calling `fit` first, which causes the error.\n\n```\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom optparse import OptionParser\nimport numpy as np\nfrom sklearn import metrics\nimport pandas\n\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_bool('test_with_fake_data', False,\n                         'Test the example code with fake data.')\n\nMAX_DOCUMENT_LENGTH = 200\nHIDDEN_SIZE = 60\n\nparser = OptionParser()\nparser.add_option(\"-m\", \"--model\", dest=\"model_dir\",\n                  help=\"specify current model directory\")\nparser.add_option(\"-t\", \"--testonly\", action=\"store_true\", dest=\"testonly\",\n                  default=False, help=\"test the model without training\")\n\n(options, args) = parser.parse_args()\n\nclass ProgressMonitor(learn.monitors.BaseMonitor):\n    def __init__(self):\n        print('[Monitor] Init')\n    def begin(self, max_steps):\n        print('[Monitor] Starting run.')\n    def end(self):\n        print('[Monitor] Completed run.')\n    def step_begin(self, step):\n        print('[Monitor] Step %d...' % step)\n        return []\n    def step_end(self, step, outputs):\n        pass\n\ndef char_rnn_model(x, y):\n  \"\"\"Character level recurrent neural network model to predict classes.\"\"\"\n\n  # restore saved model if provided\n  y = tf.one_hot(y, 15, 1, 0)\n  byte_list = learn.ops.one_hot_matrix(x, 128)\n  byte_list = tf.unpack(byte_list, axis=1)\n\n  cell = tf.nn.rnn_cell.GRUCell(HIDDEN_SIZE)\n  #cell = tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE)\n  #cell = tf.nn.rnn_cell.LSTMCell(HIDDEN_SIZE)\n  _, encoding = tf.nn.rnn(cell, byte_list, dtype=tf.float32)\n\n  prediction, loss = learn.models.logistic_regression(encoding, y)\n\n  train_op = tf.contrib.layers.optimize_loss(\n      loss, tf.contrib.framework.get_global_step(),\n      optimizer='Adam', learning_rate=0.01)\n\n  return {'class': tf.argmax(prediction, 1), 'prob': prediction}, loss, train_op\n\n\ndef main(unused_argv):\n\n  # Prepare training and testing data\n  dbpedia = learn.datasets.load_dataset(\n      'dbpedia', test_with_fake_data=FLAGS.test_with_fake_data)\n  x_train = pandas.DataFrame(dbpedia.train.data)[1]\n  y_train = pandas.Series(dbpedia.train.target)\n  x_test = pandas.DataFrame(dbpedia.test.data)[1]\n  y_test = pandas.Series(dbpedia.test.target)\n\n  # Process vocabulary\n  char_processor = learn.preprocessing.ByteProcessor(MAX_DOCUMENT_LENGTH)\n  x_train = np.array(list(char_processor.fit_transform(x_train)))\n  x_test = np.array(list(char_processor.transform(x_test)))\n\n  # Build model\n  classifier = learn.Estimator(model_fn=char_rnn_model, model_dir=options.model_dir)\n\n  # Train and predict\n  monitor = ProgressMonitor()\n  if not options.testonly:\n    classifier.fit(x_train, y_train, max_steps=10, batch_size=10000, monitors=[monitor])\n  y_predicted = classifier.predict(x_test, batch_size=10000)\n  score = metrics.accuracy_score(y_test, y_predicted['class'])\n  print('Accuracy: {0:f}'.format(score))\n\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nThe error:\n\n```\n[Monitor] Init\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 454, in apply_op\n    as_ref=input_arg.is_ref)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 628, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n    raise ValueError(\"None values not supported.\")\nValueError: None values not supported.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./text_classification_character_rnn.py\", line 119, in <module>\n    tf.app.run()\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./text_classification_character_rnn.py\", line 113, in main\n    y_predicted = classifier.predict(x_test, batch_size=10000)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 323, in predict\n    as_iterable=as_iterable)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 592, in _infer_model\n    predictions = self._get_predict_ops(features)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 824, in _get_predict_ops\n    predictions, _, _ = self._call_model_fn(features, targets, ModeKeys.INFER)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 733, in _call_model_fn\n    return self._model_fn(features, targets)\n  File \"./text_classification_character_rnn.py\", line 73, in char_rnn_model\n    y = tf.one_hot(y, 15, 1, 0)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2717, in one_hot\n    name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1421, in _one_hot\n    axis=axis, name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 458, in apply_op\n    as_ref=input_arg.is_ref).dtype.name\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 628, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n    raise ValueError(\"None values not supported.\")\n```\n\nAs a workaround, I can call `classifier.evaluate(x_train, y_train, batch_size=10000)` before calling `predict`, and then it works fine. Maybe this is not a bug but simply an API misunderstanding. I don't see any indication that `evaluate` must be called before `predict` can be called.\n", "The original issue posted by liusiqi43@ should already be fixed at HEAD.\n", "the same issue.\n\npython train_cifar.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\n\n> > Downloading cifar-10-binary.tar.gz 100.0%\n> > Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.\n> > Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n> > Traceback (most recent call last):\n> >   File \"train_cifar.py\", line 311, in <module>\n> >     tf.app.run()\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n> >     sys.exit(main(sys.argv[:1] + flags_passthrough))\n> >   File \"train_cifar.py\", line 307, in main\n> >     train(is_training, logits, images, labels)\n> >   File \"/media/New_bt/ML/tensorflow-resnet/resnet_train.py\", line 33, in train\n> >     loss_ = loss(logits, labels)\n> >   File \"/media/New_bt/ML/tensorflow-resnet/resnet.py\", line 148, in loss\n> >     cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 745, in sparse_softmax_cross_entropy_with_logits\n> >     logits = ops.convert_to_tensor(logits)\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 657, in convert_to_tensor\n> >     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n> >     return constant(v, dtype=dtype, name=name)\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n> >     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n> >   File \"/home/ozzie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 346, in make_tensor_proto\n> >     raise ValueError(\"None values not supported.\")\n> > ValueError: None values not supported.\n", "Did anyone find solution to this problem?\n", "I meet this bug too, it seems about the tf.Variable, you can try it with  tf.Variable(0, trainable = False)", "@yuanbyu I think I saw something recently about that. Was that fixed at some point recently?", "I met the same exception: ValueError: None values not supported.\r\nIt is impossible to use train model in the way:\r\n`  nn = tf.contrib.learn.Estimator(model_fn=model_fn,model_dir='/path')\r\n    predictions = nn.predict(x=prediction_set.data, as_iterable=True)\r\n`\r\n\r\nthe hack to solve it is to run an evaluation before a prediction. \r\n`  nn = tf.contrib.learn.Estimator(model_fn=model_fn,model_dir='/path')\r\n    ev = nn.evaluate(x=test_set.data, y=test_set.target, steps=1)\r\n    predictions = nn.predict(x=prediction_set.data, as_iterable=True)\r\n`\r\n", "@agniszczotka \r\nGreat ! That solved my problem ! \r\nBut I still do not know why ~", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 3207, "title": "fix trivial typo (word repetition)", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3205, "title": "Failed to build tensorflow using custom Python/3.5.1-CrayGNU-2016.03", "body": "I am trying to build tensorflow 0.9.0 (bdc43730c9e6037c608adb91fe55d6c1a82879a8) on a cray cluster using bazel 0.3.0. \n\nI was able to build tensorflow using a fresh installation of python3.5.1 but [this paper from the cluster admins](https://cug.org/proceedings/cug2016_proceedings/includes/files/pap145.pdf) suggests that I loose quite some performance by not using an optimized python installation. \n\nTherefore I want to install tensorflow using the provided python installation. \nI create a virtualenv (inheriting the locally installed packages) and activate it. Then I run configure and select the proposed python binary from virtualenv.\nBut unfortunately building fails:\n\n```\nbazel build --linkopt '-lrt' --config=cuda --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package\nINFO: $TEST_TMPDIR defined: output root default is '/scratch/daint/user_name/bazelout'.\n.....\nINFO: Waiting for response from Bazel server (pid 4431)...\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /users/user_name/tensorflow-cray/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nINFO: Found 1 target...\n[removed code]\nERROR: /users/user_name/tensorflow-cray/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command \n  (cd /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/execroot/tensorflow-cray && \\\n  exec env - \\\n    PATH=/users/user_name/tf_cray_env/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Python/3.5.1-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tk/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/SQLite/3.9.2-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tcl/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/freetype/2.5.5-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libpng/1.6.16-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libreadline/6.3-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/ncurses/6.0-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/bzip2/1.0.6-CrayGNU-2016.03/bin:/opt/cray/rca/1.0.0-2.0502.60530.1.62.ari/bin:/opt/cray/alps/5.2.4-2.0502.9822.32.1.ari/sbin:/opt/cray/dvs/2.5_0.9.0-1.0502.2188.1.116.ari/bin:/opt/cray/xpmem/0.1-2.0502.64982.5.3.ari/bin:/opt/cra\n y/pmi/5.0.10-1.0000.11050.0.0.ari/bin:/opt/cray/ugni/6.0-1.0502.10863.8.29.ari/bin:/opt/cray/udreg/2.3.2-1.0502.10518.2.17.ari/bin:/opt/toolworks/totalview.8.11.0-0/bin:/opt/totalview-support/1.1.4/bin:/opt/gcc/4.9.3/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/libnvvp:/opt/java/jdk1.8.0_51/bin:/apps/common/UES/SLES11/ddt/6.0.6/libexec:/apps/common/UES/SLES11/ddt/6.0.6/bin:/opt/cray/mpt/7.3.2/gni/bin:/apps/daint/munge/default/bin:/apps/daint/slurm/default/bin:/opt/slurm/default/bin:/opt/cray/craype/2.4.0/bin:/opt/cray/switch/1.0-1.0502.60522.1.61.ari/bin:/opt/cray/eslogin/eswrap/1.1.0-1.020200.1231.0/bin:/opt/modules/3.2.10.3/bin:/users/user_name/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/usr/lib/mit/bin:/usr/lib/mit/sbin:/sbin:/usr/sbin:.:/usr/lib/qt3/bin:/opt/cray/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/dain\n t/system/bin \\\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /users/user_name/tf_cray_env/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/* bazel-out/local_linux-py3-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.\n/users/user_name/tf_cray_env/bin/python: error while loading shared libraries: libpython3.5m.so.1.0: cannot open shared object file: No such file or directory\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 2664.471s, Critical Path: 1412.20s\n```\n", "comments": ["Looks like it can't find your libpython dso when running /users/user_name/tf_cray_env/bin/python. Make sure you have activated your virtualenv before running bazel if you are using virtualenv. Otherwise, maybe you need to adjust your LD_LIBRARY_PATH.\n", "Actually, the workaround we used is to re-build Python using rpath. \n\nWe hit the same problem with PCRE (dependency of Swig), which was also fixed by using rpath.\n", "Sure, rpath is also an option for finding shared libraries. Glad you got it to work!\n"]}, {"number": 3204, "title": "Knights Landing feature request", "body": "It would be nice to see a tensorflow binary compatible with Knights Landing for AWS.\n", "comments": ["What would be the benefit ?\n", "We now have MKL support and you will need to build from source.  I will also be updating the performance guide.  Here are the basic command, which will work starting at TF 1.2 RC2.  At some point it may become the default but we are reluctant to support another TF variant.  \r\n\r\n```bash\r\n1.       Configure tensorflow\r\n./configure\r\nMKL -> yes\r\neverything else -> default\r\n\r\n2.       Build\r\nbazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nThis will provide a signifiant boost and Intel is actively working on improving edge cases as they are found.  \r\n\r\nIs KNL available on AWS?  I would like to use it can you provide a link.  "]}, {"number": 3203, "title": "ImportError for graph_util from tensorflow.python.framework", "body": "Importing `graph_util` from `tensorflow.python.framework` fails with an `ImportError`.\n\nI discovered this while I was trying to go through the [TensorFlow for Poets Codelab](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html), an the the [re-training](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#4) failed.\n\nI can reproduce the same error in my Python shell. I am able to verify that TensorFlow is installed correctly by importing `tensorflow`, `tensor_shape` from `tensorflow.python.framework`, and `gfile` from `tensorflow.python.platform` (as in the [retraining script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py)); but trying to import `graph_util` results in the same `ImportError`:\n\n```\n>>> import tensorflow\n# Success\n>>> from tensorflow.python.framework import tensor_shape\n# Success\n>>> from tensorflow.python.platform import gfile\n# Success\n>>> from tensorflow.python.framework import graph_util\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: cannot import name graph_util\n```\n\nI have also posted this as a [question on Stack Overflow](http://stackoverflow.com/questions/38218274/tensorflow-importerror-for-graph-util-from-tensorflow-python-framework), and haven't received any answers so far. I am not sure if this is a bug or a configuration problem etc. Feels like a bug, since I can import `tensor_shape` from `tensorflow.python.framework` no problem.\n### Environment info\n\nOperating System: OS X El Capitan (v10.11.5)\nPython: v2.7.11 via Homebrew \n\nTensorFlow 0.9.0 installed from binary pip package for Mac OS X, CPU only, Python 2.7 (TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py2-none-any.whl).\n### Steps to reproduce\n\nIn Python shell:\n\n```\n>>> from tensorflow.python.framework import graph_util\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: cannot import name graph_util\n```\n### What have I tried?\n- Looked to see if the file `graph_util` is there inside `tensorflow/python/framework`. It is.\n- Looked to see if the current source code I am examining has undergone any [changes since v0.9.0](https://github.com/tensorflow/tensorflow/compare/v0.9.0...r0.9) that would fix this issue that appears in the release that I am using. It doesn't appear so to me.\n", "comments": ["I'm having the same problem and can't seem to find a solution with the master branch.\nWhile this is no real solution for the problem itself you could try pulling the r0.9 version from git. \nThis seems to work for me at the very least.\n", "Assigning @danmane since he is on sync rotation next week to see the patch through.\n", "I suspect the patch went through, though don't know which commit fixed this :(\n", "The issue persists.\n", "Ah, graph_util.py was moved from python/client to python/framework after r0.9.  You should either check out the code from the r0.9 branch, or use the nightly PIPs linked from github.com/tensorflow/tensorflow to get access to more recent installs that match the latest source code in master.\n", "Solved my problem by checking out the r0.9 branch.\n", "Are newer versions deprecated? ", "I also encountered the same problem as yours, and I used the following two steps to solve the problem\uff1a\r\n1.Activate TensorFlow\uff0cand stay active during following steps as well as running retrain.py\uff1a\r\n    source ~/tensorflow/bin/activate # bash, sh, ksh, or zsh\r\n2.Upgrade TensorFlow version by those steps:\r\n     (tensorflow)$ easy_install -U pip\r\n     (tensorflow)$ pip install --upgrade tensorflow      # for Python 2.7\r\nReference tensorflow official link:https://www.tensorflow.org/install/install_linux\r\n"]}, {"number": 3202, "title": "genrule //tensorflow/contrib/session_bundle/example:half_plus_two ignores bazels TEST_TMPDIR and uses uses /tmp/", "body": "I am trying to build tensorflow 0.9.0 on a cray cluster using bazel 0.3. Becuase I have limited space in my home directory I set TEST_TMPDIR to some scratch space.\n\nSomehow the /tmp directory already contains a folder half_plus_two created by another user of the system. Therefore I don't have write access and the build fails: \n\n```\nbazel  build  --linkopt '-lrt' --config=cuda --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package\nINFO: $TEST_TMPDIR defined: output root default is '/scratch/daint/user_name/bazelout'.\nExtracting Bazel installation...\n.\nINFO: Waiting for response from Bazel server (pid 9772)...\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /users/user_name/tensorflow-cray/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nWARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nINFO: Found 1 target...\n[removed output...]\nERROR: /users/user_name/tensorflow-cray/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command \n  (cd /scratch/daint/user_name/bazelout/e48b2676a5a6481d625353bc3f790885/execroot/tensorflow-cray && \\\n  exec env - \\\n    PATH=/users/user_name/tf_cray_env/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Python/3.5.1-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tk/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/SQLite/3.9.2-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tcl/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/freetype/2.5.5-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libpng/1.6.16-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libreadline/6.3-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/ncurses/6.0-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/bzip2/1.0.6-CrayGNU-2016.03/bin:/opt/cray/rca/1.0.0-2.0502.60530.1.62.ari/bin:/opt/cray/alps/5.2.4-2.0502.9822.32.1.ari/sbin:/opt/cray/dvs/2.5_0.9.0-1.0502.2188.1.116.ari/bin:/opt/cray/xpmem/0.1-2.0502.64982.5.3.ari/bin:/opt/cray/pmi/5.0.10-1.0000.11050.0.0.ari/bin:/opt/cray/ugni/6.0-1.0502.10863.8.29.ari/bin:/opt/cray/udreg/2.3.2-1.0502.10518.2.17.ari/bin:/opt/toolworks/totalview.8.11.0-0/bin:/opt/totalview-support/1.1.4/bin:/opt/gcc/4.9.3/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/libnvvp:/opt/java/jdk1.8.0_51/bin:/apps/common/UES/SLES11/ddt/6.0.6/libexec:/apps/common/UES/SLES11/ddt/6.0.6/bin:/opt/cray/mpt/7.3.2/gni/bin:/apps/daint/munge/default/bin:/apps/daint/slurm/default/bin:/opt/slurm/default/bin:/opt/cray/craype/2.4.0/bin:/opt/cray/switch/1.0-1.0502.60522.1.61.ari/bin:/opt/cray/eslogin/eswrap/1.1.0-1.020200.1231.0/bin:/opt/modules/3.2.10.3/bin:/users/user_name/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/usr/lib/mit/bin:/usr/lib/mit/sbin:/sbin:/usr/sbin:.:/usr/lib/qt3/bin:/opt/cray/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin \\\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /users/user_name/tf_cray_env/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/* bazel-out/local_linux-py3-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nrm: cannot remove `/tmp/half_plus_two/00000123/assets': Permission denied\nrm: cannot remove `/tmp/half_plus_two/00000123/export-00000-of-00001': Permission denied\nrm: cannot remove `/tmp/half_plus_two/00000123/export.meta': Permission denied\nrm: cannot remove `/tmp/half_plus_two/00000123/checkpoint': Permission denied\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 1912.489s, Critical Path: 975.47s\n```\n\nWouldn't it make sense if the genrule half_plus_two would also use TEST_TMPDIR or is there some reason that it does not. \n\nWhere do I have to make changes to hardcode the directory used by the genrule?\n\nThanks for whatever support you are able to provide.\n", "comments": ["I was able to circumvent this issue because I am the owner of the directory in /tmp/ on one cluster node.. Still, this should get fixed some how..\n", "The right thing to do is probaly use tempfile module which will use the standard temp directory TMPDIR or TMP or TEMP depending on platform. Please feel free to submit a PR at this time. I'll also file an internal bug to improve our handling of temporary files, because this is not an isolated problem.\n", "Half plus two rules have been modofied, due to other issues caused by them.\r\nThis issue should be resolved as a side effect.\r\nI will close this issue, but please reopen and assign to me if the issue is still there at master or 0.12"]}, {"number": 3201, "title": "Calculate a vector l1 norm of a tensor creates unnecessary copy of tensor", "body": "I am using tensorflow 0.9.\nwhen I am trying to calculate a simple l1-norm of vector, like \n\n``` python\n    matrix = vs.get_variable(\"Matrix\", [total_arg_size, output_size])                      \n    l1norm = tf.reduce_mean(tf.abs(matrix))                                                 \n```\n\nTensorflow allocates memory for the results of tf.abs(matrix). when matrix size are large, this could cause out of memory issue.\nIs there a way I can avoid this additional allocation? \n", "comments": ["I have encountered the same problem. Tensorflow also allocates memory for gradients of intermediate operations and it makes working with large models impossible. It would be great to hear reasons for such memory model and how unnecessary allocations can be avoided.\n", "It is always possible to create monolithic custom ops on your side when you find bottlenecks that are show stoppers. However, we are always working to improve performance. Perhaps  @michaelisard @vrv can provide context and point of view.\n", "We realize that unnecessary copies are undesirable: they can make you run out of GPU memory as you observe, and even when they don't they consume unnecessary memory bandwidth.\n\nThere are two strategies being investigated that could help here, but both are non-trivial and will take some time to be done in a comprehensive fashion.\n\nThe first is to allow general-purpose Ops to do in-place updates, i.e. re-use the input memory buffer instead of allocating a new buffer for the output. This is non-trivial because buffers in TensorFlow can be aliased, and obviously we can't update a buffer that another consumer believes is immutable. It isn't as simple as just reference counting because aliased variables add more complexity. I am working on a formal memory model for TensorFlow which is a step towards doing the analysis that would allow in-place updates to be done with confidence.\n\nThe second is to do some kind of operator fusion as in #164 which again is being worked on but will take some time.\n\nIn the meantime as @aselle indicates the workaround is do write a custom fused Op. It's not an ideal situation but should allow you to make progress if you are really blocked on memory.\n"]}, {"number": 3200, "title": "dnn_linear_combined.py is not compatible with Python 3", "body": "in Python 3.x, line 215 of dnn_linear_combined.py (master version) results in an error.\n\n**line 215 is:**\nreturn sorted(set(self._dnn_feature_columns)) if self._dnn_feature_columns else None\n\n**the error is:**\nbuiltins.TypeError: unorderable types: _SparseColumnHashed() < str()\n\n**to reproduce this error:**\nin wide_n_deep_tutorial.py, change the following line:\nfeature_cols = dict(continuous_cols.items() + categorical_cols.items())\nto\nfeature_cols = {_**continuous_cols , *_*categorical_cols}\nthis change makes wide_n_deep_tutorial.py compatible with Python 3.x.\nNow simply run it like:\npython3.5 wide_n_deep_tutorial.py --model_type=wide_n_deep\n", "comments": ["That only works on 3.5 or higher, so it would make it incompatible with python 2.x  so maybe we should do\nfeature_cols = dict(continuous_cols)\nfeature_cols.update(categorical_cols)\n", "@hengtze could you take a look at the fix and integrate it if possible?\n", "But the error in line 215 of dnn_linear_combined.py still persists.\n", "yes\n", "under the python3.5, the newest wide_n_deep_tutorial.py still encounter the  problem of \"TypeError: unorderable types: _SparseColumnHashed() < str()\"\n", "This works fine for me(python 3.4).\nChange function _get_dnn_feature_columns in learn/python/learn/estimators/dnn_linear_combined.py as:\n\ndef _get_dnn_feature_columns(self):\n    return sorted(\n        set(self._dnn_feature_columns),\n        key=lambda x: x.key) if self._dnn_feature_columns else None\n", "Thanks, checked with 3.5, and your solution solves the issue.\n", "I had the same _SparseColumnHashed() < str() error on wide_n_deep_tutorial.py \n\nThe change skywildworld suggested fixed it for me as well on 3.5\n", "@hengtze could you take a look at this please?\n", "No problem. I'll take a look again. Thanks for reporting the issue!\n", "I'm not sure how the change that @skywildworld suggested would fix the problem.\n\nIf you look at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py#L236\n\ndef _get_dnn_feature_columns(self):\n    if not self._dnn_feature_columns:\n      return None\n    feature_column_ops.check_feature_columns(self._dnn_feature_columns)\n    return sorted(set(self._dnn_feature_columns), key=lambda x: x.key)\n\nIt's doing the same operations (except the line feature_column_ops.check_feature_columns). Since  @eyewy mentioned \"line 215\" of dnn_linear_combined.py, I wonder if some people are running older versions of the code. Can someone confirm that this issue occurs with the latest version of the code, and that skywildworld's solution fixes the issue?\n", "@hengtze \n**I can confirm this issue is present in the most recent version of code.** I was trying to do the tutorial here: https://www.tensorflow.org/versions/r0.9/tutorials/wide/index.html using [this code](https://github.com/JulianNorton/trump-weather/blob/87062b07e037e1c3dedb06bd45c95d222e175f85/tensor-flow.py).\n\nPython 3.5.1\nTensorflow 0.9.0\n\n## Problem\n\n```\ndef _get_dnn_feature_columns(self):\n      return sorted(\n        set(self._dnn_feature_columns),\n        key=lambda x: x.key) if self._dnn_feature_columns else None\n```\n\nin dnn_linear_combined.py was causing the issue as @skywildworld mentioned.\n\n```\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 216, in _get_dnn_feature_columns\n    self._dnn_feature_columns)) if self._dnn_feature_columns else None\nTypeError: unorderable types: _SparseColumnKeys() < str()\n```\n\n## Solution\n\nChange line 214 in `dnn_linear_combined.py`\n\n```\ndef _get_dnn_feature_columns(self):\n      return sorted(\n        set(self._dnn_feature_columns),\n        key=lambda x: x.key) if self._dnn_feature_columns else None\n```\n\nand now the program works with this output\n\n```\naccuracy: 0.820588\neval_auc: 0.8732\nloss: 1.13403\n```\n", "I see that the suggested changes have been made to the file.\r\nhttps://github.com/tensorflow/tensorflow/commit/ab30c2d368ecd7fc691de15a1a8b242ad59bc2af seems to have resolved this. Closing issue."]}, {"number": 3199, "title": "All weights become nan after training more than about 20000+10000 times", "body": "Operating System: CentOS 7\nInstalled version of CUDA and cuDNN: cuda 7.5.18, cudnn4\n\nWhen I run my own project, I found that all weights would become nan after training more than 20000+10000 times (That means I first trained the model for 20000 times, and then I continued training the model for 10000 times). The accuracy would suddenly change from 0.8 to 0.5. I thought that might be my own problem of setting weights and they become divergent after a certain point.\n\nBut we I rerun the Tensorflow tutorial: \"Deep MNIST for Experts\", I got the same problem.\nFollow the instruction, I run the following script:\n\nfor i in range(20000):\n  batch = mnist.train.next_batch(50)\n  if i%100 == 0:\n    train_accuracy = accuracy.eval(feed_dict={\n        x:batch[0], y_: batch[1], keep_prob: 1.0})\n    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\nEverything is perfect until now, and the training accuracy is as high as 0.99.\n\nHowever, when I rerun the above script, something strange happened. The training accuracy suddenly become around 0.1 and all weights become nan. Like following: \n<img width=\"372\" alt=\"screen shot 2016-07-06 at 02 19 17\" src=\"https://cloud.githubusercontent.com/assets/19503832/16603033/79ca3a3a-4321-11e6-92b7-19750de858c9.png\">\n<img width=\"775\" alt=\"screen shot 2016-07-06 at 02 20 15\" src=\"https://cloud.githubusercontent.com/assets/19503832/16603036/8074b87e-4321-11e6-9736-6ff2a98f5a4c.png\">\n\nTo reproduce the problem, first train the model for 20000 times, and then continue training the module for 20000 times, using another for loop.\n", "comments": ["I tried again, training 40000 times continuously. I got the same problem at training step 32400.\n<img width=\"295\" alt=\"screen shot 2016-07-06 at 12 52 28\" src=\"https://cloud.githubusercontent.com/assets/19503832/16614456/0917f60c-437a-11e6-8c49-c6b3e888a190.png\">\n", "I do not know that's a hardware problem or software problem. However, at the end, I indeed got some warning of running out of memory.\n<img width=\"1009\" alt=\"screen shot 2016-07-06 at 12 53 51\" src=\"https://cloud.githubusercontent.com/assets/19503832/16614604/d82f2e38-437a-11e6-9f8e-afea48f5e5b9.png\">\n", "NaN's are a common situation with neural network training. If the dataset\nis easy enough, then SGD will drive your log loss to negative infinity,\nwhich will overflow at some point and cause NaNs.\n\nAn indication of a problem is when you run the same network on two\ndifferent versions of tensorflow, and it only diverges on one, but not the\nother.\n\nOn Wed, Jul 6, 2016 at 2:09 PM, Yu Li notifications@github.com wrote:\n\n> I do not know that's a hardware problem or software problem. However, at\n> the end, I indeed got some warning of running out of memory.\n> [image: screen shot 2016-07-06 at 12 53 51]\n> https://cloud.githubusercontent.com/assets/19503832/16614604/d82f2e38-437a-11e6-9f8e-afea48f5e5b9.png\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3199#issuecomment-230732164,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AABaHMjH4Vi-1iekm1TLQzOx6eg7XbTMks5qS37qgaJpZM4JFoR6\n> .\n", "@yaroslavvb , thank you!\n\nI found a solution to this problem just now. http://stackoverflow.com/questions/33712178/tensorflow-nan-bug?newreg=c7e31a867765444280ba3ca50b657a07.\n"]}, {"number": 3198, "title": "Error: Nodes were connected by a reference connection", "body": "I am running distributed TF 0.8 for Py 3.5. I have followed the initialization of tf.train.Server() as in the imagenet_distributed_train.py. I am getting the following error while executing sv.prepare_or_wait_for_session(). I am passing remote ps server and local workers as the arguments. I do have blocks of code using tf.device('/cpu:0') at some places.\n\nsv = tf.train.Supervisor(is_chief=is_chief,\n                                       init_op=init_op,\n                                        summary_op=None,\n                                        global_step=global_step)\nsess_config = tf.ConfigProto(\n                 allow_soft_placement=True,\n               log_device_placement=True)\n # Get a session.\nsess = sv.prepare_or_wait_for_session(target, config=sess_config)\n\nError while executing last line:\ntensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: Nodes were connected by a reference connection (requiring them to be on the same device), but the two nodes were assigned two different devices: Cannot colocate nodes 'Variable' and 'Assign: Cannot merge devices with incompatible jobs: '/job:ps/task:0' and '/job:worker/task:0'\n         [[Node: Assign = Assign[T=DT_FLOAT, use_locking=false, validate_shape=true, _device=\"/job:worker/task:0\"](Variable, mul)]]\n\nAny idea what is happening?\n", "comments": ["@mrry, could you please take a look.\n", "Specifically, I have converted [translate.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py) to run in the TF synchronous distributed mode. The above error occurs while preparing the session:-\n\nsess = sv.prepare_or_wait_for_session(target, config=sess_config)\n", "Hi there! I'm on vacation right now, but if this is still a problem in a fortnight, feel free to reassign to me.\n", "You cannot place the assign op on a different device than the variable -- fix that and the problem goes away -- as far as I can tell this isn't a bug, so any follow ups should probably be on StackOverflow.\n", "Hi - I am not doing any assignment in the code. As noted above, I am changing translate.py example in TF to the distributed one. It is using seq2seq implementation from TF code itself. I suspect there is bug in the seq2seq implementation in TF which is assigning nodes to the different devices.\n", "Try updating to r0.9 -- I checked in a change that ignores impossible placements a month or so ago. :)\n", "The similar problem occurs again in TF 1.4. My distributed tf codes work fine for TF 1.2,  when I update TF to version 1.4, below errors are reported for some codes, take seq2seq as example:\r\n\r\n------------------------------------------\r\n2017-12-25 11:00:50.946656: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session 8f2200ccca936616 with config: allow_soft_placement: true\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Cannot colocate nodes 'tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/read_tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases_0' and 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/RMSProp_1: Cannot merge devices with incompatible jobs: '/job:worker/task:1/device:CPU:0' and '/job:ps/task:0/device:CPU:0'\r\n\t [[Node: tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/read_tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases_0 = Identity[T=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases\"], _device=\"/job:ps/task:0/device:CPU:0\"](tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/cond/Merge)]]\r\n\r\nCaused by op u'tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/read_tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases_0', defined at:\r\n  File \"/home/peng/letrain/applications/letrain.py\", line 241, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/peng/letrain/applications/letrain.py\", line 238, in main\r\n    LeTrain().model_train(user_mode)\r\n  File \"/home/peng/letrain/platform/base_train.py\", line 1046, in model_train\r\n    tvars_ps, acc_grads = self._gen_ps_model_and_acc_grads(variables_to_train, deploy_config)\r\n  File \"/home/peng/letrain/platform/base_train.py\", line 679, in _gen_ps_model_and_acc_grads\r\n    trainable=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\r\n    use_resource=use_resource, constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 345, in _init_from_args\r\n    self._build_initializer_expr(self._initial_value),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 777, in _build_initializer_expr\r\n    new_op = self._build_initializer_expr(initial_value.op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 813, in _build_initializer_expr\r\n    attrs=initial_value.node_def.attr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Cannot colocate nodes 'tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/read_tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases_0' and 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/RMSProp_1: Cannot merge devices with incompatible jobs: '/job:worker/task:1/device:CPU:0' and '/job:ps/task:0/device:CPU:0'\r\n\t [[Node: tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases/read_tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases_0 = Identity[T=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/biases\"], _device=\"/job:ps/task:0/device:CPU:0\"](tvars_ps35_embedding_attention_seq2seq_embedding_attention_decoder_attention_decoder_AttnOutputProjection_biases/cond/Merge)]]\r\n\r\n\r\n\r\n", "FWIW, I am running into this issue on Tensorflow 1.7.0\r\n\r\nI am using a single parameter server and a single worker. I am training a seq2seq model and using the `tf.train.replica_device_setter(...)` function to assign variables to the parameter server and ops to the worker node.\r\n\r\nHere is the error message that I am getting: \r\n```\r\nInvalidArgumentError (see above for traceback): Cannot colocate nodes 'Decoder-Word-Embedding/embeddings' and 'training/Nadam/gradients/Decoder-Word-Embedding/Gather_grad/Shape: Cannot merge devices with incompatible jobs: '/job:worker/task:0' and '/job:ps/task:0'\r\n   [[Node: Decoder-Word-Embedding/embeddings = VariableV2[container=\"\", dtype=DT_FLOAT, shape=[4278,300], shared_name=\"\", _device=\"/job:ps/task:0\"]()]]\r\n```"]}, {"number": 3197, "title": "add l2 regularization and dropout", "body": "Hi,\n\nIs it posible to add l2 regularization and dropout in the text_classification_cnn.py ?\n\nThanks\n", "comments": ["@rubenstern You can use `contrib.layers.regularizers` found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py)\n", "@rubenstern, does this address your need. If so please close the bug.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3196, "title": "Nightly builds 404 Not Found", "body": "I'm getting a 404 error on trying to download all nightly builds: https://github.com/tensorflow/tensorflow#installation\n", "comments": ["The links here do not seem to work https://github.com/tensorflow/tensorflow#installation\nThe links here do work https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#optional-install-cuda-gpus-on-linux\n", "@caisq can you look at this? I think either the cp commands in the builds need to be updated, or we should just adjust the links.\n", "@aselle I need the nightly builds. I don't see any nightly builds in the second link. I need `conv3d_transpose` added here: https://github.com/tensorflow/tensorflow/pull/3049#issuecomment-229742733\n", "If you click on the \"build history\" links, you can click through to the\nactual file from there.\n\nOn Wed, Jul 6, 2016 at 3:29 PM Kendall Weihe notifications@github.com\nwrote:\n\n> @aselle https://github.com/aselle I need the nightly builds. I don't\n> see any nightly builds in the second link. I need conv3d_transpose added\n> here: #3049 (comment)\n> https://github.com/tensorflow/tensorflow/pull/3049#issuecomment-229742733\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3196#issuecomment-230926570,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_ZP4a8Ydku-olV3CUAzAojRQNemdks5qTCxegaJpZM4JFglQ\n> .\n", "@martinwicke I'm missing the \"build history\" link. You're saying it's on this page right? https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#optional-install-cuda-gpus-on-linux\n\n(that's what @aselle linked) I actually just need the latest Python 3.5 build for linux\n", "They're in the readme: \nCPU: http://ci.tensorflow.org/view/Nightly/job/nightly-python35-linux-cpu/\nGPU: http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3.5,label=gpu-linux/\n", "@martinwicke when I install that build it installs it in python 3.4?\n\n **UPDATE** I am unable to install any tensorflow for python 3.5, so I'm guessing it is throwing it in 3.4. When I try to install the current release of 3.5 from https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#pip-installation I get the following error: `tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl is not a supported wheel on this platform.`\n\nI tried suggestion by @tim-scharf here: https://github.com/tensorflow/tensorflow/issues/3079 but no luck\n\nI have confirmed this issue on both of my linux machines\n", "That's the 3.5 link, so no. The top level readme contains the nightly build\nhistory links.\nOn Thu, Jul 7, 2016 at 07:53 Kendall Weihe notifications@github.com wrote:\n\n> @martinwicke https://github.com/martinwicke when I install that build\n> it installs it in python 3.4?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3196#issuecomment-231102275,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_QDOTngA7hMN0GJ6G7OVutI3p0JNks5qTRL9gaJpZM4JFglQ\n> .\n", "Why would it be installing in python 3.4? When I run `python3.5 tensorflow_project.py` it gives me `no module named tensorflow` and I have confirmed it isn't in the python 3.5 directory. But I have also confirmed that when I run that installation, it refreshes my python 3.4 directory. \n", " That probably just means your pip is setup for your Python 3.4.\nOn Thu, Jul 7, 2016 at 08:35 Kendall Weihe notifications@github.com wrote:\n\n> Why would it be installing in python 3.4? When I run python3.5\n> tensorflow_project.py it gives me no module named tensorflow and I have\n> confirmed it isn't in the python 3.5 directory. But I have also confirmed\n> that when I run that installation, it refreshes my python 3.4 directory.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3196#issuecomment-231116284,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_ZIgjsNfSIr9RI2ZRdrs17ISs7Ksks5qTRzTgaJpZM4JFglQ\n> .\n", "You did the right thing, Stackoverflow is the place to ask these questions.\n\nOn Thu, Jul 7, 2016 at 9:06 AM Kendall Weihe notifications@github.com\nwrote:\n\n> I am unable to find any support for installing pip for python 3.5. I've\n> tried upgrading sudo pip -U pip but it tells me it is already up to date.\n> \n> I've outlined everything here:\n> http://stackoverflow.com/questions/38249961/install-pip-for-python-3-5\n> \n> Any help?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3196#issuecomment-231126681,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_XXju1Wb-zV5afb0RkaMFTlchEWIks5qTSQPgaJpZM4JFglQ\n> .\n", "http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/150/\n\nas of build 151, the name changed from none-linux to none-any.\n", "Website is also updated (many many times since this issue :) ) to point to correct URLs.\r\nClosing this issue."]}]