[{"number": 33378, "title": "Problem with Keras, Tensorflow", "body": "\r\n**System information**\r\n- Windows 10\r\n- TensorFlow installed from anaconda\r\n- Python version: 3.7\r\n- Installed using conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Nvidia GeForce GTX 260, Graphics memory 3GB\r\n\r\nCode:\r\n\r\nfrom keras.models import Sequential\r\n\r\nError:\r\n\r\nUsing TensorFlow backend.\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-9c5e0a19b646>\", line 1, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\chris\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["Does your CPU support AVX?", "Probably not. It's quite an old CPU, Intel Core 2 Quad Q9400. Could you please clarify what the problem is particularly? I tried to install keras several times but it hasn't worked yet.", "The installed package will have been compiled for use with AVX. If you don't have AVX then you'll need to compile yourself for your machine.\r\n\r\nSee #19584 and #33279.", "@christosiraklis \r\n\r\nPlease, let us know which TensorFlow version you are using?\r\n\r\nTensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\n\r\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n\r\n- Try Google Colab to use TensorFlow.\r\n\r\n1.The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=). You get pre-installed latest stable TF version. Also you can use pip install to install any other preferred TF version.\r\n2.It has an added advantage since you can you easily switch to different hardware accelerators\r\n(cpu, gpu, tpu) as per the task.\r\n3.All you need is a good internet connection and you are all set.\r\n\r\n- Try to build TF from sources by changing CPU optimization flags.\r\n\r\nPlease let us know if this helps.", "Ok thanks guys. Understood.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33378\">No</a>\n", "I am also having this issue but cannot find a way to solve it. Has anyone had this problem solved?", "Try installing older versions of keras and tensorflow or go with Google Colab.", "I managed to solve this problem: just following [this post](https://towardsdatascience.com/tensorflow-gpu-installation-made-easy-use-conda-instead-of-pip-52e5249374bc), i.e., creating a new environment with tensorflow-gpu 2.0 support, activating it, and installing all necessary packages (e.g. keras, scikit-learn, etc), will do the trick. \r\n\r\n`conda create --name tf_gpu tensorflow-gpu `\r\n`activate tf_gpu`\r\n\r\nI've spent hours trying to install tensorflow-gpu 2.0 in the base environment on Windows 10, but it just can't. \r\n\r\n\r\n", "i am also facing the same issue and my system is Intel(R) Core(TM) i5-2450M CPU @2.50GHz. I even checked that it supports AVX. And now not able detect the issue.", "@Alankriti44 did you install the latest MSVC redistributable?", "I solved this issue by downloading and installing \r\n\"Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019\". It worked for me.\r\n\r\nPre-requisite: Python + Jupyter notebook + tensorflow installation already done\r\n\r\nYou get this error when you \"import tensorflow\"\r\n\r\nFollow the below steps:\r\n\r\nStep 1: Download \"Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 - community edition\"\r\n\r\nStep 2: Select \"Python Workload\" while installing Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019\r\n\r\nStep 3: Restart your computer once\r\n\r\nStep 4: That's it now open Jupyter notebook and \"import tensorflow\" and the error will not occur  ", "I have \"Microsoft Visual C++ 2015 Redistributable (x86)-14.0.23026\" installed in my system. But still not working. Please guide me what is wrong with it.", "Latest is 2019, not 2015", "> I have \"Microsoft Visual C++ 2015 Redistributable (x86)-14.0.23026\" installed in my system. But still not working. Please guide me what is wrong with it.\r\n\r\n\r\n\r\nPlease install the latest from the below link.. \r\n\r\nUse community edition and select python workload while installation. \r\n\r\nhttps://visualstudio.microsoft.com/downloads/\r\n\r\n\r\nPlease restart you computer after the installation is over. \r\n\r\nPlease try and let me know what you get. ", "Step 1: Create a new conda environment where we will install our modules to built our models\r\nStep 2: Open Anaconda Prompt (Run as Administrator)\r\nconda create --name deeplearning\r\nStep 3: Activate the conda environment that we just created use\r\nactivate deeplearning\r\nStep 4: Install Keras\r\nconda install -c anaconda keras\r\nStep 5: Install Jupyter \r\nconda install jupyter #very important if you work on Jupyter Notebook\r\nStep 6: Update tensorflow\r\npip install --ignore-installed --upgrade tensorflow==2.0\r\nStep 7: Install following \r\nconda install spyder #very important if you work on spyder\r\nconda install matplotlib\r\nconda install pandas"]}, {"number": 33377, "title": "Fix typo in docstring", "body": "`Input`s should be `Inputs` in the add_loss() docstring at tensorflow/python/keras/engine/base_layer.py", "comments": ["I don't think this is required. The class is called `Input`, not `Inputs`", "> I don't think this is required. The class is called `Input`, not `Inputs`\r\n\r\nSo it's just a redundant ```s``` in the docstring that should be removed right?", "There are multiple instances of class `Input`, so they get called \"`Input`s\"", "Okay i get it now."]}, {"number": 33376, "title": "importing tensorflow inside a function/object causes a memory leak", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip install tensorflow==1.14\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nWhen importing tensorflow from a function or object, the `import` statement somehow keeps a reference to the function and increasing it's reference count. The full `import` stacktrace is never freed, making it impossible for the object (and anything referenced from that object or function) to be freed from memory.\r\n\r\n**Describe the expected behavior**\r\nIt should be possible to free the function calling `import tensorflow`. This is not an issue with any other imports (like `import logger`).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport gc\r\n\r\n\r\nclass TFImporter:\r\n    def __init__(self, name):\r\n        self._name = name\r\n        print(f\"TFImporter init {self._name}\")\r\n\r\n    def get_tf(self):\r\n        print(f\"import tensorflow {self._name}\")\r\n        import tensorflow\r\n        print(tensorflow.version.VERSION)\r\n\r\n    def get_other_module(self):\r\n        print(f\"import logging {self._name}\")\r\n        import logging\r\n        logging.info(\"Message\")\r\n\r\n    def __del__(self):\r\n        print(f\"TFImporter delete {self._name}\")\r\n\r\n\r\ndef main():\r\n    importer1 = TFImporter(1)\r\n    importer1.get_other_module()\r\n    del importer1\r\n    print(\"importer1 deleted\")\r\n\r\n    importer2 = TFImporter(2)\r\n    importer2.get_tf()\r\n    del importer2\r\n    print(\"importer2 deleted\")\r\n\r\n    importer3 = TFImporter(3)\r\n    importer3.get_tf()\r\n    del importer3\r\n    print(\"importer3 deleted\")\r\n\r\n    print(f\"Garbage collection: {gc.collect()}\")\r\n\r\n    print(f\"Waiting for input:\")\r\n    input()\r\n\r\n\r\nmain()\r\n```\r\n\r\nthis outputs:\r\n\r\n```\r\n/Users/jan/miniconda/envs/foo/bin/python /Users/jan/code/tensorflow_error.py\r\nTFImporter init 1\r\nimport logging 1\r\nTFImporter delete 1\r\nimporter1 deleted\r\nTFImporter init 2\r\nimport tensorflow 2\r\n1.14.0\r\nimporter2 deleted\r\nTFImporter init 3\r\nimport tensorflow 3\r\n1.14.0\r\nTFImporter delete 3\r\nimporter3 deleted\r\nGarbage collection: 22\r\nWaiting for input:\r\nfoo\r\nTFImporter delete 2\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\nSo `importer2` is only freed after the python application finishes. Neither `gc.collect` nor deleting the object causes it to be released in python.\r\n\r\nThis is not an issue in this toy example, but `importer2` could have a reference to a large number of other objects that take considerable space in memory in reality.\r\n\r\nAlso, this only happens for the first `import`. `importer3` can be freed without issues.\r\n\r\n**Other info / logs**\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/3729501/tf_env.txt)\r\n", "comments": ["Issue replicating for Tf 1.14, kindly for the [gist](https://colab.sandbox.google.com/gist/oanush/e224d0fa208b982d84e5cb18c1317ce9/33376.ipynb).ThThanks!", "@annarev is this related to lazy loaders or estimator/keras integration?", "It appears to be due to saving error when importing portpicker here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L44\r\n\r\nWe can probably save the error text instead or import portpicker inside the function that creates a cluster.", "Yeah, it seems weird that we'd survive the import, only to error out later.\nLet's either import it inside the cluster creation, or print the error\ndirectly on import (but still continue), and later error with a note to\nlook for the earlier error.\n\nHonestly, I think the local import is preferable in this case.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376\">No</a>\n"]}, {"number": 33375, "title": "TF2.0 ptxas ignores PATH", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux x86_64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 10.0/7.6\r\n- GPU model and memory: GeForce RTX 2080 Ti\r\n\r\n**Describe the problem**\r\n\r\nI am receiving an error\r\n`E tensorflow/stream_executor/cuda/ptxas_utils.cc:110] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 9.2.88).  Compilation of XLA kernels below will likely fail.`\r\nsuggesting that tensorflow uses ptxas version that ignores the PATH variable.\r\n\r\nPATH, LD_LIBRARY_PATH, CUDA_HOME all points to the CUDA 10.0 directory\r\nLD_LIBRARY_PATH also points to the CUDNN 7.6 directory\r\n\r\ntyping `ptxas --version` gives me:\r\n`Cuda compilation tools, release 10.0, V10.0.145`\r\n\r\nHow is it possible that tensorflow launches ptxas of version 8 (probably from /usr/local/cuda/bin/) when all the important environment variables points to ptxas of version 10?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nThe bug can be spotted for example when using tensorflow-addons and image rotate function.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_addons as tfa\r\n\r\nclass Model:\r\n    def __init__(self):\r\n        tf.keras.backend.clear_session()\r\n        \r\n        inp = tf.keras.layers.Input((32,32,3), name='input_image')\r\n        net = tf.keras.layers.Conv2D(3, 3, padding=\"same\")(inp)\r\n\r\n        self.model  = tf.keras.Model(inputs=inp, outputs=net)\r\n        self.optimizer = tf.keras.optimizers.Adam()\r\n        self.loss_obj = tf.keras.losses.MeanSquaredError()\r\n        \r\n    @tf.function\r\n    def train_step(self):        \r\n        angles_rad = tf.random.uniform((), 0, 3.14)\r\n        images = tf.random.uniform((2,32,32,3))\r\n\r\n        with tf.GradientTape() as tape:\r\n            features = self.model(images, training=True)\r\n\r\n            #angles_rad = tf.constant([0.5,0.4])\r\n            rot_features = tfa.image.rotate(features, angles_rad, interpolation='NEAREST', name=\"rotate_features\")\r\n            \r\n            loss = self.loss_obj(images, rot_features)\r\n\r\n        variables = self.model.trainable_variables\r\n        gradients = tape.gradient(loss, variables)\r\n        self.optimizer.apply_gradients(zip(gradients, variables))\r\n        return loss\r\n    \r\n    def train(self, nr_epochs):\r\n        for epoch in range(nr_epochs):\r\n            loss = self.train_step()\r\n            print(\"Train Epoch {}: {}\".format(epoch, loss))\r\n\r\ntrainer = Model()\r\ntrainer.train(5000)\r\n```\r\n\r\n**Any other info / logs**\r\nFull log of the code above:\r\n\r\n2019-10-15 15:23:07.768703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-10-15 15:23:07.780261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\r\npciBusID: 0000:3b:00.0\r\n2019-10-15 15:23:07.780892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-15 15:23:07.782852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-15 15:23:07.784779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-10-15 15:23:07.785515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-10-15 15:23:07.787842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-10-15 15:23:07.790057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-10-15 15:23:07.794875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-15 15:23:07.796010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-15 15:23:07.796248: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-10-15 15:23:07.804370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200000000 Hz\r\n2019-10-15 15:23:07.806385: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d5b167670 executing computations on platform Host. Devices:\r\n2019-10-15 15:23:07.806411: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-10-15 15:23:07.919879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d5b1ca830 executing computations on platform CUDA. Devices:\r\n2019-10-15 15:23:07.919925: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2019-10-15 15:23:07.920755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\r\npciBusID: 0000:3b:00.0\r\n2019-10-15 15:23:07.920810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-15 15:23:07.920825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-15 15:23:07.920837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-10-15 15:23:07.920855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-10-15 15:23:07.920867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-10-15 15:23:07.920878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-10-15 15:23:07.920894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-15 15:23:07.921926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-15 15:23:07.921954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-15 15:23:07.922826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-15 15:23:07.922841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-10-15 15:23:07.922853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-10-15 15:23:07.923954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10312 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5)\r\n2019-10-15 15:23:10.869688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-15 15:23:12.622865: E tensorflow/stream_executor/cuda/ptxas_utils.cc:110] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 9.2.88).  Compilation of XLA kernels below will likely fail.\r\n\r\nYou do not need to update CUDA; cherry-picking the ptxas binary is sufficient.\r\n2019-10-15 15:23:12.700955: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'\r\n\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n2019-10-15 15:23:15.104683: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x562d5b1cdff0\r\n2019-10-15 15:23:15.104819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-10-15 15:23:15.436019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-15 15:23:15.727354: F tensorflow/core/kernels/cuda_solvers.cc:99] Check failed: cublasCreate(&cublas_handle) == CUBLAS_STATUS_SUCCESS Failed to create cuBlas instance.\r\nAborted (core dumped)\r\n", "comments": ["@DawyD, I tried on colab with Tf 2.0.0. It is working as expected please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/78ce12516b50127ba4cf21df959063a7/untitled200.ipynb). Thanks!", "@gadagashwini, I know, that the code will work on colab and 99% of systems. The code is not the point of this issue. The point is, that if you have multiple installations of CUDA on the system, it is somehow unclear where the ptxas is loaded from.", "I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n\r\nThe workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.", "Mark, we have the same problem", "Mark", "@DawyD, Thanks for the workaround. \r\n@KANGRuipeng and @lileicv  can you try the @DawyD's workaround and let us know if that helps. Thanks!", "> I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n> \r\n> The workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.\r\n\r\nHello there, @DawyD could you please provide a more detailed explanation on how to do this new linked directory? Do I have to create a new env var?", "> > I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n> > The workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.\r\n> \r\n> Hello there, @DawyD could you please provide a more detailed explanation on how to do this new linked directory? Do I have to create a new env var?\r\n\r\nHi @kleyersoma. The workaround for this particular problem on unix-based machines is to link your cuda bin to your working directory. Go to the directory, where you launch your python code and create the link:\r\n`ln -s /full/path/to/your/cuda/installation/bin .`\r\nThis sovles the problem. The point is that TF first tries to load the ptxas from ./bin directory, then from /usr/local/cuda/bin. Unfortunately, it completely ignores the environment variables (which I consider to be a bug).", "Hello @DawyD \r\nI currently have the same problem as you did. There are several versions of CUDA installed on our GPU server, and since I am not sudo, I had to install CUDA in a custom directory. I guess you did the same.\r\n\r\nI tried to create a symbolic link as you said, however tensorflow keeps ignoring the correct version of ptxas. Even physically copying the ptxas binary in a `bin` folder doesn't work either... Is there something I'm missing about the workaround you gave ?\r\n\r\nGenerally speaking, I guess there isn't a whole load of peoples complaining about the problem since, first, they have to had installed CUDA themselves, and then to carefully look at the logs to see the problem.\r\n\r\nNevertheless, I agree with you @DawyD I looks like a bug.", "@cheshire Could this be a bug or miscommunication with the `pxtas` path loading code? It looks like the ptxas binary is supposed to load from the preferred CUDA root directory, but for these users it loads from the wrong place. Some of the logic is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/gpu/asm_compiler.cc, e.g.:\r\n\r\n```cpp\r\n  string ptxas_path;\r\n  auto env = tensorflow::Env::Default();\r\n  for (const string& cuda_root :\r\n       tensorflow::CandidateCudaRoots(options.preferred_cuda_dir)) {\r\n    ptxas_path = tensorflow::io::JoinPath(cuda_root, \"bin\", \"ptxas\");\r\n    VLOG(2) << \"Looking for ptxas at \" << ptxas_path;\r\n    if (env->FileExists(ptxas_path).ok()) {\r\n      break;\r\n    }\r\n  }\r\n  TF_RETURN_IF_ERROR(env->FileExists(ptxas_path));\r\n  VLOG(2) << \"Using ptxas at \" << ptxas_path;\r\n```", "@angerson @DawyD TF does not read CUDA_HOME.\r\nIt is possible to check where asm_compiler looks by running with the environment variable `TF_CPP_VMODULE=asm_compiler=2`.\r\nBasically at this point it will only look in the directory where CUDA is expected to be installed. I'm looking into feasibility/desirability of looking for ptxas under PATH, but as a workaround you can symlink ptxas into the directory where asm_compiler is looking.", "Ah apologies, I've missed the message above stating the workaround.\r\nAt the moment we are considering two possible fixes: either read the PATH variable and look for ptxas there, or try to figure out ptxas location from the locations of loaded shared objects (notably, `libcudart`)", "> @angerson @DawyD TF does not read CUDA_HOME.\r\n> It is possible to check where asm_compiler looks by running with the environment variable `TF_CPP_VMODULE=asm_compiler=2`.\r\n> Basically at this point it will only look in the directory where CUDA is expected to be installed. I'm looking into feasibility/desirability of looking for ptxas under PATH, but as a workaround you can symlink ptxas into the directory where asm_compiler is looking.\r\n\r\nThanks for your answer @cheshire.\r\nVery sorry if the following question looks dumb to you but I tried to run a simple job preceded by `export TF_CPP_VMODULE=asm_compiler=2` and I did not saw any additional ligne in the logs refering to the path the asm compiler was looking at.\r\nCould you be more specific on how to do that ?", "@N0ciple `TF_CPP_VMODULE` simply states \"print log messages with the file of a given name at a given verbosity level\".\r\nThe file is called `asm_compiler` in a nightly version. If you have an earlier version, it was called `ptxas_utils`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33375\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33375\">No</a>\n", "> > > I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n> > > The workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.\r\n> > \r\n> > \r\n> > Hello there, @DawyD could you please provide a more detailed explanation on how to do this new linked directory? Do I have to create a new env var?\r\n> \r\n> Hi @kleyersoma. The workaround for this particular problem on unix-based machines is to link your cuda bin to your working directory. Go to the directory, where you launch your python code and create the link:\r\n> `ln -s /full/path/to/your/cuda/installation/bin .`\r\n> This sovles the problem. The point is that TF first tries to load the ptxas from ./bin directory, then from /usr/local/cuda/bin. Unfortunately, it completely ignores the environment variables (which I consider to be a bug).\r\n\r\nThanks, it solved my problem!! Thanks!", "mark, same problem.", "@tootal Could you open a new issue with a reproducer? For the original author the issue was fixed.", "> > > I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n> > > The workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.\r\n> > \r\n> > \r\n> > Hello there, @DawyD could you please provide a more detailed explanation on how to do this new linked directory? Do I have to create a new env var?\r\n> \r\n> Hi @kleyersoma. The workaround for this particular problem on unix-based machines is to link your cuda bin to your working directory. Go to the directory, where you launch your python code and create the link:\r\n> `ln -s /full/path/to/your/cuda/installation/bin .`\r\n> This sovles the problem. The point is that TF first tries to load the ptxas from ./bin directory, then from /usr/local/cuda/bin. Unfortunately, it completely ignores the environment variables (which I consider to be a bug).\r\n\r\n\r\nI am sorry. I did this but all i got is : \r\nln: failed to create symbolic link './bin': File exists\r\n\r\nDo you know of another workaround @DawyD ?", "Can someone give a clear explanation on where to find the cuda path directory and the steps of the workaround ?\r\n\r\nWill be much appreciated... Thank you", "> > > I found out that it truly loads the ptxas from /usr/local/bin completely ignoring the PATH and CUDA_HOME environment variables.\r\n> > > The workaround is to create a \"bin\" directory where we launch the python and link it to the $CUDA_HOME/bin directory.\r\n> > \r\n> > \r\n> > Hello there, @DawyD could you please provide a more detailed explanation on how to do this new linked directory? Do I have to create a new env var?\r\n> \r\n> Hi @kleyersoma. The workaround for this particular problem on unix-based machines is to link your cuda bin to your working directory. Go to the directory, where you launch your python code and create the link:\r\n> `ln -s /full/path/to/your/cuda/installation/bin .`\r\n> This sovles the problem. The point is that TF first tries to load the ptxas from ./bin directory, then from /usr/local/cuda/bin. Unfortunately, it completely ignores the environment variables (which I consider to be a bug).\r\n\r\nThis solves my problem and saves the day :-)"]}, {"number": 33374, "title": "Python3.8 support", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 2\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: venv\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\n cant install tensorflow\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ninstall python 3.8\r\ncreate a new venv\r\n`venv> pip install tensorflow`\r\nfails with `ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow`\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nEDIT: I guess you don't provide binaries for python 3.8 (https://pypi.org/project/tensorflow/#files)\r\nis there another issue I can subscribe for about support for python 3.8? (couldn't find one, so keeping this open for now)", "comments": ["As you can refer from this [page](https://www.tensorflow.org/install/pip) Tensorflow is only supported till python 3.7 as of now.", "'awaiting response' from me?\r\n\r\nIn any case, I would prefer subscribe to an issue than wait for the web page update.", "@amitport I am going to close this issue and we will keep you updated once Tensorflow supports Python 3.8.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">No</a>\n", "still, IMHO, python3.8 support should be an issue open for discussion/contribution/updates.", "> As you can refer from this [page](https://www.tensorflow.org/install/pip) Tensorflow is only supported till python 3.7 as of now.\r\n\r\nThe page says 'python > 3.4' and then if you scroll down to 'Package Locations' you can see that there isn't one for 3.8, and I guess that means we're supposed to know to use 3.7 (or 3.6 for Windows)? Last I checked, both 3.7 and 3.8 are '> 3.4' so the documentation should probably reflect the version restrictions clearly.", "Looks like there are also build issues with python 3.8.\r\nLet's follow those up in https://github.com/tensorflow/tensorflow/issues/33543\r\n\r\nAnd once all our dependencies release python 3.8 packages, we will quickly move to prepare ours.", "so how install 3.7? i am on 3.8 now x.x", "@nonoyek as gunan said. They're waiting for their dependencies to release python3.8 packages and then release their python3.8.\r\n\r\nyou can either wait (hopefully not long) or install python3.7 (if you asking how to do that, then this is not the correct place. try stackoverflow.com)", "I have the same issue. Now I have both 3.7 and 3.8 installed, but it defaults to 3.8.\r\n\r\nI've tried to uninstall 3.8 by removing the 3.8 folder in Applications and also in the Python.Framework directory, but it is still looking for that path and just doesn't find it.\r\n\r\nHow do I go back to 3.7?", "@geoffreyhughes @nonoyek @amitport \r\n\r\nTensorFlow currently not support python 3.7. but I have solved this issue (on windows 10) by using Python environments like virtualenv , conda.\r\n\r\nfirst, you need to download python 3.5x or 3.6x >> https://www.python.org/downloads/ \r\nand install it to your machine. then you'll need to create a virtual environment with Python 3.6 or 3.5.\r\n( virtualenv -p {path to python.exe(3.6)}  {environment name} ) .\r\n\r\nfinally, check your python version with activating the virtual environment. \r\n\r\n", "I was able to successfully build TF on windows with python 3.8.\r\nHowever, grpcio still did not publish their python 3.8 package.\r\nTherefore, we are blocked on their release for our python 3.8 release", "FYI, these are the issues at grcpio: https://github.com/grpc/grpc/issues/20615 and https://github.com/grpc/grpc/issues/20831", "I will reopen this issue until python 3.8 nightlies are out.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">No</a>\n", "closed by accident... sorry", "This is not limited to windows. Rolling linux distributions without the option to downgrade  software packages are also facing the problem, especially with pip.", "@georgebush422 @gowthamkpr  should probably remove [subtype:windows](https://github.com/tensorflow/tensorflow/labels/subtype%3Awindows) tag", "Grpcio has released binaries for 3.8: grpc/grpc#20831. Do we have an estimate for when TF will be releasing?", "That's great news. We can start working on it. The roadmap is to first release `tf-nightly` with support for Python 3.8 (that is, provide support on `master` branch) and only after that we will release a TF version for 3.8. That is, TF 2.1 will not support 3.8 (as we are already in the process of releasing it) but TF 2.2 most likely will.", "I am on Arch Linux rolling release, I cannot install the any versions of tensorflow.\r\nlol Do I have to change the OS ?, not worth it.", "@debendraoli Install tensorflow using the Arch package.", "@debendraoli please read previous messages on the issue. Support for python3.8 is not yet released but will be done in the next year.", "> @debendraoli Install tensorflow using the Arch package.\r\n\r\nhow to install tensorflow arch package on virtualenv? ", "Install it systemwide. Or use 3.7 in a virtualenv.\n\nOn Sun, Dec 29, 2019, 17:13 Thomas Yeun <notifications@github.com> wrote:\n\n> @debendraoli <https://github.com/debendraoli> Install tensorflow using\n> the Arch package.\n>\n> how to install tensorflow arch package on virtualenv?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374?email_source=notifications&email_token=AA4OENI62K7BM46JOVYH753Q3DLEJA5CNFSM4JA4OP42YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHZEAUA#issuecomment-569524304>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AA4OENLAJGIZC2WV5THYJQLQ3DLEJANCNFSM4JA4OP4Q>\n> .\n>\n", "Arch guys, please create a different issue, don't pollute this one", "Python 3.8.0b1 Release Date: June 4, 2019\r\nI guess Top5 most popular Github project could do better.\r\nPlease update this issue with the progress on scale from 0 to 100 with step size 10.", "As we are a large project, we have to wait untill all our dependencies are\npython 3.8 compatible. This also prevents us from being able to try with\nthe beta release, the release you mention. Grpcio only released a\ncompatible package in mid-December, and we only were able to make sure all\nour build issues are resolved.\nSo, if you like you can build TF from sources for python 3.8 at the moment.\n\nNowadays, most of the team is on vacation. As we slowly come back from\nholidays, we will set up nightly 3.8 builds sometime in January. Official\nrelease with python 3.8 is planned in march, the 2.2 release. 2.1 was cut\nbefore all python 3.8 issues were resolved.\n\nOn Mon, Jan 6, 2020, 12:34 PM Alexander Grigoryev <notifications@github.com>\nwrote:\n\n> Python 3.8.0b1 Release Date: June 4, 2019\n> I guess Top5 most popular Github project could do better.\n> Please update this issue with the progress on scale from 0 to 100 with\n> step size 10.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374?email_source=notifications&email_token=AB4UEONV6BFCXYNDALXH3C3Q4L3KHA5CNFSM4JA4OP42YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIE5IVI#issuecomment-571069525>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AB4UEOOMCDI3BA3QIRACXT3Q4L3KHANCNFSM4JA4OP4Q>\n> .\n>\n", "As others said, in the meantime, it would go a long way if you could fix the docs as currently, it could be hard for newcomers to figure out why `pip install tensorflow` yields since it is stated that the Python Requirement is python 3.4 or later.\r\n\r\n```console\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\n@debendraoli you don't need to change OS, just use `virtualenv`.  ", "> @debendraoli you don't need to change OS, just use `virtualenv`.\r\n\r\nAs he mentioned, you don't need to change OS, you just need python 3.7. Try the following:\r\n```\r\nvirtualenv --system-site-packages -p python3.7 DEST_DIR \r\n```\r\n\r\n`DEST_DIR` is your destination directory. Make sure you have Python 3.7 installed. In my case, I installed it from the AUR.", "> As others said, in the meantime, it would go a long way if you could fix the docs as currently, it could be hard for newcomers to figure out why pip install tensorflow yields since it is stated that the Python Requirement is python 3.4 or later.\r\n\r\nGreat suggestion. Thank you for the feedback.\r\n@lamberta Can we update our docs to say currently python 3.8 is not supported yet?", "Sure. System requirements are in this doc: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.html#L31\r\n\r\nWhat should it say? Python 3.4-3.7 ?", "@lamberta yes, and \"3.8 soonish\".  This was were I also expected the docs to mention the requirements of Python supported.  I'd advise the team to keep that updated, requirements being a fairly important thing :)", "FYI, I built TF 1.15 with Python 3.8 myself at https://github.com/yaroslavvb/tensorflow-community-wheels/issues/139", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">No</a>\n", "Why was this closed? It is not resolved AFAIK (yes it can be built locally, but that's not the issue)", "ERROR: Could not find a version that satisfies the requirement tf-nightly (from versions: none)\r\nERROR: No matching distribution found for tf-nightly\r\nDoesn't work here either.", "it was autoclosed by a commit. we are still aware that 3.8 binaries are not available.", "@NIravMeghani this issue is still open, I would have been surprised if it did work", "@NIravMeghani Your wheel link points to a tensorflow 1.8.0 macOS wheel that is not compiled for python3.8. There is no way this wheel could actually work :) Also this issue is about python3.8 support for tensorflow 2.x.\r\n\r\nLook at https://www.tensorflow.org/install/pip#package-location for the latest possible wheels (Python 3.8 wheels are not yet available).\r\n\r\nFor now the easiest way is to build the wheel by yourself, takes possibly a few hours max.\r\nFollow the instructions at https://www.tensorflow.org/install/source_windows\r\nAdditional potentially useful hints:\r\n```\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\r\n```\r\nAlso set `set BAZEL_VC_FULL_VERSION=14.16.27023` for tensorflow 2.1 build regardless what the actual VC version is (any version works as long as it matches `float(environ_cp.get('TF_VC_VERSION', '0')) >= 16.4`). This is to ensure the build does not take a full day. Look at `configure.py` for the details.\r\n\r\nClone the tensorflow source from git, checkout the tag of your interest (2.1 is known to work, not sure about 1.15).\r\n\r\npython configure.py\r\nOptimization flags\r\n/arch:AVX2\r\n```\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_cuda_10_1\r\n```", "until 2.2 is released, `pip install tensorflow` will not work with python 3.8\r\nPlease see https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-571074915", "@mihaimaruseac , Please consider these changes in [#1435](https://github.com/tensorflow/docs/pull/1435) for doc correction till python 3.8 is not supported and review PR.", "Release date for a new version tensorflow that works on Python 3.8?", "So only downgrading to 3.7 or lower is the solution?", "For now there are 2 solutions: use Python 3.7 or compile from source. \r\n\r\nTF 2.2 will have python3.8 support.", "What about `tf-nightly`?", "We have some issues on Linux CPU where `tf-nightly` has been broken these past few days. Once they are resolved we can restart the process of building 3.8 nightlies and it should be at most 2-3 days after that.\r\n\r\nSo, hopefully by mid February we can release 3.8 nightlies.", "@mihaimaruseac Any ETA on TF 2.2? Weeks? Months?\r\n\r\nEdit: I should read more carefully, thanks!\r\n\r\n>So, hopefully by mid February we can release 3.8 nightlies.", "@martinwicke @ewilderj do we have our release roadmap published externally?", "Looks like a 3.8 wheel is now available for Linux:\r\n\r\n![image](https://user-images.githubusercontent.com/3727925/75978118-bd962480-5ed5-11ea-9a43-77d0043ffe3f.png)\r\n", "@ErikBjare @gunan I guess this is something like a roadmap? https://github.com/orgs/tensorflow/projects/8#card-32797473", "@harahu Yes, those are the issues that should be solved before TF2.2 gets released.\r\n\r\n@beojan (and others): Yes, nightly now has py3.8 support and TF 2.2 will also have this. However, note that this will be for Windows and Linux for now. MacOS support is supposed to arrive in the upcoming weeks, hopefully before the TF 2.2 final release (it's an upstream issue, not something we can fix at the moment).", "Curious. Tried today pip install tf-nightly on Windows with Python 3.82 x64 and get this message:\r\nERROR: Could not find a version that satisfies the requirement tf-nightly-gpu (from versions: none)\r\nERROR: No matching distribution found for tf-nightly-gpu", "> Curious. Tried today pip install tf-nightly on Windows with Python 3.82 x64 and get this message:\r\n> ERROR: Could not find a version that satisfies the requirement tf-nightly-gpu (from versions: none)\r\n> ERROR: No matching distribution found for tf-nightly-gpu\r\n\r\nNot yet published for Windows:\r\nhttps://pypi.org/project/tf-nightly/2.2.0.dev20200307/#files", "Is anyone working on this issue? I see no progress with the Windows Version. Any possibilities to put priority on it? Like using Patreon or other Donation sites? Else would start fixing it myself in case it stays open for the next few months :)", "@NickDinges It's likely part of the 2.2.0 release.\r\n\r\nCurrent option is to compile it manually: Windows, Python 3.8 and CUDA 10.1 is known to work with the latest r2.2 branch and v2.2.0-rc0 tag.  Unfortunately without TensorRT and XLA support.", "2.2.0 release should have python 3.8", "Correct.\nTf nightlies and 2.2.0 rc0 both have python 3.8 support. Except for macos,\nwhich is due to some issues we are having updating our mac cloud.\n\nOn Sat, Mar 14, 2020, 8:47 AM Mihai Maruseac <notifications@github.com>\nwrote:\n\n> 2.2.0 release should have python 3.8\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-599083532>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AB4UEOKDLQ5IQNHQRR25ZKDRHORJFANCNFSM4JA4OP4Q>\n> .\n>\n", "Yes, just curious while there is still no image.\r\n\r\nhttps://pypi.org/project/tf-nightly/2.2.0.dev20200307/#files", "@NickDinges this seems like a bug on our side", "Hi all, I am on a mac catalina with python 3.8. What should I do? Should I compile from source, wait for the new release or downgrade to python3.7? ", "@NickDinges py38 pips for 2.2.0-rc0 will get uploaded shortly. Also, we have a fix in progress for the nightly pips for windows/py38.\r\n\r\n@lucaturchet If in rush, downgrading to py3.7 will allow you to `pip install`. Otherwise, you can try compiling from source or waiting until 2.2 final release", "@mihaimaruseac  thanks a lot. Could you please provide an estimate of when you foresee to release the support for 3.8? Just to have an idea", "A few weeks. We already have rc0 for 2.2", "@NickDinges Python 3.8 pips uploaded to [`tf-nightly-gpu`](https://pypi.org/project/tf-nightly-gpu/#files) and [`tf-nightly-cpu`](https://pypi.org/project/tf-nightly-cpu/#files) for Windows and Linux. From tomorrow all these will also be uploaded to `tf-nightly`", "Awesome! Thanks :-)", "Just checked, all files are updated except those needed for windows ;-(", "[tf-nightly](https://pypi.org/project/tf-nightly/#files), [tf-nightly-cpu](https://pypi.org/project/tf-nightly-cpu/#files), and [tf-nightly-gpu](https://pypi.org/project/tf-nightly-gpu/#files) all have linux and windows python 3.8 packages.\r\n\r\nProbably you checked before they got uploaded", "Yes. Works now. The windows image was 5 hours later than the other images :-) Didnt expect that :)", "Does it really work? Please help how to install. \r\nMy attempt: **pip install tensorflow** has brown the same as one month ago:\r\n\r\n\"Could not find the version that satisfies the requirement tensorflow...\"", "Yes. you have to use \"pip install tf-nightly-gpu\"", "Yes. Thanks. \r\nI tried to execute the simple CV code:\r\n\r\n```\r\nimport imageai\r\nfrom imageai.Detection import ObjectDetection\r\nimport os\r\n\r\nexecution_path = os.getcwd()\r\ndetector = ObjectDetection()\r\ndetector.setModelTypeAsYOLOv3()\r\ndetector.setModelPath(os.path.join(execution_path, \"yolo.h5\"))\r\ndetector.loadModel()\r\ndetections = detector.detectObjectFromImage(input_image = os.path.join(execution_path,\r\n                                                                \"input.jpg\"), output_image_path =\r\n                                                                os.path.join(execution_path, \"output.jpg\"),\r\n                                                                minimum_percentage_probability = 30)\r\nfor eachObject in detections:\r\n    print(eachObject[\"name\"], \" : \", eachObject[\"percentage_probability\"],\r\n            \" : \", eachObject[\"box_points\"])\r\n    print(\"_\", x10)\r\n```\r\n\r\nAnyway I still have a problem with Tensorflow:\r\n\r\n```\r\nTraceback (most recent call last):\r\ndetector = ObjectDetection()\r\n...\\imageai\\Detection\\__init__.py\", line 88, in __init__\r\n    self.sess = K.get_session()\r\n...\\keras\\backend\\tensorflow_backend.py\", line 378, in get_session\r\n    raise RuntimeError(\r\nRuntimeError: `get_session` is not available when using TensorFlow 2.0.\r\n```\r\n\r\nMay be approach in my code is obsolete.", "Check this: https://stackoverflow.com/questions/58255821/how-to-use-k-get-session-in-tensorflow-2-0-or-how-to-migrate-it", "tf_nightly_gpu-2.2.0.dev20200315 is still expecting cuda 10.1 not 10.2", "@keke8273 I don't think cuda 10.2 will be supported in TF 2.2.\r\n\r\nIf you already have installed the latest nvidia drivers and cuda, consider adding 10.1 cuda as a manual download and adjusting the paths. Latest nvidia drivers work with older cuda versions.\r\n\r\nSee https://twitter.com/ahtik/status/1238079762758807554 for some hints.", "> Except for macos, which is due to some issues we are having updating our mac cloud.\r\n\r\n@gunan  Is there an issue number for this that can be followed? ", "Please don't derail the thread with other issues. CUDA 10.2 is not the focus of TF 2.2 (though you should be able to compile from source).\r\n\r\n@alanjcastonguay it is an internal issue unfortunately, so no public issue number. We will update this thread when all versions will have py38 releases", "> Yes. you have to use \"pip install tf-nightly-gpu\"\r\n\r\nDo i have to update pip or something ? I'm still getting the same error. At this point it might be me trying to use python for the first time...", "Yes you have to update pip.\n\nOn Mon, Mar 16, 2020, 10:04 Iluvalar <notifications@github.com> wrote:\n\n> Yes. you have to use \"pip install tf-nightly-gpu\"\n>\n> Do i have to update pip or something ? I'm still getting the same error.\n> At this point it might be me trying to use python for the first time...\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-599652823>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAEM57J5JTDIYA7ZXQ7PKN3RHZLZ7ANCNFSM4JA4OP4Q>\n> .\n>\n", "I'm currently setting up a new clean Windows 10 OS and am getting this error with the latest default build of Python `3.8.2`. The OS is update to date for all Windows updates.\r\n\r\nBoth options still have an error:\r\n```bash\r\npip install tensorflow\r\npip install tf-nightly-gpu\r\n```\r\nBoth still error:\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\nDoes anyone know of helpful build instructions to work around this issue or is there anything I can provide from my system that might help?", "According to https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-599226072 we only have nightly pips at the moment with python3.8\r\n\r\nCan you try any of those packages? Also, make sure you have `pip` upgraded (`pip install --upgrade pip setuptools`) and that your CPU supports AVX", "@ConradSollitt , \"works for me\". Both for `tensorflow` and `tf-nightly-gpu` pip.\r\n```\r\nC:\\Users\\ak>\\python38\\python.exe -m venv \\arx\\tf2-2.2rc\r\nC:\\Users\\ak>\\arx\\tf2-2.2rc\\Scripts\\activate\r\n\r\n(tf2-2.2rc) C:\\Users\\ak>python -VV\r\nPython 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]\r\n```\r\n\r\n**tf-nightly-gpu**\r\n\r\n```\r\n(tf2-2.2rc) C:\\Users\\ak>pip install --no-cache-dir tf-nightly-gpu\r\nCollecting tf-nightly-gpu\r\n  Downloading tf_nightly_gpu-2.2.0.dev20200319-cp38-cp38-win_amd64.whl (400.0 MB)\r\n```\r\n\r\n**tensorflow**\r\n```\r\n(tf2-2.2rc) C:\\Users\\ak>pip install --no-cache-dir tensorflow\r\nCollecting tensorflow\r\n  Downloading tensorflow-2.2.0rc1-cp38-cp38-win_amd64.whl (459.1 MB)\r\n```\r\n\r\n**tensorflow-gpu**\r\n```\r\n(tf2-2.2rc) C:\\Users\\ak>pip install --no-cache-dir tensorflow-gpu\r\nCollecting tensorflow-gpu\r\n  Downloading tensorflow_gpu-2.2.0rc1-cp38-cp38-win_amd64.whl (460.3 MB)\r\n```\r\n\r\nEDIT: I was a bit quick with the conclusion, `tensorflow-gpu` installation fails after a few minutes with\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow-gpu-estimator<2.3.0,>=2.2.0rc0 (from tensorflow-gpu) (from versions: 2.1.0)\r\nERROR: No matching distribution found for tensorflow-gpu-estimator<2.3.0,>=2.2.0rc0 (from tensorflow-gpu)\r\n```", "Oh, there shouldn't be any `tensorflow-gpu-estimator`. Thanks for catching that. We will have to fix by the final release", "@mihaimaruseac and @ahtik  Thanks for taking time to help, it works now! \ud83d\udc4d \r\n\r\nNormally I would use `python --version` to check version but now realize I need to probably use `python -VV` in most cases. I used the default download link for Windows from the main Python site and ended up installing 32-bit.\r\n\r\nOnce I installed 64-bit build of Python it worked to install. Then after downloading the latest [Visual Studio C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) I was able to run a previous image classification server that I had created.\r\n\r\nSeems like there is opportunity to improve the following error messages in pip and I see that there is at least one issue open at https://github.com/pypa/pip/issues/6526\r\n```\r\nERROR: Could not find a version that satisfies the requirement {package} (from versions: none)\r\nERROR: No matching distribution found for {package}\r\n```\r\n\r\nRegardless that is not a TensorFlow issue though ", "Hi,\r\n\r\nI have downloaded the anaconda and created a virtual env with python 3.8.2 . am not able to install tensorflow 2.1.0 in 3.8.2 env.\r\nis it still the issue in 3.8.2 python for Tensorflow ? or it fixed ?\r\nhow i can install Tf 2.1.0 in python 3.8.2", "TensorFlow 2.1 is **NOT** released on Python 3.8\r\nTensorFlow 2.2 **WILL BE** released on Python 3.8", "@amrithadevadiga \r\nIterating on what was already said, it's still not available, it will be!\r\nAs an advice, always try to catch/read the thread before posting... ", "TF 2.2.0-rc2 has been released and Python 3.8 wheels are available to install. https://pypi.org/project/tensorflow/2.2.0rc2/#files", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">No</a>\n", "@mihaimaruseac \r\nAny hopes for a Mac release?", "> TF 2.2.0-rc2 has been released and Python 3.8 wheels are available to install. https://pypi.org/project/tensorflow/2.2.0rc2/#files\r\n\r\nIs this production ready? I can't say so! Then why closing the issue? Are you guys done? Do you have the specific date of final? Stop wasting our time please, py38 is over a year here. For anyone else: please shut up and stop derailing the issue until it's over.", "Sorry, closed by mistake. Reopening.\r\n\r\nWe publish the RCs for two reasons: so people can test early and identify major regression (since we only do patch releases for security reasons) and so that people who want to be on the bleeding edge and don't want to compile from source can still get access to pips compiled on new infrastructure. RC versions can be specified during `pip install`.\r\n\r\nFurthermore, once RC versions are released, you can be sure that a final version is at most a few weeks ahead, depending on how many regressions are identified in an RC. We are in RC2 and it's likely that the release happening this week will be a final release.\r\n\r\n@j-pb: unfortunately the upstream team has been unresponsive in providing support for building on MacOS. We will probably have to go ahead without a 3.8 release on MacOS now and upload the pips for python 3.8 at a later time when the upstream issues get solved", "@mihaimaruseac Aight! Thanks for the heads up :)", "pip install tensorflow==2.2.0rc2\r\nERROR: Could not find a version that satisfies the requirement tensorflow==2.2.0rc2 (from versions: none)\r\nERROR: No matching distribution found for tensorflow==2.2.0rc2", "@acegilz It's useful to comment with the OS and exact steps taken to get to this error.\r\n`pip install tensorflow==2.2.0rc2` does work fine for both Ubuntu and Windows 10, using 64-bit Python 3.8. Output from `python -VV` can help you pinpoint the issue.", "@acegilz Are you sure you are on python **3.8** and not **3.8.2**?\r\n `pip install tensorflow==2.2.0rc2` works on 3.8 but won't on 3.8.2 I had to add a virtual env with a plain 3.8.0 installation for it to work.", "That is very surprising. The packages for 3.8 should work for all patch\nreleases.\n", "@constantinexisc It should work with both 3.8 and 3.8.2. It's not clear which OS @acegilz is using, but at this point there are no python 3.8 wheels available for MacOS.\r\n\r\nLinux and Windows should work fine, https://pypi.org/project/tensorflow/2.2.0rc2/#files", "Well that's weird. I'm on windows 10 insiders so I won't bother figuring why exactly my 3.8.2 installation didn't work with 2.2.0rc2, working fine on 3.8 now.", "@constantinexisc Most likely the culprit is 64 vs 32 bit python version. Could you check both python binaries by running corresponding `python.exe -VV` and comparing the results? TF 2.2.0rc2 Windows wheels are only available for 64 bit Python.", "I'll be damned you are right! The 3.8.2 is the 32bit version. How did I install a 32bit python.. my eyesight needs some work. Thanks for clearing it up \ud83d\ude05", "RC3 is out and has [py3.8 pips for all 3 operating systems](https://pypi.org/project/tensorflow/2.2.0rc3/#files)", "Can someone with an older macos installed verify our mac images?\r\nWe had to build on macos catalina, therefore, we want to make sure they are ok on older versions before we release final.", "Ubuntu 20.04 will ship with Python 3.8.x (possibly 3.8.2), so this means you can't install tensorflow on it yet.", "@fcole90 that's not completely true. First, you can always use a virtualenv with another python. But also later this week or early next week we'l release tf 2.2 final that would work with Python 3.8", "Yes, of course I meant with the shipped python. I installed myself a 3.7 in a virtualenv as well. BTW, great to hear that you're going to release that version soon \ud83d\ude03", "Confirmed that I could \"import tensorflow\" with MacOS 10.14.6 and Python 3.8.2\r\n\r\n```\r\n(venv) \u279c  src sw_vers\r\nProductName:\tMac OS X\r\nProductVersion:\t10.14.6\r\nBuildVersion:\t18G4032\r\n(venv) \u279c  src pip list | grep tensorflow\r\ntensorflow             2.2.0rc3   \r\ntensorflow-estimator   2.2.0rc0   \r\nWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n(venv) \u279c  src python\r\nPython 3.8.2 (default, Mar 11 2020, 00:28:52) \r\n[Clang 11.0.0 (clang-1100.0.33.17)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n>>> \r\n```\r\n", "@jontignis thanks for verifying. ", "[In rc4](https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc4/tensorflow/tools/pip_package/setup.py#L304), the pip package still declares support for 2.7 (contrary to what docs say), but not 3.8:\r\n```python\r\n # PyPI package information.\r\n    classifiers=[\r\n        ...\r\n        'Programming Language :: Python :: 2',\r\n        'Programming Language :: Python :: 2.7',\r\n        'Programming Language :: Python :: 3',\r\n        'Programming Language :: Python :: 3.4',\r\n        'Programming Language :: Python :: 3.5',\r\n        'Programming Language :: Python :: 3.6',\r\n        'Programming Language :: Python :: 3.7',\r\n        'Topic :: Scientific/Engineering',\r\n        ...\r\n    ],\r\n```\r\n\r\nIs there any hope that final release will support 3.8?\r\n", "@mjmikulski 2.x drop and 3.8 intro was pushed in the beginning of Mar (https://github.com/tensorflow/tensorflow/pull/37384) and should be part of 2.2 release. These classifiers are just for metainfo, you can already today use rc4 Python 3.8 wheels on all the supported platforms (https://pypi.org/project/tensorflow/2.2.0rc4/#files) either with CPU or with CUDA 10.1. CUDA 10.2 requires manual build, is known to work at least with Linux and Windows.\r\n\r\n@mihaimaruseac any ideas why https://github.com/tensorflow/tensorflow/pull/37384 is not merged into the r2.2 branch?", "@ahtik: there was no PR to cherry-pick. On it", "#39188 should fix", "YEAH!!  This was fixed in [TensorFlow 2.2.0](https://github.com/tensorflow/tensorflow/releases) which was released 11 hours ago.", "And now we can finally close this. Apologies for the long time until the final release.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33374\">No</a>\n", "God bless. Please make following releases quicker.", "We prefer to not release it if we find there are issues. Sometimes that makes for a longer wait.", "I still can't install `tensorflow` on **windows 10 (64bit -2004 )** **python 3.8.2** by running \r\n> `pip install tensorflow`\r\n\r\nIt returns this error: \r\n`ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow`\r\n\r\n<br/>\r\n\r\nI also tried using this command: \r\n> `python -m pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-2.2.0-cp38-cp38-win_amd64.whl`\r\n\r\nWhich also didn't work and returned this error: \r\n`ERROR: tensorflow_gpu-2.2.0-cp38-cp38-win_amd64.whl is not a supported wheel on this platform.`\r\n\r\n<br/>\r\n\r\n**What'd I do now**?", "@Prottoy2938 Does `python -VV` confirm you're using python v3.8.2 AMD64/64-bit? It does sound like a 32 vs 64 bit python binary issue.", "`pip --version ` # Linked to Python 3.8 or to legacy Python?  \r\n`pip3 --version ` # Linked to Python 3.8?\r\n\r\n`python3.8 -m pip install tensorflow`\r\n\r\n`py --version `  #\u00a0if Python 3.8 then\r\n`py -m  pip install tensorflow`", "@cclauss Often `python --version` is not useful as it does not show the 32 vs 64 bit build info, which causes problems all the time because of the way python.org Download site at https://www.python.org/downloads/ defaults to the 32-bit Windows installer without even warning about being a 32-bit. `python -VV` shows both the version and 32 vs 64 bit info.", "@ahtik , `python -W` returns \r\n\r\n`Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 22:45:29) [MSC v.1916 32 bit (Intel)]`\r\n\r\nAnd my device's processors: \r\n`intel(r) core(tm) i5-6200u cpu @ 2.30ghz 2.40ghz`", "@Prottoy2938 There you go :) Replace your a 32-bit python with a 64-bit version and it's good to go. Tensorflow does not support 32-bit architecture. `i5-6200u` would be fine.", "I couldn't install it. when I run `python3.8 -m pip install tensorflow` I get this error >> `ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none) ERROR: No matching distribution found for tensorflow`", "@AsmaTidafi `python -W`? Please read messaged above, in case solution is present", "@mihaimaruseac\r\n```\r\nPython 3.8.0 (default, Nov 12 2019, 19:43:25)\r\n[GCC 5.4.0]\r\n```", "Operating system? CPU version and architecture? `pip --version`? `pip3 --version`? I would recommend opening a new issue and filling in issue template, after making sure that the solution presented here does not apply:\r\n\r\n1. check that your CPU supports 64 bit binaries and AVX\r\n1. check that your Python is on 64 bits\r\n1. check that `pip` is updated to the latest version", "@AsmaTidafi Also try `python -VV` or in your case likely `python3.8 -VV`. I used that after help from @mihaimaruseac and other's here and realized I was running a 32-bit Version of Python on 64-Bit Windows when I had last setup a new computer. The default Python download link for Windows users is 32-bit so it's easy to make the mistake during setup; luckily if that's the case it's easy to uninstall and then re-install the 64-bit version.", "1.All the above methods dont work.When i type tensorflow --version,shows no module 'tensorflow'.\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-4-5a6241c68c53> in <module>\r\n----> 1 tensorflow --v\r\n\r\nNameError: name 'tensorflow' is not defined\r\nalthough on pip install tensorflow shows requirement satisfied", "* `python3 --version`\r\n* `python3 -VV`  # Vee-Vee, not W\r\n* `python3 -c \"import tensorflow ; print(tensorflow.__version__)\"`", "Hi Thank you for your reply but actually when i run it shows python-3 is\nnot defined.\nplease look as to how can I download tensorflow i tried everything\n\nOn Wed, Jul 8, 2020 at 12:45 PM Christian Clauss <notifications@github.com>\nwrote:\n\n>\n>    - python3 --version\n>    - python3 -W\n>    - python3 -c \"import tensorflow ; print(tensorflow.*version*)\"\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-655335060>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJ7CHEONS2LDLZMZTOUYFGTR2QMJJANCNFSM4JA4OP4Q>\n> .\n>\n", "Are you on Linux, macOS, or Windows?\r\n\r\nIf Windows, use `py` instead of `python3` in the examples above.\r\n\r\nIf on Linux or macOS, try `which -a python3 ; which -a python`", "Nope same error\npython3 -c \"import tensorflow ; print(tensorflow.*version*)\"\nerror:\n\n File \"<ipython-input-21-910ef3eb6f32>\", line 1    py -c import\ntensorflow          ^SyntaxError: invalid syntax\n\n\nOn Wed, Jul 8, 2020 at 12:54 PM Christian Clauss <notifications@github.com>\nwrote:\n\n> Are you on Linux, macOS, or Windows?\n>\n> If Windows, use py instead of python3 in the examples above.\n>\n> If on Linux or macOS, try which -a python3 ; which -a python\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-655338881>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJ7CHEM6JCIQYKW7WSWZJJLR2QNJVANCNFSM4JA4OP4Q>\n> .\n>\n", "You must have forgotten the quotes on the statement above.\r\nWhat was the result of `py -VV` ?", "@Aanyajain\r\nTry `python3 -c 'import tensorflow as tf; print(tf.__version__)'`\r\n\r\nDid you try and first install tensorflow? Full syntax from CLI: `python3 -m pip install tensorflow`\r\n\r\n@cclauss I think there might be an issue with `*` vs `_` characters is related to markdown formatting. I just used the code formatting to update the command so it can be correctly copied and pasted.\r\n", "Yes sir i tried it it shows error:\n\n File \"<ipython-input-1-e11003545201>\", line 1    python3 -m pip\ninstall tensorflow               ^SyntaxError: invalid syntax\n\n\n\n\nOn Wed, Jul 8, 2020 at 3:07 PM Conrad Sollitt <notifications@github.com>\nwrote:\n\n> @Aanyajain <https://github.com/Aanyajain>\n> Try python3 -c 'import tensorflow as tf; print(tf.__version__)'\n>\n> Did you try and first install tensorflow? Full syntax from CLI: python3\n> -m pip install tensorflow\n>\n> @cclauss <https://github.com/cclauss> I think there might be an issue\n> with * vs _ characters is related to markdown formatting. I just used the\n> code formatting to update the command so it can be correctly copied and\n> pasted.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-655408995>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJ7CHEKYHFZDMBVERRVUVMLR2Q46LANCNFSM4JA4OP4Q>\n> .\n>\n", "@Aanyajain \r\nSounds like you might have an issue with your Python setup; looks like the `python` or `python3` command runs a version of `ipython` on your local machine. Can you try the following and report back?:\r\n\r\n1) Create File: **tf_ver.py**\r\n~~~\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n~~~\r\n\r\n2) Then run:\r\n`python tf_ver.py' or `python3 tf_ver.py'", "Hello sir I have a new problem I cant run any cmd in jupyter notebook as it\nis not getting connected like the symbol on top just breaks when I run any\nCommand.Can you please help.Its not working I dont know what to do I\nsearched everywhere on net nothing yet.If it gets connected then Ill\nprobably try to run what you just sent.\nPlease help Im direly in need of it.\n\nOn Wed, Jul 8, 2020 at 3:41 PM Conrad Sollitt <notifications@github.com>\nwrote:\n\n> @Aanyajain <https://github.com/Aanyajain>\n> Sounds like you might have an issue with your Python setup; looks like the\n> python or python3 command runs a version of ipython on your local\n> machine. Can you try the following and report back?:\n>\n>    1. Create File: *tf_ver.py*\n>\n> import tensorflow as tf\n> print(tf.__version__)\n>\n>\n>    1. Then run:\n>    python tf_ver.py' or python3 tf_ver.py'\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-655425907>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJ7CHEI7PJ6S3QOV2LW7JCLR2RA4FANCNFSM4JA4OP4Q>\n> .\n>\n", "@Aanyajain please open a new issue. In this case, it seems your system is in a bad state, not an issue of TensorFlow. We recommend StackOverflow for questions related to the operating system setup.\r\n\r\nEdit: Locking this conversation as the original issue has been resolved and there are many people subscribed to this. We don't want all of them to be notified for every additional issue. Please open new issues, filling in issue template as that would make debugging much easier."]}, {"number": 33373, "title": "tf.reduce_mean gives incorrect results on CPU", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.7.4\r\n\r\n**Current Behavior**\r\n\r\nThe following script:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n(x_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\r\nx_train = x_train.astype('float32')\r\n\r\ntf_mean = tf.reduce_mean(x_train, axis=[0, 1, 2], keepdims=False)\r\nnp_mean = np.mean(x_train, (0,1,2))\r\nprint('channel means:')\r\nprint('  tf:', tf_mean)\r\nprint('  np:', np_mean)\r\n```\r\n\r\nprints:\r\n\r\n```\r\nchannel means:\r\n  tf: tf.Tensor([83.88608 83.88608 83.88608], shape=(3,), dtype=float32)\r\n  np: [125.3069  122.95015 113.866  ]\r\n```\r\n\r\nNote: the numpy results are the correct channel-wise means for CIFAR10.\r\n\r\n**Expected Behavior**\r\nTensorflow and numpy should give at least vaguely similar results.", "comments": ["I have tried on colab with TF version 2.0  and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/d4946579404e70cca2fbbd56137dfd2d/untitled274.ipynb). Thanks!.", "The results of `tf.reduce_mean` and `np.mean` are similar if we use `axis = None` or `axis = [0,1,2, 3]`. However, results are very different when `axis = [0,1,2]`. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/86b2d6db331554600e5c27c10be97831/33373.ipynb#scrollTo=S7CWFytQJi4d).", "@kazimuth: I believe the problem here is that TensorFlow is doing the computation with 32-bit float values whereas numpy is using 64-bit floating almost all the time. Even if you change `np.mean` to use `dtype=float32`, it still seems to perform the calculation with 64-bit float values. If you want the same behavior I suggest you change `x_train` to use float64 and then cast to float32 in the very end like so:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n(x_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\r\nx_train = x_train.astype('float64')\r\n\r\ntf_mean = tf.cast(tf.reduce_mean(x_train, axis=[0, 1, 2,], keepdims=False), dtype=tf.float32)\r\nnp_mean = np.mean(x_train, (0,1,2), dtype=np.float32)\r\nprint('channel means:')\r\nprint('  tf:', tf_mean)\r\nprint('  np:', np_mean)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33373\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33373\">No</a>\n"]}, {"number": 33372, "title": "fixed formatting error in docstring", "body": "`Input`s should be `Inputs` in the add_loss() docstring https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py", "comments": []}, {"number": 33371, "title": "How to make a custom Model with a stateful LSTM", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): The Decoder part in the official example: https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1080Ti, 12 GB\r\n\r\n**Describe the current behavior**\r\nValueError: If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \r\n- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\r\n- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer.\r\n\r\n**Describe the expected behavior**\r\nI want to make a custom decoder layer with a stateful LSTM and a pre-net which is a simple Dense, but I do not want to use Sequential or functional API, because I want to control with reset_states() when the LSTM states will be reset. It always shows the error above. How should I give the input shape in this custom layer?\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nclass Decoder(Model):\r\n    def __init__(self, dim):\r\n        super(DecoderCell, self).__init__()\r\n        self.input = Sequential([\r\n            Input(batch_shape=(32, 1, num_mels)),\r\n            Dense(128, activation='relu')\r\n        ])\r\n\r\n        self.rnn = LSTM(256, stateful=True)\r\n\r\n    def call(self, x):\r\n        x = self.input(x)\r\n\r\n        x = self.rnn(x)\r\n\r\n        return x\r\n```", "comments": ["@njellinas ,This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "@njellinas Did you ask on Stackoverflow? Did you solve your problem? I have similar problem"]}, {"number": 33370, "title": "Compiling Tensorflow Lite on Arm", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.10.0\r\n- Bazel version (if compiling from source): 0.18.1\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\nI'm using ./tensorflow/contrib/lite/build_imx6_lib.sh to build tensorflow-lite, \r\nmodified a little from build_rpi_lib.sh: CC_PREFIX=arm-poky-linux-gnueabi- make -j 3 -f tensorflow/contrib/lite/Makefile TARGET=RPI TARGET_ARCH=armv7-a\r\n\r\n\r\n**Any other info / logs**\r\nAnd I got following problem:\r\n./tensorflow/contrib/lite/build_iMx6_lib.sh \r\n+ set -e\r\n+++ dirname ./tensorflow/contrib/lite/build_iMx6_lib.sh\r\n++ cd ./tensorflow/contrib/lite\r\n++ pwd\r\n+ SCRIPT_DIR=/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite\r\n+ cd /home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/../../..\r\n+ CC_PREFIX=arm-poky-linux-gnueabi-\r\n+ make -j 3 -f tensorflow/contrib/lite/Makefile TARGET=imx6 TARGET_ARCH=armv7-a\r\ntensorflow/contrib/lite/Makefile:25: \"CROSS :imx6 HOST_ARCH: TARGET_ARCH:armv7-a TARGET_TOOLCHAIN_PREFIX:\"\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/bin/imx6_armv7-a/benchmark_model\r\ng++ -pthread -fPIC -O3 -DNDEBUG --std=c++11 -I. -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/../../../ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/eigen -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/neon_2_sse -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/farmhash/src -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/flatbuffers/include -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/ -I/usr/include -c tensorflow/contrib/lite/kernels/activations.cc -o /home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/activations.o\r\ng++ -pthread -fPIC -O3 -DNDEBUG --std=c++11 -I. -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/../../../ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/eigen -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/neon_2_sse -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/farmhash/src -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/flatbuffers/include -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/ -I/usr/include -c tensorflow/contrib/lite/kernels/add.cc -o /home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/add.o\r\ng++ -pthread -fPIC -O3 -DNDEBUG --std=c++11 -I. -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/../../../ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/ -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/eigen -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/neon_2_sse -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/farmhash/src -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/flatbuffers/include -I/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/ -I/usr/include -c tensorflow/contrib/lite/kernels/arg_min_max.cc -o /home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/arg_min_max.o\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:25:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2247:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:75: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                           ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/bits/stl_algobase.h:64,\r\n                 from /usr/include/c++/4.8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/4.8/ios:40,\r\n                 from /usr/include/c++/4.8/ostream:38,\r\n                 from /usr/include/c++/4.8/iostream:39,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:20:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:25:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:76: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2252:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2263:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2247:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:75: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                           ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:76: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2252:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2263:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:86:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:57: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                         ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/bits/stl_algobase.h:64,\r\n                 from /usr/include/c++/4.8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/4.8/ios:40,\r\n                 from /usr/include/c++/4.8/ostream:38,\r\n                 from /usr/include/c++/4.8/iostream:39,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:20:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:58: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:91:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const RuntimeShape& shape) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:97:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const Dims<N>& dims) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:108:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:70: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/bits/stl_algobase.h:64,\r\n                 from /usr/include/c++/4.8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/4.8/ios:40,\r\n                 from /usr/include/c++/4.8/ostream:38,\r\n                 from /usr/include/c++/4.8/iostream:39,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:20:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:71: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:113:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:122:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:130:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:141:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:154:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Array<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:69: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                     ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/bits/stl_algobase.h:64,\r\n                 from /usr/include/c++/4.8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/4.8/ios:40,\r\n                 from /usr/include/c++/4.8/ostream:38,\r\n                 from /usr/include/c++/4.8/iostream:39,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:20:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:70: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:159:1: error: \u2018ArrayMap\u2019 does not name a type\r\n ArrayMap<Scalar> MapAsArrayWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:172:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithGivenNumberOfRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:17: error: \u2018Eigen\u2019 does not name a type\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                 ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected unqualified-id before \u2018<\u2019 token\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected \u2018)\u2019 before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected initializer before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::FullyConnected(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:932:74: error: \u2018MapAsMatrixWithGivenNumberOfRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithGivenNumberOfRows(input_data, input_dims, input_rows);\r\n                                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:934:63: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(weights_data, weights_dims);\r\n                                                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), input_matrix_map, &output_matrix_map);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:25:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:86:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:57: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                         ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:58: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:91:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const RuntimeShape& shape) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:97:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const Dims<N>& dims) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:108:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:70: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:71: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:113:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:122:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:130:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:141:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:154:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Array<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:69: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                     ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:70: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:159:1: error: \u2018ArrayMap\u2019 does not name a type\r\n ArrayMap<Scalar> MapAsArrayWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:172:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithGivenNumberOfRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:17: error: \u2018Eigen\u2019 does not name a type\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                 ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected unqualified-id before \u2018<\u2019 token\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected \u2018)\u2019 before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected initializer before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::FullyConnected(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:932:74: error: \u2018MapAsMatrixWithGivenNumberOfRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithGivenNumberOfRows(input_data, input_dims, input_rows);\r\n                                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:934:63: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(weights_data, weights_dims);\r\n                                                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), input_matrix_map, &output_matrix_map);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2247:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:75: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                           ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:34:0,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2249:76: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<std::Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2252:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h:2263:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Conv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, int, int, float, float, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1990:70: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(gemm_input_data, *gemm_input_dims);\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1992:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:25:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Conv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, int, int, float, float, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1990:70: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(gemm_input_data, *gemm_input_dims);\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1992:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\nIn file included from tensorflow/contrib/lite/kernels/activations.cc:25:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::ConvAsGemm(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: note: (if you use \u2018-fpermissive\u2019, G++ will accept your code, but allowing the use of an undeclared name is deprecated)\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2232:60: error: there are no arguments to \u2018MapAsMatrixWithLastDimAsCols\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithLastDimAsCols\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2234:61: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(output_data, output_dims);\r\n                                                             ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:86:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:57: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                         ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:88:58: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, 1>>>::type;\r\n                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:91:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const RuntimeShape& shape) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:97:1: error: \u2018VectorMap\u2019 does not name a type\r\n VectorMap<Scalar> MapAsVector(Scalar* data, const Dims<N>& dims) {\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:108:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Matrix<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:70: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:110:71: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Matrix<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:113:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:122:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:130:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:141:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithLastDimAsCols(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:154:5: error: \u2018Eigen\u2019 was not declared in this scope\r\n     Eigen::Map<const Eigen::Array<typename std::remove_const<Scalar>::type,\r\n     ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:69: error: wrong number of template arguments (2, should be 3)\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                     ^\r\nIn file included from /usr/include/c++/4.8/bits/move.h:57:0,\r\n                 from /usr/include/c++/4.8/bits/stl_pair.h:59,\r\n                 from /usr/include/c++/4.8/utility:70,\r\n                 from /usr/include/c++/4.8/algorithm:60,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:21,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/usr/include/c++/4.8/type_traits:77:12: error: provided for \u2018template<bool <anonymous>, class, class> struct std::conditional\u2019\r\n     struct conditional;\r\n            ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:156:70: error: expected identifier before \u2018::\u2019 token\r\n     Eigen::Map<Eigen::Array<Scalar, Eigen::Dynamic, Eigen::Dynamic>>>::type;\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:159:1: error: \u2018ArrayMap\u2019 does not name a type\r\n ArrayMap<Scalar> MapAsArrayWithFirstDimAsRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:172:1: error: \u2018MatrixMap\u2019 does not name a type\r\n MatrixMap<Scalar> MapAsMatrixWithGivenNumberOfRows(Scalar* data,\r\n ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Relu(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2369:57: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   const auto input = MapAsVector(input_data, input_shape);\r\n                                                         ^\r\nIn file included from tensorflow/contrib/lite/kernels/add.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::ConvAsGemm(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: note: (if you use \u2018-fpermissive\u2019, G++ will accept your code, but allowing the use of an undeclared name is deprecated)\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2232:60: error: there are no arguments to \u2018MapAsMatrixWithLastDimAsCols\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithLastDimAsCols\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2234:61: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(output_data, output_dims);\r\n                                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:17: error: \u2018Eigen\u2019 does not name a type\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                 ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected unqualified-id before \u2018<\u2019 token\r\n void Gemm(const Eigen::MatrixBase<Lhs>& lhs, const Eigen::MatrixBase<Rhs>& rhs,\r\n                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected \u2018)\u2019 before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:408:34: error: expected initializer before \u2018<\u2019 token\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::FullyConnected(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:932:74: error: \u2018MapAsMatrixWithGivenNumberOfRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithGivenNumberOfRows(input_data, input_dims, input_rows);\r\n                                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:934:63: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(weights_data, weights_dims);\r\n                                                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), input_matrix_map, &output_matrix_map);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:938:75: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Relu(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2369:57: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   const auto input = MapAsVector(input_data, input_shape);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Add(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2755:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2756:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2757:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Add(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2755:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2756:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2757:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Mul(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3078:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3079:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3080:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Mul(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3078:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3079:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3080:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LstmCell(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:3: error: \u2018ArrayMap\u2019 was not declared in this scope\r\n   ArrayMap<float> activ_temp_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> activ_temp_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3483:24: error: \u2018activ_temp_map\u2019 was not declared in this scope\r\n   auto input_gate_sm = activ_temp_map.block(0 * output_depth, 0, output_depth,\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected primary-expression before \u2018const\u2019\r\n   ArrayMap<const float> prev_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected \u2018;\u2019 before \u2018const\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LstmCell(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:3: error: \u2018ArrayMap\u2019 was not declared in this scope\r\n   ArrayMap<float> activ_temp_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> activ_temp_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3483:24: error: \u2018activ_temp_map\u2019 was not declared in this scope\r\n   auto input_gate_sm = activ_temp_map.block(0 * output_depth, 0, output_depth,\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_activ_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected primary-expression before \u2018const\u2019\r\n   ArrayMap<const float> prev_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected \u2018;\u2019 before \u2018const\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3500:3: error: \u2018output_state_map\u2019 was not declared in this scope\r\n   output_state_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_activ_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:31: error: \u2018Eigen\u2019 has not been declared\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3500:3: error: \u2018output_state_map\u2019 was not declared in this scope\r\n   output_state_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:66: error: expected primary-expression before \u2018float\u2019\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:31: error: \u2018Eigen\u2019 has not been declared\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:66: error: expected primary-expression before \u2018float\u2019\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:32: error: \u2018Eigen\u2019 has not been declared\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:32: error: \u2018Eigen\u2019 has not been declared\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:67: error: expected primary-expression before \u2018float\u2019\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:67: error: expected primary-expression before \u2018float\u2019\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3504:11: error: \u2018prev_state_map\u2019 was not declared in this scope\r\n           prev_state_map;\r\n           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3504:11: error: \u2018prev_state_map\u2019 was not declared in this scope\r\n           prev_state_map;\r\n           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3505:3: error: \u2018output_activ_map\u2019 was not declared in this scope\r\n   output_activ_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3505:3: error: \u2018output_activ_map\u2019 was not declared in this scope\r\n   output_activ_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:32: error: \u2018Eigen\u2019 has not been declared\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:32: error: \u2018Eigen\u2019 has not been declared\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:67: error: expected primary-expression before \u2018float\u2019\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:67: error: expected primary-expression before \u2018float\u2019\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::AveragePool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3805:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::AveragePool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3805:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3809:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3809:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::MaxPool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3980:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::MaxPool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3980:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::L2Pool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4128:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::L2Pool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4128:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:19: error: expected \u2018;\u2019 before \u2018in_square\u2019\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:19: error: expected \u2018;\u2019 before \u2018in_square\u2019\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4132:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4132:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4154:9: error: \u2018in_square\u2019 was not declared in this scope\r\n         in_square =\r\n         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4154:9: error: \u2018in_square\u2019 was not declared in this scope\r\n         in_square =\r\n         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LocalResponseNormalization(const float*, const tflite::Dims<4>&, int, float, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4188:76: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n   const auto data_in = MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LocalResponseNormalization(const float*, const tflite::Dims<4>&, int, float, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4188:76: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n   const auto data_in = MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:19: error: expected \u2018;\u2019 before \u2018padded_square\u2019\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:19: error: expected \u2018;\u2019 before \u2018padded_square\u2019\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4197:3: error: \u2018padded_square\u2019 was not declared in this scope\r\n   padded_square.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4197:3: error: \u2018padded_square\u2019 was not declared in this scope\r\n   padded_square.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Softmax(const float*, const tflite::RuntimeShape&, float, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4231:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Softmax(const float*, const tflite::RuntimeShape&, float, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4231:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected primary-expression before \u2018float\u2019\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected primary-expression before \u2018float\u2019\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4241:32: error: \u2018scale\u2019 was not declared in this scope\r\n   out_mat.array().rowwise() *= scale;\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4241:32: error: \u2018scale\u2019 was not declared in this scope\r\n   out_mat.array().rowwise() *= scale;\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Logistic(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4693:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Logistic(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4693:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:35: error: \u2018Eigen\u2019 has not been declared\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:35: error: \u2018Eigen\u2019 has not been declared\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:70: error: expected primary-expression before \u2018float\u2019\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:70: error: expected primary-expression before \u2018float\u2019\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Tanh(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4899:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Tanh(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4899:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Floor(const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5163:54: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_dims);\r\n                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Floor(const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5163:54: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_dims);\r\n                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5165:24: error: \u2018Eigen\u2019 has not been declared\r\n   output_map.array() = Eigen::floor(input_map.array());\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5165:24: error: \u2018Eigen\u2019 has not been declared\r\n   output_map.array() = Eigen::floor(input_map.array());\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::TransposeConv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6047:61: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(im2col_data, im2col_dims);\r\n                                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::TransposeConv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6047:61: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(im2col_data, im2col_dims);\r\n                                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6049:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6049:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/activations.cc:25:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/add.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Conv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, int, int, float, float, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1990:70: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(gemm_input_data, *gemm_input_dims);\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1992:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:1996:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\nIn file included from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:0:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::ConvAsGemm(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2230:59: note: (if you use \u2018-fpermissive\u2019, G++ will accept your code, but allowing the use of an undeclared name is deprecated)\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2232:60: error: there are no arguments to \u2018MapAsMatrixWithLastDimAsCols\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithLastDimAsCols\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2234:61: error: there are no arguments to \u2018MapAsMatrixWithFirstDimAsRows\u2019 that depend on a template parameter, so a declaration of \u2018MapAsMatrixWithFirstDimAsRows\u2019 must be available [-fpermissive]\r\n       MapAsMatrixWithFirstDimAsRows(output_data, output_dims);\r\n                                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Relu(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2369:57: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   const auto input = MapAsVector(input_data, input_shape);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Add(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2755:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2756:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:2757:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Mul(const int32*, const tflite::Dims<4>&, const int32*, const tflite::Dims<4>&, int32*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3078:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input1_map = MapAsVector(input1_data, input1_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3079:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto input2_map = MapAsVector(input2_data, input2_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3080:57: error: there are no arguments to \u2018MapAsVector\u2019 that depend on a template parameter, so a declaration of \u2018MapAsVector\u2019 must be available [-fpermissive]\r\n   auto output_map = MapAsVector(output_data, output_dims);\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LstmCell(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:3: error: \u2018ArrayMap\u2019 was not declared in this scope\r\n   ArrayMap<float> activ_temp_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> activ_temp_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3481:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3483:24: error: \u2018activ_temp_map\u2019 was not declared in this scope\r\n   auto input_gate_sm = activ_temp_map.block(0 * output_depth, 0, output_depth,\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected primary-expression before \u2018const\u2019\r\n   ArrayMap<const float> prev_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3491:12: error: expected \u2018;\u2019 before \u2018const\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_state_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3493:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected primary-expression before \u2018float\u2019\r\n   ArrayMap<float> output_activ_map =\r\n            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3495:12: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3500:3: error: \u2018output_state_map\u2019 was not declared in this scope\r\n   output_state_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:31: error: \u2018Eigen\u2019 has not been declared\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                               ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3501:66: error: expected primary-expression before \u2018float\u2019\r\n       input_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:32: error: \u2018Eigen\u2019 has not been declared\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3503:67: error: expected primary-expression before \u2018float\u2019\r\n       forget_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3504:11: error: \u2018prev_state_map\u2019 was not declared in this scope\r\n           prev_state_map;\r\n           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3505:3: error: \u2018output_activ_map\u2019 was not declared in this scope\r\n   output_activ_map =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:32: error: \u2018Eigen\u2019 has not been declared\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3506:67: error: expected primary-expression before \u2018float\u2019\r\n       output_gate_sm.unaryExpr(Eigen::internal::scalar_sigmoid_op<float>()) *\r\n                                                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::AveragePool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3805:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3808:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3809:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::MaxPool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:3980:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::L2Pool(const tflite::PoolParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4128:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4130:19: error: expected \u2018;\u2019 before \u2018in_square\u2019\r\n   Eigen::VectorXf in_square(in_mat.rows());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4131:19: error: expected \u2018;\u2019 before \u2018out_count\u2019\r\n   Eigen::VectorXf out_count(out_mat.cols());\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4132:3: error: \u2018out_count\u2019 was not declared in this scope\r\n   out_count.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4154:9: error: \u2018in_square\u2019 was not declared in this scope\r\n         in_square =\r\n         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::LocalResponseNormalization(const float*, const tflite::Dims<4>&, int, float, float, float, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4188:76: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n   const auto data_in = MapAsMatrixWithFirstDimAsRows(input_data, input_dims);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4196:19: error: expected \u2018;\u2019 before \u2018padded_square\u2019\r\n   Eigen::VectorXf padded_square(data_in.rows() + double_range);\r\n                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4197:3: error: \u2018padded_square\u2019 was not declared in this scope\r\n   padded_square.setZero();\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Softmax(const float*, const tflite::RuntimeShape&, float, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4231:75: error: \u2018MapAsMatrixWithLastDimAsRows\u2019 was not declared in this scope\r\n   const auto in_mat = MapAsMatrixWithLastDimAsRows(input_data, input_shape);\r\n                                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:3: error: \u2018Eigen\u2019 has not been declared\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected primary-expression before \u2018float\u2019\r\n   Eigen::Array<float, 1, Eigen::Dynamic> scale =\r\n                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4239:16: error: expected \u2018;\u2019 before \u2018float\u2019\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4241:32: error: \u2018scale\u2019 was not declared in this scope\r\n   out_mat.array().rowwise() *= scale;\r\n                                ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Logistic(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4693:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:35: error: \u2018Eigen\u2019 has not been declared\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                   ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4696:70: error: expected primary-expression before \u2018float\u2019\r\n       input_map.array().unaryExpr(Eigen::internal::scalar_sigmoid_op<float>());\r\n                                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Tanh(const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:4899:55: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_shape);\r\n                                                       ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::Floor(const float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5163:54: error: \u2018MapAsVector\u2019 was not declared in this scope\r\n   auto input_map = MapAsVector(input_data, input_dims);\r\n                                                      ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5165:24: error: \u2018Eigen\u2019 has not been declared\r\n   output_map.array() = Eigen::floor(input_map.array());\r\n                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h: In function \u2018void tflite::optimized_ops::TransposeConv(const float*, const tflite::Dims<4>&, const float*, const tflite::Dims<4>&, int, int, int, int, float*, const tflite::Dims<4>&, float*, const tflite::Dims<4>&)\u2019:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6047:61: error: \u2018MapAsMatrixWithFirstDimAsRows\u2019 was not declared in this scope\r\n       MapAsMatrixWithFirstDimAsRows(im2col_data, im2col_dims);\r\n                                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6049:60: error: \u2018MapAsMatrixWithLastDimAsCols\u2019 was not declared in this scope\r\n       MapAsMatrixWithLastDimAsCols(filter_data, filter_dims);\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: error: \u2018Gemm\u2019 was not declared in this scope\r\n   Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map);\r\n                                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:6053:76: note: suggested alternative:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:31:0,\r\n                 from tensorflow/contrib/lite/kernels/arg_min_max.cc:17:\r\n/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/downloads/gemmlowp/public/gemmlowp.h:74:6: note:   \u2018gemmlowp::Gemm\u2019\r\n void Gemm(GemmContextType* context,\r\n      ^\r\ntensorflow/contrib/lite/Makefile:221: recipe for target '/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/add.o' failed\r\nmake: *** [/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/add.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\ntensorflow/contrib/lite/Makefile:221: recipe for target '/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/activations.o' failed\r\nmake: *** [/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/activations.o] Error 1\r\ntensorflow/contrib/lite/Makefile:221: recipe for target '/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/arg_min_max.o' failed\r\nmake: *** [/home/lyra/tf2arm/tfr1.10/tensorflow/contrib/lite/gen/obj/imx6_armv7-a/tensorflow/contrib/lite/kernels/arg_min_max.o] Error 1\r\n\r\nAnyone has any idea how to deal with it? \r\n\r\n", "comments": ["I download  an Eigen package and replace the old one, the problem has fixed.", "Good to hear the problem is fixed. Let me know if there is any remaining issues.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33370\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33370\">No</a>\n"]}, {"number": 33369, "title": "Dose the data division for multi-gpu destruct the accuracy?", "body": "Data division for multi-gpu after tf1.11 seems to have the same shape of data across all gpus, which will result in a bigger variance of loss between different steps. For example, for the transformer model, when in one step, all the gpus are feeded with the data with length near 8, but in the next step, all the gpus are feeded with the data with length near 32, which will result in a bigger variance of loss.\r\n\r\nIn practice, I got a lower accuracy trained with tf2.0 than tf1.11.\r\n\r\n@guptapriya @yuefengz @zongweiz @sgpyc", "comments": ["Hi,\n\nThank you for your question. Can you elaborate on your example? Why is the\ndata length 8 vs 32 in subsequent steps? Do you mean you have dynamic input\nper step?\n\nWe have been able to train transformer to the state of art accuracy with\n2.0 and 1.15, but we havent tested with 1.11. can you share your setup?\nWhich API are you you using, what are the batch sizes etc?\n\nOn Tue, Oct 15, 2019, 2:32 AM venuswu <notifications@github.com> wrote:\n\n> Data division for multi-gpu after tf1.11 seems to have the same shape of\n> data across all gpus, which will result in a bigger variance of loss\n> between different steps. For example, for the transformer model, when in\n> one step, all the gpus are feeded with the data with length near 8, but in\n> the next step, all the gpus are feeded with the data with length near 32,\n> which will result in a bigger variance of loss.\n>\n> In practice, I got a lower accuracy trained with tf2.0 than tf1.11.\n>\n> @guptapriya <https://github.com/guptapriya> @yuefengz\n> <https://github.com/yuefengz> @zongweiz <https://github.com/zongweiz>\n> @sgpyc <https://github.com/sgpyc>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33369?email_source=notifications&email_token=ADLTSF4IFVKOA3AHVZHYSV3QOVPW3A5CNFSM4JAX3ZAKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HRYXD4A>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADLTSF5JAK4TUE6MUJFV2ADQOVPW3ANCNFSM4JAX3ZAA>\n> .\n>\n", "Yes, I used dynamic batchsize to train the official/transformer.\r\nhttps://github.com/tensorflow/models/blob/master/official/transformer/v2/data_pipeline.py\r\n\r\nHere is the data pipeline of 2.0 same as 1.11, for which batchsize means the number of tokens.  For example in tf1.11, I set the batchsize to 4096 which means 4096 tokens for every replica, for a replica       the length of the tokens seem to be as near as possible(padding fills up the gap), for example a replica can get a batch with the shape of [1024,4], and another get a shape of [ 128,32], in the same step, the shape of the batch may vary between different replica. But there is similar situation between steps.\r\nFor the later version like tf1.14 and tf2.0, the parameter batchsize means total tokens of all the replicas, so for example the batchsize 4096*8 may have a shape of [8192,4] and autoshard across all the replicas, every replica get the same shape of [1024,4], but for the next step, it may read a shape of [1024, 32], and every replica get the same shape of [128,32], which may result in a variance between different steps.\r\n\r\nI have read a paper https://arxiv.org/pdf/1806.00187.pdf\r\n![image](https://user-images.githubusercontent.com/3830256/66908721-27548580-f03e-11e9-85fc-e4ffb4eced36.png)\r\n in which it is said that it my destruct the accuracy with all replica feeded with the same shape of data.\r\n\r\nI don't kown whether I have described the question clearly.\r\n@guptapriya @ravikyram \r\n", "`python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR \\\r\n    --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET \\\r\n    --train_steps=$TRAIN_STEP --steps_between_evals=$TRAIN_STEP \\\r\n    --batch_size=4096 --max_length=256 \\\r\n    --num_gpus=8 \\\r\n    --epochs=275 \\\r\n    --enable_time_history=True \\\r\n    --enable_xla=False \\\r\n    --enable_grappler_layout_optimizer=True\r\n`\r\nHere is the command line. \r\n@guptapriya @ravikyram ", "Is there a option for Backward compatibility? @guptapriya @ravikyram \r\n", "@venuswu Is there a way that you can provide us a minimal reproducible example ? Also can you please explain it clearly as I am unable to understand what you are trying to convey? Whats the root cause of the issue?", "Clsoing this issue as it has been inactive for more than 14 days. Please add additional details and we can open this issue again", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33369\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33369\">No</a>\n"]}, {"number": 33368, "title": "Fix missing activation methods", "body": "My goal was mainly to get rid of exit(1) here which can't actually be in microcontroller firmware... yeah. Anyway, tried to go above and beyond and implemented all the rest of the activation methods defined by the enum. Just used a default that returns the input if a wrong method is passed in (shouldn't happen).", "comments": ["It would be nice to have unit tests for these activation functions too, but since it gets rid of a blocking bug for some platforms we can take this change as-is. Thanks for the contribution!"]}, {"number": 33367, "title": "Upate dockerfiles/README.md for usages of `--gpus all`", "body": "This PR updates dockerfiles/README.md for usages of `--gpus all`,\r\nas Docker version 19.03 changed.\r\n\r\nThis PR fixes #33346\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks.\r\nIf relevant, can you also update the site docs for https://www.tensorflow.org/install/docker ?\r\nThis file is here: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md\r\n", "Thanks @lamberta. I checked the site docs in https://www.tensorflow.org/install/docker . It looks like the usage of `--gpus all` has already been properly covered for docker version 19.03+. ", "Yikes, sorry I'm so late on this. I missed the notification. Looks good to me."]}, {"number": 33366, "title": "Fix delete operator being included", "body": "Not sure how this was missed. Without adding this you can't compile the code into an an application that doesn't implement delete.", "comments": ["This is for tensor flow lite for microcontrollers. Delete/New aren't used.", "@kwagyeman Could you please address Ubuntu Sanity errors? Thanks!", "@gbaned - I have no clue what the Ubuntu Sanity errors are or what is the error. Can you check them?", "@kwagyeman Can you please resolve conflicts? Thanks!", "Please update the PR as necessary and merge. I'm not tracking changes to TensorFlow right now. I was trying to give back my fixes to the main repo but this was sat on for so long that it never got in. For myself... I have the fixes I need.", "This appears to be the same change as https://github.com/tensorflow/tensorflow/pull/33366. Adding comp:micro for future micro changes helps us consolidate duplicates and triage quickly."]}, {"number": 33365, "title": "No float64 support with batch normalization in Tensorflow 2.0?", "body": "Stock Ubuntu 19.04 with Cuda 10.0, Tensorflow 2.0.0 installed via pip3, Python 3.7.3, GTX1060.\r\n\r\nI have a float64 valued dataset with a simple conv2d network that includes tf.keras.layers.BatchNormalization() which is where the error is being thrown I think.\r\n\r\nThe first set of issues:\r\n```\r\nWARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\r\n\r\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\r\n\r\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. \r\n```\r\nAfter setting tf.keras.backend.set_floatx('float64'), next set of errors:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/aj/ga.py\", line 183, in <module>\r\n    encoder = make_encoder_model(z_dim)\r\n  File \"/home/aj/ga.py\", line 138, in make_encoder_model\r\n    x = tf.keras.layers.BatchNormalization()(x)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 842, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 659, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 517, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\r\n    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/cond_v2.py\", line 84, in cond_v2\r\n    op_return_value=pred)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 503, in _fused_batch_norm_training\r\n    data_format=self._data_format)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py\", line 1509, in fused_batch_norm\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 4620, in fused_batch_norm_v3\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 631, in _apply_op_helper\r\n    param_name=input_name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint\r\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\nTypeError: Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\r\n```\r\nSo is there perhaps another (hopefully drop in) method of batch normalization that supports float64? I don't want to go hacking at allowed_list and all that.", "comments": ["@tb438 \r\n\r\nIn order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "@tb438 \r\n\r\nPlease, let us know any update on this issue. Thanks!", "Yes give me another day and I'll upload sanitized code.", "Hi. I have a similar problem.\r\nI used this keras code https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py.\r\nAnd it works fine with TF2.\r\nBut if I set  K.set_floatx('float64')\r\nIt writed \"Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\"\r\n\r\nAre there working examples, where batch normalization works with float64 in TF 2?", "Hi Ravikyram,\r\n\r\nHere is the code and exception:\r\n\r\nPython 3.7.5rc1 (default, Oct  8 2019, 16:47:45) \r\n[GCC 9.2.1 20191008] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import numpy as np\r\n>>> import tensorflow as tf\r\n>>> print(tf.__version__)\r\n2.0.0\r\n>>> tf.keras.backend.set_floatx('float64')\r\n>>> inputs = tf.keras.layers.Input(shape=(28, 28, 1))\r\n>>> x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(inputs)\r\n[...]\r\n>>> x = tf.keras.layers.LeakyReLU(0.2)(x)\r\n>>> x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\r\n>>> x = tf.keras.layers.BatchNormalization()(x)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 842, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 659, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 517, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\r\n    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/cond_v2.py\", line 84, in cond_v2\r\n    op_return_value=pred)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 503, in _fused_batch_norm_training\r\n    data_format=self._data_format)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py\", line 1509, in fused_batch_norm\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 4620, in fused_batch_norm_v3\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 631, in _apply_op_helper\r\n    param_name=input_name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint\r\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\nTypeError: Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\r\n\r\n", "I have tried on colab with TF version 2.0 , 2.1.0-dev20191029 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/e6adf13651041e582a832373063de997/untitled319.ipynb).Thanks!", "Hi Ravikyram,\r\n\r\nThank you for the prompt response. Using your gist above on Colab, I am still getting the same error?\r\n\r\n2.0.0:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-12-fffaff38b358> in <module>()\r\n      5 x = tf.keras.layers.LeakyReLU(0.2)(x)\r\n      6 x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\r\n----> 7 x = tf.keras.layers.BatchNormalization()(x)\r\n\r\n13 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)\r\n     58           \"allowed values: %s\" %\r\n     59           (param_name, dtypes.as_dtype(dtype).name,\r\n---> 60            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\n     61 \r\n     62 \r\n\r\nTypeError: Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\r\n```\r\nAnd with 2.1.0:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-fffaff38b358> in <module>()\r\n      5 x = tf.keras.layers.LeakyReLU(0.2)(x)\r\n      6 x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\r\n----> 7 x = tf.keras.layers.BatchNormalization()(x)\r\n\r\n13 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)\r\n     59           \"allowed values: %s\" %\r\n     60           (param_name, dtypes.as_dtype(dtype).name,\r\n---> 61            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\n     62 \r\n     63 \r\n\r\nTypeError: Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\r\n```\r\n", "I've updated my development workstation to 2.1.0 as well, same issue:\r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> import numpy as np\r\n>>> tf.version\r\n'2.1.0-dev20191029'\r\n>>> tf.keras.backend.set_floatx('float64')\r\n>>> inputs = tf.keras.layers.Input(shape=(28, 28, 1))\r\n>>> x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(inputs)\r\n>>> x = tf.keras.layers.LeakyReLU(0.2)(x)\r\n>>> x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\r\n>>> x = tf.keras.layers.BatchNormalization()(x)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 773, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 695, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 553, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\r\n    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/cond_v2.py\", line 83, in cond_v2\r\n    op_return_value=pred)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 958, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/normalization.py\", line 539, in _fused_batch_norm_training\r\n    data_format=self._data_format)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py\", line 1502, in fused_batch_norm\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 4248, in fused_batch_norm_v3\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 576, in _apply_op_helper\r\n    param_name=input_name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 61, in _SatisfiesTypeConstraint\r\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\nTypeError: Value passed to parameter 'x' has DataType float64 not in list of allowed values: float16, bfloat16, float32\r\n```\r\nCan you try running the same code with GPU-enabled Colab? Perhaps this would only fixed for the CPU branch and not tensorflow-gpu 2.1.0?\r\n\r\nThanks again for your help.", "ARE YOU GOOGLE MOTHERFUCKERS GOING TO FIX THIS FLOAT64 ISSUE OR NOT. WHY IS FLOAT64 A SECOND CLASS CITIZEN WHEN IT COMES TO TENSORFLOW 2.0?\r\n\r\nLEMME TELL YOU WHAT, THAT LITTLE FLOAT32-SOMETHING-OR-THE-OTHER AINT COMPARE WITH US IN OUR FLOAT64 VALUED DATASETS, AND THE GOOGLE IS STRAIGHT UP DISCRIMINATING() WITHOUT FLOAT64 AT THIS POINT", "LOOK, AGAIN, YOUR REDUCED PRECISION INT8 AND INT16 AINT MEAN NOTHING TO US, DO YOU UNDERSTAND GOOGLE? YOUR GOOGLE TPU CAIN'T TRAIN, SO IMA GO WITH CUDA128 JUST AS SOON AS YOU BRING MY FLOAT64 BATCH NORMALIZATION BABY BACK", "Hello,\r\nIs there a solution for this?\r\ni am getting it when i call the model.predict on boolean data.\r\nit also causes a segmentation fault.\r\n\r\ni am using tf2`s keras", "Hi all, supporting float64 would be really cool indeed :)\r\n\r\n@TrailBlazerAI maybe consider a change of tone when asking for other people to help you?", "> Hello,\r\n> Is there a solution for this?\r\n> i am getting it when i call the model.predict on boolean data.\r\n> it also causes a segmentation fault.\r\n> \r\n> i am using tf2`s keras\r\n\r\nI changed the data to np.float32 and it worked well with tf2, maybe it may help someone still having this issue.\r\n\r\nThanks", "Hello,\r\nCan anyone provide info on the matter?\r\nIs it gonna be fixed? If no, why?\u00a0Is there a timeline? Are there any blockers?\r\nMany thanks,\r\n- Julien", "Are there any updates to this? I'm facing the same problem and I'm having to set BatchNorm's dtype to float32 for now but it'd be nice to be able to use float64", "This appears to be an issue with fused batch norm in particular, and if you disable the fused kernel, the code above does not raise an error:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nprint(tf.version)\r\ntf.keras.backend.set_floatx('float64')\r\ninputs = tf.keras.layers.Input(shape=(28, 28, 1))\r\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(inputs)\r\nx = tf.keras.layers.LeakyReLU(0.2)(x)\r\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\r\nx = tf.keras.layers.BatchNormalization(fused=False)(x)\r\n```\r\n\r\n@reedwm / @qlzh727 -- this is an unfortunate hard edge for BatchNorm. Can we either add fp64 support to the fused kernel or not default to fusing for unsupported datatypes? ", "I'll start by not defaulting to fused for unsupported datatypes. We can add fp64 support to the fused kernel later.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33365\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33365\">No</a>\n"]}, {"number": 33364, "title": "fix typo", "body": "", "comments": []}, {"number": 33363, "title": "An unbelievable error in TensorFlow2.0 tutorials/load_data/images !!!!!!!!!!!!!!!", "body": "when i run the [tutorial](https://tensorflow.google.cn/tutorials/load_data/images?hl=en) in tensorflow2.0 , it run error in \r\n``` python\r\nfor image, label in labeled_ds.take(1):\r\n    print(\"Image shape: \", image.numpy().shape)\r\n    print(\"Label: \", label.numpy())\r\n```\r\nthe information is:\r\n```python\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-28-8c161867f891> in <module>\r\n----> 1 for image, label in labeled_ds.take(1):\r\n      2     print(\"Image shape: \", image.numpy().shape)\r\n      3     print(\"Label: \", label.numpy())\r\n\r\nc:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in __next__(self)\r\n    620 \r\n    621   def __next__(self):  # For Python 3 compatibility\r\n--> 622     return self.next()\r\n    623 \r\n    624   def _next_internal(self):\r\n\r\nc:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in next(self)\r\n    664     \"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\r\n    665     try:\r\n--> 666       return self._next_internal()\r\n    667     except errors.OutOfRangeError:\r\n    668       raise StopIteration\r\n\r\nc:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in _next_internal(self)\r\n    649             self._iterator_resource,\r\n    650             output_types=self._flat_output_types,\r\n--> 651             output_shapes=self._flat_output_shapes)\r\n    652 \r\n    653       try:\r\n\r\nc:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)\r\n   2671       else:\r\n   2672         message = e.message\r\n-> 2673       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   2674   # Add nodes to the TensorFlow graph.\r\n   2675   if not isinstance(output_types, (list, tuple)):\r\n\r\nc:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: {{function_node __inference_Dataset_map_process_path_205}} slice index -1 of dimension 0 out of bounds.\r\n\t [[{{node strided_slice}}]] [Op:IteratorGetNextSync]\r\n```\r\n\r\nAnd i don`t know why?\r\nI try download form the [github web](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb)\r\n\r\nIt also run error on the same place, i don't know why and i don't know how to fix it.\r\n\r\nI want to Submit the issue on the doce, but it can't submit issue, so i come here.\r\n\r\nDoes the function changed?\r\n\r\nAnybody can help me, i am so sad (>_<)...........", "comments": ["> when i run the [tutorial](https://tensorflow.google.cn/tutorials/load_data/images?hl=en) in tensorflow2.0 , it run error in\r\n> \r\n> ```python\r\n> for image, label in labeled_ds.take(1):\r\n>     print(\"Image shape: \", image.numpy().shape)\r\n>     print(\"Label: \", label.numpy())\r\n> ```\r\n> \r\n> the information is:\r\n> \r\n> ```python\r\n> ---------------------------------------------------------------------------\r\n> InvalidArgumentError                      Traceback (most recent call last)\r\n> <ipython-input-28-8c161867f891> in <module>\r\n> ----> 1 for image, label in labeled_ds.take(1):\r\n>       2     print(\"Image shape: \", image.numpy().shape)\r\n>       3     print(\"Label: \", label.numpy())\r\n> \r\n> c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in __next__(self)\r\n>     620 \r\n>     621   def __next__(self):  # For Python 3 compatibility\r\n> --> 622     return self.next()\r\n>     623 \r\n>     624   def _next_internal(self):\r\n> \r\n> c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in next(self)\r\n>     664     \"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\r\n>     665     try:\r\n> --> 666       return self._next_internal()\r\n>     667     except errors.OutOfRangeError:\r\n>     668       raise StopIteration\r\n> \r\n> c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in _next_internal(self)\r\n>     649             self._iterator_resource,\r\n>     650             output_types=self._flat_output_types,\r\n> --> 651             output_shapes=self._flat_output_shapes)\r\n>     652 \r\n>     653       try:\r\n> \r\n> c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)\r\n>    2671       else:\r\n>    2672         message = e.message\r\n> -> 2673       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n>    2674   # Add nodes to the TensorFlow graph.\r\n>    2675   if not isinstance(output_types, (list, tuple)):\r\n> \r\n> c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n> \r\n> InvalidArgumentError: {{function_node __inference_Dataset_map_process_path_205}} slice index -1 of dimension 0 out of bounds.\r\n> \t [[{{node strided_slice}}]] [Op:IteratorGetNextSync]\r\n> ```\r\n> \r\n> And i don`t know why?\r\n> I try download form the [github web](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb)\r\n> \r\n> It also run error on the same place, i don't know why and i don't know how to fix it.\r\n> \r\n> I want to Submit the issue on the doce, but it can't submit issue, so i come here.\r\n> \r\n> Does the function changed?\r\n> \r\n> Anybody can help me, i am so sad (>_<)...........\r\n\r\nok  after many times to try , i finall fix it.\r\n\r\ni run it on windos,and shoud use '//' to cut path, but the  tutorial  is use \u2018/\u2019 on linux!!!!!!!\r\n\r\njust change this:\r\n```python\r\ndef get_label(file_path):\r\n    # convert the path to a list of path components\r\n    parts = tf.strings.split(file_path, '\\\\')  # on windos!!\r\n    # The second to last is the class-directory\r\n    return parts[-2] == CLASS_NAMES\r\n```\r\n\r\nok ok  i really do it!!!!  I am so happy!!!!"]}, {"number": 33362, "title": "[tflite] update label_image for GPU Delegate V2", "body": "Update label_image to be GPU Delegate V2 compatible.", "comments": ["similar patch is done in de16a4f1d24d272d9282dbc1038a710cd30b35e9"]}, {"number": 33361, "title": "INFO level logs not coming in MirroredStrategy()", "body": "Hi. I am on TensorFlow 2.0 and on my local Jupyter Notebook environment. I am following [this example](https://www.tensorflow.org/tutorials/distribute/keras). When I am running the accompanying notebook Colab, the INFO level logs are getting displayed. But when I am running local, the logs are not there (although locally I am running a slightly different code) and here it is:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\n# Call the distribution scope context manager\r\nwith strategy.scope():\r\n    # Define a model to fit the above data\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Dropout(rate=0.2, input_shape=X.shape[1:]),\r\n        tf.keras.layers.Dense(units=64, activation='relu'),\r\n        tf.keras.layers.Dropout(rate=0.2),\r\n        tf.keras.layers.Dense(units=1, activation='sigmoid')\r\n    ])\r\n    \r\n    # Compile the model\r\n    model.compile(loss='binary_crossentropy',\r\n                optimizer='adam',\r\n                metrics=['accuracy'])\r\n```\r\n\r\nAny hints as to why the logs are not coming? ", "comments": ["@sayakpaul \r\n\r\nThanks for reporting the issue.Please, fill [issue template ](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n Can you please provide complete code snippet to reproduce the issue in our environment.So i can check the same in Jupyter notebook and Colab for localizing the issue faster.Thanks!", "I have already provided the complete code snippet @ravikyram ", "@sayakpaul \r\nI tried reproducing the issue in colab and Jupyter notebook.However i am getting the below error message `NameError: name 'X' is not defined`.Thanks!", "What code are you using? You should be using the following:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\n# Call the distribution scope context manager\r\nwith strategy.scope():\r\n    # Define a model to fit the above data\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Dropout(rate=0.2, input_shape=X.shape[1:]),\r\n        tf.keras.layers.Dense(units=64, activation='relu'),\r\n        tf.keras.layers.Dropout(rate=0.2),\r\n        tf.keras.layers.Dense(units=1, activation='sigmoid')\r\n    ])\r\n    \r\n    # Compile the model\r\n    model.compile(loss='binary_crossentropy',\r\n                optimizer='adam',\r\n                metrics=['accuracy'])\r\n```", "@sayakpaul \r\nPlease, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c85e97df70f575c135350ae3029a7db2/untitled287.ipynb). Please, help me in reproducing the issue.Thanks!", "Here you go:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\n# Call the distribution scope context manager\r\nwith strategy.scope():\r\n    # Define a model to fit the above data\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Dropout(rate=0.2, input_shape=(7,)),\r\n        tf.keras.layers.Dense(units=64, activation='relu'),\r\n        tf.keras.layers.Dropout(rate=0.2),\r\n        tf.keras.layers.Dense(units=1, activation='sigmoid')\r\n    ])\r\n    \r\n    # Compile the model\r\n    model.compile(loss='binary_crossentropy',\r\n                optimizer='adam',\r\n                metrics=['accuracy'])\r\n```", "@ravikyram any updates? ", "Apologies for the delay in response. Is this still an issue?\r\nI tried TF 2.0 and TF-Nightly versions in python interpreter (terminal), I can see the log info printed.\r\nCan you please confirm by trying in python interpreter? Thanks!"]}, {"number": 33360, "title": "TensorFlow source cannot be compiled with -c dbg", "body": "When compiling the TensorFlow sources (at 776b99925c1fe0d045b363f7437c21a5a9ce2357) with:\r\nbazel build -c dbg -j 24 --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nit produces many errors like:\r\n```\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:2296:30: error: selector must be an integer constant in the range 0..7\r\n     #define _MM_INSERT_EPI16 _mm_insert_epi16\r\n                              ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9369:40: note: in expansion of macro '_MM_INSERT_EPI16'\r\n #define vld1q_lane_s16(ptr, vec, lane) _MM_INSERT_EPI16(vec, *(ptr), lane)\r\n                                        ^~~~~~~~~~~~~~~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:12090:12: note: in expansion of macro 'vld1q_lane_s16'\r\n     return vld1q_lane_s16(&val, vec,  lane);\r\n```\r\nThis started when the TF build moved to C++14 compilation. It works fine with C++11.\r\nI distilled it down to the following piece of code:\r\n```\r\ntypedef short __v8hi __attribute__ ((__vector_size__ (16)));\r\nextern inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))\r\n__v8hi vsetq_lane_s16(__v8hi x,const int l)\r\n{ return __builtin_ia32_vec_set_v8hi(x,0,(l)); }\r\nvoid ff(__v8hi x) { vsetq_lane_s16(x,0);}```\r\n\r\nWhen compiling this with\r\ng++ -std=c++11 x.cc -c\r\nit compiles just fine. When compiling with\r\ng++ -std=c++14 x.cc -c\r\nit produces:\r\nx.cc: In function \u2018void ff(__v8hi)\u2019:\r\nx.cc:6:47: error: selector must be an integer constant in the range 0..7\r\n     return __builtin_ia32_vec_set_v8hi(x,0,(l));\r\n```\r\n\r\nsome details:\r\n- removing the \"const\" from the formal argument makes C++11 fail as well\r\n- removing the () around \"l\" makes c++14 pass\r\n- int(l) in stead of (l) make c++14 pass, but (int)(l) still fails\r\n\r\nTried gcc 7.4.0 with glibc 2.27 on ubuntu 18.04\r\nand gcc 5.4.0 with glibc 2.23 on ubuntu 16.04", "comments": ["@bas-aarts ,\r\nPlease provide more information on the issue like sequence of commands / steps that you executed before running into the problem?", "I just tried to build TensorFlow in debug mode:\r\nbazel build -j 24 --config=opt -c dbg //tensorflow/tools/pip_package:build_pip_package", "Can you please provide a complete log of `./configure` and the bazel build command you're running, starting from a fresh environment targeting the `master` branch?", "build:\r\nbazel build -j 24 --config=opt -c dbg //tensorflow/tools/pip_package:build_pip_package\r\n\r\nconfg:\r\nroot@1204a5c05f6b:/home/baarts/tensorflow# cat .tf_configure.bazelrc\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.6/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --config=xla\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"7.0\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib/tensorflow\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-gpu\r\ntest --build_tag_filters=-gpu\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"", "Note, this isn't fixed and the original author responded. So the status isn't right.", "I just saw that this file is compile `external/arm_neon_2_x86_sse/NEON_2_SSE.h`, but why the arm code is included? It probably shouldn't be included at first.  From the full error message, it seems it comes from tflite:\r\n\r\n```\r\nERROR: /tensorflow/tensorflow/lite/kernels/BUILD:425:1: C++ compilation of rule '//tensorflow/lite/kernels:builtin_op_kernels' failed (Exit 1)\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/5/include/x86intrin.h:41:0,\r\n                 from /usr/include/x86_64-linux-gnu/c++/5/bits/opt_random.h:33,\r\n                 from /usr/include/c++/5/random:50,\r\n                 from /usr/include/c++/5/bits/stl_algo.h:66,\r\n                 from /usr/include/c++/5/algorithm:62,\r\n                 from external/gemmlowp/public/../internal/../internal/common.h:24,\r\n                 from external/gemmlowp/public/../internal/../internal/kernel_default.h:22,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:20,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/integer_ops/depthwise_conv.h:19,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:16:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'void tflite::optimized_integer_ops::depthwise_conv::DepthwiseConvInitAccBuffer(int, int, const int32*, int32*)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:2297:34: error: selector must be an integer constant in the range 0..3\r\n         #define _MM_INSERT_EPI32 _mm_insert_epi32\r\n                                  ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9366:40: note: in expansion of macro '_MM_INSERT_EPI32'\r\n #define vld1q_lane_s32(ptr, vec, lane) _MM_INSERT_EPI32(vec, *(ptr), lane)\r\n                                        ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:12092:12: note: in expansion of macro 'vld1q_lane_s32'\r\n     return vld1q_lane_s32(&val, vec,  lane);\r\n            ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:2297:34: error: selector must be an integer constant in the range 0..3\r\n         #define _MM_INSERT_EPI32 _mm_insert_epi32\r\n                                  ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9366:40: note: in expansion of macro '_MM_INSERT_EPI32'\r\n #define vld1q_lane_s32(ptr, vec, lane) _MM_INSERT_EPI32(vec, *(ptr), lane)\r\n                                        ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:12092:12: note: in expansion of macro 'vld1q_lane_s32'\r\n     return vld1q_lane_s32(&val, vec,  lane);\r\n            ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'void tflite::optimized_ops::depthwise_conv::DepthwiseConvInitAccBuffer(int, int, const int32*, int32*)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:2297:34: error: selector must be an integer constant in the range 0..3\r\n         #define _MM_INSERT_EPI32 _mm_insert_epi32\r\n                                  ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9366:40: note: in expansion of macro '_MM_INSERT_EPI32'\r\n #define vld1q_lane_s32(ptr, vec, lane) _MM_INSERT_EPI32(vec, *(ptr), lane)\r\n                                        ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:12092:12: note: in expansion of macro 'vld1q_lane_s32'\r\n     return vld1q_lane_s32(&val, vec,  lane);\r\n            ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:2297:34: error: selector must be an integer constant in the range 0..3\r\n         #define _MM_INSERT_EPI32 _mm_insert_epi32\r\n                                  ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9366:40: note: in expansion of macro '_MM_INSERT_EPI32'\r\n #define vld1q_lane_s32(ptr, vec, lane) _MM_INSERT_EPI32(vec, *(ptr), lane)\r\n                                        ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:12092:12: note: in expansion of macro 'vld1q_lane_s32'\r\n     return vld1q_lane_s32(&val, vec,  lane);\r\n            ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "I've implemented a workaround for this in the dbg config. Compiling with\r\n  --config=dbg\r\nin stead of\r\n   --config=opt -c dbg\r\ncircumvents this issue by disabling x86 neon\r\n\r\nclosing this issue (no response for over 6 months)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33360\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33360\">No</a>\n", "I got the same error on tf2.4 \r\nIt seems the bug is still there."]}, {"number": 33359, "title": "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.6\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: 9.0/7\r\n- GPU model and memory: GeForce GTX TITAN and Tesla K40c\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nwhen \"import tensorflow\", will show \"ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\" \r\n\r\nBut /usr/local/cuda-9.0 is installed, and CUDA_HOME points to this path. \r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n\r\n>>> \"libcublas.so.9.0\" in os.listdir(\"/usr/local/cuda-9.0/lib64\")\r\nTrue\r\n>>> os.environ[\"CUDA_HOME\"]\r\n'/usr/local/cuda-9.0'\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/project/activelearning/shalijiang/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n", "comments": ["@shalijiang \r\n\r\nCan you go through the below [link1 ](https://stackoverflow.com/questions/48428415/importerror-libcublas-so-9-0-cannot-open-shared-object-file) , #20569 and see [software requirements](https://www.tensorflow.org/install/gpu) and see if it helps you.Thanks!", "@shalijiang \r\n\r\nAny updates on the issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33359\">No</a>\n"]}, {"number": 33358, "title": "Cannot train canned estimators in multiple estimator.train() calls when using tf.keras.optimizers or tf.optimizers", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- Platform: Code run in google Colab\r\n- Python version: Python 3\r\n- Tensorflow version: v2.0.0-rc1-51-g2646d23 2.0.0-rc2\r\n\r\n**Describe the current behavior**\r\nWhen training a canned estimator with multiple tf.train calls while using any tf.keras.optimizer the optimizer raises an exception. \r\n\r\n**Describe the expected behavior**\r\nRepeated tf.train calls train for the given amount of steps.\r\n\r\n**Code to reproduce the issue**\r\nLightly edited example using canned estimators:\r\nhttps://gist.github.com/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9\r\n\r\n**Other info / logs**\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-17-75a55ecc34ba> in <module>()\r\n      5 classifier.train(\r\n      6     input_fn=lambda: input_fn(train, train_y, training=True),\r\n----> 7     steps=500)\r\n\r\n7 frames\r\n/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in iterations(self, variable)\r\n    660   def iterations(self, variable):\r\n    661     if self._iterations is not None:\r\n--> 662       raise RuntimeError(\"Cannot set `iterations` to a new Variable after \"\r\n    663                          \"the Optimizer weights have been created\")\r\n    664     self._iterations = variable\r\n\r\nRuntimeError: Cannot set `iterations` to a new Variable after the Optimizer weights have been created\r\n", "comments": ["@JoshEZiegler ,\r\nHi, i tried running the given gist for TF-2.0 and 2.0rc1 i did not face any error. Can you provide gist of colab where you are facing the issue ? Thanks!", "I'm not sure what you mean by a gist of colab. The gist I provided was saved from colab and shows to me a link to open the ipynb in colab. It may have been still processing something when you saw it? I'm a bit unfamiliar with particulars of colab/gists so I could certainly be making a mistake.\r\n\r\nAfter checking the traceback, it appears that the issue I had occurred with 2.0rc2 so this could be specific to that version (maybe that's what you're saying here). In that case maybe this is solved in the most recent release?", "I tried versions 2.0.0-rc1 and 2.0.0 with this same ipynb in colab but they both gave me the same error. \r\n\r\nChanging to tf.optimizers rather than keras does not change it either.", "@JoshEZiegler ,\r\nI tried with versions [2.0](https://colab.sandbox.google.com/gist/oanush/0f34ce19865eba4c3da1b4447e333f33/2-0.ipynb), [2.0rc1](https://colab.sandbox.google.com/gist/oanush/7820ba5760b80c49c4b425c1125e7faf/2-0rc1.ipynb),[2.0rc2 ](https://colab.sandbox.google.com/gist/oanush/a7d5efe15ba9653866dbf7350a5f4bee/2-0rc2.ipynb)and didn't face any error. Please find gist of colab for respective versions.", "Here is a link directly to the code in colab with TF 2.0.0:\r\nhttps://colab.research.google.com/gist/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9/premade.ipynb\r\n\r\nTF 2.0.0-rc2:\r\nhttps://colab.research.google.com/gist/JoshEZiegler/6191d345f7dbd5f8e1152ac64fc890cb/premade.ipynb\r\n\r\nTF 2.0.0-rc1:\r\nhttps://colab.research.google.com/gist/JoshEZiegler/9f73f47ed7d52a6a88ccf7355e5856b8/premade.ipynb\r\n", "I tried running the linked code and I confirm I also see an error: \r\n\r\n> RuntimeError: Cannot set `iterations` to a new Variable after the Optimizer weights have been created", "With some investigation, it looks like running estimator.train() multiple times is ok with the default optimizer, or by specifying the optimizer with a string. I believe that this is because the estimator.train() actually creates a new instance of the string-specified optimizer with each call, but retains the optimizer object if one was specified in the train call (see below).\r\n\r\nA possible workaround for the above error could be to modify this function to return a fresh optimizer with the same parameters as the opt instance specified. However, I'm not sure if this is easily achievable or if there are any use cases that this would break...\r\n\r\nFrom /tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/canned/optimizers.py\r\n```\r\ndef get_optimizer_instance(opt, learning_rate=None):\r\n\r\nif isinstance(opt, six.string_types):\r\n\r\n    if opt in six.iterkeys(_OPTIMIZER_CLS_NAMES):\r\n      if not learning_rate:\r\n        raise ValueError('learning_rate must be specified when opt is string.')\r\n      return _OPTIMIZER_CLS_NAMES[opt](learning_rate=learning_rate)\r\n    raise ValueError(\r\n        'Unsupported optimizer name: {}. Supported names are: {}'.format(\r\n            opt, tuple(sorted(six.iterkeys(_OPTIMIZER_CLS_NAMES)))))\r\n  if callable(opt):\r\n    opt = opt()\r\n  if not isinstance(opt, optimizer_lib.Optimizer):\r\n    raise ValueError(\r\n        'The given object is not an Optimizer instance. Given: {}'.format(opt))\r\n  return opt\r\n```", "@JoshEZiegler I'm not sure if this is applicable here, but I got the same error in different context and solution for me was to pass a callable instead of the instance as `optimizer` parameter allows that ([docs)](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier#args). In your case you can pass `optimizer=tf.keras.optimizers.Ftrl`, I think.", "@awolant I believe that workaround ends up being equivalent to what I mentioned just above your comment: passing a string to specify the optimizer. The key use case excluded by these workarounds is manual tuning of the hyperparams of the optimizer. It's unclear to me if there's a way to do that without passing an instance of ```optimizer```...", "@JoshEZiegler Right. My use case was a bit different and I missed that. But since we can pass any callable, then maybe something like this will work for you:\r\n```python\r\nfrom functools import partial\r\nAdamWithParams = partial(Adam, learning_rate = 0.1)\r\n\r\n...\r\n\r\noptimizer = AdamWithParams\r\n```\r\n\r\nMore on what `partial` is you can find in  [the docs](https://docs.python.org/2/library/functools.html#functools.partial). In my code it worked as expected.", "@awolant Nice! Thanks, that sounds like the perfect workaround. \r\n\r\nI'll leave this issue open because I don't believe that is the intended way to use `optimizers` with `Estimators`. At the very least not the way it is done in the TF docs.", "Can you try with the latest tf-nightly? This should be already fixed. ", "@yhliang2018 This issue still shows up with tf-nightly-2.2.0.dev20200306. See [this](https://colab.research.google.com/gist/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9/premade.ipynb) colab notebook.\r\n\r\nWas there a specific version where you believe it should work?", "Have you resolved it in TF-v2", "I have got the same issue here too", "[Experienced the same issue](https://colab.research.google.com/gist/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9/premade.ipynb) in the latest `tf-nightly`, and reopening.\r\n\r\n```python\r\nRuntimeError: Cannot set `iterations` to a new Variable after the Optimizer weights have been created\r\n```", "@mustafa-qamaruddin @JoshEZiegler Could you provide your use case of calling `estimator.train()` multiple times in a training pipeline?  If the model needs to train with more steps, you can increase the `steps` arg in the `train()` method. I feel it's arguable to call `train()` method multiple times with the same optimizer in the training pipeline. \r\n\r\nI'm working on a fix, and would like to check it in if more context on the use cases are provided. Thanks!", "@yhliang2018 Sure, my use was to manually log loss/accuracy/metrics for plotting, etc within a notebook. \r\n\r\nTo get around this error I went ahead and switched to using tensorboard for achieving this same thing so I'm no longer affected by this. \r\n\r\nHopefully this is the type of context you're looking for?\r\n\r\n```def training(learning_rate, steps, batch_size, hidden_units, samples, targets, test_samples, test_targets, periods = 10):\r\n  steps_per_period = steps / periods\r\n\r\n  #create DNNRegressor Object\r\n  my_optimizer = tf.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, clipnorm=5.0)\r\n  dnn_regressor = tf.estimator.DNNRegressor(\r\n    feature_columns = construct_feature_columns(samples),\r\n    hidden_units = hidden_units,\r\n    optimizer = my_optimizer\r\n  )\r\n\r\n  # Create input functions.\r\n  training_input_fn = lambda: input_fn(samples, \r\n                                          targets, \r\n                                          batch_size=batch_size)\r\n  predict_training_input_fn = lambda: input_fn(samples, \r\n                                                  targets, \r\n                                                  num_epochs=1, \r\n                                                  shuffle=False)\r\n  predict_validation_input_fn = lambda: input_fn(test_samples, \r\n                                                    test_targets, \r\n                                                    num_epochs=1, \r\n                                                    shuffle=False)\r\n  # Train the model, but do so inside a loop so that we can periodically assess\r\n  # loss metrics.\r\n  print(\"Training model...\")\r\n  print(\"RMSE (on training data):\")\r\n  training_rmse = []\r\n  validation_rmse = []\r\n  for period in range (0, periods):\r\n    # Train the model, starting from the prior state.\r\n    print(\"Period[%s]\" % (period+1))\r\n    dnn_regressor.train(\r\n        input_fn=training_input_fn,\r\n        steps=steps_per_period\r\n    )\r\n```", "@JoshEZiegler Thanks a lot for providing your use case. Yes, `tensorboard` is definitely a good option to check such info. \r\n\r\nI think it's still good to support such use cases when you prefer to log/check the model related info manually. I will have the fix submitted soon, and let you know when it's available in `tf-nightly`.", "More thoughts on this issue: if people create an optimizer instance for canned estimator, it's natural that people think the created optimizer object is the one used in model optimization process. However, if different optimizer instances are created to support `estimator.train()` call, the optimizer for the model optimization is always the new one, which confused people a lot in some use cases. One example:\r\n```\r\n    dnn_opt = tf.keras.optimizers.SGD(1.)\r\n    linear_opt = tf.keras.optimizers.SGD(0.5)\r\n    input_fn = ...\r\n    est = dnn_linear_combined.DNNLinearCombinedClassifierV2(\r\n        ...\r\n        linear_optimizer=linear_opt,\r\n        ...\r\n        dnn_optimizer=dnn_opt)\r\n    num_steps = 1\r\n    est.train(input_fn, steps=num_steps)\r\n    assert num_steps == est.get_variable_value(linear_opt.iterations.name)  # The linear_opt is never used in the optimizer, so it breaks the access of linear_opt.iterations.\r\n    assert num_steps == est.get_variable_value(dnn_opt.iterations.name)  # Same as above, dnn_opt is never used either and its iterations cannot be accessed.\r\n```\r\n@JoshEZiegler given this, how about let's hold to check in the fix for now, and wait for more feedbacks?", "> [Experienced the same issue](https://colab.research.google.com/gist/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9/premade.ipynb) in the latest `tf-nightly`, and reopening.\r\n> \r\n> ```python\r\n> RuntimeError: Cannot set `iterations` to a new Variable after the Optimizer weights have been created\r\n> ```\r\n\r\ni got the same error, have you solved it ?", "> @JoshEZiegler Right. My use case was a bit different and I missed that. But since we can pass any callable, then maybe something like this will work for you:\r\n> \r\n> ```python\r\n> from functools import partial\r\n> AdamWithParams = partial(Adam, learning_rate = 0.1)\r\n> \r\n> ...\r\n> \r\n> optimizer = AdamWithParams\r\n> ```\r\n> \r\n> More on what `partial` is you can find in [the docs](https://docs.python.org/2/library/functools.html#functools.partial). In my code it worked as expected.\r\n\r\nThis workaround could be an option, but possibly not for your use case.", "> @yhliang2018 This issue still shows up with tf-nightly-2.2.0.dev20200306. See [this](https://colab.research.google.com/gist/JoshEZiegler/2a923a707d831ca7efd33dbfbf9779c9/premade.ipynb) colab notebook.\r\n> \r\n> Was there a specific version where you believe it should work?\r\n\r\nThe same error occurs when running this same colab notebook using the latest tf-nightly.", "Instead of `partial`, use lambda to create optimizer object each time. It's way more easier in this way.\r\n\r\n```python\r\nlinear_regressor = tf.estimator.LinearRegressor(\r\n    feature_columns=feature_columns,\r\n    optimizer=lambda:tf.keras.optimizers.SGD(learning_rate=0.0000001, clipnorm=5.0),\r\n)\r\n```", "@JoshEZiegler,\r\n\r\nWe are checking to see if this is still an issue, Can you take a look at this workaround proposed by @simnalamburt and let us know if it helps? Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sanatmpa1 Hi it looks like the workaround suggested by @simnalamburt works as well. \r\n\r\nWithout a workaround it still appears to be an issue. (Tested with version 2.8.0-dev20211019)", "Thanks for the confirmation @JoshEZiegler ", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33358\">No</a>\n"]}, {"number": 33357, "title": "Error when loading model with tf.keras.layers.Input() layer", "body": "On TensorFlow 1.14 (OS Ubuntu 16.04), when I call tf.keras.models.load_model() to load an entire tf.Keras model (following https://www.tensorflow.org/tutorials/keras/save_and_load) if the model contains tf.keras.layers.Input(), the function fails with:\r\n\r\n```\r\n(...)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\r\nin load_weights_from_hdf5_group(f, layers)\r\n    735                      'containing ' + str(len(layer_names)) +\r\n    736                      ' layers into a model with ' + str(len(filtered_layers)) +\r\n--> 737                      ' layers.')\r\n    738 \r\n    739   # We batch weight value assignments in a single backend call\r\n\r\nValueError: You are trying to load a weight file containing 6 layers into a model with\r\n0 layers.\r\n```\r\n\r\nThe minimal code to reproduce is:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.utils import to_categorical, HDF5Matrix\r\n\r\n(Xtr, Ytr), (Xva, Yva) = tf.keras.datasets.cifar10.load_data()\r\nXtr, Ytr, Xva, Yva, nc = Xtr[:1000], Ytr[:1000], Xva[:100], Yva[:100], 10\r\nXtr, Xva = Xtr.astype('float32') / 255, Xva.astype('float32') / 255\r\nYtr, Yva, ins = to_categorical(Ytr, nc), to_categorical(Yva, nc), Xtr.shape[1:]\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Input(ins)) # (1)\r\nmodel.add(tf.keras.layers.Conv2D(8, (3, 3))) # (2)\r\n#model.add(tf.keras.layers.Conv2D(8, (3, 3), input_shape=ins)) # (3)\r\nmodel.add(tf.keras.layers.Activation('relu'))\r\nmodel.add(tf.keras.layers.Conv2D(8, (3, 3), activation='relu'))\r\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(tf.keras.layers.Dropout(0.25))\r\nmodel.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))\r\nmodel.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))\r\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(tf.keras.layers.Dropout(0.25))\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(32, activation='relu'))\r\nmodel.add(tf.keras.layers.Dropout(0.5))\r\nmodel.add(tf.keras.layers.Dense(nc, activation='softmax'))\r\nopt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\r\n\r\nmodel.fit(x=Xtr, y=Ytr, batch_size=32, epochs=1, validation_data=(Xva, Yva))\r\nmodel.save('model.hdf5')\r\ndel model\r\nmodel = tf.keras.models.load_model('model.hdf5')\r\n```\r\n\r\nIf I replace (1) and (2) by (3) the load_model() function works.\r\n", "comments": ["@andmax ,\r\nHi, can you please try running the code in latest versions TF-[1.15rc3](https://colab.sandbox.google.com/gist/oanush/116de45bf971136ac90b0e671dd66874/1-15.ipynb) and also [2.0](https://colab.sandbox.google.com/gist/oanush/be5e0dab0dc5c67e013cf51e881835a9/2-0.ipynb) i didn't face any issue. kindly find the gists for the same.Thanks!", "Hi @oanush , I was able to run your gist 2.0 successfully but could not access the 1.15rc3.  But my question is: this bug is to be considered solved in TF 1.15 and 2.0?  So I should just upgrade from TF 1.14.", "@andmax ,\r\nThank you for checking on that, i have updated Tf-1.15rc3 gist, yes you can just upgrade to latest version 1.15rc3.", "This issue has been fixed in TF 1.15 and 2.0.", "Hi, I am still encountering a similar issue when using `DenseFeatures` as my initial layer."]}, {"number": 33356, "title": "'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'", "body": "I am using Huber loss implementation in tf.keras in tensorflow 1.14.0 as follows:\r\n\r\n```\r\nhuber_keras_loss = tf.keras.losses.Huber(\r\n        delta=delta,\r\n        reduction=tf.keras.losses.Reduction.SUM,\r\n        name='huber_loss'\r\n    )\r\n```\r\n\r\nI am getting the error AttributeError: module 'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'\r\n\r\nI have tried using tf.losses.Reduction, tf.compat.v2.losses.Reduction nothing seems to work.\r\n\r\nDid tensorflow remove Reduction from tf.keras.losses, it is strange if they did so because their documentation still shows: https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args", "comments": ["Hi @subhankar-ghosh, \r\n\r\nCan you please retry this on the `tf-nightly` release, and post the full code to reproduce the problem?\r\n\r\nThe 1.14 release was cut at the beginning of June, and it's entirely possible that this is fixed.", "can\u2019t solve this problem.", "This seems fixed in TF 2.1. Please reopen if you are still hitting errors."]}, {"number": 33355, "title": "Error when Saving Whole Model Keras Model with LSTM / Embedding with Checkpoints ", "body": "When running the model with the model checkpoint callback and adding `save_weights_only=True`, it works. \r\n\r\nInstall:\r\npip install tensorflow==2.0.0\r\n\r\nModel:\r\n```\r\n    model = keras.Sequential([\r\n        keras.layers.Embedding(vocab_size, embedding_dim,\r\n                               batch_input_shape=[batch_size, None]),\r\n        keras.layers.GRU(rnn_units,\r\n                         return_sequences=True,\r\n                         stateful=True,\r\n                         recurrent_initializer='glorot_uniform'),\r\n        keras.layers.Dense(vocab_size)\r\n    ])\r\n    def loss(labels, logits):\r\n        return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n\r\n    optimizer = keras.optimizers.Adam(lr=learning_rate)\r\n    model.compile(optimizer=optimizer, loss=loss)\r\n```\r\nCallback:\r\n```\r\nkeras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix)\r\n```\r\nError\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/text_generator_tf2/trainer/task.py\", line 112, in <module>\r\n    train_and_evaluate(args)\r\n  File \"/text_generator_tf2/trainer/task.py\", line 96, in train_and_evaluate\r\n    history = training_model.fit(dataset, steps_per_epoch=2, epochs=args.num_epochs, callbacks=callbacks)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 372, in fit\r\n    prefix='val_')\r\n  File \"/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\", line 119, in __exit__\r\n    next(self.gen)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 685, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 298, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 965, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 1012, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 975, in save\r\n    signatures, options)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 74, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 893, in save\r\n    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 593, in _fill_meta_graph_def\r\n    signatures = _generate_signatures(signature_functions, resource_map)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 465, in _generate_signatures\r\n    function, mapped_inputs, resource_map)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 417, in _call_function_with_mapped_captures\r\n    function.graph.captures, resource_map)\r\n  File \"/text_generator_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 339, in _map_captures_to_created_tensors\r\n    .format(interior))\r\nAssertionError: Tried to export a function which references untracked object Tensor(\"StatefulPartitionedCall/args_2:0\", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\n```\r\n\r\n", "comments": ["@TheLampshady, Please provide the standalone code to replicate the reported issue. Thanks!", "@TheLampshady,\r\nThe error occurs when you try Saving the Model in a Folder, like `model.save('model')`. Model is Saved Successfully if you use the code, `model.save('model.h5')`. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/db7d5732ecad90087382e76cce4345d7/text_generation.ipynb).\r\n\r\nPlease refer the similar issue, #33247 for more information. ", "thank you, @rmothukuru , it is similar. I was attempting to upgrade from `tf.keras.experimental.export_saved_model` for use on Googles AI Platform. \r\n\r\nRunning with a different model, allows saving with adirectory. \r\n\r\n```\r\ndef create_simple_model(input_dim, rnn_units=None, learning_rate=DEFAULT_LR):\r\n    RMSprop = keras.optimizers.RMSprop\r\n\r\n    rnn_units = rnn_units or RNN_UNITS\r\n    model = keras.Sequential()\r\n    model.add(layers.LSTM(rnn_units, input_shape=input_dim))\r\n    model.add(layers.Dense(input_dim[-1], activation='softmax'))\r\n\r\n    optimizer = RMSprop(learning_rate=learning_rate)\r\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n    return model\r\n```\r\n\r\nI also have a Colab for demo purposes. \r\n\r\nhttps://colab.research.google.com/drive/1CZvo9GzzGxJ5u7EIy2RQ5liuIOBSe3Ir#scrollTo=laOZb9L5VJdZ&uniqifier=2", "@TheLampshady,\r\nAs per my understanding, this issue is part of the issue, #33247. If so, can we close this issue and can we can follow up with #33247, in order to avoid duplication. I have updated Issue 33247 with your colab so that everything will be at one place. Please let me know your thoughts. Thanks!", "That works for me. Ty!"]}, {"number": 33354, "title": "fix documentation for tf.batch_to_space", "body": "https://www.tensorflow.org/api_docs/python/tf/batch_to_space\r\n\r\nthe documentation describing the steps is merged together and not clear.\r\n\r\nIs the link to the source code correct?\r\nyes\r\n\r\n### Submit a pull request?\r\nyes submitted a fix here: https://github.com/tensorflow/tensorflow/pull/33351\r\n\r\n\r\n\r\n", "comments": ["fixed in #33481"]}, {"number": 33353, "title": "Increase protobuf PIP requirement to >=3.8.0", "body": "This is required in order to get https://github.com/protocolbuffers/protobuf/commit/d8c2501b43c1b56e3efa74048a18f8ce06ba07fe , which adds a `RepeatedCompositeContainer.append()` method.\r\n\r\nThanks to @seanpmorgan for raising this issue. Fixes #33348.", "comments": ["@mrry can you please check build failures and resolve conflicts.", "@rthadur All conflicts are now resolved.", "@mrry thank you , @gunan can you please review new changes."]}, {"number": 33352, "title": "No module named 'tensorflow.tools.graph_transforms' in TF2.0", "body": "This functionality seems still [included](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#strip_unused_nodes) in TensorFlow 2.0, however, it raises an error when calling.\r\n\r\n```\r\n% ipython\r\nPython 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 16:52:21) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: from tensorflow.tools.graph_transforms import TransformGraph                                                 \r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-1-1fd86d9792e0> in <module>\r\n----> 1 from tensorflow.tools.graph_transforms import TransformGraph\r\n\r\nModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'\r\n```\r\n\r\nTensorFlow version:\r\n\r\n```\r\n% pip show tensorflow\r\nName: tensorflow\r\nVersion: 2.0.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /Volumes/data/venv-tf2/lib/python3.7/site-packages\r\nRequires: gast, six, tensorboard, grpcio, termcolor, tensorflow-estimator, protobuf, keras-preprocessing, keras-applications, numpy, opt-einsum, absl-py, wrapt, wheel, astor, google-pasta\r\nRequired-by: tfcoreml\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary pip install\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n", "comments": ["Similar to the issue #30746 \r\n\r\nWas able to reproduce this issue. Please find the gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/185f73a175e6b9fec45fd91a15d83830/untitled188.ipynb)\r\n", "Facing similar issue..", "This is WIA. The code is still in the repository but this code is not exposed intentionally in TF 2.0 as graphs are not central in 2.0, look to Grappler as the place for TF rewrites now. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33352\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33352\">No</a>\n", "@suharshs  how to use grappler? is it automatically enabeled? i don't find any document about it.", "@x10000year \r\n\r\nRecently, the document for the graph optimization is merged to tensorlflow/doc (https://github.com/tensorflow/docs/pull/1206).\r\nThis document describes how to control behaviours of grappler.\r\nI hope this document meets your requirement."]}, {"number": 33351, "title": "fixing documentation for tf.batch_to_space", "body": "issue #33354\r\n\r\nfixing documentation so it is easier to read on the website. \r\neach step is not separated correctly : https://www.tensorflow.org/api_docs/python/tf/batch_to_space", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac ", "Let's take this one as it improves website documentation", "However, please make sure the Pr is against master, not 2.0", "@mihaimaruseac created a new pr at #33481 to be against master"]}, {"number": 33350, "title": "Consume java_import_external from bazel_tools instead of rules_closure", "body": "The version in rules_closure is being removed here: https://github.com/bazelbuild/rules_closure/pull/239", "comments": ["//cc @davido", "Approving as it makes sense but let's wait for all CI jobs to test that it is ok to do so.", "Any updates on this?", "@mihaimaruseac can you please help merge this PR", "This fails the Android test, can you take a look", "@mihaimaruseac The CI failure look unrelated to this PR. Android demo is failing consitently on all PRs and on master."]}, {"number": 33349, "title": "Jvishnuvardhan patch 1", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33349) for more info**.\n\n<!-- need_author_consent -->"]}]