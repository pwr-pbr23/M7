[{"number": 49901, "title": "Lambda and Subclass layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- Using Google colab\r\n- TensorFlow version: `tensorflow._api.v2.version`\r\n- GPU model and memory: Python Google Compute Engine Backend (2 cores)\r\n\r\nThis is the warning I get:\r\n<pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\r\n94773248/94765736 [==============================] - 1s 0us/step\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.tensordot), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'dense_1/kernel:0' shape=(2048, 2048) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.nn.bias_add), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'dense_1/bias:0' shape=(2048,) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.tensordot_1), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'dense/kernel:0' shape=(2048, 5) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.nn.bias_add_1), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'dense/bias:0' shape=(5,) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.</pre>\r\n\r\n**Standalone code to reproduce the issue**\r\n<pre>input_tensor = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, CANAL))\r\n\r\nbase = ResNet50(weights=\"imagenet\", include_top=False,input_tensor=input_tensor)\r\n#base.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\r\n\r\ntop = Dense(N_CLASSES, activation='softmax')(\r\n            Dropout(0.5)(\r\n                Dense(2048, activation='relu')(\r\n                    Dropout(0.5)(\r\n                        MaxPooling2D()(base.output)\r\n                    )\r\n                )\r\n            )\r\n        )\r\n\r\nmodel = Model(input_tensor, top)</pre>\r\n\r\nKindly help since this isn't allowing me to train all the pre-existing layers in the model.\r\n\r\nN_CLASSES= 5\r\nCANAL = 3\r\nIMG_SIZE = 512", "comments": ["@akshitadixit kindly mention the values for IMG_SIZE, CANAL, N_CLASSES for which you are getting error. This code is not creating any error in Google colab environment.", "@tusharvickey1999 updated, added at the end", "> @tusharvickey1999 updated, added at the end\n\nCan you add a link to the Google colab notebook which produces this error since this code is not producing any error.", "@akshitadixit \r\nPlease refer to the gist shared [here](\r\nhttps://colab.research.google.com/gist/tilakrayal/6b16407f9485e40a8b80f83efc51b633/49901.ipynb), we do not see any issues.", "> @akshitadixit\r\n> Please refer to the gist shared [here](https://colab.research.google.com/gist/tilakrayal/6b16407f9485e40a8b80f83efc51b633/49901.ipynb), we do not see any issues.\r\n\r\nI'm so sorry for the time you put here. I'll run my thing once again. Though I obviously did not write the error warnings myself, I will recheck. Thank you for the patience. ", "Hey @Saduf2019 I checked out the gist and it seemed to work perfectly, however strangely doesn't yet work on my notebook. Attaching screenshots for reference. Both of them aren't any different but I just tried to be very sure.\r\n\r\n![Screenshot from 2021-06-03 16-35-33](https://user-images.githubusercontent.com/56997545/120638095-562aa400-c48d-11eb-969e-640bbf6d6d4a.png)\r\n![Screenshot from 2021-06-03 17-02-30](https://user-images.githubusercontent.com/56997545/120638333-a0138a00-c48d-11eb-846f-67c207517ada.png)\r\n\r\nThis warning is irrespective of the runtime type. If I forgot to mention, I am using Firefox as my browser.\r\nFurther, `model.summary` gives the following result.\r\n<pre>\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nTotal params: 23,587,712\r\nTrainable params: 23,534,592\r\nNon-trainable params: 53,120\r\n</pre>\r\n", "@akshitadixit \r\nDoes the warning effect your performance/result compared to what we see on colab, if not we can just ignore the warning.", "The warning somehow returns a model with zero layers on my notebook, but gives the ideal output on the gist you shared. This is really strange.", "@akshitadixit can you confirm if the warning is result of using the Resnet50 model in your network?", "@akshitadixit \r\nYou may want to check the configurational differences from colab to your system, and update your system accordingly. Can you try on venv and let us know if the issue exists.", "Sure I will.", "@Saduf2019 it works super normal on my local virtual environment, but still doesn't run on my colab notebook :(\r\n\r\n[Link](https://colab.research.google.com/drive/19S-0sgYe5xoEU1EEaf1BLQV1io45Y6ey?usp=sharing) to my colab notebook.", "> @akshitadixit can you confirm if the warning is result of using the Resnet50 model in your network?\r\n\r\nYes @tusharvickey1999 it did spring up when I used resnet, but I'm not exactly sure if it is because of that. Never happened before. Although I'm afraid if I have placed my layers somehow incorrectly, but that's the way I assume it needs to be done.", "@akshitadixit finally figured out that importing Dense layer from keras was creating the error, importing it from tensorflow.keras makes no error. Its probably due to the fact that resnet50 is pretrained on dense layer of tensorflow and importing keras dense layer creates conflict bw the two.\n\nhope this helps.", "How does it explain that the exact same code runs well on my local machine? Btw thanks it just seemed to work.", "@akshitadixit \r\nAs it works you may move this to close status and open the topic on tensorflow discussion forum or stackoverflow as there is a larger community there who could answer that.", "Sure thing. Thanks for the time. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49901\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49901\">No</a>\n"]}, {"number": 49898, "title": "Failed Build 2.5.0 on Windows with Cuda 11.2", "body": "System information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version: 2.5.0\r\nPython version: 3.8\r\nBazel version (if compiling from source): 3.7.2\r\nCUDA/cuDNN version: 11.2/8.1.0\r\nGPU model and memory: 2070\r\n\r\nThe following error occurs when I attempt to build 2.5.0. \r\n\r\n**ERROR: C:/sdks/tensorflow/tensorflow/compiler/mlir/hlo/BUILD:423:11: C++ compilation of rule //tensorflow/compiler/mlir/hlo:lhlo' failed (Exit 2): cl.exe failed: error executing command**\r\n\r\n> cd C:/users/adam/_bazel_adam/e7merofc/execroot/org_tensorflow\r\n>   SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n>     SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n>     SET PWD=/proc/self/cwd\r\n>     SET PYTHON_BIN_PATH=C:/Users/Adam/anaconda3/python.exe\r\n>     SET PYTHON_LIB_PATH=C:/Users/Adam/anaconda3/lib/site-packages\r\n>     SET RUNFILES_MANIFEST_ONLY=1\r\n>     SET TEMP=C:\\Users\\Adam\\AppData\\Local\\Temp\r\n>     SET TF2_BEHAVIOR=1\r\n>     SET TMP=C:\\Users\\Adam\\AppData\\Local\\Temp\r\n>   C:/Program Files (x86)/Microsoft Visual Studio/2019/Enterprise/VC/Tools/MSVC/14.28.29333/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/llvm-project /Ibazel-out/x64_windows-opt/bin/external/llvm-project /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_base_inc_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_structs_inc_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefBaseIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorBaseIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgSparseOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLTypesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLInterpOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ConversionPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen /Itensorflow/compiler/mlir/hlo/include /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include /Iexternal/llvm-project/llvm/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/llvm-project/mlir/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/include /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=\"redacted\" -D__TIMESTAMP__=\"redacted\" -D__TIME__=\"redacted\" /Gy /Gw /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /arch:AVX2 /std:c++14 /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_objs/lhlo/lhlo_ops_structs.obj /c tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/IR/lhlo_ops_structs.cc\r\n> Execution platform: @local_execution_config_platform//:platform\r\n> cl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release\r\n> cl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(25): error C2665: 'mlir::DictionaryAttr::get': none of the 3 overloads could convert all the argument types\r\n> bazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen\\mlir/IR/BuiltinAttributes.h.inc(261): note: could be 'mlir::DictionaryAttr mlir::DictionaryAttr::get(mlir::MLIRContext *,llvm::ArrayRef<mlir::NamedAttribute>)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(25): note: while trying to match the argument list '(llvm::SmallVector<mlir::NamedAttribute,2>, mlir::MLIRContext *)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(116): error C2665: 'mlir::DictionaryAttr::get': none of the 3 overloads could convert all the argument types\r\n> bazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen\\mlir/IR/BuiltinAttributes.h.inc(261): note: could be 'mlir::DictionaryAttr mlir::DictionaryAttr::get(mlir::MLIRContext *,llvm::ArrayRef<mlir::NamedAttribute>)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(116): note: while trying to match the argument list '(llvm::SmallVector<mlir::NamedAttribute,9>, mlir::MLIRContext *)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(266): error C2665: 'mlir::DictionaryAttr::get': none of the 3 overloads could convert all the argument types\r\n> bazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen\\mlir/IR/BuiltinAttributes.h.inc(261): note: could be 'mlir::DictionaryAttr mlir::DictionaryAttr::get(mlir::MLIRContext *,llvm::ArrayRef<mlir::NamedAttribute>)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(266): note: while trying to match the argument list '(llvm::SmallVector<mlir::NamedAttribute,4>, mlir::MLIRContext *)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(356): error C2665: 'mlir::DictionaryAttr::get': none of the 3 overloads could convert all the argument types\r\n> bazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen\\mlir/IR/BuiltinAttributes.h.inc(261): note: could be 'mlir::DictionaryAttr mlir::DictionaryAttr::get(mlir::MLIRContext *,llvm::ArrayRef<mlir::NamedAttribute>)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(356): note: while trying to match the argument list '(llvm::SmallVector<mlir::NamedAttribute,4>, mlir::MLIRContext *)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(446): error C2665: 'mlir::DictionaryAttr::get': none of the 3 overloads could convert all the argument types\r\n> bazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen\\mlir/IR/BuiltinAttributes.h.inc(261): note: could be 'mlir::DictionaryAttr mlir::DictionaryAttr::get(mlir::MLIRContext *,llvm::ArrayRef<mlir::NamedAttribute>)'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc(446): note: while trying to match the argument list '(llvm::SmallVector<mlir::NamedAttribute,4>, mlir::MLIRContext *)'\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> INFO: Elapsed time: 7072.771s, Critical Path: 304.21s\r\n> INFO: 7627 processes: 619 internal, 7008 local.\r\n> FAILED: Build did NOT complete successfully\r\n\r\nRunning again, different error message, but looks related.\r\n\r\n\r\n**ERROR: C:/sdks/tensorflow/tensorflow/compiler/mlir/xla/BUILD:265:11: C++ compilation of rule '//tensorflow/compiler/mlir/xla:hlo_utils' failed (Exit 2): cl.exe failed: error executing command**\r\n\r\n>   cd C:/users/adam/_bazel_adam/e7merofc/execroot/org_tensorflow\r\n>   SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n>     SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n>     SET PWD=/proc/self/cwd\r\n>     SET PYTHON_BIN_PATH=C:/Users/Adam/anaconda3/python.exe\r\n>     SET PYTHON_LIB_PATH=C:/Users/Adam/anaconda3/lib/site-packages\r\n>     SET RUNFILES_MANIFEST_ONLY=1\r\n>     SET TEMP=C:\\Users\\Adam\\AppData\\Local\\Temp\r\n>     SET TF2_BEHAVIOR=1\r\n>     SET TMP=C:\\Users\\Adam\\AppData\\Local\\Temp\r\n>   C:/Program Files (x86)/Microsoft Visual Studio/2019/Enterprise/VC/Tools/MSVC/14.28.29333/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/llvm-project /Ibazel-out/x64_windows-opt/bin/external/llvm-project /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_rocm /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/canonicalize_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/chlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_base_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_pattern_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefBaseIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorBaseIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgSparseOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MLIRShapeCanonicalizationIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ShapeOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLTypesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLInterpOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ConversionPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_structs_inc_gen /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Itensorflow/compiler/mlir/xla/include /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/xla/include /Itensorflow/compiler/mlir/hlo/include /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include /Iexternal/llvm-project/mlir/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/include /Iexternal/llvm-project/llvm/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Ithird_party/eigen3/mkl_include /Ibazel-out/x64_windows-opt/bin/third_party/eigen3/mkl_include /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_rocm/rocm /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm /Iexternal/local_config_rocm/rocm/rocm/include /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include /Iexternal/local_config_rocm/rocm/rocm/include/rocrand /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include/rocrand /Iexternal/local_config_rocm/rocm/rocm/include/roctracer /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include/roctracer /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=\"redacted\" -D__TIMESTAMP__=\"redacted\" -D__TIME__=\"redacted\" /Gy /Gw /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /arch:AVX2 /std:c++14 /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/xla/_objs/hlo_utils/hlo_utils.obj /c tensorflow/compiler/mlir/xla/hlo_utils.cc\r\n> Execution platform: @local_execution_config_platform//:platform\r\n> cl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release\r\n> cl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc(13): error C2011: 'mlir::mhlo::ChannelHandle': 'class' type redefinition\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc(32): error C2011: 'mlir::mhlo::ConvDimensionNumbers': 'class' type redefinition\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(32): note: see declaration of 'mlir::mhlo::ConvDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc(65): error C2011: 'mlir::mhlo::DotDimensionNumbers': 'class' type redefinition\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(65): note: see declaration of 'mlir::mhlo::DotDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc(88): error C2011: 'mlir::mhlo::GatherDimensionNumbers': 'class' type redefinition\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(88): note: see declaration of 'mlir::mhlo::GatherDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc(111): error C2011: 'mlir::mhlo::ScatterDimensionNumbers': 'class' type redefinition\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(111): note: see declaration of 'mlir::mhlo::ScatterDimensionNumbers'\r\n> external/llvm-project/llvm/include\\llvm/Support/type_traits.h(75): error C2079: 'llvm::detail::copy_construction_triviality_helper<T>::t' uses undefined class 'mlir::mhlo::ChannelHandle'\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(630): note: see reference to class template instantiation 'llvm::detail::copy_construction_triviality_helper<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> external/llvm-project/llvm/include\\llvm/Support/type_traits.h(100): note: see reference to class template instantiation 'std::is_copy_constructible<llvm::detail::copy_construction_triviality_helper<T>>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'llvm::is_trivially_copy_constructible<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(705): note: see reference to class template instantiation 'llvm::Optional<mlir::mhlo::ChannelHandle>' being compiled\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(788): error C2139: 'mlir::mhlo::ChannelHandle': an undefined class is not allowed as an argument to compiler intrinsic type trait '__is_trivially_assignable'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'std::is_trivially_copy_assignable<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(769): error C2139: 'mlir::mhlo::ChannelHandle': an undefined class is not allowed as an argument to compiler intrinsic type trait '__is_trivially_constructible'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'std::is_trivially_move_constructible<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(661): error C2139: 'mlir::mhlo::ChannelHandle': an undefined class is not allowed as an argument to compiler intrinsic type trait '__is_constructible'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'std::is_move_constructible<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(798): error C2139: 'mlir::mhlo::ChannelHandle': an undefined class is not allowed as an argument to compiler intrinsic type trait '__is_trivially_assignable'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'std::is_trivially_move_assignable<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits(705): error C2139: 'mlir::mhlo::ChannelHandle': an undefined class is not allowed as an argument to compiler intrinsic type trait '__is_assignable'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(13): note: see declaration of 'mlir::mhlo::ChannelHandle'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(54): note: see reference to class template instantiation 'std::is_move_assignable<T>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(240): error C2976: 'llvm::optional_detail::OptionalStorage': too few template arguments\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(60): note: see declaration of 'llvm::optional_detail::OptionalStorage'\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(168): error C2079: 'llvm::optional_detail::OptionalStorage<T,true>::value' uses undefined class 'mlir::mhlo::ChannelHandle'\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> external/llvm-project/llvm/include\\llvm/ADT/Optional.h(240): note: see reference to class template instantiation 'llvm::optional_detail::OptionalStorage<T,true>' being compiled\r\n>         with\r\n>         [\r\n>             T=mlir::mhlo::ChannelHandle\r\n>         ]\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2194): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2194): error C3646: 'target_arg_mapping': unknown override specifier\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2194): error C2059: syntax error: '('\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2194): error C2238: unexpected token(s) preceding ';'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2224): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2224): error C3646: 'target_arg_mappingAttr': unknown override specifier\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2224): error C2059: syntax error: '('\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2224): error C2238: unexpected token(s) preceding ';'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2225): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2225): error C2065: 'CustomCallTargetArgMapping': undeclared identifier\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2225): error C2923: 'llvm::Optional': 'CustomCallTargetArgMapping' is not a valid template type argument for parameter 'T'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2229): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2229): error C2061: syntax error: identifier 'CustomCallTargetArgMapping'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2231): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2231): error C2061: syntax error: identifier 'CustomCallTargetArgMapping'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2232): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2232): error C2061: syntax error: identifier 'CustomCallTargetArgMapping'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2233): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2233): error C2061: syntax error: identifier 'CustomCallTargetArgMapping'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2234): error C2039: 'CustomCallTargetArgMapping': is not a member of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2175): note: see declaration of 'mlir::lmhlo'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen\\mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h.inc(2234): error C2061: syntax error: identifier 'CustomCallTargetArgMapping'\r\n> tensorflow/compiler/mlir/xla/hlo_utils.cc(262): error C2027: use of undefined type 'mlir::mhlo::GatherDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(88): note: see declaration of 'mlir::mhlo::GatherDimensionNumbers'\r\n> tensorflow/compiler/mlir/xla/hlo_utils.cc(261): error C2027: use of undefined type 'mlir::mhlo::GatherDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(88): note: see declaration of 'mlir::mhlo::GatherDimensionNumbers'\r\n> tensorflow/compiler/mlir/xla/hlo_utils.cc(279): error C2027: use of undefined type 'mlir::mhlo::GatherDimensionNumbers'\r\n> bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include\\mlir-hlo/Dialect/mhlo/IR/hlo_ops_base_structs.h.inc(88): note: see declaration of 'mlir::mhlo::GatherDimensionNumbers'\r\n> tensorflow/compiler/mlir/xla/hlo_utils.cc(279): error C3861: 'get': identifier not found\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> INFO: Elapsed time: 468.026s, Critical Path: 56.72s\r\n> INFO: 504 processes: 24 internal, 480 local.\r\n> FAILED: Build did NOT complete successfully", "comments": ["Updating the latest VS2019 (v16.10) appears to solve this problem. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49898\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49898\">No</a>\n"]}, {"number": 49897, "title": "Tensorflow Lite Fail On Release Build but success on Debug Build", "body": "Debug Build = success\r\nRelease Build = Failed Severity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tC1001\tAn internal error has occurred in the compiler.\ttensorflow-lite\td:\\tensorflow\\tflite_build\\gemmlowp\\internal\\output.h\t176\t\r\n\r\nPhoto of debug build\r\n![Screenshot_2](https://user-images.githubusercontent.com/68463485/120086983-39e5da80-c10e-11eb-8dc2-11521a4ba270.png)\r\n\r\nPhoto of release build\r\n![Screenshot_3](https://user-images.githubusercontent.com/68463485/120086990-49652380-c10e-11eb-8e20-1101310aa6e3.png)\r\n\r\nError on this line 176 file output.h\r\n![Screenshot_4](https://user-images.githubusercontent.com/68463485/120087057-f6d83700-c10e-11eb-96f0-55c110e39a2e.png)\r\n", "comments": ["problem solved [https://github.com/tensorflow/tensorflow/issues/47166#issuecomment-829780437](url)\r\n\r\nchange Maximum Optimization (Favor Speed) (/O2) to Maximum Optimization (Favor Size) (/O1)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49897\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49897\">No</a>\n"]}, {"number": 49895, "title": "Plugin-able Optimizers", "body": "**System information**\r\n- Tensorflow version 2.5\r\n- Are you willing to contribute it (Yes):\r\n\r\n\r\n\r\n## Describe the feature and the current behavior/state.\r\n\r\nCurrently there are at least four different paths a user has to take to try out a different optimizer:\r\n\r\n1. The Optimizer might be found under `tf.keras.optimizers`\r\n2. If not, it might be included in `tfa.optimizers` (tensorflow/addons) or `tfp.optimizers` (tensorflow/probability)\r\n3. If not, the user might need to (statically?) install a subclass `tf.keras.optimizers.Optimizer` defined in some github repo - if lucky there is a `setup.py`\r\n4. There might not even be an implementation available subclassing `tf.keras.optimizers.Optimizer` so the user would have to reimplement that\r\n\r\nNow wouldn't it be cool if any optimizer could be installed with `pip install my-optimizer` and then accessed using `tf.optimizers.MyOptimizer`? Now the python packaging guide includes a [section about plugins](https://packaging.python.org/guides/creating-and-discovering-plugins/#using-package-metadata) which would make just that possible:\r\n\r\nLet's say I have implemented the class `MyOptimizer(tf.keras.optimizers.Optimizer)` in the file `my_optimizer.py`, then I could write the following `setup.py`:\r\n\r\n```python\r\nfrom setuptools import setup\r\n\r\nsetup(\r\n    name='my-optimizer',\r\n    version='1.0',\r\n    py_modules=[ 'my_optimizer' ],\r\n    install_requires= [...],\r\n    entry_points='''\r\n        [tf.optimizers]\r\n        my-optimizer = my_optimizer:MyOptimizer\r\n    '''\r\n)\r\n```\r\n\r\nand upload the package. Now tensorflow could include this optimizer into `tf.optimizers` by doing the following:\r\n\r\n```python\r\n# tensorflow.optimizers.__init__.py\r\n\r\nimport importlib\r\n\r\nPLUGINS = {\r\n    plugin.attr : plugin.module for plugin in\r\n    importlib.metadata.entry_points()[\"tf.optimizers\"]\r\n}\r\n\r\ndef __getattr__(name: str) -> Any:\r\n    return getattr(\r\n        importlib.import_module(PLUGINS[name]), \r\n        name\r\n)\r\n```\r\n\r\n(Alternatively one could use importlib in the dictionary comprehension already for eager loading. I am not sure which one is better. But people probably only import Optimizers only once and do not use all of them so I defaulted to the lazy version)\r\n\r\nThis [works for python 3.7+](https://stackoverflow.com/a/48916205/6662425), for python 3.6 one would have to either [replace the module with a class](https://stackoverflow.com/a/7668273/6662425)  or use something like `setattr()` on the module, `exec(f\"{plugin.attr} = importlib.import_module(plugin.module)\")`, or some other magic\r\n\r\n<details>\r\n  <summary>Old (probably wrong) suggestion</summary>\r\n\r\nI think I have misunderstood the purpose of the tf_export decorators here  \r\n\r\n```python\r\nimport importlib\r\nfrom tensorflow.python.util import tf_export\r\nfrom importlib.metadata import entry_points\r\n\r\nfor plugin in entry_points()[\"tf.optimizers\"]:\r\n    custom_optim_class = getattr(importlib.import_module(plugin.module), plugin.attr)\r\n    # export the plugin optimizer class under the name `plugin.attr` which is its self-given name \r\n    tf_export.tf_export(\"optimizers.\" + plugin.attr, metaclass=abc.ABCMeta)(custom_optim_class)\r\n```\r\n\r\n</details>\r\n\r\n\r\nUsers could then install any optimizer published with such an `entry_point` with pip and find the optimizer inside of `tf.optimizers`.\r\n\r\n## Changes to the API\r\n\r\n`tf.optimizers` would be filled with plugin Optimizers. The optimizers could alternatively be included into `tf.keras.optimizers` or any other place, ideally it would unify the place where one could find optimizers in the long term.\r\n\r\n## Who will benefit from this feature?\r\n\r\nI am assuming that the reason `tensorflow/addons` and `tensorflow/probability` exists, is to reduce the base install size. If all optimizers are plugins which are extremely easy to install but all found in the same module by some import magic, then it will be easier to try out custom optimizers. And if the current \"batteries included\" optimizers are converted into such plugins as well, then you could not only reduce the base install of tensorflow (making them [optional dependencies](https://setuptools.readthedocs.io/en/latest/userguide/dependency_management.html#optional-dependencies) - e.g. `tensorflow[all]` would still include them), but these default plugins would also become standalone \"examples\" how to subclass the Optimizer class properly.\r\n\r\nIt is also fairly trivial to create a GitHub Template Repository with such a setup.py and stumps of such an Optimizer class with included github actions that deploy the package to pypa.\r\n\r\nSo people who would want to create new optimizers could simply click \"use template\" on those repositories, replace \"my-optimizer\" occurances with their optimizer name, implement the method stumps, and set the pypa access token in the github secrets. And their optimizer would immediately be available to download with pip and automatically included in the `tf.optimizers` module.\r\n\r\nThis means that the first three install methods would be merged. And since creating a new optimizer is made easier using this template, it is likely that more people would do so, moving more of the fourth category optimizers into this as well.\r\n\r\nThe general idea is to take the \"software engineering\" aspect out of writing Optimizers as much as possible such that researchers have an easier time.\r\n\r\nLastly things like\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef optimizers_as_dict():\r\n    return { name : cls for name, cls in tf.optimizers.__dict__.items() if issubclass(cls, tf.keras.optimizers.Optimizer) }\r\n```\r\n\r\ncould provide easy dynamic access to all installed optimizers making it a lot easier to do AutoML with them. This could also be included as a method in `tf.optimizers`.\r\n\r\n## Extension\r\n\r\nThis plugin approach could also be applied to layers, loss functions, etc. to make tensorflow more dynamic in general.\r\n", "comments": ["Hm - circular imports might be a problem. Optimizers will need tensorflow, and tensorflow tries to import optimizers. But since optimizers will generally not use `tf.optimizers` this _should_ be manageable.", "Draft for such a Template: https://github.com/FelixBenning/tf-optimizer", "Demo Implementation for how tensorflow might incorporate such plugins into its modules https://github.com/FelixBenning/tensorflow-plugins (here the plugins are included into `tf_plugins.optimizers` etc.\r\n\r\nI think the biggest issue will be static codecompletion. I am not sure if there is a way around this. At the moment this means that only the default objects are completed\r\n", "<details><summary>Bogus Namespace Alternative</summary>\r\n\r\na different way to do this might be `namespaces packages` (https://docs.python.org/3/whatsnew/3.3.html#pep-420-implicit-namespace-packages) this would also allow people to write packages extending the `tensorflow.optimizers` This would require there to be no `__init__.py` file in `tensorflow.optimizers` not only in tensorflow itself, but also in none of the plugins.\r\n\r\nThe advantage of this approach is its simplicity (it would not require any import magic at all) and the fact that static code completion would probably work with it.\r\n\r\nThe disadvantage of this approach is the discipline it requires: If any of the plugins create an `__init__.py` in this folder things break. One could test whether that happends at import and warn the user - probably even tell them the culprit package but it is still a bit more annoying to deal with. It might also be harder to access all plugins programmatically.\r\n\r\n</details>\r\n\r\nEDIT: Nevermind, even with namespaces you would still have to import the optimizers from the modules since files are always modules and not namespaces. So people would have to put unique modules into that `tensorflow.optimizer` namespace forcing dynamic imports of the classes anyway. So this does not really help static intellisense. \r\n\r\nBut since `__getattr__` is only called when some property is not found, one could always do a hybrid approach of hardcoding some imports while letting other be dynamic.", "Adding Mihai from TF infra team and Tomer for addons. ", "Thanks for reporting the issue.\r\n\r\nFirstly, if you want to access the optimizer you implemented (or implemented by someone else), having the optimizer under the tf.keras.optimizers name space doesn't actually change any functionality. Since TF has strong API contract, we actually moved most of the custom layers/optimizers/loss to the tf_addon repo, which suppose to be the location for your use case. The API boundary here is that anything under tf namespace will be ensure by the contract and backwards compatible. Having anything is not belonging to TF to be appear is defeating the purpose. \r\n\r\nHaving tf_addons and other PIP package as the optional dependency is definitely something we want to avoid. TF is already a quite large package, and we are trying our best to reduce its size. We only include any dependency that is necessary. Also the TF -> Addon dependency seems to be a issue for circular dependency. ", "@qlzh727 I know that this does not change the functionality of the optimizer - it just guarantees that *all* installed optimizers are found under the same namespace (also without having to send pull requests to tensorflow/addons and waiting for them to be processed). This might seem like a trivial change, but it is also a trivial change to implement and allows for easy looping over optimizers and easier use.\r\n\r\n> Having tf_addons and other PIP package as the optional dependency is definitely something we want to avoid. TF is already a quite large package, and we are trying our best to reduce its size.\r\n\r\naddons are already an optional dependency, that is the point of \"optional\". The point is, that you could have more fine grained control over what you want to install if every single optimizer is installed via pip. I just wanted to argue that you can still bundle some of these optimizers into optional dependencies. In fact this _reduces_ the size of tensorflow because optimizers, etc. are _only_ installed if you use these addon features", "If we let all the custom optimizer co-exist in the same namespace, then we need to check for name conflict and loading priority, which could certainly cause confusing error when optimizer with same name appears. This will then led to the requirement that each optimizer need to have it unique name under the namespace, so TF has to have a way to somehow allow user to register that.\r\n\r\nI don't think the proposed approach provides much benefit comparing to having it in its own PIP package and import with its own package/module path.\r\n\r\nI would also suggest the addon repository again, which is the recommended repository for hosting this kind of contribution."]}, {"number": 49894, "title": "List of Initializers are specified twice in the Classes Section of documentation", "body": "Please provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/initializers#classes\r\n\r\n## Description of issue (what needs changing):\r\nEvery **`Initializer`** has been specified twice, (`Constant`, `GlorotUniform`,etc..) and (`constant`, `glorot_uniform`, etc..).\r\n\r\nHowever, they, for example [GlorotUniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform) and [glorot_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform), point to the same link.\r\n\r\nIs there any specific reason for this redundancy?", "comments": ["They are intentionally retained, See comment\r\nhttps://github.com/tensorflow/tensorflow/blob/d0e3ce5b4bc8bea4bbb9fe51635dd36104e4ad86/tensorflow/python/keras/initializers/__init__.py#L66", "@worldpeaceaspirer \r\n\r\nCould you please check the above comment ,move this to closed status if it helps.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> They are intentionally retained, See comment\r\n> https://github.com/tensorflow/tensorflow/blob/d0e3ce5b4bc8bea4bbb9fe51635dd36104e4ad86/tensorflow/python/keras/initializers/__init__.py#L66\r\n\r\n@ymodak,\r\nI see that they are intentionally retained. Thank you. "]}, {"number": 49893, "title": "Probability is mismatching  for the image classification example", "body": "used same code what given in the below url ,\r\nhttps://www.tensorflow.org/tutorials/images/classification\r\n\r\ncreated the .tflite for Android and imported the tflite but while executing the code Probability is not matching with the python code.\r\n\r\nPercentage in python is ,\r\nThis image most likely belongs to sunflowers with a **95.65** percent confidence. \r\n\r\nThe android code:\r\nval model = Model.newInstance(this)\r\n        val bitmap: Bitmap =\r\n            BitmapFactory.decodeResource(resources, R.drawable.image)\r\n// Creates inputs for reference.\r\n        val image = TensorImage.fromBitmap(bitmap)\r\n\r\n// Runs model inference and gets result.\r\n        val outputs = model.process(image)\r\n        val probability = outputs.probabilityAsCategoryList\r\n\r\n// Releases model resources if no longer used.\r\n        model.close()\r\n\r\n        val outputsProbability = probability.apply {\r\n            sortByDescending { it.score } // Sort with highest confidence first\r\n        }.take(5)\r\n\r\n        val items = mutableListOf<Recognition>()\r\n        for (output in outputsProbability) {\r\n            items.add(Recognition(output.label, output.score))\r\n        }\r\n\r\n        Log.d(\"propability\", items.toString())\r\n        \r\no/p:\r\nD/propability: [dandelion / 554.4%, daisy / 61.7%, roses / -75.3%, tulips / -282.9%, sunflowers / **-426.3**%]", "comments": ["@spadiyar67 ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error]  reported.\r\n\r\nThanks!", "@tilakrayal \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):used the code as per the tensot flow link,\r\nhttps://www.tensorflow.org/tutorials/images/classification\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy note 8\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.4.1\r\n- Python version:3.8.2\r\n- Bazel version (if compiling from source): not seeing bezel version from the command bazel --version\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version:-\r\n- GPU model and memory: 500 GB\r\n\r\n\r\nI have given python and android code below.\r\nSteps:\r\nCreated tflite from the python code ->imported in Android studio->android code i have given below->the probability while running python and android code mismatching.\r\n\r\n**Python code**:\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport os\r\nimport PIL\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tflite_support import flatbuffers\r\nfrom tflite_support import metadata as _metadata\r\nfrom tflite_support import metadata_schema_py_generated as _metadata_fb\r\nfrom absl import flags\r\nimport imageio\r\nimport cv2\r\nimport numpy as np\r\nimport pathlib\r\n\r\n\r\nbatch_size = 32\r\nimg_height = 180\r\nimg_width = 180\r\ndata_dir = \".keras/datasets/flower_photos\"\r\n\r\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n    data_dir,\r\n  validation_split=0.2,\r\n  subset=\"training\",\r\n  seed=123,\r\n  image_size=(img_height, img_width),\r\n  batch_size=batch_size)\r\n\r\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n  data_dir,\r\n  validation_split=0.2,\r\n  subset=\"validation\",\r\n  seed=123,\r\n  image_size=(img_height, img_width),\r\n  batch_size=batch_size)\r\n\r\nclass_names = train_ds.class_names\r\nprint(class_names)\r\n\r\n\r\n\r\nfor image_batch, labels_batch in train_ds:\r\n  print(image_batch.shape)\r\n  print(labels_batch.shape)\r\n  break\r\n\r\ndata_augmentation = keras.Sequential(\r\n  [\r\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\r\n                                                 input_shape=(img_height,\r\n                                                              img_width,\r\n                                                              3)),\r\n    layers.experimental.preprocessing.RandomRotation(0.1),\r\n    layers.experimental.preprocessing.RandomZoom(0.1),\r\n  ]\r\n)\r\nnum_classes = 5\r\nmodel = Sequential([\r\n  data_augmentation,\r\n  layers.experimental.preprocessing.Rescaling(1./255),\r\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Dropout(0.2),\r\n  layers.Flatten(),\r\n  layers.Dense(128, activation='relu'),\r\n  layers.Dense(num_classes)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\n\r\nprint(len(train_ds))\r\nprint(len(val_ds))\r\n\r\nepochs = 15\r\nhistory = model.fit(\r\n  train_ds,\r\n  validation_data=val_ds,\r\n  epochs=epochs\r\n)\r\nprint(len(train_ds))\r\nprint(len(val_ds))\r\n\r\n\r\nsunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\r\nsunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\r\n\r\nimg = keras.preprocessing.image.load_img(\r\n    sunflower_path, target_size=(img_height, img_width)\r\n)\r\nimg_array = keras.preprocessing.image.img_to_array(img)\r\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\r\n\r\npredictions = model.predict(img_array)\r\nscore = tf.nn.softmax(predictions[0])\r\n\r\nprint(\r\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\r\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\r\n)\r\n\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n\r\n\r\n\r\n\"\"\" ... \"\"\"\r\n\"\"\"Creates the metadata for an image classifier.\"\"\"\r\n\r\n# Creates model info.\r\nmodel_meta = _metadata_fb.ModelMetadataT()\r\nmodel_meta.name = \"MobileNetV1 image classifier\"\r\nmodel_meta.description = (\"Identify the most prominent object in the \"\r\n                          \"image from a set of 1,001 categories such as \"\r\n                          \"trees, animals, food, vehicles, person etc.\")\r\nmodel_meta.version = \"v1\"\r\nmodel_meta.author = \"TensorFlow\"\r\nmodel_meta.license = (\"Apache License. Version 2.0 \"\r\n                      \"http://www.apache.org/licenses/LICENSE-2.0.\")\r\n\r\n# Creates input info.\r\ninput_meta = _metadata_fb.TensorMetadataT()\r\n# Creates output info.\r\noutput_meta = _metadata_fb.TensorMetadataT()\r\n\r\ninput_meta.name = \"image\"\r\ninput_meta.description = (\r\n    \"Input image to be classified. The expected image is {0} x {1}, with \"\r\n    \"three channels (red, blue, and green) per pixel. Each value in the \"\r\n    \"tensor is a single byte between 0 and 255.\".format(160, 160))\r\ninput_meta.content = _metadata_fb.ContentT()\r\ninput_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\r\ninput_meta.content.contentProperties.colorSpace = (\r\n    _metadata_fb.ColorSpaceType.RGB)\r\ninput_meta.content.contentPropertiesType = (\r\n    _metadata_fb.ContentProperties.ImageProperties)\r\ninput_normalization = _metadata_fb.ProcessUnitT()\r\ninput_normalization.optionsType = (\r\n    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\r\ninput_normalization.options = _metadata_fb.NormalizationOptionsT()\r\ninput_normalization.options.mean = [127.5]\r\ninput_normalization.options.std = [127.5]\r\ninput_meta.processUnits = [input_normalization]\r\ninput_stats = _metadata_fb.StatsT()\r\ninput_stats.max = [255]\r\ninput_stats.min = [0]\r\ninput_meta.stats = input_stats\r\n\r\n# Creates output info.\r\noutput_meta = _metadata_fb.TensorMetadataT()\r\noutput_meta.name = \"probability\"\r\noutput_meta.description = \"Probabilities of the 1001 labels respectively.\"\r\noutput_meta.content = _metadata_fb.ContentT()\r\noutput_meta.content.content_properties = _metadata_fb.FeaturePropertiesT()\r\noutput_meta.content.contentPropertiesType = (\r\n    _metadata_fb.ContentProperties.FeatureProperties)\r\noutput_stats = _metadata_fb.StatsT()\r\noutput_stats.max = [1.0]\r\noutput_stats.min = [0.0]\r\noutput_meta.stats = output_stats\r\nlabel_file = _metadata_fb.AssociatedFileT()\r\nlabel_file.name = os.path.basename(\"/MachineLearning/TensorFlow/Label.txt\")\r\nlabel_file.description = \"Labels for objects that the model can recognize.\"\r\nlabel_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\r\noutput_meta.associatedFiles = [label_file]\r\n\r\n# Creates subgraph info.\r\nsubgraph = _metadata_fb.SubGraphMetadataT()\r\nsubgraph.inputTensorMetadata = [input_meta]\r\nsubgraph.outputTensorMetadata = [output_meta]\r\nmodel_meta.subgraphMetadata = [subgraph]\r\n\r\nb = flatbuffers.Builder(0)\r\nb.Finish(\r\n    model_meta.Pack(b),\r\n    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\r\nmetadata_buf = b.Output()\r\n\r\npopulator = _metadata.MetadataPopulator.with_model_file(\"model.tflite\")\r\npopulator.load_metadata_buffer(metadata_buf)\r\npopulator.load_associated_files([\"/MachineLearning/TensorFlow/Label.txt\"])\r\npopulator.populate()\r\n\r\n# **Android Code**:\r\nval model = Model.newInstance(this)\r\nval bitmap: Bitmap =\r\nBitmapFactory.decodeResource(resources, R.drawable.image)\r\n// Creates inputs for reference.\r\nval image = TensorImage.fromBitmap(bitmap)\r\n\r\n// Runs model inference and gets result.\r\nval outputs = model.process(image)\r\nval probability = outputs.probabilityAsCategoryList\r\n\r\n// Releases model resources if no longer used.\r\nmodel.close()\r\n\r\n val outputsProbability = probability.apply {\r\n        sortByDescending { it.score } // Sort with highest confidence first\r\n    }.take(5)\r\n\r\n    val items = mutableListOf<Recognition>()\r\n    for (output in outputsProbability) {\r\n        items.add(Recognition(output.label, output.score))\r\n    }\r\n\r\n    Log.d(\"propability\", items.toString())\r\n", "@spadiyar67 ,\r\n\r\nOn executing the given code, I am facing an error. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/0dcae8fbfd711e9dc58213b703de4166/49893.ipynb) and share all dependencies to replicate the issue or share a colab gist with the reported error.\r\n\r\nThanks!\r\n", "@tilakrayal \r\nI have uploaded all the necessary files and now able to create the tflite file in the colab . could you please give a try and check the probability in both the platform.\r\n\r\nIf you see same error  then create \"Label.txt\" file and add  below labels inside the file .\r\ndaisy\r\ndandelion\r\nroses\r\nsunflowers\r\ntulips\r\n\r\nyou can use the below link also for the Label.txt file,\r\nhttps://drive.google.com/file/d/1IsuPh1VNFKWow1CHpyovnsWNfvhkzy44/view?usp=sharing\r\n", "@spadiyar67 ,\r\n\r\nThe code provided is fairly complex and indentation errors hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro?  Please share the colab link.That will allow us to determine the source of the issue easily. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49893\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49893\">No</a>\n"]}, {"number": 49892, "title": "[MLIR][DISC] pattern conversion from tf2mhlo: ConvertTileOpDynamic", "body": "We are porting our MLIR-based dynamic shape compiler to tf community (From OP def, Patttern, to Optimization pass, etc).\r\nThis is the 4th PR about tf2mhlo pattern conversion, which including ConvertTileOpDynamic.\r\nThe rest pattern conversions we will add:\r\n- ConvertSqueezeOpxxx\r\n- ConvertStridedSliceOpxxx\r\n- ConvertUnpackOpxxx\r\n- ConvertPrintOp\r\n- ConvertSigmoidGradOpxxx\r\n- ConvertSignOpxxx\r\n", "comments": ["@azazhu  Can you please resolve conflicts? Thanks!", "> @azazhu Can you please resolve conflicts? Thanks!\r\n\r\nSure, I will resolve this conflict after https://github.com/tensorflow/tensorflow/pull/49919 merged.", "> > @azazhu Can you please resolve conflicts? Thanks!\r\n> \r\n> Sure, I will resolve this conflict after #49919 merged.\r\n\r\nRebased"]}, {"number": 49891, "title": "TensorflowJS Issue : Looking for previous version of cusolver64_10", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlowJS version: 3.6.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: RTX 2060 MAXQ\r\n**Describe the problem**\r\nGPU build is looking for cusolver64_10 instead of latest cusolver64_11 version", "comments": ["@fireholster ,\r\n\r\nIssues related to TensorflowJS are tracked in tensorflow/tfjs repo.\r\n\r\nCould you please submit a new issue using [this link](https://github.com/tensorflow/tfjs/issues) and fill in the template, so that the issue can be tracked there. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49891\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49891\">No</a>\n", "sure let me open it there\r\n", "@fireholster ,\r\n\r\nPlease feel free to move this issue to closed status, if new issue was submitted in tfjs repo  so that we can track the issue there. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49891\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49891\">No</a>\n", "moved it to tensorflow/tfjs reo"]}, {"number": 49890, "title": "Documentation for Model.trainable_weights is missing", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model\r\n\r\n## Description of issue (what needs changing): \r\n**`model.trainable_weights`** returns the **`Weights`** and **`Biases`** of all the **`Layers`** of the **`Model`**. Documentation to that function is missing in [Tensorflow.org](https://www.tensorflow.org/api_docs/python/tf/keras/Model).", "comments": ["@worldpeaceaspirer `trainable_weights` is the property of `tf.keras.layers.Layer` class, which is the super class of `tf.keras.models` and that's why you can call it using `model.trainable_weights`. \r\nThe property is listed in the documentation's attribute section at this link : [tensorflow.org](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) \r\n\r\nhope this helps \ud83d\ude00.", "@worldpeaceaspirer \r\n\r\nCould you please check the above comment and let us know if it helps.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tusharvickey1999,\r\nThank you for your response but still the **documentation** on what exactly **`model.trainable_weights`** or **`layer.trainable_weights`** does and what does that **`function`** **`Return`**, is missing. ", "@worldpeaceaspirer it's is stated under the attribute that it gets you list of all the trainable_weights/variables for the layer/model.", "@worldpeaceaspirer You may want to refer usage examples listed on the same page https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#examples\r\nExample 1 and 3 talks about implementing  `trainable_weights` and `non_trainable_weights`", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @tusharvickey1999,\r\n> Thank you for your response but still the **documentation** on what exactly **`model.trainable_weights`** or **`layer.trainable_weights`** does and what does that **`function`** **`Return`**, is missing.\r\n\r\nI think mentioning **`List of Weights and Biases`** makes more sense than mentioning **`List of Variables`**, for better clarity.", "> > @tusharvickey1999,\n> > Thank you for your response but still the **documentation** on what exactly **`model.trainable_weights`** or **`layer.trainable_weights`** does and what does that **`function`** **`Return`**, is missing.\n> \n> I think mentioning **`List of Weights and Biases`** makes more sense than mentioning **`List of Variables`**, for better clarity.\n\nIn a deep neural network, we have weights, biases and several other variable which cannot be classified as weights/biases. therefore we collectively call all those parameter as variable of the network. for eg. batch normalisation has variable which can be learned but it is not weight/bias.\nhopefully this answers your query.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 49888, "title": "Validate that a and b are proper sparse tensors", "body": "PiperOrigin-RevId: 373248068\nChange-Id: I0a2041a0747901b3f00387a6a3bce9bca6b0b3b1", "comments": []}, {"number": 49887, "title": "Validate that a and b are proper sparse tensors", "body": "PiperOrigin-RevId: 373248068\nChange-Id: I0a2041a0747901b3f00387a6a3bce9bca6b0b3b1", "comments": []}, {"number": 49886, "title": "Validate that a and b are proper sparse tensors", "body": "PiperOrigin-RevId: 373248068\nChange-Id: I0a2041a0747901b3f00387a6a3bce9bca6b0b3b1", "comments": []}, {"number": 49885, "title": "Validate that a and b are proper sparse tensors", "body": "PiperOrigin-RevId: 373248068\nChange-Id: I0a2041a0747901b3f00387a6a3bce9bca6b0b3b1", "comments": []}, {"number": 49884, "title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`", "body": "PiperOrigin-RevId: 373244623\nChange-Id: I2d6cbbc8c67b238a8815bf58097f7586d87c54f2", "comments": []}, {"number": 49883, "title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`", "body": "PiperOrigin-RevId: 373244623\nChange-Id: I2d6cbbc8c67b238a8815bf58097f7586d87c54f2", "comments": []}, {"number": 49882, "title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`", "body": "PiperOrigin-RevId: 373244623\nChange-Id: I2d6cbbc8c67b238a8815bf58097f7586d87c54f2", "comments": []}, {"number": 49881, "title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`", "body": "PiperOrigin-RevId: 373244623\nChange-Id: I2d6cbbc8c67b238a8815bf58097f7586d87c54f2", "comments": []}, {"number": 49880, "title": "Prevent memory overflow in ParseAttrValue from nested tensors.", "body": "PiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889", "comments": []}, {"number": 49879, "title": "Prevent memory overflow in ParseAttrValue from nested tensors.", "body": "PiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889", "comments": []}, {"number": 49878, "title": "Prevent memory overflow in ParseAttrValue from nested tensors.", "body": "PiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889", "comments": []}, {"number": 49877, "title": "Prevent memory overflow in ParseAttrValue from nested tensors.", "body": "PiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889", "comments": []}, {"number": 49876, "title": "Fix crash with tf.transpose when a is complex and conjugate is True", "body": "", "comments": []}, {"number": 49875, "title": "Fix crash with tf.transpose when a is complex and conjugate is True", "body": "", "comments": []}, {"number": 49874, "title": "Fix crash with tf.transpose when a is complex and conjugate is True", "body": "", "comments": []}, {"number": 49873, "title": "Fix crash with tf.transpose when a is complex and conjugate is True", "body": "", "comments": []}, {"number": 49872, "title": "Allow `keras.utils.Sequence` sub-classes to use sparse/ragged tensors", "body": "This adjusts the way `GeneratorDataAdapter` supplies the shapes and types of tensors from the first (peeked) batch when converting from a generator to a `Dataset`, in order to allow sub-classes of `keras.utils.Sequence` to return `SparseTensors` or `RaggedTensors` in batches.\r\n\r\nResolves #41419.\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49872) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@nluehr Here's the PR for the change related to downstream issues in [NVTabular](https://github.com/NVIDIA/NVTabular). Thanks for your help!", "@karlhigley  Please submit this PR to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thankyou.\r\n@fchollet, @qlzh727, @tomerk", "@karlhigley  Any update on this PR? Please. Thanks!\r\n", "@gbaned Resubmitted as keras-team/keras#15264.", "Closing this PR since it is summited to keras-team/keras#15264.  Thank you!"]}, {"number": 49871, "title": "Added tensorflow medium", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49871) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 49870, "title": "TF lite issue", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, LOGISTIC, MAX_POOL_2D. Here is a list of operators for which you will need custom implementations: IdentityN.\r\nTraceback (most recent call last):\r\n  File \"/home/skycope/venv_py36_gen/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/skycope/venv_py36_gen/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/skycope/venv_py36_gen/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/skycope/venv_py36_gen/lib/python3.6/site-packages/absl/app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"/home/skycope/venv_py36_gen/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/skycope/venv_py36_gen/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, LOGISTIC, MAX_POOL_2D. Here is a list of operators for which you will need custom implementations: IdentityN.\r\n", "comments": ["Please consider using the Select TF op option. The above `IdentityN` operator can be supported through it.\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select"]}, {"number": 49869, "title": "failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error : Ubuntu 20.04.2, RTX 2070 SUPER GPU ", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.7.10\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: NVIDIA Corporation TU104 [GeForce RTX 2070 SUPER] / 8GB\r\n\r\nI have been receiving the \"E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\"  for running the simplest tensorflow command of creating a constant. The commanf execute successfuly, but I could see tensorflow using only CPU for this. I have also checked this by a running a simple script that comapres the time of execution of a compute problem between GPU and CPU in which case same error message and also the time of computation for both CPU and GPU came out to be same. I feel tensorflow is not able to detect the GPU in this system.\r\nThe tensorflow and CUDA installation were based on the instructions provided in this link \"https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local\" which are follows,\r\n1. wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\r\n2. sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\n3. wget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.debsudo dpkg -i cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb\r\n4. sudo apt-key add /var/cuda-repo-ubuntu2004-11-3-local/7fa2af80.pub\r\n5. sudo apt-get update\r\n6. sudo apt-get -y install cuda\r\n\r\nI have used the following instructions to install cudnn,\r\n1.sudo dpkg -i libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb\r\n2. sudo dpkg -i libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb\r\n\r\nFollowing is the snapshot of output I get from creating the tensorflow constant variable,\r\n\r\n(tkeras) smart@smart-B460MDS3H:/usr/local$ python\r\nPython 3.7.10 (default, Feb 26 2021, 18:47:35) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-05-29 10:47:51.427226: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n>>> a = tf.constant(20)\r\n2021-05-29 10:47:55.936327: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-05-29 10:47:55.959954: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\r\n2021-05-29 10:47:55.959977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: smart-B460MDS3H\r\n2021-05-29 10:47:55.959982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: smart-B460MDS3H\r\n2021-05-29 10:47:55.960023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.73.1\r\n2021-05-29 10:47:55.960041: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.73.1\r\n2021-05-29 10:47:55.960046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.73.1\r\n2021-05-29 10:47:55.960242: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n>>> tf.__version__\r\n'2.5.0'\r\n\r\nI am also attaching the gpu versus cpu time comparison script with this issue.\r\n[tempScript.txt](https://github.com/tensorflow/tensorflow/files/6562795/tempScript.txt)\r\n\r\n", "comments": ["Please try with cuda 11.2 for TF 2.5\r\nSee https://www.tensorflow.org/install/source#gpu", "Should I try directly the binaries or build from source is the only option.", "TF 2.5 binaries support 11.2. You can use pip packages.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49869\">No</a>\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49869\">No</a>\n"]}, {"number": 49868, "title": "Made rounding in convert_image_dtype for numbers close to zero", "body": "Fixes #48701", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49868) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49868) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49868) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49868) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49868) for more info**.\n\n<!-- need_author_cla -->", "@pointhex can you please check build failures ?", "> @pointhex can you please check build failures ?\r\n\r\nHi, I will try to do it by the end of the next week. I have and will have a bit busy week. is it ok?", "Hi @kkimdev, @rthadur,\r\nI see that tests, that I've broked, are fixed now. \r\nBut for Linux GPU and copybara links are broken for me.\r\nAbout Windows Bazel GPU, looks like some infrastructure error.\r\nCould you check plz or tell me what I should do with that?", "Here are the internal errors, @pointhex can you please verify ? Thanks!\r\n\r\nTraceback (most recent call last):\r\n  File \"/tensorflow/python/ops/image_ops_test.py\", line 4648, in testConvertBetweenFloat32AndInt8SmallNumbers\r\n    self.assertEqual(x0.numpy(), 0)\r\n  File \"/tensorflow/python/framework/ops.py\", line 402, in __getattr__\r\n    self.__getattribute__(name)\r\nAttributeError: 'Tensor' object has no attribute 'numpy'", "> Here are the internal errors, @pointhex can you please verify ? Thanks!\r\n> \r\n> Traceback (most recent call last):\r\n> File \"/tensorflow/python/ops/image_ops_test.py\", line 4648, in testConvertBetweenFloat32AndInt8SmallNumbers\r\n> self.assertEqual(x0.numpy(), 0)\r\n> File \"/tensorflow/python/framework/ops.py\", line 402, in **getattr**\r\n> self.**getattribute**(name)\r\n> AttributeError: 'Tensor' object has no attribute 'numpy'\r\n\r\nHi @gbaned,\r\nI did it another way. Hope it will help.", "Here are the internal errors, @pointhex can you please verify ? also can you please address  pylint errors ? Thanks!\r\n\r\nTraceback (most recent call last):\r\n  File \"/tensorflow/python/ops/image_ops_test.py\", line 918, in testHalfSaturation\r\n    self.assertAllEqual(y_tf, y_np)\r\n  File \"/tensorflow/python/framework/test_util.py\", line 1275, in decorated\r\n    return f(*args, **kwds)\r\n  File \"/tensorflow/python/framework/test_util.py\", line 2976, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=\"\\n\".join(msgs))\r\n  File \"/py/numpy/testing/_private/utils.py\", line 931, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"/py/numpy/testing/_private/utils.py\", line 840, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nArrays are not equal\r\n\r\nnot equal where = (array([0, 1]), array([1, 0]), array([1, 0]))\r\nnot equal lhs = array([180, 136], dtype=uint8)\r\nnot equal rhs = array([181, 135], dtype=uint8)\r\nMismatched elements: 2 / 12 (16.7%)\r\nMax absolute difference: 255\r\nMax relative difference: 1.40883978\r\n x: array([[[  7,   9,  13],\r\n        [140, 180, 226]],\r\n...\r\n y: array([[[  7,   9,  13],\r\n        [140, 181, 226]],\r\n...", "> Here are the internal errors, @pointhex can you please verify ? also can you please address pylint errors ? Thanks!\r\n> \r\n> Traceback (most recent call last):\r\n> File \"/tensorflow/python/ops/image_ops_test.py\", line 918, in testHalfSaturation\r\n> self.assertAllEqual(y_tf, y_np)\r\n> File \"/tensorflow/python/framework/test_util.py\", line 1275, in decorated\r\n> return f(*args, **kwds)\r\n> File \"/tensorflow/python/framework/test_util.py\", line 2976, in assertAllEqual\r\n> np.testing.assert_array_equal(a, b, err_msg=\"\\n\".join(msgs))\r\n> File \"/py/numpy/testing/_private/utils.py\", line 931, in assert_array_equal\r\n> verbose=verbose, header='Arrays are not equal')\r\n> File \"/py/numpy/testing/_private/utils.py\", line 840, in assert_array_compare\r\n> raise AssertionError(msg)\r\n> AssertionError:\r\n> Arrays are not equal\r\n> \r\n> not equal where = (array([0, 1]), array([1, 0]), array([1, 0]))\r\n> not equal lhs = array([180, 136], dtype=uint8)\r\n> not equal rhs = array([181, 135], dtype=uint8)\r\n> Mismatched elements: 2 / 12 (16.7%)\r\n> Max absolute difference: 255\r\n> Max relative difference: 1.40883978\r\n> x: array([[[ 7, 9, 13],\r\n> [140, 180, 226]],\r\n> ...\r\n> y: array([[[ 7, 9, 13],\r\n> [140, 181, 226]],\r\n> ...\r\n\r\nThe main problem is that I changed that for CPU from 135 to 136 but for some reason on GPU it computes as 135. The same for 180, 180 works for CPU, 181 works for GPU. @gbaned Could you tell me if you have some ideas on how I can fix that? ", "@kkimdev Can you please assist on above comments from @pointhex. Thanks!", "I guess the test was affected by your `convert_image_dtype` change, could you try printing intermediate values in your changes using `tf.print` and compare CPU and GPU?", "> I guess the test was affected by your `convert_image_dtype` change, could you try printing intermediate values in your changes using `tf.print` and compare CPU and GPU?\r\n\r\nI'm sure that it because of my change:) I will try to do it by print. But still, it strange a bit. Maybe, floating-point arithmetic shows some differences.", "@pointhex  Any update on this PR? Please. Thanks!", "> @pointhex Any update on this PR? Please. Thanks!\r\n\r\nUnfortunately, I don't have. I tried to set up a build on my machine for GPU. But it still doesn't work. I will be on vacation for 2 weeks. So this time I will not have time for work on this commit( So if it hot and can't wait for me. So someone can finish it.\r\nI still think that it is some CPU and GPU computing problem.", "@kkimdev Can you please assist on above comments from @pointhex. Thanks!", "> @kkimdev Can you please assist on above comments from @pointhex. Thanks!\r\n\r\nI'm working on the problem. I managed to install cuda, but getting some errors during builds. Hope it will be solved. And I will check on my machine.", "Checked with cuda. \r\nUsed two commands:\r\nbazel test --config=cuda --repo_env=CC=clang-12  //tensorflow/python:image_ops_test\r\nbazel test --repo_env=CC=clang-12  //tensorflow/python:image_ops_test\r\nand now tests passes. \r\nIs it right way?", "@kkimdev Could you please approve it?"]}]