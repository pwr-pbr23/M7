[{"number": 13838, "title": "optimize_for_inference - KeyError", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yUP.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Elementary OS 0.4 Loki\r\n- **TensorFlow installed from (source or binary)**: ```pip install tensorflow```\r\n- **TensorFlow version (use command below)**: ```('v1.3.0-rc2-20-g0787eee', '1.3.0')```\r\n- **Python version**: 2.7.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.5\r\n- **GPU model and memory**: NVIDIA GTX 1060 - 6GB \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nExperiencing a strange KeyError whilst attempting to optimize graph.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/keo7/Projects/AgriDoctorAlpha/model/keras/main.py\", line 126, in <module>\r\n    export_model(tf.train.Saver(), model, [\"input_1\"], \"dense_3/kernel\")\r\n  File \"/home/keo7/Projects/AgriDoctorAlpha/model/keras/main.py\", line 115, in export_model\r\n    tf.float32.as_datatype_enum)\r\n  File \"/home/keo7/.virtualenvs/deeplearning/local/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py\", line 109, in optimize_for_inference\r\n    placeholder_type_enum)\r\n  File \"/home/keo7/.virtualenvs/deeplearning/local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py\", line 83, in strip_unused\r\n    raise KeyError(\"The following input nodes were not found: %s\\n\" % not_found)\r\nKeyError: \"The following input nodes were not found: set(['input_1'])\\n\"\r\n```\r\n\r\n### Source code / logs\r\n\r\n```python\r\noutput_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n            input_graph_def, [\"input_1\"], [\"dense_3/kernel\"]\r\n            tf.float32.as_datatype_enum)\r\n```\r\n\r\nGraph:\r\n\r\n```\r\nnode {\r\n  name: \"input_1\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 48\r\n        }\r\n        dim {\r\n          size: 48\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0997509360313\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0997509360313\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block1_conv1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 4107740\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block1_conv1/random_uniform/max\"\r\n  input: \"block1_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block1_conv1/random_uniform/RandomUniform\"\r\n  input: \"block1_conv1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block1_conv1/random_uniform/mul\"\r\n  input: \"block1_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/kernel\"\r\n  input: \"block1_conv1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block1_conv1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 64\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/bias\"\r\n  input: \"block1_conv1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block1_conv1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"input_1\"\r\n  input: \"block1_conv1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block1_conv1/convolution\"\r\n  input: \"block1_conv1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block1_conv1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000@\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0721687823534\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0721687823534\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block1_conv2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 9992257\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block1_conv2/random_uniform/max\"\r\n  input: \"block1_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block1_conv2/random_uniform/RandomUniform\"\r\n  input: \"block1_conv2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block1_conv2/random_uniform/mul\"\r\n  input: \"block1_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/kernel\"\r\n  input: \"block1_conv2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block1_conv2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 64\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/bias\"\r\n  input: \"block1_conv2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block1_conv2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000@\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block1_conv1/Relu\"\r\n  input: \"block1_conv2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block1_conv2/convolution\"\r\n  input: \"block1_conv2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_conv2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block1_conv2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block1_pool/MaxPool\"\r\n  op: \"MaxPool\"\r\n  input: \"block1_conv2/Relu\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ksize\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"VALID\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\\200\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0589255653322\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0589255653322\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block2_conv1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 6910695\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block2_conv1/random_uniform/max\"\r\n  input: \"block2_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block2_conv1/random_uniform/RandomUniform\"\r\n  input: \"block2_conv1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block2_conv1/random_uniform/mul\"\r\n  input: \"block2_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/kernel\"\r\n  input: \"block2_conv1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block2_conv1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 128\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/bias\"\r\n  input: \"block2_conv1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block2_conv1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\\200\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block1_pool/MaxPool\"\r\n  input: \"block2_conv1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block2_conv1/convolution\"\r\n  input: \"block2_conv1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block2_conv1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\200\\000\\000\\000\\200\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0510310381651\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0510310381651\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block2_conv2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 7708517\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block2_conv2/random_uniform/max\"\r\n  input: \"block2_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block2_conv2/random_uniform/RandomUniform\"\r\n  input: \"block2_conv2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block2_conv2/random_uniform/mul\"\r\n  input: \"block2_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/kernel\"\r\n  input: \"block2_conv2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block2_conv2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 128\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/bias\"\r\n  input: \"block2_conv2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block2_conv2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\200\\000\\000\\000\\200\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block2_conv1/Relu\"\r\n  input: \"block2_conv2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block2_conv2/convolution\"\r\n  input: \"block2_conv2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_conv2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block2_conv2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block2_pool/MaxPool\"\r\n  op: \"MaxPool\"\r\n  input: \"block2_conv2/Relu\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ksize\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"VALID\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\200\\000\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0416666679084\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0416666679084\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block3_conv1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 8232814\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block3_conv1/random_uniform/max\"\r\n  input: \"block3_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block3_conv1/random_uniform/RandomUniform\"\r\n  input: \"block3_conv1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block3_conv1/random_uniform/mul\"\r\n  input: \"block3_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/kernel\"\r\n  input: \"block3_conv1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 256\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/bias\"\r\n  input: \"block3_conv1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\200\\000\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block2_pool/MaxPool\"\r\n  input: \"block3_conv1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block3_conv1/convolution\"\r\n  input: \"block3_conv1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block3_conv1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0360843911767\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0360843911767\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block3_conv2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 7964615\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block3_conv2/random_uniform/max\"\r\n  input: \"block3_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block3_conv2/random_uniform/RandomUniform\"\r\n  input: \"block3_conv2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block3_conv2/random_uniform/mul\"\r\n  input: \"block3_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/kernel\"\r\n  input: \"block3_conv2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 256\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/bias\"\r\n  input: \"block3_conv2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block3_conv1/Relu\"\r\n  input: \"block3_conv2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block3_conv2/convolution\"\r\n  input: \"block3_conv2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block3_conv2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0360843911767\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0360843911767\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block3_conv3/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 6435287\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block3_conv3/random_uniform/max\"\r\n  input: \"block3_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block3_conv3/random_uniform/RandomUniform\"\r\n  input: \"block3_conv3/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block3_conv3/random_uniform/mul\"\r\n  input: \"block3_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/kernel\"\r\n  input: \"block3_conv3/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv3/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 256\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/bias\"\r\n  input: \"block3_conv3/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block3_conv3/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block3_conv2/Relu\"\r\n  input: \"block3_conv3/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block3_conv3/convolution\"\r\n  input: \"block3_conv3/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_conv3/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block3_conv3/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block3_pool/MaxPool\"\r\n  op: \"MaxPool\"\r\n  input: \"block3_conv3/Relu\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ksize\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"VALID\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0294627826661\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0294627826661\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block4_conv1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 215528\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block4_conv1/random_uniform/max\"\r\n  input: \"block4_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block4_conv1/random_uniform/RandomUniform\"\r\n  input: \"block4_conv1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block4_conv1/random_uniform/mul\"\r\n  input: \"block4_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/kernel\"\r\n  input: \"block4_conv1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/bias\"\r\n  input: \"block4_conv1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\001\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block3_pool/MaxPool\"\r\n  input: \"block4_conv1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block4_conv1/convolution\"\r\n  input: \"block4_conv1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block4_conv1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block4_conv2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 5791903\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block4_conv2/random_uniform/max\"\r\n  input: \"block4_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block4_conv2/random_uniform/RandomUniform\"\r\n  input: \"block4_conv2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block4_conv2/random_uniform/mul\"\r\n  input: \"block4_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/kernel\"\r\n  input: \"block4_conv2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/bias\"\r\n  input: \"block4_conv2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block4_conv1/Relu\"\r\n  input: \"block4_conv2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block4_conv2/convolution\"\r\n  input: \"block4_conv2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block4_conv2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block4_conv3/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 6240709\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block4_conv3/random_uniform/max\"\r\n  input: \"block4_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block4_conv3/random_uniform/RandomUniform\"\r\n  input: \"block4_conv3/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block4_conv3/random_uniform/mul\"\r\n  input: \"block4_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/kernel\"\r\n  input: \"block4_conv3/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv3/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/bias\"\r\n  input: \"block4_conv3/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block4_conv3/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block4_conv2/Relu\"\r\n  input: \"block4_conv3/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block4_conv3/convolution\"\r\n  input: \"block4_conv3/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_conv3/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block4_conv3/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block4_pool/MaxPool\"\r\n  op: \"MaxPool\"\r\n  input: \"block4_conv3/Relu\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ksize\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"VALID\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block5_conv1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 7151531\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block5_conv1/random_uniform/max\"\r\n  input: \"block5_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block5_conv1/random_uniform/RandomUniform\"\r\n  input: \"block5_conv1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block5_conv1/random_uniform/mul\"\r\n  input: \"block5_conv1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/kernel\"\r\n  input: \"block5_conv1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/bias\"\r\n  input: \"block5_conv1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block4_pool/MaxPool\"\r\n  input: \"block5_conv1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block5_conv1/convolution\"\r\n  input: \"block5_conv1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block5_conv1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block5_conv2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 4344407\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block5_conv2/random_uniform/max\"\r\n  input: \"block5_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block5_conv2/random_uniform/RandomUniform\"\r\n  input: \"block5_conv2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block5_conv2/random_uniform/mul\"\r\n  input: \"block5_conv2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/kernel\"\r\n  input: \"block5_conv2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/bias\"\r\n  input: \"block5_conv2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block5_conv1/Relu\"\r\n  input: \"block5_conv2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block5_conv2/convolution\"\r\n  input: \"block5_conv2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block5_conv2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0255155190825\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"block5_conv3/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 3686380\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"block5_conv3/random_uniform/max\"\r\n  input: \"block5_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"block5_conv3/random_uniform/RandomUniform\"\r\n  input: \"block5_conv3/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"block5_conv3/random_uniform/mul\"\r\n  input: \"block5_conv3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/kernel\"\r\n  input: \"block5_conv3/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv3/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 512\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/bias\"\r\n  input: \"block5_conv3/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"block5_conv3/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/convolution/Shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\003\\000\\000\\000\\003\\000\\000\\000\\000\\002\\000\\000\\000\\002\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/convolution/dilation_rate\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/convolution\"\r\n  op: \"Conv2D\"\r\n  input: \"block5_conv2/Relu\"\r\n  input: \"block5_conv3/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"SAME\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_cudnn_on_gpu\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"block5_conv3/convolution\"\r\n  input: \"block5_conv3/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_conv3/Relu\"\r\n  op: \"Relu\"\r\n  input: \"block5_conv3/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"block5_pool/MaxPool\"\r\n  op: \"MaxPool\"\r\n  input: \"block5_conv3/Relu\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ksize\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"padding\"\r\n    value {\r\n      s: \"VALID\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"strides\"\r\n    value {\r\n      list {\r\n        i: 1\r\n        i: 2\r\n        i: 2\r\n        i: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/kernel\"\r\n  input: \"Placeholder\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_1\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_1\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/bias\"\r\n  input: \"Placeholder_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_2\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_2\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/kernel\"\r\n  input: \"Placeholder_2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_3\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 64\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_3\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/bias\"\r\n  input: \"Placeholder_3\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_4\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 64\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_4\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/kernel\"\r\n  input: \"Placeholder_4\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_5\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_5\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/bias\"\r\n  input: \"Placeholder_5\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_6\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_6\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/kernel\"\r\n  input: \"Placeholder_6\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_7\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 128\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_7\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/bias\"\r\n  input: \"Placeholder_7\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_8\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 128\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_8\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/kernel\"\r\n  input: \"Placeholder_8\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_9\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_9\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/bias\"\r\n  input: \"Placeholder_9\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_10\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_10\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/kernel\"\r\n  input: \"Placeholder_10\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_11\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_11\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/bias\"\r\n  input: \"Placeholder_11\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_12\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_12\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/kernel\"\r\n  input: \"Placeholder_12\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_13\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 256\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_13\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/bias\"\r\n  input: \"Placeholder_13\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_14\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 256\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_14\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/kernel\"\r\n  input: \"Placeholder_14\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_15\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_15\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/bias\"\r\n  input: \"Placeholder_15\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_16\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_16\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/kernel\"\r\n  input: \"Placeholder_16\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_17\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_17\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/bias\"\r\n  input: \"Placeholder_17\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_18\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_18\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/kernel\"\r\n  input: \"Placeholder_18\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_19\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_19\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/bias\"\r\n  input: \"Placeholder_19\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_20\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_20\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/kernel\"\r\n  input: \"Placeholder_20\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_21\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_21\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/bias\"\r\n  input: \"Placeholder_21\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_22\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_22\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/kernel\"\r\n  input: \"Placeholder_22\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_23\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_23\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/bias\"\r\n  input: \"Placeholder_23\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_24\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_24\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/kernel\"\r\n  input: \"Placeholder_24\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_25\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Assign_25\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/bias\"\r\n  input: \"Placeholder_25\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"init\"\r\n  op: \"NoOp\"\r\n  input: \"^block1_conv1/kernel/Assign\"\r\n  input: \"^block1_conv1/bias/Assign\"\r\n  input: \"^block1_conv2/kernel/Assign\"\r\n  input: \"^block1_conv2/bias/Assign\"\r\n  input: \"^block2_conv1/kernel/Assign\"\r\n  input: \"^block2_conv1/bias/Assign\"\r\n  input: \"^block2_conv2/kernel/Assign\"\r\n  input: \"^block2_conv2/bias/Assign\"\r\n  input: \"^block3_conv1/kernel/Assign\"\r\n  input: \"^block3_conv1/bias/Assign\"\r\n  input: \"^block3_conv2/kernel/Assign\"\r\n  input: \"^block3_conv2/bias/Assign\"\r\n  input: \"^block3_conv3/kernel/Assign\"\r\n  input: \"^block3_conv3/bias/Assign\"\r\n  input: \"^block4_conv1/kernel/Assign\"\r\n  input: \"^block4_conv1/bias/Assign\"\r\n  input: \"^block4_conv2/kernel/Assign\"\r\n  input: \"^block4_conv2/bias/Assign\"\r\n  input: \"^block4_conv3/kernel/Assign\"\r\n  input: \"^block4_conv3/bias/Assign\"\r\n  input: \"^block5_conv1/kernel/Assign\"\r\n  input: \"^block5_conv1/bias/Assign\"\r\n  input: \"^block5_conv2/kernel/Assign\"\r\n  input: \"^block5_conv2/bias/Assign\"\r\n  input: \"^block5_conv3/kernel/Assign\"\r\n  input: \"^block5_conv3/bias/Assign\"\r\n}\r\nnode {\r\n  name: \"flatten_1/Shape\"\r\n  op: \"Shape\"\r\n  input: \"block5_pool/MaxPool\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"out_type\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/strided_slice/stack\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/strided_slice/stack_1\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/strided_slice/stack_2\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/strided_slice\"\r\n  op: \"StridedSlice\"\r\n  input: \"flatten_1/Shape\"\r\n  input: \"flatten_1/strided_slice/stack\"\r\n  input: \"flatten_1/strided_slice/stack_1\"\r\n  input: \"flatten_1/strided_slice/stack_2\"\r\n  attr {\r\n    key: \"Index\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"begin_mask\"\r\n    value {\r\n      i: 0\r\n    }\r\n  }\r\n  attr {\r\n    key: \"ellipsis_mask\"\r\n    value {\r\n      i: 0\r\n    }\r\n  }\r\n  attr {\r\n    key: \"end_mask\"\r\n    value {\r\n      i: 1\r\n    }\r\n  }\r\n  attr {\r\n    key: \"new_axis_mask\"\r\n    value {\r\n      i: 0\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shrink_axis_mask\"\r\n    value {\r\n      i: 0\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/Prod\"\r\n  op: \"Prod\"\r\n  input: \"flatten_1/strided_slice\"\r\n  input: \"flatten_1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/stack/0\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n        }\r\n        int_val: -1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/stack\"\r\n  op: \"Pack\"\r\n  input: \"flatten_1/stack/0\"\r\n  input: \"flatten_1/Prod\"\r\n  attr {\r\n    key: \"N\"\r\n    value {\r\n      i: 2\r\n    }\r\n  }\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"axis\"\r\n    value {\r\n      i: 0\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"flatten_1/Reshape\"\r\n  op: \"Reshape\"\r\n  input: \"block5_pool/MaxPool\"\r\n  input: \"flatten_1/stack\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tshape\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\000\\002\\000\\000\\000\\004\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0625\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0625\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"dense_1/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 9805962\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"dense_1/random_uniform/max\"\r\n  input: \"dense_1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"dense_1/random_uniform/RandomUniform\"\r\n  input: \"dense_1/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"dense_1/random_uniform/mul\"\r\n  input: \"dense_1/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 512\r\n        }\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_1/kernel\"\r\n  input: \"dense_1/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_1/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 1024\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_1/bias\"\r\n  input: \"dense_1/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_1/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/MatMul\"\r\n  op: \"MatMul\"\r\n  input: \"flatten_1/Reshape\"\r\n  input: \"dense_1/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_a\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_b\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"dense_1/MatMul\"\r\n  input: \"dense_1/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_1/Relu\"\r\n  op: \"Relu\"\r\n  input: \"dense_1/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/keras_learning_phase\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        unknown_rank: true\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/Switch\"\r\n  op: \"Switch\"\r\n  input: \"dropout_1/keras_learning_phase\"\r\n  input: \"dropout_1/keras_learning_phase\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/switch_t\"\r\n  op: \"Identity\"\r\n  input: \"dropout_1/cond/Switch:1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/switch_f\"\r\n  op: \"Identity\"\r\n  input: \"dropout_1/cond/Switch\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/pred_id\"\r\n  op: \"Identity\"\r\n  input: \"dropout_1/keras_learning_phase\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/mul/y\"\r\n  op: \"Const\"\r\n  input: \"^dropout_1/cond/switch_t\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 1.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/mul/Switch\"\r\n  op: \"Switch\"\r\n  input: \"dense_1/Relu\"\r\n  input: \"dropout_1/cond/pred_id\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/Relu\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/mul\"\r\n  op: \"Mul\"\r\n  input: \"dropout_1/cond/mul/Switch:1\"\r\n  input: \"dropout_1/cond/mul/y\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/keep_prob\"\r\n  op: \"Const\"\r\n  input: \"^dropout_1/cond/switch_t\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.5\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/Shape\"\r\n  op: \"Shape\"\r\n  input: \"dropout_1/cond/mul\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"out_type\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform/min\"\r\n  op: \"Const\"\r\n  input: \"^dropout_1/cond/switch_t\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform/max\"\r\n  op: \"Const\"\r\n  input: \"^dropout_1/cond/switch_t\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 1.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"dropout_1/cond/dropout/Shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 4883238\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/max\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/RandomUniform\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/mul\"\r\n  input: \"dropout_1/cond/dropout/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/add\"\r\n  op: \"Add\"\r\n  input: \"dropout_1/cond/dropout/keep_prob\"\r\n  input: \"dropout_1/cond/dropout/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/Floor\"\r\n  op: \"Floor\"\r\n  input: \"dropout_1/cond/dropout/add\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/div\"\r\n  op: \"RealDiv\"\r\n  input: \"dropout_1/cond/mul\"\r\n  input: \"dropout_1/cond/dropout/keep_prob\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/dropout/mul\"\r\n  op: \"Mul\"\r\n  input: \"dropout_1/cond/dropout/div\"\r\n  input: \"dropout_1/cond/dropout/Floor\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/Switch_1\"\r\n  op: \"Switch\"\r\n  input: \"dense_1/Relu\"\r\n  input: \"dropout_1/cond/pred_id\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/Relu\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dropout_1/cond/Merge\"\r\n  op: \"Merge\"\r\n  input: \"dropout_1/cond/Switch_1\"\r\n  input: \"dropout_1/cond/dropout/mul\"\r\n  attr {\r\n    key: \"N\"\r\n    value {\r\n      i: 2\r\n    }\r\n  }\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\000\\004\\000\\000\\000\\004\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0541265867651\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0541265867651\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"dense_2/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 3506239\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"dense_2/random_uniform/max\"\r\n  input: \"dense_2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"dense_2/random_uniform/RandomUniform\"\r\n  input: \"dense_2/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"dense_2/random_uniform/mul\"\r\n  input: \"dense_2/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 1024\r\n        }\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_2/kernel\"\r\n  input: \"dense_2/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_2/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 1024\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_2/bias\"\r\n  input: \"dense_2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_2/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/MatMul\"\r\n  op: \"MatMul\"\r\n  input: \"dropout_1/cond/Merge\"\r\n  input: \"dense_2/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_a\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_b\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"dense_2/MatMul\"\r\n  input: \"dense_2/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_2/Relu\"\r\n  op: \"Relu\"\r\n  input: \"dense_2/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/shape\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\000\\004\\000\\000\\n\\000\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/min\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: -0.0761755108833\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/max\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0761755108833\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/RandomUniform\"\r\n  op: \"RandomUniform\"\r\n  input: \"dense_3/random_uniform/shape\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed\"\r\n    value {\r\n      i: 87654321\r\n    }\r\n  }\r\n  attr {\r\n    key: \"seed2\"\r\n    value {\r\n      i: 1428162\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/sub\"\r\n  op: \"Sub\"\r\n  input: \"dense_3/random_uniform/max\"\r\n  input: \"dense_3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform/mul\"\r\n  op: \"Mul\"\r\n  input: \"dense_3/random_uniform/RandomUniform\"\r\n  input: \"dense_3/random_uniform/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/random_uniform\"\r\n  op: \"Add\"\r\n  input: \"dense_3/random_uniform/mul\"\r\n  input: \"dense_3/random_uniform/min\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/kernel\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 1024\r\n        }\r\n        dim {\r\n          size: 10\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/kernel/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_3/kernel\"\r\n  input: \"dense_3/random_uniform\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/kernel/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_3/kernel\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 10\r\n          }\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/bias\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 10\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/bias/Assign\"\r\n  op: \"Assign\"\r\n  input: \"dense_3/bias\"\r\n  input: \"dense_3/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/bias/read\"\r\n  op: \"Identity\"\r\n  input: \"dense_3/bias\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/MatMul\"\r\n  op: \"MatMul\"\r\n  input: \"dense_2/Relu\"\r\n  input: \"dense_3/kernel/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_a\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_b\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"dense_3/MatMul\"\r\n  input: \"dense_3/bias/read\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3/Softmax\"\r\n  op: \"Softmax\"\r\n  input: \"dense_3/BiasAdd\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/iterations/initial_value\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT64\r\n        tensor_shape {\r\n        }\r\n        int64_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/iterations\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/iterations/Assign\"\r\n  op: \"Assign\"\r\n  input: \"SGD/iterations\"\r\n  input: \"SGD/iterations/initial_value\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/iterations\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/iterations/read\"\r\n  op: \"Identity\"\r\n  input: \"SGD/iterations\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/iterations\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/lr/initial_value\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 9.99999974738e-05\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/lr\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/lr/Assign\"\r\n  op: \"Assign\"\r\n  input: \"SGD/lr\"\r\n  input: \"SGD/lr/initial_value\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/lr\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/lr/read\"\r\n  op: \"Identity\"\r\n  input: \"SGD/lr\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/lr\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/momentum/initial_value\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.899999976158\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/momentum\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/momentum/Assign\"\r\n  op: \"Assign\"\r\n  input: \"SGD/momentum\"\r\n  input: \"SGD/momentum/initial_value\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/momentum\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/momentum/read\"\r\n  op: \"Identity\"\r\n  input: \"SGD/momentum\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/momentum\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/decay/initial_value\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/decay\"\r\n  op: \"VariableV2\"\r\n  attr {\r\n    key: \"container\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shared_name\"\r\n    value {\r\n      s: \"\"\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/decay/Assign\"\r\n  op: \"Assign\"\r\n  input: \"SGD/decay\"\r\n  input: \"SGD/decay/initial_value\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/decay\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"SGD/decay/read\"\r\n  op: \"Identity\"\r\n  input: \"SGD/decay\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/decay\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3_target\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"dense_3_sample_weights\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Sum/reduction_indices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n        }\r\n        int_val: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Sum\"\r\n  op: \"Sum\"\r\n  input: \"dense_3/Softmax\"\r\n  input: \"loss/dense_3_loss/Sum/reduction_indices\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/div\"\r\n  op: \"RealDiv\"\r\n  input: \"dense_3/Softmax\"\r\n  input: \"loss/dense_3_loss/Sum\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 1.00000001169e-07\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/sub/x\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 1.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/sub\"\r\n  op: \"Sub\"\r\n  input: \"loss/dense_3_loss/sub/x\"\r\n  input: \"loss/dense_3_loss/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/clip_by_value/Minimum\"\r\n  op: \"Minimum\"\r\n  input: \"loss/dense_3_loss/div\"\r\n  input: \"loss/dense_3_loss/sub\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/clip_by_value\"\r\n  op: \"Maximum\"\r\n  input: \"loss/dense_3_loss/clip_by_value/Minimum\"\r\n  input: \"loss/dense_3_loss/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Log\"\r\n  op: \"Log\"\r\n  input: \"loss/dense_3_loss/clip_by_value\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/mul\"\r\n  op: \"Mul\"\r\n  input: \"dense_3_target\"\r\n  input: \"loss/dense_3_loss/Log\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Sum_1/reduction_indices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n        }\r\n        int_val: 1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Sum_1\"\r\n  op: \"Sum\"\r\n  input: \"loss/dense_3_loss/mul\"\r\n  input: \"loss/dense_3_loss/Sum_1/reduction_indices\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Neg\"\r\n  op: \"Neg\"\r\n  input: \"loss/dense_3_loss/Sum_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Mean/reduction_indices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Mean\"\r\n  op: \"Mean\"\r\n  input: \"loss/dense_3_loss/Neg\"\r\n  input: \"loss/dense_3_loss/Mean/reduction_indices\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/mul_1\"\r\n  op: \"Mul\"\r\n  input: \"loss/dense_3_loss/Mean\"\r\n  input: \"dense_3_sample_weights\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/NotEqual/y\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 0.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/NotEqual\"\r\n  op: \"NotEqual\"\r\n  input: \"dense_3_sample_weights\"\r\n  input: \"loss/dense_3_loss/NotEqual/y\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Cast\"\r\n  op: \"Cast\"\r\n  input: \"loss/dense_3_loss/NotEqual\"\r\n  attr {\r\n    key: \"DstT\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"SrcT\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Const_1\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Mean_1\"\r\n  op: \"Mean\"\r\n  input: \"loss/dense_3_loss/Cast\"\r\n  input: \"loss/dense_3_loss/Const_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/div_1\"\r\n  op: \"RealDiv\"\r\n  input: \"loss/dense_3_loss/mul_1\"\r\n  input: \"loss/dense_3_loss/Mean_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Const_2\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/dense_3_loss/Mean_2\"\r\n  op: \"Mean\"\r\n  input: \"loss/dense_3_loss/div_1\"\r\n  input: \"loss/dense_3_loss/Const_2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/mul/x\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n        }\r\n        float_val: 1.0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"loss/mul\"\r\n  op: \"Mul\"\r\n  input: \"loss/mul/x\"\r\n  input: \"loss/dense_3_loss/Mean_2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/ArgMax/dimension\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n        }\r\n        int_val: -1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/ArgMax\"\r\n  op: \"ArgMax\"\r\n  input: \"dense_3_target\"\r\n  input: \"metrics/acc/ArgMax/dimension\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"output_type\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/ArgMax_1/dimension\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n        }\r\n        int_val: -1\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/ArgMax_1\"\r\n  op: \"ArgMax\"\r\n  input: \"dense_3/Softmax\"\r\n  input: \"metrics/acc/ArgMax_1/dimension\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"output_type\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/Equal\"\r\n  op: \"Equal\"\r\n  input: \"metrics/acc/ArgMax\"\r\n  input: \"metrics/acc/ArgMax_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/Cast\"\r\n  op: \"Cast\"\r\n  input: \"metrics/acc/Equal\"\r\n  attr {\r\n    key: \"DstT\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"SrcT\"\r\n    value {\r\n      type: DT_BOOL\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        int_val: 0\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"metrics/acc/Mean\"\r\n  op: \"Mean\"\r\n  input: \"metrics/acc/Cast\"\r\n  input: \"metrics/acc/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"Tidx\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"keep_dims\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n        }\r\n        string_val: \"model\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/SaveV2/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 36\r\n          }\r\n        }\r\n        string_val: \"SGD/decay\"\r\n        string_val: \"SGD/iterations\"\r\n        string_val: \"SGD/lr\"\r\n        string_val: \"SGD/momentum\"\r\n        string_val: \"block1_conv1/bias\"\r\n        string_val: \"block1_conv1/kernel\"\r\n        string_val: \"block1_conv2/bias\"\r\n        string_val: \"block1_conv2/kernel\"\r\n        string_val: \"block2_conv1/bias\"\r\n        string_val: \"block2_conv1/kernel\"\r\n        string_val: \"block2_conv2/bias\"\r\n        string_val: \"block2_conv2/kernel\"\r\n        string_val: \"block3_conv1/bias\"\r\n        string_val: \"block3_conv1/kernel\"\r\n        string_val: \"block3_conv2/bias\"\r\n        string_val: \"block3_conv2/kernel\"\r\n        string_val: \"block3_conv3/bias\"\r\n        string_val: \"block3_conv3/kernel\"\r\n        string_val: \"block4_conv1/bias\"\r\n        string_val: \"block4_conv1/kernel\"\r\n        string_val: \"block4_conv2/bias\"\r\n        string_val: \"block4_conv2/kernel\"\r\n        string_val: \"block4_conv3/bias\"\r\n        string_val: \"block4_conv3/kernel\"\r\n        string_val: \"block5_conv1/bias\"\r\n        string_val: \"block5_conv1/kernel\"\r\n        string_val: \"block5_conv2/bias\"\r\n        string_val: \"block5_conv2/kernel\"\r\n        string_val: \"block5_conv3/bias\"\r\n        string_val: \"block5_conv3/kernel\"\r\n        string_val: \"dense_1/bias\"\r\n        string_val: \"dense_1/kernel\"\r\n        string_val: \"dense_2/bias\"\r\n        string_val: \"dense_2/kernel\"\r\n        string_val: \"dense_3/bias\"\r\n        string_val: \"dense_3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/SaveV2/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 36\r\n          }\r\n        }\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/SaveV2\"\r\n  op: \"SaveV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/SaveV2/tensor_names\"\r\n  input: \"save/SaveV2/shape_and_slices\"\r\n  input: \"SGD/decay\"\r\n  input: \"SGD/iterations\"\r\n  input: \"SGD/lr\"\r\n  input: \"SGD/momentum\"\r\n  input: \"block1_conv1/bias\"\r\n  input: \"block1_conv1/kernel\"\r\n  input: \"block1_conv2/bias\"\r\n  input: \"block1_conv2/kernel\"\r\n  input: \"block2_conv1/bias\"\r\n  input: \"block2_conv1/kernel\"\r\n  input: \"block2_conv2/bias\"\r\n  input: \"block2_conv2/kernel\"\r\n  input: \"block3_conv1/bias\"\r\n  input: \"block3_conv1/kernel\"\r\n  input: \"block3_conv2/bias\"\r\n  input: \"block3_conv2/kernel\"\r\n  input: \"block3_conv3/bias\"\r\n  input: \"block3_conv3/kernel\"\r\n  input: \"block4_conv1/bias\"\r\n  input: \"block4_conv1/kernel\"\r\n  input: \"block4_conv2/bias\"\r\n  input: \"block4_conv2/kernel\"\r\n  input: \"block4_conv3/bias\"\r\n  input: \"block4_conv3/kernel\"\r\n  input: \"block5_conv1/bias\"\r\n  input: \"block5_conv1/kernel\"\r\n  input: \"block5_conv2/bias\"\r\n  input: \"block5_conv2/kernel\"\r\n  input: \"block5_conv3/bias\"\r\n  input: \"block5_conv3/kernel\"\r\n  input: \"dense_1/bias\"\r\n  input: \"dense_1/kernel\"\r\n  input: \"dense_2/bias\"\r\n  input: \"dense_2/kernel\"\r\n  input: \"dense_3/bias\"\r\n  input: \"dense_3/kernel\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n        type: DT_INT64\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/control_dependency\"\r\n  op: \"Identity\"\r\n  input: \"save/Const\"\r\n  input: \"^save/SaveV2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@save/Const\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"SGD/decay\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2/tensor_names\"\r\n  input: \"save/RestoreV2/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign\"\r\n  op: \"Assign\"\r\n  input: \"SGD/decay\"\r\n  input: \"save/RestoreV2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/decay\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_1/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"SGD/iterations\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_1/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_1\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_1/tensor_names\"\r\n  input: \"save/RestoreV2_1/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_INT64\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_1\"\r\n  op: \"Assign\"\r\n  input: \"SGD/iterations\"\r\n  input: \"save/RestoreV2_1\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/iterations\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_2/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"SGD/lr\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_2/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_2\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_2/tensor_names\"\r\n  input: \"save/RestoreV2_2/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_2\"\r\n  op: \"Assign\"\r\n  input: \"SGD/lr\"\r\n  input: \"save/RestoreV2_2\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/lr\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_3/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"SGD/momentum\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_3/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_3\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_3/tensor_names\"\r\n  input: \"save/RestoreV2_3/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_3\"\r\n  op: \"Assign\"\r\n  input: \"SGD/momentum\"\r\n  input: \"save/RestoreV2_3\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@SGD/momentum\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_4/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block1_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_4/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_4\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_4/tensor_names\"\r\n  input: \"save/RestoreV2_4/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_4\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/bias\"\r\n  input: \"save/RestoreV2_4\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_5/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block1_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_5/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_5\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_5/tensor_names\"\r\n  input: \"save/RestoreV2_5/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_5\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv1/kernel\"\r\n  input: \"save/RestoreV2_5\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_6/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block1_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_6/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_6\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_6/tensor_names\"\r\n  input: \"save/RestoreV2_6/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_6\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/bias\"\r\n  input: \"save/RestoreV2_6\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_7/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block1_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_7/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_7\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_7/tensor_names\"\r\n  input: \"save/RestoreV2_7/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_7\"\r\n  op: \"Assign\"\r\n  input: \"block1_conv2/kernel\"\r\n  input: \"save/RestoreV2_7\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block1_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_8/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block2_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_8/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_8\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_8/tensor_names\"\r\n  input: \"save/RestoreV2_8/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_8\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/bias\"\r\n  input: \"save/RestoreV2_8\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_9/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block2_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_9/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_9\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_9/tensor_names\"\r\n  input: \"save/RestoreV2_9/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_9\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv1/kernel\"\r\n  input: \"save/RestoreV2_9\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_10/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block2_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_10/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_10\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_10/tensor_names\"\r\n  input: \"save/RestoreV2_10/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_10\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/bias\"\r\n  input: \"save/RestoreV2_10\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_11/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block2_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_11/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_11\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_11/tensor_names\"\r\n  input: \"save/RestoreV2_11/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_11\"\r\n  op: \"Assign\"\r\n  input: \"block2_conv2/kernel\"\r\n  input: \"save/RestoreV2_11\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block2_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_12/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_12/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_12\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_12/tensor_names\"\r\n  input: \"save/RestoreV2_12/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_12\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/bias\"\r\n  input: \"save/RestoreV2_12\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_13/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_13/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_13\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_13/tensor_names\"\r\n  input: \"save/RestoreV2_13/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_13\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv1/kernel\"\r\n  input: \"save/RestoreV2_13\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_14/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_14/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_14\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_14/tensor_names\"\r\n  input: \"save/RestoreV2_14/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_14\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/bias\"\r\n  input: \"save/RestoreV2_14\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_15/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_15/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_15\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_15/tensor_names\"\r\n  input: \"save/RestoreV2_15/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_15\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv2/kernel\"\r\n  input: \"save/RestoreV2_15\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_16/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_16/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_16\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_16/tensor_names\"\r\n  input: \"save/RestoreV2_16/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_16\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/bias\"\r\n  input: \"save/RestoreV2_16\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_17/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block3_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_17/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_17\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_17/tensor_names\"\r\n  input: \"save/RestoreV2_17/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_17\"\r\n  op: \"Assign\"\r\n  input: \"block3_conv3/kernel\"\r\n  input: \"save/RestoreV2_17\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block3_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_18/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_18/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_18\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_18/tensor_names\"\r\n  input: \"save/RestoreV2_18/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_18\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/bias\"\r\n  input: \"save/RestoreV2_18\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_19/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_19/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_19\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_19/tensor_names\"\r\n  input: \"save/RestoreV2_19/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_19\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv1/kernel\"\r\n  input: \"save/RestoreV2_19\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_20/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_20/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_20\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_20/tensor_names\"\r\n  input: \"save/RestoreV2_20/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_20\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/bias\"\r\n  input: \"save/RestoreV2_20\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_21/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_21/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_21\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_21/tensor_names\"\r\n  input: \"save/RestoreV2_21/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_21\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv2/kernel\"\r\n  input: \"save/RestoreV2_21\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_22/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_22/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_22\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_22/tensor_names\"\r\n  input: \"save/RestoreV2_22/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_22\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/bias\"\r\n  input: \"save/RestoreV2_22\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_23/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block4_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_23/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_23\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_23/tensor_names\"\r\n  input: \"save/RestoreV2_23/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_23\"\r\n  op: \"Assign\"\r\n  input: \"block4_conv3/kernel\"\r\n  input: \"save/RestoreV2_23\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block4_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_24/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_24/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_24\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_24/tensor_names\"\r\n  input: \"save/RestoreV2_24/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_24\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/bias\"\r\n  input: \"save/RestoreV2_24\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_25/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_25/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_25\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_25/tensor_names\"\r\n  input: \"save/RestoreV2_25/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_25\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv1/kernel\"\r\n  input: \"save/RestoreV2_25\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_26/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_26/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_26\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_26/tensor_names\"\r\n  input: \"save/RestoreV2_26/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_26\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/bias\"\r\n  input: \"save/RestoreV2_26\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_27/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_27/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_27\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_27/tensor_names\"\r\n  input: \"save/RestoreV2_27/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_27\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv2/kernel\"\r\n  input: \"save/RestoreV2_27\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_28/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_28/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_28\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_28/tensor_names\"\r\n  input: \"save/RestoreV2_28/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_28\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/bias\"\r\n  input: \"save/RestoreV2_28\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_29/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"block5_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_29/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_29\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_29/tensor_names\"\r\n  input: \"save/RestoreV2_29/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_29\"\r\n  op: \"Assign\"\r\n  input: \"block5_conv3/kernel\"\r\n  input: \"save/RestoreV2_29\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@block5_conv3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_30/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_1/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_30/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_30\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_30/tensor_names\"\r\n  input: \"save/RestoreV2_30/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_30\"\r\n  op: \"Assign\"\r\n  input: \"dense_1/bias\"\r\n  input: \"save/RestoreV2_30\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_31/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_1/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_31/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_31\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_31/tensor_names\"\r\n  input: \"save/RestoreV2_31/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_31\"\r\n  op: \"Assign\"\r\n  input: \"dense_1/kernel\"\r\n  input: \"save/RestoreV2_31\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_1/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_32/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_2/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_32/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_32\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_32/tensor_names\"\r\n  input: \"save/RestoreV2_32/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_32\"\r\n  op: \"Assign\"\r\n  input: \"dense_2/bias\"\r\n  input: \"save/RestoreV2_32\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_33/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_2/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_33/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_33\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_33/tensor_names\"\r\n  input: \"save/RestoreV2_33/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_33\"\r\n  op: \"Assign\"\r\n  input: \"dense_2/kernel\"\r\n  input: \"save/RestoreV2_33\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_2/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_34/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_3/bias\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_34/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_34\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_34/tensor_names\"\r\n  input: \"save/RestoreV2_34/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_34\"\r\n  op: \"Assign\"\r\n  input: \"dense_3/bias\"\r\n  input: \"save/RestoreV2_34\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/bias\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_35/tensor_names\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"dense_3/kernel\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_35/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/RestoreV2_35\"\r\n  op: \"RestoreV2\"\r\n  input: \"save/Const\"\r\n  input: \"save/RestoreV2_35/tensor_names\"\r\n  input: \"save/RestoreV2_35/shape_and_slices\"\r\n  attr {\r\n    key: \"dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/Assign_35\"\r\n  op: \"Assign\"\r\n  input: \"dense_3/kernel\"\r\n  input: \"save/RestoreV2_35\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_class\"\r\n    value {\r\n      list {\r\n        s: \"loc:@dense_3/kernel\"\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n  attr {\r\n    key: \"validate_shape\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"save/restore_all\"\r\n  op: \"NoOp\"\r\n  input: \"^save/Assign\"\r\n  input: \"^save/Assign_1\"\r\n  input: \"^save/Assign_2\"\r\n  input: \"^save/Assign_3\"\r\n  input: \"^save/Assign_4\"\r\n  input: \"^save/Assign_5\"\r\n  input: \"^save/Assign_6\"\r\n  input: \"^save/Assign_7\"\r\n  input: \"^save/Assign_8\"\r\n  input: \"^save/Assign_9\"\r\n  input: \"^save/Assign_10\"\r\n  input: \"^save/Assign_11\"\r\n  input: \"^save/Assign_12\"\r\n  input: \"^save/Assign_13\"\r\n  input: \"^save/Assign_14\"\r\n  input: \"^save/Assign_15\"\r\n  input: \"^save/Assign_16\"\r\n  input: \"^save/Assign_17\"\r\n  input: \"^save/Assign_18\"\r\n  input: \"^save/Assign_19\"\r\n  input: \"^save/Assign_20\"\r\n  input: \"^save/Assign_21\"\r\n  input: \"^save/Assign_22\"\r\n  input: \"^save/Assign_23\"\r\n  input: \"^save/Assign_24\"\r\n  input: \"^save/Assign_25\"\r\n  input: \"^save/Assign_26\"\r\n  input: \"^save/Assign_27\"\r\n  input: \"^save/Assign_28\"\r\n  input: \"^save/Assign_29\"\r\n  input: \"^save/Assign_30\"\r\n  input: \"^save/Assign_31\"\r\n  input: \"^save/Assign_32\"\r\n  input: \"^save/Assign_33\"\r\n  input: \"^save/Assign_34\"\r\n  input: \"^save/Assign_35\"\r\n}\r\nnode {\r\n  name: \"init_1\"\r\n  op: \"NoOp\"\r\n  input: \"^dense_1/kernel/Assign\"\r\n  input: \"^dense_1/bias/Assign\"\r\n  input: \"^dense_2/kernel/Assign\"\r\n  input: \"^dense_2/bias/Assign\"\r\n  input: \"^dense_3/kernel/Assign\"\r\n  input: \"^dense_3/bias/Assign\"\r\n  input: \"^SGD/iterations/Assign\"\r\n  input: \"^SGD/lr/Assign\"\r\n  input: \"^SGD/momentum/Assign\"\r\n  input: \"^SGD/decay/Assign\"\r\n}\r\nversions {\r\n  producer: 24\r\n}\r\n\r\n```", "comments": ["`KeyError: If any element in input_node_names is not found in the graph.` Tensorflow is unable to find set(['input_1'].\r\nAre you passing  this correctly ? `input_node_names: A list of names of the nodes that are fed inputs during inference.`", "Hi there @printdhruv,\r\n\r\nI'm under the weather today, so excuse my sloppy reply.\r\n\r\nIf you look at the graph, the very first \"node\" is:\r\n\r\n```\r\nnode {\r\n  name: \"input_1\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 48\r\n        }\r\n        dim {\r\n          size: 48\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n", "@KeironO Can you list the whole program with the steps/procedure you are taking to execute it?", "I've stripped out a bit.\r\n\r\n```python\r\nimport os, copy\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.applications.vgg16 import VGG16\r\nfrom keras.models import Sequential, Model\r\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\r\nfrom keras.optimizers import SGD\r\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\r\n\r\nfrom keras import backend as K\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\n\r\n# Global Variables\r\n\r\n# Input values\r\nheight, width, nb_channels  = 150, 150, 3\r\n\r\ndata_directory = \"/home/keo7/Data/PVS/\"\r\n\r\n# Data directories\r\ntrain_directory = os.path.join(data_directory, \"train/\")\r\nvalidation_directory = os.path.join(data_directory, \"val/\")\r\ntest_directory = os.path.join(data_directory, \"test/\")\r\n\r\n# Training parameters\r\n\r\nMODEL_NAME = \"VGG16\"\r\n\r\ndef create_model():\r\n    model = VGG16(weights=\"imagenet\",\r\n                  include_top=False,\r\n                  input_shape=[height,width, nb_channels])\r\n\r\n    # Freeze layers we don't want to train.\r\n\r\n    for layer in model.layers[:5]:\r\n        layer.trainable = False\r\n\r\n    # Output layers\r\n\r\n    output_layers = model.output\r\n    output_layers = Flatten()(output_layers)\r\n    output_layers = Dense(1024,\r\n                          activation=\"relu\")(output_layers)\r\n    output_layers = Dropout(0.5)(output_layers)\r\n    output_layers = Dense(1024,\r\n                          activation=\"relu\")(output_layers)\r\n    predictions = Dense(nb_classes,\r\n                        activation=\"softmax\")(output_layers)\r\n\r\n    final_model = Model(input = model.input,\r\n                        output = predictions)\r\n    final_model.compile(loss=\"categorical_crossentropy\",\r\n                        optimizer=SGD(lr=0.0001,\r\n                                      momentum=0.9),\r\n                        metrics=[\"accuracy\"])\r\n\r\n    return final_model\r\n\r\ndef export_model(saver, model, input_node_names, output_node_name):\r\n    tf.train.write_graph(K.get_session().graph_def, 'out', \\\r\n        MODEL_NAME + '_graph.pbtxt')\r\n\r\n    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\r\n\r\n    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\r\n        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\r\n        \"save/restore_all\", \"save/Const:0\", \\\r\n        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\r\n\r\n    input_graph_def = tf.GraphDef()\r\n    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\r\n        input_graph_def.ParseFromString(f.read())\r\n\r\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n            input_graph_def, input_node_names, [output_node_name],\r\n            tf.float32.as_datatype_enum)\r\n\r\n    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\nif __name__ == \"__main__\":\r\n    model = create_model()\r\n    model.summary()\r\n    export_model(tf.train.Saver(), model, [\"input_1\"], \"dense_3/kernel\")\r\n", "I've had no luck with this as of yet.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The optimize_for_inference script is now deprecated in favor of the Graph Transform Tool (though we should make that clearer in the documentation):\r\nhttps://www.tensorflow.org/mobile/prepare_models\r\n\r\nClosing this, since I don't believe the GTT approach has the same issue.", "I'm tempted to suggest that a warning should be provided to users, warning them that this is the case.", "please help me i am also facing same problem", "Nobody will care when you have to scroll forever to comment.\r\n\r\nSee here https://github.com/tensorflow/tensorflow/issues/19515"]}, {"number": 13837, "title": "issue when installing Tensorflow", "body": "Hello, I have tried to install tensorflow gpu version with \"pip3 install --upgrade tensorflow-gpu\" but I have got this error message:\r\n```\r\nC:\\Users\\Martin>python\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\ncan someone help me ?", "comments": ["Could you try to run [this script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) and see what it points you to?", "I got that:\r\n```\r\nC:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\python.exe C:/Users/Martin/PycharmProjects/TestTensorflow/test/test\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.5.\r\n\r\n- TensorFlow is installed at: C:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Download and install CUDA 8.0 from\r\n  this URL: https://developer.nvidia.com/cuda-toolkit\r\n\r\n- Could not find cuDNN 6.\r\n\r\n  The GPU version of TensorFlow requires that the correct cuDNN DLL be installed\r\n  in a directory that is named in your %PATH% environment variable. Note that\r\n  installing cuDNN is a separate step from installing CUDA, and it is often\r\n  found in a different directory from the CUDA DLLs. The correct version of\r\n  cuDNN depends on your version of TensorFlow:\r\n\r\n  * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll')\r\n  * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll')\r\n\r\n  You may install the necessary DLL by downloading cuDNN from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\nProcess finished with exit code -1\r\n\r\n```", "@FerrandMartin Please follow the instructions. You need to download these packages from NVidia as requested.", "I have got some trouble to install them but I only need now cudart64_80. When I install Nvidia gpu toolkit it install only cudart64_90.dll not cudart64_80.dll", "cudart64_80 is available when downloading cuda v8 here: [CUDA Toolkit 8.0](https://developer.nvidia.com/cuda-80-ga2-download-archive)\r\nthank for the support!", "Yay!"]}, {"number": 13836, "title": "Add \"PlainSessionCreator\"", "body": "Not sure if this is desirable, but I found this improves the usability of the `SessionCreator` interface. When I use a factory to create session, it's helpful that it can at least create session in the simplest way.\r\nAn example usage would be to write a \"train\" function that takes a SessionCreator and a bunch of other things.", "comments": ["Can one of the admins verify this patch?", "Thanks! Didn't notice that due to all the complications in ChiefSessionCreator. Then it makes sense to close this PR."]}, {"number": 13835, "title": "Feature query: How to load the graph(model) only once and then give series of inputs", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No. Running the Simple Audio recognition network tutorial\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04 \r\n-**TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.6.0\r\n\r\n### Describe the problem\r\nI am a tensorflow and neural network novice. I was able to run the [Simple audio recognition](https://www.tensorflow.org/versions/master/tutorials/audio_recognition) network. For a given input wavefile the model obtained gives the result in approx. 5 seconds. I want reduce this time to 100s of milliseconds. From the issue https://github.com/tensorflow/tensorflow/issues/11618, there seems to be a way to do this using the graph. \r\n\r\nI used the graph optimisation tool but there wasn't a considerable reduction in time.I heard that loading the graph is what takes time and hence I need to figure out how to load the graph only once and then feed the inputs without feeding all the parameters every time a new input needs to be tested.\r\n\r\nThe command that is used for decoding is as follows: \r\n\r\npython tensorflow/examples/speech_commands/label_wav.py \\\r\n--graph=/tmp/my_frozen_graph.pb \\\r\n--labels=/tmp/speech_commands_train/conv_labels.txt \\\r\n--wav=/tmp/speech_dataset/left/a5d485dc_nohash_0.wav\r\n\r\nAlso does anyone know if there is official data on how long alexa/google home take to respond to trigger words?", "comments": ["@serendipity24 please note that you first have to load the tensorflow package. That takes about 2-3 seconds on python2, and in the 1.3 version, it can take 8 seconds (that is before we fixed the inspect stack in the tf decorator).\r\n\r\nRunning the inference should be very quick. You can modify the program to load, then ask for a prompt and pass in a waveform.", "@drpngx Thank you for your reply. \r\n\r\n\"You can modify the program to load, then ask for a prompt and pass in a waveform\" - I will try this. ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Assuming this worked for you."]}, {"number": 13834, "title": "Allow _FilterFloat to pass None values.", "body": "[Tensorflow 1.3: tf.constant with dtype=[float32, float64, float16] may have inconsistent behavior. #13827](https://github.com/tensorflow/tensorflow/issues/13827)\r\n\r\n - This fix allows _FilterFloat to allow None values to pass.\r\n - We add `tf.float16` into the `_TF_TO_IS_OK` dictionary.\r\n - We add tests for `convert_to_tensor` and `tensor_util`.", "comments": ["Can one of the admins verify this patch?", "I think we should do option (1). There are already a few places in which\nconvert_to_tensor disagrees with numpy (about what dtype to use and about\nwhat to do with strings containing nul bytes, for example).\n\nOn Sun, Oct 29, 2017 at 9:58 PM, Ouwen Huang <notifications@github.com>\nwrote:\n\n> *@Ouwen* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/framework/tensor_util.py\n> <https://github.com/tensorflow/tensorflow/pull/13834#discussion_r147617934>\n> :\n>\n> > @@ -252,7 +252,7 @@ def _FilterInt(v):\n>  def _FilterFloat(v):\n>    if isinstance(v, (list, tuple)):\n>      return _FirstNotNone([_FilterFloat(x) for x in v])\n> -  return None if isinstance(v, compat.real_types) else _NotNone(v)\n> +  return None if isinstance(v, compat.real_types) or v is None else _NotNone(v)\n>\n> @alextp <https://github.com/alextp>, thanks for giving this a look over!\n>\n> Currently there exists inconsistent behavior since numpy.array will\n> convert None into nan for float types but, convert_to_tensor does not.\n> This seems to break the promised convert_to_tensor abstraction referenced\n> from issue #13827 <https://github.com/tensorflow/tensorflow/issues/13827>.\n>\n> Since the convert_to_tensor abstraction states the following are\n> equivalent\n> <https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/ops.py#L575-L578>\n>\n> value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n> value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n> value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n>\n> I believe that the below should be equivalent as well\n>\n> value_a = my_func(tf.constant([[1.0, 2.0], [3.0, None]], dtype=tf.float32))\n> value_b = my_func(np.array([[1.0, 2.0], [3.0, None]], dtype=np.float32))\n>\n> From this inconsistency in convert_to_tensor, I believe there are a\n> couple options.\n>\n>    1. We document that the abstraction does not hold for floats.\n>    2. We remove the convert_to_tensor abstraction\n>    3. We update NumPy to not convert None to nan for float types\n>    4. We silently convert None to nan specifically for float types\n>\n> Options 1 and 4 seem reasonable to me, but in my opinion option 4 is a\n> good choice given that convert_to_tensor already silently converts and\n> that it follows the semantics NumPy has set forth.\n>\n> Please let me know what you think. Happy to make any needed changes!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13834#discussion_r147617934>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxav419Oc9w5QbrSLn20p9YCtNi07ks5sxVdmgaJpZM4P_iGB>\n> .\n>\n\n\n\n-- \n - Alex\n", "@alextp, you have a good point with NumPy  having different behavior when handling `null` types for strings. If `convert_to_tensor` does not fall back on NumPy semantics, perhaps it is better to allow users to explicitly decide the method of conversion.\r\n\r\nWith that, I can update the PR so that we add `tf.float16` into the `_TF_TO_IS_OK` dictionary for consistent assertion. Additionally, I will make a note that tensors with `None` values can have differing behavior from NumPy in the documentation.\r\n\r\nIf this sounds good to you guys @alextp  @mrry @MarkDaoust @vrv, I can go ahead and make that change.", "@alextp @josh11b @mrry @MarkDaoust @vrv, any updates? Just want to make sure this is the plan moving forward.\r\n\r\nAn alternative would be to potentially default to numpy semantics for all tensors that are made.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/408fd454d7d2a16269576ea12bcd516e25a6b0c5/tensorflow/python/framework/tensor_util.py#L375-L377\r\n\r\nSo the following lines would be flipped to attempt a numpy conversion, and if that fails we can fall back to the compatibility error.\r\n\r\nThis would mean `None` would be converted to `nan` for floats, and that `None` would be converted to `'None'` for strings.\r\n\r\n", "Hi Ouwen,\r\n\r\nThanks for the ping.\r\n\r\n>  I can update the PR so that we add tf.float16 into the _TF_TO_IS_OK dictionary for \r\n> consistent assertion. Additionally, I will make a note that tensors with None values can have\r\n> differing behavior from NumPy in the documentation.\r\n\r\nBoth vrv and mrry suggested josh11b decide, and josh11b sent alextp. So I think the `None` issue is settled, and this is the right direction.\r\n\r\nI think everyone agrees that float16 should follow the same rules as the other floats, and that the discrepancy between tf and numpy should be documented so the intent is clear (you could also note the strings with null bytes difference that alextp mentioned).\r\n\r\nThanks again.", "Appreciate the clarification @MarkDaoust! I've put up the PR change", "Thanks for the contribution!", "Jenkins, test this please."]}, {"number": 13833, "title": "Fix import of spatial_softmax from tensorflow.contrib.layers", "body": "Currently `spatial_softmax` cannot be imported from `tensorflow.contrib.layers`, but has to be imported all the way from `tensorflow.contrib.layers.python.layers`\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "Trying one more time"]}, {"number": 13832, "title": "Fix AWS SDK missing symbols on Linux PPC", "body": "TF on linux ppc64le builds but when loading the environment, some AWS related symbols are missing and thus resulting in a failure to load TF. This patch adds the same file inclusions/macro definitions to linux_ppc as one does to linux_x86 and this seems to fix the problem.\r\n\r\nError message reads:\r\n```\r\nTraceback (most recent call last):\r\n  File \"gru_ops_test.py\", line 23, in <module>\r\n    from tensorflow.contrib.rnn.python.kernel_tests import benchmarking\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: /localhd/tjin/tensorflow_latest/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws4Time9LocalTimeEP2tml\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```", "comments": ["Can one of the admins verify this patch?", "Any update?", "@tensorflow-jenkins test this please"]}, {"number": 13831, "title": "Fix casting to `size_t` for mkl conv filter dims", "body": "Here's the output from clang regarding explicit casting `int64` to `size_t`.\r\n\r\n```clang\r\ntensorflow/core/kernels/mkl_conv_ops.cc:291:31: error: non-constant-expression cannot be narrowed from type 'int64' (aka 'long long') to 'size_t' (aka 'unsigned long') in initializer list [-Wc++11-narrowing]\r\n```\r\n\r\nAfter modifying those lines I was able to compile successfully for CPU w/MKL + XLA.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 13830, "title": "R1.3", "body": "On Windows, after reinstalling Anaconda3 I run the command \r\n`conda create -n tensorflow python=3.5`\r\nto create a tensorflow environment within Anaconda installation in the hidden user appdata folder.\r\n\r\nThen I opened the new and updated navigator of anaconda. Changed the environment from root to tensorflow. I was given the option to install Spyder. That I did. Within minutes it installed Spyder within the tensorflow environment.\r\n\r\nThe first two Tensorflow programs in the guide ran perfectly and smoothly.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I think you meant to open up an issue?", "Thanks, I signed CLA. No issue intended."]}, {"number": 13829, "title": "Update layers.py", "body": "I have added a check on beta with reference to the following issue raised.\r\nhttps://github.com/tensorflow/tensorflow/issues/11673\r\n\r\nPlease verify and get back.\r\nThank you.\r\n\r\nI will add update the unit test cases to verify this patch.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Please add the test as requested in the previous version of the CL, otherwise this looks great, thanks!", "https://github.com/tensorflow/tensorflow/pull/13864 contains the updated unit test case.", "Can one of the admins verify this patch?", "It looks like you may be having trouble updating this PR to include all the changes  -- perhaps it makes sense to resend a new fresh PR with all of the requested changes (layers.py and layers_test.py change in the same PR).  Thanks!"]}, {"number": 13828, "title": "Update resnet.py", "body": "Test with mnist test set. Previously it was testing on the training set.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please."]}, {"number": 13827, "title": "Tensorflow 1.3: tf.constant with dtype=[float32, float64, float16] may have inconsistent behavior.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04 with docker running `gcr.io/tensorflow/tensorflow:latest` \r\n\r\n- **TensorFlow installed from (source or binary)**: NA\r\n- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n// works\r\ntest = numpy.array([1,2,3,4,5,6, None], dtype=numpy.float32)\r\nsess = tf.Session()\r\nprint(sess.run(tf.constant(test, dtype=tf.float32)))\r\n```\r\n\r\n```\r\n// works\r\nsess = tf.Session()\r\nprint(sess.run(tf.constant([1, 2, 3, 4, 5, 6, None], dtype=tf.float16)))\r\n```\r\n```\r\n// returns error\r\nsess = tf.Session()\r\nprint(sess.run(tf.constant([1, 2, 3, 4, 5, 6, None], dtype=tf.float32)))\r\n// TypeError: Expected float32, got None of type '_Message' instead.\r\n```\r\n\r\n### Describe the problem\r\nA tensorflow constant with None in array with dtype float32, float64 seem to throw an error. However, if they are first wrapped by a numpy array, none is accepted and turned into NaN. This behavior seems inconsistent.", "comments": ["/CC @MarkDaoust \r\n\r\nThat's unfortunate. Would you like to contribute a fix?", "I'd love to take a stab at contributing. From a brief glance i'm wondering if the `convert_to_tensor` function may be culprit. Glad to take any pointers as well.", "So here is what I've found after looking through the code. This error is propagated from tensorflow version `0.5.0` to `1.4.0-rc0`\r\n\r\n`tf.float16` `None` values pass without any problems because they are not checked in [`_TF_TO_IS_OK`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L273-L291). `None` values are thus not stopped by the [`_AssertCompatible`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L376) call, where they continue onward to be transformed into `nan` values by [`np.array`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L377)\r\n\r\nFor `float32`, and  `float64` types, `None` values are caught by the [`_AssertCompatible`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L294-L303), and since they are not an instance of [`compat.real_types`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L243) `(_numbers.Real, _np.integer, _np.floating)` a `TypeError` is raised.\r\n\r\nSo while the following produces an error: \r\n```\r\nsess = tf.Session()\r\nprint(sess.run(tf.constant([1, 2, 3, 4, 5, 6, None], dtype=tf.float32)))\r\n// TypeError: Expected float32, got None of type '_Message' instead.\r\n```\r\n\r\nUsing explicit `nan` will not cause an error\r\n```\r\nsess = tf.Session()\r\nprint(sess.run(tf.constant([1, 2, 3, 4, 5, 6, float('nan')], dtype=tf.float32)))\r\n```\r\n\r\nSince the `convert_to_tensor` abstraction states the [following are equivalent](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/ops.py#L575-L578)\r\n```\r\nvalue_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\r\nvalue_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\r\nvalue_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\r\n```\r\nI believe that the below should be equivalent as well\r\n```\r\nvalue_a = my_func(tf.constant([[1.0, 2.0], [3.0, None]], dtype=tf.float32))\r\nvalue_b = my_func(np.array([[1.0, 2.0], [3.0, None]], dtype=np.float32))\r\n```\r\n\r\nGiven what has been found, I would like to\r\n1. Update [`_FilterFloat`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L240-L243) to allow for `None` values.\r\n\r\n2. Add `tf.float16` into the  [`_TF_TO_IS_OK`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/tensor_util.py#L273-L291) dictionary with the `_FilterFloat` function\r\n\r\n3. Add a test into [`ops_test.py`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/framework/ops_test.py) named `testConvertToTensorFloatNoneValue`\r\n\r\nPlease let me know if this is a good plan assuming nothing breaks.", "Thanks Ouwen! This is the best kind of bug report.\r\n\r\nI'm not an expert on this part of TensorFlow, but this all looks pretty reasonable. Please send a PR after you fix that missing `(self)`.", "Appreciate it @MarkDaoust, here is the PR https://github.com/tensorflow/tensorflow/pull/13834", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "This is fixed by #13834."]}, {"number": 13826, "title": "while_loop gradient failure with ints", "body": "This is puzzling:\r\n\r\n```python\r\ng=tf.Graph()\r\nwith g.as_default():\r\n    i=tf.constant(1, name=\"i\")\r\n    inc=tf.constant(1, name=\"inc\")\r\n    w=tf.while_loop(lambda i,inc: i<=5, lambda i,inc: [i+inc, inc], [i,inc])\r\n    grad=tf.gradients(w[0],i)\r\n```\r\nresults in `grad[0]==None`\r\n\r\nBut changing the constants to floats:\r\n\r\n```python\r\ng=tf.Graph()\r\nwith g.as_default():\r\n    i=tf.constant(1.0, name=\"i\")\r\n    inc=tf.constant(1.0, name=\"inc\")\r\n    w=tf.while_loop(lambda i,inc: i<=5.0, lambda i,inc: [i+inc, inc], [i,inc])\r\n    grad=tf.gradients(w[0],i)\r\n```\r\n\r\ngives the correct gradient (ie, grad[0] is <tf.Tensor 'gradients/while/Enter_grad/Exit:0' shape=() dtype=float32>).\r\n\r\nThis is on `tensorflow.VERSION == 1.3.0`.\r\n\r\n", "comments": ["I think a float is better for interpolation. A type of integer can't have decimals. Was the first parameter of the constant return method a float? It could have parsed the 1 only as a 1.0. Where you passed the 1.0, it would have allowed the while loop actually to have the option to go through 1.1, 1.2, 1.3, etc. (even 1.111511...), where an integer of 1 would just return a fixed 1.0. I am not even sure even if the 1 (int) in your first example even cast or convert as floats. Their API shows an example of using -1.0 a float. https://www.tensorflow.org/api_docs/python/tf/constant. \r\n\r\nNot sure if this helped.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I thought it was a bug, though.", "Especially since this *does* work (`grad` is not `None` at the end), where the only difference is whether `inc` is external to the while loop or not:\r\n\r\n```python\r\nwith g.as_default():\r\n    i=tf.constant(1, name=\"i\")\r\n    inc=tf.constant(1, name=\"inc\")\r\n    w=tf.while_loop(lambda i: i<=5, lambda i: [i+inc], [i])\r\n    grad=tf.gradients(w, i)\r\n```", "I could be missing something, but gradients of interval-valued functions are undefined. Can you explain your use case further?  Or are you just looking for it to return None for this case, instead of some undefined nonsensical value?", "I don't have an opinion on what the answer should be-just that it should be\nconsistent whether or not 'inc' is an int or a float, and whether or not\n'inc' is internal or external to the looo.\nOn Fri, Oct 20, 2017 at 6:07 PM andydavis1 <notifications@github.com> wrote:\n\n> I could be missing something, but gradients of interval-valued functions\n> are undefined. Can you explain your use case further? Or are you just\n> looking for it to return None for this case, instead of some undefined\n> nonsensical value?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13826#issuecomment-338333261>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AA8SvdbkDfT_UkASx6TRXGoyedBUTO-Uks5suRmwgaJpZM4P-nXU>\n> .\n>\n", "Again, maybe I'm missing something, but your initial cases make sense to me. If the induction variable update is a integer in the loop body, then it cannot compute a gradient and so returns None. However, if the induction variable it a float it can compute a gradient and so returns one. This seems \"working as intended\", no?"]}, {"number": 13825, "title": "GRU cell implementation different from Reference paper \"Cho 14\"", "body": "Hello, \r\n\r\nI've been looking through GRUCell implementation on Tensorflow at \"tensorflow/tensorflow/python/ops/rnn_cell_impl.py\", and got a bit confused.\r\n\r\nThe output of GRUCell is implemented as\r\n`new_h = u * state + (1 - u) * c`\r\n\r\nHowever, from the reference paper \"Cho 14\" at https://arxiv.org/pdf/1412.3555.pdf\r\nI think it should be like\r\n`new_h = (1 -  u) * state + u * c`\r\n\r\nI am not sure if this is a bug or an intended variation from the reference.\r\n\r\nThank you", "comments": ["To be clear we are looking at Eq 5 in the paper and the code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl.py#L351).\r\n\r\n@ebrevdo what do you think?", "Any comments on the issue?", "code is right as detail explain in 2.3 of https://arxiv.org/pdf/1406.1078.pdf", "@hksonngan \r\nThanks! \r\nWonder why the equations are the different in the papers though."]}, {"number": 13824, "title": "GPU Question: dtype supports ", "body": "According to https://github.com/tensorflow/tensorflow/issues/9506, gpu currently only supports floats. In NLP tasks however there's no way around looking up the embedding matrix with int-typed indices. \r\n\r\nSo I wonder if it on your shortlist to extend to int support? If not, how to get around the index-lookup issue? Thanks.", "comments": ["Please ask this first on StackOverflow to see if you get some response to using TF with embedding integer index lookups.\r\n\r\n\r\n\r\n"]}, {"number": 13823, "title": "feature request: more efficient tf.eye", "body": "tf.eye(n) creates a constant of size n*4\r\nA better implementation would use `Fill` instead of constant\r\n\r\nThis is similar to issue https://github.com/tensorflow/tensorflow/issues/13221#issuecomment-333893186 , where zeros is getting refactored to use Fill instead of constant", "comments": ["Seems reasonable.\r\n\r\n@reedwm @alextp @zffchen78 @cwhipkey Any takers?", "@tfboyd for performance.", "Obviously, @yaroslavvb we accept contributions as well :-)", "Hi, do you mean to replace `array_ops.zeros` by `fill`?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/408fd454d7d2a16269576ea12bcd516e25a6b0c5/tensorflow/python/ops/linalg_ops.py#L134", "Actually I just realized someone already has a PR to fix this: https://github.com/tensorflow/tensorflow/pull/13666\r\n\r\nTo see problem with current solution try\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.reset_default_graph()\r\nsess = tf.Session()\r\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE,output_partition_graphs=True)\r\nrun_metadata = tf.RunMetadata()\r\nsess.run(tf.eye(10).op, options=run_options,run_metadata=run_metadata)\r\nprint(run_metadata)\r\n```\r\n\r\nYou see a large const node being allocated on the GPU which is a problem because this memory will not be released at the end of `sess.run`", "OK, closing then."]}, {"number": 13822, "title": "Convolutional layers cannot be used multiple times", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source (branch 1.4)\r\n- **TensorFlow version (use command below)**: 1.4.0-dev\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: nVidia 1080Ti 11G\r\n- **Exact command to reproduce**: run the script below\r\n\r\n### Describe the problem\r\nKeras convolutional layers cannot be used multiple times without creating a name conflict. This is especially bad when trying to copy layers from one model to another (See the second example below). This was working a few weeks ago. Here is a simple test case that used to work:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\nc = Conv2D(32, (3, 3))\r\nc(a)\r\nc(a)\r\n```\r\n\r\nI added some print statement to different versions of the code. It looks like the convolutional ops are created with the following names in the old code:\r\n\r\n1. conv2d/convolution/\r\n2. conv2d/convolution_1/\r\n\r\nIn the new code they are:\r\n\r\n1. conv2d/convolution/\r\n2. conv2d/convolution/\r\n\r\nIt looks like the name scope code was changed recently. I specifically notice that some of the scope handling was moved to __init__ where it used to happen when the function was called. \r\n\r\nThis is a slightly more complex version of the code that shows that copying convolutional layers doesn't work:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\nfrom tensorflow.contrib.keras.api.keras.models import Model\r\n\r\na = Input(shape=(None, 32, 3))\r\nb = a\r\nb = Conv2D(32, (3, 3))(b)\r\nmod1 = Model(inputs=a, outputs=b)\r\na = Input(shape=(None, 32, 3))\r\nb = a\r\nfor layer in mod1.layers[1:]:\r\n    b = layer(b)\r\nmod2 = Model(inputs=a, outputs=b)\r\n```\r\nThis is an example of the traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/root/vish/test.py\", line 16, in <module>\r\n    b = layer(b)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 252, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 577, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py\", line 172, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 841, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 503, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 191, in __call__\r\n    name=self.name)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\r\n    data_format=data_format, name=name)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2959, in create_op\r\n    self._add_op(ret)\r\n  File \"/opt/rh/rh-python35/root/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2599, in _add_op\r\n    \"is already used\" % op.name)\r\nValueError: cannot add op with name conv2d/convolution as that name is already used\r\n```", "comments": ["Also to note that when using keras-2.0.8 the same code creates convolutional ops with following names:\r\n\r\n1. conv2d_1/convolution\r\n2. conv2d_1_1/convolution\r\n\r\nMoreover, when nesting scopes, the differences became even more apparent. A slightly modified code that calls the other copy in some scope behaves much differently in keras vs. tf.keras (1.3.0).\r\n\r\n```\r\na = Input(shape=(None, 32, 3))\r\nc = Conv2D(32, (3, 3))\r\nc(a)\r\n\r\nwith tf.name_scope('my_scope'):\r\n    c(a)\r\n```\r\n\r\nkeras names:\r\n\r\n1. conv2d_1/convolution\r\n2. my_scope/conv2d_1/convolution\r\n\r\ntf.keras names:\r\n\r\n1. conv2d/convolution\r\n2. conv2d/convolution_1\r\n\r\nAlthough the functionality is the same, keras way of scoping does not interfere with the name scope concept and therefore it behaves as expected.", "New scoping implementation (the cause of the opened issue) also causes scopes not scoping their implementations correctly.\r\n\r\nA slightly modified code with repeating layers results in bad scoping.\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\na = Conv2D(32, (3, 3))(a)\r\na = Conv2D(32, (3, 3))(a)\r\n```\r\n\r\nConvolutions are named:\r\n\r\n1. conv2d_1/convolution\r\n2. conv2d_2/convolution\r\n\r\nAnd their weights are named:\r\n\r\n1. conv2d/kernel\r\n2. conv2d_1/kernel\r\n\r\nWhich results in different layers being placed partially in the same scope and partially in different scopes.\r\n\r\n", "@martinwicke Can you comment on this one? Thanks...", "I'm sorry -- @antifriz what you describe looks like it's working as intended. What would be the desired behavior here? \r\n\r\nThe scoping differences should be immaterial, you should be able to save and load *Keras* models between the different backends, etc.\r\n\r\nImportant is that reusing a layer reuses the variables, and that using a new layer will *not* share any variables.\r\n\r\n@fchollet FYI, if you see an issue here that I missed.", "@martinwicke, @fchollet \r\n\r\nI included visual comparison of keras and tf.keras behaviors to clarify what I think is wrong with tf.keras scoping.\r\n\r\nSo for two layers tf.keras produces three scopes where second layer is splitted in two scopes:\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\na = Conv2D(32, (3, 3))(a)\r\na = Conv2D(32, (3, 3))(a)\r\n```\r\n\r\n<img width=\"717\" alt=\"screen shot 2017-10-21 at 8 21 56 am\" src=\"https://user-images.githubusercontent.com/6382271/31848812-5089a624-b639-11e7-9238-855ec6418792.png\">\r\n\r\nWith keras scoping is as expected:\r\n```\r\nfrom keras.layers import Conv2D\r\nfrom keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\na = Conv2D(32, (3, 3))(a)\r\na = Conv2D(32, (3, 3))(a)\r\n```\r\n<img width=\"422\" alt=\"screen shot 2017-10-21 at 8 23 34 am\" src=\"https://user-images.githubusercontent.com/6382271/31848813-50a64e96-b639-11e7-8489-d5beb1c309d4.png\">\r\n\r\nIn tf.keras this happens only if you do not explicitly specify the name of the layer. If it is specified, result is as expected (like keras one).\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\na = Conv2D(32, (3, 3), name='conv_first')(a)\r\na = Conv2D(32, (3, 3), name='conv_second')(a)\r\n```\r\n<img width=\"480\" alt=\"screen shot 2017-10-21 at 8 35 10 am\" src=\"https://user-images.githubusercontent.com/6382271/31848926-dffd175e-b63a-11e7-9f0a-b9cd7d7837cf.png\">\r\n\r\nAlso to mention, with three repeating layers, scope `conv2d_2` contains ops for the second layer and weights for the third.\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Conv2D\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\na = Conv2D(32, (3, 3))(a)\r\na = Conv2D(32, (3, 3))(a)\r\na = Conv2D(32, (3, 3))(a)\r\n```\r\n<img width=\"665\" alt=\"screen shot 2017-10-21 at 9 25 51 am\" src=\"https://user-images.githubusercontent.com/6382271/31849438-41cc4700-b642-11e7-8757-6437ebf42467.png\">\r\n", "regardless of the weird scoping, the original issue still remains in that it is not possible to use the same layer twice due to the name conflict. ", "Can you check what happens with layers from `tf.layers`?", "Relate to #13429? ", "@fchollet I'm less familiar with using straight tensorflow layers, but the following gives me roughly the same  error:\r\n```\r\nimport tensorflow as tf                                                                                                                                                              \r\n                                                                                                                                                                                     \r\nfrom tensorflow.python.layers.convolutional import Conv2D                                                                                                                            \r\na = tf.placeholder(tf.float32, (None, 32, 32, 3))                                                                                                                                    \r\nc = Conv2D(32, (3, 3))                                                                                                                                                               \r\nc(a)                                                                                                                                                                                 \r\nc(a)  \r\n```\r\n\r\nHere is the traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 8, in <module>\r\n    c(a)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 171, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\r\n    data_format=data_format, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2959, in create_op\r\n    self._add_op(ret)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2599, in _add_op\r\n    \"is already used\" % op.name)\r\nValueError: cannot add op with name conv2d/convolution as that name is already used\r\n```\r\n\r\nThis code also works with the older version of tensorflow from a few weeks back. The names of the layers in the old code are:\r\nconv2d/convolution\r\nconv2d/convolution_1\r\n", "@vishvananda what TF version is that? If it is the GitHub one, then I believe this is a bug that was introduced in relation to eager mode and has been fixed recently. It should not be related to the issue from this thread. Try with a different layer (e.g. `Dense`).\r\n\r\n> Relate to #13429?\r\n\r\nYes, I would think so, but would like confirmation.", "This is the r1.4 branch from last week. I'm building again from current r1.4. Will post the results shortly", "The current r1.4 branch still fails. I'm now trying against current master, although it will take a while to do the build from scratch", "@fchollet Current master also fails. Both of the following Dense scenarios work fine, so it looks like the error is specific to convolutional layers\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python.layers.core import Dense\r\na = tf.placeholder(tf.float32, (None, 32, 32, 3))\r\nc = Dense(32)\r\nx = c(a)\r\ny = c(a)\r\n```\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.keras.api.keras.layers import Dense\r\nfrom tensorflow.contrib.keras.api.keras.layers import Input\r\n\r\na = Input(shape=(None, 32, 3))\r\nc = Dense(32)\r\nx = c(a)\r\ny = c(a)\r\n```", "@fchollet I assume you are referring to the fixes contained in this pr: https://github.com/tensorflow/tensorflow/pull/13934\r\n\r\nI have merged that branch into master and it does fix the issues here", "Ok this was fixed in master by https://github.com/tensorflow/tensorflow/pull/13976. r1.4 still needs to be updated though", "@case540 is on it.", "I can confirm that this is fixed in 1.4 as of https://github.com/tensorflow/tensorflow/pull/14044"]}, {"number": 13821, "title": "Feature request: classifier deallocation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.6\r\n- **TensorFlow installed from (source or binary)**: Binary? (pip)\r\n- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0') (tensorflow)\r\n- **Python version**: 2.7.8\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: https://gist.github.com/alltom/75f3c0e62cd679c5e8af368bb49370c6\r\n\r\n### Describe the problem\r\n[DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) doesn't appear to have any methods for freeing its resources, and that doesn't seem to occur automatically if I let the classifier go out of scope.\r\n\r\nIn [the gist linked above](https://gist.github.com/alltom/75f3c0e62cd679c5e8af368bb49370c6), I train, evaluate, and throw away DNNClassifiers as part of a genetic algorithm for feature selection, but after training a little more than a hundred models, it fails:\r\n\r\n`InvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./model_2017-10-18-21:41:26/125/model.ckpt-4000: Resource exhausted: ./model_2017-10-18-21:41:26/125`\r\n\r\n### Source code / logs\r\nhttps://gist.github.com/alltom/75f3c0e62cd679c5e8af368bb49370c6", "comments": ["Thank you for the report! Appreciate the effort to create a repro case.\r\n\r\n@roumposg any clue?", "I don't see why DNNClassifier should free up resources when it goes out of scope. Python does not have variable scopes like c++. To me, this looks like it is working as intended. @xiejw what do you think?\r\n\r\nWhy do you need to create a new DNNClassifier in every iteration? Can't you just have one and keep training.", "We tried to reproduce your error, but we are missing the training.csv and test.csv files. Can you provide those files, or edit your code to not depend on them?\r\n\r\nAlso, it is not clear if the error message is due to memory exceeded or disk exceeded. Can you monitor memory and disk usage while your program is running? That will help us debug, thanks.", "Whoops, I added the data files to the gist.\r\n\r\nDisk usage looks fine, but I haven't monitored RAM. I'm used to \"resource exhausted\" meaning that the process is out of file descriptors, but I haven't confirmed that that's the case here.\r\n\r\nWhether by garbage collection or by explicit deallocation, it seems like there should be some way to free a DNNClassifier's resources. That's my feature request, anyway. :) Currently, DNNClassifier leaks.\r\n\r\nOne of the hyperparameters I'm configuring is the network structure, and it doesn't look like DNNClassifier supports reconfiguring the network after initialization, so I don't think I can reuse the same object.", "I ran it again, but memory and disk usage remained stable (save for the tiny model files the DNNClassifiers were saving, and nowhere near full), so my guess it's file handle exhaustion.\r\n\r\nI added a call to `gc.collect()` right before every time a new model is trained, and this time instead of failing with the \"resource exhausted\" error, it failed with `Segmentation fault: 11` at the same part (~125 models trained). So\u2026 don't know how to reconcile that with Activity Monitor showing flat memory pressure.", "SIGSEGV is definitely a problem.", "to get sigserv stack trace:\r\n\r\nulimit -Sc unlimited\r\n-crash things>\r\ngdb python\r\ncore core\r\n\r\n-paste stack trace>", "Thanks for uploading the files. I modified train.py to add a counter for counting how many candidates have been constructing in total, and ran it in ubuntu (Tensorflow 1.3 installed with virtualenv). It produced ~1000 candidates so far without problems before I stopped the script.\r\n\r\nPerhaps this is something mac-specific, so I will try running it on macOS.\r\n\r\nTom, can you paste the full error message / stack trace? Thanks.", "@yaroslavvb I don't have gdb installed, so I can't get a core dump that way. :(\r\n\r\n@roumposg I added a complete stack trace to the gist, although the trace isn't *exactly* the same from run to run.", "I was not able to reproduce the problem. It seems like it is mac-specific, and I am not an expert in that, so I am unassigning myself.\r\n\r\nFor the record, I attach the modified file I used, which counts the number of models created (rename from train.txt to train.py to use the file).\r\n[train.txt](https://github.com/tensorflow/tensorflow/files/1438398/train.txt)\r\n", "Closing since it's hard to repro."]}, {"number": 13820, "title": "Custom Reader Op : Undeclared Inclusions", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nCustom Code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\nLinux Ubuntu 16.04 \r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n- **TensorFlow version (use command below)**:\r\n1.4.0\r\n- **Python version**: \r\n2.7\r\n- **Bazel version (if compiling from source)**:\r\n0.6.1\r\n\r\n- **CUDA/cuDNN version**:\r\nLaptop CPU\r\n- **GPU model and memory**:\r\nLaptop CPU\r\n- **Exact command to reproduce**:\r\n bazel build -c opt //tensorflow/core/user_ops:rest_api.so --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"\r\n\r\n### Describe the problem\r\nI am getting undeclared inclusions for files in the //tensorflow/core/framework directory. I am not sure why this is happening since the user_ops_op_lib in the //tensorflow/core/BUILD has \":framework\" as its dependency. Is there a missing dependency that needs to be added? \r\n\r\n### Source code / logs\r\n\r\nBUILD File In /tensorflow/core/user_ops\r\n```\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\r\n\r\ncc_library(\r\n        name = \"rest_api_dependencies\",\r\n        srcs = glob([\"rest_api.cc\", \"*.c\", \"*.cpp\"]),\r\n        hdrs = glob([\"rest_api.h\", \"*.h\", \"*.hpp\", \"dict.c\"]),\r\n\tlinkopts = [\"-pthread\", \"-lev\", \"-fexceptions\"],\r\n)\r\n\r\ntf_custom_op_library(\r\n        name = \"rest_api.so\",\r\n        srcs = [\"rest_api.cc\"],\r\n        deps = [\":rest_api_dependencies\"],\r\n)\r\n```\r\n\r\nundeclared inclusion(s) in rule '//tensorflow/core/user_ops:rest_api_dependencies':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/user_ops/rest_api.cc':\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/op_def.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/attr_value.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/tensor.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/resource_handle.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/tensor_shape.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/types.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/lib/core/error_codes.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/step_stats.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/allocation_description.pb.h'\r\n  'bazel-out/local-opt/genfiles/tensorflow/core/framework/tensor_description.pb.h'\r\n", "comments": ["user_ops_op_lib will only apply the :framework dep to sources it collects. If you define your own cc_library rule you'll need to add the required deps explicitly. You should be able to just add `deps = [\"//tensorflow/core:framework\"]`.", "@allenlavoie Okay, everything is working now. Thank you! \r\nFor anyone who stumbles upon this, I had to do one more step to get my custom op to successfully build with bazel. The dependencies I needed were disallowed in tensorflow.bzl. I removed these disallowed dependencies and  everything worked after that. ", "Ah. Yes, I should reconsider whether that check is at all necessary (I think no at this point, after the RTLD_GLOBAL removal). What does bypass that check is using framework_headers_lib.\r\n\r\nAre you interested in removing the :framework check in a pull request? You can mention me and I'll review. Not 100% certain it's safe, but it should be."]}, {"number": 13819, "title": "Branch 172647355", "body": "@vrv the release needed a push so I hope you don't mind, went ahead and did one early.\r\n\r\n@caisq and @jart there was a conflict with the setup.py file. I updated the protobuf version, but kept TensorBoard as is. Please let me know if that's okay. ", "comments": ["I'll be updating TensorBoard to the latest protobuf shortly. I'm also in the process of setting up a tb-nightly PIP package that tf-nightly can depend on."]}, {"number": 13818, "title": "Feature request: C API \"TF_FinishWhile\" should create a \"WhileContextDef\"", "body": "Thanks @skye et al for getting while loops into the C API!\r\n\r\nI'd like to request that `TF_FinishWhile` generate a `WhileContextDef` protobuf object. That way, non-Python TensorFlow clients can create metagraphs involving while loops which the Python client can then import and take gradients of. Ideally, you could gradients of while loops directly in the C API, but I think just creating the while context should be much easier and is a good stop gap on the way there. \r\n", "comments": ["@asimshankar Can you comment on this one. Thanks..", "Out of curiosity, could you describe your use case where you generate a metagraph in a non-Python language and create the gradients in Python?", "This is the strategy the [the Julia client](https://github.com/malmaud/TensorFlow.jl) takes to get around the limited number of gradients implemented in C++.\r\n\r\nWhen a user requests gradients, the current graph is serialized and sent to a Python process. The Python process then adds gradient operations to the graph, serializes it, and sends it back to the Julia client. A little round-about, but it works. ", "I see. I'm a little hesitant to expose this low-level proto in the C API, but I understand we're not leaving you with many options (at least until gradients are fully implemented in the C API). I need to give this more thought, I'll keep you updated.", "Great, thanks.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hey, sorry for leaving this hanging for so long... is this still an issue for you?", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 63 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 78 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 93 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 108 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 123 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 13817, "title": "allow to run configure from a parent workspace", "body": "With this patch you can configure tensorflow directly using bazel.\r\n\r\nFixes #12761 \r\n\r\n```\r\nexport TF_NEED_CUDA=1\r\nexport TF_CUDA_VERSION=8.0\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\r\nexport TF_CUDNN_VERSION=6\r\nexport CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu\r\nexport PYTHON_BIN_PATH=`which python2`\r\nexport TF_NEED_GCP=1\r\nexport TF_NEED_HDFS=0\r\nexport TF_ENABLE_XLA=1\r\nexport TF_NEED_VERBS=1\r\nexport CC_OPT_FLAGS=\"-mavx -msse4.2 -mfpmath=both -DEIGEN_USE_VML\"\r\nexport TF_NEED_MKL=1\r\nexport TF_DOWNLOAD_MKL=1\r\nbazel run @org_tensorflow//:configure -- --tf_workspace= $(bazel info output_base)/external/org_tensorflow`\" --workspace=$(PWD)\r\n```", "comments": ["Can one of the admins verify this patch?", "@gunan do you know a better reviewer for this?", "Potentially @yifeif, but she is OOO for a few weeks. I will look into this.", "Ping for @Mistobaan ", "One more ping for @Mistobaan ?", "sorry @vrv being swamped with work. I will push an update in the next day", "Any updates @Mistobaan ", "@vrv I finally got the time to go over this once again.\r\n\r\n```bash\r\nbazel run //:configure -- --tf_workspace=$(PWD) --workspace=$(PWD)\r\n```\r\nThis will write the bazelrc inside the current workspace. \r\nI haven't find a way to pass the full workspace path to the bazel rule other than explicitly settting them. We might change ./configure to run `bazel` with those parameters.\r\n\r\nThe nice thing is now importing tensorflow from another module works. See this bareminimum workspace: https://github.com/Mistobaan/sample_tf_bazel_import\r\n", "@yifeif could you take another look?", "@tensorflow-jenkins test this please", "Looks like there's some incompatibility with the way the configure script checks for the TF workspace file (revealed by the failing CIs). ", "@Mistobaan could you address @angersson comment to fix the build? Also, please pull rebase and push again.", "Looks like the build issues are still there. But this is something we would like to get in.\r\nChecking with @case540 to see if we already merged an equivalent change.", "@angersson @case540 \r\nLet's look into merging this change. Did we already merge anything equivalent?\r\nIf not, let's either merge this, or move it to internal and merge it internally.", "I don't think we have anything like this currently and I think its worth adding. configure script changed a bit so I think this change just needs some small updates.\r\n\r\nAn alternative would be to write some Bazel repo rule that acts like http_archive https://docs.bazel.build/versions/master/be/workspace.html#http_archive but then immediately runs configure.py . Then people using TF as an external dep would not have to manually run configure. Problem is it would add things to .bazelrc file, and I dont think the things added to .bazelrc would be used until the second time you build.", "@case540 @gunan, so what do we do?", "@case540 if @Mistobaan is OK with it, could you take over this change?", "@gunan sure! ", "Nagging Assignee @vrv: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 13816, "title": "Disable flaky tests in cmake build.", "body": "", "comments": ["Do you mean the failures in jenkins? Or the disabled tests.\r\nThe local cluster creation is definitely not looked at.\r\nbatch_matmul I have an open bug, and I will revisit when I can see a stack trace.\r\nThe others, occasionally if someone needs them they need the ops these tests cover.", "Jenkins, test this please.", "(The disabled tests; the list is super long now and doesn't seem to be shrinking much).", "Current test failure is a known issue, merging.\r\n\r\nWe can discuss what we can do about the disabled tests further.\r\nEvery now and then I revisit these and try them on my machine, and enable them like this:\r\nhttps://github.com/gunan/tensorflow/commit/ac6442ee5227693a8a0f23cb52b821e54e777b54#diff-154d7a6e7930f8e143fbd4b8329c67d0\r\nBut we need more than what I can do by myself.", "(I can merge if you'd like?)"]}, {"number": 13815, "title": "Cherry-pick in additional bug fixes to r1.4 branch.", "body": "Fixes to Datasets, S3 file system, and a change to no longer set random seed in Estimator run_config.", "comments": ["kernel_tests:dataset_from_generator_op_test is timing out", "Hmmm, locally dataset_from_generator_op_test runs and passes just fine. mrry, do you know what could be causing this?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please\r\n\r\n(I assume I'm supposed to test again?)"]}, {"number": 13814, "title": "Kernel/Bias created for only one LSTM when using BasicLSTMCell with MultiRNNCell", "body": "I am using the example code ptb_word_lm.py that creates 2 layers of lstm's. The code clearly creates 2 (c,h) tuples, each tuple corresponding to one LSTM. Each c and h should depend on matrices i,j,f,o (input_gate, new_input, foget_gate, outpu_gate) that are found in BasicLSTMCell  in rnn_cell_impl.py. With tf.global_variables() you should be able to get these matrices. In fact, it returns a kernel matrix and a bias matrix. The kernel matrix is of size 400x800 which corresponds to only one LSTM parameters. (the i,j,f,o matrices are concatenated horizontally. The matrices for the input and h_t-1 are concatenated vertically). However, whether I am using 1 layer LSTM or 2 layer LSTM, the number of parameters stays the same (400x800), when it should be 400x1600 or a tuple of some sort or an additional kernel and bias. It seems that tf.global_variables() does not expose all trainable parameters in this case. Is that true or am I missing something?\r\n\r\nEDIT:\r\nI am now fairly certain that this is a problem, because when I use the \"block\" option in the script, multirnncell works correctly and generates 2 kernel matrices and 2 bias matrices. with BasicLSTMCell, it only generates one kernel matrix and 1 bias matrix.\r\n", "comments": ["@ebrevdo Can you comment on this one? Otherwise, lets ask this question on stackoverflow.", "Send a link to the code you are looking at?", "@ebrevdo https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py\r\n\r\nL216: If you set config.rnn_mode == BASIC, it only creates one layer of LSTMs. If you set it to BLOCK it creates 2 layers.\r\nThe issue seems to be on line L221 where the code calls MultiRNNCell", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Great catch!  This was affecting model quality. I believe we fixed this\nrecently.\n\nOn Wed, Dec 20, 2017, 11:28 AM Alfred <notifications@github.com> wrote:\n\n> It has been 14 days with no activity and the awaiting tensorflower label\n> was assigned. Please update the label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13814#issuecomment-353158414>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxbnEb2qtqt5jBZPp66bJ_5G8Cd8ks5tCV8agaJpZM4P-AN->\n> .\n>\n"]}, {"number": 13813, "title": "Add GPU kernel for `tf.bincount`", "body": "This fix tries to address the issue raised in #11554 where there is no GPU support for `tf.bincount`.\r\n\r\nThis fix adds GPU support for `tf.bincount`.\r\n\r\nThis fix fixes #11554.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Note that in the case of weights being passed to bincount, it is equivalent to unsorted_segment_sum.  I would prefer a solution that just replaces bincount with a call to unsorted_segment_sum in this case (ideally in the graph after the output size is determined).\r\n\r\nFor the case where no weights are given and they are assumed to be one, then it would be best to have the implementation call CUB as it will be _significantly_ faster.", "@ringw can you take a look at this?  Let me know if you want me to find someone else for the GPU kernel code review.", "Missed @ekelsen's comment, probably should do that :)", "@ekelsen @vrv Thanks for the suggestion. Will spend some time and get `CUB` implementation added.", "@yongtang thanks for taking this on!  CUB for weights == 1 case will be great.  Avoiding code duplication by calling the gpu kernel that already exists for unsorted_segment_sum in the case where weight != None will also be very helpful!", "@ekelsen @vrv The PR has been updated with `CUB` used for `weights.size() == 0` and `unsorted_segment_sum` used for `weights.size() != 0`. Please take a look and let me know if there are any issues.\r\n\r\nAs `cub::DeviceHistogram::HistogramEven` depends on `atomicAdd` which does not have the `double` and `half` types, only `float` is enabled for `CUB` now. I will investigate further to see if there are ways to create wrapper for `double` and `half` versions of `atomicAdd`.", "Sorry for the delay! Looks good pending @ekelsen's comments.", "Thanks @ekelsen @ringw for the review. The PR has been updated. Please take a look and let me know if there area any issues.", "Thanks @ekelsen for the review. The PR has been updated. Please take a look.", "Thanks @ekelsen. The PR has been updated with tests added. Here are some numbers for the new version:\r\n```\r\nRunning main() from test_main.cc\r\nBenchmark                  Time(ns) Iterations\r\n----------------------------------------------\r\nBM_Bincount_cpu_32_1000      114922       5150   285.1M items/s\r\nBM_Bincount_cpu_32_2000      124291       5524   263.6M items/s\r\nBM_Bincount_cpu_32_5000      159548       4287   205.4M items/s\r\nBM_Bincount_cpu_64_1000      145006       4793   452.0M items/s\r\nBM_Bincount_cpu_64_2000      150301       4457   436.0M items/s\r\nBM_Bincount_cpu_64_5000      180001       3880   364.1M items/s\r\nBM_Bincount_cpu_128_1000     204993       3405   639.4M items/s\r\nBM_Bincount_cpu_128_2000     209144       3311   626.7M items/s\r\nBM_Bincount_cpu_128_5000     231580       3003   566.0M items/s\r\n\r\nBM_Bincount_gpu_32_1000       61178      10000   535.6M items/s\r\nBM_Bincount_gpu_32_2000       61021      10000   537.0M items/s\r\nBM_Bincount_gpu_32_5000       61177      10000   535.6M items/s\r\nBM_Bincount_gpu_64_1000       61317      10000   1068.8M items/s\r\nBM_Bincount_gpu_64_2000       60726      10000   1079.2M items/s\r\nBM_Bincount_gpu_64_5000       61721      10000   1061.8M items/s\r\nBM_Bincount_gpu_128_1000      69935      10000   1874.2M items/s\r\nBM_Bincount_gpu_128_2000      79760       9852   1643.3M items/s\r\nBM_Bincount_gpu_128_5000     100407       6974   1305.4M items/s\r\n\r\n```", "@tensorflow-jenkins test this please\r\n\r\n@ekelsen can you take one final look?", "LGTM", "I couldn't see all of the CI failure logs, though one failure is:\r\n```\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/examples/wav_to_spectrogram/BUILD:40:1: Couldn't build file tensorflow/examples/wav_to_spectrogram/wav_to_spectrogram_test: Linking of rule '//tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram_test' failed (Exit 34). Note: Remote connection/protocol failed with: connection failed: com.google.devtools.build.lib.remote.RetryException: after 6 attempts: io.grpc.StatusRuntimeException: UNAVAILABLE: Subchannel shutdown invoked\r\n```\r\n\r\nI think that is an internal CI or network failure?", "It sure looks like a flaky network failure.\r\n\r\n@tensorflow-jenkins please re-test", "@tensorflow-jenkins test this please", "Half of the Jenkins tests passed. For the other half they are not invoked. I think a label of `kokoro:force-run` has to be attached to this PR to invoke the other tests to run.", "Most of the test passed now. The error seems to be related to the network failure:\r\n```\r\nWARNING: /tmpfs/src/github/tensorflow/tensorflow/core/BUILD:1786:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /tmpfs/src/github/tensorflow/tensorflow/tensorflow.bzl:1048:30\r\nERROR: /tmpfs/tmp/bazel/external/boringssl/BUILD:115:1: Couldn't build file external/boringssl/_objs/crypto/external/boringssl/src/crypto/mem.o: C++ compilation of rule '@boringssl//:crypto' failed (Exit 34). Note: Remote connection/protocol failed with: connection failed: com.google.devtools.build.lib.remote.RetryException: after 6 attempts: io.grpc.StatusRuntimeException: UNAVAILABLE: Subchannel shutdown invoked\r\n\tat com.google.devtools.build.lib.remote.Retrier.execute(Retrier.java:217)\r\n\tat com.google.devtools.build.lib.remote.GrpcRemoteExecutor.lambda$executeRemotely$2(GrpcRemoteExecutor.java:136)\r\n\tat com.google.devtools.build.lib.remote.Retrier.execute(Retrier.java:203)\r\n\tat com.google.devtools.build.lib.remote.GrpcRemoteExecutor.executeRemotely(GrpcRemoteExecutor.java:126)\r\n```\r\n\r\nI think a re-run may resolve the issue?", "Looks like boncount_op_test is failing to build on multiple configurations, and we seem to be changing the public TF API with this change. \r\nCould you take a look at the failures?", "Thanks @gunan for the help. Let me take a look and fix it.", "@gunan The api compatibility test failure is caused by addition of `Bincount` into `hidden.txt`. I have removed it from `hidden.txt`.\r\n\r\nFor the gpu test linkage failure, on my dev machine previously I added the following so that it could pass locally:\r\n```\r\n        \"@local_config_cuda//cuda:cublas\",\r\n        \"@local_config_cuda//cuda:cuda_driver\",\r\n        \"@local_config_cuda//cuda:cudnn\",\r\n        \"@local_config_cuda//cuda:cufft\",\r\n        \"@local_config_cuda//cuda:curand\",\r\n```\r\n\r\nIt seems that on CI/CD those libs should not be specified explicitly. I have removed those extra dependencies from the bazel `BUILD` build file. I think that will resolve the issue on Jenkins CI/CD.", "@gunan The PR has been updated. Can you start the Jenkins build again? Thanks for the help and patient during the process and really appreciate that.", "Thank you for the updates.\r\nJenkins, test this please."]}, {"number": 13812, "title": "Add missing `uint16` type registration for ops `CropAndResize`/`CropAndResizeGradBoxes`", "body": "This fix adds missing `uint16` type registration in `image_ops.cc` for `CropAndResize` and `CropAndResizeGradBoxes`.\r\n\r\nThe kernel of `uint16` is available for `CropAndResize` and `CropAndResizeGradBoxes` though it is missing in `image_ops.cc`. This fix addresses this issue.\r\n\r\nThis fix also adds incomplete test cases for `CropAndResize`\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Nice!  It looks like far fewer kernels are registered for Grad though, and specifically only floating point values are supported on GPU, but this seems okay.\r\n\r\n@tensorflow-jenkins test this please"]}, {"number": 13811, "title": "fix the issue: \"libcuda.so.1 not found\" and add some minor changes.", "body": "* The newer version of Bazel, i.e. ```BAZEL_VERSION=0.6.1``` won't cause any trouble. I've built the image that uses this version of Bazel successfully.\r\n* ```python-wheel``` has to be installed, otherwise\r\n    >error: invalid command 'bdist_wheel'\r\n\r\n  pops out while building the docker image.\r\n* I add *Compute Capability*```7.0``` in order to support *NVIDIA Tesla V100*.\r\n* Currently, ```ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1``` is necessary, otherwise you will see the following warning while building the image:\r\n    >/usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scc_Cops_Simage_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n\r\n    and the installation of TensorFlow will fail due to this.\r\n* I prefer ```tensorflow/tools/ci_build/builds/configured GPU``` rather than ```yes \"\" | ./configure``` when it comes to configure TensorFlow, since it outputs more information that sometimes could be helpful, such as: \r\n    > TF_BUILD_INFO = {container_type: \"gpu\", command: \"\", source_HEAD: \"bedfe8ac14bddbf21c5acf80d55abff9df4a7967\", source_remote_origin: \"https://github.com/tensorflow/tensorflow.git\", OS: \"Linux\", kernel: \"4.4.0-92-generic\", architecture: \"x86_64\", processor: \"Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\", processor_count: \"80\", memory_total: \"528276076 kB\", swap_total: \"0 kB\", Bazel_version: \"Build label: 0.6.1\", Java_version: \"1.8.0_131\", Python_version: \"2.7.12\", gpp_version: \"g++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\", swig_version: \"\", NVIDIA_driver_version: \"384.81\", CUDA_device_count: \"0\", CUDA_device_names: \"\", CUDA_toolkit_version: \"V9.0.176\"}", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "(make sure that the email in https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/13811.patch is the one you used to sign the CLA)", "I've changed my email that links to my GitHub's account. Is my CLA fine now?", "Still no. Your commit is still not updated. You may need to update the commit emails in this PR, and force push to the same branch.", "How about this way... I've linked my gmail account, the account that I use to sign CLA, with my current email account (chi-hung.weng@gmx.de) on GitHub. Is it Okay now?", "CLAs look good, thanks!\n\n<!-- ok -->", "CLA is now OK. Please also update your PR with all the above comments.", "Jenkins, test this please.\r\n"]}, {"number": 13810, "title": "tf.nn.max_pool memory leak?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 5.\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm using a tensorflow graph for offline preprocessing, and I believe I've stumbled onto a memory leak problem with tf.nn.maxpool. After certain amount of feed-forward operations (only inference, no training), I get a `Allocator (cuda_host_bfc) ran out of memory trying to allocate ...` error. This happens consistently after a number of data*points* fed through the graph, independtly on how those datapoints are spread over batches. e.g. with batchsize 4 I get this after 64 iterations, with batchsize 2 I get this error after 128 iterations.\r\nThe following rough code should reproduce this issue on a Titan XP with 12gb memory, didn't test this due to time constraints.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nimport tensorflow as tf\r\nfrom keras import Input\r\nfrom keras.layers import AvgPool2D, MaxPool2D, Lambda, Concatenate\r\nfrom keras.engine import Model\r\nimport numpy as np\r\n\r\nthumb_dim = 8192\r\nstrides = 1\r\npooling = 22\r\ninputs, outputs = [], []\r\nslide = Input([thumb_dim, thumb_dim, 3])\r\nmask = Input([thumb_dim, thumb_dim, 1])\r\ninputs.append(slide)\r\ninputs.append(mask)\r\n\r\nhsv_slide = Lambda(lambda x: tf.image.rgb_to_hsv(x))(slide)\r\nheatmap = Lambda(\r\n    lambda x: x[..., 1:2] * tf.cast(x[..., 2:3] > 0.3, 'float32'))(\r\n    hsv_slide)\r\n# heatmap = AvgPool2D(4, strides=1, padding='same')(heatmap)\r\n\r\nto_pool = Concatenate(axis=-1)([heatmap, mask])\r\nconcat = Lambda(lambda x: tf.stop_gradient(tf.nn.max_pool(x, ksize=(1, pooling, pooling, 1),\r\n                                                          strides=(1, strides, strides, 1), padding='VALID')))(to_pool)\r\n\r\noutputs.append(concat)\r\nrpn = Model(inputs, outputs)\r\nrpn.predict_generator(([\r\n    np.random.random((2, thumb_dim, thumb_dim, 3)),\r\n    np.random.random((2, thumb_dim, thumb_dim, 1))] for _ in range(200)))\r\n```", "comments": ["@yzhwang could this be up your street? I recall you looked into a somewhat relevant avg pool bug as well.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@basveeling I haven't been able to reproduce your issue on my GTX 1080 (which has less memory). Note that to make your code work, steps argument needs to be added in predict_generator(). I set steps to be 1. Could you provide more information on how to reproduce this so that I can take a look?", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 37 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 13809, "title": "gitignore: ignore build files relevant for iOS sample apps", "body": "", "comments": ["Can one of the admins verify this patch?"]}]