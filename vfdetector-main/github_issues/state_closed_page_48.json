[{"number": 53918, "title": "Add a check for Key being scalar tensor for MapStage and OrderedMapSt\u2026", "body": "\u2026age ops.\r\n\r\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\r\n\r\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\r\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\r\n\r\nPiperOrigin-RevId: 413822112\r\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2e", "comments": []}, {"number": 53917, "title": "Fix some integer overflow", "body": "Cherrypick b51b82fe65ebace4475e3c54eb089c18a4403f1c and 9cd218133f5 on r2.5", "comments": []}, {"number": 53916, "title": "Fix some integer overflow", "body": "Cherrypick b51b82fe65ebace4475e3c54eb089c18a4403f1c and a68f68061e263a88321c104a6c911fe5598050a8 on r2.6", "comments": []}, {"number": 53915, "title": "Fix some integer overflow", "body": "Cherrypick b51b82fe65ebace4475e3c54eb089c18a4403f1c and a68f68061e263a88321c104a6c911fe5598050a8 on r2.7", "comments": []}, {"number": 53914, "title": "Fix several integer overflows", "body": "Cherrypick 1b54cadd19391b60b6fcccd8d076426f7221d5e8 and 1e4692287b7 on r2.5", "comments": []}, {"number": 53913, "title": "Fix several integer overflows", "body": "Cherrypick 1b54cadd19391b60b6fcccd8d076426f7221d5e8 and e952a89b7026b98fe8cbe626514a93ed68b7c510 on r2.6", "comments": []}, {"number": 53912, "title": "Fix several integer overflows", "body": "Cherrypick 1b54cadd19391b60b6fcccd8d076426f7221d5e8 and e952a89b7026b98fe8cbe626514a93ed68b7c510 on r2.7", "comments": []}, {"number": 53911, "title": "iterating over `tf.Tensor` is not allowed", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.3\r\n- Python version:3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI have a dictionary that I build by accessing only the channel dimensions of an output layer of a convolutional neural network (it has a shape (100,24,24,6) )\r\nTherefore keys of this dictionary are tuples of tensor shape (6, ) . I want to map these keys to the input of the next layer using the tf.map_fn(). However, i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them .\r\nLooking for some help. Thank you.\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @saylideshmukh ! Could you please share a standalone code to reproduce this issue?", "Hi @saylideshmukh ! Is this issue  duplicate to  feature request  #53910 ?", "Yes", "Hi @mohantym I realized that I can try to access the tf.Tensor objects by delaying my python function i.e. delaying the execution of the do_mapping function. Any idea regarding this?", "@saylideshmukh ! Could you provide the gist of solution you are working on and close the duplicate feature request #53910 ?", "Hello @mohantym I have a built a custom layer and trained it by just passing the outputs of the previous layer to the custom layer and then recording these output values so that i can observe them . i use a dictionary for observing. I observed that most of the values in the channel dimension of output values are similar. So in my custom layer build i encode a dictionary (vmap)that have these enumerated similar values . Now i want to freeze all the previous layers to the custom layer and retrain my model by passing my encoded dictionary values (vmap) to the inputs of the preceding layer of the custom layer. For this purpose i need to map my enumerated values using tf.map_fn to the input channel dimension of the preceeding layer. The problem i am having is while trying to iterate over the keys of the dictionary(vmap), which are tuple of 6 tf.Tensor objects. I want to access this tf.Tensor objects of the key tuple. \r\nI have tried the eager execution and decorating my mapping function with tf.decorator so that i can iterate over these tf.Tensor objects . But the error i get is :TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\r\nEncountered error:\r\n\"\"\"\r\niterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n\r\nHere is the gist of the custom layer Class : \r\n\r\n\r\nclass valuemaplayer(keras.layers.Layer):\r\n    def __init__(self,data_format = None,**kwargs):\r\n        super(valuemaplayer,self).__init__(**kwargs)\r\n        self._vmap = {}\r\n        self._data = []\r\n        self._compression = True\r\n        self.data_format = conv_utils.normalize_data_format(data_format)\r\n      \r\n\r\n    def build(self, input_shape):\r\n            pass\r\n\r\n    def enable_compression(self):\r\n        value = list(self.get_values())\r\n        vmap = self._vmap\r\n        cnt = 0\r\n       \r\n        for v0 in value:\r\n            for v1 in v0:\r\n                for v2 in v1:\r\n                    for v3 in v2:\r\n                        v = tuple(v3)\r\n                        if v not in vmap:\r\n                            vmap[v]=cnt\r\n                            cnt+=1\r\n        self._compression = True\r\n\r\n    @tf.function\r\n    def do_mapping(self,pixel):\r\n        if self._compression :       #can i make this python free if cond?\r\n            pixel = tuple(pixel)\r\n        # to do convert pixel(of channel axis) from tensor to a tuple\r\n\r\n        for en in range(len(pixel.shape)) :   #can i make this in tf.range of tf.while_loop cond?\r\n            enumerated_value=self._vmap.get(pixel)\r\n        return enumerated_value\r\n\r\n\r\n    @tf.function\r\n    def call(self, inputs, training=True):#use eager execution or decorate with @tf.function\r\n        if self._compression:\r\n                # input_shape = inputs.get_shape()\r\n                # input_channel = self._get_input_channel(input_shape)\r\n                # channel_axis = self._get_channel_axis()\r\n            inputs = tuple(inputs[-1,-1,-1,:])\r\n\r\n\r\n            # TODO check if channel axis gets mapped by tf.map_fn\r\n            #resize inputs to 2 axis, 1 for each pixel and other channel , work on each pixel\r\n            changed_inputs = tf.map_fn(self.do_mapping(pixel=self._vmap.keys()), elems=inputs,fn_output_signature=tf.TensorSpec)\r\n        return changed_inputs\r\n        # # else compression is disabled\r\n        # # in case we're training, we do not want to observe values\r\n        if not training:\r\n            self._data.append(inputs)\r\n        return inputs\r\n\r\n        # get values of the output of value map layer\r\n    def get_values(self):\r\n        for d in self._data:\r\n            try:\r\n                d = d.numpy()\r\n            except AttributeError:\r\n                continue\r\n        yield d", "If the Tensor is of tf.data.Dataset instance then you can loop the tensor using [tf.data.Iterator](https://www.tensorflow.org/api_docs/python/tf/data/Iterator). Below is the simple illustration of the same. \r\n```\r\ndataset = tf.data.Dataset.range(2)\r\nfor element in dataset:\r\n  print(element)\r\n```\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53910, "title": "iterating over `tf.Tensor` is not allowed", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI have a dictionary that I build by accessing only the channel dimensions of an output layer of a convolutional neural network (it has a shape (100,24,24,6) )\r\nTherefore keys of this dictionary are tuples of tensor shape (6, ) . I want to map these keys to the input of the next layer using the tf.map_fn(). However, i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them .\r\nLooking for some help. Thank you.\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["Issue #53911 ", "@saylideshmukh \r\nCan you please elaborate about your Feature and please specify the Use Cases for this feature. Thanks!"]}, {"number": 53909, "title": "[ROCm] Fix for MI200 related performance issue with Resnet50 model.", "body": null, "comments": ["/cc @cheshire @chsigg @jurahul ", "@cheshire gentle ping", "@cheshire gentle ping."]}, {"number": 53908, "title": "Not getting consistent results with .h5 and .tflite models on different machines", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Windows 11, Intel Mac, Mac M1 v11.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary (tensorflow for windows and tensorflow-macos for Mac)\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.12\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: 11.0 (for training only)\r\n- GPU model and memory: Mac M1\r\n\r\n**Describe the current behavior**\r\nThe same h5 and/or TFLite model gives different outputs on different machines. For an image regression model where ground truth labels range between [0, 3] the results differ by ~0.2-0.3 on different machines, which causes thresholding issues.\r\n\r\n**Describe the expected behavior**\r\nThe same model should theoretically perform the same on all machines or at least they should match upto more precision.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe current model arch and the compilation info:\r\n```\r\nbase_model = tf.keras.applications.MobileNetV3Small(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\r\n                                               include_top=False,\r\n                                               weights='imagenet',\r\n                                               minimalistic=True)\r\n\r\nbase_model.trainable = True\r\n    \r\nmodel = tf.keras.Sequential([\r\n        base_model,\r\n        #pretrained_model,\r\n        tf.keras.layers.GlobalAveragePooling2D(),\r\n        #tf.keras.layers.Dense(256,activation = 'relu',dtype=tf.float32),\r\n        tf.keras.layers.Dense(2, dtype=tf.float32)\r\n    ])\r\n\r\nmodel.compile(\r\n        loss = tf.keras.losses.MeanAbsoluteError(),\r\n        optimizer = tf.keras.optimizers.Adam(),\r\n        metrics = [tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()],\r\n        steps_per_execution=64\r\n    )\r\n\r\nmodel.summary()\r\n```\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nMobilenetV3small (Functional (None, 4, 4, 1024)        1031848   \r\n_________________________________________________________________\r\nglobal_average_pooling2d (Gl (None, 1024)              0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 2)                 2050      \r\n=================================================================\r\nTotal params: 1,033,898\r\nTrainable params: 1,021,786\r\nNon-trainable params: 12,112\r\n```\r\nThe model was converted to the usual TFLite format as well, but the issue persisted.\r\n```\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\nThe model, thus obtained, can be used to reproduce the issue on different machines. Any ideas on why it might be happening and how to deal with it would mean a lot. Thanks!", "comments": ["@rohanmishra21 Could you please try on the latest version of TF v2.7.0 and let us know the outcome?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sushreebarsa Thanks for the reply! It seemed to be some issue with the tensorflow-metal plugin on the mac which led to inconsistencies, removing it solved the issue. Closing this issue now :)"]}, {"number": 53907, "title": "[tensorflow/examples] TensorFlow Lite Example for Android: Insecure protocols error during build", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10 Entreprise 21H1**\r\n- Android Studio Version: **Android Studio Arctic Fox 2020.3.1 Patch 4**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **Any android device**\r\n- tensorflow/examples Repo Version: [**Commit eb925e4**](https://github.com/tensorflow/examples/tree/eb925e4)\r\n- TensorFlow version: **tensorflow-lite:2.5.0**\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen I build any Android example, I get this error :\r\n```\r\n> Using insecure protocols with repositories, without explicit opt-in, is unsupported. Switch Maven repository 'ossrh-snapshot(http://oss.sonatype.org/content/repositories/snapshots)' to redirect to a secure protocol (like HTTPS) or allow insecure protocols. See https://docs.gradle.org/7.3.2/dsl/org.gradle.api.artifacts.repositories.UrlArtifactRepository.html#org.gradle.api.artifacts.repositories.UrlArtifactRepository:allowInsecureProtocol for more details. \r\n```\r\n\r\nWe need to set `allowInsecureProtocol` to `true` in the build.gradle for the example to compile. \r\n```\r\nmaven {\r\n    name 'ossrh-snapshot'\r\n    url 'http://oss.sonatype.org/content/repositories/snapshots'\r\n    allowInsecureProtocol = true\r\n    }\r\n```\r\nThis happens on this example and all other android examples: \r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android  \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. Get the tensorflow/examples repo with  `git clone https://github.com/tensorflow/examples`  \r\n1. Open `examples\\lite\\examples\\object_detection\\android` in Android Studio  \r\n1. Run `Build > Rebuild Project`  \r\n", "comments": ["This error seems to be on the gradle side, in the above example when the insecure url is used from the `gradle` file with `http:// `this exception is thrown, as per the error suggestion,  you need to set `allowInsecureProtocol` to `true` to build. \r\nThis won't be the issue when you build the example with secured url starting with `https:// `. Thanks!", "Do you want me to make a PR with https for each example?", "Was the build successful without any error after changing it to https in the build.gradle file?", "Commit [d315ddb](https://github.com/tensorflow/examples/commit/d315ddb) corrected this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53907\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53907\">No</a>\n"]}, {"number": 53906, "title": "This program requires version 3.9.0 of the Protocol Buffer runtime library, but the installed version is 3.8.0. Please update your library", "body": "env:\r\n16.04.1-Ubuntu X86_64, GPU Driver 470.94, Cuda 11.2, Cudnn 8.1\r\n\r\ni am tring to build the tensorflow 2.6.2 version with bazel 3.7.2 and Gcc 7.5.0. After about two hours, it actually generate the following shared libs:\r\nlibtensorflow_cc.so.2.6.2, libtensorflow_framework.so.2.6.2\r\n\r\nhowever, when i excute myself program which link to above shared libraries, it tips following errors:\r\n\r\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/stubs/common.cc:75] This program requires version 3.9.0 of the Protocol Buffer runtime library, but the installed version is 3.8.0. Please update your library. If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.\r\n\r\nActually, i check that the environment protobuf version with \"protoc --version\", it tells 3.9.2 version.\r\n\r\ni also remove all the protobuf installed before, downloading the 3.9.2 protobuf version and install. it still tells the same errors.\r\n\r\nDid the same question occure in your programe? can you give me some advices or a solution?\r\n\r\nThanks\r\n", "comments": ["this question has been solved.\r\n\r\nmy program depends two shared libraries, which both link to tensorflow shared libs. However, for the two libs, one linked to 2.6.2 tensorflow which include 3.9.2 protobuf, other one linked to 1.5.0 tensorflow which include 3.8.0\u3002\r\n\r\nafter i removed the old tensorflow, and corrected the link directories in Cmakelist.txt, the error tips didn't appear."]}, {"number": 53904, "title": "Fix more boosted trees vulnerabilities.", "body": "Please no longer use Boosted trees inside TF. The authors of the code no\r\nlonger work on this after getting their promotion and moving to other\r\nteams.", "comments": []}, {"number": 53903, "title": "Fix more boosted trees vulnerabilities.", "body": "Please no longer use Boosted trees inside TF. The authors of the code no\r\nlonger work on this after getting their promotion and moving to other\r\nteams.", "comments": []}, {"number": 53902, "title": "Fix more boosted trees vulnerabilities.", "body": "Please no longer use Boosted trees inside TF. The authors of the code no\r\nlonger work on this after getting their promotion and moving to other\r\nteams.", "comments": []}, {"number": 53901, "title": "DeepXDE for 1D Time-dependent Wave Equation", "body": "I have published a paper about modeling a 1D wave equation with a single time-dependent source. It would be great to see it in the list of related publications.", "comments": ["@engsbk \r\nIn order to expedite the trouble-shooting process , could you please provide more information on the issue reported here? \r\nThanks!"]}, {"number": 53900, "title": "Add a check for pad width to be a positive value.", "body": "PiperOrigin-RevId: 413275853\r\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "comments": []}, {"number": 53899, "title": "Add a check for pad width to be a positive value.", "body": "PiperOrigin-RevId: 413275853\r\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "comments": []}, {"number": 53898, "title": "Add a check for pad width to be a positive value.", "body": "PiperOrigin-RevId: 413275853\r\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "comments": []}, {"number": 53897, "title": "[tf.data] Set limit on number of threads used in threadpool_dataset.", "body": "PiperOrigin-RevId: 410922677\r\nChange-Id: Ib25814a99043ab10805b5d2d7088ae0e0b7b04fd", "comments": []}, {"number": 53896, "title": "[tf.data] Set limit on number of threads used in threadpool_dataset.", "body": "PiperOrigin-RevId: 410922677\r\nChange-Id: Ib25814a99043ab10805b5d2d7088ae0e0b7b04fd", "comments": []}, {"number": 53895, "title": "[tf.data] Set limit on number of threads used in threadpool_dataset.", "body": "PiperOrigin-RevId: 410922677\r\nChange-Id: Ib25814a99043ab10805b5d2d7088ae0e0b7b04fd", "comments": []}, {"number": 53894, "title": "Fix Segfault in Concat V2 shape function.", "body": "PiperOrigin-RevId: 412120654\r\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011be", "comments": []}, {"number": 53893, "title": "Fix Segfault in Concat V2 shape function.", "body": "PiperOrigin-RevId: 412120654\r\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011be", "comments": []}, {"number": 53892, "title": "Fix Segfault in Concat V2 shape function.", "body": "PiperOrigin-RevId: 412120654\r\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011be", "comments": []}, {"number": 53891, "title": "Fix integer overflow leading to divide by zero error in Unravel index\u2026", "body": "\u2026 kernel when dimensions product exceeds max int value.\r\n\r\nPiperOrigin-RevId: 413250052\r\nChange-Id: I9450b6e8acecd2e881a64b882e2b7c70e8e9289a", "comments": []}, {"number": 53890, "title": "Fix integer overflow leading to divide by zero error in Unravel index\u2026", "body": "\u2026 kernel when dimensions product exceeds max int value.\r\n\r\nPiperOrigin-RevId: 413250052\r\nChange-Id: I9450b6e8acecd2e881a64b882e2b7c70e8e9289a", "comments": []}, {"number": 53889, "title": "Fix integer overflow leading to divide by zero error in Unravel index\u2026", "body": "\u2026 kernel when dimensions product exceeds max int value.\r\n\r\nPiperOrigin-RevId: 413250052\r\nChange-Id: I9450b6e8acecd2e881a64b882e2b7c70e8e9289a", "comments": []}, {"number": 53888, "title": "Add negative bound check for row and column pooling_sequence in Fract\u2026", "body": "\u2026ionalAvgPoolGrad op to avoid out of bound heap access\r\n\r\nPiperOrigin-RevId: 413837346\r\nChange-Id: I2b86034101df31bee161abcb781755e236c7bccd", "comments": []}]