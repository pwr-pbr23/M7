[{"number": 53628, "title": "TensorFlow Lite C API TfLiteInterpreter misleading documentation", "body": "This is documentation bug in TFLite C API. I am not sure if I chose a proper issue tag.\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nSee [the documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/c/c_api.h#L146-L158) of `TfLiteInterpreterCreate`.\r\n\r\nAccording to this documentation, the snippet below is valid:\r\n```c++\r\nstd::vector<char> model_data;\r\n{\r\n    // Fill model data    \r\n}\r\nTfLiteModel *model = TfLiteModelCreate(model_data.data(), model_data.size());\r\n// Create the interpreter.\r\nTfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);\r\n// According to documentation, I can delete the model.\r\n// Hence, the lifetime of the model ends.\r\nTfLiteModelDelete(model);\r\n```\r\n\r\nFrom now on, according to [the documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/c/c_api.h#L98-L104) of `TfLiteModelCreate`, `model_data` \r\ncan be modified. Like the snippet below:\r\n```c++\r\nfor (char& e : model_data) {\r\n  e = 0;\r\n}\r\n```\r\nThis is just a demo to show that current or another process may modify the memory region.\r\n\r\nHowever, this is not valid, and corrupts the interpreter severely. Deleting a `TfLiteModel` object is ok, if one reads it from a file, because the interpreter relies on the file which is _assumed_ to stay unmodified during the lifetime of the interpreter. On the other hand, lifetime of an Interpreter must be bounded by the model which is bounded by the lifetime of the model data to avoid errors. Similar statement can be found in [the documentation](https://www.tensorflow.org/lite/api_docs/cc/class/tflite/interpreter#summary) of the C++ API (see the usage snippet).\r\n\r\nI think @jdduke is the one who can fix the documentation properly, but my suggestion is to replace `... and can destroy it immediately after creating the interpreter; the interpreter will maintain its own reference to the underlying model data` part with ` and the model data must outlive the interpreter` to avoid confusion.", "comments": ["@ebraraktas ,\r\nCan you please feel free to submit a PR for the requested change or share the link where requested change is to be made?\r\n", "@tilakrayal , it seems @rthadur has fixed the issue. You can close it if you want.", "@ebraraktas ,\r\nCan you please feel free to move this issue to closed status as related PR has been merged.Thanks!"]}, {"number": 53627, "title": "Xla const output cache on GPU ", "body": "#53609\r\n\r\n**Problem overview:** the const outputs of xla executable is kept in host memory. if the const output of executable need a device tensor, we need to do an H2D(host memory to device memory) .\r\n\r\n**Ideas overview:** cache the const output of xla executable to device memory, then replace H2D with lookup from cache.\r\n\r\n**Background(features async H2D)** :\r\n\r\nThe total ops in out model are set on the gpu device, so model spends data very fast, but the data part(parsing the data from TFRecord to Features) complete run on host memory, so we need copy features from host to device, this H2D will launch lots of requests of H2D on H2D stream. we use prefetch_to_device to overlap the time required for feature H2D.(prefetch_to_device: async copy features from host to device. The method of model obtaining data is replaced from synchronous H2D to obtain from cache)\r\n\r\n**Problem**:\r\n\r\nWe use xla to increase speed of training, but we found gpu util is 0 after xla run and model hung, As follows:\r\n\r\nWe carefully analyse nsys profiling file, found xla brought H2D once, and this H2D will block by features H2D in background.\r\n\r\n**Solution**:\r\n\r\nWe found that this H2D is generated by the xla op, and then we read the code about xla carefully, we found that the const output tensor of the executable is placed on the host, and then copy to the device side through memcpyH2D.\r\n\r\nWe can add a cache<executable output index, device tensor> on device. We put pair<executable output index, device tensor> to cache in the first time, and the next time replace to get device tensor from synchronous H2D to get device tensor from cache.\r\n\r\n**result(special model)**:\r\n\r\nno prefetch_to_device: No performance drop.\r\n\r\nprefetch_to_device: preformance 15%\u2191\r\n\r\nIs there a pr template\uff1f It's a little late in China, can I change it tomorrow?", "comments": ["https://github.com/tensorflow/tensorflow/issues/53609", "(tagged so that we run some internal tests, still pending more code review)", "@paynecl ", "Why does this check fail ? and Details is ```http://cl/423940400``` ???", "I've tagged it manually I think. Could you write a larger PR description?", "ci test:\r\nAMD ROCm: ```No module named 'packaging'```\r\nwindow error: ```404 Not Found```", "Your PR was rolled back because it caused data race issues (detected with TSAN). I believe you may need to add locks when accessing the cache.", "> Your PR was rolled back because it caused data race issues (detected with TSAN). I believe you may need to add locks when accessing the cache.\r\n\r\nI'm so sorry. \r\nWe use this feature on many of our models and have seen no data races, so can you give me a reproduction environment or a TSAN report or core dump file to help me to solve this data races?\r\n\r\nMaybe two session run a graph ?", "> I'm so sorry. We use this feature on many of our models and have seen no data races, so can you give me a reproduction environment or a TSAN report or core dump file to help me to solve this data races?\r\n> \r\n> Maybe two session run a graph ?\r\n\r\nThe test which fails is a TPU test, so unfortunately I cannot give you a reproduction environment. But I added a comment to the code which code lines are involved in the TSAN report finding.", "> > I'm so sorry. We use this feature on many of our models and have seen no data races, so can you give me a reproduction environment or a TSAN report or core dump file to help me to solve this data races?\r\n> > Maybe two session run a graph ?\r\n> \r\n> The test which fails is a TPU test, so unfortunately I cannot give you a reproduction environment. But I added a comment to the code which code lines are involved in the TSAN report finding.\r\n\r\nI probably know where the problem is, and I will test on our model ."]}, {"number": 53626, "title": "CUDA_ERROR_ILLEGAL_ADDRESS when enable unified memory in multi-GPUs training", "body": "I perform data parallel training on nvidia v100 based on horovod+tensorflow. Since a single gpu cannot accommodate the size of my model, I am trying to use tensorflow's unified memory through `per_process_gpu_memory_fractio`.\r\n\r\nWhen I use 4 gpus for training and enable unified memory, everything is fine, and the performance loss is acceptable.\r\n\r\nBut when I used 8 gpus for training and turned on unified memory, I encountered the following error:\r\n```\r\nE tensorflow/stream_executor/event.cc:34] error destroying CUDA event in context 0x7fd97d23d970: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\nterminate called after throwing an instance of 'std::logic_error'\r\n  what():  cudaEventSynchronize failed: an illegal memory access was encounteredterminate called after throwing an instance of \r\n```\r\n\r\n- Tensorflow version: 1.13.1\r\n- CUDA 10.0\r\n- CentOS 7.2\r\n\r\nI don\u2019t know the reason for this error, any troubleshooting suggestions will be very much appreciated.", "comments": ["Hi @firejq ! \r\n1.x versions of Tensorflow is not supported any more. Could you please try in latest version 2.7 and let us know ?Attaching relevant threads . [1](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/), [2](https://discuss.tensorflow.org/t/mult-gpus-training-with-unified-memory/6428).  Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53626\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53626\">No</a>\n"]}, {"number": 53625, "title": "model.build documentation absent on wensite", "body": "The build method for model class is not documented or/and is not present on the [page](https://www.tensorflow.org/api_docs/python/tf/keras/Model#methods_2). Can this be added?\r\nThank you!\r\n", "comments": ["@old-school-kid \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose), to provide more information on this issue?Thanks!", "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: \r\n\r\nPlease provide a link to the documentation entry: [Tensorflow model methods](https://www.tensorflow.org/api_docs/python/tf/keras/Model#methods_2)\r\n\r\n## Description of issue (what needs changing)\r\nThe documentation for `build` method is missing. \r\n\r\n### Clear description\r\n\r\nBasic method present in every model. Without `build` one wont be able to see the summary and cant see the network even.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example? There is no example right now but the method is used to build custom models in the documentation.\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content? No\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?  No\r\nSee the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "`build()` method is to be used for subclassed models, which do not know at instantiation time what their inputs look like.\r\n This method only exists for users who want to call `model.build()` in a standalone way (as a substitute for calling the \r\nmodel on real data to build it). It will never be called by the framework (and thus it will never throw unexpected errors in an unrelated workflow).\r\nYou can check the usage of build() in subclassed layer documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer?version=nightly) and [here](https://www.tensorflow.org/guide/keras/custom_layers_and_models)."]}, {"number": 53624, "title": "Fix time_major=False for Hybrid Bidirectional LSTM", "body": "We converted some models to TFLite through our own model converter and found out that the `EvalHybrid` function of the Bidirectional LSTM leads to a segfault. With some investigation, we figured out the cause is that the variable `time_major` is somehow pinned to `true`. This PR changes that by passing the real value of `time_major`.", "comments": []}, {"number": 53623, "title": "[TF:TRT] Fix access to TRT_ShapedWeights shape_ member, temp weights creation", "body": "This change resolves two long standing \"todos\" in the code base. The first is regarding the questionable public accessibility of the `shape_` member of `TRT_ShapedWeights`. This change adds appropriate const and non-const accessor methods, and all call sites are updated. The second issue involves the `GetTempWeights` methods of the WeightsStore class. These methods were directly returning `TRT_ShapedWeights` and using `TF_CHECK` methods to check errors, which can potentially cause a crash during the conversion process. The signatures are updated to return a `StatusOr<TRT_ShapedWeights>` and call sites are updated appropriately to handle potential errors.", "comments": ["@bixia1 for review when available", "Looks good to me. Please also squash your commits after you address the comment.", "All done, thanks"]}, {"number": 53622, "title": "Jit index64", "body": "Enable 64 bit indexing for GPU based JIT kernels \r\n@frgossen ", "comments": ["@kushanam Can you please resolve conflicts? Thanks!", "> @kushanam Can you please resolve conflicts? Thanks!\r\n\r\nResolved.", "> Thanks Kushan! This looks very good :)\r\nThank Frederik for your enormous helps!\r\n"]}, {"number": 53621, "title": "TF 2.4, CUDA 11.5.50, cudnn 8.3.1.22: Could not find any cudnn.h", "body": "**System information**\r\n- OS Platform and Distribution: Slackware64 Linux (current), kernel 5.15.11\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 2.4\r\n- Python version: 3.9\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 11.2.0\r\n- CUDA/cuDNN version: 11.5.50, 8.3.1.22\r\n- GPU model and memory: Nvidia Quadro RTX 4000, 8GB\r\n\r\n**the problem**\r\n\r\n     # ./configure\r\ngives this\r\n```\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11.5\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8\r\n\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: \r\n\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/share/cuda/bin,/usr/share/cuda/include,/usr/include,/usr/lib64,/usr/share/cuda\r\n\r\n\r\nCould not find any cudnn.h, cudnn_version.h matching version '8' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\nof:\r\n        '/usr/include'\r\n        '/usr/lib64'\r\n        '/usr/share/cuda'\r\n        '/usr/share/cuda/bin'\r\n        '/usr/share/cuda/include'\r\n```\r\nYet it is there:\r\n```\r\n$ ls /usr/share/cuda/include/cudnn.h\r\n/usr/share/cuda/include/cudnn.h\r\n```\r\nI don't have any `cudnn_version.h`. Should I?", "comments": [">I don't have any `cudnn_version.h`. Should I?\r\n\r\nIssue was the [the packager](https://slackbuilds.org/slackbuilds/14.2/development/cudnn/cudnn.SlackBuild) only installed `cudnn.h` and didn't install `cudnn_version.h`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53621\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53621\">No</a>\n"]}, {"number": 53619, "title": "[PluggableDevice] Add DEVICE_DEFAULT registration for Fill", "body": null, "comments": []}, {"number": 53618, "title": "Update double-conversion to 3.1.7, and use vendor-provided Bazel BUILD file instead.", "body": "The double-conversion library used in tensorflow has not been updated for quite some time (previous version used was in 2018) and the Bazel BUILD file was maintained by tensorflow.\r\n\r\nRecently double-conversion has provided Bazel BUILD file.\r\n\r\nThis PR updates double-conversion to the latest 3.1.7, and use the vendor-provided BUILD file instead so that tensorflow does not need to maintain the Bazel BUILD file separately.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 53617, "title": "Update sqlite to 3.37.1 (sqlite-amalgamation-3370100)", "body": "This PR updates sqlite to the latest 3.37.1 (sqlite-amalgamation-3370100)\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 53616, "title": "Android TensorFlow GPU Delegate", "body": "I want to apply cartoon effect to picture in android (java/kotlin or c/c++) with tensorflow lite. (tflite model / dr, fp16, int8 quantization)\r\n\r\nI found [this tutorial.](https://blog.tensorflow.org/2020/09/how-to-create-cartoonizer-with-tf-lite.html)\r\n\r\n[This code](https://github.com/margaretmz/Cartoonizer-with-TFLite) is also based on it.\r\n\r\nMy demo app works on CPU with 4 threads but when I want to test it with GPU delegate gives an [error.](https://i.stack.imgur.com/4whGx.jpg)\r\n\r\nI used several devices and the result was the same in all of them.\r\n\r\n```\r\n// Check if device supports GPU delegate\r\n\r\nval compatList = CompatibilityList()\r\n\r\nval isSupported = compatList.isDelegateSupportedOnThisDevice\r\n\r\n// If device does not support, then it will be done on 4 CPU threads\r\n\r\nval options = Model.Options.Builder().apply {\r\n\r\nif(isSupported) setDevice(Model.Device.GPU)\r\n\r\nelse setNumThreads(4)\r\n\r\n}.build()\r\n\r\nval model = WhiteboxCartoonGanFp16.newInstance(this, options)\r\n\r\nval process = model.process(picture)\r\n                     \r\nval cartoon = process.cartoonizedImageAsTensorImage\r\n\r\nval bitmap = image.bitmap\r\n                                    \r\nmodel.close()\r\n```", "comments": ["@soiavaq \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),also refer to the [TensorFlow Lite GPU delegate](https://www.tensorflow.org/lite/performance/gpu) for more details.\r\nThanks!", "+1 to what @sushreebarsa said -- It would be helpful to understand the used TFLite version etc. \r\n\r\nBy looking at the error message, it seems that it's hitting [this](https://github.com/tensorflow/tensorflow/blob/90393c40b1623cfae7929987ab830d0995f9bea7/tensorflow/lite/delegates/gpu/common/object_reader.cc#L47) path, and it's probably a case that's not handled by GPU delegate yet. \r\n@impjdi do you have any insight? ", "Sorry, absolutely no experience with Kotlin or its multithreading which OpenGL is very sensitive with.", "When I change version (downgrade tensorflow-lite from 2.7.0 to 1.15) , this problem is solved but in speed it is no different with CPU, while GPU should be faster.\r\nI think in this case it works on CPU instead of GPU.\r\nI tested other tflite models like MobileNet and they work.", "@soiavaq Could you please  check if your GPU inference part is running in a different thread than the main app thread in the latest version ?Could you please refer to [this](https://github.com/tensorflow/tensorflow/issues/41839) similar issue and let us know if it helps? Please make sure you're using TF v2.4 or later as older versions are no longer supported.If you could provide the error  in text format rather than image ,then it would be more helpful to analyze the issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53616\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53616\">No</a>\n"]}, {"number": 53614, "title": " Error loading option @local_config_cuda//:enable_cuda: Argument 0 of execute is neither a path, label, nor string.", "body": "**System information**\r\n- OS Platform : Windows 11\r\n- TensorFlow version: 2.8\r\n- Python version: 3.9.9\r\n- Bazel version : 421\r\n- GPU model and memory: GTX1650\r\n- CUDA/CUdnn: 11.5/8.3.1\r\n\r\n\r\n**Describe the problem**\r\nProblem when build from source.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=156\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=E:/Python3/python.exe\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=E:/Python3/python.exe --action_env PYTHON_LIB_PATH=E:/Python3/lib/site-packages --python_path=E:/Python3/python.exe --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.5 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --define=override_eigen_strong_inline=true\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:cuda in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:opt in file c:\\users\\dubli\\downloads\\tensorflow\\.tf_configure.bazelrc: --copt=/arch:FMA3 --host_copt=/arch:FMA3\r\nINFO: Found applicable config definition build:windows in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --features=compiler_param_file --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository local_config_cuda instantiated at:\r\n  C:/users/dubli/downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  C:/users/dubli/downloads/tensorflow/tensorflow/workspace2.bzl:878:19: in workspace\r\n  C:/users/dubli/downloads/tensorflow/tensorflow/workspace2.bzl:96:19: in _tf_toolchains\r\nRepository rule cuda_configure defined at:\r\n  C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl:1448:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1401, column 38, in _cuda_autoconf_impl\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1182, column 53, in _create_local_cuda_repository\r\n                host_compiler_includes = get_cxx_inc_directories(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 306, column 49, in get_cxx_inc_directories\r\n                includes_cpp = _get_cxx_inc_directories_impl(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 277, column 22, in _get_cxx_inc_directories_impl\r\n                result = raw_exec(repository_ctx, [cc, \"-E\", \"-x\" + lang, \"-\", \"-v\"] +\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/remote_config/common.bzl\", line 252, column 34, in raw_exec\r\n                return repository_ctx.execute(cmdline)\r\nError in execute: Argument 0 of execute is neither a path, label, nor string.\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1401, column 38, in _cuda_autoconf_impl\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1182, column 53, in _create_local_cuda_repository\r\n                host_compiler_includes = get_cxx_inc_directories(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 306, column 49, in get_cxx_inc_directories\r\n                includes_cpp = _get_cxx_inc_directories_impl(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 277, column 22, in _get_cxx_inc_directories_impl\r\n                result = raw_exec(repository_ctx, [cc, \"-E\", \"-x\" + lang, \"-\", \"-v\"] +\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/remote_config/common.bzl\", line 252, column 34, in raw_exec\r\n                return repository_ctx.execute(cmdline)\r\nError in execute: Argument 0 of execute is neither a path, label, nor string.\r\nINFO: Found applicable config definition build:cuda in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Argument 0 of execute is neither a path, label, nor string.\r\n\r\n**Any other info / logs**\r\nERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Argument 0 of execute is neither a path, label, nor string.\r\n", "comments": ["Hi @DublikuntMux ! Could you try again with TF 2.7 and Python 3.8/3.9 ? You can use below command to build Tensorflow with GPU support. \r\n`bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n`    \r\nThanks!", "Repository rule cuda_configure defined at:\r\n  C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl:1448:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1401, column 38, in _cuda_autoconf_impl\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1182, column 53, in _create_local_cuda_repository\r\n                host_compiler_includes = get_cxx_inc_directories(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 306, column 49, in get_cxx_inc_directories\r\n                includes_cpp = _get_cxx_inc_directories_impl(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 277, column 22, in _get_cxx_inc_directories_impl\r\n                result = raw_exec(repository_ctx, [cc, \"-E\", \"-x\" + lang, \"-\", \"-v\"] +\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/remote_config/common.bzl\", line 252, column 34, in raw_exec\r\n                return repository_ctx.execute(cmdline)\r\nError in execute: Argument 0 of execute is neither a path, label, nor string.\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1401, column 38, in _cuda_autoconf_impl\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1182, column 53, in _create_local_cuda_repository\r\n                host_compiler_includes = get_cxx_inc_directories(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 306, column 49, in get_cxx_inc_directories\r\n                includes_cpp = _get_cxx_inc_directories_impl(\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/gpus/cuda_configure.bzl\", line 277, column 22, in _get_cxx_inc_directories_impl\r\n                result = raw_exec(repository_ctx, [cc, \"-E\", \"-x\" + lang, \"-\", \"-v\"] +\r\n        File \"C:/users/dubli/downloads/tensorflow/third_party/remote_config/common.bzl\", line 252, column 34, in raw_exec\r\n                return repository_ctx.execute(cmdline)\r\nError in execute: Argument 0 of execute is neither a path, label, nor string.\r\nINFO: Found applicable config definition build:cuda in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Argument 0 of execute is neither a path, label, nor string.", "Reinstall MSVC and tensorflow repo fix problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53614\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53614\">No</a>\n"]}, {"number": 53611, "title": "Problem with setting up CUDA or cuDNN", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10 21H2 19044.1415\r\n- TensorFlow installed from: pip install (binary)\r\n- TensorFlow version: 2.7.0 (keras too)\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: nope, pip\r\n- CUDA/cuDNN version: cudnn-windows-x86_64-8.3.1.22 cuda 11.5 \r\n- GPU model and memory: GTX 1050Ti 4GB\r\n\r\n\r\nI get this error in terminal \r\n`\r\nCould not load library cudnn_cnn_infer64_8.dll. Error code 126\r\nPlease make sure cudnn_cnn_infer64_8.dll is in your library path!\r\n`\r\n\r\n![installed cudnn .dll files](https://i.ibb.co/C7qgYB5/temp.jpg)\r\n\r\n\r\nI also tried with v11.2 with modifiaction on system env. variable, did not help...\r\n\r\nAlso adding this lines of code did not helped\r\n`\r\nimport os\r\nos.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.5/bin\")\r\n`\r\n\r\nThe problem shows on clear python env. and in jupyter notebook.", "comments": ["Hi @suchencjusz! Can you please check this [thread](https://stackoverflow.com/questions/66355477/could-not-load-library-cudnn-ops-infer64-8-dll-error-code-126-please-make-sure) for answer? Thanks!", "@mohantym I checked your thread, did not worked.", "@suchencjusz ! Could you try these following steps and let us know ?                                                                                          \r\n1. Please Uninstall Cuda \r\n2. Switch to Cuda 11.2 (presently 11.5 as mentioned in template) and Cudnn 8.1  \r\n3. Try  again with a new environment  .\r\n\r\nIf it still displays same error then try copying the .dll files from Cuda download location. Ref [1](https://www.tensorflow.org/install/source#gpu) ,[ 2 ](https://stackoverflow.com/a/69935795/11530462) .Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53611\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53611\">No</a>\n", "Yes this issue persists. Some of the devices it is not working at all."]}, {"number": 53610, "title": "Loading a Keras model which contains __ne__ or __eq__ operators fails", "body": "I posted this on Keras first, but it didn't get any attention, so posting here as well.\r\nhttps://github.com/keras-team/keras/issues/15832", "comments": ["@OmriSteiner Sorry for the late response in [keras-team/keras#15832](https://github.com/keras-team/keras/issues/15832) !\r\nPlease move this issue to close status as we will track the other ticket in keras-team/keras repo.  \r\nWe are addressing the Keras issues in `keras-team/keras repo`. To know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53610\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53610\">No</a>\n"]}, {"number": 53609, "title": "[XLA] The output of const type have some redundancy H2D ops", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): master\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: ?? yes\r\n\r\n**Describe the current behavior**\r\nxla_run will move const type output from Host to Device in every steps.\r\n\r\n**Describe the expected behavior**\r\nFill output from cache instead of H2D\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):yes\r\n- Briefly describe your candidate solution(if contributing):\r\n1. Record xla const output: \r\n```\r\nmap<output_idx, output_const_tensors> cache_;\r\n```\r\n2. Get output from cache; \r\n```\r\nfor (int i = 0; i < ctx->num_outputs(); ++i) {\r\n  ...\r\n  if (kernel->outputs[i].is_constant) {\r\n    ctx->allocate_output(i, const_tensor.shape(), &output_tensor));\r\n    output_tensor = cache_[i];\r\n  else(others) {\r\n    ...\r\n  }\r\n  ...\r\n}\r\n```\r\n\r\n### Background\r\n1. GPU training data H2D:\r\n  Training data in CPU and model in GPU, so we need to move training data from host to device.We want to Increase training speed so we use ```prefetch_to_device``` to async H2D and training.\r\n2. XLA H2D:\r\n![image](https://user-images.githubusercontent.com/33950866/147870122-7d7fd471-2b63-4a4c-bae6-83ba86842b05.png)\r\n(tensorflow/compiler/jit/xla_launch_util.cc:290, Status XlaComputationLaunchContext::PopulateOutputs)\r\n### Problem\r\n  Background 1 and Background 2 is in two completely unrelated threads, so XLA H2D maybe wait until features H2D done, like:\r\n![image](https://user-images.githubusercontent.com/33950866/147870952-9ac17707-6059-4b7a-9415-a3622c1e236a.png)\r\n### Solution\r\n  I think that the output of the constant type has the same value at each step, so we don't need to have H2D for each step. We should cache the output in the device, and then get the result in the cache.\r\n  I try to cache device tensor, like:\r\n![image](https://user-images.githubusercontent.com/33950866/147870539-b48bc0d2-7ac7-40a7-9f50-80e0737b18ec.png)\r\n", "comments": ["@zhaozheng09 ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53609\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53609\">No</a>\n"]}, {"number": 53608, "title": "Tensorflow consuming too much GPU memory?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Windows 10\r\n- Tensorflow 2.5.0 (from pip)\r\n- Python version: 3.8.9\r\n- CUDA/cuDNN version: CUDA 11.2 / CuDNN 8.1\r\n- GPU model and memory: NVIDIA RTX 3080 (10GB)\r\n\r\n**Describe the current behavior**\r\nI am running a basic ResNet50 model w/ 23.6M params (~.1GB). This model takes up 8.2GB of GPU memory upon being loaded (after calling `model.compile`). **However, the largest batchsize I can run is 48 before I get OOM errors**. During training w/ batchsize 48, it takes up 9.1/10GB GPU memory. This batchsize seems very low to me for a 10GB RTX 3080 GPU. Is this expected or is this indeed a performance issue?   \r\n\r\n\r\n**Describe the expected behavior**\r\nI would imagine I can run the model with a much larger batchsize. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nprint(\"TF version:\", tf.__version__)\r\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\r\n\r\nBATCH_SIZE = 48\r\nN_CLASSES = 27\r\nINPUT_SHAPE = (240, 320, 3)\r\n\r\nclass DataGenerator(tf.keras.utils.Sequence):\r\n    'Generates random data'\r\n\r\n    def __init__(self, batch_size=32, dim=INPUT_SHAPE, n_classes=10):\r\n        'Initialization'\r\n        self.dim = dim\r\n        self.batch_size = batch_size\r\n        self.n_classes = n_classes\r\n\r\n    def __len__(self):\r\n        'Denotes the number of batches per epoch'\r\n        return 10000000\r\n\r\n    def __getitem__(self, index):\r\n        'Generate one batch of data'\r\n        X = np.random.uniform(size=([self.batch_size] + list(self.dim)))\r\n        y = np.random.randint(0, self.n_classes, size=(self.batch_size, 1))\r\n        return X, y\r\n\r\n\r\ntrain_ds = DataGenerator(batch_size=BATCH_SIZE, n_classes=N_CLASSES)\r\nvalid_ds = DataGenerator(batch_size=BATCH_SIZE, n_classes=N_CLASSES)\r\n\r\nbase_model = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, pooling='avg',\r\n                                                               weights=None, input_shape=INPUT_SHAPE)\r\nmodel = tf.keras.Sequential([\r\n    # Explicitly define the input shape so the model can be properly\r\n    # loaded by the TFLiteConverter\r\n    tf.keras.layers.InputLayer(input_shape=INPUT_SHAPE),\r\n    base_model,\r\n    tf.keras.layers.Dense(N_CLASSES, kernel_regularizer=tf.keras.regularizers.l2(0.0001))\r\n])\r\nmodel.build((None,) + INPUT_SHAPE)\r\nmodel.summary()\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\r\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n    metrics=['accuracy']\r\n)\r\n\r\nhist = model.fit(\r\n    train_ds,\r\n    epochs=5, steps_per_epoch=100,\r\n    validation_data=valid_ds,\r\n    validation_steps=10).history\r\n```\r\n\r\n**Output log**\r\n```\r\nC:\\code\\ai_dev\\venv\\Scripts\\python.exe \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2021.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\" --multiproc --qt-support=auto --client 127.0.0.1 --port 64926 --file C:/Users/Administrator/AppData/Roaming/JetBrains/PyCharmCE2021.3/scratches/scratch.py\r\nConnected to pydev debugger (build 213.5744.248)\r\n2022-01-01 21:10:24.141719: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\nTF version: 2.5.0\r\n2022-01-01 21:10:28.471977: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n2022-01-01 21:10:28.503983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2022-01-01 21:10:28.504378: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2022-01-01 21:10:28.938839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2022-01-01 21:10:28.938949: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2022-01-01 21:10:29.194104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n2022-01-01 21:10:29.225316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n2022-01-01 21:10:29.439959: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n2022-01-01 21:10:29.640869: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n2022-01-01 21:10:30.322655: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2022-01-01 21:10:30.322801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\nGPU is available\r\n2022-01-01 21:10:30.357061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-01-01 21:10:30.358533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2022-01-01 21:10:30.358724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-01 21:10:31.060271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-01 21:10:31.060365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2022-01-01 21:10:31.060412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2022-01-01 21:10:31.062137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7440 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:09:00.0, compute capability: 8.6)\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nresnet50v2 (Functional)      (None, 2048)              23564800  \r\n_________________________________________________________________\r\ndense (Dense)                (None, 27)                55323     \r\n=================================================================\r\nTotal params: 23,620,123\r\nTrainable params: 23,574,683\r\nNon-trainable params: 45,440\r\n_________________________________________________________________\r\nBackend TkAgg is interactive backend. Turning interactive mode on.\r\n2022-01-01 21:15:37.453277: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nEpoch 1/5\r\n2022-01-01 21:15:47.718187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2022-01-01 21:15:48.810810: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\r\n2022-01-01 21:15:50.745911: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2022-01-01 21:15:51.640704: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2022-01-01 21:15:53.390127: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:53.390348: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:53.401685: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n2022-01-01 21:15:54.460765: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.461055: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.487507: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.487759: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.583271: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.583537: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.790347: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2022-01-01 21:15:54.790599: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n100/100 [==============================] - 40s 219ms/step - loss: 3.3853 - accuracy: 0.0202 - val_loss: 3.3123 - val_accuracy: 0.0000e+00\r\nEpoch 2/5\r\n100/100 [==============================] - 27s 203ms/step - loss: 3.3962 - accuracy: 0.0150 - val_loss: 3.3624 - val_accuracy: 0.0000e+00\r\nEpoch 3/5\r\n\r\nProcess finished with exit code -1\r\n```", "comments": ["Hi @rsandler00 ! \r\nIt is not replicating in TF 2.7 [Colab environment](https://colab.sandbox.google.com/gist/mohantym/6c4cdc04e32e694e4722c85f367839c7/github_53608.ipynb)  though.    \r\n            \r\nI see this message \"This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2 .To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\"  in  error stack trace. \r\n\r\nCan you try again after building Tensorflow 2.7 referring these threads and let us know if the issue still persist? Ref [1](https://www.tensorflow.org/install/source_windows) , [2](https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions) ,[3](https://technofob.com/2019/06/14/how-to-compile-tensorflow-2-0-with-avx2-fma-instructions-on-mac/) Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53607, "title": "Nit in scatter_nd_update", "body": "`\"Scatter` -> `Scatter`", "comments": ["@mihaimaruseac \r\n\r\nYes.\ud83d\ude05 \r\nHowever I came across this while going through the docs and just raised a PR for the same immediately. \r\n\r\nThanks for the approval.", "#53340"]}, {"number": 53606, "title": "Unable to restore custom metric.", "body": "I have written a code for training a neural network in tensorflow where I added a custom metric just for the sake of printing the current learning rate at each epoch (this is useful for me when I use learning schedules). I trained my model and then I tried to load it again for re-training however I got the following error:\r\n\r\nUnable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\r\n\r\nI tried the proposed solution in many other posts in which one use the custom_objects for indicating the custom metric, however I have not been able to solve this issue, below a simple code to reproduce the issue.\r\n\r\n```python\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n\r\nprint(tf.__version__)\r\n\r\ndef get_lr_metric(optimizer):\r\n    def lr(y_true, y_pred):\r\n        return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\r\n    return lr\r\n\r\n\r\n_input = tf.keras.layers.Input(shape=(500), name=\"fbank\") # B*T*F*c\r\nout = tf.keras.layers.Dense(50, activation=\"tanh\")(_input)\r\nprobabilities = tf.keras.layers.Dense(2, activation=\"softmax\")(out)\r\nmodel = tf.keras.Model(inputs=_input, outputs=probabilities)\r\noptimizerAdam = keras.optimizers.Adam(learning_rate=1e-5)\r\nlr_metric = get_lr_metric(optimizerAdam)\r\n\r\nmodel.compile(optimizerAdam, loss=tf.keras.losses.CategoricalCrossentropy(), \r\n              metrics=['accuracy', lr_metric])\r\n\r\nmodel.summary()\r\n\r\nx=np.random.rand(300,500)\r\ny=np.random.rand(300,2)\r\nmodel.fit(x,y,batch_size=100, epochs=2)\r\n\r\npath = 'saved_model/'\r\nmodel.save(path, save_format='tf')\r\n\r\ndel model\r\nmodel = tf.keras.models.load_model('saved_model', compile=False,custom_objects={\"lr_metric\": lr_metric})\r\nprint(\"Done\")\r\n\r\n\r\n```", "comments": ["@saddamhijazi \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Thank you, the issue is posted on the keras project.\r\n"]}, {"number": 53605, "title": "What can I use instead of \"tf.contrib.layers.embed_sequence\"", "body": "I try to build a chatbot for studying purpose, but it seems like the lesson is quite out-dated, they used tensorflow v1 and there are some problems with that.\r\n\r\nWhat can I use instead of \"tf.contrib.layers.embed_sequence\" since \"contrib\" is no longer available and I can't find anything in [tf_slim/layers](https://github.com/google-research/tf-slim/tree/master/tf_slim/layers) and [addons](https://github.com/tensorflow/addons), too.", "comments": ["@BuuDien ,\r\nPlease take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/46666#issuecomment-775313197) from the issue and the SO [link](https://stackoverflow.com/questions/55518033/where-can-i-find-tensorflow-contrib-layers-for-tensorflow-2-0).It helps.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53604, "title": "MaxPool2D crashes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: cuda 11.2\r\n- GPU model and memory: n/a\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nkernel_size = [1,3]\r\nstrides = [2,2]\r\nlayer = tf.keras.layers.MaxPool2D(kernel_size,strides=strides)\r\ninput_tensor = tf.random.uniform([3, 1, 1, 64], dtype=tf.float32)\r\nlayer(input_tensor) \r\n# Aborted (core dumped)\r\n```\r\nThis code would crash with GPU. \r\n\r\n**Describe the expected behavior**\r\nWith CPU the output of the `MaxPool2D` layer would be a tensor of shape `(3, 1, 0, 64)`. I think the output should be similar with GPU, or at least there should also be some error checking instead of crashing.\r\n", "comments": ["Input tensor should be of shape [1, x, 3, y] at least as you have set the pool size as [1, 3]. I guess this is why its crashing.", "Hi @chunduriv ! Could you please look at this issue ? It is replicating in GPU mode only. Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/43b459c155f4b16a69854f2a1b4ec800/github_53604.ipynb) for reference. Thanks!", "@lugalUrim \r\nI ran the code and made few changes on GPU, as per errors reported in keras team, please find the gist [here](https://colab.research.google.com/gist/Saduf2019/61e7a8c327dd820b9a20e4dff383e2e3/untitled653.ipynb), you may fix the error in this using this [link](https://github.com/nginyc/rafiki/issues/154),[link1](https://stackoverflow.com/questions/55195701/tensorflow-why-does-cudnn-fails-to-launch-cuda-error-launch-failed).\r\n\r\nIn case of any more keras related issues please create this in keras repo.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53604\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53604\">No</a>\n"]}, {"number": 53603, "title": "[TF:TRT] Remove dead code from convert_nodes.cc", "body": "Removes some dead helper functions from `tf2tensorrt/convert/convert_nodes.cc`.", "comments": ["@bixia1 please review when available"]}, {"number": 53602, "title": "[TF:TRT] Consolidate helper functions for TRT and TF tensor shape types", "body": "Currently, there are  multiple functions for helping convert `nvinfer1::Dims` to  and from other types, yet they are declared in disparate translation units. This PR cleans up the helper functions in `convert_nodes.cc` for converting from TF Tensor shape types to `nvinfer1::Dims`. One helper function accomplishes the same task as `TensorShapeToTrtDims` in `convert/utils.h` yet performs fewer error checks. It is moved to `convert/utils.h` and renamed `TensorShapeToTrtDimsUnsafe`. Another function is highly specific and only used once and thus is inlined at the call site, resulting in code reduction and improved clarity.", "comments": ["Depends on #53623", "@bixia1, probably best to do #53623 first as that reduces the number of changes here", "For the adapter class, changed strategy to return errors where they occur (e.g. on creation of the adapter) rather than storing an internal status. This simplified usage. Some of the most common use cases (constructing a `DimsAdapter` from `nvinfer1::Dims`, or from a span) then have limited error checking requirements, and we don't need to add `StatusOr` to all the property access functions.", "rebased", "@bixia1 I squashed the one line correction in the `trt_engine_resource_ops_test.cc` as we discussed", "I came up with the same change and am in the process of merging, currently blocked by failure that doesn't look relevant.", "Merged, closing"]}, {"number": 53601, "title": "[TF:TRT] Elide extra func for nvinfer::Dims equality testing", "body": "Removes a redundant helper function `DimsEqual` for comparing two `nvinfer1::Dims` objects. This function is an exact duplicate of the equality operator in `tf2tensorrt/common/utils.h`.", "comments": ["@bixia1 please review when available"]}, {"number": 53600, "title": "raggedtensor: how to convert a list of numpy array with a uniform dim in a certain axis to a ragged tensor", "body": "suppose I have three numpy array with shape (1,3) and Stack them to group with shape (2,3) and (1,3). Then I stack them with tf.ragged.stack to get a ragged tensor\r\n\r\n```\r\nx1 = np.asarray([1,0,0])\r\nx2 = np.asarray([0,1,0])\r\nx3 = np.asarray([0,0,1])\r\n\r\ngroup_a = np.stack([x1,x2])\r\ngroup_b = np.stack([x3])\r\n\r\n\r\nac = tf.ragged.stack([group_a,group_b], axis=0)\r\n```\r\n\r\nI expect its shape to be (2, None, 3) but (2, None, None). How to implement it?? Using tf 2.5.2", "comments": []}, {"number": 53599, "title": "Tensor Issue. 1", "body": "https://github.com/tensorflow/tensorflow/blob/c256c071bb26e1e13b4666d1b3e229e110bc914a/tensorflow/python/ops/tensor_array_ops.py#L961-L1296", "comments": ["@RonSherfey ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced] or if possible share a colab gist with the issue reported."]}, {"number": 53598, "title": "Keras: how to define custom loss function for a ragged tensor output with shape(None, 1)", "body": "Suppose the output of my model is with shape (None,1) and how can I define custom loss function such as\r\n```\r\ndef mycrossentropy(y_true, y_pred):\r\n    loss = K.categorical_crossentropy(K.exp(y_true)/K.sum(K.exp(y_true)), K.exp(y_pred)/K.sum(K.exp(y_pred)))\r\n    return loss\r\n```\r\nThis function is used for normal tensor with shape (20,1) before. Now with new model, the output shape become (None, 1) ragged tensor. So, in this function y_pred should be a ragged tensor with shape(None, 1) and I can guarantee that y_true and y_pred have the same dimensions during training.\r\n\r\nI am using tf 2.5.2 and tf.keras API for model define", "comments": ["Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 53596, "title": "[PluggableDevice] Add DEVICE_DEFAULT registration for Min and Max", "body": null, "comments": ["Hi,\r\n\r\nCould someone review this PR? This is something that we need for the release of our pluggable device plugin.\r\n\r\nThank you!"]}, {"number": 53595, "title": "An AttributeError message in base_layer.py", "body": "In the definition of input_shape(self), the other half of the double quote \u201d\u201c is missing in the AttributeError message", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 53594, "title": "Keras: How to use another model as a layer in current model which input is ragged tensor and  output is also ragged tensor with same shape", "body": "Suppose I have a base model take two inputs and output single value:\r\n\r\n```\r\n# define two input\r\ninput1 = keras.Input(shape=(100,), dtype=tf.int8)\r\ninput2 = keras.Input(shape=(20,), dtype=tf.int8)\r\n# DNN for onehot feature\r\ndense1 = Dense(32, activation='relu')(input1)\r\ndense2 = Dense(4, activation='relu')(input2 )\r\n# output \r\noutput = Dense(1, activation='sigmoid')(Concatenate(axis=1)([dense1 , dense2 ]))\r\n# define base model \r\nitem_base_model = keras.Model(inputs=[input1, input2], outputs=output, name=\"base_model\")\r\n```\r\n\r\nThen I have a model take (None,100) and (None, 20) array as two inputs:\r\n```\r\n# define input list\r\ninput1_list = keras.Input(shape=(None, 100],), dtype=tf.int8)\r\ninput2_list = keras.Input(shape=(None, 20,), dtype=tf.int16)\r\n```\r\n\r\nI want to ask that how I can call the based model for each input in the inpu1_list and input2_list and get their output as a tensor with shape (None,).  Finally, I will train the entire model", "comments": ["@zwh14 ,\r\n In order to expedite the trouble-shooting process, could you please provide a complete code and the TensorFlow version you are using.\r\n", "Also can you please take a look at link [1](https://stackoverflow.com/questions/47678108/keras-use-one-model-output-as-another-model-input) and [2](https://github.com/keras-team/keras/issues/3465) with the similar issue.It helps.Thanks!", "@tilakrayal\r\n\r\nI am using the tf 2.5.2.\r\nIn fact that is almost all code. I first define the base model. Its inputs is with shape(100,) and (20,) and it output a value. \r\nThan I want to define another model, its inputs is with shape(None,100,) and (None, 20). I just want to iterate the ragged tensor with the base model to get a (None,) shape output. I think the output is also ragged tensor? I do not know how to implement ", "This is the base model\r\n\r\n```\r\n# define item-base model\r\ninput_aspects_onehot = keras.Input(shape=(100,), dtype=tf.int8)\r\ninput_aspects_ordinal = keras.Input(shape=(20,), dtype=tf.int16)\r\n\r\n\r\n# DNN for onehot feature\r\ndense1_onehot_output = Dense(256, activation='relu')(input_aspects_onehot)\r\ndense2_onehot_output = Dense(64, activation='relu')(dense1_onehot_output)\r\n\r\n# Embedding and Max Pool Layer for ordinal feature\r\naspects_embedding = Embedding(input_dim=2000, \r\n                              output_dim=64, \r\n                              mask_zero=True)(input_aspects_ordinal)\r\n\r\naspects_embedding_maxpool = GlobalMaxPooling1D()(aspects_embedding)\r\n\r\n# stacking the two dense2_onehot_output and aspects_embedding_maxpool\r\ndense_stack_output = Dense(64, activation='relu')(Concatenate(axis=1)([dense2_onehot_output, aspects_embedding_maxpool]))\r\n\r\n# output for one item\r\noutput = Dense(1)(dense_stack_output)\r\n\r\nitem_base_model = keras.Model(inputs=[input_aspects_onehot,input_aspects_ordinal], outputs=output, name=\"item_base_model\")\r\nitem_base_model.summary()\r\n```\r\nThis is another model which will call the base model\r\n\r\n```\r\n# define list model\r\ninput_aspects_onehot_list = keras.Input(shape=(None, 100,), dtype=tf.int8)\r\ninput_aspects_ordinal_list = keras.Input(shape=(None, 20,), dtype=tf.int16)\r\n\r\nbase_model_output_list = []\r\nfor i in range(len(input_aspects_onehot_list)):\r\n    base_model_output_list.append(item_base_model(input_aspects_onehot_list[i], input_aspects_ordinal_list[i]))\r\noutput = tf.stack(base_model_output_list)\r\n\r\nitem_base_model = keras.Model(inputs=[input_aspects_onehot_list,input_aspects_ordinal_list], outputs=output, name=\"model\")\r\n```", "Obviously I can't do a for loop for keras Input.I'm just trying to express that logic", "@zwh14 ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53594\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53594\">No</a>\n"]}]