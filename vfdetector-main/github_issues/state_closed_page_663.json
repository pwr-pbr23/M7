[{"number": 33713, "title": "ArithmeticOptimizer produced AlreadyExistsError for certain architectures when run on CPU", "body": "", "comments": []}, {"number": 33712, "title": "Conversion to TFLite model does not work -error ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (but, from example at taken from https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c02_dogs_vs_cats_with_augmentation.ipynb)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):  2.0.0\r\n- Python version: 3.6.1  (via Jupyter notebook)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI can save the tensorflow keras model to an h5 file but, when subsequently try to convert to TFLite using code below it fails.   Following directions at https://www.tensorflow.org/tutorials/keras/save_and_load  to perform conversion to TFLite (see code below) \r\n\r\n**Describe the expected behavior**\r\nShould save a TFLite file after conversion\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`tflite_file  = os.path.join(BASE_DIRECTORY, 'my_tflite_model.h5')\r\nprint(\" want to save tflite_file\" + tflite_file)\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nprint(\"converter = \" + str(converter))\r\ntflite_model = converter.convert()\r\n\r\n#no save the tflight model to the file\r\ntflite_model.save(tflite_file)`\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nError I am getting:-------------------------------\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-49-fc606e1e0a8b> in <module>()\r\n      5 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n      6 print(\"converter = \" + str(converter))\r\n----> 7 tflite_model = converter.convert()\r\n      8 \r\n      9 #no save the tflight model to the file\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\lite.py in convert(self)\r\n    444         input_tensors=input_tensors,\r\n    445         output_tensors=output_tensors,\r\n--> 446         **converter_kwargs)\r\n    447 \r\n    448     if self._is_calibration_quantize():\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    447       input_data.SerializeToString(),\r\n    448       debug_info_str=debug_info_str,\r\n--> 449       enable_mlir_converter=enable_mlir_converter)\r\n    450   return data\r\n    451 \r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198       stdout = _try_convert_to_unicode(stdout)\r\n    199       stderr = _try_convert_to_unicode(stderr)\r\n--> 200       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    201   finally:\r\n    202     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\nTraceback (most recent call last):\r\n  File \"c:\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\python36\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Python36\\Scripts\\toco_from_protos.exe\\__main__.py\", line 5, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.contrib'\r\n\r\n", "comments": ["Please note I have read the issue 25162 that I believe is related but, was not resolved.  Does this have something to do with running on Windows?\r\nhttps://github.com/tensorflow/tensorflow/issues/25162"]}, {"number": 33711, "title": "TFLITE MODEL INPUT DYNAMIC INPUT SIZE", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**: 1.14\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nWhen I am resizing input tensor in tflite model and allocating the tensors I am getting error )Node number 0 (RESHAPE) failed to prepare.\r\n\r\n\r\n### Source code / logs\r\n File \"tflite_inference.py\", line 176, in <module>\r\n    inference_from_tflite(path_to_tflite,path_to_input)\t\r\n  File \"tflite_inference.py\", line 118, in inference_from_tflite\r\n    interpreter.allocate_tensors()\r\n  File \"/home/asus/miniconda/espnet/tools/venv/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\", line 95, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/home/asus/miniconda/espnet/tools/venv/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: tensorflow/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (44000 != 4000)Node number 0 (RESHAPE) failed to prepare.\r\n\r\n\r\nSource Code:\r\n        interpreter = tf.lite.Interpreter(model_path=tflite_model)\r\n        #Getting the input data\r\n        input_data = np.load(input_mel)\r\n        print(input_data.shape)\r\n        input_details = interpreter.get_input_details()\r\n        output_details = interpreter.get_output_details()\r\n        input_data_resized = np.reshape(input_data,(1,input_data.shape[0],80))\r\n        interpreter.resize_tensor_input(input_details[0]['index'], (1, input_data.shape[0], 80))\r\n        interpreter.allocate_tensors()\r\n        interpreter.set_tensor(input_details[0]['index'],input_data_resized)\r\n        interpreter.invoke()\r\n\r\n", "comments": ["@tulasiram58827 Can you please provide a simple standalone code to reproduce the issue? Thanks!", "Use shape (1,550,80)", "I had already provided the source code in the first comment itself. Now I am posting again the code to reproduce the issue:\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_model)\r\n#Getting the input data\r\ninput_data = np.load(input_mel)\r\nprint(input_data.shape)\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninput_data_resized = np.reshape(input_data,(1,input_data.shape[0],80))\r\ninterpreter.resize_tensor_input(input_details[0]['index'], (1, input_data.shape[0], 80))\r\ninterpreter.allocate_tensors()\r\n\r\n\r\n\r\nI am also attaching the code which is used to convert into tensorflow lite model.\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n          graph_def_file, input_arrays, output_arrays,input_shapes = {\"input_mel\":[None,50,80]})\r\nconverter.allow_custom_ops=False\r\ntflite_model = converter.convert()\r\nopen(\"output.tflite\", \"wb\").write(tflite_model)\r\n", "@tulasiram58827 Can you please create a colab and share with us. Currently, I cannot run your code as `graph_def_file` is missing. Thanks!", "This is the colab notebook link:\r\nhttps://colab.research.google.com/drive/10lvhLU9CQ53Ie9IiLNJmOTTyYlX13P-o\r\n\r\nGraph def file:\r\n[dc_11lakh.pb.tar.gz](https://github.com/tensorflow/tensorflow/files/3797812/dc_11lakh.pb.tar.gz)\r\n", "@tulasiram58827 Unfortunately this is still not a standalone code. `input_data_resized` is missing. I replaced it with `input_data` and I get different error. Please check the gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/82768ad01f5d57284992d5d8228a7a2b/dynamic_input.ipynb).\r\n\r\nPlease run the code in the colab before sending it. You could also check with `TF1.15` which is newer version. We can resolve faster if all the details are there. Thanks! ", "Sorry some details are missing. I updated the notebook and I am able to reproduce the same error with the updated notebook. Please check this [link](https://colab.research.google.com/gist/tulasiram58827/000ec1ebebae1bd90cc5c99bd3fdf1bd/dynamic_input.ipynb) ", "@jvishnuvardhan please look into this", "assigning this to nupurgarg@ who is working on dynamic shape support.", "@gargn Any update on this", "Support for unknown dimensions in TensorFlow Lite was added last week (5591208).\r\n\r\nCan you try converting your model again with the `tf-nightly` (`pip install tf-nightly`). Convert the model with `experimental_new_converter = True`.\r\n\r\nWhen you load the model it should have an additional field `shape_signature` that contains the shape with any unknown dimensions marked with `-1`. `shape` will have those dimensions marked with `1`.\r\n\r\nYou can then call `ResizeInputTensor` with the desired shape when running the interpreter. The generated model will only work on the latest TensorFlow version (i.e. the interpreter on the `tf-nightly` version you are running).\r\n\r\nCurrently, models using quantization are not supported.", "@gargn Hi, i'm wondering why don't we set the fixed length large enough then use tf.slice or tf.boolean_mask to obtain the desired shape. Example the inputs_shape is [1, 1000] then we can pass the 2nd input tensor is the scalar real_length so we can easily obtain the desired inputs by using tf.slice(inputs, [0, 0], [-1, real_length]). By this way we can also use with quantization and it fake almost 100% dynamic shape without any speed sacrification, am i wrong something ? ", "hello, everyone \r\nI have a model which I convert from mat file to file input size is 1x3x224x244.\r\nI wanted to change the input size of Tensorflow in the android example so I use this model with the above size"]}, {"number": 33710, "title": "Is is possible to run Tensorflow Lite with threading disables / without Pthreads / only 1 thread", "body": "I am trying to compile TensorflowLite for emscripten (I am aware of TensorflowJS) and pthreads are currently disabled. Is there a way to use it without pthreads?\r\n\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "@davlhd \r\nDid you manage to build tflite with emscripten?\r\nCould you share the bazel/workspace file's for the configuration?"]}, {"number": 33709, "title": "K.batch_dot work not right when dims >3", "body": "In TF 2.0 the  K.batch_dot  output dim is wrong\r\n`import tensorflow.keras.backend as K\r\nimport tensorflow as tf\r\n\r\na = K.ones((7, 4, 2))\r\nb = K.ones((7, 2, 5))\r\nc = K.batch_dot(a, b)\r\nprint(c.shape)\r\n\r\na1 = K.ones((8, 7, 4, 2))\r\nb1 = K.ones((8, 7, 2, 5))\r\nc1 = K.batch_dot(a1, b1)\r\nprint(\"K.batch_dot(a1, b1): \", c1.shape)\r\nc2 = tf.matmul(a1, b1)\r\nprint(\"tf.matmul(a1, b1): \", c2.shape)`\r\n\r\noutput:\r\n`(7, 4, 5)\r\nK.batch_dot(a1, b1):  (8, 7, 4, 7, 5)\r\ntf.matmul(a1, b1):  (8, 7, 4, 5)\r\n`\r\n\r\n", "comments": ["Was able to reploduce the issue. Heres my github [gist](https://colab.sandbox.google.com/gist/gowthamkpr/8b961afedcdb49de048431b503b7ae48/untitled211.ipynb).", "This is fixed with latest tf-nightly version '2.2.0-dev20200218'. Thanks!\r\n```python\r\n(7, 4, 5)\r\nK.batch_dot(a1, b1):  (8, 7, 4, 5)\r\ntf.matmul(a1, b1):  (8, 7, 4, 5)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33709\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33709\">No</a>\n"]}, {"number": 33708, "title": "non_max_suppression GPU version is 3x slower than CPU version in  TF 1.15", "body": "<em>\r\n</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.15\r\n- Python version:3.0\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10\r\n- GPU model and memory:K80\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nnon_max_suppression GPU version is 3x slower than CPU version.\r\n**Describe the expected behavior**\r\nGPU version is expected to be faster ( or at the least same ) than CPU version.\r\n\r\n**Code to reproduce the issue\r\n```\r\nfrom __future__ import absolute_import                                                                                                                                  \r\nfrom __future__ import division                                                                                                                                         \r\nfrom __future__ import print_function                                                                                                                                   \r\n                                                                                                                                                                        \r\nimport tensorflow as tf                                                                                                                                                 \r\nfrom tensorflow.python.framework import load_library                                                                                                                    \r\nfrom tensorflow.python.platform import resource_loader                                                                                                                  \r\n                                                                                                                                                                        \r\nimport numpy as np                                                                                                                                                      \r\nimport os                                                                                                                                                               \r\nimport argparse                                                                                                                                                         \r\n                                                                                                                                                                        \r\nfrom tensorflow.python.platform import test                                                                                                                             \r\nimport time                                                                                                                                                             \r\nfrom tensorflow.python.ops import gen_image_ops                                                                                                                         \r\n                                                                                                                                                                                                                                                                \r\n                                                                                                                                                                        \r\ndef yolo_non_max_suppression(boxes, scores, classes, sess, max_boxes = 10, iou_threshold = 0.5, rundevice=\"cpu:0\"):                                                                              \r\n    \"\"\"                                                                                                                                                                                          \r\n    Applies Non-max suppression (NMS) to set of boxes                                                                                                                                            \r\n                                                                                                                                                                                                 \r\n    Arguments:                                                                                                                                                                                   \r\n    scores -- tensor of shape (None,), output of yolo_filter_boxes()                                                                                                                             \r\n    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)                                                                        \r\n    classes -- tensor of shape (None,), output of yolo_filter_boxes()                                                                                                                            \r\n    max_boxes -- integer, maximum number of predicted boxes you'd like                                                                                                                           \r\n    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering                                                                                                      \r\n                                                                                                                                                                                                 \r\n    Returns:                                                                                                                                                                                     \r\n    scores -- tensor of shape (, None), predicted score for each box                                                                                                                             \r\n    boxes -- tensor of shape (4, None), predicted box coordinates                                                                                                                                \r\n    classes -- tensor of shape (, None), predicted class for each box                                                                                                                            \r\n                                                                                                                                                                                                 \r\n    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this                                                                                \r\n    function will transpose the shapes of scores, boxes, classes. This is made for convenience.                                                                                                  \r\n    \"\"\"                                                                                                                                                                                          \r\n                                                                                                                                                                                                 \r\n    init_val_np = np.array ( [max_boxes], dtype=np.int32)                                                                                                                                        \r\n    max_boxes_tensor = tf.Variable(max_boxes,  dtype='int32')     # tensor to be used in tf.image.non_max_suppression()                                                                          \r\n    sess.run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor                                                                                                \r\n                                                                                                                                                                                                 \r\n    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep                                                                                              \r\n    ### START CODE HERE ### (~ 1 line)                                                                                                                                                           \r\n    with tf.device(rundevice):                                                                                                                                                                   \r\n        score_threshold = 0.1                                                                                                                                                                    \r\n        soft_nms_sigma=0.0                                                                                                                                                                       \r\n        pad_to_max_output_size=False                                                                                                                                                             \r\n        if True:                                                                                                                                                                                 \r\n            nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, )                                                                                                        \r\n            #nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)                                                                            \r\n            #nms_indices = nms(boxes_np, 0.5)                                                                                                                                                    \r\n            #nms_indices = gen_image_ops.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )                                                                                \r\n            #nms_indices = tf.image.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )                                                                                     \r\n            #nms_indices = gen_image_ops.non_max_suppression_v3(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold)                                                                 \r\n            #nms_indices,_ = gen_image_ops.non_max_suppression_v4(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, pad_to_max_output_size)                                       \r\n            #nms_indices = gen_image_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                                 \r\n            #nms_indices,_,_ = non_max_suppression_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                   \r\n            #nms_indices,_,_ = tf.image.non_max_suppression_with_scores(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                         \r\n        ### END CODE HERE ###                                                                                                                                                                    \r\n                                                                                                                                                                                                 \r\n        ### START CODE HERE ### (~ 3 lines)                                                                                                                                                      \r\n        scoreso = tf.gather(scores, nms_indices)                                                                                                                                                 \r\n        boxeso = tf.gather(boxes, nms_indices)                                                                                                                                                   \r\n        classeso = tf.gather(classes, nms_indices)                                                                                                                                               \r\n        summary_writer = tf.summary.FileWriter(os.getenv('TENSORBOARD_DIR'), sess.graph)                                                                                                         \r\n        ### END CODE HERE ###                                                                                                                                                                    \r\n                                                                                                                                                                                                 \r\n    return scoreso, boxeso, classeso\r\n\r\ndef test_yolo_non_max_suppression(rundevice=\"cpu:0\", roinum=300):                                                                                                                                \r\n    with tf.device(\"cpu:0\"):                                                                                                                                                                     \r\n        with tf.Session() as test_b:                                                                                                                                                             \r\n            roinum = 300                                                                                                                                                                         \r\n            scoresi = tf.random_normal([roinum,], mean=1, stddev=4, seed = 1)                                                                                                                    \r\n            boxesi = tf.random_normal([roinum, 4], mean=1, dtype = tf.float32, stddev=4, seed = 1)                                                                                               \r\n            classesi = tf.random_normal([roinum,], mean=1, dtype = tf.float32, stddev=4, seed = 1)                                                                                               \r\n            scorest, boxest, classest = yolo_non_max_suppression(boxesi, scoresi, classesi, test_b, rundevice=rundevice, )                                                                       \r\n            time0 = time.time()                                                                                                                                                                  \r\n            for i in range(1,10001):                                                                                                                                                             \r\n                scores, boxes, classes = test_b.run([scorest, boxest, classest])                                                                                                                 \r\n                if i%2000 == 0:                                                                                                                                                                  \r\n                    print (i, (time.time() - time0)/i )                                                                                                                                          \r\n            time_taken = (time.time() - time0)/i                                                                                                                                                 \r\n            print (i, time_taken)                                                                                                                                                                \r\n            print(\"scores[2] = \" + str(scores[2]))                                                                                                                                               \r\n            print(\"boxes[2] = \" + str(boxes[2]))                                                                                                                                                 \r\n            print(\"classes[2] = \" + str(classes[2]))                                                                                                                                             \r\n            print(\"scores.shape = \" + str(scores.shape))                                                                                                                                         \r\n            print(\"boxes.shape = \" + str(boxes.shape))                                                                                                                                           \r\n            print(\"classes.shape = \" + str(classes.shape))                                                                                                                                       \r\n                                                                                                                                                                                                 \r\n            return time_taken\r\n\r\nif __name__ == '__main__':                                                                                                                                                                       \r\n    print (tf.__version__)                                                                                                                                                                       \r\n    from tensorflow.python.client import device_lib                                                                                                                                              \r\n    print (\"devices: \", device_lib.list_local_devices())                                                                                                                                         \r\n    cpu_time_taken = test_yolo_non_max_suppression(rundevice=\"cpu:0\", roinum=300)                                                                                                                \r\n    gpu_time_taken = test_yolo_non_max_suppression(rundevice=\"gpu:0\", roinum=300)                                                                                                                \r\n    print(\"========  cpu vs gpu time per batch =================\")                                                                                                                               \r\n    print ( \"cpu: \", cpu_time_taken, \" gpu: \", gpu_time_taken, \" cpu/gpu :\", cpu_time_taken/gpu_time_taken,)\r\n\r\n1.15.0\r\ndevices:  [name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 7555561621581721093\r\n, name: \"/device:XLA_CPU:0\"\r\ndevice_type: \"XLA_CPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 8901332661850439463\r\nphysical_device_desc: \"device: XLA_CPU device\"\r\n, name: \"/device:XLA_GPU:0\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 740119289257596209\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nmemory_limit: 11330115994\r\nlocality {\r\n  bus_id: 1\r\n  links {\r\n  }\r\n}\r\nincarnation: 8545750488051512624\r\nphysical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\r\n]\r\n2000 0.000534496068954\r\n4000 0.000523755788803\r\n6000 0.000520971179008\r\n8000 0.000516991376877\r\n10000 0.000515855407715\r\n10000 0.000515921497345\r\nscores[2] = 10.583145\r\nboxes[2] = [ 9.513624   -1.2187521   2.245485    0.23083931]\r\nclasses[2] = 10.583145\r\nscores.shape = (10,)\r\nboxes.shape = (10, 4)\r\nclasses.shape = (10,)\r\n2000 0.00289141702652\r\n4000 0.00219018751383\r\n6000 0.0019565414985\r\n8000 0.00184808599949\r\n10000 0.00177410800457\r\n10000 0.00177413899899\r\nscores[2] = 10.583145\r\nboxes[2] = [ 9.513624   -1.2187521   2.245485    0.23083931]\r\nclasses[2] = 10.583145\r\nscores.shape = (10,)\r\nboxes.shape = (10, 4)\r\nclasses.shape = (10,)\r\n========  cpu vs gpu time per batch =================\r\ncpu:  0.000515921497345  gpu:  0.00177413899899  cpu/gpu : 0.290801057662\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I could reproduce the issue. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/4dd3cc207accf2251aaa8bcfbb80f004/untitled601.ipynb) is the gist. Thanks!", "sgambient@: This could be due to a lot of copies between GPU & CPU. Could you see if using int64 instead of int32 helps?", "@sgambient: Could you please verify if int64 helps?", "Check this repo for more info on this issue. \r\n\r\nhttps://github.com/whatdhack/tf-nms/blob/master/README.md\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33707, "title": "comment typo of  `is_fully_defined` function", "body": "comment typo of  `is_fully_defined` function", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac @chanshah", "Furthermore, this is not a typo. `iff` means \"If and only if\"", "Thank you, that's very nice of you ~"]}, {"number": 33706, "title": "Reduce if-else branch,code do nothing in if branch", "body": "code did nothing in if branch,so I delete this branch.", "comments": []}, {"number": 33705, "title": "File \"C:\\Users\\idzha\\Anaconda3\\lib\\sqlite3\\__init__.py\", line 23, in <module> from sqlite3.dbapi2 import *   File \"C:\\Users\\idzha\\Anaconda3\\lib\\sqlite3\\dbapi2.py\", line 27, in <module>     from _sqlite3 import *ImportError: DLL load failed: The specified module could not be found.", "body": "", "comments": [" Using cmder on windows 10:-\r\npython manage.py runserver\r\nWatching for file changes with StatReloader\r\nException in thread django-main-thread:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\threading.py\", line 865, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py\", line 54, in wrapper\r\n    fn(*args, **kwargs)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\core\\management\\commands\\runserver.py\", line 109, in inner_run\r\n    autoreload.raise_last_exception()\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py\", line 77, in raise_last_exception\r\n    raise _exception[1]\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 337, in execute\r\n    autoreload.check_errors(django.setup)()\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py\", line 54, in wrapper\r\n    fn(*args, **kwargs)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\__init__.py\", line 24, in setup\r\n    apps.populate(settings.INSTALLED_APPS)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\apps\\registry.py\", line 114, in populate\r\n    app_config.import_models()\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\apps\\config.py\", line 211, in import_models\r\n    self.models_module = import_module(models_module_name)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\contrib\\auth\\models.py\", line 2, in <module>\r\n    from django.contrib.auth.base_user import AbstractBaseUser, BaseUserManager\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\contrib\\auth\\base_user.py\", line 47, in <module>\r\n    class AbstractBaseUser(models.Model):\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\models\\base.py\", line 117, in __new__\r\n    new_class.add_to_class('_meta', Options(meta, app_label))\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\models\\base.py\", line 321, in add_to_class\r\n    value.contribute_to_class(cls, name)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\models\\options.py\", line 204, in contribute_to_class\r\n    self.db_table = truncate_name(self.db_table, connection.ops.max_name_length())\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\__init__.py\", line 28, in __getattr__\r\n    return getattr(connections[DEFAULT_DB_ALIAS], item)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\utils.py\", line 201, in __getitem__\r\n    backend = load_backend(db['ENGINE'])\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\utils.py\", line 110, in load_backend\r\n    return import_module('%s.base' % backend_name)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\site-packages\\django\\db\\backends\\sqlite3\\base.py\", line 13, in <module>\r\n    from sqlite3 import dbapi2 as Database\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\sqlite3\\__init__.py\", line 23, in <module>\r\n    from sqlite3.dbapi2 import *\r\n  File \"C:\\Users\\idzha\\Anaconda3\\lib\\sqlite3\\dbapi2.py\", line 27, in <module>\r\n    from _sqlite3 import *\r\nImportError: DLL load failed: The specified module could not be found.", "@Idzhan94, Looks like the issue is not related to Tenosrflow. \r\nTo install Tensorflow please follow the instructions mentioned in [this link](https://www.tensorflow.org/install/pip).  Thanks!", "@Idzhan94, Were you able to solve this issue? Thanks!", "Closing issue as it is not related to Tensorflow. Please feel free to reopen if this issue is from Tensorflow. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33705\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33705\">No</a>\n"]}, {"number": 33704, "title": "relu6", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@sashiomarda, Please provide the information asked in the template. Thanks! "]}, {"number": 33703, "title": "[Intel MKL]code cleanup", "body": "", "comments": ["@gbaned @adisakshya This PR has pending on ready to pull for 5 days, can you help to check this? thanks."]}, {"number": 33702, "title": "build tensorflow on mac failed", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS high sierra\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: source on branch r1.13\r\n- **Python version**: 3.6.5(Anaconda)\r\n- **Bazel version (if compiling from source)**: 0.21.0\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)\r\n- **CUDA/cuDNN version**: No\r\n- **GPU model and memory**: No\r\n- **Exact command to reproduce**:\r\n```\r\ngit checkout r1.13\r\n./configure\r\nonly XLA support is enabled\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n```\r\n\r\n### Describe the problem\r\nbuild tensoeflow from source failed.\r\n\r\n> ImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE\r\n\r\n### Source code / logs\r\nINFO: From Linking tensorflow/core/libgpu_runtime_impl.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device_factory.o) has no symbols\r\nERROR: /Users/dongxiao/working/tensorflow/tensorflow/BUILD:579:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash failed: error executing command\r\n  (cd /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/bin:/usr/bin \\\r\n    PYTHON_BIN_PATH=/Users/dongxiao/anaconda3/bin/python \\\r\n    PYTHON_LIB_PATH=/Users/dongxiao/anaconda3/lib/python3.6/site-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1 --root_init_template=tensorflow/api_template_v1.__init__.py --apidir=bazel-out/darwin-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --compat_apiversion=1  --compat_init_template=tensorflow/compat_template_v1.__init__.py --package=tensorflow.python,tensorflow.lite.python.lite --output_package=tensorflow._api.v1 bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/v1.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/autograph/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/autograph/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/distribute/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/io/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/queue/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/layers/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/lite/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/lite/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/ragged/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/signal/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/version/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/app/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/autograph/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/autograph/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/bitwise/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/compat/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/data/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/data/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/debugging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/distribute/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/distributions/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/dtypes/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/errors/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/feature_column/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/io/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/graph_util/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/queue/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/activations/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/densenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/inception_v3/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/mobilenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/nasnet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/resnet50/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/vgg16/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/vgg19/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/xception/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/backend/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/callbacks/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/constraints/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/cifar10/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/cifar100/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/imdb/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/reuters/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/estimator/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/models/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/optimizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/text/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/regularizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/wrappers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/layers/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/linalg/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/lite/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/lite/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/logging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/manip/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/math/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/nn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/nn/rnn_cell/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/profiler/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/python_io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/quantization/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/ragged/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/random/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/resource_loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/strings/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/builder/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/main_op/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/signature_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/signature_def_utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/tag_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/signal/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sparse/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/spectral/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/summary/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sysconfig/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/test/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/train/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/train/queue_runner/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/user_ops/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/version/__init__.py')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/Users/dongxiao/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Users/dongxiao/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE\r\n  Referenced from: /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so\r\n  Expected in: flat namespace\r\n in /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/Users/dongxiao/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Users/dongxiao/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE\r\n  Referenced from: /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so\r\n  Expected in: flat namespace\r\n in /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n", "comments": ["Does your cpu support AVX instruction sets?", "@ymodak Yes, the result of `sysctl -a | grep machdep.cpu.features` is shown below.\r\n\r\n> \u279c  xla sysctl -a | grep machdep.cpu.features\r\n> machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C", "Can you try compiling TF with avx flag? You may also try installing prebuilt TF binaries instead.\r\nSee https://www.tensorflow.org/install/pip", "@ymodak Thanks for your advice. I have switched to branch r1.14 and built tensorflow with xla successfully. The error does not occur with r1.14", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33702\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33702\">No</a>\n"]}, {"number": 33701, "title": "Add Selu and Softsign to auto mixed precision gray list", "body": "`Elu` and `Softplus` are already part of the auto mixed precision gray list, so I think it is save to add `Selu` and `Softsign` too.\r\n\r\n/cc @reedwm", "comments": []}, {"number": 33700, "title": "Added default values for the two LSTM parameters.", "body": "This is very useful as it is not clear at all what LSTM returns.", "comments": ["We will not be encouraging one liner changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac ", "Make use of Continuous Deployment. \r\nThis is not very friendly response guys. ", "We do, but because we need to test on 3 operating systems and several python versions and additional testing inside Google this results in hours of CI/CD time wasted for a one line fix.\r\n\r\nEspecially now with Hacktoberfest, we are trying to only get high quality content and no spam PRs. Of course, some legit PRs can get rejected by this, but people can always fix multiple issues in the same file."]}, {"number": 33699, "title": "suppress unused result in s3_filesystem (-Wunused-result)", "body": "Building tensorflow with additional warnings as errors.  Suppress the warning to build the library.\r\n\r\n```\r\nerror: ignoring return value of function declared with 'warn_unused_result' attribute [-Werror,-Wunused-result]\r\n```", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33699) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33699) for more info**.\n\n<!-- ok -->", "Several things:\r\n\r\nPlease use a descriptive title for the PR\r\nPlease describe the PR. At least justify the change\r\nIf there is an issue, please reference it.\r\nPlease reference/add tests\r\nA one line change still triggers several CPU/GPU hours worth of CI. Please fix the issue in all cases in the file/directory so that we don't waste enormous amounts of compute hours for tiny fixes.", "thanks.  this only needs changed in `s3_file_system.cc` for building core.", "I'm not sure how to proceed from the CI.  Am I in a queue for Ubuntu CC?  ", "luxe@: It is pending approval by a developer internally and it should be merged into GitHub soon."]}, {"number": 33698, "title": "Add missing V2/V3 ops to grappler op types", "body": "This PR adds missing V2 or V3 ops to grappler op types. This should extend the range of ops grappler can handle.", "comments": []}, {"number": 33697, "title": "The value of the validation accuracy is very low ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9/7.5\r\n- GPU model and memory: Nvidia Geforce 840m\r\n\r\nI have a trained model that detects an eye region with landmarks, this model gives good results:\r\n\r\n![image](https://user-images.githubusercontent.com/19480228/67513317-e0e4d380-f69a-11e9-88b6-aa8327d4bc58.png)\r\n\r\nBut when I evaluate this model using this code:\r\n```python\r\ndef _eval_input_fn():\r\n    \"\"\"Function for evaluating.\"\"\"\r\n    return input_fn(\r\n        record_file=\"./validiris.record\",\r\n        batch_size=2,\r\n        num_epochs=1,\r\n        shuffle=False)\r\ndef main(unused_argv):\r\n    \"\"\"MAIN\"\"\"\r\n    # Create the Estimator\r\n    estimator = tf.estimator.Estimator(\r\n        model_fn=cnn_model_fn, model_dir=\"./irismodel\")\r\n\r\n    # Choose mode between Train, Evaluate and Predict\r\n    mode_dict = {\r\n        'train': tf.estimator.ModeKeys.TRAIN,\r\n        'eval': tf.estimator.ModeKeys.EVAL,\r\n        'predict': tf.estimator.ModeKeys.PREDICT\r\n    }\r\n    mode = mode_dict['eval']\r\nif mode == tf.estimator.ModeKeys.TRAIN:\r\n        estimator.train(input_fn=_train_input_fn, steps=200000)\r\n\r\n        # Export result as SavedModel.\r\n        estimator.export_savedmodel('./saved_model', serving_input_receiver_fn)\r\n elif mode == tf.estimator.ModeKeys.EVAL:\r\n        evaluation = estimator.evaluate(input_fn=_eval_input_fn)\r\n        print(evaluation)\r\n\r\n```\r\n\r\nI got an unbelievable value of accuracy, as you can see that was the logs that I have got:\r\n\r\n**Other info / logs**\r\n>2019-10-24 19:51:54.628843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-10-24 19:53:57.017603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-24 19:53:57.026100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-10-24 19:53:57.033023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-10-24 19:53:58.438331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3058 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0)\r\nWARNING:tensorflow:From C:\\Users\\starinfo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from ./irismodel\\model.ckpt-146849\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\n2019-10-24 19:54:10.280447: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library cublas64_100.dll locally\r\nINFO:tensorflow:Finished evaluation at 2019-10-24-18:00:00\r\nINFO:tensorflow:Saving dict for global step 146849: accuracy = 1.5903983e-06, global_step = 146849, loss = 0.00016725865\r\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 146849: ./irismodel\\model.ckpt-146849\r\n{'accuracy': 1.5903983e-06, 'loss': 0.00016725865, 'global_step': 146849}\r\n\r\n\r\nWhat is the problem here?\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33696, "title": "GpuLaunchKernel errors with Internal: invalid device function", "body": "**System information**\r\n- Windows 10\r\n- TensorFlow GPU installed from PIP installer:\r\n- TensorFlow version: 2.0.0\r\n- Python version:  3.7.4\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Geforce GTX 1050 4GB\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to run a facial recognition project and the message bellow appears\r\n\r\nUsing TensorFlow backend.\r\n\r\n```\r\n2019-10-24 14:32:44.154323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2019-10-24 14:32:51.960166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-10-24 14:32:52.321115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\r\nname: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493\r\npciBusID: 0000:01:00.0\r\n2019-10-24 14:32:52.325985: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-24 14:32:52.331740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-24 14:32:52.335877: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-10-24 14:32:52.342803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\r\nname: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493\r\npciBusID: 0000:01:00.0\r\n2019-10-24 14:32:52.346290: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-24 14:32:52.350583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-24 14:32:52.458458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-24 14:32:52.461435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0\r\n2019-10-24 14:32:52.462925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N\r\n2019-10-24 14:32:52.467353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3083 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-10-24 14:32:52.647343: F .\\tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid device function\r\n```", "comments": ["Can you please provide the sequence of steps or a minimal code to reproduce this issue and expedite the process. Thanks! ", "I trying to run this projetct\r\nhttps://github.com/yu4u/age-gender-estimation.git", "an you please try running the project on google colab and if see if you are encountering the same issue. Thanks!", "Here it goes\r\n\r\nUsing TensorFlow backend.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2019-10-24 20:30:03.809026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2019-10-24 20:30:03.809331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3c901c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-10-24 20:30:03.809372: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-10-24 20:30:03.814851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-10-24 20:30:03.952342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:03.953224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3c90380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2019-10-24 20:30:03.953256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\r\n2019-10-24 20:30:03.954473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:03.955200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:04.0\r\n2019-10-24 20:30:03.962065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-24 20:30:03.962146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-24 20:30:04.052434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-10-24 20:30:04.052667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-10-24 20:30:04.052740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-10-24 20:30:04.174903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-10-24 20:30:04.175034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-24 20:30:04.175183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:04.175967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:04.176739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-24 20:30:04.180762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-24 20:30:04.182365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-24 20:30:04.182402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-10-24 20:30:04.182418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-10-24 20:30:04.183538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:04.184299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-24 20:30:04.185021: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2019-10-24 20:30:04.185076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\r\n\r\nVIDEOIO ERROR: V4L: can't open camera by index 0\r\nTraceback (most recent call last):\r\n  File \"/content/age-gender-estimation/demo.py\", line 138, in <module>\r\n    main()\r\n  File \"/content/age-gender-estimation/demo.py\", line 99, in main\r\n    for img in image_generator:\r\n  File \"/content/age-gender-estimation/demo.py\", line 60, in yield_images\r\n    raise RuntimeError(\"Failed to capture image\")\r\nRuntimeError: Failed to capture image\r\n\r\n", "Can you please share the github gist of the minimum reproducible example. Thanks!", "Unfortunately, this is not possible because the project has interdependent files. ", "I could reproduce the issue as well.\r\n\r\n**System information**\r\n\r\n- Windows 10\r\n- TensorFlow GPU installed from PIP installer:\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Geforce GTX 1080 6GB\r\n\r\n**Code**\r\n\r\n```\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\n\r\nmodel = Sequential()\r\nprint(1)\r\nmodel.add(Dense(512, activation='relu', input_shape=((28 * 28),))) #crashes here\r\nprint(2) #not printed\r\n```\r\n\r\n**Logs**\r\n\r\nUsing TensorFlow backend.\r\n2019-10-27 18:19:50.390966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n1\r\n2019-10-27 18:19:51.450798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-10-27 18:19:51.525684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\r\npciBusID: 0000:03:00.0\r\n2019-10-27 18:19:51.525870: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-27 18:19:51.526328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-27 18:19:51.526602: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-10-27 18:19:51.529355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\r\npciBusID: 0000:03:00.0\r\n2019-10-27 18:19:51.529537: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-27 18:19:51.529999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-27 18:19:51.617783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-27 18:19:51.617918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-10-27 18:19:51.617997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-10-27 18:19:51.618650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6430 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2019-10-27 18:19:51.879458: F .\\tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid device function", "@s2pstefan, with you code, I had same issue. ", "@s2pstefan I was not able to reproduce your error on colab. Heres my [github gist](https://colab.sandbox.google.com/gist/gowthamkpr/59ea8d13c80023f699328b7407b44fbb/untitled209.ipynb).", "Hi @gowthamkpr ,\r\n\r\nI see two issues with your test:\r\n\r\n1. It does not use tensorflow-gpu\r\n2. It does not run on Windows 10\r\n\r\nI think that the error quite specific to this environment. Both @glaucimarfaleiro and myself were able to reproduce, given the correct setup.", "I used tensorflow-gpu 2.0 but was not able to reproduce it. Heres my [github gist](https://colab.sandbox.google.com/gist/gowthamkpr/3e9074efcea097b19009761df3be5cfd/untitled209.ipynb) I think this issue is specific to windows.", "Good news, I tested again now and it seems that this issue has been fixed in the latest tf-nightly-gpu. @glaucimarfaleiro , can you please check as well?", "@s2pstefan, it worked with tf-nightly-gpu. Thanks a lot.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33696\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33696\">No</a>\n", "I had this problem when compling TF 1.15.4 with --linkopt=\"/DEBUG:NONE\" on windows"]}, {"number": 33695, "title": "Do I need the NVIDIA CUDA Toolkit along with conda installation of the CUDA toolkit?", "body": "Version mismatch issues encountered at the installation of Tensorflow with local GPU support led me **question the need for the coexistence on the same machine of both CUDA packages**, namely: \r\n\r\nThe NVIDIA **CUDA Toolkit** along with **CUDNN**\r\n\r\n<img width=\"257\" alt=\"Annotation 2019-10-24 122829\" src=\"https://user-images.githubusercontent.com/39677929/67505904-1ae1b580-f65a-11e9-9c18-78c22b4266e2.png\">\r\n\r\nand the `conda` installation of the **cudatoolkit** along with **cudnn** \r\n\r\n<img width=\"311\" alt=\"Annotation 2019-10-24 121845\" src=\"https://user-images.githubusercontent.com/39677929/67506044-5c726080-f65a-11e9-8f24-d1286d9da45d.png\">\r\n\r\nAs shown above, on my machine these packages have different versions but tensorflow is configured for GPU support and is working:\r\n\r\n`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`\r\n\r\noutputs something along the lines:\r\n\r\n<img width=\"401\" alt=\"Annotation 2019-10-24 124233\" src=\"https://user-images.githubusercontent.com/39677929/67507285-99d7ed80-f65c-11e9-8de5-ba3fa440b3b4.png\">\r\n\r\nConda installation of tensorflow-gpu via \r\n\r\n` conda create -n tensorflow tensorflow-gpu`\r\n\r\nseems to resolve version mismatch issues encountered with `pip install`, `keras::install_keras()` or with `tensorflow::install_tensorflow()`\r\n\r\n\r\nThe reason for my question is twofold: \r\n\r\n1. Beside CUDA,  the NVIDIA CUDA Toolkit installs a plethora of tools that may not be used by everyone therefore, a guide to the custom installation of the CUDA Toolkit would be more than welcome;\r\n\r\n2. The _cudart64-100.dll cannot be found_ error popping at version mismatch between CUDA/CUDNN, Python and Tensorflow  refers to the _dll_ library located in the `conda` environment and not to the NVIDIA CUDA installation (which in my case contains the _cudart64-101.dll_ and still works)\r\n\r\n", "comments": ["No, you don't need both; there are two probable issues you are encountering:\r\n\r\n1st: I don't believe TF supports CUDA 10.1 yet (_**I could be wrong**_). I know for my build I use CUDA 10.0 with cuDNN v7.50. You can see in your conda installation you have CUDA 10.0; not 10.1.\r\n\r\nDownload v10.0: https://developer.nvidia.com/cuda-10.0-download-archive?target_os=Windows&target_arch=x86_64\r\n\r\n2nd: Check to ensure you have the following paths in your environment variables **and** above conda's paths:\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\\\<VERSION_HERE>\\bin\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\\\<VERSION_HERE>\\extras\\CUPTI\\libx64\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\\\<VERSION_HERE>\\include\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\\\<VERSION_HERE>\\lib\\x64\r\n\r\nEXTRA: When I install CUDA, I specifically uncheck the following settings (through advanced setup):\r\n1. Documentation (in CUDA)\r\n2. Visual Studio Integration (unless you will be using Visual Studio [not VS Code]) (in CUDA)\r\n3. Samples (in CUDA)\r\n4. Driver components\r\n\r\nIt keeps the size down and speeds up installation. You do not have to do this if you don't want to.\r\n\r\nAfter CUDA is installed, install the latest graphics driver for your graphics card from NVIDIA. Everything unchecked in Driver components is installed when you install the graphics driver.", "@JulianOrteil\r\n\r\n Thank you for your time! \r\n\r\nI am a bit confused by your answer as my question referred to the necessity of co-existence of both NVIDIA CUDA and conda `cudatoolkit` installations.\r\n\r\nSince your answer to this question is no, am I correct to uninstall Nvidia CUDA/CUDNN and leave the conda `cudatoolkit` installation ONLY?\r\n\r\nIf it is correct to remove NVIDIA CUDA/CUDNN installation, then should all environment variables pointing to the NVIDIA CUDA installation be removed?\r\n\r\nI am asking all these questions because tensorflow seems to be looking for `cudatoolkit` and not for NVIDIA CUDA install and I am supporting this observation with the fact that every time I installed mismatched versions of tensorflow/python I got the error \"_cudart64-100.dll cannot be found_\" - event which coincided with  `cudatoolkit` missing from respective conda environment.\r\n\r\nThis mismatch was automatically solved by a conda installation such as:\r\n\r\n `conda create -n tensorflow tensorflow-gpu` \r\n\r\nwhich took care automatically of tensorflow-gpu/python version matching and also automatically installed the `cudatoolkit` v.10.0 to which tensorflow points. \r\n\r\nNVIDIA CUDA installation doesn't seem to exist although is installed and respective environment variables are set!\r\n\r\nSo, in summary: will tensorflow-gpu work after uninstalling NVIDIA CUDA and removing all pertaining environment variables leaving only conda installation? \r\n\r\nOne more thing: do I need installed\r\n\r\n- Nvidia CUDA Development and \r\n- Nvidia Insight Visual Studio Edition \r\n\r\nThank you!    ", "@drag05 \r\n\r\nSorry for the confusion! I installed TF directly into Python installed in my user not a conda environment.\r\n\r\nIf you installed Tensorflow using a conda environment, then no you should not need the NVIDIA CUDA/cuDNN files. You can also remove them from path, in fact you should to keep your path size down.\r\n\r\nJust make sure you do not remove any Anaconda paths.\r\n\r\nAs to your last question, I am unsure if you need those. If you would like to experiment with that and it works without them, let me know! (I would rather not experiment in my environment since I am training models at the current moment)\r\n\r\nOne last thing, even though you do not need the CUDA/cuDNN files, you do need to ensure your graphics card driver is above 390 (I believe it is that version). Just install the latest and you should be fine.\r\n\r\n~Jules", "@JulianOrteil \r\n\r\nThank you for the prompt response! \r\nI have uninstalled Nvidia CUDA/CUDNN and removed all pertaining environment variables. \r\n\r\nTested tensorflow-gpu/keras on RStudio and still works. \r\n\r\nAlso tested the gaming and still woks. \r\n\r\nI guess tensorflow-gpu installation instructions would be less confusing if were split into the option of installing from Python OR the option of installing from *conda. \r\n\r\nCheers!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33695\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33695\">No</a>\n"]}, {"number": 33694, "title": "Add missing V2 ops to auto mixed precision list", "body": "This PR adds `BlockLSTMV2`, `BlockLSTMGradV2` to the auto mixed precision white list and `SelectV2` to the clear list.\r\n\r\nThe corresponding `*V1` ops are already part of respective lists.\r\n@reedwm @benbarsdell Is there a reason not to include them?", "comments": ["Thanks for the change! This looks good to me. I don't see anything different about BlockLSTMV2 that would affect precision. And SelectV2 definitely belongs on the clearlist. @benbarsdell, let me know if there's any reason not to include the V2 version of these ops.", "@reedwm Thanks for the fast response.\r\nShould  `SelectV2` also be added to `grappler/op_types.cc`\r\nhttps://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/op_types.cc#L460\r\nwhich is used in the layout optimizer?\r\nhttps://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/optimizers/generic_layout_optimizer_transposer_factory.cc#L95-L97", "@andyly, do you know? In SelectV2, the inputs do not need to be the same shape but only need to be broadcastable to each other, which I'm not sure if the layout optimizer will produce a correct graph for.\r\n\r\n@lgeiger, if @andyly thinks this is OK, please add to #33698 instead of this PR."]}, {"number": 33693, "title": "TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(None), -1, Dimension(2048)). Consider casting elements to a supported type.", "body": "I am getting these error when trying to run my model:\r\n\r\n```\r\n\"Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\", line 558, in make_tensor_proto\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\", line 558, in <listcomp>\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py\", line 65, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got Dimension(None)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/root/.local/lib/python3.5/site-packages/trainer/image_captioning.py\", line 123, in <module>\r\n    (batch_features.shape[0], -1, batch_features.shape[3]))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 7715, in reshape\r\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 530, in _apply_op_helper\r\n    raise err\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1224, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 305, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 246, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\", line 562, in make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\nTypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(None), -1, Dimension(2048)). Consider casting elements to a supported type.\r\n```\r\n\r\n\r\nAnd i believe the issue is in this bit of code:\r\n\r\n```\r\n# Get unique images\r\nencode_train = sorted(set(img_name_vector))\r\n\r\nimage_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\r\nimage_dataset = image_dataset.map(\r\n  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\r\n\r\nfor img, path in image_dataset:\r\n  batch_features = image_features_extract_model(img)\r\n  batch_features = tf.reshape(batch_features,\r\n                              (batch_features.shape[0], -1, batch_features.shape[3]))\r\n\r\n  for bf, p in zip(batch_features, path):\r\n    np.save(file_io.FileIO(IMG_PATH, 'w'), bf.numpy())\r\n```\r\n\r\nSo it seems that batch_features.shape[0] is returning None - how can I handle this?\r\n\r\nI have tried to use `tf.shape(batch_features)[0]` instead of `batch_features.shape[0]` but then the error is:\r\n```\r\nTypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.\r\n```", "comments": ["@anthonyatp ,\r\nCan you please provide a complete reproducible code snippet to reflect this issue? Also mention the TF version being used. Thanks!", "@oanush \r\nSo im actually running the Image captioning tutorial: https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset\r\n\r\nthe 2 main differences are I am using a different dataset of images and captions and I am running this on google ai platform:\r\n```\r\ngcloud ai-platform jobs submit training $JOB_NAME \\\r\n--staging-bucket $STAGING_BUCKET \\\r\n--module-name trainer.image_captioning \\\r\n--package-path ./trainer \\\r\n--region europe-west1 \\\r\n--config=trainer/cloudml_gpu.yaml \\\r\n--python-version 3.5 \\\r\n--runtime-version 1.14\r\n```\r\n\r\nI have tensorflow version 2.0 installed in my virtualenv", "when I run locally the shape of 'batch_features' is `(16, 8, 8, 2048)` but in the cloud it seems its `(?, 8, 8, 2048)` and therefore i am getting Dimension(None)", "maybe its the way I am loading the json file containing image ids and captions?\r\n\r\n`with tf.io.gfile.GFile(\"gs://{BUCKET_NAME}/captions.json\", 'r') as f: annotations = json.load(f)`", "ok I think I have narrowed down the problem to the version of tensorflow. I had no problems running locally because I have tf version 2 installed (with python 3.8), however, the latest supported version of tf on google ai platform is v1.14.\r\n\r\nI downgraded locally to v1.14 and now I am getting the same error as when I run the model on the google ai platform. \r\n\r\nSo I assume parts of the TensorFlow API I am using are only compatible with version 2. \r\n\r\nAny advice to get this running on google ai platform?", "I have the same issue when training a model on GCP AI-platform.. Did you solve it? Thanks!", "the issue is the model using tensorflow version 2.0, however, google ai platform does not support this version yet. To get around this, you can create a notebook instance with a tf v2.0 environment to train the model", "I think the root of this issue is that version of tensorflow. @YINGYINGHU1220 Please follow the recommendation of @anthonyatp and it should solve your issue. I am closing this issue for now. \r\n\r\nIf you have any more doubts, you can add additional comments and we can open this issue again. Thanks!"]}, {"number": 33692, "title": "How can i predict on image classifier?", "body": "https://www.tensorflow.org/tutorials/images/classification\r\n", "comments": ["Can I work on it?\r\n", "Yes you have the link for an example", "I have made a test with other images and the prediction reach zeros and for me this is not good. Thank you a lot for the work on top of it.", "@ktfth Are you testing your own images of cats and/or dogs? I think this network is made as a simple model to demonstrate the classification and related operations. If the prediction is not good for your images, then you can update the model by adding some more hidden layers.\r\n\r\nHaving said that this is not a build/installation or Bug and Performance issue.\r\n\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33691, "title": "ResizeBilinear op mismatch in TF2.0/TFLite", "body": "There have been changes in how ResizeBilinear works across the last few versions and its causing issues.\r\n\r\n- Originally ResizeBilinear op (what you get with tf.image.resize) was completely wrong (see the weird shift below)\r\n- This was made less-wrong with the align_corners=True param (defaults to False for compat which makes sense).\r\n- None of these match OpenCV, align_corners is not completely terrible but still not right.\r\n- for TF2.0 a newer version of the op was made that is really nice and matches OpenCV. PyTorch also matches this version too. The antialias=False (default) param only matters for downscaling. \r\n- The `tf.keras.layers.UpScaling2D` layer calls `tf.keras.backend.resize_images`\r\n- In TF1.x, `tf.keras.backend.resize_images` called `tf.image.resize_bilinear` with default args, so got the broken op.\r\n- After r1.14 was branched off master, `tf.keras.backed.resize_images` was changed to use the V2 op.\r\n- TF2.0 was branched off master, so has the new good op\r\n- TF1.15 was branched off master, so also has the new good op, but is backwards incompatible\r\n- TOCO/TFLiteConverter forces any resize_bilinear to use the old broken resize op. In fact it forces align_corners=False without even looking at what the input model has.\r\n\r\nTFLite needs to have the new op implemented, and TFLiteConverter needs to distinguish and error if the wrong op is used.\r\n\r\nReproducer:\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.compat.v1 as tf1\r\nimport tensorflow.compat.v2 as tf2\r\n\r\nassert tf.version.VERSION == '2.0.0'\r\nnp.set_printoptions(precision=2, suppress=True)\r\n\r\nstart_shape = (2, 2)\r\nresize_shape = (10, 10)\r\nupsample_size = (resize_shape[0] // start_shape[0], resize_shape[1] // start_shape[1])\r\n\r\n# A 2x2 image with diagonal corners = 5\r\na = np.ones((1, start_shape[0], start_shape[1], 1), dtype=np.float32)\r\na[0, 0, 0, 0] = 5.0\r\na[0, -1, -1, 0] = 5.0\r\n\r\n\r\nb = tf.constant(a, dtype=tf.float32)\r\nc = tf1.image.resize(b, resize_shape,\r\n                     method=tf1.image.ResizeMethod.BILINEAR,\r\n                     align_corners=False)\r\nd = tf1.image.resize(b, resize_shape,\r\n                     method=tf1.image.ResizeMethod.BILINEAR,\r\n                     align_corners=True)\r\n\r\ne = tf2.image.resize(b, resize_shape,\r\n                     method=tf2.image.ResizeMethod.BILINEAR,\r\n                     antialias=False)\r\nf = tf2.image.resize(b, resize_shape,\r\n                     method=tf2.image.ResizeMethod.BILINEAR,\r\n                     antialias=True)\r\n\r\nz = cv2.resize(a[0], resize_shape, interpolation=cv2.INTER_LINEAR)\r\n\r\n\r\nprint(\"Input: b\")\r\nprint(b.numpy()[0, :, :, 0])\r\n\r\nprint(\"\\nTensorflow: c, tf1 align corners False\")\r\nprint(c.numpy()[0, :, :, 0])\r\n\r\nprint(\"\\nTensorflow: d, tf1 align corners True\")\r\nprint(d.numpy()[0, :, :, 0])\r\n\r\nprint(\"\\nTensorflow: e, tf2 antialias False\")\r\nprint(e.numpy()[0, :, :, 0])\r\n\r\nprint(\"\\nTensorflow: f, tf2 antialias True\")\r\nprint(f.numpy()[0, :, :, 0])\r\n\r\nprint(\"OpenCV:\")\r\nprint(z)\r\n\r\n\r\n# for TF2.0, the UpSampling2D layer uses tf2 antialias=False\r\ninput_layer = tf.keras.layers.Input(shape=(start_shape[0], start_shape[1], 1), batch_size=1)\r\nx = tf.keras.layers.UpSampling2D(size=upsample_size, interpolation='bilinear')(input_layer)\r\nmodel = tf.keras.models.Model(input_layer, x)\r\n\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test the TensorFlow Lite model on random input data.\r\ninput_shape = input_details[0]['shape']\r\ninterpreter.set_tensor(input_details[0]['index'], a)\r\n\r\ninterpreter.invoke()\r\n\r\n# The function `get_tensor()` returns a copy of the tensor data.\r\n# Use `tensor()` in order to get a pointer to the tensor.\r\ntflite_results = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n# Test the TensorFlow model on random input data.\r\ntf_results = model(b)\r\n\r\nprint(\"tflite results shape:\", tflite_results.shape, \"TF results shape:\", tf_results.shape)\r\nprint(\"TFLite results:\")\r\nprint(tflite_results[0, :, :, 0])\r\n\r\nprint(\"\\nTF results:\")\r\nprint(tf_results.numpy()[0, :, :, 0])\r\n\r\nprint(\"\\ntf1 align_corners=False matches tflite:\", np.allclose(c, tflite_results))\r\nprint(\"UpSampling2D: TF matches TFLite:\", np.allclose(tf_results, tflite_results))\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nInput: b\r\n[[5. 1.]\r\n [1. 5.]]\r\n\r\nTensorflow: c, tf1 align corners False\r\n[[5.   4.2  3.4  2.6  1.8  1.   1.   1.   1.   1.  ]\r\n [4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8  1.8  1.8 ]\r\n [3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6  2.6  2.6 ]\r\n [2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4  3.4  3.4 ]\r\n [1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2  4.2  4.2 ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]]\r\n\r\nTensorflow: d, tf1 align corners True\r\n[[5.   4.56 4.11 3.67 3.22 2.78 2.33 1.89 1.44 1.  ]\r\n [4.56 4.21 3.86 3.52 3.17 2.83 2.48 2.14 1.79 1.44]\r\n [4.11 3.86 3.62 3.37 3.12 2.88 2.63 2.38 2.14 1.89]\r\n [3.67 3.52 3.37 3.22 3.07 2.93 2.78 2.63 2.48 2.33]\r\n [3.22 3.17 3.12 3.07 3.02 2.98 2.93 2.88 2.83 2.78]\r\n [2.78 2.83 2.88 2.93 2.98 3.02 3.07 3.12 3.17 3.22]\r\n [2.33 2.48 2.63 2.78 2.93 3.07 3.22 3.37 3.52 3.67]\r\n [1.89 2.14 2.38 2.63 2.88 3.12 3.37 3.62 3.86 4.11]\r\n [1.44 1.79 2.14 2.48 2.83 3.17 3.52 3.86 4.21 4.56]\r\n [1.   1.44 1.89 2.33 2.78 3.22 3.67 4.11 4.56 5.  ]]\r\n\r\nTensorflow: e, tf2 antialias False\r\n[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]\r\n [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]\r\n [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]\r\n [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]\r\n\r\nTensorflow: f, tf2 antialias True\r\n[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]\r\n [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]\r\n [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]\r\n [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]\r\nOpenCV:\r\n[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]\r\n [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]\r\n [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]\r\n [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]\r\ntflite results shape: (1, 10, 10, 1) TF results shape: (1, 10, 10, 1)\r\nTFLite results:\r\n[[5.   4.2  3.4  2.6  1.8  1.   1.   1.   1.   1.  ]\r\n [4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8  1.8  1.8 ]\r\n [3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6  2.6  2.6 ]\r\n [2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4  3.4  3.4 ]\r\n [1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2  4.2  4.2 ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]\r\n [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]]\r\n\r\nTF results:\r\n[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]\r\n [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]\r\n [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]\r\n [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]\r\n [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]\r\n [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]\r\n\r\ntf1 align_corners=False matches tflite: True\r\nUpSampling2D: TF matches TFLite: False\r\n```\r\n", "comments": ["Assigned to @jdduke -- this is the bug I mentioned this morning.", "Great catch, and thanks for flagging! TFLite should be consistent with TF behavior here. We're investigating internally.", "@jdduke oh, its probably worth investigating how the resize bilinear op works in the android NNAPI and EdgeTPU and TFLite GPU and all those places too, I haven't looked at those yet so just throwing it out there first. It'll be complicated to sync all those up if they're different :(.\r\n\r\nAlso it'll be important to make sure TOCO throws an error if the op args dont match. My problem was that the model converted perfectly as far as i could tell but had silently swapped the op underneath so i didn't notice till later.", "Absolutely, our preference is to fail early (during conversion) rather than silently in buggy/unexpected ways at runtime. We'll be validating semantics for all of our various delegate backends as well.", "Looks like the V2 op contains a [`half_pixel_centers`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L1335) parameter that our current converter (TOCO) doesn't really recognize. As a result, it just defaults to the `align_corners=False` behavior.\r\n\r\nWe have an experimental new converter that will flag this as an 'unrecognized' op. To enable it, please change the relevant part as follows:\r\n\r\n```\r\nconverter = tf2.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\nFWIW:\r\n1. TFLite behavior is correct if you use the TF1.x version, even with align_corners=True. If you use TOCO and change `half_pixel_centers` to `align_corners` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L1335), things behave same as TF1.x :-).\r\n2. In case you are intent on using the ResizeBilinear op from TF2, you could try using the [Select TF ops](https://www.tensorflow.org/lite/guide/ops_select) feature(In case you haven't already), at the expense of binary size.\r\n\r\nIn any case, we need to improve TFLite's builtin support for image-processing ops to being them closer to OpenCV :-). I will explore this further.", "@srjoglekar246 Thanks for looking into this!\r\nIn my case as a workaround using TFSelect would be the best for now since thats how i've trained the model. How do I make toco use the select-op instead of the regular builtin tflite-ops for only the resizeBilinear, all the other ops are good as-is and I can keep using. I've normally only seen TFSelect for ops that are missing. (i could hack TOCO and remove it from the list i suppose, but is there a better way?)", "You could this:\r\n\r\n```\r\nconverter = tf2.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf2.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf2.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```\r\n\r\nSince the new converter doesn't recognize that ResizeBilinear, it will only convert that one to the Select-TF version. However, note that Select-TF isn't available (currently) via the Python API, but you can verify the model works by using one of the [other APIs](https://www.tensorflow.org/lite/guide/ops_select#running_the_model).", "Is there any update on this? I'm either trying to find a valid workaround or a fix. The solution provided by @srjoglekar246 would work, but I need to run my code using the Python API, so I can't use `SELECT_TF_OPS`.", "We haven't pushed any changes yet, but this should be fixed by end of the year. Sorry for the delay!", "Thank you for the response @srjoglekar246 . I take it there is no need for me to look into fixing this issue then? It is already fixed internally?", "Not fixed, but on the way :-). We will most likely improve our kernel to match TensorFlow's behavior.", "Hi! Just wanted to mention that I just ran into this as well (I'm using `tf.keras.layers.Upsample2D` with `interpolation=\"bilinear\"`)\r\n\r\nI used workaround 1 from @srjoglekar246 's suggestions.  Is there any update on the timeline for a more permanent fix?\r\n\r\nThanks!", "@srjoglekar246 any idea if this has been fixed?", "I have implemented the new version, its currently under review. This op and its code is used at multiple places in internal tests, so I had to ensure nothing was broken :-). This should go in within a week or so. Sorry about the delay!", "That's good news, can't wait to try it out. Can you drop a comment when it reaches master? Then I can try it in one of the nightly builds.", "Sure, np!", "@srjoglekar246 I've seen a [commit](https://github.com/tensorflow/tensorflow/commit/0e805c551596362fbe8560b40b1abab419d2b949) by you in `master` that seems to affect this subject, is that the fix you were talking about? I tried the nightly from today but the issue still persists for me. Using tf-nightly, I have converted my model to tflite again (I don't think this was necessary?) and ran it on an image. I'm working on semantic segmentation and the segments are all shifted to the top left by some clearly noticeable amount of pixels. This was the case before and is still the case with tf-nightly. Am I doing something wrong? Or did the fix for this issue not yet reach `master`?", "The latter :-). Since it affects a bunch of stuff, the review is taking time. I will ping back on this issue as soon as its in. Thanks for the patience!", "This change has gone in to TensorFlow's master branch. @hgaiser May you confirm and close this issue if it works?", "Awesome! Can't wait to try it out. I will confirm it next Tuesday, but I can't close it because this is not my issue ;)", "Awesome @srjoglekar246 , latest `tf-nightly` fixed my issue. Thank you! :tada: ", "Awesome!"]}, {"number": 33690, "title": "RNNCellDropoutWrapper applies dropout on the LSTM c state", "body": "**System information**\r\n- Have I written custom code: No\r\n- TensorFlow installed from: source (pip)\r\n- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nThe `_call_wrapped_cell` method of the `DropoutWrapperBase` class applies dropout on both `c` and `h` states of an LSTM cell. Its default method to determine if a state should take dropout, `_default_dropout_state_filter_visitor`, only works correctly with LSTM states packed as a `LSTMStateTuple` namedtuple. This was fine in TensorFlow 1.x, where the LSTM state is passed around as a `LSTMStateTuple`. However, in TensorFlow 2.0 the state is a Python tuple, and the method returns `True` for both substates.\r\n\r\n**Describe the expected behavior**\r\nExclude the LSTM `c` state from the list of dropout candidates.\r\n\r\n", "comments": ["For keras LSTM cell, it by default support dropout. You can use param dropout or recurrent dropout for that. The DropoutWrapper is not expected to be used with keras cells.\r\n\r\nI am going to add an error message when keras lstm cell is used with dropout wrapper.", "Is there any reason why `RNNCellDropoutWrapper` cannot be updated to work with `tf.keras.layers.LSTMCell` ? It seems that the only issue is the `LSTMStateTuple` code which needs to be ported.\r\n\r\nThe `dropout` and `recurrent_dropout` parameters of `LSTMCell` are not supporting all the features of `DropoutWrapper`. For example, the dropout mask is reused across timesteps in `LSTMCell`, which is not the default behaviour of `DropoutWrapper`. This aspect introduces new independent variables in all experiments running code ported from TF 1.x.\r\n\r\nFurthermore, dropout in `LSTMCell` is not compatible with `tfa.seq2seq.BasicDecoder` (when using variable batch sizes) and ``tfa.seq2seq.BeamSearchDecoder` (because of the beam width multiplication changing the input shape).\r\n", "Sorry for the very late reply, I was at TF world last few days.\r\n\r\nThe dropout_wrapper was ported from v1 tf.nn.rnn API, and it has duplicated functionality wrt to existing keras API. We port all the wrappers since they provide some values to user, but we would prefer user to rely on the keras API since they are better integrated.\r\n\r\nFor this particular issue, the fix isn't very straight forward, since the keras lstm cell only returns list as [h, c]. We could check the cell type when it is passed in, but it possible to have the cell being wrapped by other wrapper, etc.\r\n\r\nIf you have other proposal, feel free to send a PR and I would be happy to review it. Thanks.", "Thanks for the reply, @qlzh727.\r\nI agree that we should focus our effort on a single API.\r\nWould you mind looking at https://github.com/tensorflow/tensorflow/issues/33991, which describes an error when using dropout in LSTMCell ?\r\n\r\nBtw, above I was saying that not all functionalities of DropoutWrapper have been ported in TF2.0/LSTMCell. It seems that `variational_recurrent=False` and output dropout (`output_keep_prob`) are no longer supported. Would it be possible to have an option in LSTM/LSTMCell to apply new dropout masks at every call ?", "Sorry for the late reply.\r\n\r\nI will take a look for the issue you referred.\r\n\r\nFor the variational dropout, the default value is False in DropoutWrapper. However, I would expect most of the user to use True value. The reason to have False by default is being defensive and not changing user's code when adding new flags. You can check the paper for that, and see the performance/accuracy comparison there. \r\n\r\nOn keras side, we are using variational dropout by default, since we believe this is better than the non-variational version. We didn't expose the knob to user to control it based on the consideration for API complexity and ease of use.\r\n\r\nAlso for the output dropout, it can be easily achieved by adding a dropout layer to the output tensor. ", "Thanks again, @qlzh727 "]}, {"number": 33689, "title": "tf.function strange behavior with global variables", "body": "Hi, I'm trying to migrate the following function form TF 1.x to TF 2.0.\r\n```\r\ndef bar(value=None):\r\n    if value is not None:\r\n        result = tf.constant(value)\r\n    else:\r\n        result = tf.Variable(1)\r\n    return result\r\nbar()\r\n```\r\n at a first attempt I wrote the folowing code:\r\n```\r\nfoo = None\r\n\r\n@tf.function\r\ndef bar(value=None):\r\n   global foo\r\n    if value is not None:\r\n        result = tf.constant(value)\r\n        return result\r\n    else:\r\n        if foo is None:\r\n            foo = tf.Variable(1)\r\n        return foo\r\n\r\nbar()\r\n```\r\nbut it raised an error ` ValueError: tf.function-decorated function tried to create variables on non-first call.`\r\nRewriting the code in the one bellow it works but I can't understand why the first solution dosen't work. Could you please give me an explication?\r\n\r\n```\r\nfoo = None\r\n\r\n@tf.function\r\ndef bar(value=None):\r\n    if value is not None:\r\n        result = tf.constant(value)\r\n        return result\r\n    else:\r\n        global foo\r\n        if foo is None:\r\n            foo = tf.Variable(1)\r\n        return foo\r\n\r\nbar()\r\n```\r\n\r\n", "comments": ["tf.function may evaluate your python function more than once.\r\n\r\nFor more clearer explanation you can refer to the following [comment](https://github.com/tensorflow/tensorflow/issues/26812#issuecomment-474595919)  and also I would recommend you to go through the following [doc](https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md#functions-that-create-state) to understand the difference between a session in TF 1.x and function in tf 2.x.", "@thadumi Is it still an issue. Were you able to understand it?", "Hi, sorry for the delay. \r\n No, it's not an issue anymore. I was able to find the issue, thanks.\r\n\r\nI'd like to use this thread for opening another one about the lists population using for and if constructs.\r\ne.g.  in TF 1.x I used to have a lot of lines like this one `[foo(x) for x in foos if x not in bars]`\r\nand then I put them together using one or more tf.concat. In TF2.0 if I try to wrap this kind of code in a function decorated with tf.function I get the following error:\r\n```\r\nFile \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 317, in minimize\r\n    loss, var_list=var_list, grad_loss=grad_loss)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 351, in _compute_gradients\r\n    loss_value = loss()\r\n  File \"/home/thadumi/Projects/FBK/projects/tensor-flow/logictensornetworks/examples_ltn/smokes_friends_cancer.py\", line 111, in <lambda>\r\n    optimizer.minimize(lambda: loss(theory()), var_list=lambda: variables)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in call\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().wrapped(*args, **kwds)\r\n  File \"/home/thadumi/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 905, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nNameError: in converted code:\r\n    /home/thadumi/Projects/FBK/projects/tensor-flow/logictensornetworks/examples_ltn/smokes_friends_cancer.py:84 theory  *\r\n        facts = [Friends(g[x], g[y]) for (x, y) in friends] + \\\r\n    NameError: free variable 'x' referenced before assignment in enclosing scope\r\n```\r\n", "@thadumi Please create a new issue as the same thread cannot be used to discuss multiple issues. I'm going to close this issue for now. Thanks!"]}, {"number": 33687, "title": "Unsure as to compile options for Intel i7 930, Bloomfield CPU for when rebuilding Tensorflow from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 7\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nPC\r\n\r\n- TensorFlow installed from (source or binary):\r\nTrying to recompile TensorFlow 2.0 for my older machine without AVX support\r\n\r\n- TensorFlow version: 2\r\n- Python version:  3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.28.1\r\n- GCC/Compiler version (if compiling from source): latest\r\n- CUDA/cuDNN version:  n/a I have an older GTS-250 card that does not support\r\n- GPU model and memory:\r\nCPU is an Intel i7 930 which I believe is a Bloomfield model\r\n\r\n**Describe the problem**\r\nI'm at the step during the rebuild that is asking me for optimization flags.  I want to make sure that I am picking the correct ones with my CPU and GPU.\r\n\r\nsome of the previous options were:\r\n\r\nFound possible Python library paths:\r\n  C:\\Users\\Bill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\Bill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nSo I'm at this point and I'm not sure if I should use --config-opt or something like -march core2 I checked to see if there was a -march bloomfield but no option exists... \r\n\r\nWould someone be able to spell out the exact options that I should be using.  Many thanks ahead of time!\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nlisted above\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["maybe just:\r\n-march=nehalem    ?\r\n\r\nor should it be:\r\n--config=opt   -march=nehalem\r\n\r\nhttps://en.wikipedia.org/wiki/List_of_Intel_Core_i7_microprocessors\r\n", "I pushed forward with the compile and ended up seeing the following errors...\r\n\r\nH:\\Python\\TensorFlowCompile\\tensorflow>python ./configure.py\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.29.1 installed.\r\nPlease specify the location of python. [Default is C:\\Users\\Zeek\\AppData\\Local\\Programs\\Python\\Python37\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Users\\Zeek\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\Zeek\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: N\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]: --config=v2 -march=nehalem\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: Y\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n\r\nH:\\Python\\TensorFlowCompile\\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=0 --terminal_columns=269\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Users/Zeek/AppData/Local/Programs/Python/Python37/python.exe\r\nINFO: Reading rc options for 'build' from h:\\python\\tensorflowcompile\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2\r\nINFO: Reading rc options for 'build' from h:\\python\\tensorflowcompile\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/Zeek/AppData/Local/Programs/Python/Python37/python.exe --action_env PYTHON_LIB_PATH=C:/Users/Zeek/AppData/Local/Programs/Python/Python37/lib/site-packages --python_path=C:/Users/Zeek/AppData/Local/Programs/Python/Python37/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file h:\\python\\tensorflowcompile\\tensorflow\\.bazelrc: --define=tf_api_version=2\r\nINFO: Found applicable config definition build:monolithic in file h:\\python\\tensorflowcompile\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Found applicable config definition build:monolithic in file h:\\python\\tensorflowcompile\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded, 0 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages loaded, 18 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages loaded, 18 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages loaded, 18 targets configured)\r\nINFO: Call stack for the definition of repository 'com_google_protobuf' which is a tf_http_archive (rule definition at H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl:121:19):\r\n - H:/python/tensorflowcompile/tensorflow/tensorflow/workspace.bzl:434:5\r\n - H:/python/tensorflowcompile/tensorflow/WORKSPACE:19:1\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages loaded, 18 targets configured)\r\nINFO: Repository 'com_google_protobuf' used the following cache hits instead of downloading the corresponding file.\r\n * Hash 'b9e92f9af8819bbbc514e2902aec860415b70209f31dfc8c4fa72515a5df9d59' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/310ba5ee72661c081129eb878c1bbcec936b20f0.tar.gz\r\nIf the definition of 'com_google_protobuf' was updated, verify that the hashes were also updated.\r\nERROR: An error occurred during the fetch of repository 'com_google_protobuf':\r\n   Traceback (most recent call last):\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 101\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 68, in _apply_patch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'C:\\msys64\\usr\\bin\\bash.exe -l -c \"patch\" \"-p1\" \"-d\" \"C:/users/Zeek/_bazel_Zeek/hfhzrtpt/external/com_google_protobuf\" \"-i\" \"H:/python/tensorflowcompile/tensorflow/third_party/protobuf/protobuf.patch\"':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@com_google_protobuf//': Traceback (most recent call last):\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 101\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 68, in _apply_patch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"H:/python/tensorflowcompile/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'C:\\msys64\\usr\\bin\\bash.exe -l -c \"patch\" \"-p1\" \"-d\" \"C:/users/Zeek/_bazel_Zeek/hfhzrtpt/external/com_google_protobuf\" \"-i\" \"H:/python/tensorflowcompile/tensorflow/third_party/protobuf/protobuf.patch\"':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\nINFO: Elapsed time: 19.298s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (6 packages loaded, 18 targets configured)\r\nFAILED: Build did NOT complete successfully (6 packages loaded, 18 targets configured)\r\n\r\nperhaps my Bazel options are incorrect?\r\n\r\n\r\n", "looks like patch.exe isn't installed, have updated it and compile is getting farther... \r\n\r\nAs a double check are my options correct above and are they going to take effect?\r\n--config=v2 -march=nehalem", "I got a bit closer and now PythonZipper is failing... \r\n\r\n\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\n\r\n[0 / 23] [Prepa] PythonZipper tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.zip ... (3 actions, 0 running)\r\nERROR: H:/python/tensorflowcompile/tensorflow/tensorflow/lite/python/BUILD:46:1: PythonZipper tensorflow/lite/python/tflite_convert.zip failed (Exit 255)\r\nFATAL: MappedOutputFile(bazel-out/x64_windows-opt/bin/tensorflow/lite/python/tflite_convert.zip): CreateFileMapping failed\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 38.195s, Critical Path: 4.35s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "I ran the bezel config again and upon my second compile it now busts much sooner..\r\n\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'REPOSITORY_DIRECTORY:@local_config_cc' (requested by nodes 'REPOSITORY:@local_config_cc')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:528)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:399)\r\n        at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)\r\n        at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)\r\n        at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)\r\n        at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)\r\n        at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)\r\nCaused by: java.nio.file.InvalidPathException: Illegal char <*> at index 60: C:/users/bill/_bazel_bill/hfhzrtpt/external/local_config_cc/**********************************************************************\r\n** Visual Studio 2017 Developer Command Prompt v15.0\r\n** Copyright (c) 2017 Microsoft Corporation\r\n**********************************************************************\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/BuildTools/VC/Auxiliary/Build/VCVARSALL.BAT\r\n        at java.base/sun.nio.fs.WindowsPathParser.normalize(Unknown Source)\r\n        at java.base/sun.nio.fs.WindowsPathParser.parse(Unknown Source)\r\n        at java.base/sun.nio.fs.WindowsPathParser.parse(Unknown Source)\r\n        at java.base/sun.nio.fs.WindowsPath.parse(Unknown Source)\r\n        at java.base/sun.nio.fs.WindowsFileSystem.getPath(Unknown Source)\r\n        at java.base/java.nio.file.Path.of(Unknown Source)\r\n        at java.base/java.nio.file.Paths.get(Unknown Source)\r\n        at com.google.devtools.build.lib.vfs.JavaIoFileSystem.getNioPath(JavaIoFileSystem.java:84)\r\n        at com.google.devtools.build.lib.vfs.JavaIoFileSystem.exists(JavaIoFileSystem.java:119)\r\n        at com.google.devtools.build.lib.vfs.Path.exists(Path.java:356)\r\n        at com.google.devtools.build.lib.bazel.repository.skylark.SkylarkPath.exists(SkylarkPath.java:79)\r\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n        at java.base/java.lang.reflect.Method.invoke(Unknown Source)\r\n        at com.google.devtools.build.lib.syntax.MethodDescriptor.call(MethodDescriptor.java:135)\r\n        at com.google.devtools.build.lib.syntax.DotExpression.eval(DotExpression.java:126)\r\n        at com.google.devtools.build.lib.syntax.DotExpression.doEval(DotExpression.java:51)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.UnaryOperatorExpression.doEval(UnaryOperatorExpression.java:98)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.Eval.execIf(Eval.java:139)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:214)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:91)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.callWithArgArray(BaseFunction.java:474)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:436)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.callFunction(FuncallExpression.java:992)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:904)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.UnaryOperatorExpression.doEval(UnaryOperatorExpression.java:98)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.Eval.execIf(Eval.java:139)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:214)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:91)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.callWithArgArray(BaseFunction.java:474)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:436)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.callFunction(FuncallExpression.java:992)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:904)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.Eval.execAssignment(Eval.java:72)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:192)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.Eval.execStatements(Eval.java:231)\r\n        at com.google.devtools.build.lib.syntax.Eval.execIf(Eval.java:144)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:214)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:91)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.callWithArgArray(BaseFunction.java:474)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:436)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.callFunction(FuncallExpression.java:992)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:904)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.Eval.execAssignment(Eval.java:72)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:192)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:91)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.callWithArgArray(BaseFunction.java:474)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:436)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.callFunction(FuncallExpression.java:992)\r\n        at com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:904)\r\n        at com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:75)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:201)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.Eval.execStatements(Eval.java:231)\r\n        at com.google.devtools.build.lib.syntax.Eval.execIfBranch(Eval.java:83)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:198)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.Eval.execIf(Eval.java:140)\r\n        at com.google.devtools.build.lib.syntax.Eval.execDispatch(Eval.java:214)\r\n        at com.google.devtools.build.lib.syntax.Eval.exec(Eval.java:183)\r\n        at com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:91)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.callWithArgArray(BaseFunction.java:474)\r\n        at com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:436)\r\n        at com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryFunction.fetch(SkylarkRepositoryFunction.java:173)\r\n        at com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.fetchRepository(RepositoryDelegatorFunction.java:298)\r\n        at com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.compute(RepositoryDelegatorFunction.java:225)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:451)\r\n        ... 7 more\r\nFAILED: Build did NOT complete successfully (231 packages loaded, 3779 targets configured)\r\nWARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)\r\n\r\nH:\\Python\\TensorFlowCompile\\tensorflow>", "I dunno what to do next at this point other than to wipe out any .o files that may have been created and start a fresh build all over again.  Is there a Python zip package that I need to install, is that why the pythonZipper failed?\r\n\r\nI'm attempting to following the following windows compilation of tensorFlow to account for the fact that my windows machine lacks a CPU/GPU that support AVX commands...\r\n\r\nhttps://www.tensorflow.org/install/source_windows", "For old computers please use tensorflow 1.5 version and python <= 3.6 version.", "@Belgrath1900 ,\r\nIs this still an issue?\r\n\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33687\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33687\">No</a>\n"]}, {"number": 33686, "title": "TF 2.0 tf.keras.models.load_model won't load models compiled with a loss dictionary", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): docker image (tensorflow/tensorflow:2.0.0-gpu-py3)\r\n- TensorFlow version (use command below):  v2.0.0-rc2-26-g64c3d38 2.0.0     \r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nAttempting to load a keras model which has been compiled with a loss dictionary fails, throwing the following error:\r\nValueError: Unknown entries in loss dictionary: ['MyLoss']. Only expected following keys: ['dense_1']\r\n\r\n**Describe the expected behavior**\r\nThe model should load.\r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\nEDIT - _refer to latest gist below_\r\n\r\n**Other info / logs**\r\nN/A\r\n", "comments": ["I have tried on colab with TF version 2.0 , 2.1.0-dev20191024 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/33341889953f2e4a695282ac2f2eb3a2/untitled298.ipynb). Thanks!", "@optiluca Did you define any custom loss function? If you are trying to define custom loss, please follow this [link](https://stackoverflow.com/questions/43818584/custom-loss-function-in-keras) or similar kinds of resources to write the custom loss function. Thanks!", "I did not.  I think the example code is pretty clear?  There's nothing custom about it.", "@optiluca I modified couple of things in the code and it works without any issues. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/6b67e588cad1c274afe2d5ccca391ec8/untitled600.ipynb). \r\n\r\nPlease close this issue if this was resolved. Thanks!", "The changes to the code now simply mean that it doesn't have a loss dictionary, so indeed it works.  The bug I reported is that it's impossible to load a model which has a loss dictionary defined.  I have a model with multiple outputs (each with its own loss function) that breaks because of this bug.  Simply removing the loss dictionary isn't an option, I reduced it down to the test code I posted above for ease of reproducibility and to isolate the issue.", "I've played around with the gist, I think I'd made a mistake in my example script (not assigning the name of the last layer to match the name of the key in the loss dictionary).  I've made a new repro script [here](https://colab.research.google.com/gist/optiluca/83eeca1cd238ed119d6a6185bd45c635/untitled298.ipynb), the issue still stands.  Could it be that the real issue is that the layer names aren't persisting across a save/load, meaning that the dictionary key then turns out to be wrong?  I say this because if I name my output \"output_1\" then it works.", "Hi, is there any update on this issue?  The latest gist is [here](https://colab.research.google.com/gist/optiluca/83eeca1cd238ed119d6a6185bd45c635/untitled298.ipynb)", "@optiluca Looks like this was resolved in `tf-nightly`. I cannot reproduce the issue with `tf-nightly`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/19db72f446e25f5192d2df18b09bbc8c/untitled298.ipynb). Thanks!\r\n\r\nPlease close the issue if it was resolved for you. Thanks!\r\n\r\n", "Looks ok now, thanks!  When can I expect this to be released officially?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33686\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33686\">No</a>\n", "@optiluca TF Team is working hard on releasing the TF2.1. As of now, I don't know exact release date. Thanks!"]}, {"number": 33685, "title": "Could not find valid device for node. Node: {{node NonMaxSuppressionV4}}", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **tensorflow 1.14.0**\r\n- Python version: **3.7.3**\r\n\r\ni was trying to use `tf.image.non_max_suppression_padded()`, but i got an error, maybe i write a wrong code, hope somebody can help.\r\n\r\ntest code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnp.random.seed(0)\r\n\r\nnum_objs_per_img = 10\r\n\r\nboxes = np.sort(np.random.rand(num_objs_per_img, 4))\r\nscores = np.random.rand(num_objs_per_img)\r\n\r\nidx = tf.image.non_max_suppression_padded(boxes, scores, max_output_size=7, iou_threshold=0.7)\r\nprint(idx)\r\n```\r\n\r\nterminal log:\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"draft.py\", line 11, in <module>\r\n    idx = tf.image.non_max_suppression_padded(boxes, scores, max_output_size=7, iou_threshold=0.7)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py\", line 2646, in non_max_suppression_padded\r\n    pad_to_max_output_size)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 2561, in non_max_suppression_v4\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node.\r\nNode: {{node NonMaxSuppressionV4}}\r\nAll kernels registered for op NonMaxSuppressionV4 :\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_HALF]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_HALF]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_HALF]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_HALF]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n [Op:NonMaxSuppressionV4]\r\n```", "comments": ["@Xie-Fangyuan \r\n\r\nI tried to execute your code with TF 1.14. However i am not seeing any issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/7d6708be5be58ef979892901471c034b/untitled299.ipynb).Thanks!", "sorry, I didn't realize that I was also using eager execution. and I use CPU to run.\r\n\r\nhere is the new test code:\r\n\r\n```python\r\nfrom tensorflow.compat.v1 import enable_eager_execution\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\nenable_eager_execution()\r\nnp.random.seed(0)\r\n\r\nnum_objs_per_img = 10\r\n\r\nboxes = np.sort(np.random.rand(num_objs_per_img, 4))\r\nscores = np.random.rand(num_objs_per_img)\r\n\r\nidx = tf.image.non_max_suppression_padded(boxes, scores, max_output_size=7, iou_threshold=0.7)\r\nprint(idx)\r\n```\r\n\r\nit did show the error logs. should I use without eager execution when using nms?", "I have tried on colab with TF version 1.14,1.15.0-rc3 and was able to reproduce the issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/30062ca18ac915e01acfb42473d3603b/untitled314.ipynb).Thanks!", "@Xie-Fangyuan I think the error was due to `dtype` of `boxes` and `scores`. When I converted both the dtypes to `tf.float32`, there was no error. \r\n\r\nThe two lines of code I added is here\r\n```\r\nboxes = np.sort(np.random.rand(num_objs_per_img, 4))\r\nboxes = tf.dtypes.cast(boxes,tf.float32)\r\nscores = np.random.rand(num_objs_per_img)\r\nscores = tf.dtypes.cast(scores,tf.float32)\r\n```\r\n\r\nPlease check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/ef0802b70622b3294a251108bd3ee5a5/untitled314.ipynb). \r\n\r\nI am closing this issue as it was resolved. Please feel free to open the issue if it persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33685\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33685\">No</a>\n", "really thanks! float32 works well.", "float32 works well.", "https://medium.com/@HojjatA/could-not-find-valid-device-for-node-while-eagerly-executing-8f2ff588d1e\r\n\r\nGreat fix to the problem", "I got a similar error but in my case pbtxt file for the tfrecord had a problem, try checking that also.", "I think your value should be float as error message says. I have encountered the same problem while finding the determinant of a matrix and changed the dtype to float32 and problem solved."]}, {"number": 33684, "title": "[TF 2.0 Nightly] Tensorflow 2.0 nightly build doesn't work with colab TPUs", "body": "TPU strategy can't be instantiated in colab. I am aware that this issue might be more suitable for colaboratory  github but there many issues are not getting a response very fast so I thought it will be better to ask you about a potential solution (if there is a bug related to the last build and not google colab environment) or whether it is planned that colab will have this support in the nearby future.\r\n\r\nThe following link demonstrates the issue: https://colab.research.google.com/drive/1DsM_lsZXvBnlz3weymB8GHQ6cjoaxPgq\r\n\r\nTPU runtime was selected and the version of the installed tf2.0 is '2.1.0-dev20191024'. Thanks!", "comments": ["Can you try with  `2.1.0-dev20191020` instead? There is a failure in between 20 and 22 that I'm currently investigating, so just in case that's also the issue you're seeing, please try with 20.", "@mihaimaruseac I tried it but it results in the same error.", "Looking back, it doesn't seem related to what I was debugging", "I have tried on colab with TF version 2.1.0-dev20191024 ,2.1.0-dev20191020, 2.1.0-dev20191021,2.1.0-dev20191022 ,2.1.0-dev20191019 and was able to reproduce the issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/fea33e547df4f4368a4e88518c4ed8c2/tpu_colab_not_working_with_tf2-0nightly.ipynb) Thanks!", "Yes, this expected due to how TPUs and Colab work: You can upgrade the version of TensorFlow in Colab kernel but the version of TensorFlow on the remote TPU currently cannot be changed. We have ongoing work to fix this, which will hopefully land in the next few weeks. In the meantime, if you want to use TF2.0 and TPU and have access to Cloud TPU, you can allocate a one with the version 'nightly-2.x' and then follow the instructions [here](https://research.google.com/colaboratory/local-runtimes.html) to setup and connect to a Colab runtime running on the Cloud TPU VM.", "@bfontain Thank you! I will use your solution in the meantime. Is there any way I can follow the progress with colab's TPUs?", "No problem. I'll update this bug once above mentioned work is finished.", "@bfontain I've been trying your solution past couple of days but I couldn't figure out why I can't make it work.\r\n\r\nI created a VM instance in google cloud and after that a TPU instance. Both are on the same zone and have the same name. For the TPU computing instance I've specified the tensorflow version by setting the --tf-version flag to \"nightly-2.x\". They were both created and I connected to the VM as described in guides. So far, so good. The problem appears when I'm trying to run the following python script to check connection to TPU.\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\ntpu_addr = 'grpc://{ip}:8470'\r\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_addr)\r\ntf.config.experimental_connect_to_cluster(cluster_resolver)\r\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\r\n\r\nprint(strategy)\r\n```\r\nThe problem is that the process hangs with the following output:\r\n\r\n```\r\ngeorgealexandruvlad@tpu-bert:~$ python3 file.py\r\n2019-11-06 22:19:16.116169: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-11-06 22:19:16.116213: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.1.0-dev20191106\r\n2019-11-06 22:19:17.457940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-11-06 22:19:17.457982: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-11-06 22:19:17.458016: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-bert): /proc/driver/nvidia/version does not exist\r\n2019-11-06 22:19:17.458833: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-11-06 22:19:17.466620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\r\n2019-11-06 22:19:17.466836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556822a2a050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-06 22:19:17.466937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-11-06 22:19:17.473816: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}\r\n2019-11-06 22:19:17.473853: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:32891}georgealexandruvlad@tpu-bert:~$ python3 file.py\r\n2019-11-06 22:19:16.116169: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-11-06 22:19:16.116213: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.1.0-dev20191106\r\n2019-11-06 22:19:17.457940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-11-06 22:19:17.457982: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-11-06 22:19:17.458016: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-bert): /proc/driver/nvidia/version does not exist\r\n2019-11-06 22:19:17.458833: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-11-06 22:19:17.466620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\r\n2019-11-06 22:19:17.466836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556822a2a050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-06 22:19:17.466937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-11-06 22:19:17.473816: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}\r\n2019-11-06 22:19:17.473853: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:32891}\r\n```\r\n\r\nI installed on the vm the last tf-nightly version and checked that it is seen by the system. Both instances have owner permissions to rule out the possibility of a any restrictions of this kind.\r\n\r\nDo you happen to know what might be the cause of this error? I've searched a lot past few days and I have no idea how to solve it. I'm trying to find out if there is a bug and I should stop searching or it's something faulty in my approach.", "If you have the chance, can you try setting tpu_addr to just the name of the cloud tpu you allocated rather than the grpc://+ip address? TPUClusterResolver should be able to figure everything out from just that information, so long as the GCE instance is in the same zone/project as the TPU.", "Already tried this. I've checked again to be sure and it has the following output:\r\n\r\n```\r\n2019-11-07 09:35:32.471945: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-11-07 09:35:32.471988: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.1.0-dev20191106\r\n2019-11-07 09:35:34.243429: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-11-07 09:35:34.243479: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-11-07 09:35:34.243516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-bert): /proc/driver/nvidia/version does not exist\r\n2019-11-07 09:35:34.460615: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-11-07 09:35:34.709331: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000134999 Hz\r\n2019-11-07 09:35:34.709561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55abc59a2790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-07 09:35:34.709587: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-11-07 09:35:34.861465: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}\r\n2019-11-07 09:35:34.861517: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31015}\r\n```\r\n\r\nAs you said, based on the name it figures out the IP address and port to the TPU but unfortunately it hangs again.", "OK, I just tried this with a new gce instance with 2.1.0-dev20191106 installed and a freshly created v3-8 TPU (running in europe-west4-a) with nightly-2.x and your code worked for me. In my case I created the GCE instance and TPU by hand in the cloud console and the only non-default settings I had to use for the GCE instance other than the name//region was to 'Allow full access to all Cloud APIs'. For the TPU, I picked the nightly-2.x version and a v3-8.\r\n\r\nWhat your seeing is the same symptom I see if I pick an address/port that the GCE instance can't connect to. Was your TPU created in the same project as the GCE instance?\r\n\r\nThere is a slight possibility that you ended up with a bad combination TensorFlow versions and TPU/nightly-2.x version. Could you try deleting and recreating the TPU?", "Yes, they were created in the same project otherwise the VM wouldn't have set the environment variable TPU_NAME, as I understood. After connecting to the VM I've checked for this. I deleted and created more than 10 VMs and TPUs past few days but I will give it a try again. It's important that you succeeded and now I know the problem is on my side. Thanks for that!", "Thanks for being patient with this. I talked with one of my colleagues who is more familiar with Cloud TPU issues. Is there anyway that the TPU and GCE instance are on different networks? In my GCE instance has network 'default' under 'Network interfaces' and the TPU has network 'default' under its 'Network endpoints'.\r\n\r\nIf the network matches, is there any chance that you have custom firewall rules?", "My colleague took a closer look at your issue and suggested that you file a bug here https://issuetracker.google.com/issues/new?component=508028 so they can help you directly.", "I've checked the firewall rules and everything is on default. I've tried to make the instances directly from the console as you did and I left everything on default less the zone, the tf version for TPU (going for nightly-2.x) and the name which I made sure it's the same for both. I also checked the 'Allow full access to all Cloud APIs'. box. So I get a Debian VM and a TPU (I tried with v2-8 and v3-8). On the VM I installed python-3.7 for tensorflow 2.0 to work and tried to run the code I posted in here. Unfortunately, it resulted in the same problem. I will file an issue to the link you provided. Thanks a lot for your time!\r\n\r\nEDIT: the code I've tried is the same I posted above with the mention that I provided the name of the TPU to the _TPUClusterResolver_ instead of the address as you suggested", "Hi, @bfontain ! Do you have any new information about the progress on the issue (colab TPU's compatibility with tf 2.0)?", "Hi, right now you can try '%tensorflow_version 2.x' in a cell. That will bring you to TF 2.0 + a 2.0 TPU backend. Once 2.1 is released then I believe that will switch to 2.1. I'm currently working with the colab team to see if we can implement a '%tensorflow_version nightly' (this does not work right now).", "Sorry for the delay, it looks like %tensorflow_version 2.x now brings in TF2.1-rc1 and works on TPUs. As an example of directly using TPUs in colab + TF 2.x, a colleague recently posted this colab notebook: https://colab.research.google.com/github/znah/tpu4fun/blob/master/feature_viz.ipynb", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33684\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33684\">No</a>\n"]}, {"number": 33683, "title": "How to replace contrib.rnn.stack_bidirectional_dynamic_rnn in tf2.0", "body": "I use contrib.rnn.stack_bidirectional_dynamic_rnn in my code, but I upgrade my tf to 2.0 now, how to replace it?", "comments": ["So there are two ways to build bidirectional RNN in tf 2.0 with keras layers, and the existing stack_bidirectional_dynamic_rnn() is using the second approach. There isn't any right/wrong between those 2 approaches, the major difference is that whether the cell state will be feed to next layer as initial states.\r\n\r\n1. Does not feed cell states to next layer as initial states, note that forward and backward cellls are just simpleRNN cells and you can replace them with LSTM or GRU cells.\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers\r\n\r\nbatch = 32\r\ntimestep = 10\r\ninput_shape = 8\r\n\r\ncell_size = 4\r\nnum_layers = 6\r\ncells = [layers.SimpleRNNCell(cell_size) for _ in range(num_layers)]\r\n\r\nmodel = tf.keras.Sequential()\r\n\r\nmodel.add(tf.keras.Input(shape=(None, input_shape)))\r\nmodel.add(layers.Bidirectional(\r\n    layers.RNN(cells)\r\n))\r\n\r\nresult = model.predict(np.ones(shape=(batch, timestep, input_shape), dtype=np.float32))\r\nprint(result)\r\n\r\n```\r\n\r\n2. Using the previous layers end state as the initial state for the next layer. Since now we need to probably pass the states between layers, we will need to use functional API, rather than just the Sequential model as the example above.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers\r\n\r\nbatch = 32\r\ntimestep = 10\r\ninput_shape = 8\r\n\r\ncell_size = 4\r\nnum_layers = 6\r\n# cells = [layers.SimpleRNNCell(cell_size) for _ in range(num_layers)]\r\n\r\ninputs = tf.keras.Input(shape=(None, input_shape))\r\noutput = inputs\r\nstates = None\r\nfor _ in range(num_layers):\r\n  result = layers.Bidirectional(\r\n      layers.RNN(layers.SimpleRNNCell(cell_size),\r\n                 return_state=True, return_sequences=True))(output, states)\r\n  output, states = result[0], result[1:]\r\n# If you only care about the output for the last time step, you can just slide it here.\r\noutput = output[:, -1, :]\r\n\r\nmodel = tf.keras.Model(inputs, output)\r\n\r\nresult = model.predict(np.ones(shape=(batch, timestep, input_shape), dtype=np.float32))\r\nprint(result)\r\n```\r\n\r\nHope this resolve your question."]}]