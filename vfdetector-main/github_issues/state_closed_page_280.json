[{"number": 45944, "title": "Tensorflow 1.14 is not recognizing custom operator: Posenet_Decoder_Op", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: using virtualenv and pip\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source):  gcc (GCC) 7.3.1 20180712 (Red Hat 7.3.1-11)\r\n- CUDA/cuDNN version: --\r\n- GPU model and memory: --\r\n\r\n\r\n**Describe the problem**\r\nI have been trying to run this model: [posenet](https://github.com/google-coral/project-posenet/blob/master/models/mobilenet/posenet_mobilenet_v1_075_481_641_quant_decoder.tflite) but it retrieves an error in the decoder part indicating you need a custom operator called PosenetDecoderOp. I investigated what to do and I approached this problem installing Tensorflow from source adding the custom operators. After compilation and instalation of Tensorflow I tried to run my code again:\r\n\r\n              _``import numpy as np\r\n              import tensorflow as tf\r\n              \r\n              #Load the TFLite model and allocate tensors.\r\n              interpreter = tf.lite.Interpreter(model_path=\"posenet_mobilenet_v1_075_481_641_quant_decoder.tflite\")\r\n              interpreter.allocate_tensors()\r\n              \r\n              #Get input and output tensors.\r\n              input_details = interpreter.get_input_details()\r\n              output_details = interpreter.get_output_details()\r\n              \r\n              #Test the model on random input data.\r\n              input_shape = input_details[0]['shape']\r\n              input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n              interpreter.set_tensor(input_details[0]['index'], input_data)\r\n              \r\n              interpreter.invoke()\r\n              output_data = interpreter.get_tensor(output_details[0]['index'])\r\n              print(output_data)``_\r\n\r\nAnd I got the following error:\r\n`  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/ec2-user/decoder/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nTraceback (most recent call last):\r\n  File \"tf_run_model.py\", line 5, in <module>\r\n    interpreter = tf.lite.Interpreter(model_path=\"posenet_mobilenet_v1_075_481_641_quant_decoder.tflite\")\r\n  File \"/home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\", line 76, in __init__\r\n    _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\r\n  File \"/home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/usr/local/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 28, in <module>\r\n    _tensorflow_wrap_interpreter_wrapper = swig_import_helper()\r\n  File \"/home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_tensorflow_wrap_interpreter_wrapper', fp, pathname, description)\r\n  File \"/usr/local/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/local/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\n  File \"<frozen importlib._bootstrap>\", line 696, in _load\r\n  File \"<frozen importlib._bootstrap>\", line 670, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 583, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 1043, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: /home/ec2-user/decoder/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so: undefined symbol: _ZN6tflite3ops6custom27Register_POSENET_DECODER_OPEv`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "Please follow the instruction at https://github.com/google-coral/project-posenet#the-poseengine-class\r\n\r\nThe above PosenetDecoderOp is not a part of the TFLite project but it is a part of the project posenet. You need to register the custom op before invoking the TFLite interpreter. Please refer the custom op guide document: https://www.tensorflow.org/lite/guide/ops_custom\r\n\r\nhttps://github.com/google-coral/edgetpu/tree/master/src/cpp/posenet", "> Please follow the instruction at https://github.com/google-coral/project-posenet#the-poseengine-class\r\n> \r\n> The above PosenetDecoderOp is not a part of the TFLite project but it is a part of the project posenet. You need to register the custom op before invoking the TFLite interpreter. Please refer the custom op guide document: https://www.tensorflow.org/lite/guide/ops_custom\r\n> \r\n> https://github.com/google-coral/edgetpu/tree/master/src/cpp/posenet\r\n\r\nThank you so much abattery, I'm trying this and I will update with the results.", "Hello again @abattery \r\n\r\n> Please follow the instruction at https://github.com/google-coral/project-posenet#the-poseengine-class\r\n> \r\nI tried this but it is no posible to run the model cause I'm using the cpu version: [this model](https://github.com/google-coral/project-posenet/blob/master/models/mobilenet/posenet_mobilenet_v1_075_481_641_quant_decoder.tflite)\r\nnevertheless, it requires an operator that is from the edgetpu library. This is the operator I tried to put in my compilated from source Tensorflow.\r\n\r\nThis is the output:\r\n```\r\n python3 simple_pose.py\r\nTraceback (most recent call last):\r\n  File \"simple_pose.py\", line 15, in <module>\r\n    from pose_engine import PoseEngine\r\n  File \"/home/ec2-user/project-posenet/pose_engine.py\", line 15, in <module>\r\n    from pycoral.utils import edgetpu\r\nModuleNotFoundError: No module named 'pycoral'\r\n\r\n```\r\n\r\n> The above PosenetDecoderOp is not a part of the TFLite project but it is a part of the project posenet. You need to register the custom op before invoking the TFLite interpreter. Please refer the custom op guide document: https://www.tensorflow.org/lite/guide/ops_custom\r\n> \r\n> https://github.com/google-coral/edgetpu/tree/master/src/cpp/posenet\r\n\r\nI used this documentation you attached and also [this article](https://medium.com/@bsramasubramanian/running-a-tensorflow-lite-model-in-python-with-custom-ops-9b2b46efd355) to register the custom operator but I'm getting the same error I described in the origina post:\r\n\r\n`[...]_tensorflow_wrap_interpreter_wrapper.so: undefined symbol: _ZN6tflite3ops6custom27Register_POSENET_DECODER_OPEv`\r\n\r\nI don't know what else to do at this point.", "Regarding the 'pycoral' import issue, you need to have edgetpu project in your development environment. You can probably ask it to the edgetpu project.\r\n\r\nFor the undefined symbol problem, I think you need to expose tflite::ops::custom::Register_POSENET_DECODER_OP function in the header and the global symbol can be retrieved from the Python program.", "Is the edgetpu always required to run in cpu? Im doing this in a cloud instance so I cannot connect the edgetpu. ", "No, it's not necessary.\r\nYou'd better just check how to create interpreter instance with posenet_lib since the pose_engine has dependency on edgetpu.\r\n\r\n```\r\n        posenet_decoder_delegate = load_delegate(POSENET_SHARED_LIB)\r\n        self._interpreter = Interpreter(\r\n            model_path, experimental_delegates=[posenet_decoder_delegate])\r\n        self._interpreter.allocate_tensors()\r\n```", "> No, it's not necessary.\r\n> You'd better just check how to create interpreter instance with posenet_lib since the pose_engine has dependency on edgetpu.\r\n> \r\n> ```\r\n>         posenet_decoder_delegate = load_delegate(POSENET_SHARED_LIB)\r\n>         self._interpreter = Interpreter(\r\n>             model_path, experimental_delegates=[posenet_decoder_delegate])\r\n>         self._interpreter.allocate_tensors()\r\n> ```\r\n\r\nHello terryheo! I appreciate your help, I came to this conclussion after dealing with many errors and I finally made it work :D (using the tflite_runtime and a compilated .so file).\r\n\r\nI attach the Issue where I updated all the process: [project-posenet Issue #49](https://github.com/google-coral/project-posenet/issues/49)", "> I came to this conclussion after dealing with many errors and I finally made it work :D\r\n\r\n@lupitia1,\r\nThank you for the update.\r\n\r\nIs this still an issue? Please feel free to close the issue if resolved. ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45944\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45944\">No</a>\n"]}, {"number": 45940, "title": "Problem about distributed training with XLA compiling.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n  - custom layer and custom training step\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  - I have tested on Windows 10, Ubuntu 16.04, and Ubuntu 18.04.\r\n- TensorFlow installed from (source or binary):\r\n  - both\r\n- TensorFlow version (use command below):\r\n  - I have tried TF 2.4, 2.5 distributed version and source installed 2.4\r\n- Python version:\r\n  - 3.7\r\n- Bazel version (if compiling from source):\r\n  - 3.5.0\r\n- GCC/Compiler version (if compiling from source):\r\n  - 7.5\r\n- CUDA/cuDNN version:\r\n  - 10.1 and 11.0\r\n- GPU model and memory:\r\n  - 1080ti x4\r\n\r\n**Describe the current behavior**\r\nWhen I train my model on multi-gpu with XLA compiling below error is occurred.\r\n```\r\nTraining starts\r\nTraceback (most recent call last):\r\n  File \"FFP_/train_w_pruning.py\", line 76, in <module>\r\n    train_step(*data)\r\n  File \"/home/cvip/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 787, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/cvip/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 854, in _call\r\n    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/home/cvip/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1920, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/cvip/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 561, in call\r\n    ctx=ctx)\r\n  File \"/home/cvip/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Trying to access resource ResNet/conv/kernel/replica_1_879 located in device /job:localhost/replica:0/task:0/device:GPU:0 [Op:__inference_train_step_dist_88943]\r\n```\r\n\r\n**Describe the expected behavior**\r\nI want to compile my multi-gpu code but it seems unavailable.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://github.com/sseung0703/TF2-multi-gpu-training\r\n", "comments": ["@sseung0703,\r\nThe code provided in the GitHub repo is fairly complex hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro? That will allow us to determine the source of the issue easily. Thanks!", "@amahendrakar\r\nSorry for the complex example. I write a code as simple as possible as below.\r\nIt requires three codes in my repo, i.e., nets/ResNet.py, nets/tcl.py, and op_utils.py\r\nIt is still complex, but I think they should be checked because the problem may be in custom layers or a training step.\r\n\r\n```\r\nimport os, argparse\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.debugging.set_log_device_placement(False)\r\n\r\nimport op_utils\r\nfrom nets import ResNet\r\n\r\nparser = argparse.ArgumentParser(description='')\r\n\r\nparser.add_argument(\"--gpu_id\", default= [0], type=int, nargs = '+')\r\nparser.add_argument(\"--compile\", default=True, action = 'store_true')\r\nparser.add_argument(\"--learning_rate\", default=1e-1, type=float)\r\nparser.add_argument(\"--weight_decay\", default=5e-4, type=float)\r\nparser.add_argument(\"--batch_size\", default=128, type=int)\r\nargs = parser.parse_args()\r\n\r\nif __name__ == '__main__':\r\n    gpus = tf.config.list_physical_devices('GPU')\r\n    tf.config.set_visible_devices([tf.config.list_physical_devices('GPU')[i] for i in args.gpu_id], 'GPU')\r\n    for gpu_id in args.gpu_id:\r\n        tf.config.experimental.set_memory_growth(gpus[gpu_id], True)\r\n    devices = ['/gpu:{}'.format(i) for i in args.gpu_id]\r\n    strategy = tf.distribute.MirroredStrategy(devices, cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n\r\n    with strategy.scope():\r\n        options = tf.data.Options()\r\n        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\r\n\r\n        def inference(image, label):\r\n            image = tf.cast(image, tf.float32)\r\n            image = (image-np.array([113.9,123.0,125.3]))/np.array([66.7,62.1,63.0])\r\n            return image, label\r\n\r\n        from tensorflow.keras.datasets.cifar100 import load_data\r\n        (train_images, train_labels), (test_images, test_labels) = load_data()\r\n\r\n        test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\r\n        test_ds = test_ds.map(inference, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        test_ds = test_ds.batch(args.batch_size)\r\n        test_ds = test_ds.with_options(options)\r\n        test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n        model = ResNet.Model(num_layers = 56, num_class = 100, name = 'ResNet', trainable = True)\r\n\r\n        train_step, train_loss, train_accuracy, optimizer = op_utils.Optimizer(args, model, strategy)\r\n\r\n        for step, data in enumerate(test_ds):\r\n            train_step(*data)\r\n            print('check')\r\n```", "@sseung0703,\r\nI was able to run the code without any issues on TF v2.4 and CUDA 11/cuDNN 8. Please check the below screenshot for reference. \r\n![image](https://user-images.githubusercontent.com/57165142/103370963-3fee7580-4af4-11eb-8f4e-677b138bd360.png)\r\n\r\n\r\nCould you please create a new virtual environment and check if you are facing the same error in that as well? Thanks!", "@amahendrakar \r\nDid you check the above code on multi-GPU?", "@sseung0703,\r\nYes, I ran the code on a machine with two Tesla V100s. Thanks!", "@amahendrakar\r\nIn the above code did you set the argument to use multi-GPU like \"--gpu_id 0 1\" ?", "@sseung0703,\r\nThank you for the update. I had initially run the code without any arguments (i.e. with the default arguments). \r\n\r\nOn running the code with `--gpu_id 0 1`. I was able to reproduce the issue.\r\n![Screenshot 2021-01-06 at 7 28 37 PM](https://user-images.githubusercontent.com/57165142/103778391-30bd7980-5058-11eb-99d1-51bc804037b4.png)\r\n", "@amahendrakar \r\nYes, that is the same error as mine.\r\nI think when the graph is compiled by XLA, parameters are not shareable.\r\nHow can I solve this?", "Hi @sseung0703, to clarify, your code runs with `MirroredStrategy` if `experimental_compile` is not true. Is that correct?", "@nikitamaia yes, without compiling my code works well. You can handle that parameter by argument \u201c\u2014compile\u201d.", "I believe using custom training loops with tf.distribute.Strategy and XLA is not a supported feature. The error message indicates the code generates a computation graph that contains ops from multiple devices, and such computation graph is not compatible with XLA (within a XLA cluster, there must be only one device).", "Hi @ckkuang, then is there any other option to use XLA on multi-gpu?", "You can try [auto-clustering](https://www.tensorflow.org/xla#auto-clustering) (although it seems to be an experimental feature). Don't forget to remove  the `experimental_compile` knob from your tf.function.", "@ckkuang I have tried auto-clustering, but there is no performance improvement. Does it mean there is no compilable operation in my code due to sharable parameters?", "@sseung0703 Your example does not show the whole code, since the part actually applying `experimental_compile=True` is not in your example.\r\n\r\n@nnigania is currently working on supporting collective ops under XLA:GPU compilation, so I think the best bet is to wait for this work to land.\r\n\r\nAlternatively, you would have to compile the part of your model which is not using any collectives (as we did for MLPerf).", "Hi @cheshire, you can find the whole code in my first question, which contains experimental_compile.\r\nAnyway, I'm glad to hear that someone is taking care of this issue. :)\r\nI will wait for the next version.", "'jit_compile' is the new alias for 'experimental_compile'\r\n\r\nCurrent suggestion is to \"jit_compile\" only parts of training which are running independently on each replica(GPU). Any time any communication/synchronization is needed then jit_compile around that will fail. So a 'jit_compile' around entire strategy.run will fail, and a 'jit_compile' around the function containing 'optimizer.apply_gradients' will fail. Also any 'jit_compile' around functions which update metrics will fail. But 'jit_compile' around the function doing the main training should work.\r\n\r\nWe are looking to lower the all_reduce and resolved some of these issues. Soon folks can enable 'jit_compile' on the entire training step (ideally like the way the user has done in this case).\r\n\r\nTo fix their current code, user needs to change the train_step code in <their github>/main/op_utils.py from:\r\n\r\n```\r\n    @tf.function(experimental_compile = args.compile)\r\n    def train_step(images, labels):\r\n        with tf.GradientTape() as tape:\r\n            pred = model(images, training = True)\r\n            total_loss = loss_object(labels, pred)/args.batch_size\r\n        gradients = tape.gradient(total_loss, model.trainable_variables)\r\n        if args.weight_decay > 0.:\r\n            gradients = [g+v*args.weight_decay for g,v in zip(gradients, model.trainable_variables)]\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n        train_loss.update_state(total_loss)\r\n        train_accuracy.update_state(labels, pred)\r\n   \r\n    @tf.function(experimental_compile = args.compile)\r\n    def train_step_dist(image, labels):\r\n        strategy.run(train_step, args= (image, labels))\r\n```\r\n\r\n\r\nCode needs to changed to:\r\n\r\n```\r\n    @tf.function(jit_compile = True)\r\n    def compiled_step(images, labels):\r\n        with tf.GradientTape() as tape:\r\n            pred = model(images, training = True)\r\n            total_loss = loss_object(labels, pred)/args.batch_size\r\n        gradients = tape.gradient(total_loss, model.trainable_variables)\r\n        return total_loss, pred, gradients\r\n\r\n    def train_step(images, labels):\r\n        total_loss, pred, gradients = compiled_step(images, labels)\r\n        if args.weight_decay > 0.:\r\n            gradients = [g+v*args.weight_decay for g,v in zip(gradients, model.trainable_variables)]\r\n\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n        train_loss.update_state(total_loss)\r\n        train_accuracy.update_state(labels, pred)\r\n   \r\n    @tf.function()\r\n    def train_step_dist(image, labels):\r\n        strategy.run(train_step, args= (image, labels))\r\n```\r\nPlease let me know if you still hit issues, and we will be happy to resolve them.", "Thank you for your advice @nnigania. :) \r\nI upgraded my Tensorflow version to 2.5 due to jit_compile is not available on 2.4, and had to fix more codes to remove all the update operations in the compiled_step.\r\nAnd after this work, my code works well with jit_compiling on multi-GPU, which gives 3 times faster iteration operation!!\r\n\r\nThank you very much again, and this issue is resolved :).\r\n\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45940\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45940\">No</a>\n", "@geetachavan1 @nnigania Which commit fixed this issue in TF 2.5?", "@caandewiel \r\nAs I said above, it is impossible to update mirrored variables in the jit compiled graph.\r\nSo I had to remove all the update operations in jit compiled code and then update each variable outside.\r\nYou can find my work [here.](https://github.com/sseung0703/EKG/blob/feb7c3ccb1244aea3f42663c2f426a692dd6e65a/op_utils.py#L41-L87)", "Ah excuse me, I misinterpreted your comment. I thought you meant this was fixed in 2.5. I'll take a look at your work, thanks :)", "For runs on single-host (single or multi-GPU using mirrored-strategy) we now support XLA around optimizer.apply_gradients . So now for even better performance we can do:\r\n\r\n```\r\n    @tf.function(jit_compile=True)\r\n    def train_step(*data):\r\n        # no need for xla around compiled_step \r\n        total_loss, gradients, update_vars = compiled_step(*data)\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n```\r\n+@cheshire ", "@nnigania That\u2019s great news! I was wondering what commit is responsible for achieving this behavior as I\u2019m currently using an alternative backend and would like to replicate this behavior.", "TF2.7 we added this support to enable XLA around entire training step for models using mirrored strategy. Only gotchas were tf.summary statements and tf metrics which do reductions as XLA is still working to add support for them.\r\n\r\nAlso in the most recent TF2.8 release, support was added to enable XLA for model using the Keras compile/fit API as well which leads to significant performance benefits. See TF2.8 release notes for details.\r\n\r\nModels in the TF official models can also enable XLA by passing it via a flag. This flag enables XLA for a model using the base trainer [here](https://github.com/tensorflow/models/blob/36d6f41f7584546100a002ad780a768dfc4569cf/official/core/base_trainer.py#L402).", "@nnigania I was outdated so far. Now, I can remove a bunch of pseudo distributed things and make my code much clear!\r\nThank you for informing us \ud83d\ude1a", "@nnigania can you elaborate on the gotchas for `tf.metrics`? We are using a MirroredStrategy for multi-GPU training and aggregate the metrics in our `train_step`. Will XLA/`jit_compile` not work for us yet? And does XLA work for multi-TPU training as well? ", "sure, for metrics, you can make calls to update() inside XLA scope, but calls to metrics init() and result() need some support from TF team.\r\n\r\nFrom TPU perspective, XLA is always on (and required) by default for TPU runs, and does not have the issues discussed in this thread."]}, {"number": 45939, "title": "Support OpenCL 1.1 properly by forcing buffer usage in kernels that don't check .SupportsImageBuffer()", "body": "On an OpenCL device (AMD G-series SOC with Mesa drivers) with 1.1 support we can meaningfully run the opencl gpu delegate. However given the lack of Image support some kernels need to force buffer usage instead which isn't always done.", "comments": []}, {"number": 45938, "title": "TensorFlow 1.5 API : Error : 'DatasetV1Adapter' object does not support indexing", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4\r\n- TensorFlow installed from : Binary (from docker image)\r\n- TensorFlow version : 1.15\r\n- Python version: 2.7.17\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nError emitted by TensorFlow API:\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n\r\n**Describe the expected behavior**\r\nNo error\r\n\r\n**Standalone code to reproduce the issue**\r\nimages, labels = read_list ( data_dir, data_list ) <= here data_dir is full path of dir. containing image & label files. data_list is a text file, 2 column containing names of image file and label file.\r\nThe output is an array consisting of full path of images & corresponding labels.\r\n\r\nqueue = tf.data.Dataset.from_tensor_slices([images, labels])\r\nimg_contents = tf.io.read_file(queue[0]) <= Error location\r\nlabel_contents = tf.io.read_file(queue[1])\r\n\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nHere is the traceback of the real code - \r\n\r\nTraceback (most recent call last):\r\n  File \"wasr_train_noimu.py\", line 462, in <module>\r\n    main()\r\n  File \"wasr_train_noimu.py\", line 315, in main\r\n    coord)\r\n  File \"/wasr/wasr_models/image_reader.py\", line 249, in __init__\r\n    self.image, self.label, self.imu = read_images_from_disk(self.queue, self.input_size, random_scale, random_mirror, ignore_label, img_mean)\r\n  File \"/wasr/wasr_models/image_reader.py\", line 180, in read_images_from_disk\r\n    img_contents = tf.io.read_file(input_queue[0])\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n\r\nThe code in 'Standalone code' section is a gist of the actual code. \r\n\r\nI have looked at various posts including [this](https://github.com/tensorflow/tensorflow/issues/28995) one where it is mentioned that the issue is fixed in version 1.5 but I am still encountering it. I have also gone through the TensorFlow 1.5 documentation but could not understand why I am seeing this issue or what is the correct way to use the API if my code is not correct.\r\nAny help will be highly appreciated.\r\nThanks,\r\n-Shailesh\r\n", "comments": ["@ssnirgudkar \r\n\r\nCan you please share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "Here you go -\r\nimport tensorflow as tf\r\nimageList=[]\r\nimageList.append(\"a.png\")\r\nimageList.append(\"b.png\")\r\nimageT=tf.convert_to_tensor(imageList, dtype=tf.string)\r\nqueue = tf.data.Dataset.from_tensor_slices(imageT)\r\nimg_contents = tf.io.read_file(queue[0])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n\r\nI may be making some silly mistake but I do not what!", "@ssnirgudkar \r\n\r\nCan you please upgrade to latest stable TF version 2.4 , nightly version and see if the issue still persists. Thanks!", "I cannot easily upgrade to TF 2.4 because there are other dependencies which have to be managed as well (inside our environment). It will take me number of days to do so with significant efforts.\r\nI will appreciate if you can acknowledge that this is a bug & it exists in TF 1.5 & can be fixed in 1.5.", "Also with the steps which I have provided you should be able to verify if the code works in TF 2.4 or not.", "We only patch old releases for security issues. 1.15 is too old and we cannot build it effectively if we are to patch other issues (since then they can cause further damage, so we'd need to test 100% of the test suite but this is impossible at the moment)", "@mihaimaruseac  Thank you for your response. Could you please kindly look at the conflicting doc string in the same issue here https://github.com/tensorflow/tensorflow/issues/28995", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45938\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45938\">No</a>\n"]}, {"number": 45937, "title": "Name argument ignored in operations", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Google Colab\r\n- TensorFlow version (use command below): v2.4.0-0-g582c8d236cb, 2.4.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen I try to create a named operation is just ignored and the default value is generated. \r\n`\r\nx = tf.keras.Input(shape=4, name=\"X\", dtype=\"float32\")\r\ny = tf.keras.Input(shape=4, name=\"Y\", dtype=\"float32\")\r\nex = tf.math.exp(x, name=\"exponential_X\")\r\nlx = tf.math.log(x, name=\"log_X\")\r\nxy = tf.multiply(x, y, name=\"XY\")\r\nnx = tf.norm(x, name=\"norm_X\")\r\nrmx =  tf.reduce_mean(x, name=\"reduce_mean_X\")\r\nprint(x.name)\r\nprint(ex.name)\r\nprint(lx.name)\r\nprint(xy.name)\r\nprint(nx.name)\r\nprint(rmx.name)\r\n\r\nz = tf.Variable(1.0, name=\"Z\")\r\nez = tf.math.exp(x, name=\"exponential_Z\")\r\nprint(ez.name)\r\n`\r\nX\r\ntf.math.exp_11/Exp:0\r\ntf.math.log_6/Log:0\r\ntf.math.multiply_5/Mul:0\r\ntf.compat.v1.norm_3/norm/Squeeze:0\r\ntf.math.reduce_mean_2/Mean:0\r\ntf.math.exp_12/Exp:0\r\n\r\n**Describe the expected behavior**\r\nOutput should be the names defined on the operation.\r\n\r\n**Standalone code to reproduce the issue**\r\n[Above example in Google Colab.](https://colab.research.google.com/drive/1Yc8pQoXK1MiGIPEGH-Ls9TKHpUMsrVqz)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@servandoa,\r\nLooks like this is simliar to issue #45401, #43844 and #43840.\r\n\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/45401#issuecomment-738957954) from a member of the TensorFlow team for more information. Thanks!", "Many thanks,\r\nApologies, I search for it as an open issue.\r\nRegards,", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45937\">No</a>\n"]}, {"number": 45935, "title": "saved_model.save write .pb with read only permissions that can't be removed even with admin permissions", "body": "### System information\r\n\r\n* OS: Windows 10\r\n* ONNX 1.8.0\r\n* ONNX_TF 1.7.0\r\n* TENSORFLOW 2.4.0\r\n* Desktop\r\n* Python 3.7.3\r\n* CUDA 460.89\r\n* running from anaconda3:\r\n_anaconda_depends         2019.03                  py37_0\r\nanaconda                          custom                   py37_1\r\nanaconda-client                1.7.2                       py37_0\r\nanaconda-navigator         1.9.7                        py37_0\r\nanaconda-project              0.8.3                       py_0\r\n\r\nI'm trying to convert onnx model to tensorflow and create pb file.\r\nThe conversion is successful, but the save .pb directory has \"read only\" attribute that can't be removed even when I'm running as admin (after removing it returns back)...\r\n\r\nCODE:\r\n\r\n`    onnx_model = onnx.load(onnx_model_path)\r\n    \r\n    tf_rep = prepare(onnx_model)\r\n    \r\n    tensorflow.saved_model.save(\r\n        tf_rep.tf_module,\r\n        tensorflow_model_path)\r\n`\r\n\r\nHow it looks like:\r\n![image](https://user-images.githubusercontent.com/2767433/102983532-e5ae4d00-4514-11eb-9ca7-6e2ed910772e.png)\r\n\r\nNOTE: I also used a built in function \" export_graph\" - same issue\r\n\r\n", "comments": ["@MaxxTr,\r\nThis seems like an issue with Windows rather than a TensorFlow issue. Could you please get in touch with Microsoft Windows regarding this. Thanks!", "@amahendrakar For me it looks like pure tensorflow issue, as simple python write file at this case works fine, so when tensorflow save your data tensorflow somehow changes the permissions", "@MaxxTr,\r\nCould you please provide a minimal code snippet of the issue you are facing, so that we reproduce it on our end and look into it. Thanks!", "Hi @amahendrakar  please pay attention that the code snippet was provided:\r\n\r\n`\r\n onnx_model = onnx.load(onnx_model_path)\r\n\r\ntf_rep = prepare(onnx_model)\r\n\r\ntensorflow.saved_model.save(\r\n    tf_rep.tf_module,\r\n    tensorflow_model_path)\r\n`", "@MaxxTr,\r\nThe given code snippet is incomplete. On running the code, I am facing an error stating `NameError: name 'onnx_model_path' is not defined`.\r\n\r\nIn order to reproduce the issue reported here, please provide Python script/notebook you are running along with all the files required to run the code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@amahendrakar  it's kind of obvious that this path is undefined... this is the path to the model. Do you have one ? ( I assume you should as you are support person and work with all that stuff day to day)", "@MaxxTr,\r\nOn running the code with a sample model, I see that `.pb` has both read and write permissions. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/37bb6f83164e685da27e1cb0452c594d/45935.ipynb#scrollTo=hXvXTn6CkdBf&line=1&uniqifier=1). Thanks!", "Good day @amahendrakar.\r\nLooks like you tested that on linux, but not on windows. Am I right ?", "@MaxxTr,\r\nYes, that's right. I have tested the code on a Linux machine. Thanks!", "@amahendrakar , yes but the problem is reported on windows. So isn't it wrong to test it on linux and say that everything is ok ?", "Hi @MaxxTr ! \r\nI downloaded  the onnx file from Github and ran the above code in my local windows machine in the 2.8 version . It was not in read only mode by default. Attaching screenshots for proof. [dir_model](https://user-images.githubusercontent.com/86464649/157797772-e1f413f0-e8f8-4c41-a428-fabdcb5283f9.png), [saved_model](https://user-images.githubusercontent.com/86464649/157797723-042a7362-fb11-4d26-9c57-43f7dd58ace7.png). Can you let us know from your side too?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45935\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45935\">No</a>\n"]}, {"number": 45934, "title": "[Intel MKL] CNMS performance optimization by using priority queue", "body": "Replace vector with priority queue to improve the performance in CNMS kernel", "comments": ["Below is the benchmark comparison between baseline and baseline with this PR.\r\nBenchmark | Time(ns) per iteration     Baseline | Time(ns) per iteration     PR | Baseline/PR Ratio\r\n-- | -- | -- | --\r\nBM_CombinedNMS_cpu_1_500_25_1 | 3454 | 3661 | 0.943458072\r\nBM_CombinedNMS_cpu_28_500_25_1 | 51500 | 52549 | 0.980037679\r\nBM_CombinedNMS_cpu_32_500_25_1 | 55597 | 57057 | 0.974411553\r\nBM_CombinedNMS_cpu_64_500_25_1 | 82095 | 84250 | 0.974421365\r\nBM_CombinedNMS_cpu_1_1000_25_1 | 3059 | 3029 | 1.009904259\r\nBM_CombinedNMS_cpu_28_1000_25_1 | 54182 | 54159 | 1.000424675\r\nBM_CombinedNMS_cpu_32_1000_25_1 | 60447 | 59889 | 1.009317237\r\nBM_CombinedNMS_cpu_64_1000_25_1 | 90236 | 89500 | 1.008223464\r\nBM_CombinedNMS_cpu_1_1917_25_1 | 3593 | 3377 | 1.063962097\r\nBM_CombinedNMS_cpu_28_1917_25_1 | 62043 | 57952 | 1.070592904\r\nBM_CombinedNMS_cpu_32_1917_25_1 | 69649 | 64234 | 1.084301149\r\nBM_CombinedNMS_cpu_64_1917_25_1 | 110165 | 100424 | 1.096998725\r\nBM_CombinedNMS_cpu_1_2500_25_1 | 3908 | 3404 | 1.148061105\r\nBM_CombinedNMS_cpu_28_2500_25_1 | 69272 | 62534 | 1.107749384\r\nBM_CombinedNMS_cpu_32_2500_25_1 | 75578 | 66765 | 1.1320003\r\nBM_CombinedNMS_cpu_64_2500_25_1 | 122426 | 107127 | 1.142811803\r\nBM_CombinedNMS_cpu_1_500_25_25 | 2965 | 3001 | 0.988003999\r\nBM_CombinedNMS_cpu_28_500_25_25 | 50016 | 51001 | 0.980686653\r\nBM_CombinedNMS_cpu_32_500_25_25 | 54472 | 55636 | 0.979078295\r\nBM_CombinedNMS_cpu_64_500_25_25 | 82680 | 84588 | 0.977443609\r\nBM_CombinedNMS_cpu_1_1000_25_25 | 3219 | 3122 | 1.031069827\r\nBM_CombinedNMS_cpu_28_1000_25_25 | 55428 | 55251 | 1.003203562\r\nBM_CombinedNMS_cpu_32_1000_25_25 | 61423 | 60425 | 1.016516343\r\nBM_CombinedNMS_cpu_64_1000_25_25 | 98121 | 96076 | 1.021285233\r\nBM_CombinedNMS_cpu_1_1917_25_25 | 3716 | 3239 | 1.147267675\r\nBM_CombinedNMS_cpu_28_1917_25_25 | 65656 | 60912 | 1.077882847\r\nBM_CombinedNMS_cpu_32_1917_25_25 | 74634 | 70001 | 1.066184769\r\nBM_CombinedNMS_cpu_64_1917_25_25 | 125768 | 115796 | 1.086116964\r\nBM_CombinedNMS_cpu_1_2500_25_25 | 3908 | 3575 | 1.093146853\r\nBM_CombinedNMS_cpu_28_2500_25_25 | 74623 | 67591 | 1.10403752\r\nBM_CombinedNMS_cpu_32_2500_25_25 | 83959 | 75973 | 1.105116291\r\nBM_CombinedNMS_cpu_64_2500_25_25 | 144104 | 128128 | 1.124687812\r\nBM_CombinedNMS_cpu_1_500_90_1 | 6511 | 6538 | 0.995870297\r\nBM_CombinedNMS_cpu_28_500_90_1 | 129866 | 132216 | 0.982226054\r\nBM_CombinedNMS_cpu_32_500_90_1 | 141676 | 146484 | 0.967177303\r\nBM_CombinedNMS_cpu_64_500_90_1 | 238119 | 248641 | 0.957681959\r\nBM_CombinedNMS_cpu_1_1000_90_1 | 7347 | 7065 | 1.039915074\r\nBM_CombinedNMS_cpu_28_1000_90_1 | 145292 | 142354 | 1.020638689\r\nBM_CombinedNMS_cpu_32_1000_90_1 | 158022 | 156830 | 1.007600587\r\nBM_CombinedNMS_cpu_64_1000_90_1 | 270193 | 266259 | 1.014775087\r\nBM_CombinedNMS_cpu_1_1917_90_1 | 8450 | 7920 | 1.066919192\r\nBM_CombinedNMS_cpu_28_1917_90_1 | 173900 | 160502 | 1.083475595\r\nBM_CombinedNMS_cpu_32_1917_90_1 | 196951 | 173393 | 1.13586477\r\nBM_CombinedNMS_cpu_64_1917_90_1 | 340503 | 307652 | 1.106779738\r\nBM_CombinedNMS_cpu_1_2500_90_1 | 9129 | 8477 | 1.076914003\r\nBM_CombinedNMS_cpu_28_2500_90_1 | 191715 | 169376 | 1.131889996\r\nBM_CombinedNMS_cpu_32_2500_90_1 | 214517 | 187388 | 1.144774479\r\nBM_CombinedNMS_cpu_64_2500_90_1 | 382273 | 331639 | 1.152678063\r\nBM_CombinedNMS_cpu_1_500_90_90 | 6483 | 6478 | 1.000771843\r\nBM_CombinedNMS_cpu_28_500_90_90 | 133296 | 135703 | 0.982262736\r\nBM_CombinedNMS_cpu_32_500_90_90 | 144556 | 151654 | 0.953196091\r\nBM_CombinedNMS_cpu_64_500_90_90 | 252979 | 255974 | 0.988299593\r\nBM_CombinedNMS_cpu_1_1000_90_90 | 7341 | 7220 | 1.016759003\r\nBM_CombinedNMS_cpu_28_1000_90_90 | 154367 | 151577 | 1.018406486\r\nBM_CombinedNMS_cpu_32_1000_90_90 | 173259 | 167141 | 1.036603826\r\nBM_CombinedNMS_cpu_64_1000_90_90 | 300782 | 293236 | 1.025733539\r\nBM_CombinedNMS_cpu_1_1917_90_90 | 8563 | 8060 | 1.062406948\r\nBM_CombinedNMS_cpu_28_1917_90_90 | 196507 | 179871 | 1.092488506\r\nBM_CombinedNMS_cpu_32_1917_90_90 | 222948 | 203074 | 1.097865803\r\nBM_CombinedNMS_cpu_64_1917_90_90 | 397955 | 364657 | 1.091313207\r\nBM_CombinedNMS_cpu_1_2500_90_90 | 9368 | 8621 | 1.086648881\r\nBM_CombinedNMS_cpu_28_2500_90_90 | 229845 | 202881 | 1.132905496\r\nBM_CombinedNMS_cpu_32_2500_90_90 | 251444 | 226392 | 1.11065762\r\nBM_CombinedNMS_cpu_64_2500_90_90 | 456374 | 403514 | 1.130999172\r\nBM_CombinedNMS_cpu_1_500_200_1 | 12767 | 13203 | 0.966977202\r\nBM_CombinedNMS_cpu_28_500_200_1 | 225725 | 234416 | 0.962924886\r\nBM_CombinedNMS_cpu_32_500_200_1 | 252504 | 264165 | 0.955857135\r\nBM_CombinedNMS_cpu_64_500_200_1 | 451719 | 469485 | 0.962158535\r\nBM_CombinedNMS_cpu_1_1000_200_1 | 14195 | 13936 | 1.01858496\r\nBM_CombinedNMS_cpu_28_1000_200_1 | 258482 | 253823 | 1.018355311\r\nBM_CombinedNMS_cpu_32_1000_200_1 | 291218 | 285598 | 1.019678009\r\nBM_CombinedNMS_cpu_64_1000_200_1 | 523317 | 517501 | 1.011238626\r\nBM_CombinedNMS_cpu_1_1917_200_1 | 16427 | 14862 | 1.105302113\r\nBM_CombinedNMS_cpu_28_1917_200_1 | 326365 | 292076 | 1.117397527\r\nBM_CombinedNMS_cpu_32_1917_200_1 | 366054 | 330116 | 1.108864763\r\nBM_CombinedNMS_cpu_64_1917_200_1 | 677261 | 602361 | 1.12434404\r\nBM_CombinedNMS_cpu_1_2500_200_1 | 18088 | 15840 | 1.141919192\r\nBM_CombinedNMS_cpu_28_2500_200_1 | 364184 | 315420 | 1.154600216\r\nBM_CombinedNMS_cpu_32_2500_200_1 | 415267 | 354909 | 1.17006613\r\nBM_CombinedNMS_cpu_64_2500_200_1 | 777997 | 656129 | 1.185737866\r\nBM_CombinedNMS_cpu_1_500_200_200 | 13066 | 13079 | 0.99900604\r\nBM_CombinedNMS_cpu_28_500_200_200 | 237618 | 241347 | 0.984549218\r\nBM_CombinedNMS_cpu_32_500_200_200 | 264774 | 268368 | 0.986607941\r\nBM_CombinedNMS_cpu_64_500_200_200 | 472916 | 486986 | 0.971107999\r\nBM_CombinedNMS_cpu_1_1000_200_200 | 14559 | 14003 | 1.039705777\r\nBM_CombinedNMS_cpu_28_1000_200_200 | 276220 | 274795 | 1.005185684\r\nBM_CombinedNMS_cpu_32_1000_200_200 | 316452 | 309632 | 1.022026147\r\nBM_CombinedNMS_cpu_64_1000_200_200 | 579009 | 568403 | 1.018659296\r\nBM_CombinedNMS_cpu_1_1917_200_200 | 17198 | 15559 | 1.10534096\r\nBM_CombinedNMS_cpu_28_1917_200_200 | 371166 | 335064 | 1.10774658\r\nBM_CombinedNMS_cpu_32_1917_200_200 | 417406 | 373736 | 1.116847186\r\nBM_CombinedNMS_cpu_64_1917_200_200 | 791732 | 714316 | 1.108377805\r\nBM_CombinedNMS_cpu_1_2500_200_200 | 19240 | 16614 | 1.158059468\r\nBM_CombinedNMS_cpu_28_2500_200_200 | 437781 | 384334 | 1.139063939\r\nBM_CombinedNMS_cpu_32_2500_200_200 | 488780 | 424662 | 1.150985961\r\nBM_CombinedNMS_cpu_64_2500_200_200 | 933122 | 807729 | 1.155241424\r\n\r\n"]}, {"number": 45933, "title": "Fill only currently supports int32, int64, float32, bool, string for input 1, got 9.Node number 5 (FILL) failed to invoke.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.5.0-dev20201222\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI have been able to successfully convert the [Boundless model](https://arxiv.org/pdf/1908.07007.pdf) with full integer quantization but it fails during inference. I have made sure to scale the inputs w.r.t. quantization i.e. the following - \r\n\r\n```python\r\nif quantization==\"integer\":\r\n    input_img = preprocess_image(\"test_image.jpg\")\r\n    input_scale, input_zero_point = input_details[0][\"quantization\"]\r\n    input_img = input_img / input_scale + input_zero_point\r\n    input_img = input_img.astype(input_details[0][\"dtype\"])\r\n```\r\n\r\nI am running into - \r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-35-1e81bd6daa76> in <module>()\r\n      2 interpreter.set_tensor(input_details[0]['index'], input_img)\r\n      3 start = time.time()\r\n----> 4 interpreter.invoke()\r\n      5 print(f\"Inference took: {time.time()-start} seconds\")\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in invoke(self)\r\n    758     \"\"\"\r\n    759     self._ensure_safe()\r\n--> 760     self._interpreter.Invoke()\r\n    761 \r\n    762   def reset_all_variables(self):\r\n\r\nRuntimeError: Fill only currently supports int32, int64, float32, bool, string for input 1, got 9.Node number 5 (FILL) failed to invoke.\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nCurrently, it's not clear to me why it is failing. Essentially, I would expect it to work. \r\n\r\n**Standalone code to reproduce the issue**\r\nColab Notebook: https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Boundless_TFLite.ipynb.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Currently, TFLite Fill op does not support INT8 inputs. However, it looks like the quantization tool added a Fill op node for INT8 inputs. @daverim @teijeong could you take a look?", "Hey folks.\r\n\r\nAny updates on this? ", "Should it be fixed in runtime side?", "A fix is landed in the master branch.\r\nPlease feel free to reopen if you still have this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45933\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45933\">No</a>\n", "@thaink should I test the fix with nightly? ", "@sayakpaul I believe it is included in the latest nightly.", "Just tested with `2.5.0-dev20210112` and the issue still persists. Will look again tomorrow. Anything else I should note? ", "No. Please let me know the result tomorrow."]}, {"number": 45932, "title": "Float model size is lesser than dynamic-range model size", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.5.0-dev20201222\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am converting the [Boundless model](https://arxiv.org/pdf/1908.07007.pdf) to TensorFlow Lite. While the model conversion is successful and the inference works as expected there's an inconsistency in the model sizes. Currently, the dynamic-range quantized model size is ~14 MB whereas the float16 quantized model size is ~7MB. \r\n\r\n**Describe the expected behavior**\r\n\r\nFloat16 model size should be higher, technically twice the size of the dynamic-range quantized model. \r\n\r\n**Standalone code to reproduce the issue**\r\nColab Notebook - https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Boundless_TFLite.ipynb. \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/017181b3d5102244f8d9abeaa4cf734e/45932-2-5.ipynb#scrollTo=MrtANUkQser-). Thanks!", "Hi @sayakpaul\r\n\r\nFrom looking at your model it appears that it is implemented as all tensorflow ops (`tf.lite.OpsSet.SELECT_TF_OP`). While float16 quantization is supported when using Tensorflow ops by dequantizing constant tensors at runtime, dynamic range quantization is not supported when using Tensorflow ops, so your dynamic range model is identical to the float model.\r\n\r\nI am adding an internal bug for dynamic range to work similar to the float16 in the flex case. In the meantime, this is expected behavior when a model only uses Tensorflow ops.\r\n\r\n\r\n\r\n", "Useful to know this @daverim. I guess this point is worth reflecting on in the Flex ops documentation. WDYT @daverim? ", "Hi @sayakpaul,\r\n\r\nIn the code, it seems you also have to provide `tf.lite.OpsSet.TFLITE_BUILTINS` to `supported_ops`. \r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select#convert_a_model\r\n", "@teijeong so it should be the following, right?\r\n\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_function])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, \r\n    tf.lite.OpsSet.TFLITE_BUILTINS]\r\n```\r\n\r\nUpdate: Just tried. It worked. Thanks. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45932\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45932\">No</a>\n", "Great! :)"]}, {"number": 45931, "title": "Graidents for weights in tf.keras.layers.GRUCell not being computed when using tf.estamtor", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Official docker image (tensorflow/tensorflow:2.4.0-gpu)\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb\r\n- Python version: 3.6, as is in the official image\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: as is in the official image\r\n- GPU model and memory: NVIDIA GTX1050\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nThe weights in GRUCell are not computed when using tf.estimator, `tape.gradient(loss_val, nn.trainable_variables)` returns `None` for weights in `GRUCell`\r\n**Describe the expected behavior**\r\nComputation of gradients with respect to weights in `GRUCell` should be working as in \"keras mode\", please look into the following code for details.\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Please clear `./test_output/` before re-running the code to replicated the issue.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport functools\r\nfrom typing import Optional\r\n\r\n\r\nclass TokenWeightingLayer(tf.keras.layers.Layer):\r\n    def __init__(self, mask_constant=-50000, **kwargs):\r\n        super(TokenWeightingLayer, self).__init__(**kwargs)\r\n        self.fc = tf.keras.layers.Dense(1)\r\n        self.softmax = tf.keras.layers.Softmax(axis=-1)\r\n        self._mask_constant = mask_constant\r\n\r\n    def call(self, inputs, mask, **kwargs):\r\n        activation = tf.squeeze(self.fc(tf.tanh(inputs)), axis=-1)\r\n        masked_activation = tf.where(mask, activation,\r\n                                     (tf.ones_like(activation) * self._mask_constant))  # TODO: fix dtype\r\n        alpha = self.softmax(masked_activation)\r\n        return alpha\r\n\r\n\r\nclass RNN_Attention_Clf(tf.keras.Model):\r\n    def __init__(self,\r\n                 word_embedding_dim: int,\r\n                 pos1_embedding_dim: int,\r\n                 pos2_embedding_dim: int,\r\n                 vocab_size: int,\r\n                 pos_embedding_num: int,\r\n                 rnn_dim: int,\r\n                 dropout_rate: float = 0.,\r\n                 pre_trained_word_embedding: np.ndarray = None,\r\n                 fine_tune_word_embedding: bool = False,\r\n                 variational_recurrent: bool = False,\r\n                 num_cls: Optional[int] = None,\r\n                 **kwargs):\r\n        super(RNN_Attention_Clf, self).__init__()\r\n        self._word_embedding_dim = word_embedding_dim\r\n        self._entity_1_embedding_dim = pos1_embedding_dim\r\n        self._entity_2_embedding_dim = pos2_embedding_dim\r\n        self.cell_type = tf.keras.layers.GRUCell\r\n        self._vocab_size = vocab_size  # int, without unk and pad\r\n        self._pos_embedding_num = pos_embedding_num\r\n        self._pre_trained_word_embedding = pre_trained_word_embedding  # numpy.ndarray object\r\n        self._fine_tune_word_embedding = (self._pre_trained_word_embedding is None) or kwargs.get(\r\n            \"fine_tune_word_embedding\", False)\r\n        self._variational_recurrent = variational_recurrent\r\n        self._rnn_dim = rnn_dim  # int\r\n        self._num_cls = num_cls\r\n        self._dropout_rate = dropout_rate\r\n        if pre_trained_word_embedding is None:\r\n            self.token_embedding = tf.keras.layers.Embedding(self._vocab_size, self._word_embedding_dim, mask_zero=True)\r\n        else:\r\n            raise NotImplementedError(\"WIP\")\r\n        self._pos_embedding_1 = tf.keras.layers.Embedding(self._pos_embedding_num, self._word_embedding_dim,\r\n                                                          mask_zero=True)\r\n        self._pos_embedding_2 = self._pos_embedding_1\r\n        cell = tf.keras.layers.GRUCell(rnn_dim)\r\n        rnn_layer = tf.keras.layers.RNN(cell, return_sequences=True, return_state=True)\r\n        self.rnn_encoder = tf.keras.layers.Bidirectional(rnn_layer, merge_mode=\"sum\")\r\n        self.token_weighting_layer = TokenWeightingLayer()\r\n        self.fc_layer = tf.keras.layers.Dense(num_cls, use_bias=True)\r\n\r\n    def call(self, token_ids, pos_ids_1, pos_ids_2, sequence_length, training=None, mask=None):\r\n        token_embedding = self.token_embedding(token_ids)\r\n        # token_dropout\r\n        pos_embedding_1 = self._pos_embedding_1(pos_ids_1)\r\n        pos_embedding_2 = self._pos_embedding_2(pos_ids_2)\r\n        encoded_input = tf.concat([token_embedding, pos_embedding_1, pos_embedding_2], axis=-1, )\r\n        # Compute mask\r\n        mask = tf.sequence_mask(sequence_length, maxlen=token_ids.get_shape()[1])\r\n        # BiRNN\r\n        encoder_outputs, last_state_fw, last_state_bw = self.rnn_encoder(encoded_input, mask=mask)\r\n\r\n        # The original authors of this network call this \"attention\", well...\r\n        alpha = self.token_weighting_layer(encoder_outputs, mask)\r\n        weighted_outputs = tf.squeeze(tf.matmul(tf.expand_dims(alpha, axis=1), encoder_outputs), axis=1)\r\n        out = self.fc_layer(weighted_outputs)\r\n        return out, alpha\r\n\r\n    def model_fn(self, features, labels, mode, params):\r\n        # dropout_rate = params[\"dropout_rate\"]\r\n        if labels is not None:\r\n            sparse_label_ids = labels\r\n        # TODO: Set configure RNN dropout for RNN input, state, output\r\n        input_text, inputs, pos1_inputs, pos2_inputs, sequence_length = features\r\n        training = (mode == tf.estimator.ModeKeys.TRAIN)\r\n        if not training:\r\n            self.trainable = False  # Do I have to?\r\n        logits, alpha = self(inputs, pos1_inputs, pos2_inputs, sequence_length)\r\n        print(self.summary())\r\n\r\n        top1_prediction = tf.argmax(logits, axis=-1, name=\"top1_cls\")\r\n\r\n        confidence = tf.nn.softmax(logits, axis=-1, name=\"confidence\")\r\n        top1_confidence = tf.reduce_max(confidence, axis=-1)\r\n        if mode != tf.estimator.ModeKeys.PREDICT:\r\n            def loss_fn():  # For training stage only.\r\n                logits, alpha = self(inputs, pos1_inputs, pos2_inputs, sequence_length,\r\n                                     training=True)  # Apply dropout, batch-normalization etc. when calculating loss.\r\n                loss = tf.keras.losses.sparse_categorical_crossentropy(sparse_label_ids, logits, from_logits=True)\r\n                loss = tf.reduce_mean(loss)\r\n                return loss\r\n\r\n            global_step = tf.compat.v1.train.get_or_create_global_step()\r\n            y_true = tf.one_hot(sparse_label_ids, depth=self._num_cls)\r\n            metrics = {}\r\n            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=sparse_label_ids, y_pred=confidence,\r\n                                                                   from_logits=False)\r\n            loss = tf.reduce_mean(loss)\r\n            acc = tf.metrics.SparseTopKCategoricalAccuracy(k=1)\r\n            acc.update_state(y_true=sparse_label_ids, y_pred=confidence)\r\n            metrics[\"acc\"] = acc\r\n            for cls_id in range(self._num_cls):\r\n                p = tf.metrics.Precision(top_k=1, class_id=cls_id)\r\n                p.update_state(y_true=y_true, y_pred=confidence)\r\n                metrics[\"precision_cls_{}\".format(cls_id)] = p\r\n                r = tf.metrics.Recall(top_k=1, class_id=cls_id)\r\n                r.update_state(y_true=y_true, y_pred=confidence)\r\n                metrics[\"recall_cls_{}\".format(cls_id)] = r\r\n\r\n        if mode == tf.estimator.ModeKeys.PREDICT:\r\n            predictions = {\r\n                \"cls_id\": top1_prediction,\r\n                \"confidence\": confidence,\r\n                \"att_weight\": alpha,\r\n                \"input_text\": input_text\r\n            }\r\n            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n        elif mode == tf.estimator.ModeKeys.TRAIN:\r\n            init_lr = params[\"init_lr\"]\r\n            decay_step = params[\"decay_step\"]\r\n            decay_rate = params[\"decay_rate\"]\r\n            learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(init_lr, decay_steps=decay_step,\r\n                                                                           decay_rate=decay_rate)\r\n\r\n            if params[\"optimizer\"] == 'Adam':\r\n                optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n            elif params[\"optimizer\"] == 'Adadelta':\r\n                optimizer = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\r\n            elif params[\"optimizer\"] == 'Adagrad':\r\n                optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\r\n            elif params[\"optimizer\"] == 'RMSProp':\r\n                optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\r\n            elif params[\"optimizer\"] == 'Momentum':\r\n                optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\r\n            elif params[\"optimizer\"] == 'SGD':\r\n                optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\r\n            else:\r\n                optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\r\n            trainable_variables = self.trainable_variables\r\n            optimizer.iterations = global_step\r\n            tf.summary.scalar(\"learning_rate\", learning_rate(optimizer.iterations), global_step)\r\n            clip_val = params.get(\"clip_value\")\r\n            if clip_val is not None:\r\n                # Tampering gradients manually instead of setting optimizer.clipvalue\r\n                with tf.GradientTape() as tape:\r\n                    loss_val = loss_fn()\r\n                gradients = tape.gradient(loss_val, trainable_variables)\r\n                gradients = [(tf.clip_by_value(grad, -clip_val, clip_val)) if grad is not None else grad for grad in\r\n                             gradients]\r\n                assert len(trainable_variables) == len(gradients)\r\n                for var, grad in zip(trainable_variables, gradients):\r\n                    print(\"****variable:{} Gradient: {}\".format(var, grad))\r\n                train_op = optimizer.apply_gradients(zip(gradients, trainable_variables))\r\n            else:\r\n                train_op = optimizer.minimize(loss_fn, var_list=trainable_variables)\r\n            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, eval_metric_ops=metrics)\r\n        elif mode == tf.estimator.ModeKeys.EVAL:\r\n            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\r\n        else:\r\n            raise ValueError(\"Unknown mode: {}\".format(mode))\r\n\r\n\r\n\r\ndef test_non_estimator_approach():\r\n    nn = RNN_Attention_Clf(word_embedding_dim=64, pos1_embedding_dim=5, pos2_embedding_dim=5, pos_embedding_num=6,\r\n                           vocab_size=100, rnn_dim=20, num_cls=10)\r\n    inputs = tf.constant([[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]])\r\n    pos_1 = tf.constant([[1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0]])\r\n    pos_2 = tf.constant([[1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0]])\r\n    seq_length = tf.constant([5, 4, 8])\r\n    sparse_label_ids = tf.constant([0, 1, 2])\r\n    def loss_fn():  # For training stage only.\r\n        logits, alpha = nn(inputs, pos_1, pos_1, seq_length,\r\n                           training=True)\r\n        loss = tf.keras.losses.sparse_categorical_crossentropy(sparse_label_ids, logits, from_logits=True)\r\n        loss = tf.reduce_mean(loss)\r\n        return loss\r\n\r\n    out = nn(inputs, pos_1, pos_2, seq_length)\r\n    print(nn.summary())  # Variables in `directional layers are trainable\r\n    clip_val = 5\r\n    if clip_val is not None:\r\n        with tf.GradientTape() as tape:\r\n            loss_val = loss_fn()\r\n\r\n    grads = tape.gradient(loss_val, nn.trainable_variables)\r\n    assert len(nn.trainable_variables) == len(grads)\r\n    for var, grad in zip(nn.trainable_variables, grads):\r\n        print(\"****variable:{} Gradient: {}\".format(var, grad))\r\n\r\n\r\ndef test_estimator_approach():\r\n    nn = RNN_Attention_Clf(word_embedding_dim=64, pos1_embedding_dim=5, pos2_embedding_dim=5, pos_embedding_num=6,\r\n                           vocab_size=100, rnn_dim=20, num_cls=10)\r\n    params = {\"clip_value\": 5, \"init_lr\": 0.1, \"clip_val\": 5, \"decay_step\": 1, \"decay_rate\": 0.99, \"optimizer\": \"Adam\"}\r\n    output_dir = \"./test_output\"\r\n    estimator = tf.estimator.Estimator(nn.model_fn,\r\n                                       config=tf.estimator.RunConfig(save_checkpoints_secs=20, save_summary_steps=1),\r\n                                       model_dir=output_dir,\r\n                                       params=params)\r\n    def input_fn():\r\n        def gen():\r\n            dummy_text = [\"text1\", \"text2\", \"text3\"]\r\n            dummy_labels = [0, 1, 2]\r\n            all_inputs = [[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\r\n            all_pos1 = [[1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0]]\r\n            all_pos2 = [[1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0]]\r\n            seq_length = [5, 4, 8]\r\n            for text, inputs, pos1, pos2, sequence_length, y in zip(dummy_text, all_inputs, all_pos1, all_pos2, seq_length, dummy_labels):\r\n                out = ((text, inputs, pos1, pos2, sequence_length), y)\r\n                yield out\r\n        d = tf.data.Dataset.from_generator(gen,\r\n                                           output_types=((tf.string, tf.int32, tf.int32, tf.int32, tf.int32), tf.int32),\r\n                                           output_shapes=(((), (None,), (None,), (None,), ()), ()))\r\n        d = d.batch(batch_size=3)\r\n        return d\r\n    estimator.train(input_fn=input_fn, max_steps=100)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # To replicate the issue, clear `./test_output` before re-running\r\n\r\n    test_non_estimator_approach()  # No problem with this approach\r\n    test_estimator_approach()  # No gradient computed for weights in GRUCell\r\n\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nThe most notable part from the logs:\r\n```\r\nWARNING:tensorflow:Gradients do not exist for variables ['rnn__attention__clf_1/bidirectional_1/forward_rnn_1/gru_cell_1/kernel:0', 'rnn__attention__clf_1/bidirectional_1/forward_rnn_1/gru_cell_1/recurrent_kernel:0', 'rnn__attention__clf_1/bidirectional_1/forward_rnn_1/gru_cell_1/bias:0', 'rnn__attention__clf_1/bidirectional_1/backward_rnn_1/gru_cell_1/kernel:0', 'rnn__attention__clf_1/bidirectional_1/backward_rnn_1/gru_cell_1/recurrent_kernel:0', 'rnn__attention__clf_1/bidirectional_1/backward_rnn_1/gru_cell_1/bias:0'] when minimizing the loss.\r\n```\r\nI have to skip these gradients when applying gradient clipping as they all return `None`", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5c4100aedf1f509885543539cf88cd8a/45931-2-4.ipynb). Thanks!", "Any update on this issue?", "Tested in TF v2.5. Problem remained unsolved. ", "Since `tf.estimator.Estimator` uses Tensorflow version 1 style code and is most unlikely to get any code fix in upcoming releases apart from the security fixes.\r\nMore detailed warning can be found [here](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator). Thanks!", "> Since `tf.estimator.Estimator` uses Tensorflow version 1 style code and is most unlikely to get any code fix in upcoming releases apart from the security fixes. More detailed warning can be found [here](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator). Thanks!\r\n\r\nIt's okay for me not to use `tf.estimator.Estimator`. The only problem for me is that for custom keras models that are not built from `tf.keras.models.Sequential()`, I didn't not found a way to convert them to `SavedModel` format for model serving purpose in the previous version (only models from tf.keras.models.Sequential() are supported back then. Hence I have to use `tf.estimator.Estimator`. Is there any solution for this?", "Since subclassed model can not be serialized into JSON compatible config.\r\nYou can try serializing the bytecode like via pickle else if you want more secure way, you can consider overwriting the `get_config` and `from_config` methods and register the custom object to make Keras aware of it.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45931\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45931\">No</a>\n"]}, {"number": 45930, "title": "Could not load dynamic library 'libcudart.so.11.0'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.0\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: libcudnn8_8.0.5.39-1+cuda11.0_amd64.deb (I also installed the dev version)\r\n- NVIDIA Driver Version: 450.80.02\r\n- GPU model and memory: GeForce RTX 2080 Super with Max-Q Design\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI tried following the instructions as described in: https://www.tensorflow.org/install/gpu\r\n- I installed Ubuntu 20.04 (which installed the NVIDIA driver)\r\n- Installed python using pyenv\r\n- sudo apt install nvidia-cuda-toolkit\r\n- pip install tensorflow\r\n- Installed: libcudnn8_8.0.5.39-1+cuda11.0_amd64.deb\r\n- (saw that it failed to find 'libcudart.so.11.0')\r\n- Installed: libcudnn8-dev_8.0.5.39-1+cuda11.0_amd64.deb\r\n- (still failed to find 'libcudart.so.11.0')\r\n\r\nIs there a way for me to check which part of the installation broke?\r\nAny ideas on what I can do to fix this?\r\nThanks!\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nPyDev console: starting.\r\nPython 3.7.9 (default, Dec 22 2020, 21:13:51) \r\n[GCC 9.3.0] on linux\r\n>>> import tensorflow as tf\r\n>>> print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n2020-12-22 22:56:35.044676: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2020-12-22 22:56:35.044691: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n/home/ido/TeraResearch/venv/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\r\n  warnings.warn(msg)\r\n2020-12-22 22:56:35.938373: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-22 22:56:35.938801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-12-22 22:56:37.494184: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\r\n2020-12-22 22:56:37.494273: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ido-ml\r\n2020-12-22 22:56:37.494291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ido-ml\r\n2020-12-22 22:56:37.494480: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2\r\n2020-12-22 22:56:37.494544: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\r\n2020-12-22 22:56:37.494561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2\r\nNum GPUs Available:  0\r\n```", "comments": ["@ido-tera-group \r\n\r\nAs per the build configurations from [here](https://www.tensorflow.org/install/source#gpu) it should work with this configuration. Can you please create a fresh environment and try to install from scratch and see if the issue still persists.Thanks!", "Can you refer me to clear instructions on how to install? I see a bunch of blogs each with different ideas... \r\nIs there an official (or semi-offical) guide that should actually work? Thanks!", "@ido-tera-group \r\n\r\nPlease, refer the tutorial from [here](https://www.tensorflow.org/install/gpu#install_cuda_with_apt).Thanks!", "I see, thank you! After tinkering a bit, it worked.. But I changed the instructions to work for 20.04:\r\n\r\n```\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\r\nsudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\r\nsudo apt-get update\r\n```\r\n\r\nPerhaps the docs should be updated?\r\n\r\nThanks again!", "I celebrated too soon.. tensorflow did import without that immediate message, but when I tried building a model, I got:\r\n\r\n```\r\n2020-12-24 15:31:52.325975: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-24 15:31:52.326576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-12-24 15:31:52.341852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-12-24 15:31:52.342269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\r\ncoreClock: 1.23GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\r\n2020-12-24 15:31:52.342442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-12-24 15:31:52.343750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-12-24 15:31:52.343787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-12-24 15:31:52.343824: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\r\n2020-12-24 15:31:52.343872: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\r\n2020-12-24 15:31:52.343906: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\r\n2020-12-24 15:31:52.343938: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\r\n2020-12-24 15:31:52.344019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-12-24 15:31:52.344026: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\n\r\nAny clues?", "I ended up manually installing the missing libraries, and finally got it to work!  <whew>\r\n\r\n... but now... for some reason conv1d isn't working:\r\n\r\n```\r\n2020-12-26 20:54:59.125017: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!\r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\r\n  (0) Not found:  No algorithm worked!\r\n\t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n  (1) Not found:  No algorithm worked!\r\n\t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n\t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_27]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_1582]\r\n```\r\n\r\nIs this due to improper installation or something else? (it worked on my CPU, and if I remove the conv1d layer, it also works)\r\n\r\nThanks!", "@ido-tera-group \r\n\r\nIf you follow the guidelines as mentioned in above link , you should be able to install it. Glad to know you installed.Please, close this thread if your issue was resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "saw same error:\r\n```\r\n2021-01-06 17:05:11.751597: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0';\r\ndlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/Qt/5.14.1/lib\r\n2021-01-06 17:05:11.751625: I tensorflow/stream_executor/cuda/cudart_stub.cc:29]\r\nIgnore above cudart dlerror if you do not have a GPU set up on your machine.\r\n```\r\n\r\nbut it's harmless, I don't want to use a GPU.", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45930\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45930\">No</a>\n", "I'm having the same problem if I try to install python3.8 on google colab + tensorflow 2.4", "Still having the same issue here.", "I has same problem ,and solved this problem by those step.\r\n### First, find out where the \"libcudart.so.11.0\" is\r\nIf you lost other at error stack, you can replace the \"libcudart.so.11.0\" by your word  in below:\r\n```shell\r\nsudo find / -name 'libcudart.so.11.0'\r\n```\r\nOutput in my system.This result shows  where the \"libcudart.so.11.0\" is in my system:\r\n```text\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudart.so.11.0\r\n```\r\nIf the result shows nothing, please make sure you have install cuda or other staff that must install in your system.\r\n### Second, add the path to environment file.\r\n1. edit /etc/profile\r\n```shell\r\nsudo vim /etc/profile\r\n```\r\n2. append path to  \"LD_LIBRARY_PATH\" in profile file \r\n```text\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.1/targets/x86_64-linux/lib\r\n```\r\n3. make environment file work\r\n```shell\r\nsource /etc/profile\r\n```\r\n### Last, when it all done, you can try your python code again.\r\nHope it help for you!\r\n\r\n### At the end\r\nI do every thing on guide list to install tensorflow. But still occurs the same problem\r\nmy environment:\r\nubuntu: 20.04LTS\r\ntensorflow: 2.4.1\r\npython3: 3.8\r\npip3: 21\r\nCUDA: 11.1\r\ncuDNN: 8.1.0\r\nGPU: GeForce GTX 860M\r\nGPU Driver: 460.39\r\n\r\nMy error stack before solve this problem:\r\n```shell\r\n2021-01-31 15:04:10.925736: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:10.925774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-01-31 15:04:11.738577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-01-31 15:04:11.771425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-31 15:04:11.771969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021-01-31 15:04:11.772084: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772174: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772255: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772333: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772413: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772490: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772567: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n2021-01-31 15:04:11.772745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-01-31 15:04:11.772763: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1803] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\nAfter I fix it , the python code works fine ", "A short quick fix that worked for me\r\n\r\nRunning Ubuntu 20.04, Python 3.8.5, cuDNN 8.1.0, on an RTX 2080 Super.\r\n\r\nI downloaded [this run file](https://developer.nvidia.com/cuda-11.0-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=2004&target_type=runfilelocal) from NVIDIA, then only opted in to install the CUDA 11 toolkit. After it finished downloading, I added `/usr/local/cuda-11.0/bin` to my PATH and `/usr/local/cuda-11.0/lib64` to my LD_LIBRARY_PATH. \r\n\r\nAfter that, my GPU was functional again.", "you can try to add these code to load dynamic library\r\n\r\nfrom ctypes import *\r\nlib8 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcublas.so.11')\r\nlib1 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcudart.so.11.0')\r\nlib2 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcublasLt.so.11')\r\nlib3 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcufft.so.10')\r\nlib4 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcurand.so.10')\r\nlib5 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcusolver.so.10')\r\nlib6 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcusparse.so.11')\r\nlib7 = cdll.LoadLibrary('/data/users/CHDHPC/2017902628/cuda/lib64/libcudnn.so.8')\r\n", "The fucking stupid bug still exist in the latest tf today.", "```\r\n[I 2021-02-10 12:56:49.480 ServerApp] Kernel started: 5746087b-7f04-4517-a0a3-afc5ae7ad726\r\n2021-02-10 12:57:07.427237: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-02-10 12:57:07.427347: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-02-10 12:57:40.203717: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-10 12:57:40.261141: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-02-10 12:57:40.261205: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-02-10 12:57:40.261248: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu-desktop): /proc/driver/nvidia/version does not exist\r\n2021-02-10 12:57:40.261892: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-02-10 12:57:40.262545: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n```", "I had the same problem, it was solved by installing cudatoolkit\r\n`conda install cudatoolkit`", "> I had the same problem, it was solved by installing cudatoolkit\r\n> `conda install cudatoolkit`\r\n\r\nMy computer no GPU, why I need cudatoolkit?", "> I had the same problem, it was solved by installing cudatoolkit\r\n> `conda install cudatoolkit`\r\n\r\nThis worked for me as well. ", "Ubuntu 20.04 doesn't upgrade to CUDA-11.x. Please follow the instructions at the [CUDA download page](https://developer.nvidia.com/cuda-downloads) to install CUDA-11.x.\r\n\r\nAfter all, don't forget joint the CUDA library path with environment of `LD_LIBRARY_PATH`.\r\n`echo 'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/targets/x86_64-linux/lib' >> ~/.bashrc\r\n`", "The way I solved this problem was the following:\r\n\r\n- My setup: Ubuntu 18.04, Tensor Flow 2.4. \r\n- I got missing libraries: `libcudart.so.11.0`,`libcusparse.so.11`.\r\n- I did not want to install `conda` but rather just use `pip`.\r\n\r\nMy solution:\r\n- Just run Ubuntu 18.04 docker, where you install `cudatoolkit` (version that has cuda 11)\r\n- inside that docker find locations of `libcudart.so.11.0`,`libcusparse.so.11` & copy them into your main machine (or use docker - shared folder)\r\n- once you have them in the main machine (in whatever location), add that directory path into `~/.bashrc` as mentioned in many solutions above.  \r\n", "> I see, thank you! After tinkering a bit, it worked.. But I changed the instructions to work for 20.04:\r\n> \r\n> ```\r\n> wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\r\n> sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\n> sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub\r\n> sudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\r\n> sudo apt-get update\r\n> ```\r\n> \r\n> Perhaps the docs should be updated?\r\n> \r\n> Thanks again!\r\n\r\nThanks for this. What package did you subsequently install?\r\n", "this helped me: \r\n\r\n`conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\r\n`", "> I had the same problem, it was solved by installing cudatoolkit\r\n> `conda install cudatoolkit`\r\n\r\nthis worked for me ", "> I ended up manually installing the missing libraries, and finally got it to work!\r\n> \r\n> ... but now... for some reason conv1d isn't working:\r\n> \r\n> ```\r\n> 2020-12-26 20:54:59.125017: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!\r\n> \r\n> tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\r\n>   (0) Not found:  No algorithm worked!\r\n> \t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n>   (1) Not found:  No algorithm worked!\r\n> \t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n> \t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_27]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored. [Op:__inference_train_function_1582]\r\n> ```\r\n> \r\n> Is this due to improper installation or something else? (it worked on my CPU, and if I remove the conv1d layer, it also works)\r\n> \r\n> Thanks!\r\n\r\nCould you post the instructions of you installed to fix this please as the notes cover 16.04 and 18.04 but not 20.04 which I#m also having troubles with now", "> I ended up manually installing the missing libraries, and finally got it to work!\r\n> \r\n> ... but now... for some reason conv1d isn't working:\r\n> \r\n> ```\r\n> 2020-12-26 20:54:59.125017: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!\r\n> \r\n> tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\r\n>   (0) Not found:  No algorithm worked!\r\n> \t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n>   (1) Not found:  No algorithm worked!\r\n> \t [[node sequential/conv1d/conv1d (defined at /egg_analysis/dl_eggs.py:191) ]]\r\n> \t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_27]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored. [Op:__inference_train_function_1582]\r\n> ```\r\n> \r\n> Is this due to improper installation or something else? (it worked on my CPU, and if I remove the conv1d layer, it also works)\r\n> \r\n> Thanks!\r\n\r\nThis following error is resolved. Please add following lines after the imports : \r\n\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\n\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)", "Please run these command. It will solve the issue\r\n\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\r\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\r\nsudo apt-get update\r\nsudo apt-get -y install cuda ", "> this helped me:\r\n> \r\n> `conda install pytorch torchvision cudatoolkit=10.1 -c pytorch `\r\n\r\nWhat the hell, it seriously worked for me! Can't believe it, what a lol sol.", "normally don't post but go to the following link below, do exactly as the instructions say, then reboot your linux box(server) and you should be fine.\r\n\r\nhttps://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_network\r\n\r\nPS, other people wrote the correct steps but in the case that the download URL changes or etc.... I have provided the downloads link from NVIDIA", "I am running TensorFlow v2.4.1 and PyTorch v1.8.1 LTS with an NVIDIA RTX 3090 on a JupyterHub(The Littlest Jupyter Hub).\r\nThe suggestions that involve the \"apt\" command are therefore impractical in my case.\r\nAfter scouring the internet(Github+Stack Overflow+etc.)  for multiple days, I've come up with a solution for JupyterHub users.\r\nMy suggested solutions are intended for JupyterHub users, but hopefully a quick look at the code might give other people an idea for different environments.\r\n\r\nhttps://github.com/lyh16/jupyterhub-cudnn-installer", "These command works.\r\n\r\n```\r\nwget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run\r\nsudo sh cuda_11.4.0_470.42.01_linux.run\r\n```\r\nhttps://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Debian&target_version=10&target_type=runfile_local\r\n\r\n\r\n\r\n\r\n", "> I had the same problem, it was solved by installing cudatoolkit\r\n> `conda install cudatoolkit`\r\nI directly installed \r\nNvidia Driver, CUDA, CuDnn whatever newer versions from the archive i got still i got this error but after running conda install cudatoolkit everything started working properly. \r\nThank you so much.\r\n", "This worked for me:\r\n```\r\n# dependecies \r\nsudo apt install cuda-cudart-11-0\r\nsudo apt install libcufft10\r\nsudo apt install libcurand10\r\nsudo apt install libcusolver-11-0 # installs so.10, see below \r\nsudo apt install libcudnn8\r\nsudo apt install libcublas-11-0\r\nsudo apt install libcusparse-11-0\r\n\r\n# add this path to LD_LIBRARY_PATH in .bashrc as in previous posts\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/\r\n\r\n# in the /usr/... path, run:\r\nsudo ln -s libcusolver.so.10.6.0.245 libcusolver.so.11 \r\n```", "> I had the same problem, it was solved by installing cudatoolkit\r\n> `conda install cudatoolkit`\r\n\r\nThanks! This worked for me .", "> > this helped me:\r\n> > `conda install pytorch torchvision cudatoolkit=10.1 -c pytorch `\r\n> \r\n> What the hell, it seriously worked for me! Can't believe it, what a lol sol.\r\n\r\nWorks on me too but I don't know why", "> I has same problem ,and solved this problem by those step.\r\n> \r\n> ### First, find out where the \"libcudart.so.11.0\" is\r\n> If you lost other at error stack, you can replace the \"libcudart.so.11.0\" by your word in below:\r\n> \r\n> ```shell\r\n> sudo find / -name 'libcudart.so.11.0'\r\n> ```\r\n> \r\n> Output in my system.This result shows where the \"libcudart.so.11.0\" is in my system:\r\n> \r\n> ```\r\n> /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudart.so.11.0\r\n> ```\r\n> \r\n> If the result shows nothing, please make sure you have install cuda or other staff that must install in your system.\r\n> \r\n> ### Second, add the path to environment file.\r\n> 1. edit /etc/profile\r\n> \r\n> ```shell\r\n> sudo vim /etc/profile\r\n> ```\r\n> \r\n>  2. append path to  \"LD_LIBRARY_PATH\" in profile file\r\n> \r\n> ```\r\n> export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.1/targets/x86_64-linux/lib\r\n> ```\r\n> \r\n>  3. make environment file work\r\n> \r\n> ```shell\r\n> source /etc/profile\r\n> ```\r\n> \r\n> ### Last, when it all done, you can try your python code again.\r\n> Hope it help for you!\r\n> \r\n> ### At the end\r\n> I do every thing on guide list to install tensorflow. But still occurs the same problem my environment: ubuntu: 20.04LTS tensorflow: 2.4.1 python3: 3.8 pip3: 21 CUDA: 11.1 cuDNN: 8.1.0 GPU: GeForce GTX 860M GPU Driver: 460.39\r\n> \r\n> My error stack before solve this problem:\r\n> \r\n> ```shell\r\n> 2021-01-31 15:04:10.925736: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:10.925774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n> 2021-01-31 15:04:11.738577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n> 2021-01-31 15:04:11.771425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2021-01-31 15:04:11.771969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Found device 0 with properties: \r\n> pciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\n> coreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\r\n> 2021-01-31 15:04:11.772084: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772174: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772255: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772333: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772413: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772490: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772567: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\r\n> 2021-01-31 15:04:11.772745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n> 2021-01-31 15:04:11.772763: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1803] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\n> Skipping registering GPU devices...\r\n> ```\r\n> \r\n> After I fix it , the python code works fine\r\n\r\nHi, in this how do you do Step #2? \r\n\r\n1. Do you open your virtual python environment, then do these changes to add it? \r\n2. Do you simply open the `etc/profile` file and add to the end? ", "I'm facing the same problem. I installed tensorflow-gpu 2.2.0 using Anaconda and it will automatically download cudnn 7.6 and cudatoolkit 10.1.  anyone using anaconda also faces the same problem? ( i installed tensorflow-gpu by running this line `conda create -n tf-gpu tensorflow-gpu==2.2.0 python==3.8`)", "> \r\n\r\nThanks a lot. This hugely helps. God bless you!", "I'm seeing this warning but with just tensorflow installed, not tensorflow-gpu.  I just want to suppress this warning for my library users.  What is the recommended way to suppress this warning for the regular tensorflow package?", "Oh, I guess those two packages are now combined into one:\r\nhttps://www.tensorflow.org/install\r\n![image](https://user-images.githubusercontent.com/24683184/148239161-8fb1dbb6-5da2-47e9-b41e-823fcdc310b1.png)\r\n\r\nit's really annoying to users to show this warning though if they actually don't want to use the GPU\r\n\r\nEdit:\r\nOh, I guess now you can actively install the CPU version only with the new versions of tensorflow:\r\n```\r\nA smaller CPU-only package is also available:\r\n\r\n$ pip install tensorflow-cpu\r\n```\r\nI guess that may fix my warning.", "conda install cudatoolkit=11.3 -c pytorch -c conda-forge\r\nThis worked for me\r\n\r\n", "System information\r\n\r\nOS Platform and Distribution : Linux Ubuntu 20.04\r\nTensorFlow version: 2.5.0\r\nPython version: 3.8.10\r\nNVIDIA Driver Version: 470.86\r\nGPU model: GeForce RTX 3060\r\n\r\n**ERROR**\r\n\r\n2022-01-20 20:10:02.523095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/opt/ros/noetic/lib:/usr/lib/cuda/include:/usr/lib/cuda/lib64::/usr/local/cuda/targets/x86_64-linux/lib\r\n2022-01-20 20:10:02.523121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\n**Please help me to solve this issue**", "For anyone having this issue (ping @Kamlesh364), I strongly recommend checking out Docker and using the official images: https://hub.docker.com/r/tensorflow/tensorflow/. It's a new technology to learn, but then saves a lot of time when solving these dependency-hell problems, since the Docker image has all the dependencies (including CUDA) pre-installed. Docker also integrates nicely with VSCode (check out devcontainers).\r\n\r\nYou just need to install a CUDA-capable driver and enable GPU passthrough to Docker: [Linux tutorial](https://towardsdatascience.com/how-to-properly-use-the-gpu-within-a-docker-container-4c699c78c6d1), [Windows tutorial](https://stackoverflow.com/a/66437683/6099426).", "@Kamlesh364 What is the output of `nvcc --version`?", "I've resolved the issue by performing following-\r\n1. Removed currently installed cuda and tensorflow versions.\r\n2. Installed cuda-toolkit using the command `sudo apt install nvidia-cuda-toolkit`\r\n3. upgraded to NVIDIA Driver Version: 510.54\r\n4. Installed Tensorflow==2.7.0\r\n\r\nand everything is just amazing now:)\r\nthanks for the help.", "Good to know!\r\nAnother solution that worked for me is to find the correct version of Tensorflow that matches my OS, CUDA version, and python version here: https://www.tensorflow.org/install/source#gpu, and just `pip install` that version of tensorflow.\r\n", "> Good to know! Another solution that worked for me is to find the correct version of Tensorflow that matches my OS, CUDA version, and python version here: https://www.tensorflow.org/install/source#gpu, and just `pip install` that version of tensorflow.\r\n\r\nya, this is the most applicable solution for this issue.", "> normally don't post but go to the following link below, do exactly as the instructions say, then reboot your linux box(server) and you should be fine.\r\n> \r\n> https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_network\r\n> \r\n> PS, other people wrote the correct steps but in the case that the download URL changes or etc.... I have provided the downloads link from NVIDIA\r\n\r\nThis seemed to work for me. Thank you @ithllc! You've saved my assignment! :)"]}, {"number": 45928, "title": "[ROCm] Update to use ROCm 4.0 (when building TF with --config=rocm)", "body": "/cc @cheshire @chsigg @nvining-work", "comments": ["@gbaned anything I can do on my end to get this PR merged?", "> @gbaned anything I can do on my end to get this PR merged?\r\n\r\n@deven-amd This PR is waiting for internal approval. Nothing to do at this moment from your end. Thank you!"]}, {"number": 45927, "title": "Linking issue: undefined reference to `tflite::micro::GetTensorShape SparkfunEdge", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: many versions including latest\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): gcc 7.5\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: intel onboard graphics\r\n\r\n\r\n**Describe the current behavior**\r\nCurrently trying to run the magic wand examples from another project that is written in C (one of the FreeRTOS examples on SparkFun Edge).\r\nI compiled the magic wand examples, moved all the .o files to the other project and tried compiling the other project together with linking the TFLite .o files. The linking step generated the following errors:\r\n\r\n```\r\n../gcc/edge/bin/fully_connected.o: In function `EvalFloat':\r\n/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:192: undefined reference to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)'\r\n/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:194: undefined reference to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)'\r\n/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:196: undefined reference to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)'\r\n/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:198: undefined reference to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)'\r\n../gcc/edge/bin/fully_connected.o: In function `EvalQuantizedInt8':\r\n/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:124: undefined reference to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)'\r\n../gcc/edge/bin/fully_connected.o:/home/fadel/Desktop/Projects/ml/tensorflow/tensorflow/lite/micro/kernels/fully_connected.cc:126: more undefined references to `tflite::micro::GetTensorShape(TfLiteEvalTensor const*)' follow\r\ncollect2: error: ld returned 1 exit status\r\n```\r\nThis is the exact same problem as this: https://github.com/tensorflow/tensorflow/issues/41821 except that I am not using the \"CMSIS-NN\" tag anywhere.\r\n\r\n**Describe the expected behavior**\r\nSuccessful linking of the code.\r\n\r\n**Standalone code to reproduce the issue**\r\n*Download any FreeRTOS example from SparkFun's repository, ex: https://github.com/sparkfun/SparkFun_Apollo3_AmbiqSuite_BSPs/tree/6398086a1a87ddea78274521683ba3ad817bee82/common/examples/ble_freertos_tag\r\n*Compile the magic wand example\r\n*Copy all the created .o files to the /src/gcc directory of the FreeRTOS\r\n*Use an \"extern C\" to allow magic wand's main() function to be called from a C interface (FreeRTOS project is in C).\r\n*Call the main() function in the FreeRTOS project.\r\n*Edit the Makefile of the RTOS project to link all the .o files from the magic wand example\r\n*Compile the FreeRTOS example, the error will show at the linking step.\r\n\r\nI know that it's time-consuming to replicate this, I can provide my repositories that contains the ready made Makefiles, etc. However, perhaps you know what the issue is just from reading the above.\r\n", "comments": ["Issue solved by linking the microlite library produced by the makefile together with the magic wand's .o files.\r\n\r\nWill leave this issue open as perhaps this is indeed a bug and the compiled .o files should provided the whole runtime environment.", "Hi fadelgaber,\r\n\r\nGetTensorShape is defined in tensorflow/lite/micro/kernels/kernel_util.cc \r\nCould you check if kernel_util.o is included in your project and if it contains the required symbol (you can use `nm` to list all symbols in .o files.\r\n\r\nI have an old FreeRTOS + BLE + Magic Wand demo project. It is very old. Some of the scripts might no work anymore so I've kept it private for now. I've granted you the access permission in case you find anything useful.\r\n\r\nLet me know how it goes.\r\n\r\nThanks,\r\nTiezhen", "@fadelgaber Could you please try as per the above comment  and let us know if this issue still persists ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45927\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45927\">No</a>\n"]}, {"number": 45926, "title": "No algorithm Worked", "body": "Getting this error when using the code in collab\r\n\r\nFound 14400 images belonging to 2 classes.\r\nFound 400 images belonging to 2 classes.\r\nEpoch 1/50\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-28-86598d638a85> in <module>()\r\n     15         epochs=50,\r\n     16         validation_data=test_generator,\r\n---> 17         validation_steps=800)\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    853       # In this case we have created variables on the first call, so we run the\r\n    854       # defunned version which is guaranteed to never create variables.\r\n--> 855       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    856     elif self._stateful_fn is not None:\r\n    857       # Release the lock early so that multiple threads can perform the call\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n   2942     return graph_function._call_flat(\r\n-> 2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2944 \r\n   2945   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1917       # No tape is watching; skip to running the function.\r\n   1918       return self._build_call_outputs(self._inference_function.call(\r\n-> 1919           ctx, args, cancellation_manager=cancellation_manager))\r\n   1920     forward_backward = self._select_forward_and_backward_functions(\r\n   1921         args,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    558               inputs=args,\r\n    559               attrs=attrs,\r\n--> 560               ctx=ctx)\r\n    561         else:\r\n    562           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nNotFoundError:  No algorithm worked!\r\n\t [[node sequential_2/conv2d_6/Conv2D (defined at <ipython-input-26-b3f11172c6da>:17) ]] [Op:__inference_train_function_3219]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\n\r\n\r\nMy code on colab i was just testing a random CNN architecture on my dataset\r\nhttps://colab.research.google.com/drive/1mb7c3Dg6CDwcjYitp85uNpa_A6il1J6f?usp=sharing", "comments": ["@876arham \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Please, let me know which TF version you are using?.\r\nRequest you to share sample input files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "https://www.kaggle.com/lijiyu/bossbase?select=boss_256_0.4_test is the dataset i am using\r\n\r\nversion 2.4.0 tensorflow", "@876arham \r\n\r\nI have tried in colab with TF nightly version(`2.5.0-dev20201223`) .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/b5ca4794ebaad0ee7cf8d0c0744b2c17/untitled.ipynb).You are also seeing the same behavior?\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45926\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45926\">No</a>\n"]}, {"number": 45925, "title": "label_image build fails for stm32f1", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution : ubuntu 18.04\r\n- TensorFlow installed from : Source\r\n- Tensorflow commit: bba12d0401800fbf873ea35f34517a8c47a54272 (Branch:Master)\r\n- Target platform : Arm\r\n\r\nI am trying to build target 'stm32f1' at location tensorflow/lite/tools/make/targets in file stm32f1_makefile.inc \r\nfor this I am using toolchain provided at https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-rm for x86_64 which is Pre-built GNU bare-metal toolchain for 32-bit Arm processors.\r\nwhile building label_image I am getting error saying that it was not able to find #include <dlfcn.h>\r\n\r\nFollowing are the steps to produce this issue: (in tensorflow dir)\r\n$./tensorflow/lite/tools/make/download_dependencies.sh\r\nexport the tools from toolchain downloaded from above link.\r\nAnd modified the build_rpi_build.sh where I changed TARGET_ARCH to TARGET and passes TARGET=stm32f1.", "comments": ["TFLite isn't buildable with the embedded tool chain.\r\nIt works with A-profile architecture toolchain.\r\nhttps://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-a\r\n\r\nFor stm32f1, you'd better play with TFLite micro.\r\nhttps://www.tensorflow.org/lite/microcontrollers", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45925\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45925\">No</a>\n"]}, {"number": 45924, "title": "Feature clolumns  cannot be used in the keras model, it may be a bug", "body": "## URL(s) with the issue:\r\nhttps://tensorflow.google.cn/api_docs/python/tf/keras/layers/DenseFeatures\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI have made a keras function API model, which uses' fit_generator 'for multiple input. If you don't use tensorflow feature columns, the model can work normally, but if you use feature columns to input to densefeatures layer, the model will not work. It looks like a bug, because the same code has been tried before, and the model works\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n### Usage example\r\n\r\nmy code:\r\nset use_feature_columns=False can work but,set use_feature_columns=True,it can't work.\r\n\r\n\r\nhttps://colab.research.google.com/drive/18e-T5UYi__uzsMmavXTj86pM9GPhqe7I?usp=sharing\r\n\r\n", "comments": ["@anavanab99,\r\nI do not have access to the Colab notebook you have linked. Could you please provide the required permissions to view the files. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45924\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45924\">No</a>\n"]}, {"number": 45923, "title": "Loss reported by fit vs custom_loop", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/distribute/custom_training\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI wanted to compare the `fit` performance vs a \"custom loop\" with a `MultiWorker` strategy according to the tutorials at https://www.tensorflow.org/tutorials/distribute/keras and https://www.tensorflow.org/tutorials/distribute/custom_training \r\n\r\nHowever I'm seeing differences in the loss reported. Examples for an MNIST dataset with a Lenet:\r\n- fit: Eval loss: 32.09, Eval Accuracy: 0.9307\r\n- custom loop: Eval loss: 1.742, Eval Accuracy: 0.965\r\n\r\nAlso the loss reported in the `logs` member of the callbacks seems to be higher by some factor compared to the custom_loop.\r\n\r\n### Clear description\r\n\r\nAt https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function I found the following:\r\n\r\n> - Using tf.reduce_mean is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.\r\n> - This reduction and scaling is done automatically in keras `model.compile` and `model.fit`\r\n> - ... SUM_OVER_BATCH_SIZE is disallowed because currently it would only divide by per replica batch size, and leave the dividing by number of replicas to the user, which might be easy to miss. So instead we ask the user do the reduction themselves explicitly.\r\n\r\nSo question here which isn't clear to me from reading the docs/tutorials: How is the loss calculated by `model.compile` and `model.fit` and is that expected to be the same as the one shown in the tutorial for custom_loops? \r\n\r\nWhat I recon is that it should be the average loss per sample over the whole batch (on all replicas). So the sum of all `per_example_loss` divided by the number of examples.\r\nThe custom_loop tutorial divides by the global batch size, i.e. the local batch size times the number of replicas. This would be wrong for the mentioned case where the \"per replica batch size [...] may vary step to step.\" So this sounds like `tf.reduce_mean` would be useful with an additional step of averaging the `per_replica_losses` instead of summing them after the `strategy.run` part. Why is that not recommended?", "comments": ["@Flamefire \r\n\r\nCan you please share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Flamefire,\r\nCan you please respond to the [above comment](https://github.com/tensorflow/tensorflow/issues/45923#issuecomment-749998924)? Thanks! ", "I created a minified example which trains the same model 2 times: once with the `fit` function and once with the custom loop. Both variants follow very closely the tutorial code and should train the same network on the same dataset for the same number of batches resulting in the same losses.\r\n\r\nHowever the loss for the custom loop at the end is significantly lower than that from `fit`, see https://colab.research.google.com/drive/1G_r2pU9usKgB5U_MAEkBZ0eJyK48YMta?usp=sharing\r\n\r\nWhen using multiple devices (may require GPUs, set `num_gpus = 2`) then an issue becomes visible: Batch 0 has a loss of 4.609 (custom) vs 2.304 (fit) which makes me wonder if the scaling is indeed correct.", "Ok I found the issue(s):\r\n\r\n- I was missing a `strategy.experimental_distribute_dataset`. Not sure if this is new as I started writing the code for TF 2.0\r\n- `fit` reports the loss via the `Mean` metric, so the loss is (likely) always higher then what I manually had which reported the loss for the current batch(es)\r\n\r\nIt might be worth mentioning that in the tutorial for custom loops", "Hi @Flamefire, `strategy.experimental_distribute_dataset` should be mentioned everywhere custom training loops + distribution strategy are discussed. However, if you find somewhere it's missing let me know.\r\n\r\nAs for updating the custom training loops tutorial, can you elaborate on what you think should be added and where?", "> As for updating the custom training loops tutorial, can you elaborate on what you think should be added and where?\r\n\r\nThe missing link for me was that `model.fit` reports the loss as the Mean, also in callbacks. https://www.tensorflow.org/tutorials/distribute/custom_training#training_loop has `train_loss = total_loss / num_batches` so I guess that is similar enough, but seems like I missed it. Maybe using the `Mean` metric here would be a good thing to show so users can output the current mean loss inbetween batches when starting with the tutorial code?\r\n\r\nAnyway at the current state nothing seems to be really missing, so I'd also be fine to close this now. Thanks a lot!", "Thanks! I will close this issue now.", "@nikitamaia @Flamefire @rmothukuru \r\n\r\n\r\nI had some questions about distribute strategy custom training. https://www.tensorflow.org/tutorials/distribute/custom_training. \r\n\r\n1. \"If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.\"\r\n\r\n**Why are regularization loss treated different compared to other type of losses?**\r\n\r\n2. \"Using tf.reduce_mean is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.\"\r\n\r\n**How does the batch size vary step to step per replica? Also, I am not exactly sure why we would not tf.reduce mean if the batch size changes step instead of diving by the global batch size**\r\n\r\n"]}, {"number": 45922, "title": "AutoGraph could not transform custom Train_Step function", "body": "**System information**\r\n- Have I written custom code\r\n- OS Platform: Windows 10 64-bit, Desktop\r\n- TensorFlow installed from binary:\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.7.9\r\n- CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.243\r\n- GPU model and memory: two system linked Nvidia GeForce 2070 RX.  8gb ram each (16gb total).\r\n\r\n**Describe the current behavior**\r\nI get the following warning message when using tf.function to convert my function:\r\n\"\r\nWARNING:tensorflow:AutoGraph could not transform <function Train_Step at 0x000002935E41C048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\n\"\r\n\r\n**Describe the expected behavior**\r\nI expected that when I used a @tf.function decorator the function would compile properly not throw out a warning.\r\n\r\n**Standalone code to reproduce the issue**\r\n\"\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch_size = 100\r\nfeature_length = 45\r\nlength_target = 1\r\narray_sample_data = np.asarray(np.random.random((batch_size, feature_length)), dtype = np.float32)\r\narray_target_data = np.asarray(np.random.random((batch_size, length_target)), dtype = np.float32)\r\narray_std_data = np.std(array_sample_data, axis = 0)\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Dense(50, activation = 'relu', input_shape = [feature_length]))\r\nmodel.add(tf.keras.layers.Dense(length_target, activation = 'sigmoid'))\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\nloss = tf.keras.losses.MSE\r\nmodel.compile(optimizer = optimizer, loss = loss)\r\n\r\ntensor_sample_data = tf.constant(array_sample_data, dtype = 'float32')\r\ntensor_target_data = tf.constant(array_target_data, dtype = 'float32')\r\ntensor_weight = None\r\n\r\nclip_norm = 1\r\n@tf.function\t\r\ndef Train_Step(tensor_sample_data, tensor_target_data, tensor_weight):\r\n\twith tf.GradientTape() as tape:\r\n\t\ty_pred = model.call(tensor_sample_data, training = True)\r\n\t\tloss = model.compiled_loss(y_true = tensor_target_data, y_pred = y_pred, \\\r\nsample_weight = tensor_weight, regularization_losses = model.losses) \r\n\r\n\tper_replica_gradients = tape.gradient(loss, model.trainable_variables)\r\n\tgradients = tf.distribute.get_replica_context().all_reduce('sum', per_replica_gradients) #summed all grads across devices\r\n\tloss = tf.distribute.get_replica_context().all_reduce('sum', loss)\r\n\ty_pred = tf.distribute.get_replica_context().all_reduce('sum', y_pred)\r\n\t(gradients, global_norm_value) = tf.clip_by_global_norm(t_list = gradients, clip_norm = clip_norm)\r\n\tmodel.optimizer.apply_gradients(zip(gradients, model.trainable_variables), experimental_aggregate_gradients = False)\r\n\r\n\treturn (y_pred, loss)\r\n\r\nepochs = 3\r\nfor index_epoch in range(epochs):\r\n\t(y_pred, loss) = Train_Step(tensor_sample_data = tensor_sample_data, tensor_target_data = tensor_target_data, tensor_weight = tensor_weight)\r\n\tprint('Training loss is {} on epoch {}.'.format(loss, index_epoch + 1))\r\n\r\n\"\r\nThanks for your time and consideration.", "comments": ["@YouCantHandleMyOPness,\r\nI did not face any warnings while running the code with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/a50c728f9df8d493dfd52831992ce921/45922-2-3.ipynb) and [TF v2.4](https://colab.research.google.com/gist/amahendrakar/f20d1920f1c21cb0e5a488026a6baa7e/45922.ipynb#scrollTo=VRYN13GrRUWF). Please check the linked gist for reference. \r\n\r\nYou can safely ignore the warnings and suppress the warning logs by running the below code before importing TensorFlow.  \r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\nimport tensorflow as tf\r\n```\r\n\r\nThanks!\r\n", "That's interesting.  I'll just assume that TF 2.3.1 has some strange warning message and that there is nothing to worry about.  Thanks for the help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45922\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45922\">No</a>\n"]}, {"number": 45920, "title": "Could not find device for node: {{node FloorMod}} = FloorMod[T=DT_HALF]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Google Colab\r\n- TensorFlow version (use command below): v2.4.0-0-g582c8d236cb 2.4.0\r\n- Python version: 3\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n**Describe the current behavior**\r\nSince TF 2.4.0 i get an error during FloorMod operation with float16.\r\nIn TF 2.3.1 it worked as expected.\r\n\r\n**Describe the expected behavior**\r\nFloorMod should be available for float16 dtype.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/19kRHgXjuf9R9UuBYmEmZiFQPpodnbsOM?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```python\r\nimport tensorflow as tf\r\n\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION)\r\n# v2.4.0-0-g582c8d236cb 2.4.0\r\n\r\nx = tf.constant([1, 2, 3], 'float16')\r\nx % 4\r\n\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-6-86e5a110f54d> in <module>()\r\n----> 1 x % 4\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: Could not find device for node: {{node FloorMod}} = FloorMod[T=DT_HALF]\r\nAll kernels registered for op FloorMod:\r\n  device='GPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_UINT64]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n [Op:FloorMod]\r\n```", "comments": ["I have tried in colab with TF 2.4 , nightly version(`2.5.0-dev20201222`) and was able to reproduce the issue. However I am not seeing any issue with TF 2.3 version. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/23c82e886865b955bc4f9f36058ba948/untitled568.ipynb). Thanks!", "Still not fixed in v1.12.1-52612-g74d34665fc1 2.5.0-dev20210311", "Fixed in v1.12.1-54850-g958d4f19097 2.6.0-dev20210414", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45920\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45920\">No</a>\n"]}, {"number": 45919, "title": "Error using custom activation function while mixed precision enable", "body": "Config\r\n```\r\nTensorFlow 2.3\r\n```\r\n\r\nI already posted in [SO](https://stackoverflow.com/questions/65403976/typeerror-using-custom-activation-function-while-mixed-precision-enabled), a few hours ago without any response until now. But I need a quick pointer. \r\n\r\n----\r\n\r\n### Problem\r\n\r\nI was trying to use a **custom activation** in **mixed-precision** enabled training pipelines but faced the following error:\r\n\r\n```\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n```\r\n\r\n### Reproduce \r\n\r\nEnabling Mixed precision...\r\n\r\n```\r\nimport tensorflow as tf \r\n\r\npolicy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\r\ntf.keras.mixed_precision.experimental.set_policy(policy)\r\nprint('Mixed precision enabled')\r\n```\r\n\r\nCustom activation... \r\n\r\n```\r\ndef ARelu(x, alpha=0.90, beta=2.0):\r\n    alpha = tf.clip_by_value(alpha, clip_value_min=0.01, clip_value_max=0.99)\r\n    beta  = 1 + tf.math.sigmoid(beta)\r\n    return tf.nn.relu(x) * beta - tf.nn.relu(-x) * alpha\r\n```\r\n\r\nTraining...\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n(xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.mnist.load_data()\r\n\r\ndef pre_process(inputs, targets):\r\n    inputs  = tf.expand_dims(inputs, -1)\r\n    targets = tf.one_hot(targets, depth=10)\r\n    return tf.divide(inputs, 255), targets\r\n\r\ntrain_data = tf.data.Dataset.from_tensor_slices((xtrain, ytrain)).\\\r\n    take(10_000).shuffle(10_000).batch(8).map(pre_process)\r\ntest_data = tf.data.Dataset.from_tensor_slices((xtest, ytest)).\\\r\n    take(1_000).shuffle(1_000).batch(8).map(pre_process)\r\n\r\nmodel = tf.keras.Sequential([\r\n                             \r\n            tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),\r\n                                   input_shape=(28, 28, 1), activation=ARelu),\r\n            tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\r\n\r\n            tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), \r\n                                   activation=ARelu),\r\n            tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\r\n\r\n            tf.keras.layers.Flatten(),\r\n            tf.keras.layers.Dense(64, activation=ARelu), \r\n            tf.keras.layers.Dense(10, activation='softmax', dtype=tf.float32)]) \r\n\r\nopt = tf.keras.optimizers.Adam()\r\n\r\nmodel.compile(loss='categorical_crossentropy', optimizer=opt)\r\nhistory = model.fit(train_data, validation_data=test_data, epochs=10)\r\n\r\n# ------------------\r\n\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n```\r\n\r\nHowever, without mixed-precision, it works. I understand the problem simply types miss match but where I should look into it? \r\n\r\nAdditionally, while trying to solve it, I've found that using `tf.keras.mixed_precision.LossScaleOptimizer` is safe to avoid numeric underflow. Is it something that we should use for mixed-precision training? ", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/641251e2fb3ab5eeb4d30fc646d43f21/45919-2-4.ipynb). Thanks!", "Are you telling me to get the gist or to the person whom you assigned? lolz :octocat: ", "@innat,\r\n> Are you telling me to get the gist or to the person whom you assigned? lolz :octocat:\r\n\r\nIt is an instruction to next level Engineers, so is the status, **`Awaiting Tensorflower`**.", "## Solved \r\n\r\nI have to typecast the input \r\n\r\n```\r\ndef ARelu(x, alpha=0.90, beta=2.0):\r\n    alpha = tf.clip_by_value(alpha, clip_value_min=0.01, clip_value_max=0.99)\r\n    beta  = 1 + tf.math.sigmoid(beta)\r\n\tx = tf.cast(x, 'float32')\r\n    return tf.nn.relu(x) * beta - tf.nn.relu(-x) * alpha\r\n```\r\n\r\nBut I'm not sure by doing this, do we lose the benefit of mixed-precision as well. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45919\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45919\">No</a>\n"]}, {"number": 45918, "title": "TF 2.4 met 'TypeError: can't pickle _thread.lock objects' where 2.3 did not.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v.2.4\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nI am working on distributed learning in tensorflow through estimators API using below simple code template:\r\n\r\n```\r\ndef multi_worker_strategy_estimator():\r\n    mirrored_strategy = tf.distribute.MultiWorkerMirroredStrategy()\r\n    config = tf.estimator.RunConfig(train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\r\n    regressor = tf.estimator.LinearRegressor(\r\n        feature_columns=[tf.feature_column.numeric_column('feats')],\r\n        optimizer='SGD',\r\n        config=config)\r\n\r\n    def input_fn():\r\n        dataset = tf.data.Dataset.from_tensors(({\"feats\": [1.]}, [1.]))\r\n        return dataset.repeat(1000).batch(10)\r\n\r\n    train_spec = tf.estimator.TrainSpec(\r\n        input_fn=input_fn,\r\n        max_steps=FLAGS.train_steps,\r\n        hooks=[]\r\n    )\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=input_fn)\r\n    tf.estimator.train_and_evaluate(regressor, train_spec, eval_spec)\r\n    print(\"---training finished---\")\r\n```\r\n\r\nThen I encountered the errors as follow:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/test-mutiworker-strategy.py\", line 318, in <module>\r\n    test()\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/test-mutiworker-strategy.py\", line 66, in test\r\n    config=config)\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py\", line 1369, in __init__\r\n    warm_start_from=warm_start_from)\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 183, in __init__\r\n    config, model_dir)\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1832, in maybe_overwrite_model_dir_and_session_config\r\n    config = run_config.RunConfig.replace(config, session_config=session_config)\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/run_config.py\", line 923, in replace\r\n    copy.deepcopy(self),\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"/root/PycharmProjects/urmsone-multi-gpu-tf-demo/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1542, in __deepcopy__\r\n    setattr(result, k, copy.deepcopy(v, memo))\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.lock objects\r\n```\r\n\r\nThe same code runs on Tensorflow v2.3  without this problem. \r\n\r\nIs this a bug in the  v2.4\uff1f\r\n\r\n", "comments": ["@UrmsOne,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "The complete code as follows:\r\n```\r\n# @Author: urmsone urmsone@163.com\r\n# @Date: 12/22/20 20:37\r\n# @Name: github-issue\r\n# @Description\r\n\r\nimport os\r\nimport json\r\nimport argparse\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef multi_worker_strategy_estimator():\r\n    try:\r\n        mirrored_strategy = tf.distribute.MultiWorkerMirroredStrategy()\r\n    except Exception as e:\r\n        print(\"Error: \", e)\r\n        mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n    config = tf.estimator.RunConfig(train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\r\n    regressor = tf.estimator.LinearRegressor(\r\n        feature_columns=[tf.feature_column.numeric_column('feats')],\r\n        optimizer='SGD',\r\n        config=config)\r\n\r\n    def input_fn():\r\n        dataset = tf.data.Dataset.from_tensors(({\"feats\": [1.]}, [1.]))\r\n        return dataset.repeat(1000).batch(10)\r\n\r\n    train_spec = tf.estimator.TrainSpec(\r\n        input_fn=input_fn,\r\n        max_steps=FLAGS.train_steps,\r\n        hooks=[]\r\n    )\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=input_fn)\r\n    tf.estimator.train_and_evaluate(regressor, train_spec, eval_spec)\r\n    print(\"---training finished---\")\r\n\r\n\r\ndef init_env():\r\n    if not os.environ.get('TF_CONFIG'):\r\n        # cluster = {'worker': ['localhost:2220', 'localhost:2221', 'localhost:2222'], }\r\n        cluster = {'chief': ['localhost:2220'], 'worker': ['localhost:2221', 'localhost:2222'], }\r\n        # cluster = {'chief': ['localhost:2220'], }\r\n\r\n        os.environ['TF_CONFIG'] = json.dumps({\r\n            'cluster': cluster,\r\n            'task': {'type': FLAGS.job_name, 'index': FLAGS.task_index}\r\n        })\r\n    print(os.environ.get('TF_CONFIG'))\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--batch_size', default=100, type=int, help='batch size')\r\n    parser.add_argument('--train_steps', default=3000, type=int,\r\n                        help='number of training steps')\r\n    parser.add_argument('--job_name', type=str, help='job_name')  # worker\r\n    parser.add_argument('--task_index', type=int, help='task_index')\r\n    parser.add_argument('--save_checkpoints_steps', default=500, type=int, help='save_checkpoints_steps')\r\n    parser.add_argument('--save_checkpoints_secs', default=60 * 10, type=int, help='save_checkpoints_secs')\r\n    parser.add_argument('--keep_checkpoint_max', default=2, type=int, help='keep_checkpoint_max')\r\n    parser.add_argument('--num_gpus_per_worker', default=0, type=int, help='num_gpus_per_worker')\r\n    FLAGS, unparsed = parser.parse_known_args()\r\n\r\n    init_env()\r\n    multi_worker_strategy_estimator()\r\n\r\n```\r\n\r\nQuick run on docker\r\n```\r\nroot@ubuntu:/home/prometheus# docker run -it --name tf-24 -v /root/PycharmProjects/urmsone-multi-gpu-tf-demo:/home/tf  tensorflow/tensorflow:2.3.0-gpu /bin/bash\r\n\r\n________                               _______________                \r\n___  __/__________________________________  ____/__  /________      __\r\n__  /  _  _ \\_  __ \\_  ___/  __ \\_  ___/_  /_   __  /_  __ \\_ | /| / /\r\n_  /   /  __/  / / /(__  )/ /_/ /  /   _  __/   _  / / /_/ /_ |/ |/ / \r\n/_/    \\___//_/ /_//____/ \\____//_/    /_/      /_/  \\____/____/|__/\r\n\r\n\r\nWARNING: You are running this container as root, which can cause new files in\r\nmounted volumes to be created as the root user on your host machine.\r\n\r\nTo avoid this, run the container by specifying your user's userid:\r\n\r\n$ docker run -u $(id -u):$(id -g) args...\r\n\r\nroot@05246d8eb041:/# cd /home/tf/\r\nroot@05246d8eb041:/home/tf# python github-issue.py --task_index=0 --job_name=chief > /tmp/chief-0.log 2>&1\r\nroot@05246d8eb041:/home/tf# python github-issue.py --task_index=0 --job_name=worker > /tmp/worker-0.log 2>&1\r\nroot@05246d8eb041:/home/tf# python github-issue.py --task_index=1 --job_name=worker > /tmp/worker-1.log 2>&1\r\n```\r\n\r\nOutput logs as follows:\r\n```\r\nroot@7363a4713c6f:/home/tf# tail -fn 100 /tmp/worker-1.log \r\n2020-12-22 12:47:22.825393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-12-22 12:47:23.766955: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-22 12:47:23.767090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-12-22 12:47:23.767110: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: UNKNOWN ERROR (-1)\r\n2020-12-22 12:47:23.767124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7363a4713c6f): /proc/driver/nvidia/version does not exist\r\n2020-12-22 12:47:23.767672: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-22 12:47:23.767936: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-22 12:47:23.770861: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:2220}\r\n2020-12-22 12:47:23.770893: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2221, 1 -> localhost:2222}\r\n2020-12-22 12:47:23.771081: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:2222\r\n{\"cluster\": {\"chief\": [\"localhost:2220\"], \"worker\": [\"localhost:2221\", \"localhost:2222\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}\r\nTraceback (most recent call last):\r\n  File \"github-issue.py\", line 62, in <module>\r\n    multi_worker_strategy_estimator()\r\n  File \"github-issue.py\", line 19, in multi_worker_strategy_estimator\r\n    config=config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\", line 1369, in __init__\r\n    warm_start_from=warm_start_from)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 183, in __init__\r\n    config, model_dir)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1832, in maybe_overwrite_model_dir_and_session_config\r\n    config = run_config.RunConfig.replace(config, session_config=session_config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/run_config.py\", line 923, in replace\r\n    copy.deepcopy(self),\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1542, in __deepcopy__\r\n    setattr(result, k, copy.deepcopy(v, memo))\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.lock objects\r\n```", "I encountered the same problem, Is this a bug in the Tensorflow v2.4\uff1f", "I used tf.distribute.experimental.MultiWorkerMirroredStrategy() in TF v2.4 :\r\nmirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()", "@UrmsOne,\r\nThe code you've provided runs indefinitely without messages in the output log. Could you please provide a minimal code snippet to reproduce the issue? Thanks! ", "@amahendrakar:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb\r\ntry: multi_worker_with_estimator.py in TF2.4\r\n", "> The code you've provided runs indefinitely without messages in the output log. Could you please provide a minimal code snippet to reproduce the issue? Thanks!\r\n\r\n@UrmsOne,\r\nAny updates regarding this? \r\n\r\n@jbcaep,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track your issue separately. \r\n\r\nThanks!", "@amahendrakar \r\n\r\nI also use this code  thar I provided for test\uff0c and met the error `TypeError: can't pickle _thread.lock objects` in TF-2.4.", "Was able to reproduce the issue with TF v2.4 and TF-nightly. \r\n- [worker-1.log](https://github.com/tensorflow/tensorflow/files/5844222/worker-1.log)\r\n- [worker-0.log](https://github.com/tensorflow/tensorflow/files/5844223/worker-0.log)\r\n- [chief-0.log](https://github.com/tensorflow/tensorflow/files/5844224/chief-0.log)\r\n\r\n\r\nWhereas with TF v2.3 the script throws an `Aborted (core dumped)` error. \r\n![Screenshot 2021-01-20 at 10 13 21 PM](https://user-images.githubusercontent.com/57165142/105213379-a48d7500-5b74-11eb-8e89-8af4d2410182.png)\r\n\r\nPlease check the attached logs and screenshot for reference. Thanks!", "I am also seeing this exact issue. Is there a workaround?", "Current suggestion is to use `tf.compat.v1.disable_eager_execution()`\r\nOther workarounds can be found in duplicate thread #46556", "Estimator + MultiWorkerMirroredStrategy in **eager** mode is not a blessed path. Please either use the workaround mentioned above or use Keras. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45918\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45918\">No</a>\n"]}, {"number": 45917, "title": "SavedModelBundle.java do not has serialize\uff0cso in spark do not broadcast the load model, only run local or one executor ", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/SavedModelBundle.java\r\n\r\n", "comments": ["@chlyzzo,\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nand also the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45917\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45917\">No</a>\n"]}, {"number": 45916, "title": "Survival/Drop Connect Rate (aka Stochastic Depth) is not implemented in tf.keras.applications.efficientnet", "body": "In the original implementation, [the `drop_connect` function](https://github.com/tensorflow/tpu/blob/341c3b628409a03b74d2d66d33fd09532690e04e/models/official/efficientnet/utils.py#L276-L291) is implemented in the following way:\r\n\r\n```python\r\ndef drop_connect(inputs, is_training, survival_prob):\r\n  \"\"\"Drop the entire conv with given survival probability.\"\"\"\r\n  # \"Deep Networks with Stochastic Depth\", https://arxiv.org/pdf/1603.09382.pdf\r\n  if not is_training:\r\n    return inputs\r\n\r\n  # Compute tensor.\r\n  batch_size = tf.shape(inputs)[0]\r\n  random_tensor = survival_prob\r\n  random_tensor += tf.random_uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\r\n  binary_tensor = tf.floor(random_tensor)\r\n  # Unlike conventional way that multiply survival_prob at test time, here we\r\n  # divide survival_prob at training time, such that no addition compute is\r\n  # needed at test time.\r\n  output = tf.div(inputs, survival_prob) * binary_tensor\r\n  return output\r\n```\r\n\r\nThis function is used to decide whether to keep a block or not with a given probability `p_l`; this described in depth in [the original paper](https://arxiv.org/abs/1603.09382). \r\n\r\nLooking at the `tf.keras.applications.efficientnet` implementation, we can notice that the value is used as a dropout rate instead:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5855c1c8ae2d2b36bf9d6f906b717046bb4afb36/tensorflow/python/keras/applications/efficientnet.py#L349-L353\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5855c1c8ae2d2b36bf9d6f906b717046bb4afb36/tensorflow/python/keras/applications/efficientnet.py#L413-L423\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5855c1c8ae2d2b36bf9d6f906b717046bb4afb36/tensorflow/python/keras/applications/efficientnet.py#L514-L517\r\n\r\n\r\nThe difference in implementation would be that the connection dropped is at a module level in the original implementation and at a unit level in the `tf.keras.applications` implementation.", "comments": ["I realized that the `noise_shape=(None, 1, 1, 1)` accomplishes the same as stochastic depth, so the keras implementation is indeed correct. My apologies.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45916\">No</a>\n"]}, {"number": 45915, "title": "tf.train.Saver and saver.restore do not work when data_augmentation_options rgb_to_gray and random_vertical_flip are configured in the pipeline config file", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No (but added a workaround to overcome first issue which will be explained)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13.2 (also with 1.14.0)\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI am using object detection api and training my model using faster_rcnn_resnet152. Training and evaluation worked fine until I added below data augmentation options in the pipeline config file. The evaluation script (I am using old eval.py on purpose) fails with below error. The error seems to be due to rgb_to_gray option. Pipeline config file has also subtract_channel_mean  and random_horizontal_flip options, however they work fine until the other two configurations are added. To overcome the error I added \"reshape=True\" argument to saver = tf.train.Saver(variables_to_restore) line in the legcy/evaluator.py line 270 and it started to work if only saver.restore(sess, latest_checkpoint) is commented out in the line 274. When the line is enabled this time it throws the second exception given below. Could you propose a solution/workaround without having to upgrade tensorflow/python etc versions?\r\n\r\n  data_augmentation_options {\r\n    rgb_to_gray {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    random_vertical_flip {\r\n    }\r\n\r\nERROR:1\r\n------------------------------\r\nAssign requires shapes of both tensors to match. lhs shape= [7,7,3,64] rhs shape= [7,7,1,64]\r\n         [[node save/Assign_780 (defined at /truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py:270) ]]\r\n\r\nCaused by op 'save/Assign_780', defined at:\r\n  File \"legacy/eval.py\", line 149, in <module>\r\n    tf.app.run()\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"legacy/eval.py\", line 145, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py\", line 270, in evaluate\r\n    saver = tf.train.Saver(variables_to_restore)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\r\n    self.build()\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 73, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 223, in assign\r\n    validate_shape=validate_shape)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 64, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nAssign requires shapes of both tensors to match. lhs shape= [7,7,3,64] rhs shape= [7,7,1,64]\r\n         [[node save/Assign_780 (defined at /truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py:270) ]]\r\n------------------------------------------\r\n\r\nERROR:2\r\n----------------------------------------------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n  File \"legacy/eval.py\", line 154, in <module>\r\n    tf.app.run()\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"legacy/eval.py\", line 150, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py\", line 302, in evaluate\r\n    eval_export_path=eval_config.export_path)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/eval_util.py\", line 519, in repeated_checkpoint_run\r\n    process_metrics_fn=process_metrics_fn)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/eval_util.py\", line 314, in _run_checkpoint_once\r\n    restore_fn(sess)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py\", line 280, in _restore_latest_checkpoint\r\n    saver.restore(sess, latest_checkpoint)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1312, in restore\r\n    err, \"a mismatch between the current graph and the graph\")\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nInput to reshape is a tensor with 3136 values, but the requested shape has 9408\r\n         [[node save/Reshape_780 (defined at /truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py:270) ]]\r\n\r\nCaused by op 'save/Reshape_780', defined at:\r\n  File \"legacy/eval.py\", line 154, in <module>\r\n    tf.app.run()\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"legacy/eval.py\", line 150, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py\", line 270, in evaluate\r\n    saver = tf.train.Saver(var_list=variables_to_restore,reshape=True)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\r\n    self.build()\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 68, in restore\r\n    restored_tensor = array_ops.reshape(restored_tensor, restored_shapes[0])\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\r\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/truba/home/iuzun/anaconda3/envs/tensorflow_cpu1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nInput to reshape is a tensor with 3136 values, but the requested shape has 9408\r\n         [[node save/Reshape_780 (defined at /truba/home/iuzun/Tensorflow/models/research/object_detection/legacy/evaluator.py:270) ]]\r\n----------------------------------------------------------------------------------------------------------\r\n\r\nExecuted command:\r\npython legacy/eval.py --logtostderr --pipeline_config_path=training/faster_rcnn_resnet152_coco.config --checkpoint_dir=training/ --eval_dir=eval/\r\n\r\nThanks in advance", "comments": ["@smeyg,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.4 and check if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45915\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45915\">No</a>\n"]}, {"number": 45914, "title": "TF 2.4 shows shape mismatch where 2.3.1 did not", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.4\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\ni_model = Model([obs1.input, obs2.input], x, name='icm_inverse_model') returns a shape mismatch under the current version of tensorflow.\r\n\r\n\r\nNo mismatch should be given as was the case in version 2.3.1 unless I am missing somthing...\r\n\r\n```from keras.models import Model, Sequential\r\nfrom keras.layers import Input, Concatenate, GRU, Dense, Reshape\r\nfrom keras.optimizers import Adam\r\nfrom keras.backend import clear_session\r\nfrom pathlib import Path\r\nfrom subprocess import Popen, PIPE, STDOUT, TimeoutExpired\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom rl.agents import SARSAAgent\r\nfrom rl.policy import BoltzmannQPolicy\r\nimport os\r\n\r\ncmd = 'echo Hello World!'\r\nenv_reward = 0\r\nlength_penalty = .25\r\nlearning_reward = 10\r\n\r\nhidden_layers = 4\r\nlayer_neurons = 128\r\nlearning_rate = 0.001\r\nnb_actions = 96\r\n\r\ntf.get_logger().setLevel('ERROR')\r\n\r\ndone = False\r\ncmd_in = True\r\nobs_last = None\r\ninitialize = True\r\n\r\nwhile True:\r\n    if cmd_in:\r\n        proc = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)\r\n        try:\r\n            stdout = proc.communicate(timeout=1)[0].decode()\r\n            exitcode = proc.returncode\r\n        except TimeoutExpired:\r\n            proc.kill()\r\n            stdout = proc.communicate()[0].decode()\r\n            exitcode = proc.returncode\r\n        nnin = ''.join(char for char in stdout if char.isprintable())\r\n        filename = Path('mem.txt')\r\n        filename.touch(exist_ok=True)\r\n        if not nnin:\r\n            nnin = 'Done!'\r\n            stdout = nnin\r\n        if exitcode == 0:\r\n            done = True\r\n            with open('mem.txt', 'r+') as mem:\r\n                for line in stdout.splitlines():\r\n                    if line + '\\n' not in mem:\r\n                        mem.write(line + '\\n')\r\n                        env_reward += learning_reward\r\n        cmd = ''\r\n        print('\\n')\r\n        print(stdout)\r\n        print('# ', end='', flush=True)\r\n    else:\r\n        nnin = cmd\r\n        print(nnin[-1], end='', flush=True)\r\n        env_reward -= length_penalty\r\n    idxs = (np.frombuffer(nnin.encode(), dtype=np.uint8) - 32) / 100 \r\n    env = tf.reshape(idxs, idxs.shape + (1,))\r\n    shape = env.shape\r\n\r\n\r\n    def build_actor_model(shape, nb_actions):\r\n        model = Sequential()\r\n        model.add(Reshape(shape[1::], input_shape=shape))\r\n        for layer in range(hidden_layers):\r\n            model.add(GRU(layer_neurons, name='GRU' + str(layer), return_sequences=True))\r\n        model.add(GRU(layer_neurons, name='GRU' + str(hidden_layers)))\r\n        model.add(Dense(nb_actions, name='output', activation='softmax'))\r\n        return model\r\n\r\n\r\n    def build_main(shape, name_prefix='main.'):\r\n        inputs = Input(shape=shape)\r\n        x = inputs\r\n        for layer in range(hidden_layers):\r\n            x = GRU(layer_neurons, name=name_prefix + ('GRU' + str(layer)), return_sequences=True)(x)\r\n        x = GRU(layer_neurons, name=name_prefix + ('GRU' + str(hidden_layers)))(x)\r\n        model = Model(inputs, x, name=name_prefix + 'main')\r\n        return model\r\n\r\n\r\n    def build_inverse_model(obs1, obs2, nb_actions):\r\n        x = Concatenate()([obs1.output, obs2.output])\r\n        x = Dense(nb_actions, name='icm_i.output', activation='sigmoid')(x)\r\n        i_model = Model([obs1.input, obs2.input], x, name='icm_inverse_model')\r\n        return i_model\r\n\r\n\r\n    def build_forward_model(obs1, nb_actions):\r\n        act1 = Input(shape=nb_actions)\r\n        x = Concatenate()([obs1.output, act1])\r\n        output_shape = obs1.output_shape[1]\r\n        x = Dense(output_shape, name='icm_f.output', activation='linear')(x)\r\n        f_model = Model([obs1.input, act1], x, name='icm_forward_model')\r\n        return f_model\r\n\r\n\r\n    inv_weights_fname = '{}_inv_weights.h5f'.format(\"SMB\")\r\n    fwd_weights_fname = '{}_fwd_weights.h5f'.format(\"SMB\")\r\n    agent_weights_fname = '{}_agent_weights.h5f'.format(\"SMB\")\r\n\r\n    main = build_main(shape)\r\n    main2 = build_main(shape, name_prefix='main2.')\r\n    inverse_model = build_inverse_model(main, main2, nb_actions)\r\n    inverse_model.compile(Adam(learning_rate), loss='mse', metrics=['mse'])\r\n    forward_model = build_forward_model(main, nb_actions)\r\n    forward_model.compile(Adam(learning_rate), loss='mse', metrics=['mse'])\r\n    model = build_actor_model((1,) + shape, nb_actions)\r\n    policy = BoltzmannQPolicy()\r\n    agent = SARSAAgent(model=model, nb_actions=nb_actions, policy=policy)\r\n    agent.compile(Adam(learning_rate), metrics=['mae'])\r\n    agent.reset_states()\r\n\r\n    if initialize:\r\n        if os.path.isfile(inv_weights_fname):\r\n            inverse_model.load_weights(inv_weights_fname)\r\n        if os.path.isfile(fwd_weights_fname):\r\n            forward_model.load_weights(fwd_weights_fname)\r\n        if os.path.isfile(agent_weights_fname):\r\n            agent.load_weights(agent_weights_fname)\r\n        initialize = False\r\n    agent.training = True\r\n\r\n    obs_now = env\r\n    if obs_last is None:\r\n        obs_last = obs_now\r\n    action = agent.forward(obs_now)\r\n    icm_action = np.zeros(nb_actions)\r\n    icm_action[action] = 1\r\n    inv_loss = inverse_model.train_on_batch([np.expand_dims(obs_last, 0), np.expand_dims(obs_now, 0)],\r\n                                            [np.expand_dims(icm_action, 0)])\r\n    features_now = main.predict(np.expand_dims(obs_now, 0))\r\n    fwd_loss = forward_model.train_on_batch([np.expand_dims(obs_last, 0), np.expand_dims(icm_action, 0)],\r\n                                            [features_now])\r\n    obs_last = obs_now\r\n    r_intr = (fwd_loss[0] ** 0.5) / 100\r\n    reward = r_intr + env_reward\r\n    agent.backward(reward, done)\r\n    clear_session()\r\n    done = False\r\n\r\n    enc_ascii = action + 32\r\n    if enc_ascii != 127:\r\n        cmd += chr(enc_ascii)\r\n        cmd_in = False\r\n        continue\r\n    cmd_in = True\r\n    inverse_model.save_weights(inv_weights_fname, overwrite=True)\r\n    forward_model.save_weights(fwd_weights_fname, overwrite=True)\r\n    agent.save_weights(agent_weights_fname, overwrite=True)```", "comments": ["Hi I am new to the Open source community & I would like to contribute, but i'm not able to understand where or how to start.\r\nCan anyone pls help me out with this.", "@MaruthiKo hello,\r\nIf you are new to open source then this is definitely not the repo you would contribute.\r\nStart with some small repo, explore issues with good first issue tags.", "Was able to reproduce the issue with [TF v2.4](https://colab.research.google.com/gist/amahendrakar/3253281273502be86c8135a345009a17/45914.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/9efb46c1fce066ad7a9fb1a47de9558d/45914-tf-nightly.ipynb). \r\n\r\nHowever with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/f0052d4fa4f99c4d771a9e4e07244696/45914-2-3.ipynb), I did not face any errors. Please check the linked gist for reference. Thanks!", "Checked changelog and I was able to get the model working by passing the input_spec = None parameter to the forward and inverse model, but this still seams to be a bizarre behavior.", "This is most likely intended. TF 2.4 started enforcing shape assumptions checking, causing layers that were called on incorrectly shaped inputs to fail with a clear error message. If the model was working previously, it was by accident, likely thanks to broadcasting.\r\n\r\nWhat's the error message?", "@GooseXP,\r\nCan you please respond to [@fchollet's message](https://github.com/tensorflow/tensorflow/issues/45914#issuecomment-756373652)? Thanks!  ", "@rmothukuru @fchollet Thank you both for your help but as stated previously I checked the changelog and resolved the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45914\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45914\">No</a>\n"]}, {"number": 45913, "title": "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\cloudpickle-1.6.0.dist-info\\\\direct_url.json' Consider using the `--user` option or check the permissions", "body": "i am facing this issue while intalling rasa", "comments": ["@AHSANFAROOQ1999,\r\nInstallation issues within the Anaconda environment are tracked in the Anaconda repo.\r\n\r\nCould you please submit a new issue using [this link](https://github.com/ContinuumIO/anaconda-issues/issues) and fill in the template, so that the issue can be tracked there. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45912, "title": "[Intel MKL] unit test for bfloat16 on addN, relu, gelu etc", "body": "", "comments": ["@noim210  Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@noim210  Any update on this PR? Please. Thanks!\r\n", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 45911, "title": "Important performance difference between training and evaluation mode", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7\r\n\r\nTraining a model using .fit method, there is an important difference of performance between training and validation even if the train split is also used for validation. The difference is the training and testing mode for the batchnorm but this should not give a difference in performance.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\n\r\nclass Residual3x3Unit(tf.keras.layers.Layer):\r\n    def __init__(self, channels_in, channels_out, stride, droprate=0., activate_before_residual=False):\r\n        super(Residual3x3Unit, self).__init__()\r\n        self.bn_0 = tf.keras.layers.BatchNormalization(momentum=0.999)\r\n        self.relu_0 = tf.keras.layers.LeakyReLU(alpha=0.1)\r\n        self.conv_0 = tf.keras.layers.Conv2D(channels_out, kernel_size=3, strides=stride, padding='same', use_bias=False)\r\n        self.bn_1 = tf.keras.layers.BatchNormalization(momentum=0.999)\r\n        self.relu_1 = tf.keras.layers.LeakyReLU(alpha=0.1)\r\n        self.conv_1 = tf.keras.layers.Conv2D(channels_out, kernel_size=3, strides=1, padding='same', use_bias=False)\r\n        self.downsample = channels_in != channels_out\r\n        self.shortcut = tf.keras.layers.Conv2D(channels_out, kernel_size=1, strides=stride, use_bias=False)\r\n        self.activate_before_residual = activate_before_residual\r\n        self.dropout = tf.keras.layers.Dropout(rate=droprate)\r\n        self.droprate = droprate\r\n\r\n    def call(self, x, training=True):\r\n        if self.downsample and self.activate_before_residual:\r\n            x = self.relu_0(self.bn_0(x, training=training))\r\n        elif not self.downsample:\r\n            out = self.relu_0(self.bn_0(x, training=training))\r\n        out = self.relu_1(self.bn_1(self.conv_0(x if self.downsample else out), training=training))\r\n        if self.droprate > 0.:\r\n            out = self.dropout(out)\r\n        out = self.conv_1(out)\r\n        return out + (self.shortcut(x) if self.downsample else x)\r\n\r\n\r\nclass ResidualBlock(tf.keras.layers.Layer):\r\n    def __init__(self, n_units, channels_in, channels_out, unit, stride, droprate=0., activate_before_residual=False):\r\n        super(ResidualBlock, self).__init__()\r\n        self.units = self._build_unit(n_units, unit, channels_in, channels_out, stride, droprate, activate_before_residual)\r\n\r\n    def _build_unit(self, n_units, unit, channels_in, channels_out, stride, droprate, activate_before_residual):\r\n        units = []\r\n        for i in range(n_units):\r\n            units.append(unit(channels_in if i == 0 else channels_out, channels_out, stride if i == 0 else 1, droprate, activate_before_residual))\r\n        return units\r\n\r\n    def call(self, x, training=True):\r\n        for unit in self.units:\r\n            x = unit(x, training=training)\r\n        return x\r\n\r\n\r\nclass WideResNet(tf.keras.Model):\r\n    def __init__(self, num_classes, depth=28, width=2, droprate=0., input_shape=(None, 32, 32, 3), **kwargs):\r\n        super(WideResNet, self).__init__(input_shape, **kwargs)\r\n        assert (depth - 4) % 6 == 0\r\n        N = int((depth - 4) / 6)\r\n        channels = [16, 16 * width, 32 * width, 64 * width]\r\n\r\n        self.conv_0 = tf.keras.layers.Conv2D(channels[0], kernel_size=3, strides=1, padding='same', use_bias=False)\r\n        self.block_0 = ResidualBlock(N, channels[0], channels[1], Residual3x3Unit, 1, droprate, True)\r\n        self.block_1 = ResidualBlock(N, channels[1], channels[2], Residual3x3Unit, 2, droprate)\r\n        self.block_2 = ResidualBlock(N, channels[2], channels[3], Residual3x3Unit, 2, droprate)\r\n        self.bn_0 = tf.keras.layers.BatchNormalization(momentum=0.999)\r\n        self.relu_0 = tf.keras.layers.LeakyReLU(alpha=0.1)\r\n        self.avg_pool = tf.keras.layers.AveragePooling2D((8, 8), (1, 1))\r\n        self.flatten = tf.keras.layers.Flatten()\r\n        self.dense = tf.keras.layers.Dense(num_classes, activation='softmax')\r\n\r\n    def call(self, inputs, training=True):\r\n        x = inputs\r\n        x = self.conv_0(x)\r\n        x = self.block_0(x, training=training)\r\n        x = self.block_1(x, training=training)\r\n        x = self.block_2(x, training=training)\r\n        x = self.relu_0(self.bn_0(x, training=training))\r\n        x = self.avg_pool(x)\r\n        x = self.flatten(x)\r\n        x = self.dense(x)\r\n        return x\r\n\r\ntrain_ds = tfds.load('cifar10', split=\"train\")\r\n\r\ntest_ds = tfds.load('cifar10', split=\"train\")\r\n\r\ndef preprocess(ex):\r\n\r\n    image = tf.cast(ex['image'], tf.float32) / 255.\r\n    return image, ex['label']\r\n\r\ntrain_ds = train_ds.map(preprocess).shuffle(1024).repeat().batch(64)\r\ntest_ds = test_ds.map(preprocess).repeat().batch(64)\r\n\r\nmodel = WideResNet(10)\r\n\r\noptimizer = tf.keras.optimizers.SGD(0.03, momentum=0.9)\r\nmodel.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\r\n\r\nmodel.fit(train_ds, epochs=10, steps_per_epoch=100, validation_data=test_ds, validation_steps=100)\r\n```\r\n\r\nThe output is the following:\r\n\r\n```\r\nEpoch 1/10\r\n100/100 [==============================] - 15s 58ms/step - loss: 1.9948 - accuracy: 0.2491 - val_loss: 3.6047 - val_accuracy: 0.1061\r\nEpoch 2/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.6504 - accuracy: 0.3899 - val_loss: 2.1616 - val_accuracy: 0.2086\r\nEpoch 3/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.4418 - accuracy: 0.4759 - val_loss: 5.3945 - val_accuracy: 0.1839\r\nEpoch 4/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.3975 - accuracy: 0.4871 - val_loss: 2.5811 - val_accuracy: 0.2809\r\nEpoch 5/10\r\n100/100 [==============================] - 5s 52ms/step - loss: 1.2669 - accuracy: 0.5371 - val_loss: 2.1341 - val_accuracy: 0.3431\r\nEpoch 6/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.1513 - accuracy: 0.5834 - val_loss: 3.0617 - val_accuracy: 0.3303\r\nEpoch 7/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.1181 - accuracy: 0.5982 - val_loss: 2.0735 - val_accuracy: 0.4008\r\nEpoch 8/10\r\n100/100 [==============================] - 5s 51ms/step - loss: 1.0284 - accuracy: 0.6285 - val_loss: 3.5450 - val_accuracy: 0.3250\r\nEpoch 9/10\r\n100/100 [==============================] - 5s 49ms/step - loss: 1.0219 - accuracy: 0.6352 - val_loss: 1.9222 - val_accuracy: 0.4300\r\nEpoch 10/10\r\n100/100 [==============================] - 5s 49ms/step - loss: 0.9897 - accuracy: 0.6519 - val_loss: 2.6546 - val_accuracy: 0.4075\r\n```", "comments": ["@guillaumelorre28,\r\nI did not face any issues while running the code with TF v2.4. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/22ec2955a2808e556b211932e6baeff5/45911.ipynb). \r\n\r\nCould you please let us know the expected behavior of the code, so that we can look into it? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45911\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45911\">No</a>\n"]}, {"number": 45910, "title": "TF-TRT conversion failing (maybe because of 2GB limit on GraphDef)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu Linux 16.04\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: RTX 2080\r\n\r\n**Describe the current behavior**\r\nWhile trying to convert a RoBERTa model to TRT, it throws an error: `KeyError: \"The name 'input_word_ids:0' refers to a Tensor which does not exist. The operation, 'input_word_ids', does not exist in the graph.\"`\r\n\r\nBut after checking with `saved_model_cli`, it is indeed part of the graph. Investigating a bit further, this might happen because of another (previous) error:\r\n\r\n```\r\n[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/message_lite.cc:406] tensorflow.GraphDef exceeded maximum protobuf size of 2GB: 2222908841\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should convert it to TRT, as it successfully happens when using a smaller model (e.g. `DistilRoBERTa`).\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nconverter = trt.TrtGraphConverterV2(\r\n    input_saved_model_dir=<saved model directory>, \r\n    conversion_params=trt.TrtConversionParams()\r\n)\r\n\r\nconverter.convert()\r\nconverter.save(<output dir>)\r\n```\r\n\r\nAdditional info:\r\nRelated to https://github.com/tensorflow/tensorrt/issues/229", "comments": ["@dshahrokhian,\r\nCould you please provide the saved model files you are using in the code, so that we can reproduce the issue on our end.\r\n\r\nAlso, please update TensorFlow to v2.4 and check if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45910\">No</a>\n", "@amahendrakar can confirm that the issue goes away on TF 2.4. Thank you for the help.", ">     input_saved_model_dir=<saved model directory>,\r\n\r\n@dshahrokhian,\r\nIn order to reproduce the issue, could you please share the contents of the `saved model directory` folder with us.\r\n\r\nAlternatively, you can update TensorFlow on your machine using the below command and check if it works.\r\n\r\n```\r\npip3 install --upgrade tensorflow\r\n```\r\n\r\n Thanks!", "This error does not happen with TF 2.4, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45910\">No</a>\n"]}, {"number": 45909, "title": "asdasdas", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["spam"]}]