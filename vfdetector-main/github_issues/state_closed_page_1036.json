[{"number": 22241, "title": "Update RELEASE.md", "body": "Update RELEASE.md to have 1.10.1 patch information.", "comments": []}, {"number": 22240, "title": "absl/strings/string_view.h: No such file or directory", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n- **TensorFlow version (use command below)**:\r\nLatest \r\n- **Python version**: 2.7\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI am trying to build tensorflow as a standalone project and have been following this tutorial:\r\nhttps://tuatini.me/building-tensorflow-as-a-standalone-project/\r\n\r\nEverything is working till I try to run the script. I get the following error:\r\n\r\ng++ -std=c++11 -Wl,-rpath='$ORIGIN/lib' -Iinclude -Llib main.cpp -ltensorflow_cc -o exec\r\nIn file included from include/tensorflow/core/platform/tensor_coding.h:22:0,\r\n                 from include/tensorflow/core/framework/resource_handle.h:19,\r\n                 from include/tensorflow/core/framework/allocator.h:24,\r\n                 from include/tensorflow/core/framework/tensor.h:20,\r\n                 from include/tensorflow/cc/framework/ops.h:21,\r\n                 from include/tensorflow/cc/client/client_session.h:24,\r\n                 from main.cpp:9:\r\ninclude/tensorflow/core/lib/core/stringpiece.h:34:38: fatal error: absl/strings/string_view.h: No such file or directory\r\n #include \"absl/strings/string_view.h\"\r\n                                      ^\r\nAny work around for this? Thanks!\r\n\r\n\r\n\r\n", "comments": ["Hi @roshan-dongre does the branch you're building from have https://github.com/tensorflow/tensorflow/commit/6f0c8af9c853e4d9d4cf336101cb21d619410238?", "Hi @av8ramit I'm currently on commit 506335d", "So yea it should I pulled only a few hours ago", "@angersson are all bugfixes in the r1.11 branch in master? Any idea as to why this error occurs?", "I had to include tensorflow/contrib/makefile/downloads/absl in my header search paths and that worked for me.", "@av8ramit is there a way to build tensorflow without creating the project inside the tensorflow repo and using bazel? I have working with a really large code base and bazel integration is unfortunately not possible. With bazel inside the repo it works but I need to be able to move it outside the repo. Thanks!", "had the same problem (on my Raspberry Pi) with build pi_examples/label_image by adding -I$(DOWNLOADSDIR)/absl to Makefile it worked.\r\n", "Nothing else I know of on Ubuntu unfortunately.", "This should now be resolved at head for desktop operating systems.\r\n@petewarden to check on raspberry pi.", "What commit should we checkout for v1.11 to build without this issue? Both the v1.11 tag and the branch are affected by this issue and the master's head (at least where it was 10 hours ago when I checked it out) had a different issue that broke builds via CMake.", "Tip of the 1.11 branch should be free of this problem, I think.\nYou can also use the tag for 1.11.0 release.\n\nOn Fri, Oct 5, 2018 at 12:26 AM GPhilo <notifications@github.com> wrote:\n\n> What commit should we checkout for v1.11 to build without this issue? Both\n> the v1.11 tag and the branch are affected by this issue and the master's\n> head (at least where it was 10 hours ago when I checked it out) had a\n> different issue that broke builds via CMake.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22240#issuecomment-427270426>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOca_Mfdzgtm5oAq47UB-JTV_gBh3ks5uhwmpgaJpZM4WmCRZ>\n> .\n>\n", "I used the tag to checkout 1.11.0 originally but I ran into this issue, I thought the commit with the fix was introduced later. Currently I went back to 1.10 and rebuilt that, I'll try again with 1.11 as soon as I have some time available", "I used the tag to checkout 1.11, ran into this, and was able to use beweinreich's workaround to build an iOS app.", "@angersson I thought this was resolved on 1.11?\r\nDid we forget to cherrypick the change?", "We wouldn't have been able to deploy 1.11 if the absl headers hadn't been included in the pip package or the headers hadn't been supported by Bazel.\r\n\r\nNote that this problem appears to be isolated to non-Bazel builds so far (the OP is running g++, RPi uses a Makefile, cmake is cmake, and I'm not sure what @lauriebyrum was using to build on iOS). Possibly there is something missing from TF's configure script or cmake scripts (like @beweinreich's header include) because our builds only test (and we only officially support) Bazel.", "I'm getting the same error while building on a raspberry pi (raspbian).  Realize @angersson said only Bazel is supported but just wanted to bump this in case others are having this issue too (@petewarden).  I will try the solution mentioned by @jrse \r\n\r\n> make -f tensorflow/contrib/pi_examples/label_image/Makefile\r\ngcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen/ -I/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto/ -I/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o\r\nIn file included from ./tensorflow/core/platform/tensor_coding.h:22:0,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from tensorflow/contrib/pi_examples/label_image/label_image.cc:33:\r\n./tensorflow/core/lib/core/stringpiece.h:29:38: fatal error: absl/strings/string_view.h: No such file or directory\r\n #include \"absl/strings/string_view.h\"\r\n                                      ^\r\ncompilation terminated.\r\ntensorflow/contrib/pi_examples/label_image/Makefile:79: recipe for target '/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o' failed\r\nmake: *** [/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o] Error 1\r\n\r\nedit: had to insert a quote to avoid losing all of the formatting above\r\n\r\nupdate: I got the makefile to finish without the fatal error by following jrse's recommendation above.  In case it helps others, I added \"-I$(DOWNLOADSDIR)/absl\" to the makefile right before the line \"LIBS := \\\" since that was the end of the \"includes\" section. I also had to add a backslash (a separator) to the line before the one i inserted as well.  _However_, I did get a screen full of errors about \"size_t\", like:\r\n\r\n> In file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:0:\r\n/usr/include/jpeglib.h:792:3: error: \u2018size_t\u2019 does not name a type\r\n   size_t free_in_buffer;        /* # of byte spaces remaining in buffer */\r\n   ^~~~~~\r\n\r\nI tried to run the example but it looks like the bin directory was not created..so i found this work around:\r\nhttps://github.com/tensorflow/tensorflow/issues/5200\r\nThe middle text replacement wasn't needed but the other two fixes allowed the makefile to finish without errors but there is still no \"bin\" directory so I still can't run it...\r\n\r\nI'm guessing it is related to this:\r\n\r\n> make: *** No rule to make target '/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/lib/libtensorflow-core.a', needed by '/home/pi/Documents/git/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/bin//label_image'.  Stop.\r\n\r\nupdate: I found the libtebsorflow-core.a should have been built using the command:\r\ntensorflow/contrib/makefile/build_all_linux.sh\r\nAccording to the instructions for a linux system (even though these instructions are different from the Raspberry Pi instructions.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile\r\n\r\nIts taking a while so I'll come back to this...\r\n\r\nUpdate: kept running out of memory so I increased the swap with this\r\n\r\nfree\r\ndd if=/dev/zero of=/var/swap.img bs=1024k count=1000\r\nmkswap /var/swap.img\r\nswapon /var/swap.img\r\nfree\r\n\r\nupdate: can't get the build_all_linux.sh to finish successfully, giving up on this method", "> I had to include tensorflow/contrib/makefile/downloads/absl in my header search paths and that worked for me.\r\n\r\nI'm on f905324 and cannot see any `downloads/` inside `tensorflow/contrib/makefile/`", "(@pbertoni ) did you find a solution for this?\r\n", "> > I had to include tensorflow/contrib/makefile/downloads/absl in my header search paths and that worked for me.\r\n> \r\n> I'm on [f905324](https://github.com/tensorflow/tensorflow/commit/f90532431c3785166cff35ff427b652fe460f60b) and cannot see any `downloads/` inside `tensorflow/contrib/makefile/`\r\n\r\nin contrib/makefile\uff0crun buildd_all_linux.sh", "Note that master branch no longer has contrib. If you rely on contrib being there, please move to newer APIs."]}, {"number": 22239, "title": "configure.gpu_options.per_process_gpu_memory_fraction = 1\uff0ccase OOM", "body": "### System information\r\n\r\n- **Have I written custom code**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux release 7.3.1611 (Core), but that does not matter\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.10.1-0-g4dcfddc5d1', '1.10.1')\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: docu issue\r\n\r\n### Describe the problem\r\n\r\nwhen use the code below to config the tensorflow session, will case an `CUDA_ERROR_OUT_OF_MEMORY` error.\r\n\r\n`configure.gpu_options.per_process_gpu_memory_fraction = 1`\r\n\r\n```\r\n2018-09-12 20:59:57.154299: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-12 20:59:57.409106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties:\r\nname: Tesla P40 major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:84:00.0\r\ntotalMemory: 22.38GiB freeMemory: 22.21GiB\r\n2018-09-12 20:59:57.409748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-12 20:59:59.004788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-12 20:59:59.005075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0\r\n2018-09-12 20:59:59.005126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N\r\n2018-09-12 20:59:59.008029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22912 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0, compute capability: 6.1)\r\n2018-09-12 20:59:59.015888: E tensorflow/stream_executor/cuda/cuda_driver.cc:903] failed to allocate 22.38G (24025956352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n```\r\n\r\n### Source code \r\n\r\n`cuda_driver.cc`\r\n\r\n```\r\nif (per_process_gpu_memory_fraction == 0) {\r\n    allocated_memory = available_memory;\r\n    const int64 min_system_memory = MinSystemMemory(available_memory);\r\n    if (min_system_memory < allocated_memory) {\r\n      allocated_memory -= min_system_memory;\r\n    }\r\n  } else {\r\n    allocated_memory = total_memory * per_process_gpu_memory_fraction;\r\n  }\r\n  *memory_limit = allocated_memory;\r\n```\r\n\r\ntensorflow set memory_limit by `total_memory * per_process_gpu_memory_fraction;` , this case the OOM error, I think, may be `free_memory * per_process_gpu_memory_fraction;` is better.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nGPU model and memory\nExact command to reproduce\nMobile device", "System information has updated.", "Using per_process_gpu_memory_fraction == 0 would grab all free memory which seems to be your intention. ", "Yes, as @azaks2 mentioned, if you want to use all available, set per_process_gpu_memory_fraction to 0. Using `free_memory * per_process_gpu_memory_fraction` will have unexpected behavior since multiple processes will get different actual number.", "@azaks2 @aaroey \r\nGTX 1080 has 8116 memory and I set per_process_gpu_memory_fraction=0.5, tensorflow use 4239MB,not the actual 8116/2=4058.\r\nWhy?", "@kasyoukin we use [cuMemGetInfo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_driver.cc#L1439) to get the total memory. Since I don't have that card, would you help to check what `cuMemGetInfo()` returns?\r\n\r\nThanks.", "@aaroey \r\ntotal 8510701568\r\nfree 7817658368\r\nwhen I set per_process_gpu_memory_fraction=0.5, tensorflow use 4239MB,not the actual 8116*0.5=4058.\r\nwhen I set per_process_gpu_memory_fraction=0.4 , tensorflow use 3427MB,not the actual 8116*0.4=3246.\r\n\r\nI found that tensorflow use extra 180MB memory\u3002and i don\u2018t know the reason\r\n\r\n", "Nagging Assignees @aaroey, @azaks2: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@kasyoukin may I ask where did you see the `4239MB` number? Is it from the log?", "@aaroey from the nvidia-smi", "@kasyoukin I see. The 4239MB includes the memory used to initialize CUDA runtime, which is not counted as the 50% per_process_gpu_memory_fraction. per_process_gpu_memory_fraction only includes memory that will be allocated by TF for computational purposes. So I think this is expected, and we don't know how much memory the CUDA runtime is going to take.", "I'm going to close this issue, feel free to comment if there are any other questions.", "I run into this issue through a 3rd party lib setting `per_process_gpu_memory_fraction=1` and checked the source: Why is the heuristic determining how much system memory is required not used here? Wouldn't it be better to always reduce the total_memory by the system memory and/or warn/error on `per_process_gpu_memory_fraction>=1`?"]}, {"number": 22238, "title": "TENSORFLOW quantize_graph.py throws error : Graph_def is invalid at node error", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:14.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:NA\r\n- **TensorFlow installed from (source or binary)**:PIP and BAZEL\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.15\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: NVIDIA 12GB\r\n\r\nERROR ::: Graph_def is invalid at node u'ExpandDims': Input tensor 'image_ph:0' Cannot convert a tensor of type float32 to an input of type int32\r\n\r\nI have trained a model , froze it and performed optimization (https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/) , graph transformation (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms) on tensorflow 1.4.0 till the point which there is no error but when i quantize the model i run into the above mentioned error.\r\n\r\nAs per https://github.com/tensorflow/tensorflow/issues/4044 i have tried maintaining version consistency which has failed to solve the issue.", "comments": ["Have you tried the latest TensorFlow version? ", "@wt-huang you want me to use latest tensorflow version for quantization only right?\r\nDo I need to train it from scratch and do all of the rest of the process on the latest version ?", "@Raj-08 you would need to use the latest TensorFlow version to train the model, freeze the graph, quantization etc.", "@wt-huang Same problem persists , i have tried all the processes on tensorflow 1.10\r\n\"Input 0 of node ExpandDims was passed float from image_ph incompatible with expected int32\"", "@Raj-08 I have gone through the steps of model training, freezing the graph and quantization without any issues. Can you list the commands you used also update the above spec sheet with the versions you used?", "I am using default commands given by tensorflow:\r\n\r\n`bazel build tensorflow/python/tools:optimize_for_inference\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n--input=/tf_files/retrained_graph.pb \\\r\n--output=/tf_files/optimized_graph.pb \\\r\n--input_names=Mul \\\r\n--output_names=final_result`\r\n\r\n\r\n`bazel build tensorflow/tools/quantization:quantize_graph\r\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n--input=/tf_files/optimized_graph.pb \\\r\n--output=/tf_files/rounded_graph.pb \\\r\n--output_node_names=final_result \\\r\n--mode=weights_rounded`\r\n\r\n`bazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=tensorflow_inception_graph.pb \\\r\n--out_graph=optimized_inception_graph.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs='softmax:0' \\\r\n--transforms='\r\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\nremove_nodes(op=Identity, op=CheckNumerics)\r\nfold_old_batch_norms\r\n'`\r\n\r\nFor freezing i am using my custom script --\r\nWith tf.graph.default() as graph:\r\n`input_graph_def = graph.as_graph_def()\r\n    output_node_names =_OUTPUT_NAME\r\n    output_graph_name =  '/home/ubuntu/raj/freeze_inference_graph_mobilenet.pb'\r\n\r\n    with tf.Session() as sess:\r\n        saver = tf.train.import_meta_graph('/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0.meta',clear_devices=True)\r\n        saver.restore(sess, '/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0')\r\n        print (\"Exporting graph...\")\r\n        output_graph_def = graph_util.convert_variables_to_constants(\r\n            sess,\r\n            input_graph_def,\r\n           [_OUTPUT_NAME])\r\n\r\n        with tf.gfile.GFile(output_graph_name, \"wb\") as f:\r\n            f.write(output_graph_def.SerializeToString())`", "@Raj-08 could you check whether there are any formatting issues in your model transformation. Make sure the inputs, outputs and weights are correct depending upon the mobile device you are using.", "One thing which i want to ask is this , i am using tensorflow inference on android , now i have been using two ops tf.nn.dilation and tf.nn.erosion in my training , and while inference it says no op kernel was registered for this , now is it possible that tensorflow inference on android is not able to understand these ops even though these ops were working on tensorflow GPU?", "@Raj-08 Currently tf.nn.dilation and tf.nn.erosion are not supported in TFLite per se, some of the dilation/erosion options are embedded in conv that are potentially modifiable. Alternatively, you can add a custom op as described [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md) or only use the ops the are currently supported by TFLite in your model.", "Closing this issue, feel free to open a new issue if any error comes up."]}, {"number": 22237, "title": "Graph_def is invalid at node u'ExpandDims': Input tensor 'image_ph:0' Cannot convert a tensor of type float32 to an input of type int32", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 22236, "title": "Error restoring checkpoint: BeamSearchDecoder", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows7, CPU \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: tf.VERSION = 1.10.0|tf.GIT_VERSION = b'v1.10.0-rc1-19-g656e7a2b34'| tf.COMPILER_VERSION = b'v1.10.0-rc1-19-g656e7a2b34'\r\n- **Python version**: Python 3.5.5\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nI am trying to load a model trained using basic decoder with train_ce=True and loading it with beamsearch with train_ws=True (like inference) but it fails during restore:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_ws.py\", line 502, in <module>\r\n    tf.app.run()\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"train_ws.py\", line 337, in main\r\n    saver.restore(sess, FLAGS.restore_path)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1759, in restore\r\n    err, \"a mismatch between the current graph and the graph\")\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nInput 1 of node decoder/dynamic_decoder_out/decoder/while/Merge_7_1 was passed float from decoder/dynamic_decoder_out/decoder/while/NextIteration_7:0 incompatible with expected int32.\r\n```\r\n\r\n### Source code \r\n```\r\ndef inference_s2s_ce(self, encoder_inputs, decoder_inputs, encoder_inputs_lenghts, decoder_inputs_lenghts, feed_previous):\r\n    true_batch_size = tf.size(encoder_inputs_lenghts)\r\n    encoder_outputs, encoder_state = self.input_encoder(encoder_inputs)\r\n    print('encoder_state ', encoder_state)\r\n    attention_inputs = encoder_outputs # Not time major\r\n    #encoder_outputs = tf.transpose(encoder_outputs, [1, 0, 2]) # time major\r\n    if self.mode == 'train_ws':\r\n        attention_inputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=self.beam_width)\r\n        encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=self.beam_width)\r\n        encoder_inputs_lenghts = tf.contrib.seq2seq.tile_batch(encoder_inputs_lenghts, multiplier=self.beam_width)  \r\n    with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE) as scope:\r\n        decoder_cell = tf.contrib.rnn.LSTMCell(self.rnn_size,state_is_tuple=True)\r\n        embedding_decoder = variable_scope.get_variable(\"embedding_decoder\", [self.tgt_vocab_size, self.decoder_embedding_size])\r\n        decoder_emb_inp = tf.nn.embedding_lookup(embedding_decoder, decoder_inputs)\r\n        input_layer = Dense(self.rnn_size, dtype=self.dtype, name='input_projection')\r\n        decoder_emb_inp = input_layer(decoder_emb_inp)\r\n        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention( num_units=self.rnn_size, memory=attention_inputs, \r\n        memory_sequence_length=encoder_inputs_lenghts)\r\n        attn_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism)#, attention_layer_size= self.num_units / 2)\r\n        projection_layer = tf.layers.Dense(self.tgt_vocab_size, use_bias=False)\r\n        if self.mode == 'train_ce':\r\n            helper = tf.contrib.seq2seq.TrainingHelper(decoder_emb_inp, decoder_inputs_lenghts)#,  time_major=False)\r\n            decoder_initial_state = attn_cell.zero_state(true_batch_size, dtype=tf.float32).clone(cell_state=encoder_state)\r\n            decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                cell=attn_cell, helper=helper,\r\n                initial_state=decoder_initial_state, \r\n                output_layer=projection_layer)\r\n            inference_decoder = decoder\r\n        elif self.mode == 'train_ws':\r\n            tgt_sos_id = 3\r\n            tgt_eos_id = 1\r\n            start_tokens = tf.tile(tf.constant([tgt_sos_id], dtype=tf.int32), [true_batch_size])\r\n            batch_size = true_batch_size * self.beam_width#tf.cast(true_batch_size * self.beam_width, dtype=tf.int32)\r\n            decoder_initial_state = attn_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state)\r\n            print('decoder_initial_state shape ', decoder_initial_state)\r\n            decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell = attn_cell, embedding=embedding_decoder, start_tokens=start_tokens,\r\n            end_token=tgt_eos_id, initial_state=decoder_initial_state, beam_width=int(self.beam_width), output_layer=projection_layer)\r\n            inference_decoder = decoder\r\n        with tf.variable_scope('dynamic_decoder_out', reuse=tf.AUTO_REUSE) as scope:\r\n            outputs, _, _ = seq2seq.dynamic_decode(decoder=inference_decoder,output_time_major=False,maximum_iterations=self.output_max_length) \r\n            if self.mode == 'train_ce':\r\n                logits = outputs.rnn_output\r\n                print('Logits ', logits.get_shape())\r\n                return logits\r\n            elif self.mode == 'train_ws':\r\n                return outputs.beam_search_decoder_output.scores\r\n        \r\n```\r\nI have tried restoring basicdecoder, that works.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated the system info and added NA in fields which were skipped.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22235, "title": "TF 1.10 needs CUDA 9.2 - put info in release notes", "body": "Hi,\r\nTF 1.10 needs CUDA 9.2 now. I am missing this info in the RELEASE.md file.\r\nI suggest to add that. Did cost me a lot of time installing the different CUDA versions...\r\n\r\nWhat do you think?\r\n\r\nEven this documentation is \"wrong\" about this:\r\nhttps://www.tensorflow.org/install/install_linux#tensorflow_gpu_support\r\n\r\nThanks\r\nPhilip\r\n\r\n------------------------\r\n\r\nAdded informations (that do not matter) as requested:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: newest Xubuntu but that does not matter\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: bin\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: no\r\n- **CUDA/cuDNN version**: 9.2\r\n- **GPU model and memory**: does not matter\r\n- **Exact command to reproduce**: docu issue\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler done", "I don't believe this is true, assigning @tfboyd for further clarification.", "TF 1.10 will not work with CUDA 9.2, it only works with CUDA 9 if you are using the official binaries, e.g. `pip install tensorflow-gpu`.  I only test with the docker images but since I or the team did not upgrade the build servers to have CUDA 9.2.  The server also have device driver 384.111 which is not compatible with CUDA 9.2 so the unit tests would fail instantly.  I am pretty confident they do not work with CUDA 9.2 unless something really unexpected occurred.  There are also people that are not happy we/I chose to stick with CUDA 9.0.  \r\n\r\nIt would help to have seen your error.  I do not want to close this super fast on you, if you have more info that would be helpful.  TF 1.11 is also CUDA 9.0.", "TF 1.11 not TF 1.10 did change cuDNN versions from 7.0 to 7.2 but I suspect many people were already on 7.2.  This change is/will be in the release notes and was due to a TensorRT 4.x requirement.  \r\n\r\nAdditionally, we will move to CUDA 10.x as fast as possible once it is GA, and NVIDIA plans to have a bigger range of device driver support that should allow us to move versions faster without causing people problems.  It is a bit of a no win situation and learn as you go kind of thing. ", "I did use a brand new install of Xubuntu 18.04, Bionic Beaver.\r\nBrand new! No dirt - nothing.\r\nThen I updated the system and installed CUDA 9.2 and cuDNN v7.2.1.\r\nSee here for a step by step guide written by myself: https://wiki.eniak.de/ml/cuda_unter_ubuntu_installieren\r\n\r\nI installed `tensorflow-gpu` with conda via `conda install tensorflow-gpu`. That installed  tensorflow-gpu 1.10.0.\r\n\r\nNow everything was working fine and smooth.\r\n\r\nWhen I installed CUDA 9.1 or CUDA 9.0 (which I did before) I got this error:\r\nCUDA driver version is insufficient for CUDA runtime Version\r\n\r\nMaybe here is the difference: I did use conda and not pip but I do not think this is a big difference.\r\n\r\n@tfboyd I am 100% sure about the version numbers...\r\nI am very confused and can send more details tomorrow. Just ask what you need to know...\r\n", "@PhilipMay using conda to install tensorflow does matter.\r\nConda TF package is built and maintained by anaconda. That is clearly stated in our documentation, in the same page you linked:\r\nhttps://www.tensorflow.org/install/install_linux#InstallingAnaconda\r\n\r\nPlease reach out to anaconda for support with the conda package.\r\nJust for good measure, I also just verified that the pip package on pypi for tensorflow runs on cuda 9.0:\r\n```\r\n$ pip3 install tensorflow-gpu --upgrade\r\n$ python3\r\n>>> import tensorflow as tf\r\n>>> tf.test.is_gpu_available()\r\n....\r\nTrue\r\n>>> exit()\r\n$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Thu_Oct_19_03:08:58_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.222\r\n```\r\n\r\nClosing this issue, as it is about the community supported conda package.\r\n", "@PhilipMay   \r\n\r\nI am sorry about that.  As Gunan said we do not handle the Anaconda build.  They may have chosen to use a new CUDA which I understand and that creates confusion.  I cannot think of an easy way to make this clear.  With CUDA 10 I hope we all end up on the same version and have less divergence after that.  Thank you for the extra information, I had not even considered Anaconda might build differently but it makes sense.\r\n\r\nThank you again.", "Thanks for clarification. \ud83d\ude0f"]}, {"number": 22234, "title": "[Bug] Keras TimeDistributed Concatenation", "body": "### System information\r\n- **Code**:\r\n```\r\nimport tensorflow.keras as k\r\nimport numpy as np\r\n\r\ninput1 = k.layers.Input(shape=(None, 10))\r\ninput2 = k.layers.Input(shape=(10,))\r\n\r\nconcat_layer = k.layers.Lambda(lambda x: k.layers.concatenate([x, input2]))\r\nresults = k.layers.TimeDistributed(concat_layer)(input1)\r\n\r\nmodel = k.models.Model([input1, input2], results)\r\n\r\ndata1 = np.zeros((3,7,10))\r\ndata2 = np.zeros((3,10))\r\n\r\nmodel.predict([data1,data2])\r\n```\r\n- **OS Platform and Distribution**: Windows server 2016\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\n- **Python version**: 3.6.6\r\n- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 7.0\r\n- **Have I written custom code**: all the same as above code\r\n- **Bazel version** : N/A\r\n- **GPU model and memory**: Quadro P600, 2GiB\r\n- **Exact command to reproduce**: python test.py\r\n- **Mobile device**: N/A\r\n\r\n### Describe the problem\r\nI try to run the code mentioned above.\r\nMy goal is to concatenate input2 to each timestep of input1.\r\nBut the log shows TF reshaped first two dimensions of input1 when concatenating.\r\n\r\nLine 235 in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/wrappers.py is wrong.\r\nEven the batch size is None, the time-distributed layer's behavior may relate to actual batch size.\r\n\r\n```\r\nif input_shape[0]:\r\n      # batch size matters, use rnn-based implementation\r\n      ...................\r\nelse:\r\n      # No batch size specified, therefore the layer will be able\r\n      # to process batches of any size. (TRUE)\r\n      # We can go with reshape-based implementation for performance.\r\n      (FALSE! BEHAVIOR MAY RELATE TO ACTUAL BATCH SIZE)\r\n```\r\n\r\n### Source code / logs\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1493, in predict\r\n>     self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n>   File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 374, in predict_loop\r\n>     batch_outs = f(ins_batch)\r\n>   File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2914, in __call__\r\n>     fetched = self._callable_fn(*array_vals)\r\n>   File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1382, in __call__\r\n>     run_metadata_ptr)\r\n>   File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 519, in __exit__\r\n>     c_api.TF_GetCode(self.status.status))\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [21,10] vs. shape[1] = [3,10]\r\n>          [[Node: time_distributed_2/concatenate_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_2/Reshape, _arg_input_3_0_1/_3, time_distributed_2/concatenate_1\r\n> /concat/axis)]]\r\n>          [[Node: time_distributed_2/Reshape_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_n\r\n> ame=\"edge_27_time_distributed_2/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]", "comments": ["@fchollet  Could you please help the user to understand if the existing code is as expected or if there is a change required, can suggest to open a new PR.", "@OneMoreSecond Your `Lambda` should accept a list of inputs rather than referencing the global variable `inputs2`. I'm not sure `TimeDistributed` is the best way to go about this. Here's an example that I believe satisfies your use case\r\n\r\n```python\r\nimport tensorflow.keras as k\r\nimport numpy as np\r\n\r\ninput1 = k.layers.Input(shape=(None, 10))\r\ninput2 = k.layers.Input(shape=(10,))\r\n\r\ndef expand_and_concat(x):\r\n  x0, x1 = x\r\n  x1  = tf.expand_dims(x1, axis=1)\r\n  x1  = tf.tile(x1, [1, tf.shape(x0)[1], 1])\r\n  return tf.concat([x0, x1], axis=2)\r\n\r\nresults = k.layers.Lambda(expand_and_concat)([input1, input2])\r\nmodel = k.models.Model([input1, input2], results)\r\n\r\ndata1 = np.zeros((3,7,10))\r\ndata2 = np.zeros((3,10))\r\n\r\nmodel.predict([data1,data2])\r\n```\r\n"]}, {"number": 22233, "title": "ssd_mobilenet_v2 frozen model size much larger than ssd_mobilenet_v1", "body": "Hi, comparing the pre-trained models published on tensorflow object detection model zoo, why the frozen_model/check_point/saved_model of ssd_mobilenet_v2_coco is much larger than the ones of ssd_mobilenet_v1_coco? mobilenet v2 should be more lite than mobilenet v1.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have the same query", "Please try using ssdlite for mobilenet v2 which is smaller in size: http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz", "Closing this issue since its resolved. Feel free to reopen if have any further problems. Thanks!"]}, {"number": 22232, "title": " encrypt the tflite model", "body": "  I want to encrypt the tflite model, what should I do?", "comments": ["Someone already asked this earlier [here](https://github.com/tensorflow/tensorflow/issues/21501)\r\n", "Closing this issue since this is a duplicate", "Any questions or concerns you have about this issue, just let me know.\n\nOn Wed, Sep 12, 2018 at 7:36 PM zw232618 <notifications@github.com> wrote:\n\n> emmm\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22232#issuecomment-420863114>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AozaOd3ON-AfRya0axuzJU9r01LbxEuYks5uacTHgaJpZM4Wk-Pk>\n> .\n>\n"]}, {"number": 22231, "title": "Add hessian computation for sparse softmax xent.", "body": "Closes #9368\r\n\r\nImplements second derivative for `_SparseSoftmaxCrossEntropyWithLogits` similar to `_SoftmaxCrossEntropyWithLogits`. Reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_grad.py#L448\r\n\r\n* Tests that no redundant computation is performed when only the first derivative is requested for computation\r\n* Moves `IsZero` method outside of scope of `_SoftmaxCrossEntropyWithLogits` so that it could be used by both `_SoftmaxCrossEntropyWithLogits` and `_SparseSoftmaxCrossEntropyWithLogits`.", "comments": ["LGTM; approval conditioned on all tests passing.", "@ebrevdo I fixed unused imports and eager mode related errors, not sure if the rest is related.", "@rthadur  any reason ebrevdo's review isn't enough?  I'm not familiar with this code...", "> @rthadur any reason ebrevdo's review isn't enough? I'm not familiar with this code...\r\n\r\n@vrv as this is in backlog for a long time , i was wondering if other reviewers can take a look if ebrevdo's is not available,NM i will wait for ebrevdo's review", "I see -- maybe try pinging him and find out if he can find an alternative reviewer who is familiar with the code?", "> I see -- maybe try pinging him and find out if he can find an alternative reviewer who is familiar with the code?\r\n\r\nsure , thank you ", "this is merged internally , waiting for auto-merge to happen, thank you ", "This had to be rolled back, unfortunately, because in eager mode the gradient computation accidentally inserts hessian gradients as it can't tell that the input op is a Zeros or ZerosLike.  We'll have to fix this first."]}, {"number": 22230, "title": "Fix missprint - unknown variable name.", "body": "", "comments": []}, {"number": 22229, "title": "intra_op_parallelism_threads will be invalid if call any API initialized device", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** (Red Hat 4.8.5-16)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile devic:** n/a\r\n- **TensorFlow installed from (source or binary):** source\r\n- **TensorFlow version (use command below):** 1.10.0\r\n- **python version:** 3.4.5\r\n- **Bazel version (if compiling from source):** 0.15.1\r\n- **GCC/Compiler version (if compiling from source):** gcc version 6.3.1\r\n- **CUDA/cuDNN version:** n/a\r\n- **GPU model and memory:** n/a\r\n- **Exact command to reproduce:** Run included script\r\n\r\n### Describe the problem\r\n\r\nI'm trying to run [NCF model ](https://github.com/tensorflow/models/tree/master/official/recommendation) on X86 CPU, and add the **intra_op_parallelism_threads** to tune the performance. Then I found that if we call any API including **list_devices()**, TF would initialize a global intra thread pool and overwrite the configuration of **intra_op_parallelism_threads**.\r\n\r\nNCF will call **is_gpu_available()** before training, and its implementation includes **list_devices()**, so the **intra_op_parallelism_threads** option is invalid.\r\n\r\nMy question is, dose this logic makes sense? If we want to run a model on CPU, the config may be invalid when we call some 'harmless' API and get no feedback.\r\n\r\n### Source code / logs\r\n\r\nhere's the modify of NCF to enable **intra_op_parallelism_threads**:\r\n[ncf_intra.txt](https://github.com/tensorflow/tensorflow/files/2373942/ncf_intra.txt)\r\n\r\nI also add some code to print the intra thread pool status in TF, this patch has changed the global setting to false to solve the issue, revert it to true will reproduce the question:\r\n[tf_intra.txt](https://github.com/tensorflow/tensorflow/files/2373947/tf_intra.txt)\r\n\r\nWith the print code, you can see that TF will try to initialize a device with a global intra thread pool when call **list_devices()**. Once if the global intra thread pool was initialized, other device couldn't change the configuration any more.\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Mobile device\r\n\r\nN/A.\r\nUpdated in the text, thanks.", "Does anyone have any suggestion? I'm assume this should be a bug or lack of design in Tensorflow, who   try to run [tensorflow/models](https://github.com/tensorflow/models) on CPU may meet this issue, and I also think this is the reason of #14900.", "It is a known issue and I would not call it a bug. \r\n\r\nTheoretically the session configuration should be session-wise, but some of the session config will effect in resource initialization which is difficult to release unless the process is terminated. \r\n\r\nI would suggest you to detect GPU availability before your main TF process starts.", "> It is a known issue and I would not call it a bug.\r\n> \r\n> Theoretically the session configuration should be session-wise, but some of the session config will effect in resource initialization which is difficult to release unless the process is terminated.\r\n> \r\n> I would suggest you to detect GPU availability before your main TF process starts.\r\n\r\nThe roof of this issue is **list_devices()** will initialize all available devices in this session, meanwhile the global intra thread pool is created. **is_gpu_available()** is just an instance, user may use this API anywhere, and TF API doc doesn't tell them there's side-effect here:\r\n\r\n> list_devices\r\n> list_devices()\r\n> Lists available devices in this session.\r\n> \r\n> devices = sess.list_devices()\r\n> for d in devices:\r\n>   print(d.name)\r\n> Each element in the list has the following properties: - name: A string with the full name of the device. ex: /job:worker/replica:0/task:3/device:CPU:0 - device_type: The type of the device (e.g. CPU, GPU, TPU.) - memory_limit: The maximum amount of memory available on the device. Note: depending on the device, it is possible the usable memory could be substantially less.\r\n\r\nI also listed how to solve this issue - just set the flag **use_global_threadpool_** to false. My question is, what is the effect of changing this flag, or why doesn't TF provide such API to set it?", "I agree with you; PR is always welcomed!", "I found another API used in Tensorflow official model zoo which would cause this issue: [https://github.com/tensorflow/models/blob/master/official/utils/logs/logger.py](https://github.com/tensorflow/models/blob/master/official/utils/logs/logger.py#L394).\r\nAs I said, user didn't receive any warning or suggestion from the API that could change the behaviour. I'll try to submit a PR to avoid calling these API on CPU in these models before fixing this issue."]}, {"number": 22228, "title": "Fix missprint - unknown variable name.", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->"]}, {"number": 22227, "title": "Fixed wrong variable name in example", "body": "The Keras model used a wrong variable name in the MirroredStrategy example", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 22225, "title": "Fix missprint - unknown variable name.", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->"]}, {"number": 22224, "title": "Eeager Mode:sigmoid_cross_entropy_with_logits expects int32 but not float tensor", "body": "### System information\r\nOS: ubuntu 1604\r\nVirtual Env:Conda\r\nTF Version:1.10\r\nPython:3.6.6\r\n\r\n```python\r\ntfe = tf.contrib.eager\r\ndef loss(inputs, labels):\r\n    print(labels.dtype)\r\n    logits = model(inputs, training=True)\r\n    print(logits.dtype)\r\n    return tf.reduce_mean(\r\n      tf.nn.sigmoid_cross_entropy_with_logits(\r\n        logits=logits,\r\n        labels=labels)\r\n    )\r\n\r\nval_grad_fn = tfe.implicit_value_and_gradients(loss)\r\n```\r\nError: here can be seen the type of logits is float32, same as the requirement of  [sigmoid_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits).   \r\nSo I'm curious where's wrong.\r\n```\r\n<dtype: 'int32'>\r\n<dtype: 'float32'>\r\nTraceback (most recent call last):\r\n  File \"model.py\", line 384, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"model.py\", line 335, in main\r\n    train_one_epoch(epoch_i=i, train_data=ds_train, log_interval=FLAGS.log_interval, **model_objects)\r\n  File \"model.py\", line 264, in train_one_epoch\r\n    value, grads_and_vars = val_grad_fn((u, i, i_c, ts, hist_c, sl), y)\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 203, in grad_fn\r\n    end_node = f(*args, **kwds)\r\n  File \"model.py\", line 249, in loss\r\n    labels=labels)\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 181, in sigmoid_cross_entropy_with_logits\r\n    relu_logits - logits * labels,\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1094, in _mul_dispatch\r\n    return gen_math_ops.mul(x, y, name=name)\r\n  File \"/home/ubuntu/hdd1/zip_data/Paul/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4959, in mul\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute Mul as input #0 was expected to be a int32 tensor but is a float tensor [Op:Mul] name: logistic_loss/mul/\r\n```\r\n", "comments": ["logits should be same as labels"]}, {"number": 22223, "title": "tf.unstack did not work with tf 1.8 CudnnGRU tensors", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n```\r\n$uname -r\r\n3.10.0-327.el7.x86_64\r\n```\r\n- **Mobile device**\r\n```\r\nNot mobile\r\n```\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nanaconda tf 1.8\r\n\r\n- **TensorFlow version (use command below)**:\r\n```\r\n$conda list|grep tensor\r\ntensorboard               1.8.0            py36hf484d3e_0\r\ntensorflow                1.8.0                hb381393_0\r\ntensorflow-base           1.8.0            py36h4df133c_0\r\ntensorflow-gpu            1.8.0                h7b35bdc_0\r\n```\r\n- **Python version**:\r\n```\r\n$python3.6 -V\r\nPython 3.6.2 :: Continuum Analytics, Inc.\r\n```\r\n- **Bazel version (if compiling from source)**:\r\n```\r\n$bazel version\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n```\r\n\r\n- **CUDA/cuDNN version**:\r\n```\r\n$conda list|grep -i cuda\r\ncudatoolkit               8.0                           3    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\r\ncudnn                     7.0.5                 cuda8.0_0\r\n```\r\n- **GPU model and memory**:\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux rvab01298.sqa.ztt 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7.2 (Paladin)\"\r\nVERSION_ID=\"7.2\"\r\nQihoo360_BUGZILLA_PRODUCT_VERSION=7.2\r\nQihoo360_SUPPORT_PRODUCT_VERSION=7.2\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.9.2\r\nCopyright (C) 2014 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux rvab01298.sqa.ztt 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.1)\r\ntensorflow (1.8.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = b'unknown'\r\ntf.COMPILER_VERSION = b'unknown'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/mpc-0.8.1/lib:/usr/local/gmp-4.3.2/lib:/usr/local/mpfr-2.4.2/lib:/gruntdata/qihoo360/cuda/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Sep 12 13:34:30 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K40m          On   | 0000:02:00.0     Off |                    0 |\r\n| N/A   36C    P0    67W / 235W |   1161MiB / 11439MiB |     39%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K40m          On   | 0000:03:00.0     Off |                    0 |\r\n| N/A   35C    P0    60W / 235W |     73MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0     13950    C   bin/arks                                       868MiB |\r\n|    0     27880    C   python3.6                                      288MiB |\r\n|    1     27880    C   python3.6                                       71MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/lib64/libcudart_static.a\r\n/usr/local/cuda-7.5/lib/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/lib/libcudart_static.a\r\n```\r\n\r\n### Describe the problem\r\n`tf.unstack` did not work as expected. It did not reduce `R` rank tensor to `R-1` rank tensor\r\n\r\n### Source code / logs\r\ncode:\r\n```\r\n#! /usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\r\nimport sys\r\nimport tensorflow as tf\r\nrnn_model = tf.contrib.cudnn_rnn.CudnnGRU(\r\n        num_layers=1,\r\n        num_units=64,\r\n        direction='unidirectional')\r\nrnn_model.build([3, 1, 3])\r\ninputs=[[[1,1,1],[1,1,1],[1,1,1]]]\r\ninputs_tensor= tf.convert_to_tensor(inputs, dtype=tf.float32)\r\nprint(tf.shape(inputs_tensor))\r\nrnn_out, rnn_state = rnn_model(inputs_tensor)\r\nprint(\"rnn_state: \", rnn_state)\r\nrnn_layers = tf.unstack(rnn_state)\r\nprint(\"rnn_layers\", rnn_layers)\r\n```\r\n\r\npaste the code to file `demo.py`, then run from linux command line:\r\n```\r\n$ python3.6 demo.py\r\n```\r\n\r\noutput:\r\n```\r\nTensor(\"Shape:0\", shape=(3,), dtype=int32)\r\nrnn_state:  (<tf.Tensor 'cudnn_gru/CudnnRNN:1' shape=(1, ?, 64) dtype=float32>,)\r\nrnn_layers [<tf.Tensor 'unstack:0' shape=(1, ?, 64) dtype=float32>]\r\n```\r\n\r\nthe `rnn_layers` should be ` rnn_layers [<tf.Tensor 'unstack:0' shape=(?, 64) dtype=float32>]`\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce", "rnn_state is a tuple, not a tensor.\r\n\r\nPlease debug yourself before posting issue on TensorFlow.\r\n\r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "@bignamehyp rnn_state is a tuple? but I print it out as 'Tensor', moreover, the doc of `tf.contrib.cudnn_rnn.CudnnGRU` shows returns as `Output tensor(s)`.\r\n\r\nstackoverflow issue added, the link: [stackoverflow issue](https://stackoverflow.com/questions/52306358/tf-unstack-did-not-work-with-tf-1-8-cudnngru-tensors)", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Bazel version\r\n> Exact command to reproduce\r\n\r\nok, `Bazel version` and exact command added.\r\n\r\n", "> @bignamehyp rnn_state is a tuple? but I print it out as 'Tensor', moreover, the doc of `tf.contrib.cudnn_rnn.CudnnGRU` shows returns as `Output tensor(s)`.\r\n> \r\n> stackoverflow issue added, the link: [stackoverflow issue](https://stackoverflow.com/questions/52306358/tf-unstack-did-not-work-with-tf-1-8-cudnngru-tens\r\n\r\n> rnn_state is a tuple, not a tensor.\r\n> \r\n> Please debug yourself before posting issue on TensorFlow.\r\n> \r\n> This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n> \r\n> If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n\r\nok , get it done, thx"]}, {"number": 22222, "title": "The latest process of building tensorflow serving for windows", "body": "**Have I written custom code**  in /tensorflow/contrib/cmake/CMakeLists.txt\r\n```\r\nif\uff08tensorflow_OPTIMIZE_FOR_NATIVE_ARCH\uff09\r\n  include\uff08CheckCXXCompilerFlag\uff09\r\n  CHECK_CXX_COMPILER_FLAG\uff08\u201c - march = native\u201d COMPILER_OPT_ARCH_NATIVE_SUPPORTED\uff09\r\n  if\uff08COMPILER_OPT_ARCH_NATIVE_SUPPORTED\uff09\r\n    set\uff08CMAKE_CXX_FLAGS \u201c $ {CMAKE_CXX_FLAGS} -march = native\u201d\uff09\r\n  endif\uff08\uff09\r\nendif\uff08\uff09\r\n```\r\n\r\nchanged to\r\n\r\n```\r\nif (tensorflow_OPTIMIZE_FOR_NATIVE_ARCH)\r\n  include(CheckCXXCompilerFlag)\r\n  CHECK_CXX_COMPILER_FLAG(\"-march=native\" COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n  if (COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=native\")\r\n  else()\r\n    CHECK_CXX_COMPILER_FLAG(\"/arch:AVX\" COMPILER_OPT_ARCH_AVX_SUPPORTED)\r\n    if(COMPILER_OPT_ARCH_AVX_SUPPORTED)\r\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /arch:AVX\")\r\n    endif()\r\n  endif()\r\nendif()\r\n```\r\n\r\n**OS Platform and Distribution**    windows7 x64\r\n**TensorFlow installed from**    sourse\r\n**TensorFlow version**  r1.10\r\n**Bazel version** N/A\r\n**CUDA/cuDNN** version 9.0/Cudnn 7.0\r\n**GPU model and memory** 1080Ti / 11G\r\n**Exact command to reproduce**\r\n\r\n**1. Cmake build:**\r\n```\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Debug\r\n-T host=x64\r\n-DSWIG_EXECUTABLE=D:/lib/swigwin-3.0.12/swig.exe\r\n-DPYTHON_EXECUTABLE=C:/Users/tao/AppData/Local/Programs/Python/Python35-32/python.exe \r\n-DPYTHON_LIBRARIES=C:/Users/tao/AppData/Local/Programs/Python/Python35-32/libs/python35.lib \r\n-Dtensorflow_ENABLE_GPU=ON \r\n-Dtensorflow_ENABLE_GRPC_SUPPORT=OFF\r\n-Dtensorflow_BUILD_SHARED_LIB=ON  \r\n```\r\n\r\n**2. Visual studio 2015:**\r\n\r\n`MSBuild /p:Configuration=Debug /p:Platform=x64 ALL_BUILD.vcxproj\r\n`\r\n### Describe the problem\r\n\r\nI want to use Tensorflow in my Windows C++ application. Therefore I'm trying to build in Visual studio on a Windows system.\r\n\r\nWhether to support compiling DEBUG version.\r\n### logs\r\n```\r\nfatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\captured_function.cc)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nCUDA/cuDNN version\nMobile device", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> CUDA/cuDNN version\r\n> Mobile device\r\n\r\n**CUDA/cuDNN version**   CUDA 9.0/Cudnn 7.0\r\n**Mobile device**   N/A\r\n\r\nNow I have new problems. if `-Dtensorflow_ENABLE_GRPC_SUPPORT=OFF`  Tips\uff1afatal error C1083: Cannot open include file: 'grpcpp/grpcpp.h': No such file or directory \r\n\r\nif `-Dtensorflow_ENABLE_GRPC_SUPPORT=ON`  Tips\uff1aC:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \u201ccmd.exe\u201d\u5df2\u9000\u51fa\uff0c\u4ee3\u7801\u4e3a 1\u3002 [D:\\tensorflow-master\\tensorflow\\contrib\\cmake\\build\\grpc.vcxproj]\r\n\r\nI hope to get help. Thx"]}, {"number": 22221, "title": "Threading data out of one while loop into another interferes with gradients", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.13.6\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: `b'v1.9.0-rc2-3217-g8e5c118ce8' 1.10.0`\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**: `0.15.2-homebrew`\r\n- **GCC/Compiler version (if compiling from source)**: `Apple LLVM version 9.1.0 (clang-902.0.39.2)`\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: Run included script\r\n- **Mobile device**: n/a\r\n\r\n### Describe the problem\r\nI have some code which\r\n\r\n1. Generates some data using an inference-only `tf.while_loop`.\r\n2. Uses a second while loop to run several minibatches of Adam, using the data from the first loop.\r\n\r\nBoth while loops have `back_prop=False`.  The second loop computes gradients, but these are used only inside the second loop (which includes running the `train_op`).  I use `tf.stop_gradients` to prevent gradients from flowing backwards from the second loop to the first...but to no avail:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./while-bug\", line 26, in <module>\r\n    back_prop=False)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3281, in while_loop\r\n    return_same_structure)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3001, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2936, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3245, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(lv))\r\n  File \"./while-bug\", line 16, in body\r\n    train = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 401, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 517, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 610, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 674, in _GradientsHelper\r\n    to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 204, in _PendingCount\r\n    between_op_list, between_ops, colocate_gradients_with_ops)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1442, in MaybeCreateControlFlowState\r\n    loop_state.AddWhileContext(op, between_op_list, between_ops)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1247, in AddWhileContext\r\n    grad_state = GradLoopState(forward_ctxt, outer_grad_state)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 824, in __init__\r\n    cnt, forward_index = forward_ctxt.AddForwardLoopCounter(outer_grad_state)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2580, in AddForwardLoopCounter\r\n    name=\"f_count\")\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 249, in _Enter\r\n    data, frame_name, is_constant, parallel_iterations, name=name)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\", line 179, in enter\r\n    parallel_iterations=parallel_iterations, name=name)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3254, in create_op\r\n    op_def=op_def)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1787, in __init__\r\n    self._control_flow_post_processing()\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1796, in _control_flow_post_processing\r\n    control_flow_util.CheckInputFromValidContext(self, input_tensor.op)\r\n  File \"/Users/irving/anaconda/envs/openai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_util.py\", line 322, in CheckInputFromValidContext\r\n    raise ValueError(error_msg + \" See info log for more details.\")\r\nValueError: Cannot use 'while_1/gradients/f_count_1' as input to 'while_1/gradients/f_count' because they are in different while loops. See info log for more details.\r\n```\r\n\r\n(Caveat: line numbers for the above stacktrace may be slightly wrong, since my TF has some debug print statements.)\r\n\r\nI've traced the problem to `ops/gradients_impl.py:_PendingCount` or the surrounding code.  `_PendingCount` seems to trace right through `tf.stop_gradients`.  I'm not sure where the right fix is, though, so could use some control flow expert help.\r\n\r\n### Source code / logs\r\n\r\nHere's a minimized test case:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n# First while loop\r\nrollouts = tf.while_loop(\r\n    cond=lambda _: True,\r\n    body=lambda _: tf.get_variable('b', []),\r\n    loop_vars=[tf.zeros([])],\r\n    maximum_iterations=1,\r\n    back_prop=False)\r\nrollouts = tf.stop_gradient(rollouts)\r\n\r\ndef body(i):\r\n    loss = tf.stop_gradient(rollouts)\r\n    train = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\r\n    with tf.control_dependencies([train]):\r\n        return i + 1\r\n\r\n# Second while loop.  Crashes since it thinks the gradients depend on\r\n# something from the previous while loop.\r\ntf.while_loop(\r\n    cond=lambda _: True,\r\n    body=body, maximum_iterations=1, parallel_iterations=1,\r\n    loop_vars=(tf.zeros((), dtype=tf.int32),),\r\n    back_prop=False)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "^ Fixed.", "I also tried using the `stop_gradients` argument to `tf.gradients`, but the problem persists: it still thinks gradients are flowing out of the while loop.", "@alextp recommended `tf.GradientTape` as a workaround, and that seems to work great (as long as variables are created with `use_resource=True`).  So this is still a bug, but it's no longer blocking me.", "@girving Hi, Can this be closed or any fix is being implemented ?", "@alextp?", "This is still a bug and expected to be fixed only when we transition to while_v2 as described in https://github.com/tensorflow/community/pull/13 . I'll close this for now.", "Please file a separate issue for your problem with instructions to\nreproduce.\n\nOn Tue, Mar 10, 2020 at 3:40 PM Stanley Gan <notifications@github.com>\nwrote:\n\n> I am also experiencing this error on TF1.15 when trying to compute\n> Laplacian, with 1st gradient of some operations overwritten using decorator\n> @tf.custom_gradient. I computed the Laplacian using tf.while_loop by\n> creating each row of Hessian and summing relevant parts. With this code\n> implemented without overwriting the 1st gradient, my code runs fine.\n> However, when I introduce my code in overwriting 1st gradient, which\n> involves another tf.while_loop solely for tensor manipulation and\n> multiplication, it spits out this error. I changed to using\n> tf.GradientTape() but apparently the gradient computed is None. I am\n> wondering how exactly did you solve this or any suggestions on how I should\n> I approach this issue?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22221?email_source=notifications&email_token=AAABHROW4OHDKAKAQBJBN3DRG26URA5CNFSM4FURUWJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEONOVIQ#issuecomment-597355170>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIDNITTXVAN7NDOTO3RG26URANCNFSM4FURUWJA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp. Sorry I just deleted my comment as it is pretty vague and not a good way to explain my error. I am thinking if this should be a separate issue, but I ran the same example as described by @girving in this issue on TF1.15, the error still persists. ", "And what about nightly?\n\nOn Tue, Mar 10, 2020 at 5:25 PM Stanley Gan <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp>. Sorry I just deleted my comment as\n> it is pretty vague and not a good way to explain my error. I am thinking if\n> this should be a separate issue, but I ran the same example as described by\n> @girving <https://github.com/girving> on TF1.15, the error still persists.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22221?email_source=notifications&email_token=AAABHRP6COBEJV73LZHXMDTRG3LAFA5CNFSM4FURUWJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEONVVWA#issuecomment-597383896>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKX2PD3GTX4JGWYNCLRG3LAFANCNFSM4FURUWJA>\n> .\n>\n\n\n-- \n - Alex\n", "There are no more nightly builds for version 1.15 on pypi.", "I mean the 2.x branch; the 1.15 branch will get no further fixes.\n\nOn Tue, Mar 10, 2020 at 5:55 PM Stanley Gan <notifications@github.com>\nwrote:\n\n> There are no more nightly builds for version 1.15 on pypi.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22221?email_source=notifications&email_token=AAABHRNOKRQ34D2PSYLOFOLRG3OPXA5CNFSM4FURUWJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEONXIOI#issuecomment-597390393>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMVVKAD5A7RXGL5TUTRG3OPXANCNFSM4FURUWJA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Thanks for your reply! For specific reason (package dependencies), the code which I wrote is in 1.15, hence even if running on TF2 works, I still have to figure out a way as my code is written in 1.15. Unless you are suggesting that some other fixes which I am not aware of? Though based on the community link which you posted: https://github.com/tensorflow/community/pull/13, I checked the commits to fix this were merged into 1.15 branch (unless I am missing something!). ", "So I need an example to reproduce this against nightly, which is 2.x, so I\ncan debug it.\n\nOn Wed, Mar 11, 2020 at 8:44 AM Stanley Gan <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp> Thanks for your reply! For specific\n> reason (package dependencies), the code which I wrote is in 1.15, hence\n> even if running on TF2 works, I still have to figure out a way as my code\n> is written in 1.15. Unless you are suggesting that some other fixes which I\n> am not aware of? Though based on the community link which you posted:\n> tensorflow/community#13 <https://github.com/tensorflow/community/pull/13>,\n> I checked the commits to fix this were merged into 1.15 branch (unless I am\n> missing something!).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22221#issuecomment-597708551>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIA5M4VM7WVFLI7F6LRG6WULANCNFSM4FURUWJA>\n> .\n>\n\n\n-- \n - Alex\n", "Using girving's example, ran using `tf-nightly-2.2.0-dev20200311` \r\n```\r\nimport tensorflow as tf\r\n  \r\n# First while loop\r\nrollouts = tf.while_loop(\r\n    cond=lambda _: True,\r\n    body=lambda _: tf.compat.v1.get_variable('b', []),\r\n    loop_vars=[tf.zeros([])],\r\n    maximum_iterations=1,\r\n    back_prop=False)\r\nrollouts = tf.stop_gradient(rollouts)\r\n\r\ndef body(i):\r\n    loss = tf.stop_gradient(rollouts)\r\n    train = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\r\n    with tf.control_dependencies([train]):\r\n        return i + 1\r\n\r\n# Second while loop.  Crashes since it thinks the gradients depend on\r\n# something from the previous while loop.\r\ntf.while_loop(\r\n    cond=lambda _: True,\r\n    body=body, maximum_iterations=1, parallel_iterations=1,\r\n    loop_vars=(tf.zeros((), dtype=tf.int32),),\r\n    back_prop=False)\r\n```\r\nI got a different error as shown below\r\n```\r\n2020-03-11 09:05:04.518937: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-03-11 09:05:04.531475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff78acc51e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-03-11 09:05:04.531492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:From dummy_example.py:9: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nback_prop=False is deprecated. Consider using tf.stop_gradient instead.\r\nInstead of:\r\nresults = tf.while_loop(c, b, vars, back_prop=False)\r\nUse:\r\nresults = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 378, in assert_same_structure\r\n    expand_composites)\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None)]]\r\n\r\nSecond structure: type=list str=[1, <tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>]\r\n\r\nMore specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=ResourceVariable str=<tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>\" is not\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"dummy_example.py\", line 9, in <module>\r\n    back_prop=False)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2491, in while_loop_v2\r\n    return_same_structure=True)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2731, in while_loop\r\n    nest.assert_same_structure(loop_var_structure, list(loop_vars))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 385, in assert_same_structure\r\n    % (str(e), str1, str2))\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None)]]\r\n\r\nSecond structure: type=list str=[1, <tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>]\r\n\r\nMore specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=ResourceVariable str=<tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>\" is not\r\nEntire first structure:\r\n[., [.]]\r\nEntire second structure:\r\n[., .]\r\n\r\n\r\n```", "This is an unrelated bug in the example code where it's using tf.while_loop\nincorrectly and returning variables where tf expects tensors, I think.\n\nOn Wed, Mar 11, 2020 at 10:21 AM Stanley Gan <notifications@github.com>\nwrote:\n\n> Using girving's example, ran using tf-nightly-2.2.0-dev20200311\n>\n> import tensorflow as tf\n>\n> # First while loop\n> rollouts = tf.while_loop(\n>     cond=lambda _: True,\n>     body=lambda _: tf.compat.v1.get_variable('b', []),\n>     loop_vars=[tf.zeros([])],\n>     maximum_iterations=1,\n>     back_prop=False)\n> rollouts = tf.stop_gradient(rollouts)\n>\n> def body(i):\n>     loss = tf.stop_gradient(rollouts)\n>     train = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n>     with tf.control_dependencies([train]):\n>         return i + 1\n>\n> # Second while loop.  Crashes since it thinks the gradients depend on\n> # something from the previous while loop.\n> tf.while_loop(\n>     cond=lambda _: True,\n>     body=body, maximum_iterations=1, parallel_iterations=1,\n>     loop_vars=(tf.zeros((), dtype=tf.int32),),\n>     back_prop=False)\n>\n> I got a different error as shown below\n>\n> 2020-03-11 09:05:04.518937: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n> 2020-03-11 09:05:04.531475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff78acc51e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n> 2020-03-11 09:05:04.531492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n> WARNING:tensorflow:From dummy_example.py:9: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n> Instructions for updating:\n> back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n> Instead of:\n> results = tf.while_loop(c, b, vars, back_prop=False)\n> Use:\n> results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n> Traceback (most recent call last):\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 378, in assert_same_structure\n>     expand_composites)\n> ValueError: The two structures don't have the same nested structure.\n>\n> First structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None)]]\n>\n> Second structure: type=list str=[1, <tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>]\n>\n> More specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=ResourceVariable str=<tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>\" is not\n>\n> During handling of the above exception, another exception occurred:\n>\n> Traceback (most recent call last):\n>   File \"dummy_example.py\", line 9, in <module>\n>     back_prop=False)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\n>     return func(*args, **kwargs)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2491, in while_loop_v2\n>     return_same_structure=True)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2731, in while_loop\n>     nest.assert_same_structure(loop_var_structure, list(loop_vars))\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 385, in assert_same_structure\n>     % (str(e), str1, str2))\n> ValueError: The two structures don't have the same nested structure.\n>\n> First structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None)]]\n>\n> Second structure: type=list str=[1, <tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>]\n>\n> More specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=ResourceVariable str=<tf.Variable 'b:0' shape=() dtype=float32, numpy=-0.98595977>\" is not\n> Entire first structure:\n> [., [.]]\n> Entire second structure:\n> [., .]\n>\n>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22221#issuecomment-597761869>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRICXL4P664CMAMHHTLRG7CCRANCNFSM4FURUWJA>\n> .\n>\n\n\n-- \n - Alex\n", "Let me try to fix it.", "Should I run it with `tf.compat.v1.disable_v2_behavior()`? Because v2 is eagerly executed."]}, {"number": 22220, "title": "Not running no_gpu tagged tests on GPU and not running benchmark-test\u2026", "body": "\u2026 for any pip builds.\r\n\r\nPiperOrigin-RevId: 212541571", "comments": []}, {"number": 22219, "title": "Handle model deserialization when output tensor shape is NULL.", "body": "In flatbuffers, vectors default to NULL.\r\n\r\nOriginal change by alanchiao@.\r\n\r\nPiperOrigin-RevId: 212506392", "comments": []}, {"number": 22218, "title": "Tensorflow hangs when running `broadcast_to` op", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: ---\r\n- **TensorFlow installed from (source or binary)**: binary via pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: ---\r\n- **GCC/Compiler version (if compiling from source)**: ---\r\n- **CUDA/cuDNN version**: CUDA-9.0 cuDNN-x64-v7.1\r\n- **GPU model and memory**: NVIDIA GeForce GTX 1080, 8GB\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(\"Version\", tf.GIT_VERSION, tf.VERSION)\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    \r\n    zero = tf.constant(0.0, dtype=tf.float32)\r\n    \r\n    dynamic_tensor = tf.placeholder(name=\"dynamic_tensor\", shape=[None], dtype=tf.bool)\r\n    \r\n    dynamic_shape = tf.shape(dynamic_tensor)\r\n    \r\n    broadcast_zeroes = tf.broadcast_to(input=zero, shape=dynamic_shape)\r\n    \r\n    example_feed = {dynamic_tensor: [True, False]}\r\n    \r\n    print(\"Inputs:\", sess.run([zero, dynamic_tensor, dynamic_shape], feed_dict=example_feed))\r\n    \r\n    print(\"Broadcast:\", sess.run(broadcast_zeroes, feed_dict=example_feed))\r\n    \r\n    print(\"Never reached\")\r\n```\r\nOutputs:\r\n```\r\nVersion 1.10.0 b'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\nInputs: [0.0, array([ True, False]), array([2])]\r\n```\r\n\r\n### Describe the problem\r\nTensowflow is getting stuck (hangs without any error) trying to broadcast a dynamic shape. Changing to a static `shape=[2]` produces the expected result:\r\n\r\n```\r\nVersion b'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\nInputs: [0.0, array([ True, False]), array([2])]\r\nBroadcast: [0. 0.]\r\nNever reached\r\n```", "comments": ["@csiz    I tried running the same program in Linux environment using Python 2.7 with TensorFlow 1.10 version and broadcasting a dynamic shape works fine here without any stuck. Below is the result for the same. \r\n\r\nOutput : \r\n('Version', 'v1.10.0-0-g656e7a2b34', '1.10.0')\r\n('Inputs:', [0.0, array([ True, False]), array([2], dtype=int32)])\r\n('Broadcast:', array([0., 0.], dtype=float32))\r\nNever reached\r\n\r\nCan you please try the same with Python 2.7 version and post your observations.\r\n", "Hi @harshini-gadige thanks for looking into this. Seems like it's a problem with `tensorflow-gpu` in particular. I ran the script in 3 new cases:\r\n\r\n1. On Windows subsystem for Linux, it works with a fresh install of `pip3 install tensorflow`.\r\n2. On a new virtual environment in Windows, it works with `pip install tensorflow`.\r\n3. On a new virtual environment in Windows, it *doesn't* work with `pip install tensorflow-gpu`. Pip freeze of the broken one is:\r\n```\r\nabsl-py==0.4.1\r\nastor==0.7.1\r\ngast==0.2.0\r\ngrpcio==1.15.0\r\nMarkdown==2.6.11\r\nnumpy==1.14.5\r\nprotobuf==3.6.1\r\nsix==1.11.0\r\ntensorboard==1.10.0\r\ntensorflow-gpu==1.10.0\r\ntermcolor==1.1.0\r\nWerkzeug==0.14.1\r\n```\r\n\r\nUnfortunately the Linux subsystem doesn't support GPU, and I don't have a Linux install at the moment.\r\n\r\nEdit: also tensorflow isn't available on python2.7 on windows.", "Also works when forcing the `broadcast_to` op to be put on CPU:\r\n```\r\n    with tf.device(\"CPU\"):\r\n        broadcast_zeroes = tf.broadcast_to(input=zero, shape=dynamic_shape)\r\n```", "@alextp  Hi, please provide your inputs for the above.", "Reed, can you direct this to someone on the GPU team?", "I get a segfault when I run it. I'll take a closer look soon, probably this week.", "Nagging Assignee @reedwm: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This should be fixed. https://github.com/tensorflow/tensorflow/commit/a0bfbd2241f4ca8b01dc78fb9ffe856477e47c7f", "Closing, as this is fixed."]}, {"number": 22217, "title": "Session run options for configuring the timeout of a run is not working as expected", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.2/\r\n- **GPU model and memory**: V100 and 16GB\r\n- **Exact command to reproduce**:\r\n\r\n== cat /etc/issue ===============================================\r\nLinux ip-172-31-35-59 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux ip-172-31-35-59 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy               1.14.5\r\nprotobuf            3.6.0\r\ntensorflow          1.9.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.9.0\r\ntf.GIT_VERSION = v1.9.0-0-g25c197e023\r\ntf.COMPILER_VERSION = v1.9.0-0-g25c197e023\r\nSanity check: array([1], dtype=int32)\r\n/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/lib/nccl/cuda-9.0/lib:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Sep 11 19:14:44 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   39C    P0    48W / 300W |     40MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      7354      C   nvidia-cuda-mps-server                        30MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/lib64/libcudart_static.a\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.2/lib64/libcudart.so.9.2.88\r\n/usr/local/cuda-9.2/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n\r\n--------\r\n\r\n### Describe the problem\r\nThe timeout_in_ms for session run_options seems to be not working as expected.\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\n\r\ni = tf.constant(0)\r\nc = lambda i: True\r\nb = lambda i: tf.add(i, 1)\r\n\r\nprint(\"Testing timeout\")\r\n\r\nr = tf.while_loop(c, b, [i])\r\nwith tf.Session() as sess:\r\n        sess.run(r, options=tf.RunOptions(timeout_in_ms=3000))\r\n\r\n```\r\n\r\nThe above code goes into an infinite loop and the timeout_in_ms is not taking effect.", "comments": ["Can you please help here?", "@bhagatindia I can reproduce this issue. It seems to be caused by the lack of `CancellationManager` in the while-loop related ops. I'm working on the fix. Will keep you updated. \r\n\r\ncc @skye @mrry Is my understanding right and any suggestions?", "PR #23811 is submitted to fix this issue.", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22216, "title": "tensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7.4.1708\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.4.5\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n\r\n### Describe the problem\r\nI am trying to run a char_rnn model on a TPU. To do so I am using \r\ntf.contrib.recurrent.functional_rnn. It runs successfully on CPU. When I change it to XLA_CPU I am running into the error mentioned in the title. I built from source, and the XLA_CPU works well for my other models. \r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\n\t [[Node: test_conv/Forward_eNPkQVpjczA = Forward_eNPkQVpjczA[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_6/_7, cluster_31/_2/_3, cluster_28/_10/_11, cluster_28/_10/_11, cluster_26/_14/_15, cluster_29/_8/_9/_69)]]\r\n\t [[Node: cluster_27/_12/_13/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_68_cluster_27/_12/_13\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n````\r\n", "comments": ["Can you give a self-contained example to reproduce the issue? And the stacktrace of the error?", "This is the input for the code\r\n[input.txt](https://github.com/tensorflow/tensorflow/files/2416432/input.txt)\r\n\r\nThe code is:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\nimport argparse\r\nfrom tensorflow.python.estimator import run_config\r\nfrom tensorflow.python.ops.rnn import _transpose_batch_time\r\nfrom tensorflow.python.training import training\r\n\r\nBATCH_SIZE = 64\r\nSEQ_LENGTH = 32\r\nNUM_BATCHES = 1\r\n\r\ndef file_to_input_data(file, seq_length):\r\n    \"\"\"\r\n    Reads file, divides into train, validation, test sets and returns the\r\n    corresponding input source arrays\r\n    \"\"\"\r\n    with open(file, 'r') as f:\r\n        data = f.read()\r\n\r\n    char_array = np.array(list(data))\r\n    char_list, mapped_array = np.unique(char_array, return_inverse=True)\r\n\r\n    char_map = {c: i for i, c in enumerate(char_list)}\r\n    indices_char = {i: c for i, c in enumerate(char_list)}\r\n\r\n    num_unique_chars = char_list.shape[0]\r\n    dataset_size = mapped_array.shape[0]\r\n\r\n    # create the partitions\r\n    val_start = int(0.7 * dataset_size)\r\n    test_start = int(0.8 * dataset_size)\r\n    train_data, val_data, test_data = np.array_split(mapped_array,\r\n                                                     [val_start, test_start])\r\n\r\n    # truncate into multiple of seq length\r\n    def _truncate(x):\r\n        return x[:(x.shape[0] // seq_length) * seq_length]\r\n\r\n    return {\r\n        \"train\": _truncate(train_data),\r\n        \"val\": _truncate(val_data),\r\n        \"test\": _truncate(test_data),\r\n        \"vocab_size\": num_unique_chars,\r\n        \"char_map\": char_map,\r\n        \"indices_char\": indices_char\r\n    }\r\n\r\ndef shifted(x, value=0):\r\n    '''\r\n    returns target for a given linear sequence, x\r\n    '''\r\n    print(x.shape)\r\n\r\n    return np.append(x[1:],0)#np.pad(x[:-1], (1, 0), \"constant\", constant_values=value)\r\n\r\n\r\ndef data_from_file(file, seq_length):\r\n    \"\"\"Takes params, file, converts to one hot numpy arrays\r\n    and returns x, y, and vocab_size\"\"\"\r\n    text = open(file).read()[:10000] # for debugging\r\n    print(\"Corpus len:\", len(text))\r\n    chars = sorted(list(set(text)))\r\n    vocab_size = len(chars)\r\n    print('total chars:', len(chars))\r\n    char_indices = dict((c, i) for i, c in enumerate(chars))\r\n    indices_char = dict((i, c) for i, c in enumerate(chars))\r\n    sentences = []\r\n    next_chars = []\r\n    for i in range(0, len(text)-seq_length, 2):\r\n        sentences.append(text[i:i+seq_length]) #\"the cat in the ha\"\r\n        next_chars.append(text[i+seq_length])     #\"t\"\r\n    print(\"Vectorization...\")\r\n    x = np.zeros((len(sentences), seq_length, vocab_size), dtype=np.float32)\r\n    y = np.zeros((len(sentences), vocab_size), dtype=np.float32)\r\n    for i, sentence in enumerate(sentences):\r\n        for t, char in enumerate(sentence):\r\n            x[i, t, char_indices[char]] = 1\r\n        y[i, char_indices[next_chars[i]]] = 1\r\n    return {'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\r\n\r\n\r\ndef input_fn(params, mode):\r\n    batch_size = params.get('batch_size', BATCH_SIZE)\r\n    seq_length = params.get('seq_length', SEQ_LENGTH)\r\n    char_indices = params.get('char_indices', None)\r\n    num_classes = params.get('num_classes', None)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        x = params.get('x', None)#[:32000]  #[:batch_size*NUM_BATCHES]\r\n        #print(\"X SHAPE\", x.shape)\r\n        y = params.get('y', None) #size: (4984, 57) for 10,000 char sample\r\n        repeat_count = None\r\n    elif mode == tf.estimator.ModeKeys.EVAL:\r\n        data_source = params.get('val_data', None)\r\n        repeat_count = 1\r\n    elif mode == tf.estimator.ModeKeys.PREDICT:\r\n        sentence = params.get('seed_text')\r\n        char_indices = params.get('char_indices')\r\n\r\n\r\n        x = np.zeros((len(sentence)//seq_length, seq_length, num_classes), dtype=np.float32)\r\n        for t, char in enumerate(sentence):\r\n            x[0, t, char_indices[char]] = 1\r\n\r\n\r\n        #print(\"X SHAPE: \", x.shape)\r\n        ds = tf.data.Dataset.from_tensor_slices(x)\r\n        ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(1))\r\n        return ds\r\n\r\n    assert x is not None, \"Must supply the data\"\r\n\r\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\r\n    ds = ds.repeat(repeat_count)\r\n    ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n\r\n    return ds\r\n\r\n\r\ndef lstm_model_fn(features, labels, mode, params):\r\n    \"\"\" Basic RNN that uses LSTM Cells\r\n    features = input_tensors: one-hot tensors encoding the chars\r\n    mode: instance of tf.estimator.ModeKeys (e.g. ModeKeys.TRAIN)\r\n    rnn_type = GRU, LSTM, BasicRNN\r\n    params: dict specifying [learning_rate, seq_length, hidden_units]\"\"\"\r\n\r\n    with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"):\r\n        with tf.variable_scope(\"test_rnn\", use_resource=True):\r\n            num_classes = params.get(\"num_classes\")\r\n            batch_size = params.get('batch_size', BATCH_SIZE)\r\n            state_size = params.get(\"state_size\", 128)\r\n            seq_length = params.get(\"seq_length\", SEQ_LENGTH)\r\n\r\n        #     labels = tf.Print(labels, [labels, tf.shape(labels), \"LABELS SHAPE\"])\r\n\r\n            # input tensors need to be [batch_size x sentence_size x vocab_size]\r\n            #lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)#tf.nn.rnn_cell.BasicLSTMCell(state_size)\r\n            lstm_cell = tf.nn.rnn_cell.BasicRNNCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)\r\n            initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\r\n            logits = None\r\n            predictions = None\r\n\r\n            if mode != tf.estimator.ModeKeys.PREDICT:\r\n                inputs=features\r\n                outputs,final_state=tf.contrib.recurrent.functional_rnn(cell=lstm_cell,\r\n                            inputs=inputs,initial_state=initial_state,scope=\"func\",\r\n                            sequence_length=seq_length,\r\n                            dtype= tf.float32)\r\n                #outputs = outputs_ta#.stack()\r\n\r\n                #outputs = _transpose_batch_time(outputs)\r\n        #         outputs = tf.Print(outputs, [outputs, tf.shape(outputs), \"outputs SHAPE\"])\r\n                with tf.variable_scope(\"rnn_final\",use_resource=True): #to allow prediction to call same function\r\n                    logits = tf.layers.dense(\r\n                        outputs, num_classes, name=\"final_layer\") #tf.reshape(outputs, [-1 , state_size])\r\n\r\n                logit_loss = logits[:,-1,:] #(64, 57) gets the prediction from the whole sequence\r\n                logit_loss = tf.reshape(logit_loss, (batch_size, num_classes))\r\n\r\n\r\n                predictions = tf.argmax(logits, axis=1,name=\"predictions\")\r\n\r\n            elif mode == tf.estimator.ModeKeys.PREDICT:\r\n                seed_length = len(params.get('seed_text'))\r\n                target_length = params.get('target_length')\r\n                inputs = features\r\n\r\n                outputs_ta,final_state=tf.contrib.recurrent.functional_rnn(lstm_cell,inputs,initial_state=initial_state,scope=\"func\")\r\n                predictions = outputs_ta.stack()\r\n\r\n                predictions = tf.Print(predictions, [predictions[90], \"PREDICTIONS\"])\r\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n            loss = tf.reduce_mean(\r\n                    tf.nn.softmax_cross_entropy_with_logits(\r\n                    logits=logit_loss, labels=labels)) #tf.reshape(labels, [-1]))\r\n\r\n            optimizer = tf.train.MomentumOptimizer(learning_rate=0.15, momentum=0.97)\r\n\r\n            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n\r\n            if mode == tf.estimator.ModeKeys.TRAIN:\r\n                return tf.estimator.EstimatorSpec(\r\n                    mode=mode, loss=loss, train_op=train_op)\r\n            elif mode == tf.estimator.ModeKeys.EVAL:\r\n                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)\r\n\r\nif __name__ == \"__main__\":\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\r\n        '--train_file',\r\n        type=str,\r\n        default=os.path.expanduser(\"./input.txt\"),\r\n        help='where pre-processed data is stored')\r\n    parser.add_argument(\r\n        '--mode',\r\n        type=str,\r\n        default='train',\r\n        help='train, eval, or predict')\r\n    parser.add_argument(\r\n        '--num_states', type=int, default=128, help='size of each rnn layer')\r\n    parser.add_argument(\r\n        '--seed_text', type=str, default=\"The Volsces have much corn; take\", help='seed for prediction mode')\r\n    parser.add_argument(\r\n        '--target_length', type=int, default=100, help='the output length of your given prediction')\r\n    parser.add_argument(\r\n        '--seq_length', type=int, default=SEQ_LENGTH, help='number of unrolled time steps')\r\n    parser.add_argument(\r\n        '--num_steps', type=int, default=10, help='number of training steps')\r\n    parser.add_argument(\r\n        '--batch_size', type=int, default=BATCH_SIZE, help=\"samples per batch\")\r\n    args = parser.parse_args()\r\n\r\n    data = data_from_file(args.train_file, seq_length=args.seq_length)\r\n\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn=lstm_model_fn,\r\n        params={\r\n            'num_classes': data[\"vocab_size\"],\r\n            'state_size': args.num_states,\r\n            'batch_size': args.batch_size,\r\n            'seq_length': args.seq_length,\r\n            'x': data[\"x\"],\r\n            'y': data['y'],\r\n            'char_indices': data[\"char_indices\"],\r\n            'seed_text': args.seed_text,\r\n            'target_length': args.target_length,\r\n        },\r\n        config=run_config.RunConfig(\r\n            save_summary_steps=10,\r\n            save_checkpoints_steps=100,\r\n            model_dir=\"./model\"))\r\n\r\n    classifier.train(input_fn, steps=args.num_steps)\r\n```\r\n\r\n\r\n\r\nthis is the stacktrace of the error: \r\n```\r\n2018-09-25 10:54:39.604560: E tensorflow/core/common_runtime/executor.cc:697] Executor failed to create kernel. Not found: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\nTraceback (most recent call last):\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\r\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"basic_rnn.py\", line 236, in <module>\r\n    classifier.train(input_fn, steps=args.num_steps)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\r\n    saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\r\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```", "Thanks for providing a self-contained example to reproduce the issue. That's always useful!\r\n\r\n'device:XLA_CPU:0' is used primarily for testing. Please take a look at https://www.tensorflow.org/performance/xla/jit for instructions on other ways to invoke XLA.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/17458 discusses this in more details.\r\n\r\nClosing this issue but feel free to file a new issue in case you run into an actual bug after following the XLA guide.", "@smit-hinsu, thanks for the response, but this issues seems independent of how I invoke XLA, since the other ways suggested, would keep it on the cpu device instead of the xla_cpu device which kind of hides the problem but doesn't solve it for my use case. Ideally I would want the entire graph to run on xla_cpu(currently the only way it seems to work, is by moving the while loop to the cpu). I am not running on a distributed system, so the concerns raised in #17458 may not be applicable here.  \r\n \r\nI don't think this has been fixed, so could you reopen this issue and #22102", "Could you update the example reproducing the issue with either Session or Manual mode as described in https://www.tensorflow.org/extend/xla/jit? Or you could use xla.compile as suggested by @jpienaar in the #22102. See https://github.com/tensorflow/tensorflow/blob/8c33e02e66b936d947245e6a0943898b810b16c4/tensorflow/contrib/compiler/xla.py#L63\r\n\r\nThanks!", "I used the xla.compile as seen [here] (https://github.com/tensorflow/tensorflow/issues/22102#issuecomment-428684652) (that is the stack trace when I run it)\r\n\r\nThe code I ran is : \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\nimport argparse\r\nfrom tensorflow.python.estimator import run_config\r\nfrom tensorflow.python.ops.rnn import _transpose_batch_time\r\nfrom tensorflow.python.training import training\r\n\r\nfrom tensorflow.python import debug as tf_debug\r\nhooks = [tf_debug.LocalCLIDebugHook()]\r\n\r\n\r\n\r\nBATCH_SIZE = 64#64\r\nSEQ_LENGTH = 32 #32\r\nNUM_BATCHES = 1 #for testing on really small datasets\r\n\r\n\r\ndef data_from_file(file, seq_length):\r\n    \"\"\"Takes params, file, converts to one hot numpy arrays\r\n    and returns x, y, and vocab_size\"\"\"\r\n    text = open(file).read()[:10000] # for debugging\r\n    print(\"Corpus len:\", len(text))\r\n    chars = sorted(list(set(text)))\r\n    vocab_size = len(chars)\r\n    print('total chars:', len(chars))\r\n    char_indices = dict((c, i) for i, c in enumerate(chars))\r\n    indices_char = dict((i, c) for i, c in enumerate(chars))\r\n    sentences = []\r\n    next_chars = []\r\n    for i in range(0, len(text)-seq_length, 2):\r\n        sentences.append(text[i:i+seq_length]) #\"the cat in the ha\"\r\n        next_chars.append(text[i+seq_length])     #\"t\"\r\n    print(\"Vectorization...\")\r\n    x = np.zeros((len(sentences), seq_length, vocab_size), dtype=np.float32)\r\n    y = np.zeros((len(sentences), vocab_size), dtype=np.float32)\r\n    for i, sentence in enumerate(sentences):\r\n        for t, char in enumerate(sentence):\r\n            x[i, t, char_indices[char]] = 1\r\n        y[i, char_indices[next_chars[i]]] = 1\r\n    return {'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\r\n\r\n\r\ndef input_fn(params, mode):\r\n    batch_size = params.get('batch_size', BATCH_SIZE)\r\n    seq_length = params.get('seq_length', SEQ_LENGTH)\r\n    char_indices = params.get('char_indices', None)\r\n    num_classes = params.get('num_classes', None)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        x = params.get('x', None)#[:32000]  #[:batch_size*NUM_BATCHES]\r\n        #print(\"X SHAPE\", x.shape)\r\n        y = params.get('y', None) #size: (4984, 57) for 10,000 char sample\r\n        repeat_count = None\r\n    elif mode == tf.estimator.ModeKeys.EVAL:\r\n        data_source = params.get('val_data', None)\r\n        repeat_count = 1\r\n    elif mode == tf.estimator.ModeKeys.PREDICT:\r\n        sentence = params.get('seed_text')\r\n        char_indices = params.get('char_indices')\r\n\r\n\r\n        x = np.zeros((len(sentence)//seq_length, seq_length, num_classes), dtype=np.float32)\r\n        for t, char in enumerate(sentence):\r\n            x[0, t, char_indices[char]] = 1\r\n\r\n\r\n        #print(\"X SHAPE: \", x.shape)\r\n        ds = tf.data.Dataset.from_tensor_slices(x)\r\n        ds=ds.batch(1)\r\n        features,labels=ds.make_one_shot_iterator().get_next()\r\n        #ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n        return features,labels\r\n\r\n    assert x is not None, \"Must supply the data\"\r\n    #print(\"test1\")\r\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\r\n    ds = ds.repeat(repeat_count)\r\n    #print(\"test2\")\r\n    ds=ds.batch(batch_size)\r\n    #ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    features,labels=ds.make_one_shot_iterator().get_next()\r\n    return features,labels\r\n\r\n\r\ndef lstm_model_fn(features, labels, mode, params):\r\n    \"\"\" Basic RNN that uses LSTM Cells\r\n    features = input_tensors: one-hot tensors encoding the chars\r\n    mode: instance of tf.estimator.ModeKeys (e.g. ModeKeys.TRAIN)\r\n    rnn_type = GRU, LSTM, BasicRNN\r\n    params: dict specifying [learning_rate, seq_length, hidden_units]\"\"\"\r\n    if True:\r\n    #with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"):\r\n        with tf.variable_scope(\"test_conv\", use_resource=True):\r\n            num_classes = params.get(\"num_classes\")\r\n            batch_size = params.get('batch_size', BATCH_SIZE)\r\n            state_size = params.get(\"state_size\", 128)\r\n            seq_length = params.get(\"seq_length\", SEQ_LENGTH)\r\n\r\n        #     labels = tf.Print(labels, [labels, tf.shape(labels), \"LABELS SHAPE\"])\r\n\r\n            # input tensors need to be [batch_size x sentence_size x vocab_size]\r\n            #lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)#tf.nn.rnn_cell.BasicLSTMCell(state_size)\r\n            lstm_cell = tf.nn.rnn_cell.BasicRNNCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)\r\n            initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\r\n            logits = None\r\n            predictions = None\r\n\r\n            if mode != tf.estimator.ModeKeys.PREDICT:\r\n                inputs=features\r\n                outputs,final_state=tf.contrib.recurrent.functional_rnn(cell=lstm_cell,\r\n                            inputs=inputs,initial_state=initial_state,scope=\"func\",\r\n                            sequence_length=seq_length,\r\n                            dtype= tf.float32,use_tpu=True)\r\n                #outputs = outputs_ta#.stack()\r\n\r\n                #outputs = _transpose_batch_time(outputs)\r\n        #         outputs = tf.Print(outputs, [outputs, tf.shape(outputs), \"outputs SHAPE\"])\r\n                with tf.variable_scope(\"rnn_final\",use_resource=True): #to allow prediction to call same function\r\n                    logits = tf.layers.dense(\r\n                        outputs, num_classes, name=\"final_layer\") #tf.reshape(outputs, [-1 , state_size])\r\n\r\n                logit_loss = logits[:,-1,:] #(64, 57) gets the prediction from the whole sequence\r\n                logit_loss = tf.reshape(logit_loss, (batch_size, num_classes))\r\n\r\n\r\n                predictions = tf.argmax(logits, axis=1,name=\"predictions\")\r\n\r\n            elif mode == tf.estimator.ModeKeys.PREDICT:\r\n                seed_length = len(params.get('seed_text'))\r\n                target_length = params.get('target_length')\r\n                inputs = features\r\n\r\n                outputs_ta,final_state=tf.contrib.recurrent.functional_rnn(lstm_cell,inputs,initial_state=initial_state,scope=\"func\",use_tpu=True)\r\n                predictions = outputs_ta.stack() #outputs of this are partly one-hot, partly log probs?\r\n\r\n\r\n                predictions = tf.Print(predictions, [predictions[90], \"PREDICTIONS\"])\r\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n        #     acc_labels = tf.reshape(labels, [-1, 1]) #disabling accuracy since shapes mismatched\r\n        #     accuracy = tf.metrics.accuracy(labels=acc_labels, predictions=predictions, name=\"acc_op\")\r\n\r\n            loss = tf.reduce_mean(\r\n                    tf.nn.softmax_cross_entropy_with_logits(\r\n                    logits=logit_loss, labels=labels)) #tf.reshape(labels, [-1]))\r\n\r\n            optimizer = tf.train.MomentumOptimizer(learning_rate=0.15, momentum=0.97)\r\n            #     optimizer = tf.train.AdamOptimizer(learning_rate=0.15)\r\n            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n\r\n        #     metrics = {\"accuracy\": accuracy}\r\n        #     tf.summary.scalar('accuracy', accuracy[1])\r\n\r\n            #specify what to do with each mode\r\n            if mode == tf.estimator.ModeKeys.TRAIN:\r\n                return tf.estimator.EstimatorSpec(\r\n                    mode=mode, loss=loss, train_op=train_op)\r\n            elif mode == tf.estimator.ModeKeys.EVAL:\r\n                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\r\n        '--train_file',\r\n        type=str,\r\n        default=os.path.expanduser(\"./input.txt\"), #currently only works with 'input.txt'?\r\n        help='where pre-processed data is stored')\r\n    parser.add_argument(\r\n        '--mode',\r\n        type=str,\r\n        default='train',\r\n        help='train, eval, or predict')\r\n    parser.add_argument(\r\n        '--model_dir',\r\n        type=str,\r\n        default=\"/tmp/char_rnn\",\r\n        help='where to store model results')\r\n    parser.add_argument(\r\n        '--num_states', type=int, default=128, help='size of each rnn layer')\r\n    parser.add_argument(\r\n        '--seed_text', type=str, default=\"The Volsces have much corn; take\", help='seed for prediction mode')\r\n    parser.add_argument(\r\n        '--target_length', type=int, default=100, help='the output length of your given prediction')\r\n    parser.add_argument(\r\n        '--seq_length', type=int, default=SEQ_LENGTH, help='number of unrolled time steps')\r\n    parser.add_argument(\r\n        '--num_steps', type=int, default=10, help='number of training steps')\r\n    parser.add_argument(\r\n        '--batch_size', type=int, default=BATCH_SIZE, help=\"samples per batch\")\r\n    args = parser.parse_args()\r\n\r\n    data = data_from_file(args.train_file, seq_length=args.seq_length)\r\n    #{'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\r\n\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn=lstm_model_fn,\r\n        params={\r\n            'num_classes': data[\"vocab_size\"],\r\n            'state_size': args.num_states,\r\n            'batch_size': args.batch_size,\r\n            'seq_length': args.seq_length,\r\n            'x': data[\"x\"],\r\n            'y': data['y'],\r\n            'char_indices': data[\"char_indices\"],\r\n            'seed_text': args.seed_text,\r\n            'target_length': args.target_length,\r\n        },\r\n        config=run_config.RunConfig(\r\n            save_summary_steps=10,\r\n            save_checkpoints_steps=100,\r\n            model_dir=\"./model\"))\r\n\r\n\r\n\r\nfrom tensorflow.contrib.compiler.xla import compile\r\n\r\ndef run(features,labels):\r\n    mode=tf.estimator.ModeKeys.TRAIN\r\n    params=classifier.params\r\n    net=lstm_model_fn(features, labels, mode, params)\r\n    graph = tf.get_default_graph()\r\n    list_tensors=[]\r\n    for op in graph.get_operations():\r\n        if(len(op.values())>0):\r\n            list_tensors.append(op.values()[0])\r\n\r\n    return list_tensors+tf.get_default_graph().get_operations()\r\n\r\nfeatures,labels=input_fn(classifier.params,tf.estimator.ModeKeys.TRAIN)\r\n#features,labels=csv_input_fn(train_path, train_batch_size)\r\nresult=compile(run,inputs=[features,labels])\r\n\r\nwith tf.Session() as sess:\r\n   sess.run(tf.global_variables_initializer())\r\n   sess.run(result)\r\n```\r\n\r\nHope this helps \r\n\r\n", "Thanks for the updated code.\r\n\r\nI will assign this to @jpienaar for triage.", "got fixed in tf1.12 :) \r\n\r\nCorrection: allow_soft_placement is being set to True by default, when set to false, still fails :( ", "in tf1.13 using dynamic_rnns use xla entirely :)"]}, {"number": 22215, "title": "How to get max and min x and y of bounding boxes from Object_detection_image.py?", "body": "this is the link of the image:\r\nhttps://ibb.co/nbLjc9\r\n\r\nAfter I print the \"boxes\" variable, it gives an array of numbers.\r\n\r\nWhen I change the values inside, the bounding box changes too.\r\n\r\nSo, I am pretty sure those are the values will give different size and location of bounding boxes.\r\n\r\nHowever, how can I get the max and min bounding box from this array?\r\n\r\nlike max y = 1920, max x = 1080, min y = 0, min x = 0.\r\n\r\nThank you. ", "comments": ["If you are trying to get the min/max x and y from the array in your output, simply read the output into ndarray using numpy then find the min and max. "]}, {"number": 22212, "title": "Tensorflow with MKL Very Slow", "body": "I am trying to reduce the time taken by an LSTM model using MKL. I use Tensorflow 1.10.0. I have give information about configuration I am using below. It will be great, if you can help me improve the speed of my model. Please let me know what more information you need. Thanks a lot!\r\n\r\nCPU make and model (try lscpu; if your lscpu does not list CPU flags,\r\ntry running cat /proc/cpuinfo | grep flags | sort -u)\r\nflags\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n\r\nOS version (uname -a)\r\nLinux ip-172-31-24-72 4.14.67-66.56.amzn1.x86_64 #1 SMP Tue Sep 4 22:03:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nCompiler version (gcc --version)\r\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)\r\n\r\nos.environ['OMP_NUM_THREADS'] = '32'\r\nos.environ['KMP_BLOCKTIME'] = '0'\r\nos.environ['KMP_AFFINITY'] = 'granularity=fine,verbose,compact,1,0'\r\nK.set_image_data_format('channels_first')\r\nconfig = tf.ConfigProto()\r\nconfig.inter_op_parallelism_threads = 1\r\nconfig.intra_op_parallelism_threads = 32\r\nsession = tf.Session(config=config)\r\nK.set_session(session)\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nNo\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n\r\n- **Python version**:\r\n2.7\r\n\r\n- **Bazel version (if compiling from source)**:\r\nhttps://copr.fedorainfracloud.org/coprs/vbatts/bazel/repo/epel-7/vbatts-bazel-epel-7.repo\r\n\r\n- **CUDA/cuDNN version**:\r\nNone\r\n\r\n- **GPU model and memory**:\r\nNone", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nOS Platform and Distribution\nExact command to reproduce", "`config.inter_op_parallelism_threads = 1` doesn't seem right to me. Can you try with 16/32?", "@drpngx Can you please take a look at this issue?. My initial investigation tells me that currently MKL-DNN supports CNN models for high performance computation whereas it requires additional effort for speeding up LSTM models which is yet to be completed. Probably you can guide me better here.", "@zealthinker Can you please post your observations from @ezhulenev  suggestion whenever you get a chance?\r\n\r\n> `config.inter_op_parallelism_threads = 1` doesn't seem right to me. Can you try with 16/32?\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Tested on Tensorflow 1.10.0 and tensorflow built with MKL is slower for LSTM models. I updated \r\n```\r\nconfig.inter_op_parallelism_threads, config.intra_op_parallelism_threads\r\n```\r\nwith difference combination and could not see significant improvement.", "@hhbyyh  Can you please create a new issue for this? You can mention this issue number in your new issue as well, so that we know the context as well. Thanks!", "I've noticed the same thing on Tensorflow v1.13.1\r\n\r\nAfter discovering the `TF_DISABLE_MKL` flag, I found that disabling the Intel MKL on my LSTM model doubles the performance on both Haswell and Skylake architectures."]}, {"number": 22211, "title": "The latest process of building tensorflow serving", "body": "\r\nHi, friends, can someone tell me the latest process of building tensorflow serving? I have tried the methods provided by the official documentation, but it failed, I need your help.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@HowieChang7 Please refer [here](https://stackoverflow.com/questions/51554543/build-tensorflow-serving-for-python3-failed) for issues related to building tf serving.\r\n\r\nAlso, this question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 22210, "title": "Apache Ignite Dataset", "body": "This is a proposal to add `IgniteDataset` that allows to work with [Apache Ignite](https://ignite.apache.org/). \r\n\r\nApache Ignite is a memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads, delivering in-memory speeds at petabyte scale. This proposal is a part of a more global initiative to implement so called \"TensorFlow on Apache Ignite\" ([IGNITE-8335](https://issues.apache.org/jira/browse/IGNITE-8335), [Design Document](https://docs.google.com/document/d/1jROIahK1rc7bSgOvhJhfpMqIGvht_IE8zn5NAt6x8ks)).\r\n\r\nThe integration is based on Apache Ignite [Binary Client Protocol](https://apacheignite.readme.io/v2.6/docs/binary-client-protocol) and TensorFlow [tf.data.Dataset](https://www.tensorflow.org/guide/datasets). More information about supported features you can find in [README.md](https://github.com/dmitrievanthony/tensorflow/blob/apache-ignite-dataset/tensorflow/contrib/ignite/README.md) of this module.\r\n\r\nTests have also been added. They use docker to hide configuration complexity, so that the implemented functionality can be tested quite simply by manual run.\r\n\r\n**It's a copy of #21853, because previous request has accidentally been closed because I cleaned up merge commits from the branch.**", "comments": ["Hello @mrry, @martinwicke, @perfinion. Sorry for confusion, I've recreated #21853 here. The current state is:\r\n\r\n- I've fixed all comments from @mrry.\r\n- During last CI run only Windows builds and Clang checks failed.\r\n- I've fixed Clang checks.\r\n\r\nRegarding Windows builds I see the same issues I had and asked here: https://groups.google.com/a/tensorflow.org/forum/#!topic/build/ePYss0Kxcu4. It looks like we need to add copt=-DWIN32_LEAN_AND_MEAN on CI server for Windows builds.\r\n\r\nGuys, let me ask you to continue review.", "Hi @mrry. Thank you for very detailed and deep review, I really appreciate it. I think I fixed all your comments today, so could you please have a look my changes?", "Meanwhile, @martinwicke, @perfinion, could you please rerun tests? I made a lot of changes, would be great to check CI statuses.", ": added `kokoro:run` label to help start the tests.", "@dmitrievanthony The test failure for `Experimental clang-format Check` is related to clang-format. You can use `clang-format -is --style=google <filename.cc>` to fix them.\r\n\r\nHowever, different clang-format versions may generate different outputs. I think you could use clang-format bundled with Ubuntu 16.04 to get the outputs that matches the `Experimental clang-format Check`.\r\n\r\nIf you have Docker installed on your machine, I think you may use:\r\n```\r\ndocker run -i -t --rm \\\r\n    -v $PWD:/tensorflow -w /tensorflow --net=host ubuntu:16.04 \\\r\n    sh -c 'apt-get -y update && apt-get -y install clang-format && clang-format -i --style=google tensorflow/contrib/ignite/kernels/ignite_byte_swapper.h'\r\n```\r\n\r\nto format the ignite_byte_swapper.h that is consistent with `Experimental clang-format Check`.", "Thank you, @yongtang. I fixed code style, but I see one confusing thing: `clang-format` suggests another order of \"includes\". Anyway, I updated the code so that CI style checks should pass.\r\n\r\n**Regarding Windows builds**, as I wrote above, I see the same issues I had and asked here: https://groups.google.com/a/tensorflow.org/forum/#!topic/build/ePYss0Kxcu4. It looks like we need to add `copt=-DWIN32_LEAN_AND_MEAN` on CI server for Windows builds. So, I think the problem on CI-side, not in code. Am I right?", "@dmitrievanthony I think you could add copts = [\"-DWIN32_LEAN_AND_MEAN\"] in `tensorflow/contrib/ignite/BUILD` to achieve a similar effect. Maybe you could give it a try?", "Thanks for a great advice, @yongtang. Looks like it works. Could you please check it on CI?", "Do you know, what buildifier suggests me to do here, @yongtang?\r\n\r\n```\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n57a58,60\r\n>     copts = if_windows([\r\n>         \"-DWIN32_LEAN_AND_MEAN\",\r\n>     ]),\r\n64,66d66\r\n<     copts = if_windows([\r\n<         \"-DWIN32_LEAN_AND_MEAN\",\r\n<     ]),\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```\r\n\r\nRegarding Windows GPU, it fails in some other module:\r\n\r\n```\r\nERROR: T:/src/github/tensorflow/tensorflow/contrib/nccl/BUILD:24:1: Linking of rule '//tensorflow/contrib/nccl:python/ops/_nccl_ops.so'\r\n```", "@dmitrievanthony The buildifier to format the BUILD file is:\r\nhttps://github.com/bazelbuild/buildtools/blob/master/buildifier/README.md\r\n", "@dmitrievanthony I created a PR #22258 to fix the Windows GPU build failure issue.\r\n", "Yes, buildifier just wanted reordering, @yongtang. I applied fixes.", "Hi @mrry. It's been 6 days since I fixed all review comments. Could you please take a look?", "Regarding security question, @mrry, @martinwicke, I think we can add warning in case user specifies sensitive data via parameters. What do you think?", "I think we should make it hard for credentials to end up in files or on the network in the clear. Therefore, I would prefer if we insist here that all credentials are present on the executing machine already, and we make it impossible to use credentials that are stored in the graph. \r\n\r\nI think environment variables would work fine in this case, can we restrict it to that for all sensitive information?", "I agree, it's reasonable, @mrry, @martinwicke. I updated code so that sensitive information is not encoded in graph. Be aware that it's still used in python for initial access (that is required to get data schema), but after that only environment variables are used.", "Do we have any open questions, @mrry?", "Guys, looks like I introduced a bug on Windows when changed `ignite_byte_swapper.h`. It's fixed now, so please rerun tests who can do it.\r\n\r\nAlso, as we found out previously, it was a bug in master that leads to Windows GPU build failure. See https://github.com/tensorflow/tensorflow/pull/22210#issuecomment-421089282: \r\n\r\n> @dmitrievanthony I created a PR #22258 to fix the Windows GPU build failure issue.\r\n\r\nShould I merge master into my branch? Or it's fine that Windows GPU build is broken by non-related to my code reason?", "@dmitrievanthony The windows GPU fix has been submitted internally so the build should pass. Let me help with rerun the test.", "Ok, @mrry, @martinwicke, @yongtang, all tests I expected to pass actually passed. XLA fails, but it fails all the time by reasons that are not related to my code.\r\n\r\nDerek, sorry for bothering you again, but we need you approval again. After that this PR can be merged, right?", "Hi, @mrry, @martinwicke. I'm not sure how long it takes to pass all internal steps, but it looks like it takes time. Meanwhile, as far as I see, there are several conflicts appeared. Shall I fix them?", "No need to update the branch. We're in the process of getting it to merge internally.\r\n\r\nFYI: You should check the diff between what we end up merging, and the original PR. Our internal checks seem to be more picky about style and other issues than the presubmit. It has also been necessary to disable the SSL tests and remove the checked-in private key file."]}, {"number": 22209, "title": "Does it support Android Neural Networks API?", "body": "Have I written custom code N/A\r\nOS Platform and Distribution Ubuntu 18.04\r\nTensorFlow installed from anaconda\r\nTensorFlow version 1.3.0\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A\r\nMobile devic Pixel 2", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@manchengfenxu Hi, Could you please describe your issue/question clearly ?", "@harshini-gadige Hi, I am asking if Android Neural Networks [API](https://developer.android.com/ndk/guides/neuralnetworks/)\r\ncan be deployed  to accelerate [TensorFlow Android Camera Demo ](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)  on an Android device (Pixel 2)?", "@achowdhery Hi, could you please look into this ?", "All of our Android examples @ https://github.com/tensorflow/examples/tree/master/lite now support execution with [NNAPI](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/nnapi)."]}]