[{"number": 11636, "title": "stack bidirectional RNNs: swap_memory and time_major args", "body": "### Feature Request\r\nadding `swap_memory` and `time_major` arguments to `stack_bidirectional_rnn` and `stack_bidirectional_dynamic_rnn`\r\n\r\nfrom the source i see that both stack_bidirectional function just wraps bidirectional_rnn so it use concatenated output as next bidirectional layer's input. is it intentional that `swap_memory` and `time_major` argument not added?", "comments": ["@ebrevdo : Any comments?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Looks like it was fixed in #12297."]}, {"number": 11635, "title": "Why are tensorboard removed after r1.2?", "body": "Previously it was located in tensorflow/tensorboard. Is it removed or moved to somewhere else? What if I want to add new features in tensorboard?\r\n\r\nAny suggestion is appreciated! \r\n", "comments": ["Tensorboard has been moved to it's own project/repository! If you'd like to contribute to Tensorboard then checkout the github page here: https://github.com/tensorflow/tensorboard", "@jubjamie Cool, thanks for pointing that out! I am wondering if there was a huge change, seems like the new repository does not use nodejs anymore, is there any documentation about how to run the system? Or what kind of tool should I use? Thanks a lot! ", "afaik not much has changed from the user's pov as of yet. You can still call it in the usual way `tensorboard --logdir=[..]`. I think it's more for ease of development and open-sourcing etc. It means it's its own package now although I believe that it's installed as a dependency of tensorflow so for the user there isn't a huge change. You can point your TB issues and suggestions to the team at tensorflow/tensorboard :)", "Hi @BinhangYuan,\r\n\r\nYou're right that we changed the TensorBoard build system a lot. We no longer use node and associated tooling, we found it was really hard to keep multiple build systems synchronized, since we were using bazel internally and node externally. The result was a really painful build process in open source.\r\n\r\nNow, as you can see at [DEVELOPMENT.md](https://github.com/tensorflow/tensorboard/blob/master/DEVELOPMENT.md), we simply use bazel for everything :)"]}, {"number": 11634, "title": "Add a function for generating random values with predefined seed", "body": "I added a seeded random function, as it was requested in [this PR](https://github.com/tensorflow/tensorflow/pull/11530#issuecomment-315590857):\r\n\r\n> Please use seeded rands to make the tests deterministic and easier to debug.", "comments": ["Can one of the admins verify this patch?", "@drpngx , any suggestions?", "@drpngx is out this week, unfortunately; can this wait until he gets back?", "Jenkins, test this please.", "OK, i just did this one.", "Do these need API review the same way the python API does?", "There is no requirement enforced by the build system. I think the equivalent would be `tensorflow/cc` for API. I think of this more as an internal lib change.", "Oh it's also only in lib_internal, not a public library, so yeah this is probably fine.", "(Though a test would have been nice :)"]}, {"number": 11633, "title": "when connect mnist,download mnist data,show network connection error.", "body": "![image](https://user-images.githubusercontent.com/22673941/28404110-88b436e0-6d5a-11e7-9344-596a22f5d64b.png)\r\nI know if the error show ,just our company can not connect to mnist, can i manual download mnist data, and use it? how can i do this?", "comments": ["Your companies proxy is probably getting in the way. Try setting HTTP_PROXY and HTTPS_PROXY, either in your IDE or Global settings. For windows this is: \r\nSystem Properties-> Advanced -> Environment Variables -> System variables -> New System Variable.  You'll need to get the address and port from your IT team."]}, {"number": 11632, "title": "Add interface for long(int64) datatype", "body": "Added below methods for TensorFlowInferenceInterface\r\n\r\n```Java\r\npublic void feed(String inputName, long[] src, long... dims)\r\npublic void feed(String inputName, LongBuffer src, long... dims)\r\npublic void fetch(String outputName, long[] dst)\r\npublic void fetch(String outputName, LongBuffer dst)\r\n```\r\n\r\nThey are very useful in case when we are handling int64 Tensor (e.g. output of tf.argmax)\r\n\r\nI do not see the unit test file for TensorFlowInferenceInterface.java, so I did not add any test case for the change. But this change is very straight forward. Please let me know if I missed any. Thanks.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins Test this, please."]}, {"number": 11631, "title": "Add logical_or and less_equal to tf_op_files.txt", "body": "Add below ops implementations to the list\r\ntensorflow/core/kernels/cwise_op_logical_or.cc\r\ntensorflow/core/kernels/cwise_op_less_equal.cc\r\n\r\nWhen I am using the Android and iOS lib, above ops are not registered while in full version they are available. I think these are very basic ops and should add to the list by default.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11630, "title": "Add GPU implementation for tf.segment_sum.", "body": "As per #11228, a GPU version of segment sum has been created. \r\n## Performance \r\nOn a Tesla K40c GPU, the following performance tests have been performed. \r\n- The test case sizes are represented using 3-tuples of integers. The first two integers correspond to the outer and inner dimension of the input data and the last integer corresponds to the outer dimension of the output data, which is also the total number of segments. \r\n- The first three rows of data are obtained by running reductions on float32 input type whereas the last three rows of data are obtained by running reductions on float64 input type. \r\n- We use the GPU version of unsorted segment reduction as the baseline. \r\n- During experiments, they share the same input data and outputs are compared for consistency.\r\n\r\n|  | (1024, 1024, 128)            |   (2048, 2048, 256)          |    (4096, 4096, 512)         | \r\n|-------------------------------------------------------------|-------------|-------------|-------------| \r\n| t_unsorted                                                  | 84.942us    | 332.12us    | 1.3170ms    | \r\n| t_sorted                                                    | 71.047us    | 264.16us    | 1.0391ms    | \r\n| speedup                                                     | 1.20  | 1.26 | 1.27  | \r\n|                                                             |             |             |             | \r\n| t_unsorted                                                  | 160.69us    | 594.93us    | 2.2895ms    | \r\n| t_sorted                                                    | 106.94us    | 395.19us    | 1.5662ms    | \r\n| speedup                                                     | 1.50 | 1.51 | 1.46 | \r\n\r\n## Known Limitations:\r\n- We do not check segment_id to make sure that they are within [0, num_outputs-1].\r\n- We do not verify that segment_id is increasing.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "I have updated the pertinent code. Performance tests with more aspect ratios are conducted and recorded in this [gist](https://gist.github.com/tjingrant/3113562d6e9fc8738487ca91847ffd16) including the python code used in this process. The results of both segment_sum and unsorted_segment_sum are always compared for consistency and therefore this also serves as a correctness test for potential race conditions. \r\n\r\nIn general, the execution time of sorted segment sum cuda kernel is uniformly shorter than that of unsorted segment sum cuda kernel when the problem size is medium or large. It is clear that tiling comes with an inherent cost and therefore when the problem size is small, the performance penalty imposed by tiling will be more noticeable but hopefully nevertheless small. Of all the problem sizes tested (small and large problem sizes alike), the average speed up factor is 1.17 for fp32 and 1.38 for fp64. In general, for fp32 typed segment summation, the break even point is around 512x512 and for any problem sizes beyond this point, using sorted segment sum will be profitable. For fp64, this point is very low and we actually did not see executions of any problem sizes during which sorted segment sum is slower.\r\n\r\nIt is also worth noting that sorted segment sum requires a mem copy in order to retrieve the output size (a scalar) from device memory. Therefore the overall break even point is somewhat higher but since this cost is constant, it will not impact the execution time of kernels doing more significant work. Please let me know if there is any way to mitigate this problem. Specifically, \r\n\r\n- is it possible to access the input array on the host before it is moved to the device? \r\n- Or slightly worse, is it possible to have duplicate copies of the input array at both host and device memory?\r\n\r\n", "@zheng-xq can you please take another look?", "@tensorflow-jenkins test this please", "Hi, judging from the console output, I'm not sure if the test failure is caused by my changes.\r\n\r\n`//bazel_pip/tensorflow/contrib/timeseries/python/timeseries:state_management_test FAILED in 13.3s`\r\n\r\nThis does not look like anything I've touched.", "@tjingrant indeed, that appears unrelated to your change.", "@zheng-xq XQ, this appears to pass (except for known flake). Can you approve it?", "LGTM\r\n\r\n@tjingrant, I think it is a good idea to check in your benchmark so the changes are self-sufficient. But I will leave it up to you whether you want to make it into a follow-up CL.\r\n", "Updated with benchmarks included.", "ping @zheng-xq , @rmlarsen ", "I do a quick test about your code with the [script](https://gist.github.com/nolanliou/a1dc1df3d7d6267a0177b6749ccdf696). the result show there is not as good as unsorted_segment_sum with larger scale of segment_ids.\r\n```\r\nunsorted_segment_sum: 5.616264s\r\nsorted_segment_sum: 7.558630s\r\nunique ids: 6287\r\n```", "Hi @nolanliou , thanks for checking out my code! As for your observation, as you probably know, there are a lot of factors that could affect the performance and after all, your ratio of reductions performed to your total data footprint is quite low and therefore in this case I do not expect my code to perform well. I encourage you to explore more problem sizes and reduction to data footprint ratio. Apart from that, the **main reason** you are seeing such a dramatic performance discrepancy is that you are not using the unsorted segment reductions correctly and probably it's not producing the correct results. Try placing it on a CPU device and you will see the error messages.", "Hi @zheng-xq , I think I resolved all your requested changes.", "LGTM, after minor changes.", "I have modified the commit message to use percentage differences and a todo note is added to the file segment_reduction_ops.cc.", "LGTM", "Hi @jhseu , any plan to move forward?", "Jenkins, test this please.", "Hi, the error message seems unrelated to my changes:\r\n```\r\n00:36:53 The following tests FAILED:\r\n00:36:53 \t252 - C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/training/server_lib_test.py (Timeout)\r\n00:36:53 Errors while running CTest\r\n```"]}, {"number": 11629, "title": "missing line of code in get_started tutorial on website", "body": "as mentioned by an issue closed 19 days ago [https://github.com/tensorflow/tensorflow/issues/11042](https://github.com/tensorflow/tensorflow/issues/11042) there is a line missing in the tutorial code at [https://www.tensorflow.org/get_started/get_started#a_custom_model](https://www.tensorflow.org/get_started/get_started#a_custom_model).\r\nthis earlier issue was closed, but on the current version of the site that i see, the issue still persists.\r\n\r\nthe missing line is:\r\n `eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval,4, num_epochs=1000)`\r\n which should appear after: \r\n`input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)`\r\n\r\nplease note that these same lines appear in the code above the mentioned block in the \"basic usage\" section.\r\n\r\nalso, i hope opening a new issue is the correct action in this case. if i should have done something else, please let me know\r\n", "comments": ["@MarkDaoust do you know where it's at?", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/get_started.md\r\nSir the custom model has been updated but is not being reflected on the website.\r\nPlease look through this.", "Thanks for tracking that down shreyneil@. \r\n\r\nThe \"root\" section of the website is synced to releases, but this fix is already visible in the [tf 1.3 docs](https://www.tensorflow.org/versions/r1.3/get_started/get_started).\r\n\r\nThis these docs will become \"root\" when 1.3 is released."]}, {"number": 11628, "title": "A very weird bug of tf_debug: Non-Ok-status env->NewWritableFile(file_path, &f) status: Resource exaustated", "body": "### System information\r\n- **Have I written custom code**:  Yes\r\n- **OS Platform and Distribution**: CentOS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version**: 1.2\r\n- **Python version**:  3.4\r\n\r\nWhen I run the seq2seq model, I got the `nan` loss. Thus I use `tf_debug` to find out where the problem occurs. I use `tf_debug` by \r\n \r\n    sv = tf.train.Supervisor(logdir=FLAGS.log_root,\r\n                             is_chief=True,\r\n                             saver=saver,\r\n                             summary_op=None,\r\n                             save_summaries_secs=60,\r\n                             save_model_secs=FLAGS.checkpoint_secs)\r\n    sess = sv.prepare_or_wait_for_session(config=tf.ConfigProto(\r\n        allow_soft_placement=True))\r\n    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\r\n    sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\r\n\r\nBut it got such logs and exit:\r\n\r\n    tfdebug Non-OK-status: env->NewWritableFile(file_path, &f) status: Resource exaustated: /tmp/tfdbg_9_gcc3sc/gradients/output/Reshape_1_grad/Reshape_0_DebugIdentity_150023213\r\n    Aborted (core dumped)\r\n\r\nI think it is kind of issue related to tf_debug and it may be new, since I can not find anything when I google the error. ", "comments": ["This error occurs when writing to the filesystem fails - for example if there is no space left on the device, or if the disk quota exceeded or if there were too many files etc. (see [`errors.cc`](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/platform/posix/error.cc#L86))\r\n\r\nUnfortunately, the error message given doesn't give more detail (I'll look into fixing that), but the underlying problem does appear to be that you're hitting some sort of space or user limit issues when writing to `/tmp/tfdbg_9_gcc3sc/gradients/output/Reshape_1_grad/Reshape_0_DebugIdentity_150023213`\r\n\r\nCould you look into how much space is left on the device and whether you're running into disk limits?", "@asimshankar  Thanks for your reply! But it is unlikely that no space left on the device. Cause I run the code on a server, whose space is much more than enough.  Do you think user authentication can be a possible reason. But I have no problem on writing under my path.", "I didn't quite follow what you meant by \"I have no problem on writing under my path\". Could you elaborate on that?\r\n\r\nBut regardless, it seems like the `fopen` call [here](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/platform/posix/posix_file_system.cc#L150) that is failing, so it does seem to be the filesystem rejecting the open call. So perhaps there are some `ulimits` in place?", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11627, "title": "Fix typos", "body": "This PR fixes some typos: `partiton` and `executon`.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 11626, "title": "SparseSoftmaxCrossEntropyWithLogits error while calculating gradient in c++ mode", "body": "I'm trying to use the C++ API to train a CNN model. My last layer is using SparseSoftmaxCrossEntropyWithLogits. Here is the python code which generates the prototxt of the model:\r\n\r\n```\r\nimport tensorflow as tf \r\nfrom tensorflow.python.framework import ops \r\nfrom tensorflow.python.framework import dtypes\r\n\r\nimport random  import numpy as np\r\n\r\nNUM_CLASSES = 102  IMAGE_HEIGHT = 224  IMAGE_WIDTH = 224  BATCH_SIZE = 25  NUM_CHANNELS = 3  LEARNING_RATE = 0.0001\r\n\r\nwith tf.Session() as sess:\r\n\r\n\r\n\r\nimages_placeholder = tf.placeholder (tf.float32,\r\n                                                shape=(BATCH_SIZE, IMAGE_HEIGHT,\r\n                                                IMAGE_WIDTH, NUM_CHANNELS), name=\"input\")   \r\nlabels_placeholder = tf.placeholder (tf.float32,\r\n                                                shape=(BATCH_SIZE), name=\"label\")\r\n\r\n    with tf.name_scope(\"conv1_1\") as scope:         \r\n                 kernel = tf.Variable (tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32, stddev=1e-2),\r\n                                                  name=\"weights\")         \r\n                 conv = tf.nn.conv2d (images_placeholder, kernel, [1, 1, 1, 1], padding='SAME')      \r\n                 biases = tf.Variable (tf.constant(0.0, shape=[64], dtype=tf.float32),\r\n                                                  trainable=True, name='biases')      \r\n                 out = tf.nn.bias_add (conv, biases)         \r\n                 conv1_1 = tf.nn.relu (out, name=scope)\r\n\r\n    pool1 = tf.nn.max_pool (conv1_1,\r\n                            ksize=[1, 2, 2, 1],\r\n                            strides=[1, 2, 2, 1],\r\n                            padding='SAME',\r\n                            name='pool1')\r\n\r\n    with tf.name_scope('conv2_1') as scope:         \r\n                 kernel = tf.Variable (tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32, stddev=1e-2),\r\n                                                  name='weights')       \r\n                 conv = tf.nn.conv2d (pool1, kernel, [1, 1, 1, 1], padding='SAME')       \r\n                 biases = tf.Variable (tf.constant(0.0, shape=[128], dtype=tf.float32),\r\n                                                  trainable=True, name='biases')      \r\n                 out = tf.nn.bias_add (conv, biases)         \r\n                 conv2_1 = tf.nn.relu (out, name=scope)\r\n\r\n    pool2 = tf.nn.max_pool (conv2_1,\r\n                            ksize=[1, 2, 2, 1],\r\n                            strides=[1, 2, 2, 1],\r\n                            padding='SAME',\r\n                            name='pool2')\r\n\r\n    with tf.name_scope('conv3_1') as scope:         \r\n                 kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32, stddev=1e-2),\r\n                                                name='weights')       \r\n                 conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')        \r\n                 biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\r\n                                                 trainable=True, name='biases')      \r\n                 out = tf.nn.bias_add(conv, biases)      \r\n                 conv3_1 = tf.nn.relu(out, name=scope)\r\n\r\n    pool3 = tf.nn.max_pool (conv3_1,\r\n                            ksize=[1, 2, 2, 1],\r\n                            strides=[1, 2, 2, 1],\r\n                            padding='SAME',\r\n                            name='pool3')\r\n\r\n    with tf.name_scope('conv4_1') as scope:         \r\n                 kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32, stddev=1e-2),\r\n                                                name='weights')       \r\n                conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')        \r\n                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\r\n                                                trainable=True, name='biases')      \r\n                out = tf.nn.bias_add(conv, biases)      \r\n                conv4_1 = tf.nn.relu(out, name=scope)\r\n\r\n    pool4 = tf.nn.max_pool (conv4_1,\r\n                            ksize=[1, 2, 2, 1],\r\n                            strides=[1, 2, 2, 1],\r\n                            padding='SAME',\r\n                            name='pool4')   \r\n\r\n    with tf.name_scope('mentee_conv5_1') as scope:      \r\n                 kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-2),\r\n                                                name='weights')       \r\n                 conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')        \r\n                 biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True,\r\n                                                name='biases')         \r\n                 out = tf.nn.bias_add(conv, biases)      \r\n                 conv5_1 = tf.nn.relu(out, name=scope)\r\n\r\n    pool5 = tf.nn.max_pool (conv5_1,\r\n                            ksize=[1, 2, 2, 1],\r\n                            strides=[1, 2, 2, 1],\r\n                            padding='SAME',\r\n                            name='pool5')\r\n\r\n    with tf.name_scope('fc1') as scope:         \r\n                 shape = int(np.prod(pool5.get_shape()[1:]))         \r\n                 fc1w = tf.Variable(tf.truncated_normal([shape, 4096], dtype=tf.float32, \r\n                                             stddev=1e-2), name='weights')       \r\n                 fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\r\n                                             trainable=True, name='biases')      \r\n                 pool5_flat = tf.reshape(pool5, [-1, shape])         \r\n                 fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)        \r\n                 fc1 = tf.nn.relu(fc1l)\r\n                 fc1 = tf.nn.dropout(fc1, 0.5)\r\n\r\n\r\n    labels = tf.to_int64(labels_placeholder)    \r\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits (labels=labels,\r\n                        logits=fc1, name=\"xentropy\")    \r\n    loss = tf.reduce_mean (cross_entropy, name='loss')\r\n\r\n    optimizer = tf.train.AdamOptimizer (LEARNING_RATE)  \r\n    global_step = tf.Variable (0, name='global_step', trainable=False)  \r\n    train_op = optimizer.minimize (loss, global_step=global_step, name=\"train\")\r\n\r\n    init = tf.initialize_variables (tf.all_variables(), name='init_all_vars_op')    \r\n    tf.train.write_graph (sess.graph_def, \"models/\", \"graph.pb\", as_text=False)\r\n```\r\n\r\nUnfortunately when I call the c++ code to run the train_op node, it'll throw below error:\r\n\r\n`E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'message' not in Op<name=PreventGradient; signature=input:T -> output:T; attr=T:type>; NodeDef: gradients/xentropy/xentropy_grad/PreventGradient = PreventGradient[T=DT_FLOAT, message=\"Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\'s interaction with tf.gradients()\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](xentropy/xentropy:1)\r\n`\r\nI'm still confused whether the error comes from a bug inside the TF code or not.", "comments": ["Does it work if you train from within Python?\r\n@skye, do you expect that a generated graphdef should be runnable for training in c++?", "Basically yes. I have seen C++ examples (even I tried it myself) that can train a graph. To me it seems like gradient calculation functions generally does work on C++ mode. But still based on the description, that gradient ops are only available in python, I'm not sure how they are being ported from python to C++, when we wrap the whole TF core as a shared object library.", "Some gradients certainly are not available, but you are generating the graph first, and the weird thing is it is remarking about a 2nd derivate. Which suggests you model is double differentiating somewhere or there is a bug in the C++ layer.", "Alright, so here I have one more question. If I have a model with specific operators, which gradients have not been implemented in C++ version, does it mean that during training it's gonna fail? Or it's silently continue execution with no update on the variables? I'm asking this because I'm trying to validate how much using C++ interface is practical for training models!", "If the gradient is not implemented in C++, we don't register a kernel, so it will definitely give you a \"no kernel found\" type error.", "@saman-aghazadeh Could you please share the sources from where you could create a graph in c++\r\n\r\nI am trying to create a graph in c++ from python code available at https://github.com/wolfib/image-classification-CIFAR10-tf/blob/master/softmax.py but unable to do so as I coudn't find few of the python tensorflow function in C++ , for Eg tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\r\n  labels=labels_placeholder))", "This issue is reproducible with the python API as well.\r\n\r\nIn my case, I have added an additional term to the loss function (gradient of the cross entropy with respect to the input). In this case, second derivative of sparse_softmax_cross_entropy_with_logits needs to be computed during backprop and the following error is thrown:\r\nLookupError: Gradient explicitly disabled. Reason: b\"Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation's interaction with tf.gradients()\"\r\n\r\nIt is surprising that support for second order derivative is still missing for some of the key operations in TF.", "@tensorflowbutler Yes, this is still an issue.", "I am getting this error in Python as well, similar to @vipinpillai. Is there any update on this issue? Is there any short-term workaround for it?", "@mmkamani7 Can you check with recent TF versions (`TF1.14.0` or `TF-nightly`, `TF 2.0.0rc0`) and let us know whether it was resolved or not. There were several improvements in the last couple of months. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=11626\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=11626\">No</a>\n", "When I use jupyter with tf2.0beta, there has no problem. But when I use tf2.0.0, the error 'LookupError: Gradient explicitly disabled. ' appears.", "> When I use jupyter with tf2.0beta, there has no problem. But when I use tf2.0.0, the error 'LookupError: Gradient explicitly disabled. ' appears.\r\n\r\n\tDid you have solved this problem?,I met the same error that is \"LookupError: Gradient explicitly disabled. Reason: b\"Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation's interaction with tf.gradients()\"\"", "> This issue is reproducible with the python API as well.\r\n> \r\n> In my case, I have added an additional term to the loss function (gradient of the cross entropy with respect to the input). In this case, second derivative of sparse_softmax_cross_entropy_with_logits needs to be computed during backprop and the following error is thrown:\r\n> LookupError: Gradient explicitly disabled. Reason: b\"Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation's interaction with tf.gradients()\"\r\n> \r\n> It is surprising that support for second order derivative is still missing for some of the key operations in TF.\r\n\r\nExcuse me, can you tell me how to deal with this error? Look forward to you reply, thanks"]}, {"number": 11625, "title": "[XLA] Fix plugin example buffer address for tuples", "body": "Currently the returned\u00a0`se::DeviceMemoryBase(buf, size)`\u00a0uses the incremented\u00a0`buf`, which may cause deallocation error.\r\n\r\n(Resubmit of #11595 after CLA fix)", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 11624, "title": "Missing file", "body": "The file named node_def_pb2 is missing from tensorflow/core/framework. The file is required when I try to load the MNIST data as part of the tensorflow tutorial. ", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . **Please provide all the information it asks**, in particular, steps to reproduce the problem. Thank you.\r\n\r\n(In this case, if you're building from sources, the file is generated. If you're using the installed TensorFlow pip packages, the file will be there in the installed location). Since I'm not sure about the environment in which you're building / looking for the file, I'm not quite sure what the problem is)", "My apologies -- I reinstalled the tensorflow package, and everything is working fine now. Thanks for your response!"]}, {"number": 11623, "title": "Different results from scipy imread and tensorflow decode_jpeg", "body": "### Problem Description\r\nImage decoded using decode_jpeg from tensor flow is visually similar, but numerically different from one returned by scipy imread.\r\n\r\n**Minimal Example**:\r\n```\r\nimport numpy as np\r\nimport scipy\r\nimport tensorflow as tf\r\ndef minimal_example():\r\n    #image_source = 'https://upload.wikimedia.org/wikipedia/commons/8/88/Astronaut-EVA.jpg'\r\n    image_path = 'astronaut.jpg'\r\n    image_file = open(image_path,'rb')\r\n    image_raw = image_file.read()\r\n    image_scipy = scipy.misc.imread(image_path)\r\n    image_tf = tf.image.decode_jpeg(image_raw).eval(session=tf.Session())\r\n    print('Error: ', np.sum(np.abs(image_tf - image_scipy)))\r\n    #Error:  3420883624\r\n```\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Python version**: 3.5\r\n\r\n", "comments": ["I can reproduce the result with exactly the same error using the same image and code.\r\nCan this be caused by decoders' differences? Since `scipy.misc.imread` uses `pillow`, `tf.image.decode_jpeg` still functions without `pillow`.\r\n\r\n\r\n## system information \r\n\r\n- OS: Fedora 26\r\n- Python version: 3.5.3\r\n- Python related management tool: Anaconda 3\r\n- Tensorflow(installed via `conda install`) version: 1.1.0,  np112py35_0\r\n\r\n### printed a small portion of the results\r\n````\r\n[1:10,:,2] scipy image\r\n [[0 0 0 ..., 0 2 1]\r\n [0 0 0 ..., 0 5 4]\r\n [0 0 0 ..., 0 5 4]\r\n ..., \r\n [0 0 2 ..., 0 5 5]\r\n [0 0 0 ..., 0 3 0]\r\n [0 0 0 ..., 3 3 0]]\r\n[1:10,:,2] tf image\r\n [[0 0 0 ..., 0 0 0]\r\n [0 0 0 ..., 0 3 4]\r\n [0 0 0 ..., 0 3 4]\r\n ..., \r\n [0 0 0 ..., 0 3 3]\r\n [0 0 0 ..., 0 2 0]\r\n [0 0 0 ..., 0 2 0]]\r\n````\r\n", "We use libjpeg. I am not sure what your application is. If you really need this, I would recommend writing your own op on top of pillow.\r\n\r\nI am going to close this, since I don't think it warrants changing the TF core.", "I think the reason for this difference is that Tensorflow used fast integer DCT as a default decode jpeg image \r\nhttps://github.com/tensorflow/tensorflow/blob/e073322452e41e76754314aa75d543d071003fc5/tensorflow/core/kernels/decode_image_op.cc#L109", "Oh yes, I remember some discussion about that. I think we change the default but the other version is available through options."]}, {"number": 11622, "title": "Enable passing scope to variable lookups", "body": "NB: Changes the public API, albeit in a backwards-compatible way.\r\n\r\nEspecially when copying variables between scopes it's handy to be able to grab sets of variables by scope. This allows the much more succinct:\r\n\r\n``tf.trainable_variables(\"myscope\")``\r\n\r\nwhich is equivalent to:\r\n\r\n``tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"myscope\")``\r\n\r\n- Also fixup a minor unrelated documentation bug.", "comments": ["Can one of the admins verify this patch?", "Josh, thoughts on this API change?", "Alex, you are more familiar with this stuff than I am.  What do you think?", "You can get similar functionality now with \"scope.global_variables()\": https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variable_scope.py#L907 (there is scope.trainable_variables as well) on the variable scope objects.\r\n\r\nThat said I'm not against this change, as it is backwards-compatible", "Thanks for the reviews. I've added documentation for the new args too, as well as including `_all_saveable_objects()` to the list as that will be used similarly once it's public.", "Jenkins, test this please.", "Gah, I've missed something with pylint. I'll check that when I'm home and update.", "Fixed the indentation.", "Approval for API review", "Jenkins, test this please.", "The Windows cmake test failed because of a checkout issue. The Linux CPU test failed the api compatibility test. That passes here with (albeit with this PR on top of master), with:\r\n\r\n    bazel test --verbose_failures --config=cuda --config=opt //tensorflow/tools/api/tests:api_compatibility_test\r\n\r\nI'll see if it was broken on master when I made the PR, but I'm away for a few days now.", "Jenkins, test this please.", "One needs to update the API golden files for the test to pass.  See the logs and search for api_compatiblity_test to see how to update the golden files.", "I was building with python 3 so the api checks looked like they passed, but were being skipped. Should have spotted that.\r\n\r\nUpdated.", "Jenkins, test this please."]}, {"number": 11621, "title": "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.", "body": "I have built a Custom Estimator, and I created an input function using the [Datasets API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/programmers_guide/datasets.md) when I call:\r\n\r\n``` estimator.predict(input_fn) ```\r\n\r\nI see the following Warning:\r\nWARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\r\n\r\nThe input function looks like this:\r\n```\r\ndef get_input_fn(review, word_to_id):\r\n  \"\"\"Create a Input function for classify_sentiment_analysis.py.\r\n\r\n   Args:\r\n      review (str): review sentence\r\n      word_to_id (list): list with all words represented in the embedding.\r\n                         The index is the word index in the embedding.\r\n\r\n   Return: sequence of indexes that map that words to the embedding.\r\n\r\n  \"\"\"\r\n  def _word_to_index(sequence):\r\n    \"\"\"Convert a sequence of words into a sequence of integers.\"\"\"\r\n    id_sequence = []\r\n    UNK = 399999 # vector for unkown words\r\n    for word in sequence:\r\n      if word in word_to_id:\r\n        id_sequence.append(word_to_id.index(word))\r\n      else:\r\n        id_sequence.append(UNK)\r\n    return np.array(id_sequence)\r\n\r\n  def input_fn():\r\n    \"\"\"Input function.\"\"\"\r\n    # make review a sequence of words\r\n    review_split = review.split(' ')\r\n    # converting words to indexes\r\n    review_id = _word_to_index(review_split)\r\n    # calculates the length of the sequence\r\n    x_len = len(review_split)\r\n    # creates the dataset from in memory data\r\n    ds = tf.contrib.data.Dataset.from_tensors(review_id)\r\n    # the model expects a batch\r\n    ds = ds.batch(1)\r\n\r\n    # creates iterator\r\n    x = ds.make_one_shot_iterator().get_next()\r\n\r\n    dict_x = {'x': x, rnn_common.RNNKeys.SEQUENCE_LENGTH_KEY: [x_len]}\r\n    # no label needed since we're only using this input function for prediction\r\n    # if training make sure to return a label\r\n    return dict_x, None\r\n\r\n  return input_fn\r\n```\r\n\r\nThank you!", "comments": ["You are facing this error present in the following link:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py\r\nThe condition on line number 491 is satisfied as a result of which you are getting the above error.\r\n\r\nPlease refer to the blog in order to get the correct idea of an estimator for tensorflow :\r\nhttp://terrytangyuan.github.io/2016/07/08/understand-and-build-tensorflow-estimator/\r\n\r\nPlease try the above and get back if any more problem arises.", "I think your program is perfectly correct and it's the warning that's wrong :). It was added long before the Datasets API existed, and was well intentioned. (AFAICT the `predict()` API relies on your input terminating with a `tf.errors.OutOfRangeError` and before Datasets existed only `QueueRunner`-based pipelines would terminate that way, so it probably *was* an error if no queue runners existed.)\r\n\r\n@xiejw Should we remove this warning, or is there a more cunning way to detect the error condition?", "I think we should remove this warning. I will do an internal clean up for that then (to and see whether we could this better). \r\n\r\nAs mrry@ explained, the error message was added before Datasets API, which served as a nice hint to prevent user from \"wrong behavior\".", "Thank you for the quick response \ud83d\udc4d ", "wait, how do you solve this issue? I am hitting the same error predicting like this:\r\n```python\r\n# Classify two new flower samples.\r\ndef new_samples():\r\n  return np.array(\r\n    [[6.4, 3.2, 4.5, 1.5],\r\n     [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\r\n\r\npredictions = list(classifier.predict(input_fn=new_samples)) \r\n\r\n```", "Hi @contractorwolf,\r\n\r\nFrom where I stand, I think the warning you see \"makes sense\" in your case, since this implementation suggests a queue input or the datasets API as your input pipeline.\r\n\r\nAn option would be to use [numpy input function](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn), but not sure if this is still recommended.", "mari-linhares  is correct. @contractorwolf's case deserves a warning as the Estimator.predict might not work well with constant arrays. numpy_input_fn should be the best option for now and it will be supported for future releases (see [API stability promises ](https://www.tensorflow.org/programmers_guide/version_compat))\r\n\r\nAt head, the warning should be removed for Dataset API (already). See code here\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py\r\n\r\nI am going to close this issue. Feel free to reopen if it is still a problem.\r\n", "I figured I should leave a sample that worked for me, after I read what @xiejw wrote (thanks for the advice).  This solved it for me with the Iris dataset:\r\n```\r\n# test using single records (2 real world values)\r\n# one Iris-setosa, one Iris-versicolor\r\nrecords_to_predict = pd.DataFrame([\r\n    [5.1, 3.5, 1.4, 0.2], # first records features\r\n    [5.7, 2.8, 4.1, 1.3]],# second record features\r\n    columns=columns_names)# defined column names\r\n \r\n# predict using the model to get a prediction for each item passed\r\nsaved_prediction_input_fn = tf.estimator.inputs.pandas_input_fn(records_to_predict, num_epochs=1, shuffle=False)\r\n\r\n# make predictions and store as a list\r\nsaved_prediction_result = list(saved_estimator.predict(input_fn=saved_prediction_input_fn))\r\n```", "It should be noted that in the [Estimator documentation](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict) the `input_fn` could return a `tf.Tensor` (or a tuple). I initially wrote my code so that the `input_fn` would return just that, but `predict` generates an infinite iterator.\r\n\r\nAm I misinterpreting the docs or do they need update?\r\n\r\ncc @xiejw @mrry ", "Yes, I have the same problem as @lorenzoriano . I am returning a tf.data.Dataset.from_tensor_slices and get the error message at the top of this thread. Any suggestions on how I can fix this without rewriting to not use tf.Tensor which would feel like a backward step.\r\n\r\nLater...\r\nI seem to have solved my issue by making the batch_size when getting data for .predict 1 rather than None as shown in my changed to default settings in my input_fn. \r\n```\r\ndef input_fn(features, labels=None, batch_size=None, shuffle=False, num_epochs=1):  # caused error  \r\ndef input_fn(features, labels=None, batch_size=1, shuffle=False, num_epochs=1):   # works\r\n```\r\nI couldn't find any description of this in the tensorflow documentation but I guessed it was the same as step in .evaluate where None or -1 can make it iterate for ever.", "I experinced the same warring when using :\r\n`dataset = tf.data.Dataset().from_generator(_get_generator, output_types=(tf.float32),\r\n                                                   output_shapes=(tf.TensorShape([None, None, None, None, 1])),\r\n                                                   ).repeat(1)`\r\n\r\n`iterator = dataset.make_one_shot_iterator()`\r\n\r\n`t = iterator.get_next()`\r\n"]}, {"number": 11619, "title": "Feature request: tensordot GPU kernel", "body": "Hi,\r\n\r\nI have two placeholder tensors with some matching axes that I would like to multiply element-wise and sum across. Implementation with tf.tensordot works perfectly on cpu, but it looks like there is no gpu kernel available for this op. Would it be possible to have one added? Or is there a workaround using simpler operations such as multiply and reduce_sum that are currently gpu-supported?\r\n\r\nSpecifically I would like to be able to run something equivalent to the following on gpu:\r\n`a=tf.placeholder(shape=[None,16,17,18]) #e.g.`\r\n`b=tf.placeholder(shape=[5,17,18,20]) `\r\n`c=tf.tensordot(a,b,axes=[[2,3],[1,2]])`\r\n`#shape of c: [None,16,5,20]`\r\n\r\nWhen I run c in a session using tf.device('/gpu:0') I get the following error:\r\n`InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Tensordot/ListDiff': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\n\t [[Node: Tensordot/ListDiff = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=\"/device:GPU:0\"](Tensordot/range, Tensordot/add_1)]]`\r\n", "comments": ["@aselle wdyt?", "@tklos96 what if you use tf.einsum? Both tensordot/einsum reduce to tf.matmul for the actual work", "Oooh thanks that could be good. Although I also got it working by stacking some extra dimensions at the end, and then using the broadcasting capability of tf.multiply", "solution\uff1a\r\n  sess_config = tf.ConfigProto(allow_soft_placement=False) \r\n    sess = tf.Session(config = sess_config)\r\n\r\n // Whether soft placement is allowed. If allow_soft_placement is true,\r\n  // an op will be placed on CPU if\r\n  //   1. there's no GPU implementation for the OP\r\n  // or\r\n  //   2. no GPU devices are known or registered\r\n  // or\r\n  //   3. need to co-locate with reftype input(s) which are from CPU.\r\n  bool allow_soft_placement = 7;"]}, {"number": 11618, "title": "Unable to optimise the graph", "body": "I have frozen the tensorflow graph and I have noticed that the using the graph in realtime for prediction is too slow. so I would like to do graph optimization.\r\n\r\nWithin my project file, I have got a folder called model which contains the model file (pb file).\r\n\r\nNow I tried running the following command inside the model dir\r\n```\r\n bazel build tensorflow/python/tools:strip_unused\r\n```\r\nBut it is firing the following error,\r\n\r\n\r\n>  bazel build tensorflow/python/tools:strip_unused\r\n> ERROR: no such package 'tensorflow/python/tools': BUILD file not found on package path.\r\n> \r\n> ", "comments": ["The error is not related to your project file used for optimisation, it is related to the build file in the directory,please verify the path of the build file and get back.", "where should I put my model file for optimizing it? How the directory structure has to be?", "Your model file should be inside the package path (tensorflow/python/tools) provided by you.The build file should also be in the same location.Please try to verify and get back as the above is thrown due to some glitch in the location of the files.", "Should I download [tensorflow](https://github.com/tensorflow/tensorflow) and put the model file in tensorflow/python/tools?\r\nMay I know what do you mean by build file?", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/BUILD\r\nThe above build file should be present in the package path along with your model file too.\r\nYes all of these should be present inside tensorflow.\r\nPlease verify and get back.\r\n", "By `package path` , do you mean the path where tensorflow is installed? ", "Yes insde the tensorflow folder.\r\ntensorflow/python/tools", "I have installed it using anaconda. May I know where it is in my mac?", "Okay i did so. I got the following errors,\r\n\r\n\t```\r\nfail(\"%sPython Configuration Error:%s...))\r\nPython Configuration Error: 'PYTHON_BIN_PATH' environment variable is not set\r\n and referenced by '//third_party/py/numpy:headers'.\r\nERROR: Analysis of target '//tensorflow/python/tools:strip_unused' failed; build aborted.\r\n```\r\n", "Try this:\r\nhttps://github.com/tensorflow/tensorflow/issues/9436\r\n", "Okay thanks...now I got a strange error as follows,\r\n\r\n`ERROR: Analysis of target '//tensorflow/python/tools:strip_unused' failed; build aborted.\r\n`", "This is a link error probably, this might help:\r\nhttps://github.com/tensorflow/tensorflow/issues/4458\r\n", "thank you... still the same error...any other go?", "Can you try to run configure,\r\nplease follow this and links available online on how to run configure:\r\nhttps://github.com/tensorflow/tensorflow/issues/4279", "It seems you're building from within your model directory as opposed to building in the TensorFlow source directory.\r\n\r\nAlternatively, if you want to avoid building TensorFlow from source, you could use the library function directly using something like:\r\n\r\n```python\r\nfrom tensorflow.python.tools.strip_unused import strip_unused_lib\r\n\r\nhelp(strip_unused_lib.strip_unused_from_files)\r\n```\r\n\r\nWhich is [what is being invoked by the tool](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/tools/strip_unused.py#L55)\r\n\r\nSince this issue doesn't correspond to a bug, I'm going to close it. If you need more help, I'd recommend asking on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11617, "title": "Error Building from source with ARM processor gif_io/png_io errors", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI'm following [this](https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md) guide for installing tensorflow on a raspberry pi, because it most closely resembles the environment that I am building on.\r\nI noticed that there were a couple of things that had changed since those instructions were written, so if things had changed in the code when I checked them, I didn't follow those instructions for changing the code. (I don't think the error is because of these instructions, which is why I am posting here, instead of there).\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nI am building in a Debian Jessie environment, that I have built exclusively for the purposes of building tensorflow on ARM, with the latest versions of gcc/g++ that I could find.\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\nI'm assuming the most recent, because I just cloned it yesterday.\r\nThe script errors because tf hasn't actually made it to the installation step.\r\n== cat /etc/issue ===============================================\r\nLinux 3.14.38-yocto-00005-ge466b18 #1 SMP PREEMPT Tue May 30 10:41:58 MDT 2017 armv7l GNU/Linux\r\nVERSION_ID=\"8\"\r\nVERSION=\"8 (jessie)\"\r\n== compiler =====================================================\r\nc++ (Debian 4.8.4-1) 4.8.4\r\ngcc version 4.8.4 (Debian 4.8.4-1) \r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n== uname -a =====================================================\r\nLinux 3.14.38-yocto-00005-ge466b18 #1 SMP PREEMPT Tue May 30 10:41:58 MDT 2017 armv7l GNU/Linux\r\n== check pips ===================================================\r\nnumpy (1.8.2)\r\n\r\n- **Python version**: \r\nPython 2.7.9\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.4.5- (@non-git)\r\n\r\n- **CUDA/cuDNN version**:\"\r\nN/A\r\n\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n- **Exact command to reproduce**:\r\n`bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`\r\nThough, I've also gotten errors with \r\n```\r\nbazel build -c opt --copt=\"-mfpu=neon-vfpv4\" --copt=\"-funsafe-math-optimizations\" --copt=\"-ftree-vectorize\" --copt=\"-fomit-frame-pointer\" --local_resources 1024,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package\r\n```\r\nand \r\n```\r\nbazel build -c opt --copt=\"-mfpu=neon-vfpv4\" --copt=\"-funsafe-math-optimizations\" --copt=\"-ftree-vectorize\" --copt=\"-fomit-frame-pointer\" --local_resources 1024,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n### Describe the problem\r\nI am getting the included error when I build tensorflow. I've gotten the same error with the png_io.cc file as well. I installed the libpng-dev library as was recommended [here](https://github.com/tensorflow/tensorflow/issues/3631). Unlike in that example, that library did not exist on the computer I was installing it on (neither did libgif-dev, which was my guess for the gif library error). Is there a reason these libraries should be installed at the point that I run that command? Will I also need a libjpg-dev or something of the sort?\r\n\r\n### Source code / logs\r\n```\r\nERROR: /root/tf/tensorflow/tensorflow/core/BUILD:1357:1: C++ compilation of rule '//tensorflow/core:gif_internal' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 106 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nIn file included from tensorflow/core/lib/gif/gif_io.cc:20:0:\r\n./tensorflow/core/platform/gif.h:26:2: error: #error Define the appropriate PLATFORM_<foo> macro for this platform\r\n #error Define the appropriate PLATFORM_<foo> macro for this platform\r\n  ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:20: error: 'GifFileType' was not declared in this scope\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                    ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:33: error: 'gif_file' was not declared in this scope\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                 ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:43: error: 'GifByteType' was not declared in this scope\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                           ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:56: error: 'buf' was not declared in this scope\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                                        ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:61: error: expected primary-expression before 'int'\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                                             ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:69: error: expression list treated as compound expression in initializer [-fpermissive]\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                                                     ^\r\ntensorflow/core/lib/gif/gif_io.cc:33:71: error: expected ',' or ';' before '{' token\r\n int input_callback(GifFileType* gif_file, GifByteType* buf, int size) {\r\n                                                                       ^\r\ntensorflow/core/lib/gif/gif_io.cc:111:1: error: expected '}' at end of input\r\n }  // namespace tensorflow\r\n ^\r\ntensorflow/core/lib/gif/gif_io.cc:111:1: error: expected '}' at end of input\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n```\r\n", "comments": ["@andrewharp any idea?", "update:\r\ninstalling the libjpeg(uncertain)/libpng/libgif -dev seemed to fix this problem. I'm still unable to build, because of issues with pmul/jacobi.h, but I am following up on that in a separate issue thread. I would still be curious, when in the build process I was supposed to have installed those libraries? Or if those are just libraries that are expected to be installed on most linux builds.", "Closing since the issue seemed to be resolved (I don't know when the image dev libraries are supposed to be installed though)."]}, {"number": 11616, "title": "Updating the RELNOTES for 1.3.0rc0.", "body": "", "comments": []}, {"number": 11615, "title": "Revert \"Add GradientsDebugger to tfdbg\"", "body": "This reverts commit 31f1375c01782f53cf12ce2aa4efa584483c14ea.", "comments": ["Testing Github UI. CLosing soon."]}, {"number": 11614, "title": "TypeError: __init__() got an unexpected keyword argument 'shape'", "body": "I read these codes from a book, but it can't work, and after I searched for a couple of days haven't  similar 'shape' problem how can I fix it? Is anybody have ideas? plz, thanks!\r\n----------------------------------------------------------------\r\n\r\n\\# -*- coding:utf-8 -*-\r\nimport tensorflow as tf\r\ng1 = tf.Graph()\r\nwith g1.as_default():\r\n    v = tf.get_variable(\"v\",initializer=tf.zeros_initializer(shape=[1]))\r\n", "comments": ["```python\r\n# -- coding:utf-8 --\r\nimport tensorflow as tf\r\ng1 = tf.Graph()\r\nwith g1.as_default():\r\n    v = tf.get_variable(\"v\", shape=[1], initializer=tf.zeros_initializer())\r\n```\r\nsee [documentation](http://devdocs.io/tensorflow~python/tf/get_variable) and **read:**\r\n\r\n\r\n> Please go to Stack Overflow for help and support:\r\n> \r\n> http://stackoverflow.com/questions/tagged/tensorflow\r\n> \r\n> If you open a GitHub issue, here is our policy:\r\n> \r\n> 1. It must be a bug or a feature request.\r\n> 2. The form below must be filled out.\r\n> 3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nThat said, you probably want:\r\n\r\n```\r\nv = tf.get_variable(\"v\", initializer=tf.zeroes_initializer(), shape=[1])\r\n```\r\n\r\nAs per the [documentation of `tf.zeroes_initializer`](https://www.tensorflow.org/api_docs/python/tf/zeros_initializer), it only accepts a `dtype` as an argument to creating the initializer, while [`tf.get_variable`](https://www.tensorflow.org/api_docs/python/tf/get_variable) does accept a `shape` argument.", "@asimshankar I am sorry about that, I thought it is a bug, sorry!", "@PatWie I am sorry about that, I thought it is a bug, sorry! Thank you!"]}, {"number": 11613, "title": "Error in InputQueueingStateSaver/barrier", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18\r\n- **TensorFlow installed from (source or binary)**: Binary (pip)\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI encounter an error related to barriers when using `tf.contrib.training.batch_sequences_with_states`. I use this function to batch sequences. For now, just batches of 4. I do not understand the error it but I tried empirically poking at it and it only occurs with some capacity values. For example, it does not occur within 15 minutes with a `capacity` value of 16 (good for 4 batches) and cycles through the input sequences as expected. It does occur within a minute with `capacity` values of 32 and 64.\r\n\r\nI know this is incredibly vague but I can explore more if you can help me understand the underlying issue. I do believe this question does not fit the StackOverflow format as this is buggy behaviour. \r\n\r\n### Source code / logs\r\nBelow the error log. One thing I do not understand for example is that it always complains about components 0-8. I have verified that this occurs for multiple keys. My best guess is that this has to do with `save_state` trying to save over state that has already been saved?\r\n\r\n```\r\n2017-07-19 17:16:52.465021: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 8 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465073: W tensorflow/core/kernels/queue_base.cc:294] _2_input/batch_seq_with_states/fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\n2017-07-19 17:16:52.465117: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 7 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465168: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 5 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465226: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 3 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465261: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 4 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465292: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 0 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465324: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 1 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.465798: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 2 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n2017-07-19 17:16:52.469856: W tensorflow/core/framework/op_kernel.cc:1158] Invalid argument: Key 00030_of_00112:20120305_seq1 already has a value for component 6 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Key 00030_of_00112:20120305_seq1 already has a value for component 8 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n         [[Node: input/batch_seq_with_states/InputQueueingStateSaver/BarrierInsertContext_num_frames = BarrierInsertMany[T=DT_INT64, _class=[\"loc:@input/batch_seq_with_states/fifo_queue\"], component_index=8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/batch_seq_with_states/InputQueueingStateSaver/barrier, input/batch_seq_with_states/InputQueueingStateSaver/StringJoinCurrentKeys, input/batch_seq_with_states/InputQueueingStateSaver/dims_checked_expanded_context_num_frames)]]\r\n17:16:52 [tensorflow          ] [INFO    ] : Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Key 00030_of_00112:20120305_seq1 already has a value for component 8 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n         [[Node: input/batch_seq_with_states/InputQueueingStateSaver/BarrierInsertContext_num_frames = BarrierInsertMany[T=DT_INT64, _class=[\"loc:@input/batch_seq_with_states/fifo_queue\"], component_index=8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/batch_seq_with_states/InputQueueingStateSaver/barrier, input/batch_seq_with_states/InputQueueingStateSaver/StringJoinCurrentKeys, input/batch_seq_with_states/InputQueueingStateSaver/dims_checked_expanded_context_num_frames)]]\r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 108, in <module>\r\n    solver.train(**pick(all_args, list(inspect.signature(solver.train).parameters)))\r\n  File \"/home/ruben/attention/attend/attend/solver.py\", line 122, in train\r\n    coord.join(threads + input_threads)\r\n  File \"/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/ruben/anaconda3/lib/python3.6/site-packages/six.py\", line 686, in reraise\r\n    raise value\r\n  File \"/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\r\n    enqueue_callable()\r\n  File \"/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1063, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/home/ruben/anaconda3/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Key 00030_of_00112:20120305_seq1 already has a value for component 8 in barrier _3_input/batch_seq_with_states/InputQueueingStateSaver/barrier\r\n         [[Node: input/batch_seq_with_states/InputQueueingStateSaver/BarrierInsertContext_num_frames = BarrierInsertMany[T=DT_INT64, _class=[\"loc:@input/batch_seq_with_states/fifo_queue\"], component_index=8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/batch_seq_with_states/InputQueueingStateSaver/barrier, input/batch_seq_with_states/InputQueueingStateSaver/StringJoinCurrentKeys, input/batch_seq_with_states/InputQueueingStateSaver/dims_checked_expanded_context_nu\r\n\r\n```\r\n\r\nRelevant source code in `provider.py`:\r\n\r\n```python\r\nbatch = tf.contrib.training.batch_sequences_with_states(\r\n        input_sequences={\r\n            'images': example,\r\n            self.feat_name: target,\r\n        },\r\n        input_key      = context['key'],\r\n        input_context  = context,\r\n        input_length   = tf.cast(context['num_frames'], tf.int32),\r\n        initial_states = initial_states,\r\n        num_unroll     = self.time_steps,\r\n        batch_size     = self.batch_size,\r\n        num_threads    = 2, # TODO change\r\n        capacity       = self.batch_size * 4,\r\n        name           = 'batch_seq_with_states'\r\n        )\r\n\r\n\r\n```\r\n", "comments": ["Additionally, I tested with a file holding exactly 3 examples, using a batch size of 1. A capacity of 1 would work. A capacity of 2 results in the same error.", "I could see how this might occur if the same input key is encountered (by e.g. reading the same file twice). Could anyone confirm?", "I have encountered the same error, running TensorFlow 1.2.0 on centos 7 with 4 GeForce GTX 980 Ti GPUs .  I am experimenting with a number of different recurrent neural network designs using `tf.contrib.training.batch_sequences_with_states` and `tf.nn.static_state_saving_rnn` and get the InvalidArgumentError only for some of them.  For instance, the RNN could have one or two layers and it could use GRU or LSTM cells.  With one layer and GRU cells, I have run 500 epochs (which results in about 536000 steps) without getting the error.  With two layers and GRU cells or one layer and LSTM cells, running 500 epochs results in the Invalid Argument Error at some point along the way (usually after at least 100000 and up to 400000 steps, depending on other parameters that I am modifying such as the number of cells in each layer).  With two layers and LSTM cells, the InvalidArgumentError occurs almost immediately (within the first 100 steps) and happens even if I have the queue set to read the file only once (1 epoch).  I have used different input files (with similar data, all in tfrecords format) and encountered the same error regardless of the file.\r\n\r\nRelevant code:\r\n```\r\nnum_unroll = 100\r\nbatch_size = 100\r\nnum_layers = config.num_layers\r\nsize = config.size\r\nuse_lstm = config.use_lstm\r\ndef single_cell():\r\n    \"\"\"Sets the basic cell to be either LSTM or GRU.\"\"\"\r\n    if use_lstm:\r\n        return tf.nn.rnn_cell.BasicLSTMCell(size)\r\n    return tf.nn.rnn_cell.GRUCell(size)\r\nif num_layers > 1:\r\n    stacked_cells = tf.nn.rnn_cell.MultiRNNCell([single_cell() for _ in range(num_layers)])\r\nelse:\r\n    stacked_cells = single_cell()\r\nstate_name = 'rnn_state'\r\nif num_layers > 1 and use_lstm:\r\n    initial_state = tf.zeros((stacked_cells.state_size[0][0],), dtype=data_type())\r\n    state_names = ((state_name, state_name),) * num_layers\r\nelif num_layers > 1:\r\n    initial_state = tf.zeros((stacked_cells.state_size[0],), dtype=data_type())\r\n    state_names = (state_name,) * num_layers\r\nelif use_lstm:\r\n    initial_state = tf.zeros((stacked_cells.state_size[0],), dtype=data_type())\r\n    state_names = (state_name, state_name)\r\nelse:\r\n    initial_state = tf.zeros((stacked_cells.state_size,), dtype=data_type())\r\n    state_names = state_name\r\nrnn_initial_state = {'rnn_state': initial_state}\r\nbatch = tf.contrib.training.batch_sequences_with_states(\r\n    input_key=inputs[0]['key'],\r\n    input_sequences=inputs[1],\r\n    input_context=inputs[0],\r\n    input_length=tf.cast(inputs[0]['length'], tf.int32),\r\n    initial_states=rnn_initial_state,\r\n    num_unroll=num_unroll,\r\n    batch_size=batch_size,\r\n    allow_small_batch=True,\r\n    num_threads=1,\r\n    capacity=batch_size*4,\r\n    pad=True,\r\n    make_keys_unique=True)\r\ninputs = data = batch.sequences['alert_id']\r\nlabels = batch.context['label']\r\nlengths = batch.length\r\nembedder = tf.get_variable('embedder', [config.max_alert_id, config.embedding_size])\r\nvectors = tf.nn.embedding_lookup([embedder], data, name='embed')\r\nvectors = tf.unstack(\r\n    value=vectors,\r\n    num=num_unroll,\r\n    axis=1)\r\noutputs, state = tf.nn.static_state_saving_rnn(\r\n    stacked_cells,\r\n    vectors,\r\n    state_saver=batch,\r\n    state_name=state_names)\r\n```\r\nAll of the parameters involved in the batching are unchanged across my experiments, except `initial_states` which has to change according to the number of layers and type of RNN cell used, but I don't see why that should affect the reading of the data.\r\n\r\nI don't know if it's relevant, but the error for my data always corresponds to component 13.", "Does the value of the key matters to you?\r\n\r\nThe setting below works for me: \r\n\r\n```python\r\ninput_key=tf.py_func(lambda: uuid.uuid4().hex, [], tf.string),\r\n```", "Setting\r\n```\r\ninput_key=tf.py_func(lambda: uuid.uuid4().hex, [], tf.string),\r\n``` \r\nstill produces the error for me.", "Try adding the argument `make_keys_unique=True` to `batch_sequences_with_queues`.", "@ebrevdo good call, it does make sure sequences are not repeated in the same batch and it seems to have fixed it for me. I do get a tonne of barrier warnings but they can be ignored. ", "That argument was already set to true for me.", "Try implementing a custom key generator. If you use the option `make_keys_unique=True` Tensorflow creates unique keys withrandom key generator:\r\n[sequence_queueing_state_saver.py](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/contrib/training/python/training/sequence_queueing_state_saver.py)\r\n```    \r\nif make_keys_unique:\r\n      input_key = string_ops.string_join([\r\n          input_key,\r\n          string_ops.as_string(\r\n              random_ops.random_uniform(\r\n                  (), minval=0, maxval=100000000, dtype=dtypes.int32,\r\n                  seed=make_keys_unique_seed))])\r\n```\r\nIf you need more than a million keys, there is a high chance you will encounter a collision.\r\nA counting key generator fixed it for me:\r\n```\r\nkey = tf.Variable(0)\r\n```\r\n```\r\nbatch = tf.contrib.training.batch_sequences_with_states(\r\n        input_key=tf.as_string(key.assign_add(1)), ...)\r\n```\r\nHowever, I don't think I need millions of unique keys in the queue. So probably there is another underlying problem in my model.", "The counting key generator did not solve the problem for me, nor did combining the counting key with `make_keys_unique=True`.  I did learn that the error is happening (when I run with LSTM cells, 2 layers, and `num_epochs=1`, anyway) on the 111th item, but I don't think that's relevant.\r\n\r\nI continue to find it odd that changing parameters that have no effect on the arguments passed to `batch_sequences_with_states` (e.g. learning rate parameters) affect whether or not this error occurs.  Any given parameter set has a consistent effect across repeated attempts (down to the key, except for the part generated by `make_keys_unique`, and component information in the error message), but changing the parameter set changes when or even if the error is triggered.  (Or, at least, some parameter sets won't trigger it within 500 epochs.)\r\n\r\nFor the most part I can work around this because training occurs for some time before the error, and I can simply restore the last checkpoint and continue until the error happens again.  However, that doesn't actually solve the problem.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "@raoconn can you give a minimal reproducible failure snippet?  link to gist is fine, but it should be as small as possible.  your issue is hard to debug without that because it's so specific to your data and code.", "This is no longer relevant to me.  I appreciate the effort put in, but I do not believe that it's worth either my time or anyone else's to continue investigating this unless there are others who are still having problems.", "OK; feel free to reopen if this bites you again.", "ops.....This problem bothers me"]}, {"number": 11612, "title": "pre-trained weights", "body": "can i use the tensorflow pre-trained weight model in keras and Vice versa?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11611, "title": "estimators/SVM_test.py included in test suite?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\n- **TensorFlow installed from (source or binary)**:\r\nInstalled from source, master branch\r\n- **TensorFlow version (use command below)**:\r\n>>> print(tensorflow.VERSION)\r\n1.2.1\r\n>>> print(tensorflow.GIT_VERSION)\r\nb'v1.2.0-2149-gf092326'\r\n- **Python version**: \r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10) \r\n[GCC 5.4.0 20160609] on linux2\r\n- **Bazel version (if compiling from source)**:\r\n[bazel release 0.5.2]\r\n- **CUDA/cuDNN version**:\r\nn/a\r\n- **GPU model and memory**:\r\nn/a\r\n- **Exact command to reproduce**:\r\nbazel test //tensorflow/python/... --test_verbose_timeout_warnings\r\n\r\n### Describe the problem\r\nI am troubleshooting my usage of estimators/SVM (https://stackoverflow.com/questions/45194171/tensorflow-svm-code-update-to-v1-2), and along the way it seems like svm_test.py isn't executed when running the bazel test command above. I'm a tensorflow newb, so it would be super helpful for me to understand what I'm missing here.\r\n\r\n### Source code / logs\r\n`[...]\r\n//tensorflow/python:decorator_utils_test                        (cached) PASSED in 1.2s\r\n  WARNING: //tensorflow/python:decorator_utils_test: Test execution time (1.2s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=\"short\" or size=\"small\".\r\n//tensorflow/python:deprecation_test                            (cached) PASSED in 1.1s\r\n  WARNING: //tensorflow/python:deprecation_test: Test execution time (1.1s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=\"short\" or size=\"small\".\r\n//tensorflow/python:dequantize_op_test                          (cached) PASSED in 1.1s\r\n//tensorflow/python:device_lib_test                             (cached) PASSED in 1.1s\r\n//tensorflow/python:device_setter_test                          (cached) PASSED in 1.2s\r\n//tensorflow/python/estimator:dnn_linear_combined_test          (cached) PASSED in 19.0s\r\n  Stats over 4 runs: max = 19.0s, min = 11.8s, avg = 15.4s, dev = 2.5s\r\n//tensorflow/python/estimator:dnn_test                          (cached) PASSED in 22.8s\r\n//tensorflow/python/estimator:estimator_test                    (cached) PASSED in 9.5s\r\n//tensorflow/python/estimator:export_output_test                (cached) PASSED in 1.2s\r\n//tensorflow/python/estimator:export_test                       (cached) PASSED in 5.3s\r\n//tensorflow/python/estimator:feeding_functions_test            (cached) PASSED in 1.3s\r\n//tensorflow/python/estimator:feeding_queue_runner_test         (cached) PASSED in 2.5s\r\n//tensorflow/python/estimator:head_test                         (cached) PASSED in 7.2s\r\n//tensorflow/python/estimator:linear_test                       (cached) PASSED in 35.3s\r\n//tensorflow/python/estimator:model_fn_test                     (cached) PASSED in 1.2s\r\n//tensorflow/python/estimator:numpy_io_test                     (cached) PASSED in 1.3s\r\n//tensorflow/python/estimator:optimizers_test                   (cached) PASSED in 1.0s\r\n//tensorflow/python/estimator:pandas_io_test                    (cached) PASSED in 1.5s\r\n//tensorflow/python/estimator:parsing_utils_test                (cached) PASSED in 1.5s\r\n//tensorflow/python/estimator:run_config_test                   (cached) PASSED in 1.2s\r\n//tensorflow/python/estimator:util_test                         (cached) PASSED in 1.0s\r\n  WARNING: //tensorflow/python/estimator:util_test: Test execution time (1.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=\"short\" or size=\"small\".\r\n//tensorflow/python:events_writer_test                          (cached) PASSED in 0.9s\r\n//tensorflow/python/feature_column:feature_column_test          (cached) PASSED in 5.2s\r\n  WARNING: //tensorflow/python/feature_column:feature_column_test: Test execution time (5.2s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=\"short\" or size=\"small\".\r\n//tensorflow/python:file_io_test                                (cached) PASSED in 1.9s\r\n[...]\r\n`\r\n", "comments": ["You can test it by running: \r\n```\r\nbazel test tensorflow/contrib/learn:svm_test\r\n```\r\nwhich executes [`svm_test.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/svm_test.py#L1)."]}, {"number": 11610, "title": "Changing batch size changes output for float32 matmuls elementwise by ~1e-8 (at least on CPU)", "body": "While developing a Hierarchical Attention Network, we have discovered that changing the batch size of the input effects the output of dynamic RNNs (while keeping everything else constant). In other words, feeding in [[1,2,3,4,5]] and [[6,7,8,9,10]] individually with batch size 1 will give a different result than feeding in [[1,2,3,4,5],[6,7,8,9,10]] together with batch size 2. We are currently running Bidirectional Dynamic RNNs with GRUs on the CPU-version of Tensorflow 1.2.\r\n\r\nWhile the change in output is small, when a network has many layers of RNNs, the differences become amplified. In our case, changing the batch size from 1 to 10 changes the network accuracy on our test set from 50% to 46%.\r\n\r\nSystem information and shortened sample code below.\r\n\r\n### System information\r\n== cat /etc/issue ===============================================\r\nLinux pc93071.ornl.gov 3.10.0-514.26.1.el7.x86_64 #1 SMP Tue Jun 20 01:16:02 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7.3 (Maipo)\"\r\nVERSION_ID=\"7.3\"\r\nREDHAT_BUGZILLA_PRODUCT_VERSION=7.3\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7.3\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux pc93071.ornl.gov 3.10.0-514.26.1.el7.x86_64 #1 SMP Tue Jun 20 01:16:02 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import LSTMCell, GRUCell\r\n\r\nembeddings = np.random.rand(8000,350).astype(np.float32)\r\nembeddings -= embeddings.mean()\r\nembeddings /= (embeddings.std()*2.5)\r\n\r\n#doc input and line count\r\nline = tf.placeholder(tf.int32, shape=[None,10])\r\nnum_words = tf.reduce_sum(tf.cast(tf.greater(line,0),tf.int32),1)\r\nword_embeds = tf.nn.embedding_lookup(tf.get_variable('embeddings',\r\n              initializer=embeddings,dtype=tf.float32),line)\r\n\r\n[word_outputs_fw,word_outputs_bw],_ = \\\r\n        tf.nn.bidirectional_dynamic_rnn(GRUCell(5),GRUCell(5),\r\n        word_embeds,sequence_length=num_words,\r\n        dtype=tf.float32)\r\n\r\nword_outputs = tf.concat((word_outputs_fw, word_outputs_bw),2)\r\n\r\ninit_op = tf.global_variables_initializer()\r\nsess = tf.Session()\r\nsess.run(init_op)\r\n\r\na = np.array([[1,2,3,4,5,0,0,0,0,0]])\r\nb = np.array([[6,7,8,9,10,11,12,13,14,15]])\r\nab = np.array([[1,2,3,4,5,0,0,0,0,0],[6,7,8,9,10,11,12,13,14,15]])\r\n\r\nfeed_dict = {line:a}\r\nprint sess.run(word_outputs,feed_dict=feed_dict)\r\nfeed_dict = {line:b}\r\nprint sess.run(word_outputs,feed_dict=feed_dict)\r\nfeed_dict = {line:ab}\r\nprint sess.run(word_outputs,feed_dict=feed_dict)\r\n```\r\n\r\n### Sample Output\r\n\r\nBelow, the first two matrices are the results of feeding in two inputs one at a time with batch size 1, while the second two matrices are the results of feeding in two inputs together with batch size 2. You can see that the outputs are not exactly the same. While the differences between the two are small, this becomes a major issue when there are multiple layers of RNNs as the differences become more pronounced after each layer.\r\n\r\n```\r\n[[[ 0.07946277 -0.09917585  0.01027258 -0.03145921 -0.06281948  0.27924815\r\n   -0.32083094 -0.18930595  0.17904316 -0.09718883]\r\n  [ 0.09456758 -0.06845391 -0.02745478 -0.10440759 -0.07491632  0.27888948\r\n   -0.27896836  0.03206063  0.09979809 -0.00771215]\r\n  [ 0.01643243  0.12345143  0.12964873  0.01598591 -0.18927756  0.37746075\r\n   -0.03456679 -0.01384296  0.03874877  0.06282371]\r\n  [ 0.04219431  0.02407469 -0.1588002   0.1497623  -0.17770161  0.3960323\r\n    0.16187154 -0.04393335 -0.02065297  0.10994863]\r\n  [-0.13827246 -0.07322901 -0.012384    0.12282669  0.07407188 -0.14240782\r\n    0.140168    0.02362901  0.06010906  0.05862212]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]]]\r\n[[[ 0.16048311 -0.02057735  0.18933752 -0.12690066 -0.04377137  0.32376432\r\n    0.13263705 -0.07457904  0.14895026 -0.18088266]\r\n  [ 0.16808736 -0.11579071 -0.11836589 -0.31363881  0.1567639  -0.08804542\r\n    0.1359456  -0.03568897  0.12253968 -0.08998561]\r\n  [ 0.19741508 -0.01034784 -0.03235145 -0.27677989  0.1338885  -0.14571345\r\n    0.08804264 -0.02352159  0.04717591 -0.37237346]\r\n  [ 0.24377933 -0.27160296 -0.11816068 -0.45893419 -0.09967859 -0.04910848\r\n    0.03985181 -0.01856269  0.04410465 -0.21198548]\r\n  [ 0.16746353 -0.20125373 -0.2098352  -0.36264825  0.02557869 -0.06599348\r\n   -0.11331714 -0.17118242 -0.08420456 -0.22979215]\r\n  [-0.09969822 -0.14207448  0.12536064 -0.22236535  0.11328859 -0.09342889\r\n   -0.02536193 -0.28028104 -0.11790876 -0.10144062]\r\n  [-0.09796695 -0.14415297 -0.19729097 -0.25542045 -0.15568495 -0.12689842\r\n   -0.14712927 -0.35488427 -0.06447952 -0.19063833]\r\n  [-0.12240371 -0.07732555 -0.2645728   0.11042064 -0.19387801  0.07324903\r\n   -0.03920996  0.05104404 -0.09357925 -0.13582835]\r\n  [-0.07295815 -0.02809375 -0.24317381  0.04480781 -0.06040902  0.03428879\r\n    0.10196722 -0.06142509 -0.36903486 -0.16991363]\r\n  [-0.01382132 -0.09746805  0.13226555  0.19477166  0.02158988  0.09287433\r\n    0.01845972 -0.16030487 -0.2186746  -0.07543172]]]\r\n[[[ 0.07946277 -0.09917583  0.01027257 -0.03145922 -0.06281949  0.27924818\r\n   -0.32083094 -0.1893059   0.17904317 -0.09718874]\r\n  [ 0.09456757 -0.06845395 -0.02745485 -0.10440758 -0.07491633  0.27888948\r\n   -0.27896842  0.03206065  0.09979802 -0.00771213]\r\n  [ 0.01643244  0.12345135  0.1296487   0.01598606 -0.18927751  0.37746072\r\n   -0.0345668  -0.01384297  0.03874873  0.06282371]\r\n  [ 0.0421943   0.02407462 -0.15880026  0.14976241 -0.17770153  0.39603227\r\n    0.16187152 -0.04393341 -0.02065307  0.10994864]\r\n  [-0.13827249 -0.07322903 -0.01238406  0.12282679  0.07407197 -0.14240779\r\n    0.14016804  0.02362898  0.06010904  0.05862212]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]\r\n  [ 0.          0.          0.          0.          0.          0.          0.\r\n    0.          0.          0.        ]]\r\n\r\n [[ 0.16048311 -0.02057736  0.18933751 -0.12690073 -0.04377136  0.32376438\r\n    0.13263711 -0.07457898  0.14895013 -0.18088272]\r\n  [ 0.16808733 -0.11579067 -0.11836579 -0.31363881  0.15676391 -0.0880454\r\n    0.13594568 -0.03568894  0.12253958 -0.08998567]\r\n  [ 0.19741504 -0.01034782 -0.0323514  -0.27677989  0.13388851 -0.14571348\r\n    0.08804271 -0.02352155  0.0471758  -0.37237346]\r\n  [ 0.2437793  -0.27160296 -0.11816064 -0.45893413 -0.09967858 -0.04910852\r\n    0.03985184 -0.01856264  0.04410452 -0.21198554]\r\n  [ 0.16746351 -0.20125373 -0.20983508 -0.36264819  0.02557869 -0.06599346\r\n   -0.11331721 -0.17118247 -0.08420463 -0.22979221]\r\n  [-0.09969822 -0.14207451  0.12536073 -0.22236532  0.11328855 -0.09342889\r\n   -0.02536207 -0.28028107 -0.11790879 -0.10144066]\r\n  [-0.09796697 -0.14415301 -0.19729097 -0.25542039 -0.15568499 -0.12689844\r\n   -0.14712939 -0.35488427 -0.06447949 -0.19063836]\r\n  [-0.12240377 -0.07732558 -0.2645728   0.11042073 -0.19387813  0.07324899\r\n   -0.03921008  0.05104404 -0.0935792  -0.13582836]\r\n  [-0.07295817 -0.02809371 -0.24317381  0.04480787 -0.06040911  0.03428881\r\n    0.10196713 -0.06142508 -0.3690348  -0.16991359]\r\n  [-0.0138213  -0.09746802  0.13226555  0.19477174  0.02158987  0.09287442\r\n    0.0184597  -0.16030489 -0.21867451 -0.07543168]]]\r\n\r\n```", "comments": ["@ebrevdo : Mind taking a look?", "Any update on this?", "Running your example with TF 1.3.0 in CPU-only mode:\r\n```\r\nav = sess.run(word_outputs,feed_dict={line:a})   \r\nbv = sess.run(word_outputs,feed_dict={line:b})   \r\nabv = sess.run(word_outputs,feed_dict={line:ab}) \r\nnp.linalg.norm(av-abv[0])\r\n4.1601669e-07\r\nnp.linalg.norm(bv-abv[1]) \r\n6.3027767e-07\r\n```\r\nand calculating av twice returns identical values.\r\n\r\nwhen i switch everything to float64s, the errors go to zero.\r\n\r\ni'll look into it more carefully.\r\n", "I'm able to replicate the problem with a single call to GRUCell:\r\n\r\n```\r\nc = GRUCell(5)\r\ninit = c.zero_state(tf.size(num_words), tf.float32)\r\nouts = c(word_embeds[:,0,:], init)\r\n# reinitialize variables\r\nav = sess.run(outs, {line:a})    \r\nbv = sess.run(outs, {line:b})    \r\nabv = sess.run(outs, {line:ab})  \r\n```\r\n\r\nto get:\r\n```\r\nIn [63]: av[0] - abv[0][0]\r\nOut[63]: \r\narray([[ -2.23517418e-08,   8.94069672e-08,  -2.60770321e-08,\r\n          7.45058060e-08,   0.00000000e+00]], dtype=float32)\r\n```\r\n\r\netc.\r\n\r\nperhaps we are compiling FAST_MATH, and as a result the fp32 matmul or nonlinearities (tanh/sigmoid) are returning different values along the vectorisation path?  @rmlarsen what do you think?", "Looks like the matmul is the real culprit here.  It's not deterministic for f32, at least on CPUs:\r\n\r\n```\r\n z = tf.concat((word_embeds[:,0,:], init), axis=1)  # shaped [batch_size, 355]\r\nmm = tf.matmul(z, c.variables[0])  # matmul (batch_size, 355) . (355, 10) => (batch_size, 10)\r\nav = sess.run(mm, {line:a}) \r\nbv = sess.run(mm, {line:b}) \r\nabv = sess.run(mm, {line:ab}) \r\nnp.linalg.norm(av-abv[0])   \r\n4.1578312e-07\r\nnp.linalg.norm(bv-abv[1])   \r\n4.8896561e-07\r\n```\r\n", "sorry - it's deterministic, but its output depend on the batch sizes.", "Updated issue title.", "Perhaps this is related to problems with the Python (?only?) binding to protobuf which introduces float imprecision on deserialization? ( https://github.com/tensorflow/tensorflow/issues/12876 )", "I doubt it. The identity round trips are fine, and protobuf errors are\nO(tiny), not O(eps).\n\nOn Sep 8, 2017 7:37 PM, \"loki der quaeler\" <notifications@github.com> wrote:\n\n> Perhaps this is related to problems with the Python (?only?) binding to\n> protobuf which introduces float imprecision on deserialization? ( #12876\n> <https://github.com/tensorflow/tensorflow/issues/12876> )\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11610#issuecomment-328249112>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim2zPh93Fqd5VxtLb3yEcUsv_n6xyks5sgfnLgaJpZM4Oc1VE>\n> .\n>\n", "Ok - sorry for the red herring.", "Any update on this?\r\nIn my application, it causes a large computational loss because it can not inference by reducing the batch size. ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I am also facing the same issue for tf 1.4.1 . When I am passing each individual example ( observation ) and as a batch ( 10 , 32 , whatever ) , there is difference in values ( first pass is RNN (lstm) ). This leads to final change in my predicted probabilities, as I am doing a classification. Any ideas on this ? ", "@ebrevdo - same problem with, tf 1.5.0 ( both in GPU and CPU ) . Any ideas or workaround, As @iamshang1  mentioned, initial value differences are not huge, but as we pass it through many layers, we have huge difference in final accuracy. ", "@s4sarath are you using cudnn on GPU?  i only expect this on CPU.\r\n\r\n@rmlarsen @ekelsen anything we can do about this?", "@ebrevdo - Yes I am using cudnn. I have tried it on GeForce 980i. I will check it on 1080 Ti soon . ", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "My guess is this is caused by vectorisation kicking in as batch size changes. Vectorisation code, esp if fast math is enabled, can have some effect on precision.  Reopen if it greatly affects your model performance."]}, {"number": 11609, "title": "_CoordinatedSessionCreator should inherit from SessionCreator.", "body": "`_CoordinatedSessionCreator` should inherit from `SessionCreator`.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 11608, "title": "Distributed Tensorflow : Cannot assign a device for operation...", "body": "I am trying to use a distributed version of Self-Normalizing Networks on MNIST \r\n\r\nThe full code is provided here:\r\n`\r\nclass DNN_forward_MC(object):\r\n\r\n        def __init__(self,num_data,num_test,dim_input,dim_output,num_hidden_layers,num_hidden_dims,keep_prob,num_minibatch,X_train,Y_train,X_test,Y_test):\r\n\r\n\r\n                # cluster specification\r\n                parameter_servers = [\"localhost:2222\"]\r\n                workers = [     \"localhost:2223\", \r\n                        \"localhost:2224\",\r\n                        \"localhost:2225\"]\r\n\r\n                cluster = tf.train.ClusterSpec({\"ps\":parameter_servers, \"worker\":workers})\r\n\r\n                # input flags\r\n                tf.app.flags.DEFINE_string(\"job_name\", \"\", \"Either 'ps' or 'worker'\")\r\n                tf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\r\n                FLAGS = tf.app.flags.FLAGS\r\n\r\n                # start a server for a specific task\r\n                server = tf.train.Server(\r\n                                        cluster,\r\n                                        job_name=FLAGS.job_name,\r\n                                        task_index=FLAGS.task_index)\r\n\r\n\r\n                is_chief=(FLAGS.task_index == 0)\r\n                if FLAGS.job_name == \"ps\":\r\n                        server.join()\r\n\r\n                elif FLAGS.job_name == \"worker\":\r\n                        with tf.device(tf.train.replica_device_setter(\r\n                worker_device=\"/job:worker/task:%d/cpu:0\" % FLAGS.task_index,\r\n                cluster=cluster,ps_device=\"/job:ps/cpu:0\")):\r\n\r\n                                global_step = tf.Variable(0, name=\"global_step\", trainable=False)\r\n                                self.initialize_model(num_data,num_test,dim_input,dim_output,num_hidden_layers,num_hidden_dims,keep_prob,num_minibatch)\r\n\r\n                                predictions = self.predict_training(tip='redus')\r\n                                predictions_training_full = self.predict_training(tip='full')\r\n\r\n                                predictions_testing_full = self.predict_testing()\r\n\r\n                                cost =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=self.Y_train, logits=predictions))\r\n                                opt = tf.train.GradientDescentOptimizer(1e-3)\r\n                                opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=3,total_num_replicas=3)\r\n                                train_op = opt.minimize(cost,global_step=global_step)\r\n                                init_op = tf.global_variables_initializer()\r\n\r\n                                #grads_and_vars = optimizer.compute_gradients(cost, tf.trainable_variables())\r\n\r\n                                local_init_op = opt.local_step_init_op\r\n                                if is_chief:\r\n                                        local_init_op = opt.chief_init_op\r\n\r\n                                ready_for_local_init_op = opt.ready_for_local_init_op\r\n\r\n                                # Initial token and chief queue runners required by the sync_replicas mode\r\n                                chief_queue_runner = opt.get_chief_queue_runner()\r\n                                sync_init_op = opt.get_init_tokens_op()\r\n\r\n                        train_dir = tempfile.mkdtemp()\r\n                        sv = tf.train.Supervisor(logdir=train_dir,is_chief=(FLAGS.task_index == 0),init_op=init_op,local_init_op=local_init_op,recovery_wait_secs=1,ready_for_local_init_op=ready_for_local_init_op)\r\n\r\n                        if is_chief:\r\n                                print(\"Worker %d: Initializing session...\" % FLAGS.task_index)\r\n                        else:\r\n                                print(\"Worker %d: Waiting for session to be initialized...\" % FLAGS.task_index)\r\n\r\n\r\n                        sess_config = tf.ConfigProto(allow_soft_placement=True,log_device_placement=False,device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\r\n\r\n                        with sv.prepare_or_wait_for_session(server.target,config=sess_config) as sess:\r\n                        #with tf.train.MonitoredTrainingSession(master=server.target,is_chief=is_chief,checkpoint_dir='./logs/',save_checkpoint_secs=60,save_summaries_steps=1) as sess:        \r\n                                while True:\r\n\r\n                                        lista = np.arange(self.num_data)\r\n                                        np.random.shuffle(lista)\r\n                                        current_index = lista[:self.num_minibatch]\r\n\r\n                                        likelihood_now,_,step_now = self.sess.run([cost,train_op,global_step],feed_dict={self.X_train:X_train[current_index],self.Y_train:Y_train[current_index]})\r\n                                        printare = 'nll for minibatch at iteration '+str(i)+' is '+str(likelihood_now)\r\n                                        print(printare)\r\n                                        predictions_now = self.sess.run(predictions_training_full,feed_dict={self.X_train_full:X_train})\r\n                                        print 'accuracy is : '+str(self.sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_train,1),tf.argmax(tf.nn.softmax(predictions_now),1)),tf.float32))))\r\n                                        if step_now>10:\r\n                                                break\r\n\r\n                                print '*******training last iteration**********'\r\n                                \r\n                                if is_chief:\r\n\r\n                                        predictions_now = self.sess.run(predictions_testing_full,feed_dict={self.X_test:X_test})\r\n                                        print '***********testing*************'\r\n\r\n                                        print 'accuracy at testing time is :' +str(self.sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_test,1),tf.argmax(tf.nn.softmax(predictions_now),1)),tf.float32))))\r\n\r\n                        sv.stop()\r\n        def initialize_model(self,num_data,num_test,dim_input,dim_output,num_hidden_layers,num_hidden_dims,keep_prob,num_minibatch):\r\n\r\n                ### model using just Hinton's Dropout\r\n                self.sess = tf.Session()\r\n                self.num_minibatch = num_minibatch\r\n                self.num_data = num_data\r\n                self.num_test = num_test\r\n                self.dim_input = dim_input\r\n                self.dim_output = dim_output\r\n                self.num_hidden_layers = num_hidden_layers\r\n                self.num_hidden_dims = num_hidden_dims\r\n\r\n                self.keep_prob = keep_prob\r\n                self.alpha_p = -1.7580993408473766\r\n                q = 1.0 - keep_prob\r\n                prod  = q + np.power(self.alpha_p,2)*q*(1-q)\r\n                self.a_affine = np.power(prod,-0.5)\r\n                self.b_affine = -self.a_affine * (self.alpha_p*(1-q))\r\n\r\n                self.X_train_full = tf.placeholder(shape=(self.num_data,dim_input),dtype=tf.float32)\r\n        \r\n                self.X_train = tf.placeholder(tf.float32,shape=(num_minibatch,dim_input))\r\n                self.Y_train = tf.placeholder(tf.float32,shape=(num_minibatch,dim_output))\r\n                self.X_test = tf.placeholder(tf.float32,shape=(num_test,dim_input))\r\n                self.Y_test = tf.placeholder(tf.float32,shape=(num_test,dim_output))\r\n\r\n                self.weights = []\r\n                self.biases = []\r\n\r\n                ### create parameters for Global DNN\r\n                for j in range(self.num_hidden_layers+1):                                                                                                              \r\n                        self.weights.append(tf.Variable(tf.random_normal(shape=(num_hidden_dims[j-1],self.num_hidden_dims[j]),stddev=1.0/num_hidden_dims[j-1]),dtype=tf.float32,name='weights_'+str(j)))\r\n                        self.biases.append(tf.Variable(tf.random_normal(shape=(self.num_hidden_dims[j],)),dtype=tf.float32,name='biases'+str(j)))          \r\n                \r\n                self.weights.append(tf.Variable(tf.random_normal(shape=(self.num_hidden_dims[self.num_hidden_layers],self.num_hidden_dims[self.num_hidden_layers+1])\r\n                ,stddev=1.0/self.num_hidden_dims[self.num_hidden_layers]),dtype=tf.float32,name='weights_'+str(self.num_hidden_layers+1)))\r\n                self.biases.append(tf.Variable(tf.random_normal(shape=(self.num_hidden_dims[self.num_hidden_layers+1],)),dtype=tf.float32,name='biases_'+str(self.num_hidden_layers+1)))\r\n\r\n               \r\n        def selu(self,x):\r\n\r\n                alpha= 1.6732632423543772848170429916717\r\n                lamb = 1.0507009873554804934193349852946\r\n                return lamb * tf.where(x>0.0,x,alpha * tf.nn.elu(x))\r\n\r\n        def alpha_dropout(self,x):\r\n\r\n                mask = tf.cast(tf.random_uniform(shape=x.get_shape()) < ( 1.0 - self.keep_prob ),dtype=tf.float32)\r\n                x_masked = tf.multiply(x,mask)\r\n                out = x_masked * self.a_affine + self.b_affine\r\n                return out      \r\n\r\n        def model(self,input,apply_dropout=True):\r\n\r\n                for j in range(1,self.num_hidden_layers +1):\r\n\r\n                        input = self.selu(tf.add(tf.matmul(input,self.weights[j]),self.biases[j]))\r\n                        if apply_dropout:\r\n\r\n                                input = self.alpha_dropout(input)\r\n\r\n                final_output = tf.add(tf.matmul(input,self.weights[self.num_hidden_layers+1]),self.biases[self.num_hidden_layers+1])\r\n\r\n                return final_output\r\n\r\n\r\n        def predict_training(self,tip):\r\n\r\n                if tip == 'full':\r\n                        prediction_DNN_global = self.model(input=self.X_train_full,apply_dropout=False)\r\n                else:\r\n                        prediction_DNN_global = self.model(input = self.X_train,apply_dropout=True)\r\n\r\n                return prediction_DNN_global\r\n\r\n                \r\n        def predict_testing(self):\r\n\r\n                prediction_DNN_global = self.model(input = self.X_test,apply_dropout=False)\r\n\r\n                return prediction_DNN_global\r\n\r\nif __name__ == '__main__':\r\n\r\n        training_data = np.genfromtxt('/home/spopescu/mnist_train.csv',dtype=np.float64,delimiter=',')\r\n        testing_data = np.genfromtxt('/home/spopescu/mnist_test.csv',dtype=np.float64,delimiter=',')\r\n\r\n        X_training = training_data[:,1:]\r\n        X_testing = testing_data[:,1:]\r\n        Y_training = one_hot_encoder(training_data[:,0].reshape(X_training.shape[0],1))\r\n        Y_testing = one_hot_encoder(testing_data[:,0].reshape(X_testing.shape[0],1))\r\n\r\n        obiect = DNN_forward_MC(num_data=X_training.shape[0],num_test=X_testing.shape[0],dim_input=X_training.shape[1],dim_output=Y_training.shape[1],num_hidden_layers=3,num_hidden_dims=[X_training.shape[1],200,50,20,Y_training.shape[1]],keep_prob=0.80,num_minibatch=20,X_train=X_training,Y_train=Y_training,X_test=X_testing,Y_test=Y_testing)\r\n\r\n`\r\n\r\nI am using the following Slurm bash script to send an array job:\r\n`\r\n#!/bin/sh\r\n#SBATCH --mem=20G\r\n#SBATCH -J SNN\r\n#SBATCH --array=0-3\r\n#SBATCH -o slurm-%A_%a.out\r\n#SBATCH -e slurm-%A_%a.err\r\n#SBATCH --nodelist=compute-2-3\r\n\r\ntask_type=(\"ps\" \"worker\" \"worker\" \"worker\")\r\ntask_index_array=(0 0 1 2)\r\nsrun --exclusive -N1 -n1 /home/spopescu/anaconda/bin/python2.7 DNN_forward_MC.py --job_name=${task_type[$SLURM_ARRAY_TASK_ID]} --task_index=${task_index_array[$SLURM_ARRAY_TASK_ID]}\r\n`\r\n\r\nI am using the latest version of Tensorflow as of today.\r\n\r\nI am getting the following error on my chief worker:\r\n\r\n`\r\n2017-07-19 14:49:14.087646: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}\r\n2017-07-19 14:49:14.087702: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225}\r\n2017-07-19 14:49:14.091606: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2223\r\n2017-07-19 14:49:15.137109: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 4b5afb77d3aa2b77 with config: \r\ndevice_filters: \"/job:ps\"\r\ndevice_filters: \"/job:worker/task:0\"\r\nallow_soft_placement: true\r\n\r\nTraceback (most recent call last):\r\n  File \"DNN_forward_MC.py\", line 221, in <module>\r\n    obiect = DNN_forward_MC(num_data=X_training.shape[0],num_test=X_testing.shape[0],dim_input=X_training.shape[1],dim_output=Y_training.shape[1],num_hidden_layers=3,num_hidden_dims=[X_training.shape[1],200,50,20,Y_training.shape[1]],keep_prob=0.80,num_minibatch=20,X_train=X_training,Y_train=Y_training,X_test=X_testing,Y_test=Y_testing)\r\n  File \"DNN_forward_MC.py\", line 108, in __init__\r\n    likelihood_now,_,step_now = self.sess.run([cost,train_op,global_step],feed_dict={self.X_train:X_train[current_index],self.Y_train:Y_train[current_index]})\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'save/RestoreV2_10': Operation was explicitly assigned to /job:ps/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\r\n         [[Node: save/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:ps/task:0/device:CPU:0\"](save/Const, save/RestoreV2_10/tensor_names, save/RestoreV2_10/shape_and_slices)]]\r\n\r\nCaused by op u'save/RestoreV2_10', defined at:\r\n  File \"DNN_forward_MC.py\", line 221, in <module>\r\n    obiect = DNN_forward_MC(num_data=X_training.shape[0],num_test=X_testing.shape[0],dim_input=X_training.shape[1],dim_output=Y_training.shape[1],num_hidden_layers=3,num_hidden_dims=[X_training.shape[1],200,50,20,Y_training.shape[1]],keep_prob=0.80,num_minibatch=20,X_train=X_training,Y_train=Y_training,X_test=X_testing,Y_test=Y_testing)\r\n  File \"DNN_forward_MC.py\", line 90, in __init__\r\n    sv = tf.train.Supervisor(logdir=train_dir,is_chief=(FLAGS.task_index == 0),init_op=init_op,local_init_op=local_init_op,recovery_wait_secs=1,ready_for_local_init_op=ready_for_local_init_op)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 300, in __init__\r\n    self._init_saver(saver=saver)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 448, in _init_saver\r\n    saver = saver_mod.Saver()\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\r\n    self.build()\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 691, in build\r\n    restore_sequentially, reshape)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/spopescu/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/RestoreV2_10': Operation was explicitly assigned to /job:ps/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\r\n         [[Node: save/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:ps/task:0/device:CPU:0\"](save/Const, save/RestoreV2_10/tensor_names, save/RestoreV2_10/shape_and_slices)]]\r\n`\r\n\r\n\r\n\r\nI have mostly seen the \"cannot assign a device for operation ...\" error in the case of people using GPU without specifying allow_soft_placement=True but in my case I am using just CPUs.\r\n\r\nI have seen another instance of this error when users were not specifying server.target as the device of a session,thereby creating a local session but this is not the case in my code.\r\n\r\nAny help would be much appreciated.\r\n\r\n\r\n", "comments": ["I think the problem stems from using `self.sess` (created as a `tf.Session()` in `initialize_model()`) rather than the `sess` returned from `sv.prepare_or_wait_for_session()`.", "@mrry yeah that solved the problem. Now I am getting the following error message:\r\n\r\n`\r\n I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n`\r\nI get this error message for the non-chief workers. Does that mean that somehow workers 1 and 2 don't communicate properly with the ps?", "Sorry ignore the previous question. Those two workers were running on another compute node as opposed to the ps and chief worker."]}, {"number": 11607, "title": "Add comment to clarify semantics of opt_level parameter.", "body": "Note: This is my first PR against this project. Let me know if I've done anything wrong. I should be on IBM's corporate CLA.\r\n\r\nThe meaning of the `opt_level` parameter of `OptimizerOptions` was ambiguous, leading a user to open https://github.com/tensorflow/tensorflow/issues/11087 , which requests functionality that is actually already present but undocumented. This PR documents the functionality.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 11606, "title": "replace supervised session to monitored session", "body": "The author should forget to modify doc for `MonitoredSession._is_closed` when refactoring supervisor to monitored session.\r\n", "comments": ["Can one of the admins verify this patch?"]}]