[{"number": 1029, "title": "tf.image.resize_images() expects statically known rank", "body": "It looks like the op `tf.image.resize_images()` has no effect on the image shape when the parameters `new_height` and `new_width` are dynamically computed (this is possible since the fix of issue #1001).\n\nFor example, this piece of code\n\n```\nshape = tf.shape(image)\nheight = shape[0]\nwidth = shape[1]\nnew_shorter_edge = tf.constant(400, dtype=tf.int32)\n\nheight_smaller_than_width = tf.less_equal(height, width)\nnew_height_and_width = tf.cond(\n    height_smaller_than_width,\n    lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n    lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n)\n\nimage = tf.image.resize_images(image, new_height_and_width[0], new_height_and_width[1])\nimage = tf.Print(image, [tf.shape(image), height, width, new_height_and_width[0], new_height_and_width[1]])\nreturn tf.image.random_crop(image, [224, 224])\n```\n\nthrows the following exception:\n\n```\nI tensorflow/core/kernels/logging_ops.cc:79] [122 160 3][122][160][400][524]\nW tensorflow/core/common_runtime/executor.cc:1096] 0x7f9c08008490 Compute status: Failed precondition: width must be >= target_width: width = 160, target_width = 224\n```\n\nSo as you can see in the first line of the printout, the shape of the image is not affected by `tf.image.resize_images`. Is this a bug or am I doing something wrong?\n\n---\n\nI also made up a workaround for this:\n\n```\nimage = tf.expand_dims(image, 0)\nimage = tf.image.resize_bilinear(image, tf.pack(new_height_and_width))\nimage = tf.squeeze(image, [0])\nimage = tf.Print(image, [tf.shape(image), height, width, new_height_and_width[0], new_height_and_width[1]])\nreturn tf.image.random_crop(image, [224, 224])\n```\n\nfor example prints\n\n```\nI tensorflow/core/kernels/logging_ops.cc:79] [400 711 3][281][500][400][711]\n```\n", "comments": ["@shlens: Do you know the correct way to fix this?\n", "resize_images is light wrapper around several resizing kernels, including resize_bilinear, resize_bicubic, etc. The light wrapper functionality is intended to \"assist\" with the shape information and 3d and 4d images seemlessly. If you do not need all of these \"assists\" for shape information and 3d/4d images, could you call the underlying functions directly, e.g. resize_bilinear?\n", "I renamed the issue.  Ideally `resize_image` wouldn't require shapes to be known statically; certainly there's nothing fundamental about the underlying ops that requires it.\n", "I'll work on this\n", "@fayeshine: Thank you!  Let me know if you have questions. \n", "@girving , tf.image.random_crop has changed to tf.random_crop.\nAnd now this bug seems to be solved naturally.\nI can use resize_images to correctly resize images using the following codes.\n\n```\nfrom tensorflow.examples.tutorials.mnist import input_data \nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nimport tensorflow as tf\nsess = tf.InteractiveSession()\nimport matplotlib.pyplot as plt\narr = mnist.train.images[:10].reshape([10,28,28,1])\nplt.imshow(arr[5,:,:,0])\nimages = tf.convert_to_tensor(arr, name='images')\n\ndef _compute_longer_edge(height, width, new_shorter_edge):\n    return tf.cast(width*new_shorter_edge/height, tf.int32)\n\nshape = tf.shape(images)\nheight = shape[1]\nwidth = shape[2]\nnew_shorter_edge = tf.constant(400, dtype=tf.int32)\n\nheight_smaller_than_width = tf.less_equal(height, width)\nnew_height_and_width = tf.cond(\n    height_smaller_than_width,\n    lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n    lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n)\n\nimages_ = tf.image.resize_images(images, new_height_and_width[0], new_height_and_width[1])\n#image = tf.image.resize_bilinear(images, tf.pack(new_height_and_width))\nimages_ = tf.Print(images_, [tf.shape(images_), height, width, new_height_and_width[0], new_height_and_width[1]])\n\nres = sess.run(tf.random_crop(images_, [10,224, 224,1]))\nplt.imshow(res[5,:,:,0])\n```\n", "Aside: When you paste code format it by indenting four spaces; otherwise the code's indentation will go away.\n\nIn the code you've shown the sizes are statically known since `images` comes from `convert_to_tensor`.  To exhibit the bug you'll have to make a `tf.placeholder` with no shape so that shape inference doesn't kick in.\n", "@girving I tried to use tf.placeholder with no shape, however I still cannot reproduce this bug.\n\n```\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nimport tensorflow as tf\nsess = tf.InteractiveSession()\nimport matplotlib.pyplot as plt\narr = mnist.train.images[:10].reshape([10,28,28,1])\nplt.imshow(arr[5,:,:,0])\n\n#images = tf.convert_to_tensor(arr, name='images')\nimages = tf.placeholder(tf.float32, shape=[None,None,None,None])\n\n#%%\ndef _compute_longer_edge(height, width, new_shorter_edge):\n    return tf.cast(width*new_shorter_edge/height, tf.int32)\n\nshape = tf.shape(images)\nheight = shape[1]\nwidth = shape[2]\nnew_shorter_edge = tf.constant(400, dtype=tf.int32)\n\nheight_smaller_than_width = tf.less_equal(height, width)\nnew_height_and_width = tf.cond(\n    height_smaller_than_width,\n    lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n    lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n)\n\nimages_ = tf.image.resize_images(images, new_height_and_width[0], new_height_and_width[1])\n#image = tf.image.resize_bilinear(images, tf.pack(new_height_and_width))\nimages_ = tf.Print(images_, [tf.shape(images_), height, width, new_height_and_width[0], new_height_and_width[1]])\n\nres = tf.random_crop(images_, [10,224,224,1]).eval(feed_dict={images: arr})\nplt.imshow(res[5,:,:,0])\n#%%\n\narr2 = mnist.train.images[10:20].reshape([10,56,14,1])\nres2 = tf.random_crop(images_, [10,224,224,1]).eval(feed_dict={images: arr2})\nplt.imshow(res2[5,:,:,0])\n```\n", "Please reformat the code as I mentioned so that it's easier to read.\n", "@girving , sorry, I've formatted it by indenting four spaces. I was previously thinking that you mean use 4 spaces to replace tab. :smile: \n", "@fayeshine: So close!  It looks like `resize_images` goes out of its way to break only if the _rank_ of the input tensor is unknown.  Try using `shape=None` in your placeholder instead of `shape=[None, None, None, None]` and you should see a problem.  However, I'm not sure if this is the same problem that  @mackcmillion was experiencing.\n", "@girving Yes, you are right, in this case `resize_bilinear` can work but `resize_images` throw an exception `ValueError: 'images' contains no shape.` .\nI checked the code and found:\n\n```\nif images.get_shape().ndims is None:\n    raise ValueError('\\'images\\' contains no shape.')\n  # TODO(shlens): Migrate this functionality to the underlying Op's.\n```\n\nThis seems like it is planned to move the `resize_images` function to the native c++ code.\nIn python, we cannot dynamically know what's shape of images(4-D or 3-D), so we cannot know what to do next.\nSo in this case, does it mean the solution should be move this in low-layer C++ part so we can know the shape in runtime?\n", "@fayeshine: Yep, the cleanest way is probably to make all the C++ resize ops accept any number of dimensions >= 3 and treat the initial dims-3 dimensions as batch.  There are a lot of other ops that behave this way: mixing together the last few dimensions and broadcasting over the first few. \n", "As noted in #2286, `resize_image_with_crop_or_pad` has the same problem.  It should be fixed in the same way.\n", "I saw that `resize_image_with_crop_or_pad` was fixed, does this apply to the other cropping image ops or only this one? For instance `crop_to_bouding_box`.\n", "It applies to anything that calls  `_Check3DImage` with `require_static=True` (the default).  The `require_static` option should go away entirely.  Looks like `crop_to_bounding_box` uses `require_static=False`, so it's clean.\n", "Are there any functions for Nearest neighbour upsampling of 3D images in tensorflow? Any workaround for this?\n", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you. ", "I think this is still a problem that should be addressed. Is a simple operation and it could be useful if you don't want to depend on other image libraries to do simple image transformations.\r\nHere is an example that shows the problem:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nencoded_image_data = tf.placeholder(dtype=tf.string)\r\ndecoded_image = tf.image.decode_image(encoded_image_data, channels=3)\r\nresized_image = tf.image.resize_images(decode_image, (800, 600))\r\nencoded_image = tf.image.encode_jpeg(resized_image)\r\n\r\nimport urllib2\r\nfd = urllib2.urlopen('https://c8.staticflickr.com/6/5753/20965045223_b809050285_o.jpg')\r\ndata = fd.read()\r\n    \r\nwith tf.Session() as sess:\r\n    sess.run([encoded_image], { encoded_image_data: data}) \r\n```\r\n\r\noutput:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-41-bbd519ee1c20> in <module>()\r\n      4 encoded_image_data = tf.placeholder(dtype=tf.string)\r\n      5 decoded_image = tf.image.decode_image(encoded_image_data, channels=3)\r\n----> 6 resized_image = tf.image.resize_images(decode_image, (800, 600))\r\n      7 encoded_image = tf.image.encode_jpeg(resized_image)\r\n      8 \r\n\r\n/home/fmilo/anaconda2/envs/tensorflow_built/lib/python2.7/site-packages/tensorflow/python/ops/image_ops_impl.pyc in resize_images(images, size, method, align_corners)\r\n    730   images = ops.convert_to_tensor(images, name='images')\r\n    731   if images.get_shape().ndims is None:\r\n--> 732     raise ValueError('\\'images\\' contains no shape.')\r\n    733   # TODO(shlens): Migrate this functionality to the underlying Op's.\r\n    734   is_batch = True\r\n\r\nValueError: 'images' contains no shape.\r\n\r\n```\r\n\r\n", "For anyone else who runs into this problem, using the example above with the assumption of 3 Dims:\r\n```\r\ndecoded_image = tf.image.decode_image(encoded_image_data, channels=3)\r\ndecoded_image.set_shape([None, None, None])\r\nresized_image = tf.image.resize_images(decode_image, (800, 600))\r\n```\r\n\r\nThis allows `ndims` to be returned (i.e. not be `None`) whilst allowing flexibility of resizing differently sized images.", "Had similar problems and following the last comment seems to have fixed it.\r\nBasically I just added .set_shape([None, None, None]) to my image before the resize.  Does feel like a workaround to a bug.", "Based on https://github.com/tensorflow/tensorflow/issues/9356, using `decode_png` or `decode_jpeg` to decode the image (which seems to be the most popular source of this issue) can also resolve this issue. This also seems like a workaround to a bug. ", "@dcunhas you are right. We can decode images using decode_png and decode_jpeg like this:\r\n\r\n```\r\n    image_string = tf.read_file(filename)\r\n    image_decoded = tf.cond(\r\n        tf.image.is_jpeg(image_string),\r\n        lambda: tf.image.decode_jpeg(image_string, channels=3),\r\n        lambda: tf.image.decode_png(image_string, channels=3))\r\n```", "@Alex-zhai You don't need to go that far. You can directly do:\r\n```\r\nimage_string = tf.read_file(filename)\r\nimage_decoded = tf.image.decode_jpeg(image_string, channels=3)\r\n```\r\nBased on the documentation (and my own usage), \"This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use tf.image.decode_image.\" `tf.image.decode_png` is the same. `tf.image.decode_image` is what causes the bug, and thus can obviously not be used.", "I found the solution\r\n```\r\ntf.enable_eager_execution()\r\n```\r\nadd this to the top of your code.\r\n\r\nor\r\n```\r\nimg_tensor = tf.image.decode_jpeg(img_raw,channels=3)\r\nimg_final = tf.image.resize_images(img_tensor, [192, 192])\r\nimg_final = img_final/255.0\r\nprint(img_final.shape)\r\n```"]}, {"number": 1028, "title": "Tensorflow with CUDA build failure in Docker", "body": "Hello) Trying to make dockerfile with ubuntu 14, tensorflow on python3 with cuda and ec2 support ..\n\nTF ver 0.6.0\nBazel ver 0.1.4\nStarting from docker image: nvidia/cuda:7.0-cudnn2-devel\n\nIn dockerfile have smth like this:\n\n```\n\nRUN TF_UNOFFICIAL_SETTING=1 \\\n     TF_CUDA_COMPUTE_CAPABILITIES=3.0 \\\n     PYTHON_BIN_PATH=/usr/bin/python3 ./configure && \\\n   bazel build \\\n     --config=cuda \\\n     --verbose_failures \\\n     --spawn_strategy=standalone \\\n     --local_resources 4096,1.0,1.0 \\\n     tensorflow/tools/pip_package:build_pip_package && \\\n\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\n\n    echo $(date) : \"=== Building wheel\" && \\\n\n    python3 setup.py bdist_wheel --python-tag py34 >/dev/null && \\\n\n    pip3 install --upgrade /tmp/pip/tensorflow-0.6.0-py34-none-any.whl\n```\n\nWithout --localresources had \"Killed\" error like [here](http://stackoverflow.com/questions/34699069/building-tensorflow-from-source-on-ubuntu-14-04-lts-gcc-internal-compiler-erro)\n--spawn_strategy from [here](https://github.com/bazelbuild/bazel/issues/698)\n\nNow have such error, and have no idea what to do next =(\n\n```\n\n`____[577 / 1,175] Compiling tensorflow/python/pywrap_tensorflow.cc\n____[580 / 1,175] Compiling tensorflow/core/util/work_sharder.cc [for host]\n____[585 / 1,175] Compiling tensorflow/core/lib/hash/crc32c.cc [for host]\n____[587 / 1,175] Compiling tensorflow/core/lib/histogram/histogram.cc [for host\n]\nERROR: /tensorflow/tensorflow/stream_executor/BUILD:5:1: undeclared inclusion(s)\nin rule '//tensorflow/stream_executor:stream_executor':\nthis rule is missing dependency declarations for the following files included by\n'tensorflow/stream_executor/cuda/cuda_rng.cc':\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_rng.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_activation.h'\n'/tensorflow/tensorflow/stream_executor/cuda/multi_op_activation.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_kernel.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_driver.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_helpers.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_platform_id.h'\n'/tensorflow/tensorflow/stream_executor/cuda/cuda_stream.h'.\n\n____Building complete.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n\n____Elapsed time: 998.708s, Critical Path: 715.53s`\n```\n", "comments": ["This issue was originally filed against Bazel, but we think it's more likely to be an issue with Tensorflow. Here's the issue on the Bazel side: https://github.com/bazelbuild/bazel/issues/868\n\nIf it turns out to be an issue with Bazel, please reopen the Bazel one.\n"]}, {"number": 1027, "title": "Add Docs blurb to howtos.", "body": "also fixes redundant path elements in links.\n", "comments": ["merged.\n"]}, {"number": 1026, "title": "crosstool_wrapper_driver_is_not_gcc failed: error executing command", "body": "I'm trying to build the master branch, configured with cuda compute capability 3.0,  using the following command:\n\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone\n\nOn Ubuntu 12.04 using bazel 0.1.4 and gcc 4.8.1 I get the following error:\n\nERROR: /opt/tensorflow/tensorflow/core/BUILD:416:1: C++ compilation of rule '//tensorflow/core:kernel_lib' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/#####/.cache/bazel/_bazel_#####/fbc06f9baef46cade6e35d9e4137e37c/tensorflow && \\\n  exec env - \\\n    PATH=/usr/local/cuda/bin:/opt/ros/fuerte/bin:/opt/lfd/scripts:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/opt/gurobi650/linux64/bin:/home/#####/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-fa22401ededc -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-fa22401ededc -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.d -c tensorflow/core/kernels/conv_grad_ops.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/#####/.cache/bazel/_bazel_#####/fbc06f9baef46cade6e35d9e4137e37c/tensorflow && \\\n  exec env - \\\n    PATH=/usr/local/cuda/bin:/opt/ros/fuerte/bin:/opt/lfd/scripts:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/opt/gurobi650/linux64/bin:/home/#####/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-fa22401ededc -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-fa22401ededc -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.d -c tensorflow/core/kernels/conv_grad_ops.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/conv_grad_ops.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n", "comments": ["Issue was fixed by upgrading to gcc/g++ 4.9.2.\nDidn't need to use the --spawn_strategy=standalone flag anymore.\n\nCompiled with:\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n", "Yup, we set --spawn_strategy=standalone by default now, so it's not necessary.  Glad you could fix it!\n"]}, {"number": 1025, "title": "More explicit directory structure instructions", "body": "More documentation about directory structure so I can point at it.\n", "comments": ["merged.\n"]}, {"number": 1024, "title": "Rename the parameter of wrapper function consistently with its docs and the original one.", "body": "This fixes the mismatch between parameter variable `dev` and\nits documentation `device_name_or_function`.\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "Hi, @martinwicke . \nPlease let me know if I need to do something for this. :)\n", "Rebased to the master.\n", "Thank you for merging, @keveman !\n"]}, {"number": 1023, "title": "Fix for python3 syntax incompatibility.", "body": "Encountered a syntax error while following \"Getting started\" tutorial with python3:\n\n$ python convolutional.py \nTraceback (most recent call last):\n  File \"convolutional.py\", line 31, in <module>\n    import tensorflow.python.platform\n  File \"/Users/povi/Library/Developer/virtual_envs/py3/lib/python3.5/site-packages/tensorflow/**init**.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/Users/povi/Library/Developer/virtual_envs/py3/lib/python3.5/site-packages/tensorflow/python/**init**.py\", line 73, in <module>\n    from tensorflow.python.training import training as train\n  File \"/Users/povi/Library/Developer/virtual_envs/py3/lib/python3.5/site-packages/tensorflow/python/training/training.py\", line 149, in <module>\n    from tensorflow.python.training.saver import generate_checkpoint_state_proto\n  File \"/Users/povi/Library/Developer/virtual_envs/py3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1077\n    except Exception, e:  # pylint: disable=broad-except\n                    ^\nSyntaxError: invalid syntax\n\nFixed it, so it would be python 2 & 3 compatible.\n", "comments": ["Can one of the admins verify this patch?\n", "LGTM. I was about to make the same change to fix a bunch of test failures under Python3.\n", "Jenkins, test this please.\n", "Test failure is not this PRs fault.\n", "merged.\n"]}, {"number": 1022, "title": "Python3 install-test in pip.sh", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Is this file already used in our tests, or just in the experimental ones?\n", "@martinwicke It is used in only some of the experimental builds right now. \n", "Then I'll save ourselves the testing. Merged.\n"]}, {"number": 1021, "title": "pre-trained inception v3 model should accept batches as well as singletons", "body": "At present, the inception v3 model seems to only accept size 1 for the batch size.\n", "comments": ["Inception-v3 may now run on batches of arbitrary size by using the newly released code here:\nhttps://github.com/tensorflow/models/tree/master/inception\n\nIn particular, one can adapt this script to accept arbitrary data sets:\nhttps://github.com/tensorflow/models/blob/master/inception/imagenet_eval.py\n", "The imagenet_eval file doesn't exist anymore?\n", "Hmm. Are you possibly not using the latest version of the repo? It seems to\nstill be there, no?\nhttps://github.com/tensorflow/models/blob/master/inception/inception/imagenet_eval.py\n\nOn Tue, Jun 21, 2016 at 2:53 AM, KernelSight notifications@github.com\nwrote:\n\n> The imagenet_eval file doesn't exist anymore?\n> \n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1021#issuecomment-227393472,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AMw95xcSo4WCY167uCkhDr1P0E-bjvVRks5qN7SjgaJpZM4HVrFR\n> .\n", "It is! Ah, in true inception style the new link is inside the inception folder, inside another inception folder. I just tried to find it by clicking on the above link. Thanks shlens.\n", "If I get this code right, the fix works for evaluation purposes only (i.e., computing top-k-error). Is there a way to extract the bottleneck vectors themselves (pool_3:0) in a batched fashion?\r\n\r\nCmp. this thread, for example: http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836\r\n\r\nI tried the solution proposed there (basically setting feed_dict={'ResizeBilinear:0':imgs}, where imgs is an array with, say, 10 stacked images) but it didn't work (\"Cannot feed value of shape (10, 299, 299, 3) for Tensor u'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'\"). I tested with tensorflow v0.10.0 and 0.11.0rc0, and the inception model downloaded from http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz.\r\n\r\nThanks in advance -", "Is there any solutions now? I am also looking for a way to extract the bottleneck output as pre-computing for transfer learning  @ulgus ", "The same problem @universewill @ulgus @shlens , is there any solutions? \r\nThank you!", "I (kind of) got it to work with inception_eval:\r\nhttps://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py \r\n\r\ninception_eval contains a method inference() which I used:\r\n```\r\nfrom inception import inception_model as inception\r\nimage = ... # some image\r\nsome_images = np.array(10 * [image]).astype('float32') # stack 10 images into an array\r\nimage_tensor = tf.constant(some_images)\r\ninception.inference(image_tensor, 1001) # works with 10 images\r\n```\r\n\r\nThe problem: Internally, this code sets up the whole flow graph *every time* you call inference(), i.e. there is no elegant placeholder mechanism. This leads to quite a bit of overhead: On my Tesla K40, it takes 7 seconds to setup the network and then 28 seconds for to bulk-process 500 images.\r\n\r\n \r\n\r\n\r\n", "@universewill @ulgus @shlens  is there a current solution to this ? we need a nightly batch processing of 100 of K of images. I have been considering using this method combining it with spark - http://go.databricks.com/hubfs/notebooks/TensorFlow/Distributed_processing_of_images_using_TensorFlow.html \r\n\r\nsc = pyspark Context", "The link provided by @shlens  is unreachable, I have found this \r\n https://github.com/tensorflow/models/blob/master/research/inception/inception/imagenet_eval.py\r\nBut it cannot do batch prediction via the pre-trained pb model in http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\r\n\r\nThe batch size has been fixed to 1 in this pb model, which cost too much unnecessary time on the inference stage if I need to predict lots of images.  \r\nCould you release the batch prediction version of this pb model?", "The code in the `inception` repository is deprecated. Please use the [slim](https://github.com/tensorflow/models/tree/master/research/slim) version of Inception-v3 instead."]}, {"number": 1020, "title": "Fixed tensorboard installation for pip", "body": "Broke when backend was moved to subfolder. See also #1000\n", "comments": ["Can one of the admins verify this patch?\n", "@danmane @martinwicke as of the current master, tensorboard installed through pip does not work since one of the files necessary (tensorboard_server.py) is missing. Also the issue mentioned in #1000 is solved in this PR. \n", "Looks good to me. :+1: Needs rebase though.\n", "Done\n", "@tensorflow-jenkins, test this please\n", "@vrv I don't think it's my PR that broke Linux GPU PIP... Or am I missing something?\n", "Tool failure.\nOn Tue, Feb 9, 2016 at 23:26 Panmari notifications@github.com wrote:\n\n> @vrv https://github.com/vrv I don't think it's my PR that broke Linux\n> GPU PIP... Or am I missing something?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/1020#issuecomment-182236312\n> .\n", "@panmari @martinwicke I'm working on fixing that sporadic pip install-test failure. I'll submit a PR for that today. \n", "merged. Thanks!\n", "@caisq cool! Would make life easier :D\n\nOn Wed, Feb 10, 2016, 16:59 caisq notifications@github.com wrote:\n\n> @panmari https://github.com/panmari @martinwicke\n> https://github.com/martinwicke I'm working on fixing that sporadic pip\n> install-test failure. I'll submit a PR for that today.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/1020#issuecomment-182444247\n> .\n"]}, {"number": 1019, "title": "Tensorflow Android not building for non-arm architectures.", "body": "I am trying to build the Tensorflow Android Camera Demo for x86 (or x86_64, or mips) architecture but bazel seems to be ignoring the --android_cpu flag and always builds for armeabi-v7a. \n\nI have also tried using the --fat_apk_cpu flag but I am getting compilation error about the: unrecognized command line option -mfpu=neon.\n", "comments": ["Hi, does it work if you remove the mfpu flag entirely? It significantly optimizes things on ARM, but since x86 doesn't support NEON I'm not surprised it breaks there.\n", "Hello! \n\nYes, it worked after removing the mfpu flag entirely for x86.\n\nFor arm64-v8a, we also had to remove the \"--icf=all\" inside the compile option \"-Wl,--icf=all\".\n\nFor mips we cannot still compile it. The problem seems to be different there, after removing the flag:\n undefined reference to `__atomic_fetch_add_8'\n\nFull output for mips compile, here:\n\n`INFO: Found 1 target...\nINFO: From Linking tensorflow/examples/android/libtensorflow_demo.so:\nbazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libandroid_tensorflow_lib.a(constant_folding.o): In function`tensorflow::(anonymous namespace)::ReplaceTensorWithConstant(tensorflow::Graph_, std::pair<tensorflow::Node_, int>, tensorflow::Tensor const&)':\nconstant_folding.cc:(.text._ZN10tensorflow12_GLOBAL__N_125ReplaceTensorWithConstantEPNS_5GraphESt4pairIPNS_4NodeEiERKNS_6TensorE+0x248): undefined reference to `__atomic_fetch_add_8'\nbazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libandroid_tensorflow_lib.a(resource_mgr.o): In function`tensorflow::ContainerInfo::Init(tensorflow::ResourceMgr*, tensorflow::NodeDef const&, bool)':\nresource_mgr.cc:(.text._ZN10tensorflow13ContainerInfo4InitEPNS_11ResourceMgrERKNS_7NodeDefEb+0x6a4): undefined reference to `__atomic_fetch_add_8'\ncollect2: error: ld returned 1 exit status\nERROR: /home/enrico/projects/tensorflow/tensorflow/examples/android/BUILD:10:1: Linking of rule '//tensorflow/examples/android:libtensorflow_demo.so' failed: mipsel-linux-android-gcc failed: error executing command \n  (cd /home/enrico/.cache/bazel/_bazel_enrico/a722061e4e14ee10d0cf53e5e96fcc56/tensorflow && \\\n  exec env - \\\n  external/androidndk/ndk/toolchains/mipsel-linux-android-4.9/prebuilt/linux-x86_64/bin/mipsel-linux-android-gcc -shared -o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.so -Wl,-whole-archive '-Wl,-rpath,$ORIGIN/../../../_solib_mips/_U_S_Stensorflow_Sexamples_Sandroid_Clibtensorflow_Udemo.so___Utensorflow_Sexamples_Sandroid' -Lbazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/_solib_mips/_U_S_Stensorflow_Sexamples_Sandroid_Clibtensorflow_Udemo.so___Utensorflow_Sexamples_Sandroid bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/imageutils_jni.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/jni_utils.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/rgb2yuv.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/tensorflow_jni.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/yuv2rgb.o -lpthread bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libandroid_tensorflow_lib.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/external/re2/libre2.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libprotos_all_cc.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/google/protobuf/libprotobuf.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/google/protobuf/libprotobuf_lite.a -Wl,-no-whole-archive external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/mips/libgnustl_static.a external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/mips/libsupc++.a -landroid -ljnigraphics -llog -lm -z defs -s -Wl,--exclude-libs,ALL -pthread -lpthread -static-libgcc -no-canonical-prefixes -Wl,-S '--sysroot=external/androidndk/ndk/platforms/android-21/arch-mips'): mipsel-linux-android-gcc failed: error executing command \n  (cd /home/enrico/.cache/bazel/_bazel_enrico/a722061e4e14ee10d0cf53e5e96fcc56/tensorflow && \\\n  exec env - \\\n  external/androidndk/ndk/toolchains/mipsel-linux-android-4.9/prebuilt/linux-x86_64/bin/mipsel-linux-android-gcc -shared -o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.so -Wl,-whole-archive '-Wl,-rpath,$ORIGIN/../../../_solib_mips/_U_S_Stensorflow_Sexamples_Sandroid_Clibtensorflow_Udemo.so___Utensorflow_Sexamples_Sandroid' -Lbazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/_solib_mips/_U_S_Stensorflow_Sexamples_Sandroid_Clibtensorflow_Udemo.so___Utensorflow_Sexamples_Sandroid bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/imageutils_jni.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/jni_utils.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/rgb2yuv.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/tensorflow_jni.o bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/yuv2rgb.o -lpthread bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libandroid_tensorflow_lib.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/external/re2/libre2.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/tensorflow/core/libprotos_all_cc.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/google/protobuf/libprotobuf.a bazel-out/android-mipsel-linux-android-4.9-gnu-libstdcpp-fastbuild/bin/google/protobuf/libprotobuf_lite.a -Wl,-no-whole-archive external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/mips/libgnustl_static.a external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/mips/libsupc++.a -landroid -ljnigraphics -llog -lm -z defs -s -Wl,--exclude-libs,ALL -pthread -lpthread -static-libgcc -no-canonical-prefixes -Wl,-S '--sysroot=external/androidndk/ndk/platforms/android-21/arch-mips').\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nINFO: Elapsed time: 2.265s, Critical Path: 1.92s`\n\nThank you.\n", "Ok, thanks for the info. I'll look into selecting build flags dynamically by platform for x86 and x86_64, but in the meantime it's fine to just remove the flags locally.\n\nTensorflow doesn't support MIPs currently. It looks like you're running into this: http://stackoverflow.com/questions/23065501/stdatomicunsiged-long-long-undefined-reference-to-atomic-fetch-add-8, where an 8-byte atomic add is simply not in the instruction set.\n", "Thank you for the feedback!\n", "Hi renats,\nPlease tell me the bazel commands that you used to build project for x86 and x86_64.\n", "@CalmWaves Hello! Just use:\nbazel build --fat_apk_cpu=x86,x86_x64 //tensorflow/examples/android:tensorflow_demo --verbose_failures\n", "Thank you very much for your reply. but there is very simple mistake.\nit should be like\n\nbazel build --fat_apk_cpu=x86,*_x86_64 *_//tensorflow/examples/android:tensorflow_demo --verbose_failures\n\nAgain I am so grateful for your generosity.\n"]}, {"number": 1018, "title": "Update os_setup.md with python3 documentation", "body": "Adds python3 documentation for: \"Test the TensorFlow installation\"\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@martinwicke made an update regarding your comment\n", "@martinwicke made an update regarding your comments (line breaks and backticks)\n", "Great, I'll squash an merge.\n", "Merged. Thanks!\n"]}, {"number": 1017, "title": "Patch 1", "body": "Adding python3 documentation to os_setup\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 1016, "title": "Incorrect RNN documentation", "body": "In the `tensorflow.python.ops.rnn.rnn` docs:\n\n>   Dynamic calculation returns, at time t:\n>     (t >= max(sequence_length)\n>         ? (zeros(output_shape), zeros(state_shape))\n>         : cell(input, state)\n\nBut if we look at `_dynamic_rnn_step`, what seems more reasonable is happening: the old state gets passed through unaltered if `t >= max(sequence_length)`.\n", "comments": ["okay I've just had the same problem haha so I'll continue here.\n\nIt seems the older version of tensorflow uses the unreasonable 0 everything approach in rnn.rnn\nbut the newer version of tensorflow uses the reasonable approach in _dynamic_rnn_step, and it has yet to go back to rnn to change its comments\n\nI've discovered this by trying to use the rnn and upgrading tensorflow from an old version to 0.6.0 just now.\n\nwould be nice to have an official clarification though\n", "Documentation should be fixed in the next sync\n"]}, {"number": 1015, "title": "Error when feeding model", "body": "Hi!\n\nI have downloaded and tried the [RNN tutorial](https://www.tensorflow.org/versions/0.6.0/tutorials/recurrent/index.html), it works great and I want to mod it to use it for another project.\n\nI have managed to write my own \"reader\" which uses my desired data and training the model seems to work, somewhat, I think. I feed my model the following dict:\n\n```\nfeed_dict = {m.input_data: x, m.targets: y, m.initial_state: state}\ncost, state, _ = session.run([m.cost, m.final_state, eval_op], feed_dict=feed_dict)\n```\n\nwhere `x` and `y` are the outputs from the `reader.iterator` method (the one I wrote, but nearly identical to the ptb_iterator used in the tutorial).\n\nI have also created a \"runner\" module which only imports a already trained model and runs it. But I am unable to run this code. I import a saved checkpoint into my session using the saver.restore method and that seems to work. But for the \"runner\" code I changed the `feed_dict` to be:\n`feed_dict = {m.input_data: input_id_list, m.initial_state: state}`\nsince I do not have an output this time, this is what I want the network to come up with.\nI also have this in the session.run:\n`session.run([m.cost, m.targets, eval_op], feed_dict=feed_dict)`\nSo this time (in contrast to the \"trainer\" code) I want to have the output of `m.targets`.\n\nBut when I try to run the \"runner\" code, I get this output:\n[log.txt](https://github.com/tensorflow/tensorflow/files/121384/log.txt)\n\nI have checked so the shape of `input_id_list` is (1, 4). That is also what is printed on the first line in the log file. And from the error message I can see that the Tensorflow placeholder is of shape (1,4) as well. All this makes sense since my config is set to `batch_size=1` and `num_steps=4`.\n\nIt also mentions that the input is of wrong type, not a int32, but it is the same input as when I run the \"trainer\" version of the code, so why would it work then but not now?\n\nThank you for all help and feedback! Let me know if I should submit more code/logs/etc!\n", "comments": ["@ebrevdo: Do you have any ideas here?\n", "Just saw this!  Without seeing the code that you wrote it's hard to see what the problem is.  Perhaps when you call .run or .eval you forget to pass the feed_dict to it?  Or perhaps when you call initialize_all_variables, sometimes that needs a feed_dict as well.  Are you sure the values you're feeding it are the correct numpy dtype?\n", "Closing for now due to lack of response.  Please reopen if it's still an issue!\n"]}, {"number": 1014, "title": "Fix merge gone wrong", "body": "My merge and @vrv's overlapped badly so we're left with a few duplicate imports.\n", "comments": ["Jenkins, test this please.\n"]}, {"number": 1013, "title": "Cannot import tensorflow in python", "body": "My env is like this:\n\npython 2.7.10\nI successfully installed tensorflow, using pip install \nhttps://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n\nthen I goes into `python`, \nthen `import tensorflow as tf`, \nI got this error:\n\n```\n>>> import tensorflow as tf\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\__init__.py\", line 4, in <module>\n    from tensorflow.python import *\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 22, in <module>\n    from tensorflow.python.client.client_lib import *\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\python\\client\\client_lib.py\", line 35, in <module>\n    from tensorflow.python.client.session import InteractiveSession\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 11, in <module>\n    from tensorflow.python import pywrap_tensorflow as tf_session\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"C:\\Users\\Or\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nImportError: No module named _pywrap_tensorflow\n```\n\nwould be greatful, thanks!\n", "comments": ["Answered this question on StackOverflow: http://stackoverflow.com/questions/35277339/cannot-import-tensorflow-in-python/35277461#35277461\n\nThe problem is that you are trying to install the Mac version of TensorFlow on Windows, and Windows is not supported. Follow #17 for progress in that regard. \n", "I'm using docker on my Mac and I get the same error. I'm trying to run tensorflow serving.\n\n```\nroot@9b82edf4d8e7:/serving# bazel-bin/tensorflow_serving/example/inception_export --checkpoint_dir=inception-v3 --export_dir=inception-export\nTraceback (most recent call last):\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tensorflow_serving/example/inception_export.py\", line 25, in <module>\n    import tensorflow as tf\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/external/org_tensorflow/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/external/org_tensorflow/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/external/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/external/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nImportError: No module named _pywrap_tensorflow\n```\n", "I have the same issue as killuabone as I am also using docker on OS X, running through the steps detailed here:\nhttps://tensorflow.github.io/serving/serving_inception.html\n", "I just had this problem and solved it, will post my results here for future readers.  \r\n\r\nThe problem (for me) was that my numpy was v1.08, whereas tensorflow wants v1.11.  Upgrading numpy on El Capitan may not be easy; I had to (a) reboot in recovery mode, (b) open terminal and type \"csrutil disable\", (c) boot normally and upgrade numpy (pip2 install --user --upgrade numpy), (d) reboot in recovery mode again, and (e) open terminal and type \"csrutil enable\". ", "For windows users install Visual C++ 2015 redistributable (x64 version) to be able to import tensorflow", "I got the same issue. Please, how can I solve it\r\n\r\n>>> import tensorflow as tf\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#1>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\r\n    from tensorflow.python import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/importlib/__init__.py\", line 37, in import_module\r\n    __import__(name)\r\nImportError: No module named _pywrap_tensorflow", "@alihusn Sorry to resurrect an old thread, but how did installing this fix your problem? I've installed Visual C++ 2015 Redistributable and have made sure that `MSVCP140.DLL` is in my path, yet I'm still getting the error.", "Well it worked for me :P", "After installation of Visual C++ 2015 Redistributable it worked for me", "I have the same error (ImportError: No module named _pywrap_tensorflow), my solution:\r\n\r\nIinstall cuDNN v5.1 for CUDA 8.0\r\nYou need to register a NVIDIA accelerated computing developer program, then from here (https://developer.nvidia.com/rdp/cudnn-download) download and unzip it.\r\nCopy all three subfolders and past it under CUDA folder, in my case is\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\r\n\r\nThen , you should be able to load tensorflow without any error\r\n\r\nNOTE, I use python 3.5", "+1 \r\n\r\n> After installation of Visual C++ 2015 Redistributable it worked for me", "any solution for MAC users ?", "Hi, I have laid down step-by-step instructions to successfully install Tensorflow on Windows.\r\n\r\nhttps://github.com/bhavsarpratik/install_Tensorflow_GPU_windows", "hello i have also same problem ....\r\n", "Also facing the issue tried to install the `Microsoft Visual C++ 2015 Redistributable` but when i checked the control panel it is already present there\r\n\r\n![image](https://user-images.githubusercontent.com/23471794/56352663-1e970a00-61e9-11e9-9445-f70503e850d5.png)\r\n\r\nAny Help plz ?"]}, {"number": 1012, "title": "pip installation failing on fedora", "body": "OS info:\n\n> uname -r\n> 4.3.4-300.fc23.x86_64\n> cat /etc/redhat-release \n> Fedora release 23 (Twenty Three)\n\nPython info:\npython3-numpy-1.9.2-2.fc23.x86_64\npython3-pip-7.1.0-1.fc23.noarch\npython-pip-7.1.0-1.fc23.noarch\nnumpy-1.9.2-2.fc23.x86_64\npython-2.7.10-8.fc23.x86_64\npython3-3.4.3-5.fc23.x86_64\n\nError:\nkmulvey@deepthought: ~ (master)> sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\nCollecting tensorflow==0.5.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n  Using cached https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\nRequirement already up-to-date: six>=1.10.0 in /usr/lib/python2.7/site-packages (from tensorflow==0.5.0)\nCollecting numpy>=1.9.2 (from tensorflow==0.5.0)\n  Using cached numpy-1.10.4.tar.gz\nInstalling collected packages: numpy, tensorflow\n  Found existing installation: numpy 1.9.2\n    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n    Uninstalling numpy-1.9.2:\n      Successfully uninstalled numpy-1.9.2\n  Running setup.py install for numpy ... error\n    Complete output from command /usr/bin/python -u -c \"import setuptools, tokenize;**file**='/tmp/pip-build-MVpgkh/numpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\\r\\n', '\\n'), **file**, 'exec'))\" install --record /tmp/pip-Tz7Dc0-record/install-record.txt --single-version-externally-managed --compile:\n    Running from numpy source directory.\n    blas_opt_info:\n    blas_mkl_info:\n      libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n      NOT AVAILABLE\n\n```\nopenblas_info:\n  libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n  NOT AVAILABLE\n\natlas_3_10_blas_threads_info:\nSetting PTATLAS=ATLAS\n  libraries tatlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n  NOT AVAILABLE\n\natlas_3_10_blas_info:\n  libraries satlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n  NOT AVAILABLE\n\natlas_blas_threads_info:\nSetting PTATLAS=ATLAS\n  libraries ptf77blas,ptcblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n  NOT AVAILABLE\n\natlas_blas_info:\n  libraries f77blas,cblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n  NOT AVAILABLE\n\n/tmp/pip-build-MVpgkh/numpy/numpy/distutils/system_info.py:1651: UserWarning:\n    Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n    Directories to search for the libraries can be specified in the\n    numpy/distutils/site.cfg file (section [atlas]) or by setting\n    the ATLAS environment variable.\n  warnings.warn(AtlasNotFoundError.__doc__)\nblas_info:\nC compiler: cc\n\ncreating /tmp/tmpQWMe8s/tmp\ncreating /tmp/tmpQWMe8s/tmp/tmpQWMe8s\ncompile options: '-I/usr/local/include -I/usr/include -c'\ncc: /tmp/tmpQWMe8s/source.c\n/tmp/tmpQWMe8s/source.c:1:19: fatal error: cblas.h: No such file or directory\ncompilation terminated.\n/tmp/tmpQWMe8s/source.c:1:19: fatal error: cblas.h: No such file or directory\ncompilation terminated.\n/tmp/pip-build-MVpgkh/numpy/numpy/distutils/system_info.py:635: UserWarning: Specified path  is invalid.\n  warnings.warn('Specified path %s is invalid.' % d)\n  FOUND:\n    libraries = ['blas']\n    library_dirs = ['/usr/lib64']\n\n  FOUND:\n    libraries = ['blas']\n    library_dirs = ['/usr/lib64']\n    define_macros = [('NO_ATLAS_INFO', 1)]\n\n/bin/sh: svnversion: command not found\nnon-existing path in 'numpy/distutils': 'site.cfg'\n/bin/sh: svnversion: command not found\nF2PY Version 2\nlapack_opt_info:\nopenblas_lapack_info:\n  libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n  NOT AVAILABLE\n\nlapack_mkl_info:\nmkl_info:\n  libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n  NOT AVAILABLE\n\n  NOT AVAILABLE\n\natlas_3_10_threads_info:\nSetting PTATLAS=ATLAS\n  libraries tatlas,tatlas not found in /usr/local/lib64\n  libraries lapack_atlas not found in /usr/local/lib64\n  libraries tatlas,tatlas not found in /usr/local/lib\n  libraries lapack_atlas not found in /usr/local/lib\n  libraries tatlas,tatlas not found in /usr/lib64/atlas\n  libraries lapack_atlas not found in /usr/lib64/atlas\n  libraries tatlas,tatlas not found in /usr/lib64/sse2\n  libraries lapack_atlas not found in /usr/lib64/sse2\n  libraries tatlas,tatlas not found in /usr/lib64\n  libraries lapack_atlas not found in /usr/lib64\n  libraries tatlas,tatlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries tatlas,tatlas not found in /usr/lib\n  libraries lapack_atlas not found in /usr/lib\n  libraries tatlas,tatlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries tatlas,tatlas not found in /usr/lib/\n  libraries lapack_atlas not found in /usr/lib/\n<class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n  NOT AVAILABLE\n\natlas_3_10_info:\n  libraries satlas,satlas not found in /usr/local/lib64\n  libraries lapack_atlas not found in /usr/local/lib64\n  libraries satlas,satlas not found in /usr/local/lib\n  libraries lapack_atlas not found in /usr/local/lib\n  libraries satlas,satlas not found in /usr/lib64/atlas\n  libraries lapack_atlas not found in /usr/lib64/atlas\n  libraries satlas,satlas not found in /usr/lib64/sse2\n  libraries lapack_atlas not found in /usr/lib64/sse2\n  libraries satlas,satlas not found in /usr/lib64\n  libraries lapack_atlas not found in /usr/lib64\n  libraries satlas,satlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries satlas,satlas not found in /usr/lib\n  libraries lapack_atlas not found in /usr/lib\n  libraries satlas,satlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries satlas,satlas not found in /usr/lib/\n  libraries lapack_atlas not found in /usr/lib/\n<class 'numpy.distutils.system_info.atlas_3_10_info'>\n  NOT AVAILABLE\n\natlas_threads_info:\nSetting PTATLAS=ATLAS\n  libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib64\n  libraries lapack_atlas not found in /usr/local/lib64\n  libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n  libraries lapack_atlas not found in /usr/local/lib\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/atlas\n  libraries lapack_atlas not found in /usr/lib64/atlas\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/sse2\n  libraries lapack_atlas not found in /usr/lib64/sse2\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib64\n  libraries lapack_atlas not found in /usr/lib64\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n  libraries lapack_atlas not found in /usr/lib\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/\n  libraries lapack_atlas not found in /usr/lib/\n<class 'numpy.distutils.system_info.atlas_threads_info'>\n  NOT AVAILABLE\n\natlas_info:\n  libraries f77blas,cblas,atlas not found in /usr/local/lib64\n  libraries lapack_atlas not found in /usr/local/lib64\n  libraries f77blas,cblas,atlas not found in /usr/local/lib\n  libraries lapack_atlas not found in /usr/local/lib\n  libraries f77blas,cblas,atlas not found in /usr/lib64/atlas\n  libraries lapack_atlas not found in /usr/lib64/atlas\n  libraries f77blas,cblas,atlas not found in /usr/lib64/sse2\n  libraries lapack_atlas not found in /usr/lib64/sse2\n  libraries f77blas,cblas,atlas not found in /usr/lib64\n  libraries lapack_atlas not found in /usr/lib64\n  libraries f77blas,cblas,atlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries f77blas,cblas,atlas not found in /usr/lib\n  libraries lapack_atlas not found in /usr/lib\n  libraries f77blas,cblas,atlas not found in /usr/lib/sse2\n  libraries lapack_atlas not found in /usr/lib/sse2\n  libraries f77blas,cblas,atlas not found in /usr/lib/\n  libraries lapack_atlas not found in /usr/lib/\n<class 'numpy.distutils.system_info.atlas_info'>\n  NOT AVAILABLE\n\n/tmp/pip-build-MVpgkh/numpy/numpy/distutils/system_info.py:1552: UserWarning:\n    Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n    Directories to search for the libraries can be specified in the\n    numpy/distutils/site.cfg file (section [atlas]) or by setting\n    the ATLAS environment variable.\n  warnings.warn(AtlasNotFoundError.__doc__)\nlapack_info:\n  FOUND:\n    libraries = ['lapack']\n    library_dirs = ['/usr/lib64']\n    language = f77\n\n  FOUND:\n    libraries = ['lapack', 'blas']\n    library_dirs = ['/usr/lib64']\n    define_macros = [('NO_ATLAS_INFO', 1)]\n    language = f77\n\n/usr/lib64/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'define_macros'\n  warnings.warn(msg)\nrunning install\nrunning build\nrunning config_cc\nunifing config_cc, config, build_clib, build_ext, build commands --compiler options\nrunning config_fc\nunifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\nrunning build_src\nbuild_src\nbuilding py_modules sources\ncreating build\ncreating build/src.linux-x86_64-2.7\ncreating build/src.linux-x86_64-2.7/numpy\ncreating build/src.linux-x86_64-2.7/numpy/distutils\nbuilding library \"npymath\" sources\ncustomize Gnu95FCompiler\nFound executable /usr/bin/gfortran\ncustomize Gnu95FCompiler\ncustomize Gnu95FCompiler using config\nC compiler: gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC\n\ncompile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python2.7 -c'\ngcc: _configtest.c\ngcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory\ngcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory\nfailure.\nremoving: _configtest.c _configtest.o\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/tmp/pip-build-MVpgkh/numpy/setup.py\", line 263, in <module>\n    setup_package()\n  File \"/tmp/pip-build-MVpgkh/numpy/setup.py\", line 255, in setup_package\n    setup(**metadata)\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/core.py\", line 169, in setup\n    return old_setup(**new_attr)\n  File \"/usr/lib64/python2.7/distutils/core.py\", line 151, in setup\n    dist.run_commands()\n  File \"/usr/lib64/python2.7/distutils/dist.py\", line 953, in run_commands\n    self.run_command(cmd)\n  File \"/usr/lib64/python2.7/distutils/dist.py\", line 972, in run_command\n    cmd_obj.run()\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/install.py\", line 62, in run\n    r = self.setuptools_run()\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/install.py\", line 36, in setuptools_run\n    return distutils_install.run(self)\n  File \"/usr/lib64/python2.7/distutils/command/install.py\", line 563, in run\n    self.run_command('build')\n  File \"/usr/lib64/python2.7/distutils/cmd.py\", line 326, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/lib64/python2.7/distutils/dist.py\", line 972, in run_command\n    cmd_obj.run()\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/build.py\", line 47, in run\n    old_build.run(self)\n  File \"/usr/lib64/python2.7/distutils/command/build.py\", line 127, in run\n    self.run_command(cmd_name)\n  File \"/usr/lib64/python2.7/distutils/cmd.py\", line 326, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/lib64/python2.7/distutils/dist.py\", line 972, in run_command\n    cmd_obj.run()\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/build_src.py\", line 153, in run\n    self.build_sources()\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources\n    self.build_library_sources(*libname_info)\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources\n    sources = self.generate_sources(sources, (lib_name, build_info))\n  File \"/tmp/pip-build-MVpgkh/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources\n    source = func(extension, build_dir)\n  File \"numpy/core/setup.py\", line 669, in get_mathlib_info\n    raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\nRuntimeError: Broken toolchain: cannot link a simple C program\n\n----------------------------------------\n```\n\n  Rolling back uninstall of numpy\nCommand \"/usr/bin/python -u -c \"import setuptools, tokenize;**file**='/tmp/pip-build-MVpgkh/numpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\\r\\n', '\\n'), **file**, 'exec'))\" install --record /tmp/pip-Tz7Dc0-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-MVpgkh/numpy\n", "comments": ["installing the distro version of numpy and removing the --upgrade from the above command fixed it\n"]}, {"number": 1011, "title": "Adding option for parallel build and serial tests", "body": "In ci_parameterized_build.sh, allow the option of parallel bazel build\nfollowed by serial (--jobs=1) bazel test.\n\nPotentially useful for limiting the build time for GPU builds, where the\ntests cannot run in parallel due to contention of GPU memory.\n", "comments": ["Can one of the admins verify this patch?\n", "@jendap I addressed your suggestion of keeping tensorflow/tools/ci_build/builds/configured untouched. The commits are squashed.\n", "merged\n"]}, {"number": 1010, "title": "fix minor filename typo", "body": "fix minor filename typo\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\nThanks for the project!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 1009, "title": "Example code for SummaryIterator using `tf.train.summary_iterator`.", "body": "I couldn't find [`tensorflow.summary_iterator`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/__init__.py#L92) but found it under [`tensorflow.train`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/training). I've updated the documentation to match [this test](https://github.com/tensorflow/tensorflow/blob/3b3b06278cc7971bb273563bc917a89d49d19e7d/tensorflow/python/training/summary_writer_test.py#L49) which also calls it by `tf.train.summary_iterator`.\n", "comments": ["Can one of the admins verify this patch?\n", "Merged. Thanks!\n"]}, {"number": 1008, "title": "Minor comment spelling fix.", "body": "Changing excerpt spelling in the `mnist_with_summaries.py` file.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1007, "title": "TensorFlow: fix word2vec timeouts on GPU by pinning model on CPU", "body": "Right now word2vec is not well supported on GPU (missing\nscatter sub, etc).  We can remove this limitation later when\nScatterSub and other ops are all available on GPU.\n\nWith this fix, the two word2vec tests now run in 5 seconds on a machine with GPU.\n", "comments": ["LGTM. The test failures you see on the PR gpu-pip build is due to a separate known issue. \n", "merged.\n"]}, {"number": 1006, "title": "Fixing more tests in Python3", "body": "Fixing more tests in Python3\n\n```\nThis CL fixes a number of (but not all) remaining Python3 test errors,\nincluding:\n//tensorflow/python:cwise_ops_test\n//tensorflow/python:gradients_test\n//tensorflow/python:topk_op_test\n//tensorflow/python:parsing_ops_test\n//tensorflow/python:learn_test\n\nIt also fixes a subset of the failing tests in:\n//tensorflow/python:function_test\n```\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n"]}, {"number": 1005, "title": "Add workspace root to the list of include path for swig compilation", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "@caisq, this looks like a test failure (this is an error you can apparently fix by reinstalling protobuf, according to #487). Is there an old protobuf version in the container?\n", "Merged.\n", "@jendap @martinwicke @vrv Regarding the test failure, I've seen this a number of times in the past couple of weeks. It looks sporadic. Oftentimes it goes away if you run exactly the same build again. The error message suggest that it has to do with protobuf version (see below). We should figure out the cause and solution to it because it'll most likely show up again and slow us down during release builds. \n\n> Traceback (most recent call last):\n>   File \"/tensorflow/pip_test/tests/in_topk_op_test.py\", line 21, in <module>\n>     import tensorflow.python.platform\n>   File \"/root/.local/lib/python2.7/site-packages/tensorflow/**init**.py\", line 23, in <module>\n>     from tensorflow.python import *\n>   File \"/root/.local/lib/python2.7/site-packages/tensorflow/python/**init**.py\", line 37, in <module>\n>     from tensorflow.core.framework.graph_pb2 import *\n>   File \"/root/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 10, in <module>\n>     from google.protobuf import descriptor_pb2\n>   File \"/root/.local/lib/python2.7/site-packages/google/protobuf/descriptor_pb2.py\", line 1533, in <module>\n>     **module** = 'google.protobuf.descriptor_pb2'\n>   File \"/root/.local/lib/python2.7/site-packages/google/protobuf/reflection.py\", line 123, in **new**\n>     new_class = superclass.**new**(cls, name, bases, dictionary)\n> TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases\n"]}, {"number": 1004, "title": "Strip out external/XXXX/ prefix from GetPath in cc_op_gen", "body": "GetPath was not stripping external/XXX/ which make C++ compilation\nof the generated header fail. All external repositories are added\nto the include path in C++ compilation by Bazel.\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "merged.\n"]}, {"number": 1003, "title": "Update README.md", "body": "![Final UI](http://coderbox.in/github/img/TensorFlowRM.png)\n", "comments": ["Can one of the admins verify this patch?\n", "Yes, please point the logo to https://www.tensorflow.org/images/tf_logo.png or https://www.tensorflow.org/images/tf_logo_transp.png\n", "Pretty though. Can the build status images be centered? Or is that too much to ask from Markdown?\n", "@martinwicke Thanks :blush:\n\nSorry we can't move build status table to center (as per current version of Markdown).\n\n# **Version: 1 (Pure Markdown)**\n\n![big left icon version](http://coderbox.in/github/img/TensorFlowBL.png)\n\n# **Version: 2 (Markdown+ html)**\n\n![big center icon version](http://coderbox.in/github/img/TensorFlowBC.png)\n", "I'd have to see the md to see which one is better. Some HTML annotations in MD are ok, but not all. Can I see how you did Version 2?\n", "Updated to version:2\n", "Did you as a centering div to the build status icons as well to make the image you sent? Actually, I would center the whole table (maybe just put it into the same div as the logo), and also center the build icon as you (I think) did when you made image version 2. \n\nThen it's good, and I'll merge it.\n", "@martinwicke Yes, :smile:  I have tried same but it seems that table formatting is overridden by Markdown. Included code for same.\n\n# **Expected UI (Image)**\n\n![Expected UI](http://coderbox.in/github/img/TensorFlowEXP1.png)\n\n# **Expected UI (Markup)**\n\n> **As per HTML code it should be centered but the table will be left aligned in markdown**\n> \n> ```\n> <div align=\"center\">\n>     <img src=\"https://www.tensorflow.org/images/tf_logo_transp.png\"><br><br>\n>   <table>\n>   <tr>\n>     <th>Linux CPU</th>\n>     <th>Linux GPU PIP</th>\n>     <th>Mac OS CPU</th>\n>     <th>Android </th>\n>   </tr>\n>   <tr>\n>     <td><a href='http://ci.tensorflow.org/job/tensorflow-master/'><img src='http://ci.tensorflow.org/job/tensorflow-master/badge/icon'></a></td>\n>     <td><a href='http://ci.tensorflow.org/job/tensorflow-master-gpu_pip/'><img src='http://ci.tensorflow.org/job/tensorflow-master-gpu_pip/badge/icon'></a></td>\n>     <td><a href='http://ci.tensorflow.org/job/tensorflow-master-mac/'><img src='http://ci.tensorflow.org/job/tensorflow-master-mac/badge/icon'></a></td>\n>     <td><a href='http://ci.tensorflow.org/job/tensorflow-master-android/'><img src='http://ci.tensorflow.org/job/tensorflow-master-android/badge/icon'></a></td>\n>   </tr>\n> </table>\n> ```\n\n</div>\n\n``````\n-----------------\n\n**TensorFlow** is an open source software library for numerical computation using\ndata flow graphs.  Nodes in the graph represent mathematical operations, while\nthe graph edges represent the multidimensional data arrays (tensors) that flow\nbetween them.  This flexible architecture lets you deploy computation to one\nor more CPUs or GPUs in a desktop, server, or mobile device without rewriting\ncode.  TensorFlow was originally developed by researchers and engineers\nworking on the Google Brain team within Google's Machine Intelligence research\norganization for the purposes of conducting machine learning and deep neural\nnetworks research.  The system is general enough to be applicable in a wide\nvariety of other domains, as well.\n\n**If you'd like to contribute to tensorflow, be sure to review the [contribution\nguidelines](CONTRIBUTING.md).**\n\n**We use [github issues](https://github.com/tensorflow/tensorflow/issues) for\ntracking requests and bugs, but please see\n[Community](tensorflow/g3doc/resources/index.md#community) for general questions\nand discussion.**\n\n## Installation\n*See [Download and Setup](tensorflow/g3doc/get_started/os_setup.md).*\n\n#### *Try your first TensorFlow program*\n```python\n$ python\n\n>>> import tensorflow as tf\n>>> hello = tf.constant('Hello, TensorFlow!')\n>>> sess = tf.Session()\n>>> sess.run(hello)\nHello, TensorFlow!\n>>> a = tf.constant(10)\n>>> b = tf.constant(32)\n>>> sess.run(a+b)\n42\n>>>\n``````\n\n##For more information\n- [TensorFlow website](http://tensorflow.org)\n- [TensorFlow whitepaper](http://download.tensorflow.org/paper/whitepaper2015.pdf)\n- [Tensorflow MOOC on Udacity](https://www.udacity.com/course/deep-learning--ud730)\n", "Have you tried putting the align=\"center\", or even a style attr on the td itself? It's quite possible that github's CSS sets the table to left-aligned. If that doesn't work, don't worry too much, I like the image and the centered table.\n", "@martinwicke alignment is not working with styles too, so by default the table will be aligned left as in image Version: 2 (Markdown+ html)\n", "merged, thank you!\n"]}, {"number": 1002, "title": "Set visibility of all targets to //visibilty:public", "body": "Bazel has a bug that prevent correct resolution of visibility labels\nand this change is using //visiblity:\\* targets to be able to\nload tensorflow as a remote repository.\n", "comments": ["Can one of the admins verify this patch?\n", "No need for that, sorry for the noise. Bazel has fixed that\n"]}, {"number": 1001, "title": "tf.image.resize_images() does not work with computed height and width", "body": "The wrapper function requires the new height and width arguments to be integers, for build-time checking, even though the underlying ops support Tensor-valued dimensions.\n", "comments": []}, {"number": 1000, "title": "tensorboard script fails due to failing import", "body": "It seems commit 8a59748c087a2fee535c0d5067dbabb01920e812 has done this move:  tensorflow/tensorboard/{ \u2192 backend}/tensorboard.py but the import in the tensorboard script that gets installed by pip uses the old location (I think that's defined by https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L46 ). Thus, invoking tensorboard fails with a failing import, but if you insert \"backend.\" into the script at the appropriate location it works again.\n", "comments": ["I fixed this bug in #1020, I think this issue can be closed @ptc-swalk \n", "Thanks!\n"]}]