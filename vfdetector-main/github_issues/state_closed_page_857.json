[{"number": 27804, "title": "SparkFun Edge Build Failure", "body": "On macOS 10.14.4 I'm following the directions at this location:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0\r\n\r\nEverything goes fine until step 4 when I try:\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin\r\n\r\nand get the error:\r\n\r\nIn file included from tensorflow/lite/experimental/micro/kernels/fully_connected.cc:16:0:\r\n./tensorflow/lite/kernels/internal/reference/fully_connected.h:18:10: fatal error: fixedpoint/fixedpoint.h: No such file or directory\r\n #include \"fixedpoint/fixedpoint.h\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n\r\nAny ideas why fixedpoint/fixedpoint.h is not found?", "comments": ["@denisbohm Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@muddham I believe all that information was in my original message above.  I'm using latest Tensorflow from GitHub.  Below is the full command and output when I try to make.  Is there some other information that is needed?\r\n\r\n$ gmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/main.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/main.o\r\nIn file included from ./tensorflow/lite/version.h:18:0,\r\n                 from tensorflow/lite/experimental/micro/examples/micro_speech/main.cc:26:\r\n./tensorflow/core/public/version.h:132:8: warning: type qualifiers ignored on function return type [-Wignored-qualifiers]\r\n extern const int tf_cxx11_abi_flag();\r\n        ^~~~~\r\n./tensorflow/core/public/version.h:134:8: warning: type qualifiers ignored on function return type [-Wignored-qualifiers]\r\n extern const int tf_monolithic_build();\r\n        ^~~~~\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/sparkfun_edge/audio_provider.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/sparkfun_edge/audio_provider.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/feature_provider.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/feature_provider.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/no_micro_features_data.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/no_micro_features_data.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/yes_micro_features_data.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/yes_micro_features_data.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/recognize_commands.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/recognize_commands.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/sparkfun_edge/command_responder.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/sparkfun_edge/command_responder.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/micro_features_generator.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/micro_features_generator.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/micro_model_settings.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/micro_model_settings.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/fft.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/fft.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/fft_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/fft_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/filterbank.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/filterbank.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/filterbank_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/filterbank_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/frontend.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/frontend.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/frontend_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/frontend_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_lut.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_lut.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_scale.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_scale.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_scale_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/log_scale_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/noise_reduction.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/noise_reduction.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/noise_reduction_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/noise_reduction_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/pcan_gain_control.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/pcan_gain_control.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/pcan_gain_control_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/pcan_gain_control_util.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/window.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/window.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/window_util.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/window_util.o\r\narm-none-eabi-gcc -DNDEBUG -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/tools/make/downloads/kissfft/kiss_fft.c -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/tools/make/downloads/kissfft/kiss_fft.o\r\ncc1: warning: command line option '-std=gnu++11' is valid for C++/ObjC++ but not for C\r\ncc1: warning: command line option '-fno-rtti' is valid for C++/ObjC++ but not for C\r\ncc1: warning: command line option '-fpermissive' is valid for C++/ObjC++ but not for C\r\narm-none-eabi-gcc -DNDEBUG -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/tools/make/downloads/kissfft/tools/kiss_fftr.c -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/tools/make/downloads/kissfft/tools/kiss_fftr.o\r\ncc1: warning: command line option '-std=gnu++11' is valid for C++/ObjC++ but not for C\r\ncc1: warning: command line option '-fno-rtti' is valid for C++/ObjC++ but not for C\r\ncc1: warning: command line option '-fpermissive' is valid for C++/ObjC++ but not for C\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/micro_interpreter.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/micro_interpreter.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/simple_tensor_allocator.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/simple_tensor_allocator.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/debug_log_numbers.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/debug_log_numbers.o\r\ntensorflow/lite/experimental/micro/debug_log_numbers.cc: In function 'char* {anonymous}::FastFloatToBufferLeft(float, char*)':\r\ntensorflow/lite/experimental/micro/debug_log_numbers.cc:117:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n   const uint32_t u = *reinterpret_cast<uint32_t*>(&f);\r\n                                                     ^\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/micro_mutable_op_resolver.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/micro_mutable_op_resolver.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/micro_error_reporter.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/micro_error_reporter.o\r\narm-none-eabi-g++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -ggdb -O3 -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/experimental/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/mcu/apollo3/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/boards/SparkFun_TensorFlow_Apollo3_BSP/bsp -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/devices/ -Itensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/utils/ -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/kernels/fully_connected.cc -o tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/kernels/fully_connected.o\r\nIn file included from tensorflow/lite/experimental/micro/kernels/fully_connected.cc:16:0:\r\n./tensorflow/lite/kernels/internal/reference/fully_connected.h:18:10: fatal error: fixedpoint/fixedpoint.h: No such file or directory\r\n #include \"fixedpoint/fixedpoint.h\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\ngmake: *** [tensorflow/lite/experimental/micro/tools/make/Makefile:205: tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/experimental/micro/kernels/fully_connected.o] Error 1", "Looks like https://github.com/google/gemmlowp/blob/master/fixedpoint/fixedpoint.h#L320 is the file not found.  Should this dependency be automatically downloaded by make or is there some step missing from the instructions at:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0", "Building tensor flow from source is described here:\r\n\r\nhttps://www.tensorflow.org/install/source\r\n\r\nand includes more steps that described here:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0\r\n\r\nSo it appears this is a documentation issue.  However, even that link doesn't describe steps to get gemmlowp installed...", "Hello,\r\n\r\nI have forced the download of the third party component to solve this issue by runnning the command:\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge clean_downloads", "Yeah. It sounds very likely to be a problem of the incomplete download. fixedpoint/fixedpoint.h is a file in gemmlowp which we downloaded the first time you run build.", "It looks like the original issue has been solved.  Please feel free to re-open in case this is not fully resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27804\">No</a>\n"]}, {"number": 27803, "title": "Fixes a bug in `TensorStridedSliceUpdate`", "body": "@alextp Fixes a bug introduced in #27327 .", "comments": ["@alextp Sorry I had to make an additional small change to pass the backwards compatibility test. This is necessary because I forgot to add the output definition in the op registration before.", "You shouldn't need to make the change to op_history.pbtxt because adding an output is backward-compatible and manual edits to that file are only required for non-backwards-compatible changes.\r\n\r\nThat said it's not harmful.", "> You shouldn't need to make the change to op_history.pbtxt because adding an output is backward-compatible and manual edits to that file are only required for non-backwards-compatible changes.\r\n\r\nThanks Alex! It's good to know that. The reason I actually did it is because this edit is technically not backwards-compatible as it changes the signature of the `TensorStridedSliceAssign` op (I had previously forgotten to declare that it has an output), thus resulting in a test failure.\r\n\r\n", "Adding an output to an op is a backwards-compatible change though as it does not change the behavior of existing graphdefs.", "I see. Shouldn't the backwards compatibility check test take that into account then? Because it was failing until I made that change to `op_history.pbtxt` which added the output declaration."]}, {"number": 27802, "title": "Autograph fails after restoring from the checkpoint", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n```bash\r\nconda install tensorflow-gpu==2.0-alpha\r\n```\r\n- Python version:\r\n3.7.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nnot relevent\r\n- GPU model and memory:\r\nnot relevent\r\n\r\n**Describe the current behavior**\r\nRunning the following code for the first time show no warning. However, running it the second time results in this Warning message:\r\n```\r\nW0412 15:23:38.694277 140471310108480 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fc1a2ba3908> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.W0412 15:23:38.697970 140471310108480 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fc1a00bfb38> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/t\r\nensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\r\n```\r\n**Describe the expected behavior**\r\nAutograph should works just find even after restoring from a checkpoint.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n\r\nnetwork = models.Sequential([layers.Dense(1, activation='relu')])\r\n\r\n\r\n@tf.function\r\ndef forward(batch):\r\n    network(batch)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    ckpt = tf.train.Checkpoint(model=network)\r\n    manager = tf.train.CheckpointManager(ckpt, '/tmp/ckpttest', max_to_keep=10)\r\n    if manager.latest_checkpoint:\r\n        print(f'Resume training using {manager.latest_checkpoint}')\r\n        ckpt.restore(manager.latest_checkpoint)\r\n\r\n    batch = tf.zeros((1, 1), dtype=tf.float32)\r\n    forward(batch)\r\n    manager.save()\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I could reproduce the issue with TF2.0.0-alpha0. Thanks!", "Thanks for reporting this bug! The error looks familiar, and might be fixed at head. I'll verify.", "Sorry for the delay. This is fixed in tf-nightly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27802\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27802\">No</a>\n"]}, {"number": 27801, "title": "Remove the debug changes", "body": "Undoes #27793 and #27797", "comments": []}, {"number": 27800, "title": "Add missing redirect", "body": "", "comments": ["I think I don't need this anymore, seems that builds are now progressing."]}, {"number": 27799, "title": "Added conditions in cases", "body": "There were some conditions missing in the test cases, I'm not really sure about this. So I'd like some help", "comments": ["Review pleasee @rthadur @gbaned @angersson ", "@kyscg , this is PR is similar to an old approved PR #25485.\r\n\r\nRegards\r\nAmit", "Closing as #25485 is approved. Thanks for the update @amitsrivastava78 "]}, {"number": 27798, "title": "lib_package: fix dylib symlinks on mac", "body": "Signed-off-by: Jason Zaman <jason@perfinion.com>", "comments": []}, {"number": 27797, "title": "Display bazel log file on trapped cleanup.", "body": "Follows from #27793, I should have `cat`'ed the file there", "comments": []}, {"number": 27796, "title": "shuffling of test_dataset is not explicitly done", "body": "**System information**\r\n- TensorFlow version:2.0 \r\n- Doc Link:https://www.tensorflow.org/alpha/tutorials/generative/pix2pix\r\n**Input Pipeline Cell**\r\n\r\n\r\n**Documentation/Code Issue:**\r\nCell has the following code:\r\n\r\n1. test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\r\n2. *#shuffling so that for every epoch a different image is generated*\r\n3. *#to predict and display the progress of our model.*\r\n4. train_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\n5. test_dataset = test_dataset.map(load_image_test)\r\n6. test_dataset = test_dataset.batch(1)\r\n\r\n\r\nFrom line no 4, it seems we are not shuffling the test_dataset.  Should it have been \r\n\"test_dataset = test_dataset.shuffle(BUFFER_SIZE)\" ?\r\n", "comments": ["Thanks for trying TF 2.0 alpha. We need not apply shuffle on test data (however you can choose to shuffle test data as well) since it does not affect learning weights. Shuffling training data is good practice in order to overcome learning weight biases."]}, {"number": 27795, "title": "Added name to parameters of roll function", "body": "Add name=None argument to roll function #27665 ", "comments": ["Reassigning to @alextp as this changes API", "Also note that #27075 is working on similar thing and does much more than just add an argument. Maybe unrelated, but thought of bringing that up", "The other PR doesn't actually add the name argument to roll though.\n\nOn Fri, Apr 12, 2019 at 10:51 AM Mihai Maruseac <notifications@github.com>\nwrote:\n\n> Also note that #27075\n> <https://github.com/tensorflow/tensorflow/pull/27075> is working on\n> similar thing and does much more than just add an argument. Maybe\n> unrelated, but thought of bringing that up\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27795#issuecomment-482663497>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxQbKIKbpzmdT2dl-GLBDvmo3ZLuNks5vgMe4gaJpZM4cslB1>\n> .\n>\n\n\n-- \n - Alex\n", "@mihaimaruseac , @alextp  I have added some minor changes, can you please review them and tell me the modifications I can make further?", "@alextp  am confused, how can  i proceed what file should I change to include name parameter", "@shashvatshahi1998 \r\nremove this line `.Input(\"name: N\")` from [manip_ops.cc](https://github.com/tensorflow/tensorflow/pull/27795/files/5ce3f026ee23c13c80e431ba9a59fcfa53cf29f1#diff-f509b8a3a44a5352c9ffa2410c27c678)\r\nafter that run \r\n`bazel run tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens=True` so that the definations of manip_ops gets updated in `tensorflow/tools/api/golden/v1/tensorflow.manip.pbtxt`", "@shashvatshahi1998 i tested your changes those are working.\r\n\r\n`g = tf.roll([1,2],0,0,\"hello\")`\r\n`g.name`\r\n`Out[0]: 'hello_1:0'`", "@alextp as told by  @Gurpreetsingh9465 changes are working. So whats the problem in the PR?", "https://github.com/tensorflow/tensorflow/pull/27795#issuecomment-483952002 and https://github.com/tensorflow/tensorflow/pull/27795#discussion_r276305537", "@mihaimaruseac , @alextp I have done the required changes.", "@mihaimaruseac  what are the reasons for failing of 4 checks?", "[Clicking on details gives you the test results](https://source.cloud.google.com/results/invocations/df00da25-5273-4f1a-9029-cace315507e4/targets/%2F%2Ftensorflow%2Ftools%2Fapi%2Ftests:api_compatibility_test/tests). In this case, you forgot to run the golden updates as mentioned in https://github.com/tensorflow/tensorflow/pull/27795#issuecomment-483952002\r\n\r\n    bazel run tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens=True", "@mihaimaruseac basically the problem I am facing is that my macbook in which bazel was available is not working properly for past 2-3 days . I have one more laptop with ubuntu 14.04 LTS but it is a 32 bit laptop and I guess it will not support bazel. So what can I do now ?", "@shashvatshahi1998 you can use collab and refer this notebook for command [notebook](https://colab.research.google.com/drive/1XASrkgwQp2fTQfm5F9TxHFKI8hg8WNvj) or you can install ubuntu 18.04 64 bit on a virtual machine or directly to your system.", "@Gurpreetsingh9465  ok I will try.", "@shashvatshahi1998 what's the status of this PR?", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27794, "title": "problem with hashes to install tensorflow", "body": "Has anyone had this problem when installing tensorflow? How did they solve it? Thank you\r\n\r\n\r\nTHESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n    tensorflow from https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp35-none-linux_armv7l.whl#sha256=6c00dd13db0791e83cb08d532f007cc7fd44c8d7b52662a4a0065ac4fe7ca18a:\r\n        Expected sha256 6c00dd13db0791e83cb08d532f007cc7fd44c8d7b52662a4a0065ac4fe7ca18a\r\n             Got        b3233a35689ec7246f10b55ba82e10a951f9e4ee6205cfb77d90a6fc7b959b76\r\n", "comments": ["Having the same problem here, not found a fix yet ", "@miguel1396 This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "@miguel1396 Could you try downloading tensorflow from [pypi.org](https://pypi.org/project/tensorflow/), [GitHub source](https://github.com/tensorflow/tensorflow) or [Google api](https://www.tensorflow.org/install/pip#package-location). *.whl files are available with the Googleapi site. Thanks!", "I had the same issue to install tf. But than run `pip3 install tensorflow` again and was able to install it without any errors.\r\n", "I ran into the same problem but running only `pip install tensorflow`  worked. I was trying to install on the raspberry pi", "I think it was resolved. I am closing the issue. Please open a new ticket if you see similar issue again. Thanks!", "I have the same issue...", "I was having this issue, I eventually downloaded the whl file with wget\r\n\r\n`wget https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp35-none-linux_armv7l.whl`\r\n\r\n I kept getting errors in the download, example shown below\r\n\r\n`Read error at byte 88145920/92452292 (A TLS packet with unexpected length was received.). Retrying.`\r\n\r\nEventually the file finished after throwing the above error a few times and I was able to install it locally using the command below\r\n\r\n`pip install tensorflow-1.13.1-cp35-none-linux_armv7l.whl`\r\n\r\nI also had the same problem with a few smaller packages but got those to work by trying again. I think this problem is caused by a less than idea network connection.", "tensorflow \"these packages do not match the hashes from the requirements file\"\r\n\r\nI just ran pip3 install tensorflow on a fresh new board and I get this error again now.... it's  August 2019", "One up! I got this error on both \u201dpip install tensorflow\u201d and \u201dpip3 install tensorflow\u201d", "Another One up! I also have the error with \"pip3 install tensorflow\"", "I get the same HASH problem 8th September 2019\r\n\r\n(cv2_env) pi@pi-hub:~$ pip3 install tensorflow\r\nLooking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\r\nCollecting tensorflow\r\n  Downloading https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp37-none-linux_armv7l.whl (93.2MB)\r\n    8% |???                             | 7.9MB 6.9kB/s eta 3:27:43\r\nTHESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n    tensorflow from https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp37-none-linux_armv7l.whl#sha256=25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1:\r\n        Expected sha256 25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1\r\n             Got        04e0bd34cbb02f1b9cbdc63d457d0308f1591e4f0b286b0aa2c22ac64cb83b72\r\n\r\nI will try the WGET apprach described above if I can figure out how to get the 2.0rc\r\n\r\nEDIT : Tried to install from WHL on Pi 4:\r\npip3 install tensorflow-1.14.0-cp34-none-linux_armv7l.whl\r\ntensorflow-1.14.0-cp34-none-linux_armv7l.whl is not a supported wheel on this platform.\r\n\r\nGuess I'm trying to use too many new things together (tf2rc and Pi with Buster)\r\n", "These seem to be issues associated with Pypi or the network between you and them (potential man in the middle changing the files is potential). Not a TensorFlow issue", "Same problem. Downloading with `wget` and checking with sha256sum confirms same hash as was previously \"expected\". So I feel safe and do what suggested above - manual install", "#13 22.05 ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n#13 22.05     tensorflow-gpu==1.15.* from https://files.pythonhosted.org/packages/32/d9/f977cb032856d7f65cc42541da1ff12dafc4ff35fddb819836cf5c4cab60/tensorflow_gpu-1.15.3-cp37-cp37m-manylinux2010_x86_64.whl#sha256=1fe69cc4c60f4cce9af9594bfc55970805a76c613b257ba2f7f1defc8d53b201 (from -r requirements-gpu.txt (line 17)):\r\n#13 22.05         Expected sha256 1fe69cc4c60f4cce9af9594bfc55970805a76c613b257ba2f7f1defc8d53b201\r\n#13 22.05              Got        a73c34b80b19f7905f54d787c877b738c670111fbdcdc86ec4a50821784fbcd8\r\n#13 22.05 \r\n#13 ERROR: executor failed running [/bin/bash -c python -m pip install --upgrade pip setuptools wheel && python -m pip install -r requirements-gpu.txt]: runc did not terminate sucessfully\r\n", "@maximveksler what is the contents of `requirements-gpu.txt`?\r\n\r\n```\r\n[tf] \u03bb sha256sum *\r\n1344a3541e19e5b5cfde1c7b71fb02cb2f593262841a0e064df033619137f609  tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nbd68d17b14c91f62c9dd031fe02f57cb9f4b4028aef6e83141885120b285fcdd  tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl\r\n1fe69cc4c60f4cce9af9594bfc55970805a76c613b257ba2f7f1defc8d53b201  tensorflow_gpu-1.15.3-cp37-cp37m-manylinux2010_x86_64.whl\r\n```\r\n\r\nThere is no `a73c34b80b19f7905f54d787c877b738c670111fbdcdc86ec4a50821784fbcd8` hash. Its only presence could be explained by someone tampering with the network. This is not a TF issue, it should not be reported here", "same problem now in tensorflow 2.3 ", "17:53:26  ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n17:53:26      tensorflow from https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl#sha256=5c9f9a36d5b4d0ceb67b985486fe4cc6999a96e2bf89f3ba82ffd8317e5efadd:\r\n17:53:26          Expected sha256 5c9f9a36d5b4d0ceb67b985486fe4cc6999a96e2bf89f3ba82ffd8317e5efadd\r\n17:53:26               Got        75b3e7adccf80b3e638be35a8b244a69a3d34089e4ade11c7551ab55d139dfd0", "The issue is not from TF or from PyPI. You either have a spotty internet connection, a bad package cache or someone mitm-ing.\r\n\r\nTF team cannot do anything.", "> The issue is not from TF or from PyPI. You either have a spotty internet connection, a bad package cache or someone mitm-ing.\r\n> \r\n> TF team cannot do anything.\r\n\r\nThis clearly makes sense, but the problem is it's occurring only with TF dependency (maybe) because of the large file size of the package. In our case it's happening on Github Actions hosted CI worker, so unless we assume MITM malice actions by a 3rd party player it could perhaps indicate a bug that reproduces when tf is involved. It's also not consistently failing, which makes it harder to catch for obvious reasons.", "We are aware of the huge size of the pip package. I will add this item to the tracker too to further motivate reduction of the pip's size.\r\n\r\nMeanwhile, I think using ` --no-cache-dir  ` during `pip install` might alleviate this issue, at the cost of longer time spent in downloading the dependency.", "> We are aware of the huge size of the pip package. I will add this item to the tracker too to further motivate reduction of the pip's size.\r\n> \r\n> Meanwhile, I think using `--no-cache-dir ` during `pip install` might alleviate this issue, at the cost of longer time spent in downloading the dependency.\r\n\r\nThis worked for me", "> Meanwhile, I think using `--no-cache-dir ` during `pip install` might alleviate this issue, at the cost of longer time spent in downloading the dependency.\r\n\r\nThis worked for me as well. \r\n"]}, {"number": 27793, "title": "Temporarily add debug options on bazel build", "body": "", "comments": []}, {"number": 27792, "title": "Text classification with movie reviews lacks examples of results at end", "body": "The \"[Text classification with movie reviews](https://www.tensorflow.org/tutorials/keras/basic_text_classification)\" :\r\n\r\ncould really do with some examples of correct / incorrect classification as you work through / at end. At present the dataset feels a bit like a black box, and a user doesn't really get a feel for the claimed 87% accuracy (c.f. the earlier image classification where we see samples of correct/incorrect labelling).\r\n\r\nAs example the sanity check found at end of this similar example: https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\r\nwith 5 most discriminating words for both positive and negative reviews would give more of a feel to the user on how the model was performing?", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27791, "title": "TFL Detect \"TFLite Demo has stopped.\" error using provided pets sample assets", "body": "**System information**\r\n- Linux Ubuntu 16.04 and / or ( Mint 18 ):\r\n- TensorFlow installed from binary:\r\n- TensorFlow version 1.12.0 ( Compiled without AVX ):\r\n- Python: 3.5.2 \r\n- Cuda: 9.0\r\n- Cudnn: 7.4\r\n- GPU: 1050ti\r\n- System: Dual  Xeon E5540 with 56GB Memory\r\n\r\nI am having an unique issue implementing a custom trained model into the Android Demo located here within the tensorflow source\r\n\r\n[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/android/app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/android/app)\r\n\r\nspecifically, i followed the tutorial located at\r\n\r\nhttps://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\r\n\r\nafter Android Studio is installed and configured, I clone a clean version of the tensorflow source, set up the Workspace and then run\r\n\r\n`bazel build -c opt --config=android_arm{,64} --cxxopt='--std=c++11' tensorflow/lite/examples/android:tflite_demo`\r\n\r\nThe build succeeds with a couple warnings, when pushed to my device ( Android Note 8 ) via\r\n\r\n`adb install -r tflite_demo.apk`\r\n\r\nAll three apps work great!.\r\n\r\nThe problem starts when I try to utilize the sample model and label file linked in the tensorflow tutorial on medium.com\r\n\r\n[https://storage.googleapis.com/download.tensorflow.org/models/tflite/pets_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip](https://storage.googleapis.com/download.tensorflow.org/models/tflite/pets_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip)\r\n\r\ni place both the detect.tflite and the pets_labels_list.txt in the following location\r\n\r\n`//tensorflow/lite/examples/android/app/src/main/assets`\r\n\r\nand change the following source files as instructed with the following changes\r\n\r\nBUILD file -> //tensorflow/lite/examples/android\r\n\r\n`\r\nassets = [        \"//tensorflow/lite/examples/android/app/src/main/assets:labels_mobilenet_quant_v1_224.txt\",\r\n        \"@tflite_mobilenet_quant//:mobilenet_v1_1.0_224_quant.tflite\",\r\n        \"@tflite_conv_actions_frozen//:conv_actions_frozen.tflite\",\r\n        \"//tensorflow/lite/examples/android/app/src/main/assets:conv_actions_labels.txt\",\r\n        \"@tflite_mobilenet_ssd//:mobilenet_ssd.tflite\",\r\n        \"//tensorflow/lite/examples/android/app/src/main/assets:detect.tflite\",\r\n        \"//tensorflow/lite/examples/android/app/src/main/assets:box_priors.txt\",\r\n        \"//tensorflow/lite/examples/android/app/src/main/assets:labels.txt\",\r\n    ],\r\n`\r\n\r\nDetectorActivity.java -> //tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo\r\n\r\n`\r\n  private static final int TF_OD_API_INPUT_SIZE = 300;\r\n  private static final boolean TF_OD_API_IS_QUANTIZED = true;\r\n  private static final String TF_OD_API_MODEL_FILE = \"detect.tflite\";\r\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/pets_labels_list.txt\";\r\n`\r\n\r\nOnce updated, everything recompiles with the same output as before and it installs just fin on the device. TFL Classify and TFL Speech work the same as before, but the TFL Detect presents me with a \"TFLite Demo has stopped.\" popup when ran. Using logcat, I was able to get the following stacktrace.\r\n\r\n`\r\n04-11 15:52:09.383 23876 23876 E tensorflow: DetectorActivity: Exception initializing classifier!\r\n\r\n...\r\n\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime: FATAL EXCEPTION: inference\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime: Process: org.tensorflow.lite.demo, PID: 23876\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime: java.lang.NullPointerException: Attempt to invoke interface method 'java.util.List org.tensorflow.demo.Classifier.recognizeImage(android.graphics.Bitmap)' on a null object reference\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime:        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:247)\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime:        at android.os.Handler.handleCallback(Handler.java:789)\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime:        at android.os.Handler.dispatchMessage(Handler.java:98)\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime:        at android.os.Looper.loop(Looper.java:164)\r\n04-11 15:52:09.712 23876 23893 E AndroidRuntime:        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n`\r\n\r\nWith the new error, I put the original files back and undid my changes to the source and recompiled a third time with every back to the way it was. I then installed that APK and the Detect demo was working again.\r\n\r\nI am at a loss on what to try next as exchanging the model with the other provided sample assets should work? I did try a custom trained model of my own and got the same stacktrace with my own model. I can provide info on those models if it help at all.\r\n\r\nThanks in advance!\r\n\r\n", "comments": ["@blakefox  please use the proper labels file name in declaration will resolve your problem\r\n\r\n`  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/pets_labels_list.txt\";`\r\n====> to ====>\r\n`  private static final String TF_OD_API_LABELS_FILE = \"pets_labels_list.txt\";`\r\n", "@blakefox - Were you able to resolve this issue ?", "Sorry I was out yesterday. I have not been able to resolve this issue as of  yet. I will try the fix Dayananda recommended above and report back shortly.", "A quick update,\r\n\r\nDayananda's fix did resolve the original issue of this ticket. Thank you very much for the advice.\r\n\r\nSadly the same crash now happens right as soon and the image feed starts. That being said, I think this new crash is due to my training data. If its not, I will report back with the new stack trace shortly.", "@Dayananda-V : Thank you for the support\r\n@blakefox : That's great. For now I am closing the issue since it is resolved. Thanks!"]}, {"number": 27790, "title": "google::protobuf::python::oneof_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 10.14.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: -\r\n- Python version:\r\n```\r\npython --version\r\nPython 3.6.5\r\n```\r\n- Installed using virtualenv? pip? conda?:\r\n```\r\npip --version\r\npip 19.0.3 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)\r\n- Bazel version (if compiling from source):\r\n```\r\n- GCC/Compiler version (if compiling from source):\r\n```\r\ngcc --version\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.1 (clang-1001.0.46.3)\r\nTarget: x86_64-apple-darwin18.2.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n`time bazel build tensorflow/python/tools:freeze_graph`\r\n\r\non commit \r\n\r\n```\r\ncommit d1db9860a24af2ce64626fe4c3bee69f83700afa (HEAD -> master, origin/master, origin/HEAD)\r\nAuthor: Ayush Dubey <ayushd@google.com>\r\nDate:   Fri Apr 12 07:53:06 2019 -0700\r\n```\r\n\r\nEnd of build log:\r\n\r\n```\r\n  \"__Py_NoneStruct\", referenced from:\r\n      google::protobuf::python::message_descriptor::CopyToProto(google::protobuf::python::PyBaseDescriptor*, _object*) in descriptor.o\r\n      google::protobuf::python::message_descriptor::GetContainingType(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetDefaultValue(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetMessageType(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetEnumType(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetContainingType(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetExtensionScope(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      ...\r\n  \"__Py_NotImplementedStruct\", referenced from:\r\n      google::protobuf::python::descriptor::RichCompare(google::protobuf::python::PyContainer*, _object*, int) in descriptor_containers.o\r\n      google::protobuf::python::extension_dict::RichCompare(google::protobuf::python::ExtensionDict*, _object*, int) in extension_dict.o\r\n      google::protobuf::python::cmessage::RichCompare(google::protobuf::python::CMessage*, _object*, int) in message.o\r\n      google::protobuf::python::repeated_composite_container::RichCompare(_object*, _object*, int) in repeated_composite_container.o\r\n      google::protobuf::python::repeated_scalar_container::RichCompare(_object*, _object*, int) in repeated_scalar_container.o\r\n  \"__Py_TrueStruct\", referenced from:\r\n      google::protobuf::python::message_descriptor::IsExtendable(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::message_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enum_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enumvalue_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::file_descriptor::GetHasOptions(google::protobuf::python::PyFileDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::oneof_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      ...\r\n  \"__Py_ZeroStruct\", referenced from:\r\n      google::protobuf::python::message_descriptor::IsExtendable(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::message_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enum_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enumvalue_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::file_descriptor::GetHasOptions(google::protobuf::python::PyFileDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::oneof_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      ...\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 703.629s, Critical Path: 91.08s\r\nINFO: 2309 processes: 2309 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@mrgloom Could you describe more details about the issue and its context? Were you able to build tensorflow and import it successfully? Little more description is required to understand the issue. Thanks!", "Which other details are needed?\r\n\r\nI tried to build again with fresh master:\r\ncommit 11d8edcb35bdd2589e577aa86c81857bc2e95c24\r\n\r\ngit pull\r\ntime bazel build tensorflow/python/tools:freeze_graph\r\n\r\n```\r\n      ...\r\n  \"__Py_NotImplementedStruct\", referenced from:\r\n      google::protobuf::python::descriptor::RichCompare(google::protobuf::python::PyContainer*, _object*, int) in descriptor_containers.o\r\n      google::protobuf::python::extension_dict::RichCompare(google::protobuf::python::ExtensionDict*, _object*, int) in extension_dict.o\r\n      google::protobuf::python::cmessage::RichCompare(google::protobuf::python::CMessage*, _object*, int) in message.o\r\n      google::protobuf::python::repeated_composite_container::RichCompare(_object*, _object*, int) in repeated_composite_container.o\r\n      google::protobuf::python::repeated_scalar_container::RichCompare(_object*, _object*, int) in repeated_scalar_container.o\r\n  \"__Py_TrueStruct\", referenced from:\r\n      google::protobuf::python::message_descriptor::IsExtendable(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::message_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enum_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enumvalue_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::file_descriptor::GetHasOptions(google::protobuf::python::PyFileDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::oneof_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      ...\r\n  \"__Py_ZeroStruct\", referenced from:\r\n      google::protobuf::python::message_descriptor::IsExtendable(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::message_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::field_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enum_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::enumvalue_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::file_descriptor::GetHasOptions(google::protobuf::python::PyFileDescriptor*, void*) in descriptor.o\r\n      google::protobuf::python::oneof_descriptor::GetHasOptions(google::protobuf::python::PyBaseDescriptor*, void*) in descriptor.o\r\n      ...\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 280.460s, Critical Path: 64.32s\r\nINFO: 1328 processes: 1328 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\ntime bazel build tensorflow/python/tools:freeze_graph --verbose_failures\r\n\r\n```\r\n5 warnings generated.\r\nERROR: /private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/external/protobuf_archive/BUILD:670:1: Linking of rule '@protobuf_archive//:python/google/protobuf/internal/_api_implementation.so' failed (Exit 1): cc_wrapper.sh failed: error executing command\r\n  (cd /private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=10.14 \\\r\n    PATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin \\\r\n    XCODE_VERSION_OVERRIDE=10.2.0 \\\r\n  external/local_config_cc/cc_wrapper.sh -lc++ -fobjc-link-runtime -Wl,-S -shared -o bazel-out/host/bin/external/protobuf_archive/python/google/protobuf/internal/_api_implementation.so -Wl,-force_load,bazel-out/host/bin/external/protobuf_archive/_objs/python/google/protobuf/internal/_api_implementation.so/api_implementation.o -headerpad_max_install_names -no-canonical-prefixes '-mmacosx-version-min=10.14')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nUndefined symbols for architecture x86_64:\r\n  \"_PyModule_AddIntConstant\", referenced from:\r\n      _init_api_implementation in api_implementation.o\r\n  \"_Py_InitModule4_64\", referenced from:\r\n      _init_api_implementation in api_implementation.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nINFO: Elapsed time: 2270.751s, Critical Path: 274.18s\r\nINFO: 1865 processes: 1865 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "Looks like initial errors are:\r\n\r\n`bazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.`\r\n\r\n`ERROR: /private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/external/protobuf_archive/BUILD:684:1: Linking of rule '@protobuf_archive//:python/google/protobuf/pyext/_message.so' failed (Exit 1)`\r\n\r\nSeems related to https://github.com/tensorflow/tensorflow/issues/20950\r\n\r\nbut I'm using Python 3.6.5\r\n\r\n```\r\nbrew info protobuf\r\nprotobuf: stable 3.7.1 (bottled), HEAD\r\nProtocol buffers (Google's data interchange format)\r\nhttps://github.com/protocolbuffers/protobuf/\r\n/usr/local/Cellar/protobuf/3.6.1 (352 files, 18.8MB) *\r\n  Built from source on 2018-11-20 at 15:44:44\r\nFrom: https://github.com/Homebrew/homebrew-core/blob/master/Formula/protobuf.rb\r\n==> Dependencies\r\nBuild: autoconf \u2714, automake \u2714, libtool \u2714\r\nRequired: python \u2718, python@2 \u2718\r\n==> Options\r\n--HEAD\r\n\tInstall HEAD version\r\n==> Analytics\r\ninstall: 40,585 (30 days), 99,395 (90 days), 347,964 (365 days)\r\ninstall_on_request: 18,887 (30 days), 47,911 (90 days), 166,570 (365 days)\r\nbuild_error: 0 (30 days)\r\n```", "brew upgrade protobuf\r\nbrew info protobuf\r\n```\r\nprotobuf: stable 3.7.1 (bottled), HEAD\r\nProtocol buffers (Google's data interchange format)\r\nhttps://github.com/protocolbuffers/protobuf/\r\n/usr/local/Cellar/protobuf/3.7.1 (374 files, 21.3MB) *\r\n  Poured from bottle on 2019-04-23 at 15:25:48\r\nFrom: https://github.com/Homebrew/homebrew-core/blob/master/Formula/protobuf.rb\r\n==> Dependencies\r\nBuild: autoconf \u2714, automake \u2714, libtool \u2714, python \u2718, python@2 \u2718\r\n==> Options\r\n--HEAD\r\n\tInstall HEAD version\r\n==> Analytics\r\ninstall: 40,585 (30 days), 99,395 (90 days), 347,964 (365 days)\r\ninstall_on_request: 18,887 (30 days), 47,911 (90 days), 166,570 (365 days)\r\nbuild_error: 0 (30 days)\r\n```\r\n\r\ngit pull\r\ncommit 1f15690966c31e10d28f4952c7d4345435c43557\r\ntime bazel build tensorflow/python/tools:freeze_graph\r\n\r\n```\r\nERROR: /private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/external/protobuf_archive/BUILD:670:1: Linking of rule '@protobuf_archive//:python/google/protobuf/internal/_api_implementation.so' failed (Exit 1)\r\nUndefined symbols for architecture x86_64:\r\n  \"_PyModule_AddIntConstant\", referenced from:\r\n      _init_api_implementation in api_implementation.o\r\n  \"_Py_InitModule4_64\", referenced from:\r\n      _init_api_implementation in api_implementation.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 23.953s, Critical Path: 9.87s\r\nINFO: 46 processes: 46 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "Seems works:\r\n\r\n```\r\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout f076a43591\r\nbazel build tensorflow/tools/graph_transforms:summarize_graph\r\nbazel build -c opt tensorflow/tools/benchmark:benchmark_model\r\nbazel build -c opt tensorflow/lite/tools/benchmark:benchmark_model\r\n```"]}, {"number": 27789, "title": "The text generation tutorial doesn't seem to be passing along hidden state while generating text", "body": "**System information**\r\n- TensorFlow version: `tensorflow-gpu==1.10.1`\r\n- Doc Link: https://www.tensorflow.org/tutorials/sequences/text_generation#the_prediction_loop\r\n\r\n**Describe the documentation issue**\r\nI followed the text generation tutorial, and trained my model until it achieved a cross entropy loss of ~0.5 after 30 epochs; however, the generated text was mostly garbage. Reading the code linked in the section above, I saw:\r\n\r\n```python\r\n      # We pass the predicted word as the next input to the model\r\n      # along with the previous hidden state\r\n      input_eval = tf.expand_dims([predicted_id], 0)\r\n```\r\n\r\nwhich doesn't make sense to me. The comment says we're passing along the hidden state (which maybe the model is doing for us?) but the only text that's passed along is the last predicted character. After modifying the text generation function to pass to the model last at most `seq_length` generated characters, the output text started to look like actual Shakespeare/English.\r\n\r\nMy question is: is the model supposed to implicitly propagate hidden state, (and I've done something wrong following the tutorial), or is the tutorial accidentally omitting the part where we pass along the last set of generated text?\r\n\r\n> __Note__: Since I'm running tensorflow 1.10, and the tutorial seems to require 1.13 I had to replace the loss function with `tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)`. I don't think that change is related, but is it possible that tf 1.10 doesn't propagate the hidden state in the model?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nI'm happy to contribute my code changes to the tutorial, but want to make sure I'm understanding what's going wrong first.\r\n", "comments": ["For running locally, tutorial requires TF >=1.11 You can also use google colab to execute this tutorial. It hosts TF 1.13.1 by default.", "Does this mean the behavior of \r\n\r\n```python\r\n      predictions = model(input_eval)\r\n```\r\n\r\nchanges between tensorflow 1.10 & 1.11? Namely, does the GRU cell not pass forward hidden state in tensorflow 1.10?", "The stateful RNN behavior hasn't been update/change for long time, the hidden state is attached to the model instance, and is just as initial state when the new input is coming. \r\n\r\nThe line of input_eval is just using the previous output and make it the new input. As long as the model.reset_state() is not called, the hidden state will always be attached to the model, and been updated when the calculation is performed. ", "Yeah, that's what I had assumed, which is why I was so surprised at how different the results were when explicitly passing past characters into the model vs. only passing the last generated character.  `model.reset_state()` is only called once before we start feeding the model any characters.\r\n\r\nTrained to a loss of ~0.5, and with a temperature of 1.0\r\n\r\nhere is what the code generates without any modifications: \r\n\r\n```\r\nROMEO:\r\nSIERING thed.\r\nForo yo an whizeve wick.\r\n\r\nCLo he ost.\r\nDUERESUSthoupinaio micore helell ghacheer ofismyo hin inghisicalir whice SI st thire aree f byondeminie, hindathe prd t'\r\nRDurrin ve if aft wea IORWhis dat, aile boomeceanant ighea bustad, che Katauind, d wendowhelld lde chiom dwotasis whench we he\r\n```\r\n\r\nhere is what the code generates with the modification described above:\r\n\r\n```\r\nROMEO:\r\nGood Paulina,\r\nWho hast deep a sinner to the crown?\r\n\r\nKING RICHARD III:\r\nNor newt before him, we have comes consorn.\r\n\r\nKING HENRY VI:\r\nThen know, I'll tell thee for thy sacred blood rich groat;\r\nAnd when thou fail'st--as God again; my brother's son\r\nIt rawn his convent and dispatch with him.\r\n```\r\n\r\nIs there any way I can inspect the models hidden state?", "Since the model is built with return_sequence=True, it should intake sequences and output sequences. So when you ask model to generate new test, the input should be previously generated words or sequences, not just the last char it previous generated.\r\n\r\nTo exam the hidden state of the model, specially for the GRU layer, you can get the state by gru_layer.states. ", "Also adding Mark who works on documentation.", "> Since the model is built with return_sequence=True, it should intake sequences and output sequences. So when you ask model to generate new test, the input should be previously generated words or sequences, not just the last char it previous generated.\r\n\r\nIf I remove `return_sequences=true` from the GRU layer, should the tutorial work as shown? (I'll try that right now).\r\n\r\n> To exam the hidden state of the model, specially for the GRU layer, you can get the state by gru_layer.states.\r\n\r\nSorry, I don't exactly follow, where is `gru_layer` defined?\r\n", "Removing `return_sequences=True` causes a dimension mismatch:\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\nembedding (Embedding)        (64, None, 256)           16640\r\n_________________________________________________________________\r\ncu_dnngru (CuDNNGRU)         (64, 1024)                3938304\r\n_________________________________________________________________\r\ndense (Dense)                (64, 65)                  66625\r\n=================================================================\r\nTotal params: 4,021,569\r\nTrainable params: 4,021,569\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/10\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"shakespeare.py\", line 88, in train\r\n    history = model.fit(dataset.repeat(), epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\", line 1348, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py\", line 1040, in fit_loop\r\n    do_validation=do_validation)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py\", line 284, in iterator_fit_loop\r\n    model, x, y, sample_weights=sample_weights, training=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py\", line 794, in _process_single_batch\r\n    training=training)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py\", line 155, in _model_loss\r\n    targets[i], outs[i], weights, mask=mask)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 437, in weighted\r\n    score_array = fn(y_true, y_pred)\r\n  File \"shakespeare.py\", line 70, in loss\r\n    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2053, in sparse_softmax_cross_entropy_with_logits\r\n    (labels_static_shape.ndims, logits.get_shape().ndims))\r\nValueError: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).\r\n```\r\n\r\nNote, I'm using sparse_softmax_cross_entropy_with_logits due to my TF version being 1.10", "The return_sequence is definitely needed, otherwise it will return the output with last timestep instead of all timesteps. \r\n\r\nFor gru_layer, you created it within the build_model, you can access the model.layers which should contain all the layers in the model, and gru layer should be one of them.", "This tutorial was rewritten from scratch for 2.0 and seems to train and generate text correctly.  I'm closing this, but please file a new issue if you see any other issue.  Thanks!"]}, {"number": 27788, "title": "Cant import tensorflow", "body": "**System information**\r\n- Windows 10\r\n- tensorflow-1.13.1\r\n- python 3.6.8\r\n- Installed using pip\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen i try \"import tensorflow as tf\" i get the error below\r\n\r\ninstalled python 3.6.8 then used pip install tensorflow which said \"Successfully installed numpy-1.16.2 tensorflow-1.13.1\"\r\n\r\n\r\n**Any other info / logs**\r\n\r\nPython 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import numpy as np\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["Are you installing tensorflow or tensorflow-gpu?", "normal tensorflow no gpu", "Have you install the Microsoft Visual C++ 2015 Redistributable Update 3.", "I have already installed Microsoft Visual C++ 2015  but still same error\r\n\r\n![Capture](https://user-images.githubusercontent.com/49115602/56052307-b2428380-5d6e-11e9-9b92-6bddd238a678.PNG)\r\n", "i installed it now and it still doesnt work", "@Jaeyxx Could you follow steps 3,4,5,8 and 9 [here](https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12) and let me know how it progresses. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}, {"number": 27787, "title": "Issue with neural network output", "body": "I'm trying to create a neural network which take as input a table with the format : [[9][5]] and which got 3 outputs but as output i got a table with this format : [[5][3]] and i don'y understand why\r\n\r\n\r\n**System information**\r\n- tensorflow 1.13\r\n\r\n\r\nHere my network class :\r\n\r\n\r\n```\r\nclass DQNetwork:\r\n    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\r\n        self.state_size = state_size\r\n        self.action_size = action_size\r\n        self.learning_rate = learning_rate\r\n        \r\n        with tf.variable_scope(name):\r\n            # We create the placeholders\r\n            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\r\n            # [None, 84, 84, 4]\r\n            self.inputs_ = tf.placeholder(tf.float32, shape=[state_size[1], state_size[0]], name=\"inputs\")\r\n            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\r\n            \r\n            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\r\n            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\r\n            \r\n\t\t\t\r\n            self.fc = tf.layers.dense(inputs = self.inputs_,\r\n                                      units = 50,\r\n\t\t\t\t\t\t\t\t\t  kernel_initializer=tf.contrib.layers.xavier_initializer(),\r\n                                      activation = tf.nn.elu)\r\n\t\t\t\r\n            \r\n            self.output = tf.layers.dense(inputs = self.fc, \r\n                                        units = self.action_size,\r\n\t\t\t\t\t\t\t\t\t\tkernel_initializer=tf.contrib.layers.xavier_initializer(),\r\n                                        activation=None)\r\n            \r\n\r\n  \r\n            # Q is our predicted Q value.\r\n            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\r\n            \r\n            # The loss is the difference between our predicted Q_values and the Q_target\r\n            # Sum(Qtarget - Q)^2\r\n            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\r\n            \r\n            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\r\n```\r\n\r\nHere a set of input i can give to my network :\r\n\r\n```\r\nstate = []\r\n\tstate.append([0,0,0,0,0,0,0,0,0])\r\n\tstate.append([0,1,0,0,0,0,0,0,0])\r\n\tstate.append([0,0,0,0,1,0,0,0,0])\r\n\tstate.append([0,0,1,0,0,1,0,0,0])\r\n\tstate.append([0,0,0,0,0,0,0,0,0])\r\n```\r\n\r\nthen state is a possible input\r\n\r\nAs output i expect something like : [[0.125, 0.56, 0.301]]\r\n\r\nBut i got something like :\r\n\r\n```\r\n[ [-0.06873338  0.12694651 -0.30928543]\r\n [-0.06873338  0.12694651 -0.30928543]\r\n [-0.06873338  0.12694651 -0.30928543]\r\n [-0.06873338  0.12694651 -0.30928543]\r\n [-0.06955577  0.12819782 -0.31083506]]\r\n```", "comments": ["I added a flatten layer trying to force the dimension of the inputs to be a 1 dimensional array like this :\r\n\r\n```\r\n# hidden layer\r\n            self.hidden = tf.layers.dense(inputs = self.inputs_,\r\n\t\t\t                              units = 50,\r\n\t\t\t                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\r\n\t\t\t\t\t\t\t\t\t\t  activation = tf.nn.elu)\r\n\t\t\t\t\t\t\t\t\t\t  \r\n\t\t    # flat the data in a one dimension array\r\n            self.flat = tf.layers.flatten(inputs = self.hidden)\r\n\t\t\t\t\t\t\t\t\t\t \r\n\t\t\t# output layer\r\n            self.output = tf.layers.dense(inputs = self.flat,\r\n\t\t\t                              units = self.action_size, \r\n\t\t\t\t\t\t\t\t\t\t  kernel_initializer=tf.contrib.layers.xavier_initializer())\r\n```\r\n\r\nChanged absolutely nothing .. i don't know what i missed", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing as it was a support question. Thanks!"]}, {"number": 27786, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version: 2.0.0 alpha0 \r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: pip install tensorflow-gpu==2.0.0-alpha0\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 9.0/ cuDNN = 7\r\n- GPU model and memory: Nvidia GTX 1050, 4GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**: import tensorflow as tf\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\__init__.py\", line 27, in <module>\r\n    from tensorflow._api.v2 import audio\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\_api\\v2\\audio\\__init__.py\", line 8, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\shikh\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n", "comments": ["You need to use CUDA10 instead of CUDA9.", "Can i have multiple CUDA Installations on my machine ? I'm using CUDA 9.0 with an older version of tensorflow-gpu. ", "Using TensorFlow backend.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-11-491f9b70df53> in <module>\r\n      1 import pandas as pd\r\n----> 2 from keras.models import Sequential\r\n      3 from keras.layers import Dense\r\n      4 import numpy as np\r\n      5 from sklearn.model_selection import train_test_split\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py in <module>\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py in <module>\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 \r\n      8 # Globally-importable utils.\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>\r\n      7 from six.moves import range\r\n      8 import numpy as np\r\n----> 9 from .. import backend as K\r\n     10 \r\n     11 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py in <module>\r\n     87 elif _BACKEND == 'tensorflow':\r\n     88     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 89     from .tensorflow_backend import *\r\n     90 else:\r\n     91     # Try and load external backend.\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>\r\n      3 from __future__ import print_function\r\n      4 \r\n----> 5 import tensorflow as tf\r\n      6 from tensorflow.python.framework import ops as tf_ops\r\n      7 from tensorflow.python.training import moving_averages\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 from tensorflow._api.v1 import app\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\admin\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\admin\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "> Can i have multiple CUDA Installations on my machine ? I'm using CUDA 9.0 with an older version of tensorflow-gpu.\r\nYes,you can.But this is not necessary.Tensorflow 1.13 has used CUDA10 by default.\r\n\r\n", "plz help me to solve this problem\r\n", "@shikharparikh  Were you able to install TF successfully?\r\n@Vini-S  Please post a [new issue](https://github.com/tensorflow/tensorflow/issues/new/choose) explaining your problem. Thanks!", "I was succesfully able to install tensorflow-gpu 2.0.0.\r\nHowever, i could not import tensorflow in Terminal or Atom IDE ", "Can you please paste the error stack here? ", "> I was succesfully able to install tensorflow-gpu 2.0.0.\r\n> However, i could not import tensorflow in Terminal or Atom IDE\r\n\r\nI think this is because you used anaconda.\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 27785, "title": "How to's fully_connected_reader.py raises an AttributeError", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Mac OSX\r\n- Mobile device: No\r\n- TensorFlow installed from (source or binary): pip installed\r\n- TensorFlow version: `tensorflow==1.12.0`\r\n- Python version: Python 2.7.16\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n`('v1.12.0-rc2-3-ga6d8ffae09', '1.12.0')`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running this how to script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py\r\n\r\nAn `AttributeError` is raised\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"fully_connected_reader.py\", line 218, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"fully_connected_reader.py\", line 186, in main\r\n    run_training()\r\n  File \"fully_connected_reader.py\", line 140, in run_training\r\n    train=True, batch_size=FLAGS.batch_size, num_epochs=FLAGS.num_epochs)\r\n  File \"fully_connected_reader.py\", line 129, in inputs\r\n    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\r\nAttributeError: 'module' object has no attribute 'v1'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nCode should run without error in the \"how to\"\r\n\r\n**Code to reproduce the issue**\r\n\r\nCall the Python file with `tf` installed\r\n\r\n```\r\npython fully_connected_reader.py\r\n```\r\n\r\n**To fix**\r\n\r\nTo fix this error, I changed `line 129` from:\r\n\r\n```\r\niterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\r\n```\r\n\r\nto:\r\n\r\n```\r\niterator = tf.data.Dataset.make_one_shot_iterator(dataset)\r\n```", "comments": ["The example has been updated to support latest version of TF. ```tf.compat.v1.data.make_one_shot_iterator``` is correct for 2.0 compatibility. The [master branch example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py) should pass in TF 1.13. You can also try [TF 1.12 branch example](https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py) for your case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27785\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27785\">No</a>\n"]}, {"number": 27784, "title": "BugFix for Losses with reduction None.", "body": "This is bug fix for issue #27190", "comments": ["@fchollet , can you please look into this PR and provide your feedback.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78 Thank you for the PR! The loss functions actually do not perform any reduction by default. The expectation is that the input passed to the functions will be atleast 2D. These functions return one loss value per sample as output. \r\n\r\nEg if y_true and y_pred have the shape (3, 3), return value will be of shape (3,). => we get one loss value per sample\r\nif y_true and y_pred have the shape (3, 2, 4), return value will be of shape (3, 2) => we get one loss value per sample, per timestep etc.\r\n\r\nSorry that the functions do not have any documentation about this currently. We are working on adding that, please feel free to contribute to the documentation if you are interested.", "@pavithrasv , thanks for the response i am closing this PR.Will wait for the documentation update.\r\n\r\nRegards\r\nAmit"]}, {"number": 27783, "title": "Porting the Pooling kernel to Tensorflow Lite Micro with MaxPool support", "body": "This PR ports the MaxPool-part of the pooling kernel from Tensorflow Lite to Tensorflow Lite Micro.", "comments": ["Hi Jens,\r\n\r\nI've added pooling.cc for avg_pool. Please merge. \r\n\r\nThanks.", "The force-push is due to rebasing PR onto master, and no code have been added.", "@jenselo can you please check build failures. Thanks !", "> @jenselo can you please check build failures. Thanks !\r\n\r\nYes, I'll take a look.", "It seems that the test case that fails is the testStableName in the //tensorflow/python:function_test tests (or function_test_gpu in the Linux GPU build).\r\n\r\nFor the Linux GPU build the batch_matmul_test in //tensorflow/python/compiler/tensorrt.\r\n\r\nI've also ran the function_test locally with the maxpool patches and didn't see the error.\r\n\r\nDo changes made in tensorflow/lite/experimental/micro have any impact to the tests in tensorflow/python?"]}, {"number": 27782, "title": "Finished Todo in file", "body": "Added tests for tensors, inputs, outputs, opcodes", "comments": ["Review pleasee @angersson @suharshs ", "@kyscg , this PR is similar to one of the old approved PR #25809 "]}, {"number": 27781, "title": "Fail to use tf.transpose() after tf.nn.embedding_lookup() and tf.layers.conv1d() while build a tflite file", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.3\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): 1.13.1\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n2019-04-12 16:14:22.935998: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 13 operators, 22 arrays (0 quantized)\r\n2019-04-12 16:14:22.936163: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 13 operators, 22 arrays (0 quantized)\r\n2019-04-12 16:14:22.939819: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 6 operators, 14 arrays (0 quantized)\r\n2019-04-12 16:14:22.939890: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 5 operators, 12 arrays (0 quantized)\r\n2019-04-12 16:14:22.939945: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 5 operators, 12 arrays (0 quantized)\r\n2019-04-12 16:14:22.939972: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1605] Check failed: axis < input_shape.dimensions_count() (76044600 vs. 4)\r\nAborted (core dumped)\r\n```\r\n# Copy and paste here\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`ipts = tf.placeholder(dtype=tf.int32, shape=(None, 50), name='x')`\r\n`embedding = tf.get_variable(name='embedding', shape=[3000, 256], initializer=initializer)`\r\n`res = tf.nn.embedding_lookup(params=embedding, ids=ipts)`\r\n`res = tf.layers.conv1d(ipts, 100, 1)`\r\n`res = tf.transpose(res, perm=[0, 2, 1])    # Here cause the BUG`\r\n`sess = tf.Session()`\r\n`sess.run(tf.global_variables_initializer())`\r\n`converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [ipts], [res])`\r\n`tflite_model = converter.convert()`\r\n`open('converted_model.tflite', 'wb').write(tflite_model)`\r\n", "comments": ["When I delete tf.transpose() function, the code runs well. Sometimes it also throws out this information: F tensorflow/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc:44] Check failed: new_major_index_ordering.size() == old_major_index_ordering.size() (2 vs. 3)\r\nI really confused. Do anyone met this error before? Thanks.", "When I delete tf.layers.conv1d() function or tf.nn.embedding_lookup() function, the code also runs well. When I delete one of tf.layers.conv1d(), tf.nn.embedding_lookup() and tf.transpose() function, it also runs well. Or even when I change the function order that put tf.transpose() in front of tf.layers.conv1d(), it also runs well. So it seems that I can't use codes as follow: tf.nn.embedding_lookup()->tf.layers.conv1d()->tf.transpose(). By the way, when I use tf.layers.dense() instead of tf.layers.conv1d(), the results are the same. Anyone can help? Thank you so much!", "I could convert the model with the following code:\r\n\r\ndef main(args):\r\n  ipts = tf.placeholder(dtype=tf.float32, shape=(None, 50, 50), name='x')\r\n  ids = tf.placeholder(dtype=tf.int32, shape=(None, 50), name='x')\r\n  embedding = tf.get_variable(name='embedding', shape=[3000, 256], initializer=tf.initializers.random_uniform)\r\n  res = tf.nn.embedding_lookup(params=embedding, ids=ids)\r\n  res = tf.layers.conv1d(ipts, 100, 1)\r\n  res = tf.transpose(res, perm=[0, 2, 1]) # Here cause the BUG\r\n  sess = tf.Session()\r\n  sess.run(tf.global_variables_initializer())\r\n  converter = tf.lite.TFLiteConverter.from_session(sess, [ipts], [res])\r\n  tflite_model = converter.convert()\r\n  open('/tmp/converted_model.tflite', 'wb').write(tflite_model)\r\n\r\nif __name__ == '__main__':\r\n  app.run(main)\r\n\r\nProbably sync to latest tf-nightly and try?", "> I could convert the model with the following code:\r\n> \r\n> def main(args):\r\n> ipts = tf.placeholder(dtype=tf.float32, shape=(None, 50, 50), name='x')\r\n> ids = tf.placeholder(dtype=tf.int32, shape=(None, 50), name='x')\r\n> embedding = tf.get_variable(name='embedding', shape=[3000, 256], initializer=tf.initializers.random_uniform)\r\n> res = tf.nn.embedding_lookup(params=embedding, ids=ids)\r\n> res = tf.layers.conv1d(ipts, 100, 1)\r\n> res = tf.transpose(res, perm=[0, 2, 1]) # Here cause the BUG\r\n> sess = tf.Session()\r\n> sess.run(tf.global_variables_initializer())\r\n> converter = tf.lite.TFLiteConverter.from_session(sess, [ipts], [res])\r\n> tflite_model = converter.convert()\r\n> open('/tmp/converted_model.tflite', 'wb').write(tflite_model)\r\n> \r\n> if **name** == '**main**':\r\n> app.run(main)\r\n> \r\n> Probably sync to latest tf-nightly and try?\r\n\r\nThank you for your answer and sorry for replying lately, but when I try your code after update tensorflow to 1.14.0.dev2019042301, it also doesn't work. Do I miss some important information? Or can you please show me your environment? By the way, I update tf-nightly by pip, and the BUG shows as: 2019-04-25 15:07:37.018200: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1813] Check failed: axis < input_shape.dimensions_count() (84489656 vs. 4)", "I can reproduce it under tf-nightly now. But with a simpler code:\r\n\r\n```\r\ndef func():\r\n  ipts = tf.placeholder(dtype=tf.float32, shape=(None, 50, 50), name='x')\r\n  y = tf.layers.conv1d(ipts, filters=2, kernel_size=1)\r\n  res = tf.transpose(y, perm=[0,2,1]) # Here cause the BUG\r\n  sess = tf.Session()\r\n  sess.run(tf.global_variables_initializer())\r\n\r\n  converter = tf.lite.TFLiteConverter.from_session(sess, [ipts], [res])\r\n  tflite_model = converter.convert()\r\n\r\nfunc()\r\n```\r\n\r\nAlso found some interesting things to bypass this error:\r\n1) Change the 1st dim of ipts to something > 1.  or\r\n2) use only one filter in conv1d. or\r\n3) use another perm=[1,0,2]\r\n\r\nEither of these could eliminate the error. Please stay tuned a bit as I continue to investigate the issue. Thanks.\r\n", "I met the same problem @haozha111 . \r\nHope you can fix this bug, thank you.", "Any update here? I've also hit this same issue", "> Any update here? I've also hit this same issue\r\n\r\nI tried tf nightly version 20190611, still doesn't work.", "Is there any connection between this issue and following one?\r\nhttps://github.com/tensorflow/tensorflow/issues/27640", "> I can reproduce it under tf-nightly now. But with a simpler code:\r\n> \r\n> ```\r\n> def func():\r\n>   ipts = tf.placeholder(dtype=tf.float32, shape=(None, 50, 50), name='x')\r\n>   y = tf.layers.conv1d(ipts, filters=2, kernel_size=1)\r\n>   res = tf.transpose(y, perm=[0,2,1]) # Here cause the BUG\r\n>   sess = tf.Session()\r\n>   sess.run(tf.global_variables_initializer())\r\n> \r\n>   converter = tf.lite.TFLiteConverter.from_session(sess, [ipts], [res])\r\n>   tflite_model = converter.convert()\r\n> \r\n> func()\r\n> ```\r\n> \r\n> Also found some interesting things to bypass this error:\r\n> \r\n> 1. Change the 1st dim of ipts to something > 1.  or\r\n> 2. use only one filter in conv1d. or\r\n> 3. use another perm=[1,0,2]\r\n> \r\n> Either of these could eliminate the error. Please stay tuned a bit as I continue to investigate the issue. Thanks.\r\n\r\nI tried to follow the converting process with --dump_graphviz_dir and --dump_graphviz_video option in tflite_convert.\r\n\r\nI think the error occurred in the following part:\r\ntensorflow/tensorflow/lite/toco/graph_transformations/reorder_reshape_transpose.cc\r\n\r\nThe tflite_convert computing the 'new_perm' using the function,\r\n```\r\nconst std::vector<int> new_perm =\r\n      ComputeNewPerm(input_dims, intermediate_dims, transpose_op->perm);\r\n```\r\n, with the following inputs:\r\ninput_dims = [1,1,50,2]\r\nintermediate_dims= [1,50,2]\r\ntranspose_op->perm = [0,2,1]\r\n\r\nI think the function 'ComputeNewPerm' should return 'new_perm' as,\r\nnew_perm = [3, 2, 0, 1]\r\n, however when I checked the dot file, it seems it returned\r\nnew_perm = [66094776, 3, 0, 1].\r\n\r\n66094776 is a garbage value that changes at every run.\r\n\r\nI not sure whether the function actually returned incorrect values or not.\r\nPerhaps it returned the correct values but somehow changed afterwards.\r\n\r\nBut the problem is that the 'reorder_reshape_transpose' seems to created wrong node,\r\n  int32[4] = {66094776, 3, 0, 1}, \"transpose/perm\"\r\n, in the graph transformation.\r\n\r\nI hope there exist a solution for this problem.\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/456fbc0e498e3d10604973de9f46ca48d62267cc/tensorflow/lite/toco/graph_transformations/reorder_reshape_transpose.cc#L217", "I made a test code for the 'ComputeNewPerm' function to find the problem.\r\n\r\nI think the line with problem was\r\n```\r\nintermediate_to_input_indices_map[i] =\r\n          input_indices[intermediate_to_input_indices_map.size()];\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/456fbc0e498e3d10604973de9f46ca48d62267cc/tensorflow/lite/toco/graph_transformations/reorder_reshape_transpose.cc#L74\r\n\r\nThis gave me following output:\r\n\r\n> input_dims: 1 1 50 2\r\nintermediate_dims: 1 50 2\r\nperm: 0 2 1\r\ninput_indices: 2 3\r\nintermediate_to_input_indices_map: {2: 0}, {1: 3},\r\nnew_perm (0): 0 3\r\noutput: 0 3 0 1\r\n\r\nWhen I change the line with this,\r\n```\r\nintermediate_to_input_indices_map.insert(std::pair<int,int> ( i, input_indices[intermediate_to_input_indices_map.size()] )); // fix\r\n```\r\n, I got following output and I think this is the right version:\r\n\r\n> input_dims: 1 1 50 2\r\nintermediate_dims: 1 50 2\r\nperm: 0 2 1\r\ninput_indices: 2 3\r\nintermediate_to_input_indices_map: {2: 3}, {1: 2},\r\nnew_perm (0): 3 2\r\noutput: 3 2 0 1\r\n\r\nI downloaded the 'r1.14' code (https://github.com/tensorflow/tensorflow/tree/r1.14) and fixed the line of code. Then I build the source with bazel, and made package as (https://www.tensorflow.org/install/source). Then I installed the package with pip.\r\n\r\nIt solved the problem. The graph can be converted without error now.\r\n```\r\nipts = tf.placeholder(dtype=tf.float32, shape=(None, 50, 50), name='x')\r\ny = tf.layers.conv1d(ipts, filters=2, kernel_size=1)\r\nres = tf.transpose(y, perm=[0,2,1]) # OK, with the output shape [1x2x50].\r\n```", "This was my test code.\r\n```\r\n\r\n#include <iostream>\r\n#include <unordered_map>\r\n#include <vector>\r\n\r\nvoid show_vector(std::vector<int> vec){\r\n        for (int i; i < vec.size(); i++){\r\n                std::cout << vec[i] << \" \";\r\n        }\r\n        std::cout << \"\\n\";\r\n}\r\n\r\ntemplate<typename K, typename V>\r\nvoid print_map(std::unordered_map<K,V> const &m)\r\n{\r\n    for (auto const& pair: m) {\r\n        std::cout << \"{\" << pair.first << \": \" << pair.second << \"}, \";\r\n    }\r\n    std::cout << \"\\n\";\r\n}\r\n\r\n\r\n// Computes a new permutation used to swap a reshape-transpose to a\r\n// transpose-reshape. In this case the permutation operates on the intermediate\r\n// shape.\r\nstd::vector<int> ComputeNewPerm(std::vector<int> input_dims,\r\n                                std::vector<int> intermediate_dims,\r\n                                std::vector<int> perm) {\r\n  // These are the major axis of the input.\r\n  std::vector<int> input_indices;\r\n  for (int i = 0; i < input_dims.size(); i++) {\r\n    if (input_dims[i] != 1) {\r\n      input_indices.push_back(i);\r\n    }\r\n  }\r\n  std::cout << \"input_indices: \";\r\n  show_vector(input_indices);\r\n\r\n  // This maps which indices of the input produced the intermediate indices for\r\n  // non-unary dimensions.\r\n  std::unordered_map<int, int> intermediate_to_input_indices_map;\r\n  for (int i = 0; i < intermediate_dims.size(); i++) {\r\n    if (intermediate_dims[i] != 1) {\r\n      //intermediate_to_input_indices_map[i] =\r\n      //    input_indices[intermediate_to_input_indices_map.size()];  // original\r\n\r\n      intermediate_to_input_indices_map.insert(std::pair<int,int> ( i, input_indices[intermediate_to_input_indices_map.size()] )); // fix\r\n\r\n\r\n    }\r\n  }\r\n  std::cout << \"intermediate_to_input_indices_map: \";\r\n  print_map(intermediate_to_input_indices_map);\r\n\r\n  // Translate the transpose permutation to a new permutation starting with the\r\n  // major indices.\r\n  std::vector<int> new_perm;\r\n  new_perm.reserve(input_dims.size());\r\n  for (int i = 0; i < perm.size(); i++) {\r\n    if (intermediate_dims[perm[i]] == 1) continue;\r\n\r\n    new_perm.push_back(intermediate_to_input_indices_map[perm[i]]);\r\n  }\r\n\r\n  std::cout << \"new_perm (0): \";\r\n  show_vector(new_perm);\r\n\r\n  // Fill the rest of the transpose in with the ones.\r\n  for (int index = 0; index < input_dims.size(); index++) {\r\n    if (input_dims[index] == 1) {\r\n      new_perm.push_back(index);\r\n    }\r\n  }\r\n\r\n  //CHECK_EQ(new_perm.size(), input_dims.size());\r\n  return new_perm;\r\n}\r\n\r\nint main() {\r\n  std::vector<int> input_dims{1,1,50,2};\r\n  std::vector<int> intermediate_dims{1,50,2};\r\n  std::vector<int> perm{0,2,1};\r\n\r\n\r\n  std::cout << \"input_dims: \";\r\n  show_vector(input_dims);\r\n\r\n  std::cout << \"intermediate_dims: \";\r\n  show_vector(intermediate_dims);\r\n\r\n  std::cout << \"perm: \";\r\n  show_vector(perm);\r\n\r\n  const std::vector<int> new_perm =\r\n      ComputeNewPerm(input_dims, intermediate_dims, perm);\r\n  std::cout << \"output: \" ;\r\n  show_vector(new_perm);\r\n}\r\n\r\n```", "I am using tf version 2.1.0. on Ubuntu 18.04, with the CUDA Version: 10.2 and Driver Version: 440.100. \r\n\r\nVery similar bug appeared. Right after the embedding layer, permutation: perm=[1,0,2] is failing.\r\n\r\nThe code that fails in 2.1.0 is along the following lines:\r\n\r\n```\r\nsze = 77275\r\nnegative_samples = tf.keras.Input(shape=(context_size, ), dtype=tf.int64, name='negative_samples')\r\nembedding = tf.keras.layers.Embedding(input_dim=sze,\r\n                                               output_dim=512,\r\n                                               embeddings_initializer='GlorotUniform', name='shared_embedding_layer')\r\n\r\nnegative_embeddings = embedding(negative_samples)\r\n\r\ntransposed_embeddings = tf.transpose(negative_embeddings, perm=[1,0,2], name='transpose6')\r\n```\r\n\r\nif you attempt to get `transposed_embeddings` out, I am getting an error.\r\n", "Update: I checked the tf version 2.2.0 and there the transpose seems to work fine.", "Hi @lost-libra!\r\nContrib has been removed from latest TF-2.0 version, Hence you need to modify code according to  TF 2.X versions.\r\n\r\nCould you please try on instructions from [Tflite documentation ](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) from  latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27781\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27781\">No</a>\n"]}, {"number": 27780, "title": "DepthwiseConv mixed precision train super slow(Caused byDepthwiseConv2dNativeBackpropFilter )", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MS Windows10 X64 1809 build 17763\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary(pip)\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:10.0/7.5.0.56\r\n- GPU model and memory:NVIDIA Geforce RTX2080TI 11GB\r\n\r\n**Describe the current behavior**\r\nI am trying to port mnasnet's TPU implementation to the GPU.It works fine when using FP32.But when using mixed precision training, the speed is very slow.By using the Profiler to track the training loop, I found that DepthwiseConv2dNativeBackpropFilter consumed too much time.I tried adjusting the loss_scale but it didn't work.I want to know if Depthwise convolution does not support backpropagation at half precision, or there are performance issues.\r\n![image](https://user-images.githubusercontent.com/40640909/56020277-59a4c380-5d39-11e9-9811-3166dfec6978.png)\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/rootkitchao/mnasnet_temp\r\n\r\npython mnasnet_main.py --data_dir=D:\\dataset\\imagenet_tfrecord\\ --model_dir=D:\\tf_project\\mnasnet\\  --model_name=mnasnet-a1 --use_bfloat16=True  --use_keras=False --mode=train --train_batch_size=96 --num_gpus=1 --train_steps=2335456 --steps_per_eval=33363\r\n\r\n(Temporary version.The code does not really use bfloat16, use float16 instead.)\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nN/A\r\n", "comments": ["I tried to upgrade the graphics driver and disabled the IOMMU of AMD ThreadRipper. It seems that it is useless.", "Apologies for the delay in response. Can you please provide a minimal code snippet to reproduce the issue? This can help us to reduce the troubleshooting time. Thanks!", "> Apologies for the delay in response. Can you please provide a minimal code snippet to reproduce the issue? This can help us to reduce the troubleshooting time. Thanks!\r\n\r\nThis is the code used to reproduce this issue:https://github.com/rootkitchao/mnasnet_temp.\r\nThis code is ported from [tensorflow/tpu](https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet).The --use_bfloat16 flag does not mean using bfloat16, but float16.\r\nTo run this code, use the following command:\r\n```python mnasnet_main.py --data_dir=D:\\dataset\\imagenet_tfrecord\\ --model_dir=D:\\tf_project\\mnasnet\\model  --model_name=mnasnet-a1 --use_bfloat16=True  --use_keras=False --num_gpus=1 --mode=train_and_eval --train_batch_size=96 --train_steps=2335460 --steps_per_eval=66727 --iterations_per_loop=6673```\r\nDue to another known issue (https://github.com/tensorflow/tensorflow/issues/27392), it cannot be run on multiple GPUs.I think this issue is caused by DepthwiseConv2D. If you change the DepthwiseConv2D in the code to Conv2D, the training speed is OK.\r\n![image](https://user-images.githubusercontent.com/40640909/57042719-1b475800-6c98-11e9-91d6-a326ebcd47a7.png)\r\n\r\n", "Can you replicate this with a simpler example, ideally limited to a comparison of DepthwiseConv2D and Conv2D? Can you reproduce directly with the ops in question? It's hard for us to help debug with larger models/implementations, as so much is at play.", "> Can you replicate this with a simpler example, ideally limited to a comparison of DepthwiseConv2D and Conv2D? Can you reproduce directly with the ops in question? It's hard for us to help debug with larger models/implementations, as so much is at play.\r\n\r\n \r\nThanks for reply and apologize for the delayed response.I have rewritten a test code.But this code encountered a new problem in the current tensorflow version (1.13).\r\nIf I use tf.contrib.mixed_precision.LossScaleOptimizer, the training does not work properly and displays a warning when using depthwise converge `(WARNING:tensorflow: It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable) : 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.)`.But the same code works fine when using conv2d.If I don't use it, I get a NaN error when using mixed precision training.It seems impossible to avoid NaN errors by adjusting loss_scale.\r\nBut by testing with MNASNET code, I found that this seems to be related to the usage of video memory.If I reduce the batch_size from 96 to 64, the speed of mixing precision training and the speed of training with fp32 will be very close.Further reduce the batch_size, the speed of the mixing precision training will be slightly faster than the training using fp32.But when training with fp32, the speed of batch_size=96 is normal.\r\nSo I may not understand the reason for this problem correctly. It seems that the current method of mixing precision training will consume more gpu memory than using fp32.So when the batch_size is large, the gpu memory has overflowed, and some variables are stored in the cpu memory.Eventually, memory access operations across devices cause significant performance degradation.And using depthwise conv is more likely to cause this problem.\r\nI noticed that tensorflow recently added a new api [tf.train.experimental.enable_mixed_precision_graph_rewrite](https://github.com/tensorflow/tensorflow/blob/9ce7b4a0a0757eb4019fb373ab238e12addc29d5/tensorflow/python/training/experimental/mixed_precision.py).This seems to solve the current problem.I will try this method after the official release of tensorflow 1.14.\r\nThanks again to everyone who tried to help this issue.\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport functools\r\nfrom absl import app\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2\r\nfrom tensorflow.python.estimator import estimator\r\n\r\ndef conv_kernel_initializer(shape, dtype=None, partition_info=None):\r\n\r\n    del partition_info\r\n    kernel_height, kernel_width, _, out_filters = shape\r\n    fan_out = int(kernel_height * kernel_width * out_filters)\r\n    return tf.random_normal(\r\n        shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype)\r\ndef dense_kernel_initializer(shape, dtype=None, partition_info=None):\r\n\r\n    del partition_info\r\n    init_range = 1.0 / np.sqrt(shape[1])\r\n    return tf.random_uniform(shape, -init_range, init_range, dtype=dtype)\r\n\r\nclass FakeImageDataInput(object):\r\n\r\n    def __init__(self,image_size=64,dataset_size=128*64,use_float16=True):\r\n        self._image_size = image_size\r\n        self._use_float16 = use_float16\r\n        self._dataset_size = dataset_size\r\n\r\n    def set_shapes(self, batch_size, images, labels):\r\n        \"\"\"Statically set the batch_size dimension.\"\"\"\r\n        images.set_shape(images.get_shape().merge_with(\r\n            tf.TensorShape([batch_size, None, None, None])))\r\n        labels.set_shape(labels.get_shape().merge_with(\r\n            tf.TensorShape([batch_size])))\r\n        return images, labels\r\n\r\n    def _get_random_input(self, data):\r\n        return tf.zeros([self._image_size, self._image_size, 3], tf.float16\r\n                                if self._use_float16 else tf.float32)\r\n\r\n    def make_source_dataset(self):\r\n        \"\"\"See base class.\"\"\"\r\n        return tf.data.Dataset.range(self._dataset_size).repeat().map(self._get_random_input)\r\n    def dataset_parser(self, value):\r\n        #random = tf.random.uniform(shape=[1],dtype=tf.int32,minval=0,maxval=1000 - 1)\r\n        random = np.random.randint(0,999)\r\n        return value, tf.constant(int(random), tf.int32)\r\n\r\n    def input_fn(self, params):\r\n\r\n        batch_size = params['batch_size']\r\n\r\n        dataset = self.make_source_dataset()\r\n        \r\n        dataset = dataset.apply(\r\n            tf.contrib.data.map_and_batch(\r\n                self.dataset_parser, batch_size=batch_size,\r\n                num_parallel_batches=4, drop_remainder=True))\r\n\r\n        dataset = dataset.map(functools.partial(self.set_shapes, batch_size))\r\n        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\r\n        return dataset\r\n\r\n\r\nclass TestBlock(object):\r\n    \r\n    def __init__(self,\r\n                 kernel_size,\r\n                 input_filters,\r\n                 output_filters,\r\n                 stride=1,\r\n                 use_depthwise_conv=True):\r\n        self._use_depthwise_conv = use_depthwise_conv\r\n        self._kernel_size = kernel_size\r\n        self._input_filters = input_filters\r\n        self._output_filters = output_filters\r\n        self._stride = stride\r\n        self._build()\r\n    \r\n    def _build(self):\r\n        self._expand_conv = tf.layers.Conv2D(filters=self._input_filters * 6,\r\n                                             kernel_size=[1,1],\r\n                                             strides=[self._stride,self._stride],\r\n                                             kernel_initializer=conv_kernel_initializer,\r\n                                             padding='same',\r\n                                             use_bias=False)\r\n        self._bn0 = tf.layers.BatchNormalization(axis=-1,\r\n                                                 momentum=0.99,\r\n                                                 epsilon=1e-3,\r\n                                                 fused=True)\r\n        if self._use_depthwise_conv:\r\n            self._depthwise_conv = tf.keras.layers.DepthwiseConv2D(\r\n                kernel_size=self._kernel_size,\r\n                strides=[self._stride,self._stride],\r\n                depthwise_initializer=conv_kernel_initializer,\r\n                padding='same',\r\n                use_bias=False)\r\n        else:\r\n            self._depthwise_conv = tf.layers.Conv2D(\r\n                filters=self._input_filters * 6,\r\n                kernel_size=self._kernel_size,\r\n                strides=[self._stride,self._stride],\r\n                kernel_initializer=conv_kernel_initializer,\r\n                padding='same',\r\n                use_bias=False)\r\n        self._bn1 = tf.layers.BatchNormalization(axis=-1,\r\n                                                 momentum=0.99,\r\n                                                 epsilon=1e-3,\r\n                                                 fused=True)\r\n        self._project_conv = tf.layers.Conv2D(filters=self._output_filters,\r\n                                             kernel_size=[1,1],\r\n                                             strides=[self._stride,self._stride],\r\n                                             kernel_initializer=conv_kernel_initializer,\r\n                                             padding='same',\r\n                                             use_bias=False)\r\n        self._bn2 = tf.layers.BatchNormalization(axis=-1,\r\n                                                 momentum=0.99,\r\n                                                 epsilon=1e-3,\r\n                                                 fused=True)\r\n    def call(self,inputs,training=True):\r\n        x = tf.nn.relu(self._bn0(self._expand_conv(inputs), training=training))\r\n        x = tf.nn.relu(self._bn1(self._depthwise_conv(x), training=training))\r\n        x = self._bn2(self._project_conv(x), training=training)\r\n        return x\r\n\r\nclass TestModel(tf.keras.Model):\r\n    \r\n    def __init__(self,use_depthwise_conv=True):\r\n        super(TestModel,self).__init__()\r\n        self._use_depthwise_conv = use_depthwise_conv\r\n        self._build()\r\n    def _custom_dtype_getter(self, getter, name, shape=None, dtype=tf.float32,\r\n                           *args, **kwargs):\r\n        if dtype is tf.float16:\r\n            var = getter(name, shape, tf.float32, *args, **kwargs)\r\n            return tf.cast(var, dtype=dtype, name=name + '_cast')\r\n        else:\r\n            return getter(name, shape, dtype, *args, **kwargs)\r\n\r\n    def _model_variable_scope(self,scope):\r\n        return tf.variable_scope(scope,custom_getter=self._custom_dtype_getter)\r\n    \r\n    def _build(self):\r\n        self._conv_stem = tf.layers.Conv2D(filters=32,\r\n                                           kernel_size=[3,3],\r\n                                           strides=[2,2],\r\n                                           kernel_initializer=conv_kernel_initializer,\r\n                                           padding='same',\r\n                                           use_bias=False)\r\n        self._bn0 = tf.layers.BatchNormalization(axis=-1,\r\n                                                 momentum=0.99,\r\n                                                 epsilon=1e-3,\r\n                                                 fused=True)\r\n        self._conv_head = tf.layers.Conv2D(filters=1280,\r\n                                           kernel_size=[1,1],\r\n                                           strides=[1,1],\r\n                                           kernel_initializer=conv_kernel_initializer,\r\n                                           padding='same',\r\n                                           use_bias=False)\r\n        self._bn1 = tf.layers.BatchNormalization(axis=-1,\r\n                                                 momentum=0.99,\r\n                                                 epsilon=1e-3,\r\n                                                 fused=True)\r\n        self._avg_pooling = tf.keras.layers.GlobalAveragePooling2D(\r\n            data_format='channels_last')\r\n        self._fc = tf.layers.Dense(\r\n            1000,\r\n            kernel_initializer=dense_kernel_initializer)\r\n        self._blocks = []\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=32,output_filters=16,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=16,output_filters=24,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=24,output_filters=24,stride=2,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=24,output_filters=40,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=40,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=40,stride=2,use_depthwise_conv=self._use_depthwise_conv))\r\n        #self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=80,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        #self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=80,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=80,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=40,output_filters=80,stride=2,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=80,output_filters=112,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=112,output_filters=160,stride=2,use_depthwise_conv=self._use_depthwise_conv))\r\n        self._blocks.append(TestBlock(kernel_size=[3,3],input_filters=160,output_filters=320,stride=1,use_depthwise_conv=self._use_depthwise_conv))\r\n\r\n\r\n    def call(self,inputs,training=True):\r\n        with self._model_variable_scope('testmode'):\r\n            outputs = None\r\n            self.endpoints = {}\r\n            with tf.variable_scope('testmode_stem'):\r\n                outputs = tf.nn.relu(\r\n                    self._bn0(self._conv_stem(inputs), training=training))\r\n            self.endpoints['stem'] = outputs\r\n\r\n            for idx, block in enumerate(self._blocks):\r\n                with tf.variable_scope('mnas_blocks_%s' % idx):\r\n                    outputs = block.call(outputs, training=training)\r\n                    self.endpoints['block_%s' % idx] = outputs\r\n            self.endpoints['global_pool'] = outputs\r\n            with tf.variable_scope('testmode_head'):\r\n                outputs = tf.nn.relu(self._bn1(self._conv_head(outputs), training=training))\r\n                outputs = self._avg_pooling(outputs)\r\n                outputs = self._fc(outputs)\r\n                self.endpoints['head'] = outputs\r\n        return outputs,self.endpoints\r\n\r\n\r\ndef test_model_fn(features, labels, mode, params):\r\n    \r\n    model = TestModel(use_depthwise_conv=params['use_depthwise_conv'])\r\n    if params['use_float16']:\r\n        logits, _  = model(features,training=True)\r\n        logits = tf.cast(logits, tf.float32)\r\n    else:\r\n        logits, _  = model(features,training=True)\r\n    \r\n\r\n    weight_decay = 1e-5\r\n    one_hot_labels = tf.one_hot(labels, 1000)\r\n    cross_entropy = tf.losses.softmax_cross_entropy(\r\n        logits=logits,\r\n        onehot_labels=one_hot_labels,\r\n        label_smoothing=0.1)\r\n    loss = cross_entropy + weight_decay * tf.add_n([\r\n      tf.nn.l2_loss(tf.cast(v,tf.float32))\r\n      for v in tf.trainable_variables()\r\n      if 'batch_normalization' not in v.name\r\n    ])\r\n\r\n    learning_rate = 0.01\r\n    optimizer = tf.train.MomentumOptimizer(\r\n        learning_rate=learning_rate, momentum=0.9)\r\n\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    global_step = tf.train.get_global_step()\r\n    \r\n    if params['use_float16']:\r\n      \r\n      #loss_scale_manager = tf.contrib.mixed_precision.FixedLossScaleManager(4096)\r\n      #loss_scale_optimizer = tf.contrib.mixed_precision.LossScaleOptimizer(optimizer, loss_scale_manager)\r\n      #train_op = loss_scale_optimizer.minimize(loss,tf.train.get_global_step())\r\n      loss_scale = 128\r\n      scaled_grad_vars = optimizer.compute_gradients(loss * loss_scale)\r\n      unscaled_grad_vars = [(grad / loss_scale, var)\r\n                            for grad, var in scaled_grad_vars]\r\n      minimize_op = optimizer.apply_gradients(unscaled_grad_vars, global_step)\r\n      train_op = tf.group(minimize_op, update_ops)\r\n\r\n    else: \r\n      with tf.control_dependencies(update_ops):\r\n        train_op = optimizer.minimize(loss, tf.train.get_global_step())\r\n\r\n\r\n    tf.summary.scalar('cross_entropy',cross_entropy)\r\n    tf.summary.scalar('loss',loss)\r\n\r\n    return tf.estimator.EstimatorSpec(\r\n      mode=mode,\r\n      loss=loss,\r\n      train_op=train_op,\r\n      eval_metric_ops=None,\r\n      scaffold=None)\r\n\r\ndef main(unused_argv):\r\n    use_float16 = True\r\n    use_depthwise_conv = True\r\n    model_dir = 'D:/tf_project/depthwiseconv_mixpt/model/'\r\n    batch_size = 64\r\n    train_steps = 100000\r\n    distribution_strategy = None\r\n\r\n    gpu_options = tf.GPUOptions(allow_growth=True)\r\n    config = tf.estimator.RunConfig(\r\n      model_dir=model_dir,\r\n      train_distribute=distribution_strategy,\r\n      save_checkpoints_steps=1000,\r\n      log_step_count_steps=1,\r\n      session_config=tf.ConfigProto(\r\n          graph_options=tf.GraphOptions(\r\n              rewrite_options=rewriter_config_pb2.RewriterConfig(\r\n                  disable_meta_optimizer=True)),\r\n          #gpu_options=gpu_options\r\n          ),\r\n    )\r\n    params = dict(\r\n        use_depthwise_conv=use_depthwise_conv,\r\n        steps_per_epoch=64,\r\n        use_float16=use_float16,\r\n        batch_size=batch_size\r\n        )\r\n    testmode_est = tf.estimator.Estimator(\r\n      model_fn=test_model_fn,\r\n      config=config,\r\n      params=params\r\n    )\r\n\r\n    fake_imagenet_train = FakeImageDataInput(image_size=224,dataset_size= 128 * batch_size,use_float16=use_float16)\r\n    current_step = load_global_step_from_checkpoint_dir(  # pylint: disable=protected-access\r\n        model_dir)\r\n\r\n    tf.logging.info(\r\n        'Training for %d steps (%.2f epochs in total). Current'\r\n        ' step %d.', train_steps,\r\n        train_steps / 64, current_step)\r\n    testmode_est.train(\r\n        input_fn=fake_imagenet_train.input_fn,\r\n        max_steps=train_steps\r\n    )\r\n\r\ndef load_global_step_from_checkpoint_dir(checkpoint_dir):\r\n    try:\r\n        checkpoint_reader = tf.train.NewCheckpointReader(\r\n            tf.train.latest_checkpoint(checkpoint_dir))\r\n        return checkpoint_reader.get_tensor(tf.GraphKeys.GLOBAL_STEP)\r\n    except:  # pylint: disable=bare-except\r\n        return 0\r\nif __name__ == '__main__':\r\n  tf.logging.set_verbosity(tf.logging.INFO)\r\n  app.run(main)\r\n```\r\n", "I met the same problem, it's much slow compared to float32 precision.", "@rootkitchao  did you try \"tf.train.experimental.enable_mixed_precision_graph_rewrite\"? Does it work?\r\nThanks!", "Actually under my experiments, just doing inference (without backprop), depthwise conv is still slower in fp16 than fp32. So the problem can't just be unsupported half precision in back-propagation.", "any update?", "Seems like this is still super slow", "This is fixed with #31597 and #33836.", "> This is fixed with #31597 and #33836.\r\n\r\nIn which version of tensorflow is this fixed? In the latest nightly 2.2.0.dev20200217, I still experience very slow DepthwiseConv when using mixed precision.", "You need to build TF from source using latest cuDNN.", "Any idea whether this fix will make it into the next release?", "@urimerhav Both features are included in the 2.1 release tarballs. Note that the change is only enabled with compile-time cuDNN version check, and [TensorFlow 2.1.0 on PyPI is built with cuDNN 7.6.2](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/tools/dockerfiles/partials/ubuntu/nvidia.partial.Dockerfile#L8). Note that in https://github.com/tensorflow/tensorflow/commit/1af66b1e18ca9b8739c68956001b23b0f4ed1bff#diff-1a6332ad6f785f73b7526d275744490aR31 it was updated to 7.6.4, so you could expect TF 2.2.0 PyPI package to have this feature enabled.", "@byronyi I checked the git history of v2.1.0 and seems #31597 is in but #33836 is not.", "I have just tried with v2.1.0 build for CUDA/CuDNN 10.2.89_441.22/7.6.5.32 and DepthwiseConv is still slow when using mixed precision. The fix does indeed not seem to be included in 2.1.\r\n\r\nIf I build nightly from source, should it be fixed then?", "> In the latest nightly 2.2.0.dev20200217, I still experience very slow DepthwiseConv when using mixed precision.\r\n\r\nI think this is expected for mixed precision, since depthwise convolutions are not whitelisted in the [auto mixed-precision optimizer](https://github.com/tensorflow/tensorflow/blob/7966f2df6b6405a3d4672c868f6b301246ab9870/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h#L76-L80), or am I missing something @reedwm @benbarsdell?", "Try using mixed precision manually, not the auto mixed precision optimizer.", "I am going to use regular Conv for now, that one is much faster in mixed precision. I am sorry, I don't have time to lose on this any longer. But thanks for the help.\r\n\r\nI hope DepthwiseConv for mixed precision will be supported in the next release.", "Any advances on support this? this has a huge impact on the MobileNetV2 provided by tensorflow.keras.applications.", "This should be fixed by 201d45cea27c1792a86b3fc7eb688fb2dd1d0df1. DepthwiseConv2dNativeBackpropFilter should not be significantly slower anymore in float16. Sorry for the long delay.\r\n\r\nIf anyone has any other performance issues with depthwise convolutions, please file a new issue with a self-contained (ideally short) example.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27780\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27780\">No</a>\n", "Thanks. Any idea when this fix will make it into the next release?", "This change will be in TensorFlow 2.4, but I'm unsure when it will be released"]}, {"number": 27779, "title": "[doc/keras] incorrect comment in `__init__` of `tf.keras.layers.AveragePooling1D`", "body": "#27633 ", "comments": ["@mihaimaruseac I have reopened a pr now with lesser commits."]}, {"number": 27778, "title": "linux build tensorflow c++ API error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.9\r\n- Python version: python3\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source):0.11.0- (@non-git) \r\n- GCC/Compiler version (if compiling from source): gcc 4.8\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nhow to solve the error. thanks. which version is stable\r\n1. tensorflow/contrib/makefile/build_all_linux.sh \r\n2. ./configure\r\n3. bazel build --config=opt //tensorflow:libtensorflow_cc.so.\r\nshow Info:\r\n[root@192 tensorflow]# bazel build --config=opt //tensorflow:libtensorflow_cc.so\r\nWARNING: Config values are not defined in any .rc file: opt\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/protobuf_archive/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nERROR: /root/tensorflow/tensorflow/core/platform/default/build_config/BUILD:153:1: no such package '@png_archive//': Traceback (most recent call last):\r\n\tFile \"/root/tensorflow/third_party/repo.bzl\", line 88\r\n\t\t_apply_patch(ctx, ctx.attr.patch_file)\r\n\tFile \"/root/tensorflow/third_party/repo.bzl\", line 56, in _apply_patch\r\n\t\tfail(\"patch command is not found, ple...\")\r\npatch command is not found, please install it and referenced by '//tensorflow/core/platform/default/build_config:platformlib'\r\nERROR: Analysis of target '//tensorflow:libtensorflow_cc.so' failed; build aborted: no such package '@png_archive//': Traceback (most recent call last):\r\n\tFile \"/root/tensorflow/third_party/repo.bzl\", line 88\r\n\t\t_apply_patch(ctx, ctx.attr.patch_file)\r\n\tFile \"/root/tensorflow/third_party/repo.bzl\", line 56, in _apply_patch\r\n\t\tfail(\"patch command is not found, ple...\")\r\npatch command is not found, please install it\r\nINFO: Elapsed time: 27.651s\r\nFAILED: Build did NOT complete successfully (40 packages loaded)\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nbazel version\r\n[root@192 bazel-0.11]# bazel version\r\nBuild label: 0.11.0- (@non-git)\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Apr 24 19:52:56 +51264 (1555578330776)\r\nBuild timestamp: 1555578330776\r\nBuild timestamp as int: 1555578330776\r\n\r\n", "comments": ["Bazel version 0.24.0 will not work with TensorFlow 1.9.\r\n\r\nUse bazel version 0.11.0 or 0.10.0 to build tensorflow 1.9.\r\n\r\nReference this page to find which bazel to use for which tensorflow version:\r\nhttps://www.tensorflow.org/install/source", "@wdirons @ymodak it didn't  work. the information updated  \r\n", "@laiqb , the error now in the above message is\r\n\r\n> patch command is not found, please install it \r\n\r\n`yum install patch` should resolve that issue.", "@wdirons it works. thanks"]}, {"number": 27777, "title": "The unexpected training behavior if read data from tf.record file", "body": "To save time I skip writing data into the tf.record files. Instead data is read from tf.record files created in other training experiments (from the same source raw data). But training step marked as finished much earlier than the requested steps. This problem will not happen if I write the rf.record from scratch.\r\n\r\nNoted that the training data are basically the same, it is possibly caused by some inner training mechanism in tensorflow data management that I have not noticed. \r\n\r\n**Code to reproduce the issue**\r\nHere I define the model with \r\n```python\r\nnum_train_steps = 200000\r\nmodel_fn_builder(\r\n      ...\r\n      num_train_steps=num_train_steps,\r\n)\r\n```\r\n```python\r\ntrain_file = os.path.join(FLAGS.output_dir, \"train.tf_record\")\r\ntrain_input_fn = file_based_input_fn_builder(\r\n        input_file=train_file,\r\n       )\r\n```\r\nthe training is marked as finished at, say step `1008`. \r\n\r\nIf I rewrite the tf.record again, the training step will run as expected.\r\n```python\r\nwriter = tf.python_io.TFRecordWriter(output_file)\r\nwriter.write(tf_example.SerializeToString())\r\n...\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux \r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.11\r\n- Python version: py3.6", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 27776, "title": "Cannot compute gradients in graphs using RaggedTensors", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.14\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): `pip install tensorflow==1.13.1`\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nComputing gradients for some graphs involving `RaggedTensor`s causes an error\r\n\r\n**Describe the expected behavior**\r\n\r\nThe gradients should work. This looks similar to https://github.com/tensorflow/tensorflow/issues/26015\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nnum_buckets = 10\r\nembedding_size = 3\r\n\r\ntexts = tf.constant([\"hello how\", \"are you ?\"])\r\nragged = tf.RaggedTensor.from_sparse(tf.strings.split(texts))\r\nragged_ids = tf.ragged.map_flat_values(\r\n    tf.string_to_hash_bucket,\r\n    ragged,\r\n    num_buckets\r\n)\r\nembeddings = tf.get_variable(\"embeddings\", shape=[num_buckets, embedding_size])\r\nragged_embeddings = tf.ragged.map_flat_values(\r\n  tf.nn.embedding_lookup, embeddings, ragged_ids\r\n)\r\n\r\nvariable = tf.get_variable(\r\n    \"variable\",\r\n    [1, 1, embedding_size]\r\n)\r\n\r\nragged_embeddings_1 = tf.RaggedTensor.from_row_splits(\r\n    values=(ragged_embeddings + variable),\r\n    row_splits=ragged_embeddings.row_splits,\r\n)\r\n\r\nragged_embeddings_2 = tf.concat([ragged_embeddings, ragged_embeddings], 1)\r\n\r\n\r\nsess.run(tf.global_variables_initializer())\r\n\r\ndef test_grad(ragged_tensor):\r\n  sess.run(ragged_tensor)\r\n  grad, = tf.gradients([ragged_tensor.to_tensor()], [embeddings])\r\n  sess.run(grad)\r\n\r\n# No error\r\ntest_grad(ragged_embeddings)\r\n\r\n# Raises InvalidArgumentError: Operation 'RaggedTile/Tile' has no attr named '_XlaCompile'.\r\ntest_grad(ragged_embeddings_1)\r\n\r\n# Raises LookupError: gradient registry has no entry for: RaggedGather\r\ntest_grad(ragged_embeddings_2)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nFull error for grad of `ragged_embeddings_1`:\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\r\n   2408       with c_api_util.tf_buffer() as buf:\r\n-> 2409         c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)\r\n   2410         data = c_api.TF_GetBuffer(buf)\r\n\r\nInvalidArgumentError: Operation 'RaggedTile/Tile' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    414     try:\r\n--> 415       xla_compile = op.get_attr(\"_XlaCompile\")\r\n    416       xla_separate_compiled_gradients = op.get_attr(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\r\n   2412       # Convert to ValueError for backwards compatibility.\r\n-> 2413       raise ValueError(str(e))\r\n   2414     x = attr_value_pb2.AttrValue()\r\n\r\nValueError: Operation 'RaggedTile/Tile' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    454                 preferred_dtype=default_dtype,\r\n--> 455                 as_ref=input_arg.is_ref)\r\n    456             if input_arg.number_attr and len(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_n_to_tensor(values, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1239             preferred_dtype=preferred_dtype,\r\n-> 1240             ctx=ctx))\r\n   1241   return ret\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\r\n   1174     if ret is None:\r\n-> 1175       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1176 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    976         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n--> 977         (dtype.name, t.dtype.name, str(t)))\r\n    978   return t\r\n\r\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: 'Tensor(\"gradients/RaggedTile/Tile_grad/Shape:0\", shape=(2,), dtype=int32)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-38-299d0ab83362> in <module>()\r\n     38   sess.run(grad)\r\n     39 \r\n---> 40 test_grad(ragged_embeddings_1)\r\n\r\n<ipython-input-38-299d0ab83362> in test_grad(ragged_tensor)\r\n     35 def test_grad(ragged_tensor):\r\n     36   sess.run(ragged_tensor)\r\n---> 37   grad, = tf.gradients([ragged_tensor.to_tensor()], [embeddings])\r\n     38   sess.run(grad)\r\n     39 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\r\n    662     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\r\n    663                             gate_gradients, aggregation_method, stop_gradients,\r\n--> 664                             unconnected_gradients)\r\n    665 \r\n    666 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    963                 # functions.\r\n    964                 in_grads = _MaybeCompile(grad_scope, op, func_call,\r\n--> 965                                          lambda: grad_fn(op, *out_grads))\r\n    966               else:\r\n    967                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    418       xla_scope = op.get_attr(\"_XlaScope\").decode()\r\n    419     except ValueError:\r\n--> 420       return grad_fn()  # Exit early\r\n    421 \r\n    422   if not xla_compile:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in <lambda>()\r\n    963                 # functions.\r\n    964                 in_grads = _MaybeCompile(grad_scope, op, func_call,\r\n--> 965                                          lambda: grad_fn(op, *out_grads))\r\n    966               else:\r\n    967                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py in _TileGrad(op, grad)\r\n    579   #   axes = [0, 2, 4]\r\n    580   split_shape = array_ops.reshape(\r\n--> 581       array_ops.transpose(array_ops.stack([op.inputs[1], input_shape])), [-1])\r\n    582   axes = math_ops.range(0, array_ops.size(split_shape), 2)\r\n    583   # Sum reduces grad along the first dimension for IndexedSlices\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    178     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    179     try:\r\n--> 180       return target(*args, **kwargs)\r\n    181     except (TypeError, ValueError):\r\n    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py in stack(values, axis, name)\r\n   1003                                                       expanded_num_dims))\r\n   1004 \r\n-> 1005   return gen_array_ops.pack(values, axis=axis, name=name)\r\n   1006 \r\n   1007 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in pack(values, axis, name)\r\n   5446   axis = _execute.make_int(axis, \"axis\")\r\n   5447   _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 5448         \"Pack\", values=values, axis=axis, name=name)\r\n   5449   _result = _op.outputs[:]\r\n   5450   _inputs_flat = _op.inputs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    481                                 (prefix, dtype.name))\r\n    482               else:\r\n--> 483                 raise TypeError(\"%s that don't all match.\" % prefix)\r\n    484             else:\r\n    485               raise TypeError(\r\n\r\nTypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int64, int32] that don't all match.\r\n```\r\n\r\n\r\nFull error for `ragged_embeddings_2`:\r\n\r\n```\r\nLookupError                               Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    906           try:\r\n--> 907             grad_fn = ops.get_gradient_function(op)\r\n    908           except LookupError:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_gradient_function(op)\r\n   2545     op_type = op.type\r\n-> 2546   return _gradient_registry.lookup(op_type)\r\n   2547 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/registry.py in lookup(self, name)\r\n     93       raise LookupError(\r\n---> 94           \"%s registry has no entry for: %s\" % (self._name, name))\r\n\r\nLookupError: gradient registry has no entry for: RaggedGather\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-39-8a8bafd157d6> in <module>()\r\n     38   sess.run(grad)\r\n     39 \r\n---> 40 test_grad(ragged_embeddings_2)\r\n\r\n<ipython-input-39-8a8bafd157d6> in test_grad(ragged_tensor)\r\n     35 def test_grad(ragged_tensor):\r\n     36   sess.run(ragged_tensor)\r\n---> 37   grad, = tf.gradients([ragged_tensor.to_tensor()], [embeddings])\r\n     38   sess.run(grad)\r\n     39 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\r\n    662     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\r\n    663                             gate_gradients, aggregation_method, stop_gradients,\r\n--> 664                             unconnected_gradients)\r\n    665 \r\n    666 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    921               raise LookupError(\r\n    922                   \"No gradient defined for operation '%s' (op type: %s)\" %\r\n--> 923                   (op.name, op.type))\r\n    924         if loop_state:\r\n    925           loop_state.EnterGradWhileContext(op, before=False)\r\n\r\nLookupError: No gradient defined for operation 'RaggedConcat/RaggedGather/RaggedGather' (op type: RaggedGather)\r\n```\r\n\r\n\r\n", "comments": ["I found that this has been fixed in the nightly builds.", "In `1.14.1-dev20190413`, `ragged_embeddings_1` is fixed, but `ragged_embeddings_2` is not. That is the `_XlaCompile` error goes away, but apparently `RaggedGather` still has no registered gradient", "Yes, you're right, the second error still exists. I've had to avoid using tf.concat on ragged tensors.", "Also been having trouble with this issue. I have written a quick patch for the RaggedGather:\r\n\r\n```\r\n@tf.RegisterGradient(\"RaggedGather\")\r\ndef _ragged_gather_grad(gather_op, unused,out_grads):\r\n    *params_nested_splits, params_dense_values, ragged_indices = list(\r\n        gather_op.inputs\r\n    )\r\n    if len(params_nested_splits) > 1:\r\n        raise NotImplementedError(\r\n            'Backward pass for nested RaggedTensors not supported'\r\n        )\r\n    output_nested_splits, output_dense_values = gather_op.outputs\r\n\r\n    # Turn the ragged indices into flat indices\r\n    flat_indices = tf.RaggedTensor.from_nested_row_splits(\r\n        tf.range(tf.shape(grads)[0]), [output_nested_splits]\r\n    )\r\n    flat_indices = tf.gather(flat_indices, ragged_indices).flat_values\r\n\r\n    return [\r\n        None,\r\n        tf.IndexedSlices(\r\n            values=grads, indices=flat_indices,\r\n            dense_shape=tf.shape(params_dense_values)\r\n        ),\r\n        None\r\n    ]\r\n```\r\n\r\nThe `ragged_gather` op is found in `tensorflow/python/ops/gen_ragged_array_ops.py`\r\n\r\nThis is working for `concat`s along a ragged dimension. I've only tested with `ragged_rank=1`\r\n\r\nHappy to work this into a future PR.\r\n ", "Thanks @coopie!\r\n```py\r\noutput_ragged = tf.gather(input_ragged, indices)\r\n``` \r\nYour code works perfect for `input_ragged ragged_rank is 1` and `indices is 1D`. \r\n\r\nJust a typo want to remind, all `grads` inside the function should be `out_grads`\r\n\r\n---\r\n**Updated**: model is able to running now, but compared to `convert it to tensor and then gather`, RaggedGather does not converge. \r\n```\r\noutput_tensor = tf.gather(input_ragged.to_tensor(), indices)\r\n```\r\n---\r\n**Updated**: I figured it out, there is a bug here\r\n```py\r\n    # Turn the ragged indices into flat indices\r\n    flat_indices = tf.RaggedTensor.from_nested_row_splits(\r\n        tf.range(tf.shape(grads)[0]), [output_nested_splits]\r\n    )\r\n```\r\nwhich should be \r\n```py\r\n    # Turn the ragged indices into flat indices\r\n    flat_indices = tf.RaggedTensor.from_nested_row_splits(\r\n        tf.range(tf.shape(out_grads)[0]), [params_nested_splits[0]]\r\n    )\r\n```\r\n\r\n---\r\n**the whole code**\r\n```python\r\n@tf.RegisterGradient(\"RaggedGather\")\r\ndef _ragged_gather_grad(gather_op, unused, out_grads):\r\n    *params_nested_splits, params_dense_values, ragged_indices = list(\r\n        gather_op.inputs\r\n    )\r\n    if len(params_nested_splits) > 1:\r\n        raise NotImplementedError(\r\n            'Backward pass for nested RaggedTensors not supported'\r\n        )\r\n    output_nested_splits, output_dense_values = gather_op.outputs\r\n\r\n    # Turn the ragged indices into flat indices\r\n    flat_indices = tf.RaggedTensor.from_nested_row_splits(\r\n        tf.range(tf.shape(out_grads)[0]), [params_nested_splits[0]]\r\n    )\r\n    flat_indices = tf.gather(flat_indices, ragged_indices).flat_values\r\n\r\n    return [\r\n        None,\r\n        tf.IndexedSlices(\r\n            values=out_grads, indices=flat_indices,\r\n            dense_shape=tf.shape(params_dense_values)\r\n        ),\r\n        None\r\n    ]\r\n```\r\nthen it could converge\r\n```\r\nEpoch 1/5\r\n289/288 [==============================] - 171s 591ms/step - loss: 0.2502 - rmse: 302.2978 - val_loss: 0.0024 - val_rmse: 20.7268\r\nEpoch 2/5\r\n289/288 [==============================] - 85s 295ms/step - loss: 0.0015 - rmse: 17.3415 - val_loss: 0.0013 - val_rmse: 15.1368\r\nEpoch 3/5\r\n289/288 [==============================] - 85s 295ms/step - loss: 9.2807e-04 - rmse: 13.5158 - val_loss: 8.3251e-04 - val_rmse: 12.1445\r\nEpoch 4/5\r\n289/288 [==============================] - 84s 291ms/step - loss: 6.6616e-04 - rmse: 11.4514 - val_loss: 6.6404e-04 - val_rmse: 10.8465\r\nEpoch 5/5\r\n289/288 [==============================] - 88s 303ms/step - loss: 5.0972e-04 - rmse: 10.0171 - val_loss: 4.9283e-04 - val_rmse: 9.3444\r\n```\r\n", "Fixed in f7415d1ef.  Gradient is now defined for RaggedGather (for any inputs, including ragged_rank>1 and indices.ndims>1).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27776\">No</a>\n"]}, {"number": 27775, "title": "add back-ticks for formatting", "body": "add back-ticks for formatting", "comments": []}]