[{"number": 41002, "title": "[CherryPick:r2.3] Support dynamic outputs for XLA on demand ops.", "body": "PiperOrigin-RevId: 317902879\nChange-Id: I6b6dfa54855d5996ac15d4b5c48a5db5dc230025", "comments": []}, {"number": 41000, "title": "Support matmul operation for tf.complex64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab CPU\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n\r\n[Colab example](https://colab.research.google.com/drive/1_2YSQ21OwpxGhbdrDznNUsL77aesBynH?usp=sharing)\r\n\r\nNote: I wouldn't mind to use `tf.einsum` instead, but that's not supported at all.\r\nAlso, not sure which operation *are* supported for `tf.complex`.\r\n\r\nThanks", "comments": ["I have tried in colab with TF versions, 2.2, 2.3-rc0 ,nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ce354d8108913f2eb4def033799b658a/untitled70.ipynb).Thanks!", "TF Lite doesn't support Complex natively, you will need to use Select (which runs TF kernels instead)\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\n\r\nSee more details about what TFLite Supports here\r\nhttps://www.tensorflow.org/lite/guide/inference#supported_operations", "Should be\r\n\"TF Lite doesn't support Complex natively for the requested ops\"", "Thanks, so I guess this issue is about supporting complex natively. Is that on the roadmap? when can we expect this?", "No plans at the current moment."]}, {"number": 40999, "title": ".pb object detection model with 1 output tensor conversion to 4 output tensors", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10, build 7601: SP1\r\n& Linux 16.04 guest\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n[Google Coral Edge Dev Board\r\n](https://coral.ai/products/dev-board/)- TensorFlow installed from (source or binary):\r\nPip\r\n- TensorFlow version:\r\n2.3.0-dev20200620\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: Pip\r\n- Bazel version (if compiling from source): N/A \r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A CPU only\r\n- GPU model and memory: N/A CPU only\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n\r\n**Describe the problem**\r\nThis problem is somewhat related to comment [#547708153](https://github.com/tensorflow/tensorflow/issues/33774#issuecomment-547708153) and subsequent answers.\r\n\r\nUsing Microsoft Azure CustomVision (as in above issue), I trained and labelled a tensorflow object detection model. Azure allows you to download this object detection model directly to .pb or .tflite. \r\n\r\nThe output of the .pb object detection model looks like this:\r\n![pzN0L](https://user-images.githubusercontent.com/14267992/86273918-ef2aae00-bb9e-11ea-965f-057c216d2c20.png)\r\n\r\nThis appears to be a single output tensor model on an object detection model. How does one convert to 4 output tensors as required by mobile devices?\r\n\r\n-------------------------------------------------------------------------------------------------------------------------\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAttempting to convert to .tflite with tflite_convert and quantization (note --enable_v1_converter flag enabled as per the answers in the above thread)\r\n```\r\npython tflite_convert.py \\\r\n--output_file=model.tflite \\\r\n--graph_def_file=model.pb \\\r\n--enable_v1_converter \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_shapes=1,416,416,3  \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays=model_outputs \\\r\n--mean_values=128 \\\r\n--std_dev_values=128 \\\r\n--allow_custom_ops \\\r\n--change_concat_input_ranges=false \\\r\n--allow_nudging_weights_to_use_fast_gemm_kernel=true\r\n```\r\n\r\nThis command creates a model.tflite. The tensor output of this .tflite is identical to the tensor in the .pb file above\r\n\r\nThe rest of this works, but for repeatability purposes I will continue. I then drag this .tflite into the guest linux account and push it onto the Edge device\r\n`mdt push model.tflite`\r\n\r\nThe .tflite is now on the Coral Edge board, so I set it up to run\r\n```\r\nexport DEMO_FILES=\"/usr/lib/python3/dist*/edgetpu/demo\"\r\nsudo cp model.tflite DEMO_FILES\r\n\r\nexport DISPLAY=:0 && edgetpu_detect \\\r\n-- source /dev/video1:YUY2:1280x720:20/1 \\\r\n--model ${DEMO_FILES}/model.tflite\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nCoral Edge Output confirms only one tensor (the ValueError is noted in their [docs](https://coral.ai/docs/reference/edgetpu.detection.engine/))\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nTraceback (most recent call last):\r\n  File \"/usr/bin/edgetpu_detect\", line 11, in <module>\r\n    load_entry_point('edgetpuvision==1.0', 'console_scripts', 'edgetpu_detect')()\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/detect.py\", line 207, in main\r\n    run_app(add_render_gen_args, render_gen)\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/apps.py\", line 70, in run_app\r\n    display=args.displaymode):\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/gstreamer.py\", line 240, in run_gen\r\n    inference_size = render_overlay_gen.send(None)  # Initialize.\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/detect.py\", line 144, in render_gen\r\n    engines, titles = utils.make_engines(args.model, DetectionEngine)\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/utils.py\", line 53, in make_engines\r\n    engine = engine_class(model_path)\r\n  File \"/usr/lib/python3/dist-packages/edgetpu/detection/engine.py\", line 77, in __init__\r\n    'This model has {}.'.format(output_tensors_sizes.size)))\r\nValueError: Dectection model should have 4 output tensors!This model has 1.\r\n```\r\n\r\nAnd finally, personally I have used Google's AutoML vision to train a model and push it onto the Edge device. The output of the AutoML looks like the following. This output (4 tensors) works on the Edge device. \r\n\r\n![Hzl6A](https://user-images.githubusercontent.com/14267992/86274029-108b9a00-bb9f-11ea-8cea-629093a2d49a.png)\r\n\r\nMany thanks for any ideas!\r\n", "comments": ["@Iorek73,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and a link to the object detection model you are using. \r\n\r\nAlso, please take a look at [this link](https://www.tensorflow.org/lite/models/object_detection/overview#customize_model) to customize your model and let us know if it helps. Thanks!", "Here's a [link ](https://drive.google.com/file/d/1H_zWdvPjK7idA7IA467sv1DXphH2pBiz/view?usp=sharing)to the model. Since it was trained directly using Azure CustomVision.ai there was no code required to build it. Drop images, label, train, export. All the following code is above the OP. ", "@Iorek73 \r\nHello, is that model exported from Azure cannot be used in mobile? So I have to retrain the model using Google's AutoML vision right?", "Hi @re0saya , no the model is trained with Azure and should be usable for mobile but is not. The key point is a I don't want to train it with AutoML (I know AutoML works but I don't want to use it). ", "> Here's a [link ](https://drive.google.com/file/d/1H_zWdvPjK7idA7IA467sv1DXphH2pBiz/view?usp=sharing)to the model.\r\n\r\n@Iorek73,\r\nI do not have access to the link. Could you please grant the required permissions or share the file here on GitHub, so that we can look into this. Thanks!", "Hi @amahendrakar , sorry, the file was too large (>25MB for github). Please try again. ", "@Iorek73 Could you please try on the latest TF **v2.6.0** and let us know if it helps?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40999\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40999\">No</a>\n"]}, {"number": 40998, "title": "[XLA/GPU] rsqrt is cheap and should be fused.", "body": "\r\nPlease help to review the codes. Thanks.\r\n\r\nThe pattern is observed (at least) in BERT.\r\n", "comments": ["@sanjoy @thomasjoerg \r\nCould either of you help to take a look or suggest a reviewer? Thanks!", "The heuristic is good (I like it). However, rsqrt (or div) is just mapped to one hardware instruction unlike other instrinsics, which will be expanded into a bunch of instructions when linking in libdevice. So, I think that marking cheap instructions cheap is orthogonal to the heuristic (which better deals with real expensive instructions).\r\n\r\nI see the case in layer norm.\r\n![image](https://user-images.githubusercontent.com/12016207/86946636-880d7c00-c0ff-11ea-879d-aa7ba1185535.png)\r\n\r\n", "Updated. Please help to take a look again. Thanks!", "Hi @trentlo ,\r\n\r\nThis seems to regress a variant of resnet only on V100 by around 10%.  Here is the pre-optimization HLO: https://gist.github.com/sanjoy/8161733b3e8f303d2f81b38814661f9a\r\n\r\nCan you PTAL?  Let me know if you can't reproduce the regression.", "> Hi @trentlo ,\r\n> \r\n> This seems to regress a variant of resnet only on V100 by around 10%. Here is the pre-optimization HLO: https://gist.github.com/sanjoy/8161733b3e8f303d2f81b38814661f9a\r\n> \r\n> Can you PTAL? Let me know if you can't reproduce the regression.\r\n\r\nI'd guess that it interacts with the fusion heuristic and produces a surprising fusion result. I will take a look.\r\n", "> Hi @trentlo ,\r\n> \r\n> This seems to regress a variant of resnet only on V100 by around 10%. Here is the pre-optimization HLO: > \r\n> Can you PTAL? Let me know if you can't reproduce the regression.\r\n\r\n@sanjoy, I instead see 1% speedup with this PR on V100 (according to the perf numbers reported by xla_profile). See the attached log file for some more details.\r\n[log.rsqrt_expensive.txt](https://github.com/tensorflow/tensorflow/files/4934954/log.rsqrt_expensive.txt)\r\n[log.rsqrt_cheap.txt](https://github.com/tensorflow/tensorflow/files/4934955/log.rsqrt_cheap.txt)\r\n\r\nAre you sure if the regression is related to this PR? Also, I wonder if you see any perf gain?\r\n", "> Are you sure if the regression is related to this PR? Also, I wonder if you see any perf gain?\r\n\r\nCould have been operator error, trying again."]}, {"number": 40996, "title": "TF 2.1 Automatic Mixed Precision Training Loss Not Going Down", "body": "I'm trying to use automatic mixed precision in TensorFlow 2.1.0, but my training loss has not been going down.\r\n\r\nI'm using the follow code snippets:\r\n\r\ntf.keras.mixed_precision.experimental.set_policy('mixed_float16')\r\n\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\noptimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, \"dynamic\")\r\n\r\ndef _compute_apply_gradients(x):\r\n        with tf.GradientTape() as tape:\r\n            loss, metric_value = _compute_loss(x)\r\n            loss = _optimizer.get_scaled_loss(loss)\r\n        gradients = tape.gradient(loss, _model.trainable_variables)\r\n        gradients = _optimizer.get_unscaled_gradients(gradients)\r\n        _optimizer.apply_gradients(zip(gradients, _model.trainable_variables))\r\n        return loss, metric_value\r\n\r\nFor calculating my loss, I'm doing the following:\r\n\r\noutputs_logits, _ = _model(images, is_training=True)\r\nloss = tf.nn.softmax_cross_entropy_with_logits(logits=outputs_logits, labels=labels)\r\n\r\nI also added dtype='float32' to the final layer of my model, which is a U-Net.\r\n\r\nWhen training, my loss starts from a really high value and then gradually decreases down to ~2.x, which is normal for regular training, and then just stops from there on - never going down. I have TensorFlow 2.1, Python 3.7.7, and a GPU with compute capability > 7.0.\r\n\r\nCould this be an issue in TensorFlow? Has anyone else had this issue?\r\n\r\nOr could it be an issue with the loss function? Thanks\r\n\r\n\r\n", "comments": ["@coded5282,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here along with output log. \r\n\r\nAlso, please add three back ticks (i.e. ```) before and after your code to preserve the indentation. Alternatively, you can attach the `.py` or notebook file you are running. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40995, "title": "Add filesystem ops", "body": "@mihaimaruseac \r\nThis PR adds filesystem ops. Regarding the problems with directory, I copy the current approach. But as far as I know, the curent approach can not guarantee the same behavior with `posix filesystem`. I think it maybe the good time to change the `gcs filesystem` design and drop all the `fake directory` support. In particular, CreateDir, DeleteDir, ... will always return ok. What do you think ? I do not have access to the internal code so could you check it for me. Thank you", "comments": ["So I have done some testing. Turn out the current implementation is more complex than I thought and it has the same behavior with local filesystem. But it has one trade-off, it sometimes shows the wrong information compared to the server.\r\n\r\nI have an object `'test/foo'` on the server.\r\n`tensorflow 2.2.0` returns `true` if I call `tf.io.gfile.exists(\"test\")` or `tf.io.gfile.exists(\"test/\")` but `google-cloud-cpp`, `gsutil stat` and `google-cloud-storage` (python) return not found.\r\n\r\nI would like to ask if there is any particular reason that we have to keep this behavior ? ( I think the reason is that we want to have the same behavior between filesystems )", "`tf.io.gfile.exists(path)` should return `true` whenever `path` exists.\r\n\r\nI think the other 3 only return `true` if the `path` exists and is a file.\r\n\r\nNote that the plugin interface checks for a path, not a file https://github.com/tensorflow/tensorflow/blob/e25d3e084b330de37284f54853295ce28ea93d12/tensorflow/c/experimental/filesystem/filesystem_interface.h#L506-L517", "If we do like this, we will check that if there is a object whose key contains that path ( like object `test/foo` contains `test`). I think it is not so useful in general ?", "Users might ask if a path exists (file/directory) to determine what operations to run in the future. This is much better than the alternative where if they wanted to see if a file exists they can also use `IsDirectory` and look at the return value (the `Status` tells them if the path exists but it is a file).", "Ok I got it. So first I will copy the current implementation and we could return to this topic after everything is done", "I would still like to split this PR into components:\r\n\r\n1. will just create/delete files/directories\r\n1. will just add support for moving/renaming\r\n1. will add support for checking if paths exists, if they are directories, for the stats, etc.\r\n1. will finally allow matching glob patterns and getting all children of a path", "Close for smaller PRs"]}, {"number": 40994, "title": "SavedModel of Keras Model does not save the trainable status", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Google Colab\r\n- TensorFlow installed from: binary\r\n- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nSet `trainable` for some layers of a Keras model to `False` and save the model via `model.save(..., save_format='tf')`. Loading the model again with `tf.keras.load_model(...)` does not restore the value of `trainable` but sets the value to `True`.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the `trainable` flag to saved and loaded correctly.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/drive/1tYvRK8mxfvU3_SVV9P97dKUV6W9Hue_S?usp=sharing\r\n", "comments": ["I have tried in colab with TF versions 2.2, nightly versions(`2.4.0-dev20200701`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/431be3bc71ee1d13668ee6baa9d2988e/untitled69.ipynb).Thanks!", "May I ask is there any update on this bug?", "@HedgehogCode @xqr-g  Closing the issue since the bug was fixed already [here](https://critique-ng.corp.google.com/cl/359853088). Please feel free to re open the issue if the isse still persists.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40994\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40994\">No</a>\n"]}, {"number": 40993, "title": "Add support for layers with multiple inputs and outputs", "body": "**Content**\r\nThis pull request enables the support for wrapping layers with multiple (nested) inputs and outputs.\r\n\r\n**Related Issues**\r\n- Missing support for multiple inputs #35824\r\n- Missing support for multiple outputs #40896\r\n\r\nResolves #35824, resolves #40896 ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40993) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40993) for more info**.\n\n<!-- ok -->", "@ffent  Can you please check @qlzh727's comments and keep us posted ? Thanks!", "I have implemented your suggested changes and ran the unit test as well as the build test for the PR to ensure its correctness.", "@qlzh727 can you please support with the occurring errors during the CI tests, since I'm not able to reproduce these errors on my local machine. You can find the 'logs' of the TimeDistributed unit test below.\r\n\r\n<details>\r\n<summary>Unit test results</summary>\r\n<br>\r\n\r\n```\r\nroot@7d24e37df67f:/tensorflow# /usr/bin/python3 /tensorflow/tensorflow/python/keras/layers/wrappers_test.py\r\n2020-08-06 08:44:26.860992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nRunning tests under Python 3.6.9: /usr/bin/python3\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_batchnorm\r\n2020-08-06 08:44:28.129771: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-08-06 08:44:28.129792: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: UNKNOWN ERROR (-1)\r\n2020-08-06 08:44:28.129811: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7d24e37df67f\r\n2020-08-06 08:44:28.129818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7d24e37df67f\r\n2020-08-06 08:44:28.129889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n2020-08-06 08:44:28.129920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.100.0\r\n2020-08-06 08:44:28.155483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\r\n2020-08-06 08:44:28.155983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x455a880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-06 08:44:28.156000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-06 08:44:29.164590: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1,10,2]\r\n         [[{{node Placeholder/_1}}]]\r\n2020-08-06 08:44:29.570343: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_batchnorm): 1.52s\r\nI0806 08:44:29.650143 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_batchnorm): 1.52s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_batchnorm\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_learning_phase\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_learning_phase): 0.1s\r\nI0806 08:44:29.752757 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_learning_phase): 0.1s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_learning_phase\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager): 0.19s\r\nI0806 08:44:29.942809 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager): 0.19s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph): 0.03s\r\nI0806 08:44:29.972494 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph): 0.03s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager): 0.01s\r\nI0806 08:44:29.985790 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager): 0.01s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph): 0.01s\r\nI0806 08:44:29.994126 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph): 0.01s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_trainable\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_trainable): 0.03s\r\nI0806 08:44:30.022988 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_trainable): 0.03s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_trainable\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_different_time_shapes\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_different_time_shapes): 0.02s\r\nI0806 08:44:30.046733 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_different_time_shapes): 0.02s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_different_time_shapes\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions): 0.0s\r\nI0806 08:44:30.050868 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions): 0.0s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager): 0.51s\r\nI0806 08:44:30.560951 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager): 0.51s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function): 1.14s\r\nI0806 08:44:31.700047 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function): 1.14s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors\r\nWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab40ce510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:32.764994 140304557958976 def_function.py:124] 5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab40ce510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors): 1.07s\r\nI0806 08:44:32.771704 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors): 1.07s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape\r\n1/1 [==============================] - 0s 251us/step - loss: 0.5973\r\n2020-08-06 08:44:34.661642: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.661769: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.695411: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [3]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.695496: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [3]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.714380: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.714466: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.744987: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [3]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:34.745069: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [3]\r\n         [[{{node inputs_1}}]]\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape): 1.98s\r\nI0806 08:44:34.754753 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape): 1.98s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n2/2 [==============================] - 0s 438us/step - loss: 3.4158\r\n2020-08-06 08:44:35.287111: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.287200: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.304032: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.304155: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.55s\r\nI0806 08:44:35.309945 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.55s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph\r\nTrain on 10 samples\r\n2020-08-06 08:44:35.442441: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:192] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n10/10 [==============================] - 0s 170us/sample - loss: 9.9862\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph): 0.21s\r\nI0806 08:44:35.517459 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph): 0.21s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager): 0.22s\r\nI0806 08:44:35.738596 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function\r\nWARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab471ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:35.905018 140304557958976 def_function.py:124] 6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab471ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function): 0.22s\r\nI0806 08:44:35.959031 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors\r\nWARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a941677b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.124163 140304557958976 def_function.py:124] 7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a941677b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors): 0.22s\r\nI0806 08:44:36.179700 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager): 0.0s\r\nI0806 08:44:36.181457 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function): 0.0s\r\nI0806 08:44:36.182505 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors): 0.0s\r\nI0806 08:44:36.183827 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager): 0.0s\r\nI0806 08:44:36.184898 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function): 0.0s\r\nI0806 08:44:36.185999 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors): 0.0s\r\nI0806 08:44:36.187155 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager\r\n2020-08-06 08:44:36.242561: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\n2020-08-06 08:44:36.243867: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\nWARNING:tensorflow:8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a9447b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.326344 140304557958976 def_function.py:124] 8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a9447b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a944fc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.405713 140304557958976 def_function.py:124] 9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a944fc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager): 0.22s\r\nI0806 08:44:36.410956 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function\r\n2020-08-06 08:44:36.463951: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\n2020-08-06 08:44:36.465291: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\nWARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a9447bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.548507 140304557958976 def_function.py:124] 9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a9447bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab474c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.626889 140304557958976 def_function.py:124] 9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9ab474c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function): 0.22s\r\nI0806 08:44:36.631920 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors\r\n2020-08-06 08:44:36.691112: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\n2020-08-06 08:44:36.692575: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [3]\r\n         [[{{node Placeholder/_0}}]]\r\nWARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9abc137268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.776774 140304557958976 def_function.py:124] 9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9abc137268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9abc137510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:36.856816 140304557958976 def_function.py:124] 9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9abc137510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors): 0.23s\r\nI0806 08:44:36.862071 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors): 0.23s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_regularizers\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_regularizers): 0.03s\r\nI0806 08:44:36.892794 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_regularizers): 0.03s\r\n[       OK ] TimeDistributedTest.test_regularizers\r\n[ RUN      ] TimeDistributedTest.test_session\r\n[  SKIPPED ] TimeDistributedTest.test_session\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_conv2d\r\n2020-08-06 08:44:36.919640: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1,2,4,4,5]\r\n         [[{{node Placeholder/_1}}]]\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ntime_distributed (TimeDistri (None, 2, 4, 4, 5)        65        \r\n_________________________________________________________________\r\nactivation (Activation)      (None, 2, 4, 4, 5)        0         \r\n=================================================================\r\nTotal params: 65\r\nTrainable params: 65\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_conv2d): 0.22s\r\nI0806 08:44:37.117885 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_conv2d): 0.22s\r\n[       OK ] TimeDistributedTest.test_timedistributed_conv2d\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_dense_test_mode_eager\r\nWARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9ab474c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:37.325525 140304557958976 def_function.py:124] 5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9ab474c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 233us/step - loss: 0.3989\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_eager): 0.21s\r\nI0806 08:44:37.329358 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_eager): 0.21s\r\n[       OK ] TimeDistributedTest.test_timedistributed_dense_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_dense_test_mode_graph\r\nTrain on 10 samples\r\n10/10 [==============================] - 0s 29us/sample - loss: 0.2831\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_graph): 0.14s\r\nI0806 08:44:37.467433 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_graph): 0.14s\r\n[       OK ] TimeDistributedTest.test_timedistributed_dense_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_invalid_init\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_invalid_init): 0.0s\r\nI0806 08:44:37.469172 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_invalid_init): 0.0s\r\n[       OK ] TimeDistributedTest.test_timedistributed_invalid_init\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_stacked\r\nWARNING:tensorflow:6 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9a8c721b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:37.757203 140304557958976 def_function.py:124] 6 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9a8c721b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 267us/step - loss: 0.3009\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_stacked): 0.29s\r\nI0806 08:44:37.759545 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_stacked): 0.29s\r\n[       OK ] TimeDistributedTest.test_timedistributed_stacked\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_static_batch_size\r\nWARNING:tensorflow:7 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9a94767620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW0806 08:44:37.974279 140304557958976 def_function.py:124] 7 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9a94767620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 261us/step - loss: 0.3989\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_static_batch_size): 0.22s\r\nI0806 08:44:37.976477 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_timedistributed_static_batch_size): 0.22s\r\n[       OK ] TimeDistributedTest.test_timedistributed_static_batch_size\r\n----------------------------------------------------------------------\r\nRan 35 tests in 9.852s\r\n\r\nOK (skipped=7)\r\n```\r\n</details>", "@qlzh727 Can you please assist on above comments from @ffent. Thanks!", "This is quite weird, your local tests should fail, but it just raise the warning.\r\n\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n2/2 [==============================] - 0s 438us/step - loss: 3.4158\r\n2020-08-06 08:44:35.287111: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.287200: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.304032: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\n2020-08-06 08:44:35.304155: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'inputs_1' with dtype int32 and shape [2]\r\n         [[{{node inputs_1}}]]\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.55s\r\nI0806 08:44:35.309945 140304557958976 test_util.py:1973] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.55s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n", "@ffent  Can you please check @qlzh727's comments and keep us posted ? Thanks!", "I moved back to the previous (original) implementation of the `_get_shape_tuple` function, so no tensor conversion is made anymore and the errors should not occur anymore.", "It seems that the sanity check is failing. Can u update please?\r\n\r\nFAIL: Found 1 non-allowlisted pylint errors:\r\ntensorflow/python/keras/layers/wrappers.py:339: [C0330(bad-continuation), ] Wrong continued indentation (add 6 spaces).\r\n", "Thanks @qlzh727 for running the tests again. \r\nHowever, the log file of the sanity check is not to helpful to me. Is the code style issue the only remaining issue? ", "I fixed the sanity issues and ran all tests again without any issues.\r\n\r\nFollowing test where executed:\r\n\r\n1. Code Style Checks\r\n    <details>\r\n    <summary>Style check results</summary>\r\n    <br>\r\n\r\n    ```\r\n    root@7d24e37df67f:/tensorflow# pylint --rcfile=tensorflow/tools/ci_build/pylintrc tensorflow/python/keras/layers/wrappers.py\r\n    ************* Module tensorflow.python.keras.layers.wrappers\r\n    tensorflow/python/keras/layers/wrappers.py:54:4: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:64:4: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\n    tensorflow/python/keras/layers/wrappers.py:71:18: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:75:2: W0221: Parameters differ from overridden 'from_config' method (arguments-differ)\r\n    tensorflow/python/keras/layers/wrappers.py:76:4: C0415: Import outside toplevel (tensorflow.python.keras.layers.deserialize) (import-outside-toplevel)\r\n    tensorflow/python/keras/layers/wrappers.py:127:4: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:170:2: W0222: Signature differs from overridden 'build' method (signature-differs)\r\n    tensorflow/python/keras/layers/wrappers.py:182:4: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:200:2: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\n    tensorflow/python/keras/layers/wrappers.py:460:4: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:520:2: C0116: Missing function or method docstring (missing-function-docstring)\r\n    tensorflow/python/keras/layers/wrappers.py:529:4: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\n    tensorflow/python/keras/layers/wrappers.py:566:2: W0221: Parameters differ from overridden '__call__' method (arguments-differ)\r\n    tensorflow/python/keras/layers/wrappers.py:577:13: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:621:4: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\n    tensorflow/python/keras/layers/wrappers.py:635:15: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:639:13: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:641:2: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\n    tensorflow/python/keras/layers/wrappers.py:730:2: W0222: Signature differs from overridden 'build' method (signature-differs)\r\n    tensorflow/python/keras/layers/wrappers.py:737:2: W0222: Signature differs from overridden 'compute_mask' method (signature-differs)\r\n    tensorflow/python/keras/layers/wrappers.py:771:18: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\n    tensorflow/python/keras/layers/wrappers.py:780:4: C0415: Import outside toplevel (tensorflow.python.keras.layers.deserialize) (import-outside-toplevel)\r\n\r\n    ------------------------------------------------------------------\r\n    Your code has been rated at 9.43/10 (previous run: 9.43/10, +0.00)\r\n    ```\r\n    </details>\r\n\r\n1. Tests on CPU\r\n    <details>\r\n    <summary>CPU test results</summary>\r\n    <br>\r\n\r\n    ```\r\n    bazel test //tensorflow/python/keras/layers\r\n\r\n    ...\r\n\r\n    Target //tensorflow/python/keras/layers:layers up-to-date (nothing to build)\r\n    INFO: Elapsed time: 6198.303s, Critical Path: 511.08s\r\n    INFO: 12919 processes: 12919 local.\r\n    INFO: Build completed successfully, 13032 total actions\r\n    INFO: Build completed successfully, 13032 total actions\r\n    ```\r\n    </details>\r\n\r\n1. Tests with GPU support\r\n    <details>\r\n    <summary>GPU test results</summary>\r\n    <br>\r\n\r\n    ```\r\n    export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\r\n    export flags=\"--config=opt --config=cuda -k\"\r\n    bazel test ${flags} //tensorflow/python/keras/layers\r\n\r\n    ...\r\n\r\n    Target //tensorflow/python/keras/layers:layers up-to-date (nothing to build)\r\n    INFO: Elapsed time: 6604.314s, Critical Path: 494.30s\r\n    INFO: 12923 processes: 12923 local.\r\n    INFO: Build completed successfully, 13036 total actions\r\n    INFO: Build completed successfully, 13036 total actions\r\n    ```\r\n    </details>", "@ffent  Can you please resolve conflicts? Thanks!", "@ffent  Any update on this PR? Please. Thanks!", "Resolved conflicts and ran unit tests.", "Any update on this? I am really interested to see this code merged.", "@qlzh727 are there any updates on this?", "@ffent  Can you please check @qlzh727's comments and keep us posted ? Thanks!", "@ffent Any update on this PR? Please. Thanks!", "Added requested changes and successfully ran style checks, sanity tests and unit tests.", "@qlzh727 I fixed the issue and ran all tests again. The results can be found in the following.\r\n\r\n<details>\r\n<summary>Unit test results</summary>\r\n<br>\r\n\r\n```\r\nroot@5a89dc60ae35:/tensorflow# /usr/bin/python3 /tensorflow/tensorflow/python/keras/layers/wrappers_test.py\r\n2020-11-12 12:57:30.438524: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2020-11-12 12:57:30.438543: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nRunning tests under Python 3.6.9: /usr/bin/python3\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_batchnorm\r\n2020-11-12 12:57:31.734250: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-12 12:57:31.734383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-12 12:57:31.734400: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: UNKNOWN ERROR (-1)\r\n2020-11-12 12:57:31.734417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 5a89dc60ae35\r\n2020-11-12 12:57:31.734422: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 5a89dc60ae35\r\n2020-11-12 12:57:31.734498: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n2020-11-12 12:57:31.734531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\r\n2020-11-12 12:57:31.734726: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-12 12:57:31.735186: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-12 12:57:33.090056: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:126] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-12 12:57:33.115682: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599990000 Hz\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_batchnorm): 1.46s\r\nI1112 12:57:33.189285 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_batchnorm): 1.46s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_batchnorm\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_learning_phase\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_learning_phase): 0.09s\r\nI1112 12:57:33.285387 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_learning_phase): 0.09s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_learning_phase\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager): 0.17s\r\nI1112 12:57:33.456924 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager): 0.17s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph): 0.03s\r\nI1112 12:57:33.487650 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph): 0.03s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_output_shape_return_types_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager): 0.02s\r\nI1112 12:57:33.504559 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager): 0.02s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph): 0.01s\r\nI1112 12:57:33.513795 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph): 0.01s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_reshape_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_set_static_shape\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_set_static_shape): 0.02s\r\nI1112 12:57:33.536152 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_set_static_shape): 0.02s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_set_static_shape\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_trainable\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_trainable): 0.02s\r\nI1112 12:57:33.555684 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_trainable): 0.02s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_trainable\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_different_time_shapes\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_different_time_shapes): 0.03s\r\nI1112 12:57:33.582293 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_different_time_shapes): 0.03s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_different_time_shapes\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions): 0.0s\r\nI1112 12:57:33.586338 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions): 0.0s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_invalid_dimensions\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager): 0.51s\r\nI1112 12:57:34.094254 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager): 0.51s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function): 0.98s\r\nI1112 12:57:35.074781 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function): 0.98s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors\r\nWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:36.071961 139973428025152 def_function.py:126] 5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors): 1.0s\r\nI1112 12:57:36.078145 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors): 1.0s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mask_first_implementation_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape\r\n1/1 [==============================] - 2s 2s/step - loss: 0.5973\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape): 1.95s\r\nI1112 12:57:38.034603 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape): 1.95s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masked_embedding_and_unspecified_shape\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n2/2 [==============================] - 0s 895us/step - loss: 3.4612\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.33s\r\nI1112 12:57:38.368421 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager): 0.33s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph\r\nTrain on 10 samples\r\n2020-11-12 12:57:38.483281: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-12 12:57:38.488653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:251] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n10/10 [==============================] - 0s 5ms/sample - loss: 7.3295\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph): 0.19s\r\nI1112 12:57:38.555591 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph): 0.19s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_masking_layer_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager\r\nWARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d78368a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:38.763795 139973428025152 def_function.py:126] 6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d78368a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/test_util.py:2560: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n  return np.array(a)\r\n4/4 [==============================] - 0s 14ms/step - loss: 0.7001 - time_distributed_loss: 0.3070 - time_distributed_1_loss: 0.3931\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager): 0.31s\r\nI1112 12:57:38.869727 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager): 0.31s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function\r\nWARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9c060620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:39.028650 139973428025152 def_function.py:126] 7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9c060620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787db8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:39.092951 139973428025152 def_function.py:126] 8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787db8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n4/4 [==============================] - 0s 856us/step - loss: 0.7001 - time_distributed_loss: 0.3070 - time_distributed_1_loss: 0.3931\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function): 0.69s\r\nI1112 12:57:39.556551 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function): 0.69s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors\r\nWARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d942ab9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:39.717341 139973428025152 def_function.py:126] 9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d942ab9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9412ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:39.814304 139973428025152 def_function.py:126] 10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9412ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d941ac8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:40.320980 139973428025152 def_function.py:126] 5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d941ac8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n4/4 [==============================] - 0s 827us/step - loss: 0.7001 - time_distributed_loss: 0.3070 - time_distributed_1_loss: 0.3931\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors): 0.77s\r\nI1112 12:57:40.325439 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors): 0.77s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_mimo_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager): 0.0s\r\nI1112 12:57:40.328447 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function): 0.0s\r\nI1112 12:57:40.330203 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors): 0.0s\r\nI1112 12:57:40.331420 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayerscoreDense_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager): 0.0s\r\nI1112 12:57:40.332417 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function): 0.0s\r\nI1112 12:57:40.333328 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors): 0.0s\r\nI1112 12:57:40.334386 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors): 0.0s\r\n[  SKIPPED ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_test_layer_classtensorflowpythonkeraslayersrecurrentLSTM_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d941acea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:40.471971 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d941acea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d78157378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:40.554548 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d78157378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager): 0.22s\r\nI1112 12:57:40.559378 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager): 0.22s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_eager\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9c2dba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:40.821092 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d9c2dba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d941306a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:40.900738 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d941306a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function): 0.35s\r\nI1112 12:57:40.905517 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function): 0.35s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function\r\n[ RUN      ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d783680d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:41.061782 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d783680d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787db598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:41.137290 139973428025152 def_function.py:126] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d787db598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors): 0.24s\r\nI1112 12:57:41.141960 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors): 0.24s\r\n[       OK ] TimeDistributedTest.test_TimeDistributed_with_ragged_input_with_batch_size_v2_function_use_keras_tensors\r\n[ RUN      ] TimeDistributedTest.test_regularizers\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_regularizers): 0.03s\r\nI1112 12:57:41.172101 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_regularizers): 0.03s\r\n[       OK ] TimeDistributedTest.test_regularizers\r\n[ RUN      ] TimeDistributedTest.test_session\r\n[  SKIPPED ] TimeDistributedTest.test_session\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_conv2d\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ntime_distributed (TimeDistri (None, 2, 4, 4, 5)        65        \r\n_________________________________________________________________\r\nactivation (Activation)      (None, 2, 4, 4, 5)        0         \r\n=================================================================\r\nTotal params: 65\r\nTrainable params: 65\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_conv2d): 0.22s\r\nI1112 12:57:41.387849 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_conv2d): 0.22s\r\n[       OK ] TimeDistributedTest.test_timedistributed_conv2d\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_dense_test_mode_eager\r\nWARNING:tensorflow:5 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c5dd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:41.591609 139973428025152 def_function.py:126] 5 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c5dd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 158ms/step - loss: 0.3989\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_eager): 0.21s\r\nI1112 12:57:41.595285 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_eager): 0.21s\r\n[       OK ] TimeDistributedTest.test_timedistributed_dense_test_mode_eager\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_dense_test_mode_graph\r\nTrain on 10 samples\r\n2020-11-12 12:57:41.685762: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n10/10 [==============================] - 0s 4ms/sample - loss: 2.5081\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_graph): 0.13s\r\nI1112 12:57:41.730646 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_dense_test_mode_graph): 0.13s\r\n[       OK ] TimeDistributedTest.test_timedistributed_dense_test_mode_graph\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_invalid_init\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_invalid_init): 0.0s\r\nI1112 12:57:41.732362 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_invalid_init): 0.0s\r\n[       OK ] TimeDistributedTest.test_timedistributed_invalid_init\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_stacked\r\nWARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c573488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:42.008131 139973428025152 def_function.py:126] 5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c573488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 223ms/step - loss: 0.3009\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_stacked): 0.28s\r\nI1112 12:57:42.010180 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_stacked): 0.28s\r\n[       OK ] TimeDistributedTest.test_timedistributed_stacked\r\n[ RUN      ] TimeDistributedTest.test_timedistributed_static_batch_size\r\nWARNING:tensorflow:6 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c1c8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nW1112 12:57:42.209169 139973428025152 def_function.py:126] 6 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4d9c1c8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n1/1 [==============================] - 0s 157ms/step - loss: 0.3989\r\nINFO:tensorflow:time(__main__.TimeDistributedTest.test_timedistributed_static_batch_size): 0.2s\r\nI1112 12:57:42.211110 139973428025152 test_util.py:2076] time(__main__.TimeDistributedTest.test_timedistributed_static_batch_size): 0.2s\r\n[       OK ] TimeDistributedTest.test_timedistributed_static_batch_size\r\n----------------------------------------------------------------------\r\nRan 36 tests in 10.482s\r\n\r\nOK (skipped=7)\r\n```\r\n </details>\r\n\r\n\r\n<details>\r\n<summary>Style check results</summary>\r\n<br>\r\n\r\n```\r\nroot@5a89dc60ae35:/tensorflow# pylint --rcfile=tensorflow/tools/ci_build/pylintrc tensorflow/python/keras/layers/wrappers_test.py \r\n************* Module tensorflow.python.keras.layers.wrappers_test\r\ntensorflow/python/keras/layers/wrappers_test.py:48:0: C0115: Missing class docstring (missing-class-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:54:4: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:71:2: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:82:18: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:89:21: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:104:2: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:111:0: C0115: Missing class docstring (missing-class-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:114:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:156:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:171:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:187:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:199:2: C0103: Method name \"test_TimeDistributed_learning_phase\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:210:2: C0103: Method name \"test_TimeDistributed_batchnorm\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:210:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:230:2: C0103: Method name \"test_TimeDistributed_trainable\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:241:2: C0103: Method name \"test_TimeDistributed_with_masked_embedding_and_unspecified_shape\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:241:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:274:2: C0103: Method name \"test_TimeDistributed_with_masking_layer\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:274:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:296:2: C0103: Method name \"test_TimeDistributed_with_different_time_shapes\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:296:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:310:2: C0103: Method name \"test_TimeDistributed_with_invalid_dimensions\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:319:2: C0103: Method name \"test_TimeDistributed_reshape\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:319:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:323:6: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:328:20: W0212: Access to a protected member _always_use_reshape of a client class (protected-access)\r\ntensorflow/python/keras/layers/wrappers_test.py:333:21: W0212: Access to a protected member _always_use_reshape of a client class (protected-access)\r\ntensorflow/python/keras/layers/wrappers_test.py:337:21: W0212: Access to a protected member _always_use_reshape of a client class (protected-access)\r\ntensorflow/python/keras/layers/wrappers_test.py:340:2: C0103: Method name \"test_TimeDistributed_output_shape_return_types\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:340:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:344:6: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:356:16: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:362:16: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:377:2: C0103: Method name \"test_TimeDistributed_with_mask_first_implementation\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:377:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:410:2: C0103: Method name \"test_TimeDistributed_with_ragged_input\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:410:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:424:4: W0212: Access to a protected member _run_eagerly of a client class (protected-access)\r\ntensorflow/python/keras/layers/wrappers_test.py:432:4: W0212: Access to a protected member _run_eagerly of a client class (protected-access)\r\ntensorflow/python/keras/layers/wrappers_test.py:440:2: C0103: Method name \"test_TimeDistributed_with_ragged_input_with_batch_size\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:440:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:468:2: C0103: Method name \"test_TimeDistributed_set_static_shape\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:476:2: C0103: Method name \"test_TimeDistributed_with_mimo\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:476:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:480:4: C0115: Missing class docstring (missing-class-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:483:8: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:487:6: W0235: Useless super delegation in method 'build' (useless-super-delegation)\r\ntensorflow/python/keras/layers/wrappers_test.py:488:8: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:490:6: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:533:0: C0115: Missing class docstring (missing-class-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:537:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:582:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:600:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:632:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:663:2: C0103: Method name \"test_Bidirectional_merged_value\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:663:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:726:2: C0103: Method name \"test_Bidirectional_with_time_major_input\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:726:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:759:2: C0103: Method name \"test_Bidirectional_dropout\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:759:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:785:2: C0103: Method name \"test_Bidirectional_state_reuse\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:785:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:813:2: C0103: Method name \"test_Bidirectional_state_reuse_with_np_input\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:813:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:830:2: C0103: Method name \"test_Bidirectional_trainable\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:830:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:842:2: C0103: Method name \"test_Bidirectional_updates\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:842:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:860:2: C0103: Method name \"test_Bidirectional_losses\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:860:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:876:2: C0103: Method name \"test_Bidirectional_with_constants\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:876:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:917:2: C0103: Method name \"test_Bidirectional_with_constants_layer_passing_initial_state\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:917:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:970:2: C0103: Method name \"test_Bidirectional_output_shape_return_types\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:970:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:974:6: W0221: Parameters differ from overridden 'call' method (arguments-differ)\r\ntensorflow/python/keras/layers/wrappers_test.py:985:16: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:991:16: R1725: Consider using Python 3 style super() without arguments (super-with-arguments)\r\ntensorflow/python/keras/layers/wrappers_test.py:1005:2: C0103: Method name \"test_Bidirectional_last_output_with_masking\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:1005:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1038:2: C0103: Method name \"test_Bidirectional_sequence_output_with_masking\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:1038:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1071:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1113:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1133:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1146:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1159:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1176:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1198:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1221:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1246:2: C0103: Method name \"test_Bidirectional_ragged_input\" doesn't conform to '^(?:(?P<exempt>__[a-z0-9_]+__|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$' pattern (invalid-name)\r\ntensorflow/python/keras/layers/wrappers_test.py:1246:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1295:2: C0116: Missing function or method docstring (missing-function-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1324:0: C0115: Missing class docstring (missing-class-docstring)\r\ntensorflow/python/keras/layers/wrappers_test.py:1332:4: W0612: Unused variable 'wrapper_from_config' (unused-variable)\r\ntensorflow/python/keras/layers/wrappers_test.py:1339:2: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\n\r\n------------------------------------------------------------------\r\nYour code has been rated at 8.85/10 (previous run: 8.85/10, +0.00)\r\n```\r\n </details>"]}, {"number": 40992, "title": "Run micro speech example on Apollo 2", "body": "Sorry to bother you.\r\n\r\nI tried to run micro speech example provided by Tensorflow Lite on Apollo 2 blue EVB but failed.\r\n\r\nOnce I load this code, the function failed.\r\n\r\n![image](https://user-images.githubusercontent.com/61425756/86256122-d5459700-bbaf-11ea-9619-417071056778.png)\r\n\r\nI would like to ask if Apollo 2 blue has C++11 compatibility.\r\n\r\nOr could you tell me why this happen?\r\n\r\nThank you!", "comments": ["@uf19414 \r\nPlease share the tensorflow version and simple indented stand alone code to replicate the  issue or if possible share a colab gist with error to analyse.", "> @uf19414\r\n> Please share the tensorflow version and simple indented stand alone code to replicate the issue or if possible share a colab gist with error to analyse.\r\n\r\nThe tensorflow version is 2.0. \r\n\r\n![image](https://user-images.githubusercontent.com/61425756/86383191-f37dc680-bc85-11ea-9207-e28123d75b70.png)\r\n\r\n\r\nThere is not  error when debugging and the model could run normally when simulating.\r\n\r\nBut when I load the Tensorflow code to Apollo 2 blue EVB, the LEDs dont flash.\r\n\r\nI tried deleting the \"Tensoflow CNN\" to check other function. LED parts and Deep sleep parts can work without Tensorflow CNN parts.\r\n\r\nTherefore I guess there must be something wrong with CNN. But I dont know how to correct it.\r\n\r\nCould you tell me why this happen? Thank you!\r\n\r\nHere is the whole code.\r\n\r\n![image](https://user-images.githubusercontent.com/61425756/86382874-d77a2500-bc85-11ea-91d2-688423be42b5.png)\r\n\r\n", "@uf19414 Could you please try on the latest stable version of **TF 2.6.0** and let us know if it is still an issue ?For more details please refer to the [micro_examples](https://www.tensorflow.org/lite/microcontrollers/get_started_low_level) .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40991, "title": "SavedModel file does not exist at: \u202a try.h5/{saved_model.pbtxt|saved_model.pb}", "body": "Hi, I am trying to load a saved model using load_model('path') but i am getting the following error :\r\n\r\n**SavedModel file does not exist at: \u202aC:\\Users\\YASH\\try.h5/{saved_model.pbtxt|saved_model.pb}**\r\nThe path provided is correct.\r\ni see the same issue raises at #22480 but the solutions provided there didn't worked for me.\r\n\r\nsystem info:\r\nOS: windows 10\r\npython version : '3.7.7'\r\ntensorflow version :  '2.2.0' \r\n\r\nhere is a simpler version of code : \r\nfrom tensorflow.keras.applications.vgg16 import VGG16\r\nmodel = VGG16(weights='imagenet', include_top=True)\r\nmodel.save('try.h5')\r\n\r\nafter saving it when i tried to load it again using the following code:\r\nmod = load_model('\u202aC:\\\\Users\\\\YASH\\\\try.h5')\r\ni got the following error:\r\n\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\n<ipython-input-9-455ec8db1264> in <module>\r\n----> 1 mod = load_model('\u202aC:\\\\Users\\\\YASH\\\\try.h5')\r\n\r\n~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py in load_model(filepath, custom_objects, compile)\r\n    187       filepath = str(filepath)\r\n    188     if isinstance(filepath, six.string_types):\r\n--> 189       loader_impl.parse_saved_model(filepath)\r\n    190       return saved_model_load.load(filepath, compile)\r\n    191 \r\n\r\n~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py in parse_saved_model(export_dir)\r\n    111                   (export_dir,\r\n    112                    constants.SAVED_MODEL_FILENAME_PBTXT,\r\n--> 113                    constants.SAVED_MODEL_FILENAME_PB))\r\n    114 \r\n    115 \r\n\r\nOSError: SavedModel file does not exist at: \u202aC:\\Users\\YASH\\try.h5/{saved_model.pbtxt|saved_model.pb}\r\n", "comments": ["@yash88600 \r\nPlease share the code for us to replicate the issue faced, or is possible share colab gist with the code and error faced.", "i have already mentioned the code above.\r\ni have trained a model few months back, now when i tried to load it using load_model() i am getting the mentioned error.\r\n\r\nso i tried a simple code :\r\nfrom tensorflow.keras.applications.vgg16 import VGG16\r\nmodel = VGG16(weights='imagenet', include_top=True)\r\nmodel.save('try.h5')\r\n\r\nafter saving it, i tried to load it again using the following code:\r\nmod = load_model('\u202aC:\\\\Users\\\\YASH\\\\try.h5')\r\n\r\nbut i am getting the mentioned error in this code too.\r\n", "@yash88600 Without reproducing this issue, its hard for us to debug it. Please provide us the full reproducible code for us to reproduce this issue.Thanks!", "Hey,\r\nI deleted the existing Tensorflow-GPU virtual environment (inside Anaconda Navigator) and then created a new one.\r\nDoing so solved this problem for me.\r\nThanks for the help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40991\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40991\">No</a>\n", "> Hey,\r\n> i got the issue resolved but recreating the TensorFlow environment.\r\n> Thanks for the help!\r\n\r\nCould you please elaborate?", "\r\n  File \"/home/birds/birdpred/pred.py\", line 31, in <module>\r\n    model_yn1 = tf.keras.models.load_model('./yn1_model.h5')\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\", line 186, in load_model\r\n    loader_impl.parse_saved_model(filepath)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 110, in parse_saved_model\r\n    raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\r\nOSError: SavedModel file does not exist at: ./yn1_model.h5/{saved_model.pbtxt|saved_model.pb}\r\n\r\n`/usr/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py`:\r\n```\r\n    if (h5py is not None and (\r\n        isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\r\n      return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n```\r\n\r\nfor me `h5py is None` because 2.10.0 is broken after recent archlinux update. New version (3.1.0) does not work because of #44467", "> Hey,\r\n> i got the issue resolved but recreating the TensorFlow environment.\r\n> Thanks for the help!\r\n\r\nHow did you resolve it? I am facing the same issue.", "I was just searching for solving this error.\r\n\r\n## The issue\r\n\r\nI have two scripts, `batch.py` and `analysis.py` - in  `analysis.py` I do the following (roughly) inside of a class:\r\n\r\n        class A:\r\n              def do(self, model_fn, images):\r\n                   from tensorflow.keras.models import load_model\r\n                   print(model_fn, os.path.exists(model_fn)) # True --> Exists!!!\r\n                   model = load_model(model_fn, compile=False)\r\n                   ....\r\n\r\nIn `batch.py` I am doing then the following:\r\n\r\n    a = A()\r\n    a.do(model_fn, images)\r\n\r\nThis gives me the following error:\r\n\r\n    OSError: SavedModel file does not exist at: C:\\Path\\To\\File\\model.h5\\{saved_model.pbtxt|saved_model.pb}\r\n\r\n## Solving the issue\r\n\r\nIn `batch.py`, I just import\r\n\r\n    import tensorflow as tf\r\n\r\nat the beginning of the script, and et voila, it works like a charm!\r\nI think this is what @yash88600 was talking about."]}, {"number": 40990, "title": "[WIP] Adding Mixout module", "body": "the pr is to solve issue #40983. Mixout module is written resembling the `tf.nn.dropout`\r\nI'm still figuring how to do the TF [unit test](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests), but the module is tested out of the framework. Will update once the unit test is all past", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40990) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40990) for more info**.\n\n<!-- ok -->", "yup sure! Didn't know this flow before. will resend a pr there. \r\n\r\nShall I close this pr and the issue now?", "Yes, please. Thanks!\n\nOn Wed, Jul 1, 2020 at 5:56 PM Crystina <notifications@github.com> wrote:\n\n> yup sure! Didn't know this flow before. will resend a pr there.\n>\n> Shall I close this pr and the issue now?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/40990#issuecomment-652717697>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRK5J43UMX3HYCP4FHLRZPLLPANCNFSM4ONOQRJA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 40989, "title": "_MklSoftmax 2-2.5x Slower in 1.15 Compared to 1.14 and 1.13", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `intelaipg/intel-optimized-tensorflow:1.14.0-mkl-py3` and `intelaipg/intel-optimized-tensorflow:1.15.2-mkl-py3`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): see OS\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nWe found that the `_MklSoftmax` operation is quite a bit slower in 1.15 than it was in Tf 1.13 and 1.14, about 2-2.5x worse. \r\n\r\n**Describe the expected behavior**\r\nComparable speed to previous versions.\r\n\r\n**Standalone code to reproduce the issue**\r\nn/a but confirmed by @NeoZhangJianyu (see https://github.com/tensorflow/tensorflow/issues/39851#issuecomment-652150250)\r\n\r\n**Other info / logs**\r\nn/a\r\n", "comments": ["@pks \r\n\r\nWill it be possible to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "We found that in our implementation of a Transformer model, which I unfortunately cannot share. @NeoZhangJianyu said that he could reproduce it. He could possibly add a minimal example.", "@ravikyram @pks \r\nYes, I have reproduced the issue.\r\nI have reported this issue to dev team. The checking is ongoing.\r\n\r\nThank you!", "@NeoZhangJianyu Is there any progress on this?", "@pks It's still on going. I will push to confirm and fix.", "@pks \r\nWe got the answer from dev team:\r\n\r\nThe TF 1.15 uses the mkldnn 0.20 version, which will run new path (avx512 impl on CLX or SKX), while TF 1.14 with 0.18 mkldnn will run a reference implementation.\r\n\r\nThe new path will take much more time for primitive creating than the latter path. \r\nIt's the root cause why we have poor performance for SoftMax on TF 1.15, especially for small problem size.\r\n\r\nAnd TF master branch has enabled the primitive cache for SoftMax, so there's no such performance issue.\r\n\r\nThis issue has been fixed in TF 2.2.0 and later. Please use TF 2.2.0 and later.\r\nWe can't port this new feature back to TF 1.15 because Google has cut off the updates for that branch.", "Thanks a lot for the investigation! Closing this issue for now.", "@NeoZhangJianyu That's unfortunate, since the softmax is a pretty central operation in neural networks (especially Transformers).\r\n\r\nWhat about machines that do not have AVX-512 extensions (Haswell?), will those run the reference implementation? And is there a way to enable the primitive cache when building Tensorflow from source? Switching to Tensorflow 2 is a longer endeavor if one wants to directly run graphs.", "@pks \r\nFor the machine without AVX-512, the issue is present too: it uses AVX2.\r\nI will check for any work around and feedback later.\r\n\r\nAdditional, it's recommended to upgrade to Tf 2.x. \r\nFor TF 1.15: `This is the last 1.x release for TensorFlow. We do not expect to update the 1.x branch with features, although we will issue patch releases to fix vulnerabilities for at least one year.` -- refer to https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md\r\n", "@pks\r\nI checked with the designer. There is no simple way to merge back the solution from TF 2.x to TF 1.15.\r\n", "@NeoZhangJianyu Alright, thanks for checking!", "@pks There is solution for this issue now.\r\nIntel release a special version: Intel TF 1.15.0up1 today. It includes many bugs fix of TF2.x.\r\nI have tested the MKLSoftmax issue. The performance is increased than 1.15 in small size (like 1000).  Note, all of releases have same performance in big size (like 100,000).\r\n\r\nBut it is still not same as TF 1.14.\r\nTF 2.2.0-MKL is with same performance of TF 1.14.\r\n\r\nPlease build it from source code by following guide:\r\n```\r\n$ git clone https://github.com/Intel-tensorflow/tensorflow.git  \r\n$ git checkout v1.15.0up1\r\n\r\nbazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=mkl --define build_with_mkl_dnn_v1_only=true --copt=-DENABLE_INTEL_MKL_BFLOAT16 --copt=-march=native //tensorflow/tools/pip_package:build_pip_package \r\n\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\npip install /tmp/tensorflow_pkg/tensorflow-xxx-xxx.whl\r\n```\r\n\r\n", "Thanks @NeoZhangJianyu! Unfortunately I don't seem to be able to build the wheel from this branch:\r\n```\r\n> bazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=mkl --define build_with_mkl_dnn_v1_only=true --copt=-DENABLE_INTEL_MKL_BFLOAT16 --copt=-march=native //tensorflow/tools/pip_package:build_pip_package\r\n\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=127\r\nINFO: Reading rc options for 'build' from ~/intel_tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Found applicable config definition build:mkl in file ~/intel_tensorflow/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true --copt=-DENABLE_INTEL_MKL_BFLOAT16 -c opt\r\nWARNING: ~/intel_tensorflow/tensorflow/core/BUILD:1091:11: in linkstatic attribute of cc_library rule //tensorflow/core:framework_lite: setting 'linkstatic=1' is recommended if there are no object files\r\nWARNING: ~/intel_tensorflow/tensorflow/core/BUILD:2428:11: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files\r\nERROR: ~/intel_tensorflow/tensorflow/core/common_runtime/eager/BUILD:277:11: in nocopts attribute of cc_library rule //tensorflow/core/common_runtime/eager:mkl_eager_op_rewrite: This attribute was removed. See https://github.com/bazelbuild/bazel/issues/8706 for details.\r\nERROR: ~/tf115/intel_tensorflow/tensorflow/core/common_runtime/eager/BUILD:277:11: in nocopts attribute of cc_library rule //tensorflow/core/common_runtime/eager:mkl_eager_op_rewrite: This attribute was removed. See https://github.com/bazelbuild/bazel/issues/8706 for details.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 13.751s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (402 packages loaded, 17775 targets configured)\r\n    Fetching @llvm; Restarting.\r\n```\r\n\r\nThis seems to be a problem with bazel. Which version should I be using?\r\n```\r\n> bazel --version\r\nbazel 3.4.1\r\n```\r\n\r\n", "@pks My bazel is 3.1.0.\r\n\r\nThere is binary release now, please install the TF 1.15.0up1 by PIP:\r\n`pip install https://storage.googleapis.com/intel-optimized-tensorflow/intel_tensorflow-1.15.0up1-cp36-cp36m-manylinux2010_x86_64.whl `", "@NeoZhangJianyu Thanks a lot -- this resolves our problem. The speed is even better than what we see with 1.14!\r\n\r\nEdit: Almost a ~~25~~20% improvement over stock 1.15.2 from the Intel image.", "@pks It's great news! \ud83d\udc4d \r\nThank you support! ", "@NeoZhangJianyu Which is the earliest CPU generation the wheel will work with? ", "@pks\r\nIt will work well with the CPU supports AVX2 & AVX512. AVX512 could speed up more.\r\nThe info could be searched in https://ark.intel.com/content/www/us/en/ark.html#@Processors\r\n  ", "@pks \r\nHi,\r\n   It's great to know TF 1.15.0up1 to fix your issue.\r\n  \r\n   I want to collect the customer to expect/use TF 1.15.0up1.\r\n   Could you share your company name to me?\r\n   You could send to my email: jianyu.zhang@intel.com.\r\n\r\n   Thank you!"]}, {"number": 40988, "title": "Too much information of GPU in output while running simple code", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nPython 3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-07-01 18:46:30.457181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n>>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n2020-07-01 18:49:32.218612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-07-01 18:49:32.251014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-07-01 18:49:32.258807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-07-01 18:49:32.265844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-07-01 18:49:32.272713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-07-01 18:49:32.277604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-07-01 18:49:32.285003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-07-01 18:49:32.292380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-07-01 18:49:32.305864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-07-01 18:49:32.310903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-07-01 18:49:32.314028: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-07-01 18:49:32.326897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21c2acb81f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-01 18:49:32.333259: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-07-01 18:49:32.337469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-07-01 18:49:32.346985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-07-01 18:49:32.351459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-07-01 18:49:32.356745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-07-01 18:49:32.362342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-07-01 18:49:32.366372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-07-01 18:49:32.371184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-07-01 18:49:32.377026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-07-01 18:49:32.381145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-07-01 18:49:32.930263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-07-01 18:49:32.938544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-07-01 18:49:32.941809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-07-01 18:49:32.944603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4602 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-07-01 18:49:32.955792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21c539aa230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-07-01 18:49:32.961195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060, Compute Capability 7.5\r\n>>> b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\n>>> c = tf.matmul(a, b)\r\n2020-07-01 18:51:13.160931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n>>> print(c)\r\ntf.Tensor(\r\n[[22. 28.]\r\n [49. 64.]], shape=(2, 2), dtype=float32)\r\n>>>\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["@krn-sharma,\r\nPlease take a look at [this](https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information) similar StackOverflow issue and let us know if it helps. Thanks!", "Yeah it worked but is their any way to permanently disable it? ", "@krn-sharma,\r\nPlease try changing the default Python log level and check if it works. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40987, "title": "properly setting up and compiling in windows with tensorflow c api", "body": "https://www.tensorflow.org/install/lang_c\r\n\r\nAdd,window eg with at least mingw or cmake,or simply from cmd line/*terminal* with gcc/g++?\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nWell,you see i wanted to make sure when I use it in production in the years to come I can make sure.\r\nI as an individual can make it work even if I am stranded on an island with no internet.\r\nWith probably only a disk filled with backup of binaries and backup of OS in iso.etc. \r\n\r\nIs the link to the source code correct?yes\r\n\r\nAre all parameters defined and formatted correctly?yes\r\n\r\nAre return values defined?yes\r\n\r\nI need help in getting it to work.After getting it to work. Then ,well I will contribute respectively.\r\n\r\nMy trial,as known we need to setup path point to the compiler path/*area.Then we declare lib included files right?\r\nThen we go to source code,take all bam,compiled piece of essence.\r\n\r\nBelow is my attempt.well second attempt\r\n\r\nD:\\Coding\\C\\ALLCinone>set PATH=D:\\Coding\\C\\ALLCinone\\MinGW64\\bin;D:\\Coding\\C\\ALLCinone\\MinGW64\\x86_64-w64-mingw32\\bin;C:\\Windows\\system32;C:\\Windows;(Bloated Winapps path don't need to bother)\r\n\r\nD:\\Coding\\C\\ALLCinone>cmd /k\"set includepath=E:\\Coding\\C\\WinGW\\include;E:\\Coding\\C\\WinGW\\msys\\1.0\\include\"\r\n\r\nD:\\Coding\\C\\ALLCinone>cd D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include>set includepath=%includepath%;%cd%\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include>cd D:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>gcc hello_tf.c -l\"%includepath%\" -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>%includepath%\r\nThe system cannot find the drive specified.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>echo %includepath%\r\nE:\\Coding\\C\\WinGW\\include;E:\\Coding\\C\\WinGW\\msys\\1.0\\include;D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>cd D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\\tensorflow\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\\tensorflow>set includepath=%includepath%;%cd%\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\\tensorflow>cd D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\\tensorflow\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\\tensorflow>cd D:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>gcc hello_tf.c -l\"%includepath%\" -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>gcc hello_tf.c -L\"%includepath%\" -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>g++ hello_tf.c -L\"%includepath%\" -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>g++ hello_tf.c -I\"%includepath%\" -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>g++ hello_tf.c -I%includepath% -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>g++ hello_tf.c -I%includepath% -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>g++ hello_tf.c -I %includepath% -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\test2>#(someone please save me from this hell.w)\r\n\r\n\r\n", "comments": ["test3:\r\n\r\nD:\\Coding\\C\\ALLCinone>set PATH=D:\\Coding\\C\\ALLCinone\\MinGW64\\bin;D:\\Coding\\C\\ALLCinone\\MinGW64\\x86_64-w64-mingw32\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Users\\kami\\AppData\\Local\\Microsoft\\WindowsApps;\r\n\r\nD:\\Coding\\C\\ALLCinone>cmd /k\"set includepath=D:\\Coding\\C\\ALLCinone\\MinGW64\\include;D:\\Coding\\C\\ALLCinone\\cmake-3.17.1\\Utilities\"\r\n\r\nD:\\Coding\\C\\ALLCinone>d D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\r\n'd' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\nD:\\Coding\\C\\ALLCinone>cd D:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include>set includepath=%includepath%;%cd%\r\n\r\nD:\\Coding\\C\\3rdpartylib\\libtensorflow-gpu-windows-x86_64-\\include>cd D:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3>gcc hello_tf.c -ltensorflow -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3>gcc hello_tf.c -ltensorflow -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3>gcc hello_tf.c -l%includepath% -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3>gcc hello_tf.c -L%includepath% -o hello_tf\r\nhello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n\r\nD:\\Coding\\C\\ljwversrccodes\\testtensorflow\\v3>gg.", "@LJWxyz \r\nAppologies for delayed response, could you please check [this comment](https://github.com/tensorflow/tensorflow/issues/41362#issuecomment-658301003) according to which this issue is resolved.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40986, "title": "Frozen TF2.0 model to TF1.x pb model", "body": "Linux, Tensorflow2.0\r\ni also want to convert TF2.0 model() to TF1.x pb model to inference C++, but i meet another problem. please read the page [https://github.com/esdu/misc/blob/master/bug_report_lstm_freeze.ipynb], i get same problem, \r\nif use keras.layers.GruCell i whill get \"tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 7 of node prefix/out_model/rnn/while was passed float from prefix/rnn/bias:0 incompatible with expected resource.\"\r\nif use keras.layers.GruCell i whill get \"ValueError: Input 0 of node import/lstm/while/ReadVariableOp/Enter was passed float from import/lstm/kernel:0 incompatible with expected resource.\"", "comments": ["@hahadashi \r\n\r\nI have tried in colab with TF 2.2 .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0841e741547600d63017049f7e4c1d2c/untitled64.ipynb).You are seeing the same behavior?.Thanks!", "> @hahadashi\r\n> \r\n> I have tried in colab with TF 2.2 .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0841e741547600d63017049f7e4c1d2c/untitled64.ipynb).You are seeing the same behavior?.Thanks!\r\n\r\nyes. \r\nin my another demo code,  i try to use keras.layers.GruCell\uff0ci get error message \"tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 7 of node prefix/out_model/rnn/while was passed float from prefix/rnn/bias:0 incompatible with expected resource.\". i think there are similar bug when we want to frozen keras.layers.GruCell or keras.layers.LstmCell to pb. please give some advice to fix these problem. thxs\r\n", "Sorry for the long wait. I am not sure if this is a LSTM problem, or a graph conversion problem. Assigning to @gargn from tf-lite team.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40986\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40986\">No</a>\n"]}, {"number": 40985, "title": "ValueError: Unrolling requires a fixed number of timesteps.", "body": "Hi, I am trying to build a model with tensorflow 2.1.0. I was getting this error in model.fit. Can anyone please let me know how this can be resolved? \r\n\r\ncheckpoint = ModelCheckpoint('test/checkpointv7', monitor='acc', verbose=1, save_best_only=True, mode='max')\r\ncallbacks_list = [checkpoint]\r\nmodel.fit(input_data, output_data,batch_size=2, epochs=20, callbacks=callbacks_list)\r\n\r\nEpoch 1/20\r\n 8/10 [=======================>......] - ETA: 1s - loss: 1.9467 - acc: 0.1915     \r\nEpoch 00001: acc improved from -inf to 0.21429, saving model to test/checkpointv7\r\nTraceback (most recent call last):\r\n  File \"MLtxt2txtv7.py\", line 633, in <module>\r\n    model.fit(input_data, output_data,batch_size=2, epochs=20, callbacks=callbacks_list)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib64/python3.6/contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 302, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 992, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 1029, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\", line 886, in save\r\n    checkpoint_graph_view)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_serialization.py\", line 74, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\", line 142, in list_functions\r\n    self._serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2420, in _list_functions_for_serialization\r\n    .list_functions_for_serialization(serialization_cache))\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\", line 91, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 80, in functions_to_serialize\r\n    serialization_cache).functions_to_serialize)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 95, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\", line 53, in _get_serialized_attributes_internal\r\n    serialization_cache))\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 104, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 162, in wrap_layer_functions\r\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 258, in _replace_child_layer_functions\r\n    serialization_cache).functions)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 95, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 104, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 162, in wrap_layer_functions\r\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 258, in _replace_child_layer_functions\r\n    serialization_cache).functions)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 95, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 104, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 172, in wrap_layer_functions\r\n    '{}_layer_call_and_return_conditional_losses'.format(layer.name))\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 513, in add_function\r\n    self.add_trace(*self._input_signature)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 428, in add_trace\r\n    trace_with_training(True)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 426, in trace_with_training\r\n    fn.get_concrete_function(*args, **kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 557, in get_concrete_function\r\n    return super(LayerCall, self).get_concrete_function(*args, **kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 909, in get_concrete_function\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 534, in wrapper\r\n    ret = method(*args, **kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\", line 113, in wrap_with_training_arg\r\n    lambda: replace_training_and_call(False))\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\", line 112, in <lambda>\r\n    lambda: replace_training_and_call(True),\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\", line 108, in replace_training_and_call\r\n    return wrapped_call(*args, **kwargs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 576, in call_and_return_conditional_losses\r\n    return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\", line 417, in call\r\n    zero_output_for_mask=self.zero_output_for_mask)\r\n  File \"/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 3926, in rnn\r\n    raise ValueError('Unrolling requires a fixed number of timesteps.')\r\nValueError: Unrolling requires a fixed number of timesteps.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40985\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40985\">No</a>\n", "@vyshnavigutta369 \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@vyshnavigutta369 As per the error message and the documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/backend/rnn), you will only encounter this error if in `tf.keras.backend.rnn` the argument `unroll`\u00a0is\u00a0True\u00a0but input timestep is not a fixed number. So make your timestep a fixed number and the issue should be resolved.\r\n\r\nAlso I am closing this issue as it has been inactive for more than 2 weeks. Please add additional comments for us to open this issue again. Thanks!\r\n\r\n"]}, {"number": 40984, "title": "A function that is wrapped with tf.function gives wrong gradients on loss functions that are themselves wrapped by the same decorator", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\n2.2.0\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI have two versions of loss function, one decorated with tf.function and the other not,  and I have two functions that compute the gradients using these two loss functions, one decorate with tf.function and the other not . When I use the gradient function that is not decorate I get the same results for both the loss function. However, when I use the gradient function that is decorated I get different results and in particular I get a wrong result for the loss function that is decorated.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect all of the above to give the same result.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1erNOChp355OTiCwWiizPdjA1OT1s3HYV?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6a0afaa83051077734f18b5032f8ef1c/40984.ipynb). Thanks!", "Hi @borundev, you mentioned that when you use the gradient function that is decorated, you get the wrong result for the loss function that is decorated.\r\n\r\nI'm running your colab and seeing that the different result is for the loss function that is *not* decorated. Can you double check and let me know if I'm reading this correctly?", "Hi @nikitamaia you are right. I must have mistyped it here. When I asked this on [stackoverflow ](https://stackoverflow.com/questions/62428590/gradienttape-gives-different-gradients-depending-on-loss-function-being-decorate) I said \r\n\r\n> Thus, when my outer function is decorated I only get the correct answer from the inner function that is decorated as well. I was under the impression that decorating the outer one (which is the training loop in many applications) is sufficient but here we see its not. \r\n\r\nI apologize for the confusion. \r\n\r\n", "No worries! \r\nUsing from_logits=True in your loss function is more numerically stable (see [note in docs here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/losses.py#L554)) and recommended. If you do that and also remove the softmax from your output layer you should see the same result in all cases.", "@nikitamaia So this is not considered a bug?. ", "Hi @borundev you are correct, it is a bug since the behavior is surprising and from_logits=False does not error out. And I believe this is a duplicate of issue #32895. I will close this issue now so we can track this bug in one place, but feel free to reopen if you don't think it's a duplicate.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40984\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40984\">No</a>\n"]}, {"number": 40983, "title": "adding Mixout module", "body": "**System information**\r\n- TensorFlow version (you are using): tf-1.15\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nMixout is a module proposed [here](https://openreview.net/pdf?id=HkgaETNtDB). In short, it resembles dropout, but rather than setting the randomly selected weights to zero, it replaces them with the weights in the pre-trained model. By doing so it helps to improve the stability in downstream fine-tuning tasks.\r\n\r\n**Will this change the current api? How?**\r\nYes, it would require a new API like `tf.nn.mixout` with similar signature with `tf.nn.dropout`\r\n\r\n**Who will benefit with this feature?**\r\nPeople who wanna use BERT in downstream tasks with small datasets. This feature (as claimed in the paper) improve stability.\r\n\r\n**Any Other info.**\r\nA [pytorch version](https://github.com/bloodwass/mixout) has been provided by the author. ", "comments": []}, {"number": 40982, "title": "UnknownError:  [_Derived_]  CUDNN_STATUS_BAD_PARAM", "body": "# System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen using `mask_zero=True` in `tf.keras.layers.Embedding` in a GPU environment LSTM layers causes:\r\n\r\n```\r\nUnknownError:  [_Derived_]  CUDNN_STATUS_BAD_PARAM\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1496): 'cudnnSetRNNDataDescriptor( data_desc.get(), data_type, layout, max_seq_length, batch_size, data_size, seq_lengths_array, (void*)&padding_fill)'\r\n\t [[{{node cond_17/then/_0/CudnnRNNV3}}]]\r\n\t [[model/time_distributed_1/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_16505]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function -> train_function\r\n```\r\n\r\nFull error trace is attached. \r\n\r\n[error_trace.txt.zip](https://github.com/tensorflow/tensorflow/files/4857504/error_trace.txt.zip)\r\n\r\nHere's how we defined our network:\r\n\r\n```\r\n# Input and embeddings for words\r\nword_in = Input(shape=(max_len, max_len_word,))\r\n\r\n# Word level embedding\r\nemb_word = TimeDistributed(\r\n    Embedding(input_dim=(n_words + 2), \r\n        output_dim=200,\r\n        input_length=max_len_word, \r\n        weights=[get_embedding_matrix(word_index, \r\n            embedding_path, embedding_dim)], \r\n        trainable=False,\r\n        mask_zero=True\r\n\t)\t\r\n)(word_in)\r\n\r\n# Word LSTM to get sent encodings by words\r\nemb_sent = TimeDistributed(LSTM(units=32, return_sequences=False))(emb_word)\r\n\r\nmain_lstm = Bidirectional(LSTM(units=64, return_sequences=True))(emb_sent)\r\nout = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\r\n\r\nmodel = Model([word_in], out)\r\n```\r\n\r\nA few observations:\r\n- When using a CPU environment, this issue does not show up. \r\n- When using `mask_zero=False` this issue does not show up but leads to misleading accuracy as obvious. \r\n\r\n### Source code / logs\r\n[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/b18aeca12e36f0f367e19548b81bf6a7/whats_the_news_model_baseline-1.ipynb). \r\n\r\n", "comments": ["@sayakpaul \r\nCould you please refer to these links and let us know if it helps:\r\n[link](https://stackoverflow.com/questions/58895694/cudnn-status-bad-param-when-trying-to-perform-inference-on-a-lstm-seq2seq-with-m) [link1](https://stackoom.com/question/3z7SY/%E5%B0%9D%E8%AF%95%E5%AF%B9%E5%85%B7%E6%9C%89%E5%B1%8F%E8%94%BD%E8%BE%93%E5%85%A5%E7%9A%84LSTM-Seq-Seq%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86%E6%97%B6-CUDNN-STATUS-BAD-PARAM) [link2](https://github.com/tensorflow/tensorflow/issues/40750#issuecomment-648906371)  #33148 \r\n\r\nI ran the code shared but face different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/db21531d9b70952890839fe424deb0bb/untitled251.ipynb) please provide executable code with all imports and dependencies.", "@Saduf2019 you probably forgot to run the cells in order. I just ran your gist and I did not get any errors. Here's the Gist: https://colab.research.google.com/gist/sayakpaul/74e1e8c553d6f29d7f59f2534c9bf83b/untitled251.ipynb. ", "@qlzh727 any pointers?", "I have fixed the related issue #33148. Please try your code with latest tf-nightly and see if it works. Thanks.", "Sure. Will try. ", "Assuming no news is good news. Closing this bug for now, and please reopen if you still see the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40982\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40982\">No</a>\n"]}, {"number": 40981, "title": "New model from same config not equal", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n```\r\n nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.105\r\n```\r\n- GPU model and memory: Nvidia MX110 2GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"` v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n\r\n\r\n**Describe the current behavior**\r\nI created a basic model and saved its configuration using `get_config()`\r\n**Describe the expected behavior**\r\nI created a new model using the same configuration `tf.keras.Sequential.from_config()` and compared configurations of both, but both were not equal.\r\n**Standalone code to reproduce the issue**\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nimport json\r\nimport numpy as np\r\n\r\n# Build the model\r\n\r\nmodel = Sequential([\r\n    Dense(units=32, input_shape=(32, 32, 3), activation='relu', name='dense_1'),\r\n    Dense(units=10, activation='softmax', name='dense_2')\r\n])\r\nconfig_dict = model.get_config()\r\n\r\nmodel_same_config = tf.keras.Sequential.from_config(config_dict)\r\nprint('Same config:', \r\n      model.get_config() == model_same_config.get_config())\r\nprint('Same value for first weight matrix:', \r\n      np.allclose(model.weights[0].numpy(), model_same_config.weights[0].numpy()))\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@ahmadmustafaanis \r\n\r\nI have tried in colab with TF version 2.2.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/199604647d9093c66c7474be211320e7/untitled63.ipynb).You are also seeing the same behavior?.Thanks!", "Yes, I am seeing same behavior. Instead, It should be\r\n```\r\nSame config: True\r\nSame value for first weight matrix: False\r\n```\r\nBecause we are making it from the same configuration\r\n", "@ahmadmustafaanis \r\n\r\nCan you please try with TF nightly versions and i am not seeing any issue with nightly version.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/c49c67471fd67926420796e11789b98d/untitled63.ipynb).Please verify once and close the issue. Thanks!\r\n", "Yea, It is working in tf nightly. Can you fix it in tf2.2 too?", "@ahmadmustafaanis \r\n\r\nIt is fixed in TF-2.3-rc0 as well.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ad4a2cfdd3201cd5402b6aa32012f794/untitled72.ipynb).You can use TF 2.3.Please,close this issue as the issue was fixed with TF 2.3 release.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40981\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40981\">No</a>\n"]}, {"number": 40980, "title": "tf2.1.0 training efficiency problem ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.7 \r\n- CUDA/cuDNN version: 10.1.0/7.6.4\r\n- GPU model and memory: Tesla V100*4  32478MiB\r\n\r\n\r\n**Describe the current behavior**\r\nI use tf2.1.0 keras API to build network and use tf API to build a semantic segmentation distillation loss. And I find that the training speed is about 42.1 epochs/day. I try to adjust the \"batch size\"\uff0cbut the result is almost the same.\r\n\r\nIf I use tf1.10.0 tf API to build network and loss,  the training speed is about 134  epochs/day.\r\n\r\n**Describe the expected behavior**\r\nTF2.1.0 Training speed is not lower than tf1.10.0.\r\n\r\n**Standalone code to reproduce the issue**\r\nI call function \"pairwise_suprvise\" to calculate my loss(The student_feature/teacher_feature shape is [N, 512, 512, 3]):\r\n\r\nMy code is linked:  https://github.com/chenpengf0223/semantic_segmentation_distillation/blob/master/distillation_loss.py", "comments": ["@chenpengf0223,\r\nIn the code sample, you have provided the function definitions but they are not being called anywhere. Could you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, please upgrade to the latest version of TensorFlow 2.2 and check if you are facing the same issue. Thanks!", "@amahendrakar ,thanks for your reply, I call the function \"pairwise_suprvise\" like this:\r\n RKD_dist_loss, RKD_angle_loss = pairwise_suprvise(feature_map_student, feature_map_teacher, accessible_area_distillation_mask)\r\n\r\nThe shape of \"feature_map_student\" and \"feature_map_teacher\" is [N, 512, 512, 3].\r\n\r\nI find that the training will be 3x times faster if do not call the \"pairwise_suprvise\" function.", "@amahendrakar ,  Thanks for your guidance. I try tf2.2.0\uff0cthe performance is almost the same with tf1. So maybe there is little  problem in tf2.1.0.\r\n\r\nAnother little confusion is about gpu memory:\r\nI use 4 gpus(Tesla V100 (32G) * 4) to train the model.\r\nWhen I set batch_size = 28,  every gpu memory occupation was about 9G, and when I set  batch_size = 32, the training crashed. It seemed that gpu memory was not enough.\r\nI attach tensorflow logs as following:\r\n\r\nhttps://raw.githubusercontent.com/chenpengf0223/semantic_segmentation_distillation/master/crash.log\r\n", "> When I set batch_size = 28, every gpu memory occupation was about 9G, and when I set batch_size = 32, the training crashed. It seemed that gpu memory was not enough.\r\n\r\n@chenpengf0223,\r\nPlease take a look at [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) to limit GPU memory growth and let us know if it helps. Thanks!", "@amahendrakar  Thanks for reply.\r\nI have checked my code, and found that I already limited GPU memory growth as following:\r\n`for gpu in gpus:\r\n tf.config.experimental.set_memory_growth(device=gpu, enable=True)`\r\n\r\n\r\nWhen I set batch_size = 28, every gpu memory occupation was about 9G, If I do not limit GPU memory growth, the occupation would be 32G, right?\r\n\r\nSo GPU memory growth limit does not help.", "> When I set batch_size = 28, every gpu memory occupation was about 9G, If I do not limit GPU memory growth, the occupation would be 32G, right?\r\n\r\n@chenpengf0223,\r\nBy default, TensorFlow maps nearly all of the GPU memory of all GPUs visible to the process.\r\n\r\nTry setting a hard limit on the total memory to allocate on the GPU using `tf.config.experimental.set_virtual_device_configuration` as shown in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40979, "title": "Test for 2D zero padding.", "body": "I rewrote the unit test for 2D zero padding to support both channels first and channels last convention.\r\n\r\nI used the `test_upsampling_2d(self)` as guideline to ensure consistency with other tests. \r\n\r\n\r\nFixes #40724 \r\n\r\n", "comments": ["@jpodivin Can you please resolve conflicts? Thanks!", "@gbaned \r\nThe #41253 seems to have already fixed the issue, although in a slightly different fashion. Therefore I think this PR should be closed\r\n", "@jpodivin Thanks for the confirmation, closing the PR. "]}, {"number": 40978, "title": "importing tensorflow gives error \"illegal instruction\"", "body": "Hi.. I am trying to install tensorflow  in my python3 virtual environment.\r\nOS- centos 7.8kvm\r\ntensorflow installed from binary\r\ntensorflow version 1.15.0\r\npython version 3.6.8\r\ninstalled in virtualenv  using pip with the command\r\n`TMPDIR=/data/vincents/ pip install --cache-dir=/data/vincents/ --build /data/vincents/ tensorflow==1.15.0`\r\nI have 2GB RAM and I am using 2GB swap memory\r\n\r\n\r\nthis is my CPU info\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                2\r\nOn-line CPU(s) list:   0,1\r\nThread(s) per core:    1\r\nCore(s) per socket:    1\r\nSocket(s):             2\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 13\r\nModel name:            QEMU Virtual CPU version 2.5+\r\nStepping:              3\r\nCPU MHz:               2397.222\r\nBogoMIPS:              4794.44\r\nHypervisor vendor:     KVM\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              4096K\r\nL3 cache:              16384K\r\nNUMA node0 CPU(s):     0,1\r\nFlags:                 fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 syscall nx lm rep_good nopl xtopology eagerfpu pni cx16 x2apic hypervisor lahf_lm\r\n\r\nI have succeeded to install tensorflow=1.15.0, but whenever  I try to import it in a python shell in throws error\r\n`illegal instruction`\r\n![106207928_274334003654354_6896801223456467874_n](https://user-images.githubusercontent.com/35559892/86229455-8c8edd80-bbb1-11ea-8e2b-af699107dcd3.jpg)\r\n\r\nDO I NEED TO UPGRADE MY SERVER TO 4CPU? OR IS THERE SOME OTHER PROBLEM?\r\n\r\nN.B: I CANNOT SWITCH TO ANY OTHER VERSION. I NEED EXACTLY THIS VERSION\r\n\r\n", "comments": ["from the TensorFlow [installation guide](https://www.tensorflow.org/install/pip), you need AVX.\r\n```\r\nStarting with TensorFlow 1.6, binaries use AVX instructions which may not run on older CPUs.\r\n```", "@AnikaTabassum \r\nIs there any particular reason to install older version of tensor flow when later versions are available.\r\nPlease refer to [this link](https://github.com/tensorflow/tensorflow/issues/40875#issuecomment-650698437) , [ this link with same error](https://github.com/tensorflow/tensorflow/issues/21969#issuecomment-417262184 ) and let us know.", "yes for an open source package I need to install tensorflow 1.15.0. .i cannot use any other versions.\r\n\r\nDOES INCREASING CPUS SOLVE THIS PROBLEM?????\r\nI AM SORRY I AM NOT AN EXPERT \r\n", "@AnikaTabassum\r\nCan you please confirm if your cpu supports AVX,  as informed earlierplease refer to the instructions [here](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nPlease verify if you meet the requirements.", "No, my cpu Doesn't support avx. So it Doesn't matter how many cpus but if those support AVX   ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40978\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40978\">No</a>\n", "Sorry I closed this by mistake.  So do I need to upgrade my CPU?  ", "@AnikaTabassum \r\nCan you refer to [this link](https://github.com/tensorflow/tensorflow/issues/34558#issuecomment-565150738) as it answers the issue faced.\r\n[This comment](https://github.com/tensorflow/tensorflow/issues/36138#issuecomment-578010350) confirms the alternative for your issue.", "thanks for your assistance. so i have to build tf from source code. I am afraid I couldn't find any source of tensorflow 1.15.0\r\ncan you please assist me with the link with the exact version? ", "`git switch r1.15` after you clone the repository.", "Hi @mihaimaruseac ! I tried this after cloning, but unfortunately got this error \r\n`fatal: not a git repository (or any of the parent directories): .git`\r\n![image](https://user-images.githubusercontent.com/35559892/86284632-069c8200-bc05-11ea-99a6-7b980ba667b3.png)\r\n", "There was the same problem to me, but version dependencies made it difficult to solve this problem previously. I recommend you upgrading the CPU.\r\n", "@AnikaTabassum `cd tensorflow` before `git switch ...`. BTW, since you are running qemu, it might be possible to turn on AVX. See [qemu menu](https://www.qemu.org/docs/master/system/target-i386.html)", "SO i installed bazel 0.26.1 from the linux installer, as it is the necessary version for tf 1.15 (got form the docs) with the command-\r\n`./bazel-0.26.1-installer-linux-x86_64.sh`\r\nThen tried to build tf 1.15 with the following command:\r\n` bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nit took about one hour and I finally got this error:\r\n`ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_mlir/BUILD:1546:1: C++ compilation of rule '@local_config_mlir//:mlir-tblgen' fai\r\nled (Exit 1)\r\ngcc: error: unrecognized command line option '-std=c++14'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3239.923s, Critical Path: 89.28s\r\nINFO: 4043 processes: 4043 local.\r\nFAILED: Build did NOT complete successfully`\r\n\r\n![image](https://user-images.githubusercontent.com/35559892/86328152-2dd76b80-bc66-11ea-989f-cec614b3165d.png)\r\n\r\n", "@AnikaTabassum \r\nCan you please let us know the gcc version, and as per error faced can you refer to [this link](https://github.com/tensorflow/tensorflow/issues/31760#issuecomment-523114446).\r\n[link](https://github.com/tensorflow/tensorflow/issues/32677#issuecomment-534278822).\r\n\r\n", "gcc version 4.8.5\r\n`gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.`", "You need `gcc 7.3.1` See https://www.tensorflow.org/install/source#cpu", "@AnikaTabassum \r\nPlease update as per above comment.", "sorry, i have tried to install with gcc 7.3.1, made gcc7.3.1 as my default gcc version but unfoltunately getting the following error:\r\n![image](https://user-images.githubusercontent.com/35559892/86457984-55056a00-bd46-11ea-9b66-128cac68716b.png)\r\n", "Please post the actual error message in properly formatted Markdown, not a screenshot. It is much easier to read, easy to grep for, easy to select and copy-paste in other places (search in code, create new issues, triage duplicates), easier for others to locate similar errors. Plus, not all people have all images loaded in the browser. Textual error message takes a few hundred of bytes whereas an image takes MB.\r\n\r\nNow that that is aside, can you try `bazel clean --expunge` and then `bazel build -s ... &> log.txt` (replace `...` with all other arguments you would have used) and then **attach** `log.txt` to a reply?", "@mihaimaruseac I am extremely sorry for my fault.\r\nI am attaching the log.txt file.\r\ni gave the coomand:\r\n`bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package &> log.txt`\r\nand my gcc version is 7.3.1\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/4872198/log.txt)\r\n", "It seem you get a compile failure from the start\r\n\r\n```\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/com_google_protobuf/BUILD:106:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1)\r\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\nWhat is the output of `git show`? How about the output of `git log -n=5 --format=oneline`?", "It seems to me the failure `gcc: error trying to exec 'cc1plus': execvp: No such file or directory` is there because g++ was not installed or properly configured.", "@AnikaTabassum \r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi.. so I these instructions didn't solve my issue. I had to create an anaconda environment and install tensorflow 1.15.0 there.\r\nbut thanks for all your assistance..", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40978\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40978\">No</a>\n", "Hi @AnikaTabassum \r\nI'm trying to build tensorflow from source on centOS 7. Have upgraded gcc to 5.4.0 but I see I need >7 version. Getting same errors as you. How did you make it work? ", "I updated the gcc version but it didn't help. So I switched environment. Previously I was working in a python3 environment, I started using anaconda environment. Installed tensorflow using conda, and it's working. "]}, {"number": 40977, "title": "Bug: You must feed a value for placeholder tensor X with dtype Y and shape [?,?]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): >= 2.0\r\n- Python version: 3.6\r\n- Running on: CPUs (But I guess it happens on GPUs as well)\r\n\r\nFrom my experience, this kind of errors happens very often. Here is a (dumb) example where I write a custom layer and pass some parameters when I call that layer. Running the following code results in the below error:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\n\r\nclass CustomEmbedding(tf.keras.layers.Layer):\r\n    def __init__(self, masking_boolean, vocab, dimension, **kwargs):\r\n        self.masking_boolean = masking_boolean\r\n        self.vocab = vocab\r\n        self.dimension = dimension\r\n        super(CustomEmbedding, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(name='kernel', \r\n                                      shape=(self.vocab, self.dimension),\r\n                                      initializer='glorot_uniform', dtype='float32',\r\n                                      trainable=True)\r\n        super(CustomEmbedding, self).build(input_shape)\r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs)\r\n    def compute_mask(self, inputs, mask=None):\r\n        return self.masking_boolean\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (K.shape(input_shape)[0], K.shape(input_shape)[1], self.dimension)\r\n\r\ndef main():\r\n    def create_model():\r\n        sentence = tf.keras.layers.Input(dtype='int32', shape=(None,), name='sentence')\r\n        pos_ids_mask_boolean = K.not_equal(0, sentence)\r\n        pos_ids_mask_float = K.cast(pos_ids_mask_boolean, dtype='float32')\r\n        a = CustomEmbedding(pos_ids_mask_boolean, 500, 512)(sentence)\r\n        a = a*pos_ids_mask_float\r\n        model = tf.keras.models.Model(inputs=[sentence], outputs=a)\r\n        return model\r\n    model = create_model()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  You must feed a value for placeholder tensor 'sentence' with dtype int32 and shape [?,?]\r\n[[node sentence (defined at bug.py:32) ]] [Op:__inference_keras_scratch_graph_33]\r\n```\r\n\r\nFixing this for this case is actually easy because this example is small (see the code below). Nonetheless when it comes to a large project it is hard to find and debug this (it is a nightmare, actually, because I have to remove a lot of code to simplify the model until I find the root of the error).\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\n\r\nclass CustomEmbedding(tf.keras.layers.Layer):\r\n    def __init__(self, masking_boolean, vocab, dimension, **kwargs):\r\n        self.masking_boolean = masking_boolean\r\n        self.vocab = vocab\r\n        self.dimension = dimension\r\n        super(CustomEmbedding, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.kernel = self.add_weight(name='kernel', \r\n                                      shape=(self.vocab, self.dimension),\r\n                                      initializer='glorot_uniform', dtype='float32',\r\n                                      trainable=True)\r\n        super(CustomEmbedding, self).build(input_shape)\r\n    def call(self, inputs):\r\n        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs)\r\n    def compute_mask(self, inputs, mask=None):\r\n        return self.masking_boolean\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (K.shape(input_shape)[0], K.shape(input_shape)[1], self.dimension)\r\n\r\ndef main():\r\n    def create_model():\r\n        sentence = tf.keras.layers.Input(dtype='int32', shape=(None,), name='sentence')\r\n        pos_ids_mask_boolean = K.not_equal(0, sentence)\r\n        pos_ids_mask_float = K.cast(K.not_equal(0, sentence), dtype='float32')\r\n        a = CustomEmbedding(pos_ids_mask_boolean, 500, 512)(sentence)\r\n        a = a*pos_ids_mask_float\r\n        model = tf.keras.models.Model(inputs=[sentence], outputs=a)\r\n        return model\r\n    model = create_model()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\n\r\nSo I posted it here to raise the issue. I hope the TF team will fix it soon. \r\n\r\n\r\n", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/3ff5d6fd47734a17379d0e76074b5c30/untitled255.ipynb)", "Hi @AgoloCuongHoang, can you explain what your fix was? I ran the second block of code and I am seeing the error message `TypeError: Could not build a TypeSpec for <KerasTensor: shape=(None, None) dtype=bool (created by layer 'tf.math.not_equal')> with type KerasTensor`. Please [see this gist](https://colab.research.google.com/gist/nikitamaia/7d0d444e7255ba0f57ffd73415968541/40977.ipynb). ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40977\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40977\">No</a>\n"]}, {"number": 40976, "title": "Query result not show aliased functions", "body": "If we search `tf.argmax` in [tensorflow r1.15 documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/argmax), no result get for tf 1.x\r\n\r\nHowever, if search \"tf.math.argmax\", you will get it.\r\n\r\nBut they're both annations:\r\n```Python\r\n# pylint: disable=redefined-builtin\r\n@tf_export(v1=[\"math.argmax\", \"argmax\"])         # !!!! This line\r\n@deprecation.deprecated_args(None, \"Use the `axis` argument instead\",\r\n                             \"dimension\")\r\n@_set_doc(\r\n    gen_math_ops.arg_max.__doc__.replace(\"dimensions\", \"axes\").replace(\r\n        \"dimension\", \"axis\"))\r\ndef argmax(input,\r\n           axis=None,\r\n           name=None,\r\n           dimension=None,\r\n           output_type=dtypes.int64):\r\n  axis = deprecation.deprecated_argument_lookup(\r\n      \"axis\", axis, \"dimension\", dimension)\r\n  return argmax_v2(input, axis, output_type, name)\r\n```\r\n\r\nWhy only show the first aliased annotation in documentation? ", "comments": ["### I would like to work of this issue.\r\nCan anyone explain me why is this happening ? \r\n@jvishnuvardhan ", "@MarkDaoust can you help me whit my doubt ?", "Hi @aavishkarmishra,\r\n\r\nThanks for your interest. There's no easy fix for this. \r\n\r\nIt would be a big rewrite to the code that generates the _toc.yaml file here. \r\n\r\nI agree that we should do it, but its **not** a simple fix.\r\n\r\nedit: missing \"not\"", "Then can you tell where I can find the code generates the _toc.yaml file here, this can help me understanding more about how this stuff actually works.", "@MarkDaoust Yes, please provide some hints for where these docs are generated.", "Sorry, in my earlier comment I was missing a **not** on the last line.\r\n\r\nThe code that does this is here: https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/generate_lib.py#L539-L541\r\n\r\nBut the problem is that it currently doesn't have access to an organized view of those aliases, I'd need to change the lower levels to pass up the tree structure being generated here:\r\n\r\nhttps://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/doc_generator_visitor.py#L76", "@MarkDaoust How can I start with this, as I cannot see that how can we provide access to an organised view of those classes.\r\n\r\nActually I don't exactly got the idea that where those aliases are being used."]}, {"number": 40975, "title": "Resizing in Tensorflow Lite", "body": "Dear Tensorflow developers, \r\nI have got a trained model that has Conv, GlobalAveargePooling, Fully Connected, Reshape, and Deconve (upsampling) layers.  I converted the frozen graph to tflite and this model with fixed input size didn't have any errors when running but when resizing I get below error.\r\n\"Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/kernel_util.cc:224 d1 == d2 || d1 == 1 || d2 == 1 was not true. Node number 94 (ADD) failed to prepare.\"\r\nanybody can help me?\r\nThanks!", "comments": ["@AliBahri94,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, complete code and the dataset you are using. Thanks!", "Thank you for your attention.\r\nTensorFlow version: 1.15\r\nconvert code (.pb to .tflite):\r\n################\r\ngraph_def_file = \"address of the saved model (pb)\"\r\ninput_arrays = [\"model/t_lr\"]\r\noutput_arrays = [\"model/Generator/add_global_res\"]\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\ngraph_def_file, input_arrays, output_arrays, input_shapes= {\"model/t_lr\" : [1, 512, 512, 3]})\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n#################\r\n\r\nThis error happened on mobile GPU  when I resize the graph.\r\nThanks!\r\n\r\n\r\n\r\n", "@AliBahri94,\r\nCould you please share the `.pb` file or the code to generate the `.pb` file as well. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40974, "title": "Import error-- OSError: [WinError 193] %1 is not a valid Win32 application", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.2\r\n- Python version:3.8 64 bit\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: RTX 2060, 6GB \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n![tensorflow](https://user-images.githubusercontent.com/55295294/86224846-05d50300-bba7-11ea-989f-9ff087e62858.PNG)\r\ni have installed all the requirement given in tensorflow website but keep getting this error. I have one more question- if everything is 64 bit then why it is showing win32?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["i have install tensorflow using 'pip install tensorflow-gpu'", "i just reinstall scipy and it worked", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40974\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40974\">No</a>\n", "> i just reinstall scipy and it worked\r\n\r\nYes! It works :)"]}, {"number": 40973, "title": "distribute keras sparse feature training error", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\"16.04.6 LTS (Xenial Xerus)\"\r\n- TensorFlow installed from  \r\nbinary\r\n- TensorFlow version (use command below):\r\n2.2.0\r\n- Python version:\r\n3.7.3\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\nTesla P40  22919MiB\r\n\r\n\r\n**Standalone code to reproduce the issue** (only part of the code)\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras.backend as K\r\nimport sys\r\n\r\nfrom datetime import date, timedelta\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras import Model, Sequential\r\nfrom meta import ModelMeta\r\nfrom dataset import train_input_fn\r\nfrom layers import EmbedLayerForSparse\r\nfrom deepctr.layers import InnerProductLayer, PredictionLayer\r\nbatch_thread_number = 15\r\nbatch_size = 8192\r\ndimension = 16\r\n\r\nstrategy = tf.distribute.experimental.CentralStorageStrategy()\r\nwith strategy.scope():\r\n    inputs = {}\r\n    outputs = {}\r\n    for k, v in capacity_map.items():\r\n        inputs[k] = Input(shape=(v,), sparse=True, name=k)\r\n        outputs[k] = EmbedLayerForSparse(vocabulary_size=v, embedding_size=dimension, embed_initializer=tf.keras.initializers.he_normal(), n\\\r\name='SparseLayer'+k)(inputs[k])\r\n    linear = list(outputs.values())\r\n    inner = InnerProductLayer()([Reshape((1, dimension))(f) for f in outputs.values()])\r\n    inner_reshaped = Reshape((inner.get_shape().as_list()[1],))(inner)\r\n    concat = Concatenate(axis=1)(linear + [inner_reshaped])\r\n    outputs = ReLU()(BatchNormalization()(concat))\r\n    outputs = Dense(512)(outputs)\r\n    outputs = ReLU()(BatchNormalization()(outputs))\r\n    outputs = Dense(128)(outputs)\r\n    outputs = ReLU()(BatchNormalization()(outputs))\r\n    outputs = Dense(1)(outputs)\r\n    outputs = PredictionLayer(use_bias=False)(outputs)\r\n\r\n    model = tf.keras.Model(inputs=list(inputs.values()), outputs=outputs)\r\n    model_meta = ModelMeta(model, candidate_meta)\r\n    initial_learning_rate = 0.001\r\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\r\n            initial_learning_rate,\r\n            decay_steps=1000,\r\n            decay_rate=0.96,\r\n            staircase=True)\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.kera\\\r\ns.metrics.AUC(num_thresholds=10000)])\r\n    print('compile complete')\r\nwith strategy.scope():\r\n  while start_date < end_date:\r\n    dataset = train_input_fn('/path/to' + start_date.isoformat(), batch_thread_number, batch_size, capacity_map)\r\n    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_batch=0)])\r\n    model.save('model.' + start_date.isoformat())\r\n    start_date += timedelta(days=1)\r\n    break\r\n\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nwork.log:\r\nhon.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nNo similar op available at this time.\r\nWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/parsing_config.py:719: sparse_merge (from tensorflow.pyt\r\nhon.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nNo similar op available at this time.\r\n2020-07-01 16:16:14.067956: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[6689] = [527,217950] is repeated\r\n2020-07-01 16:16:14.123837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[8964] = [527,217950] is repeated\r\n2020-07-01 16:16:14.556197: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[6689] = [527,217950] is repeated\r\n2020-07-01 16:16:14.606631: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[20296] = [446,1263545] is repeated\r\n2020-07-01 16:16:14.605999: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[20296] = [446,1263545] is repeated\r\n2020-07-01 16:16:14.670875: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[8964] = [527,217950] is repeated\r\n2020-07-01 16:16:14.806522: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[2997] = [104,246925] is repeated\r\n2020-07-01 16:16:15.025014: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[27417] = [1409,577748] is repeated\r\n2020-07-01 16:16:15.616607: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[121] = [1,827513] is repeated\r\n2020-07-01 16:16:34.125064: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[115717] = [4149,1289703] is repeated\r\n2020-07-01 16:16:34.184952: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\n2020-07-01 16:16:34.187837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[183021] = [4086,3891] is repeated\r\nTraceback (most recent call last):\r\n  File \"pnn.py\", line 67, in <module>\r\n    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_ba\r\ntch=0)])\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[6689] = [527,217950] is repeated\r\n\t [[{{node SerializeManySparse_10}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNext]] [Op:__inference_train_function_25126]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\n\r\nps.log:\r\n2020-07-01 16:16:34.184952: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[183021] = [4086,3891] is repeated\r\n2020-07-01 16:16:34.187837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen\r\nt: indices[183021] = [4086,3891] is repeated\r\nTraceback (most recent call last):\r\n  File \"pnn.py\", line 67, in <module>\r\n    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_ba\r\ntch=0)])\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[6689] = [527,217950] is repeated\r\n\t [[{{node SerializeManySparse_10}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNext]] [Op:__inference_train_function_25126]\r\n\r\nFunction call stack:\r\ntrain_function\r\n", "comments": ["@yuandaxing \r\n\r\nI have tried in colab with TF -GPU version 2.2 and i am seeing the below error message `(ImportError: cannot import name 'ModelMeta'`).Please, share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram @yuandaxing \r\nI have encountered the same problem, and I put my code on google drive and colab.\r\nHere is the link:\r\nhttps://drive.google.com/drive/folders/1PU7QtZa2_2nuf1sDK_2sNj3w3CtJA9ep\r\n\r\nThe script should be run in distributed mode, but I had no idea how to do this in colab.\r\nSo I wrote the script 'run-dist.sh', you can reproduce the error by running it.", "Hi @justsmoke and @yuandaxing. Is it possible for one of you to provide a minimal example using data from tf.keras.datasets or tfds so that we don't have to download the data separately to reproduce?", "@nikitamaia \r\nthe training data is file p0 which is included in the google drive link:\r\nhttps://drive.google.com/drive/folders/1PU7QtZa2_2nuf1sDK_2sNj3w3CtJA9ep", "@nikitamaia  \r\n  Great thanks for your response, I have blocked with this problem for a long time.\r\n  @justsmoke's problem is the same with me. please use code and data he provided above.", "@justsmoke can you add your stack trace here so I can verify it is the same? I'm seeing something similar, but slightly different to what @yuandaxing posted.", "Can either of you also confirm that you still see this same error when your model only contains tf.keras.layers and no deepctr.layers?", "@nikitamaia \r\nI have updated the pnn_keras.py script, and it no longer depends on deepctr.\r\nAnd the error still occurs, here is my stack trace:\r\nps.log:\r\n2020-07-03 09:41:50.993744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-07-03 09:41:52.374363: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-07-03 09:41:52.374484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 6db40ae45fe4\r\n2020-07-03 09:41:52.374520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 6db40ae45fe4\r\n2020-07-03 09:41:52.374708: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.40.4\r\n2020-07-03 09:41:52.374775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.40.4\r\n2020-07-03 09:41:52.374802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.40.4\r\n2020-07-03 09:41:52.375558: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-07-03 09:41:52.393014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2199890000 Hz\r\n2020-07-03 09:41:52.396294: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fcbf0bafc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-03 09:41:52.396348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:From /opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/ops/parsing_config.py:715: sparse_merge (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nNo similar op available at this time.\r\n2020-07-03 09:42:06.620853: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1419] = [73,209681] is repeated\r\n2020-07-03 09:42:06.621060: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1419] = [73,209681] is repeated\r\n2020-07-03 09:42:06.621303: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[699] = [4,1866171] is repeated\r\n2020-07-03 09:42:06.624197: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[13589] = [542,27051] is repeated\r\n2020-07-03 09:42:06.646976: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[17834] = [790,476866] is repeated\r\n2020-07-03 09:42:06.647197: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[20119] = [426,508352] is repeated\r\n2020-07-03 09:42:06.646990: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[20119] = [426,508352] is repeated\r\n2020-07-03 09:42:06.646995: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[27656] = [933,1537230] is repeated\r\n2020-07-03 09:42:06.647204: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[27656] = [933,1537230] is repeated\r\n2020-07-03 09:42:06.648311: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[64637] = [759,1443134] is repeated\r\nTraceback (most recent call last):\r\n  File \"pnn.py\", line 117, in <module>\r\n    model.fit(dataset, batch_size=batch_size, shuffle=False)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n2020-07-03 09:42:06.685234: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[43729] = [542,355339] is repeated\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n2020-07-03 09:42:06.734912: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[3872] = [159,1328680] is repeated\r\n2020-07-03 09:42:06.735250: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[31196] = [646,1269494] is repeated\r\n2020-07-03 09:42:06.735724: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1722] = [19,709261] is repeated\r\n2020-07-03 09:42:06.735998: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[9860] = [410,133009] is repeated\r\n2020-07-03 09:42:06.736760: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[31196] = [646,1269494] is repeated\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1661, in _filtered_call\r\n    return self._call_flat(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1745, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 593, in call\r\n    outputs = execute.execute(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[1419] = [73,209681] is repeated\r\n         [[{{node SerializeManySparse_9}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]] [Op:__inference_train_function_10267]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\nworker.log:\r\n2020-07-03 09:42:06.403419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-07-03 09:42:07.910154: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[27656] = [933,1537230] is repeated\r\n2020-07-03 09:42:07.910257: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[20119] = [426,508352] is repeated\r\n2020-07-03 09:42:07.918541: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[64637] = [759,1443134] is repeated\r\n2020-07-03 09:42:07.919704: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[20119] = [426,508352] is repeated\r\n2020-07-03 09:42:07.921871: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[17834] = [790,476866] is repeated\r\n2020-07-03 09:42:07.923514: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[27656] = [933,1537230] is repeated\r\nTraceback (most recent call last):\r\n  File \"pnn.py\", line 117, in <module>\r\n    model.fit(dataset, batch_size=batch_size, shuffle=False)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1661, in _filtered_call\r\n    return self._call_flat(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1745, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 593, in call\r\n    outputs = execute.execute(\r\n  File \"/opt/conda/envs/deepctr/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  indices[27656] = [933,1537230] is repeated\r\n         [[{{node SerializeManySparse_38}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n         [[IteratorGetNext/_6]]\r\n  (1) Invalid argument:  indices[27656] = [933,1537230] is repeated\r\n         [[{{node SerializeManySparse_38}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_10267]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function\r\n\r\n2020-07-03 09:42:07.980333: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1419] = [73,209681] is repeated\r\n2020-07-03 09:42:07.980589: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1419] = [73,209681] is repeated\r\n2020-07-03 09:42:07.980987: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[13589] = [542,27051] is repeated\r\n2020-07-03 09:42:07.984101: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[699] = [4,1866171] is repeated\r\n2020-07-03 09:42:08.022799: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[43729] = [542,355339] is repeated\r\n2020-07-03 09:42:08.049527: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[31196] = [646,1269494] is repeated\r\n2020-07-03 09:42:08.049589: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[9860] = [410,133009] is repeated\r\n2020-07-03 09:42:08.050278: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[31196] = [646,1269494] is repeated\r\n2020-07-03 09:42:08.050705: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[3872] = [159,1328680] is repeated\r\n2020-07-03 09:42:08.052225: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argument: indices[1722] = [19,709261] is repeated", "@nikitamaia I have found that this error disappears when there is no multi-value features, and once a multi-value feature is added, the error occurs. I don't know why this happens, hope you can help analyze this problem.", "Thanks for helping to debug. Can you give an example of one of these multi-value features? I was able to reproduce the error with the data you provided, so if you can point me to the features in the p0 dataset that you're referring to that would be helpful.", "@nikitamaia I create a new file named multiValueFeatures and put it under the shared directory.", "I am running into a \"corrupted record\" error. Did you change any of your tf record parsing code? Can you also just clarify what you mean by multi value features?", "@nikitamaia \r\nI didn't change the code, can you provide some details about \"corrupted record\" error?\r\nMulti value features are actually multi-valued categorical features, which is categorical, and may have multiple values in one training sample.\r\nFor example, if feature A is a multi-valued categorical feature, and it has three values: v1, v2, v3, then A=v1 and A=v2 can both exist in one training sample.", "@nikitamaia @yuandaxing \r\nI discovered that there were duplicate feature values in some multi-valued categorical features, and after I remove those duplicates, the error disappears.\r\nThanks a lot for help debug the problem, and I think that this issue can closed now.", "great job!!!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40973\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40973\">No</a>\n"]}, {"number": 40972, "title": "Official Docker Image Build that Sugget GPU Support Utilizes CPU Only", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): official Docker image (tensorflow/tensorflow:1.12.3-gpu-py3)\r\n- TensorFlow version: 1.12.3\r\n- Python version: 3.5.2\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: (unchanged as is in the official docker image)\r\n- GPU model and memory: GTX1050, 4042MiB\r\n\r\n\r\n\r\n**Describe the problem**\r\nOfficial release of docker image `tensorflow/tensorflow:1.12.3-gpu-py3` suggests gpu support in its tag, yet it does not utilize GPU. \r\n\r\nI have `nvidia-docker` (the native support version, with the `--gpus all` syntax) installed correctly. I've verified it thorugh additional test in `tensorflow/tensorflow:1.15.2-gpu-py3`, it worked fine, unlike `tensorflow/tensorflow:1.12.3-gpu-py3`.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- Run python3 in a container created from `tensorflow/tensorflow:1.12.3-gpu-py3`\r\n`docker run -it --rm --gpus all tensorflow/tensorflow:1.12.3-gpu-py3 python3`\r\n- Execute the following code\r\n```\r\nimport tensorflow as tf\r\nwith tf.device(\"gpu:0\"):\r\n     c=tf.constant(0)\r\n\r\nwith tf.Session() as sess:\r\n     sess.run(c)\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nAfter executing code in container created from `tensorflow/tensorflow:1.12.3-gpu-py3`, the error suggests that there is no avaliable GPU device:\r\n```\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation Const: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\r\n\t [[node Const (defined at <stdin>:2)  = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=\"/device:GPU:0\"]()]]\r\n```\r\n\r\nThe code above works fine in `tensorflow/tensorflow:1.15.2-gpu-py3`.\r\n", "comments": ["@BorisPolonsky,\r\nIs there a specific reason you are using TF v1.12?\r\n\r\nTF 1.x is not actively supported and since this issue is resolved with TF v1.15 can we close this issue? Thanks!", "> @BorisPolonsky,\r\n> Is there a specific reason you are using TF v1.12?\r\n> \r\n> TF 1.x is not actively supported and since this issue is resolved with TF v1.15 can we close this issue? Thanks!\r\n\r\nThere's no such reason using this. I just found that one of the official image does not work as suggest in its tag. It's up to you to decide if it should be fixed (or documented).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40972\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40972\">No</a>\n"]}, {"number": 40971, "title": "[Intel MKL] Factor out the macros for handling test registeration", "body": "", "comments": ["@penpornk Can you please review this PR ? Thanks!"]}]