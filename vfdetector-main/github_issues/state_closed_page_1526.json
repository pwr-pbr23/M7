[{"number": 7146, "title": "Nested `tf.while_loop`s hang when they are placed on CPU", "body": "When I place all ops within nested `tf.while_loop` on CPU, evaluating the output of nested `tf.while_loop` makes the program hang.\r\n\r\nI also [posted a question on StackOverflow](http://stackoverflow.com/questions/41929472/why-does-nested-tf-while-loop-freeze-in-test-session-of-tf-test-testcase).\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n```\r\n/usr/local/cuda/lib64/libcudadevrt.a\r\n/usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\n/usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n/usr/local/cuda/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda/lib64/libcudart_static.a\r\n/usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\n/usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n/usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n/usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n`28f5099d532ce59787ee58012b8ef04c498947ae`\r\n\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.3\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Dec 22 12:31:25 2016 (1482409885)\r\nBuild timestamp: 1482409885\r\nBuild timestamp as int: 1482409885\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nThe following code is run on python 3.5:\r\n\r\n``` python\r\nimport tensorflow as tf\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement=False)\r\nwith tf.Session(config=config) as sess, tf.device('/cpu:0'):\r\n    num_outer_iters = tf.constant(3)\r\n    num_inner_iters = tf.constant(5)\r\n\r\n    def outer_body(loop_outer_index, loop_outer_ta):\r\n\r\n        def inner_body(loop_inner_index, loop_inner_ta):\r\n            loop_inner_ta = loop_inner_ta.write(loop_inner_index,\r\n                                                tf.constant(0))\r\n            return (loop_inner_index + 1, loop_inner_ta)\r\n\r\n        inner_index = tf.constant(0)\r\n        inner_ta = tf.TensorArray(tf.int32, num_inner_iters)\r\n        (_, inner_ta) = tf.while_loop(\r\n            lambda index, *_: index < num_inner_iters,\r\n            inner_body,\r\n            (inner_index, inner_ta))\r\n\r\n        loop_outer_ta = loop_outer_ta.write(loop_outer_index,\r\n                                            inner_ta.stack())\r\n        return loop_outer_index + 1, loop_outer_ta\r\n\r\n    outer_index = tf.constant(0)\r\n    outer_ta = tf.TensorArray(tf.int32, num_outer_iters)\r\n    (_, outer_ta) = tf.while_loop(\r\n        lambda index, *_: index < num_outer_iters,\r\n        outer_body,\r\n        (outer_index, outer_ta),\r\n        parallel_iterations=1, back_prop=False)\r\n\r\n    print(sess.run(outer_ta.concat()))\r\n\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nIf I replace `num_inner_iters = tf.constant(5)` with `num_inner_iters = 5`, the program will exit normally.\r\n\r\n### Logs or other output that would be helpful\r\nThe program hangs without any error message.\r\n", "comments": ["I tried your code with the latest head (current master), (configured with XLA) and it works normally there", "Can you try it with latest head and see if problem persists?", "The program still froze with latest master branch. (`4cc0d1e7905454de7bd3cb6c20c3f9fb459ed335`)\r\n\r\nI got the following output before the program froze:\r\n```\r\n2017-01-31 14:40:36: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\n2017-01-31 14:40:36: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\n2017-01-31 14:40:36: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\n2017-01-31 14:40:36: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\n2017-01-31 14:40:36: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n2017-01-31 14:40:38: I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:06:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 5.32GiB\r\n2017-01-31 14:40:38: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\n2017-01-31 14:40:38: I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\n2017-01-31 14:40:38: I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\r\n2017-01-31 14:40:42: I tensorflow/core/platform/default/cuda_libdevice_path.cc:35] TEST_SRCDIR environment variable not set: using local_config_cuda/cuda under this executable's runfiles directory as the CUDA root.\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 20 visible devices\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 20 visible devices\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\r\n2017-01-31 14:40:42: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\r\n```\r\n\r\nI used gdb to attach the program, and the output of `bt` was:\r\n\r\n```\r\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\r\n#1  0x00007f436db3591c in std::condition_variable::wait(std::unique_lock<std::mutex>&) ()\r\n   from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#2  0x00007f4370601f1b in tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, long long)\r\n    () from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#3  0x00007f4370601fcd in tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, tensorflow::CancellationManager*, long long) ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#4  0x00007f437060c735 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#5  0x00007f436f1afd21 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Tensor**, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Buffer*, TF_Status*) [clone .constprop.533] ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#6  0x00007f436f1b0538 in TF_Run ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#7  0x00007f436f0a167d in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#8  0x00007f436f0a17c3 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#9  0x00007f436f089365 in _wrap_TF_Run ()\r\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#10 0x00000000004e9b9f in PyCFunction_Call ()\r\n#11 0x000000000052b595 in PyEval_EvalFrameEx ()\r\n#12 0x000000000052e87a in PyEval_EvalCodeEx ()\r\n#13 0x00000000004ebcc3 in ?? ()\r\n#14 0x00000000005b7167 in PyObject_Call ()\r\n#15 0x00000000005262af in PyEval_EvalFrameEx ()\r\n#16 0x000000000052d2e3 in ?? ()\r\n#17 0x0000000000529332 in PyEval_EvalFrameEx ()\r\n#18 0x000000000052d82f in ?? ()\r\n#19 0x0000000000529332 in PyEval_EvalFrameEx ()\r\n#20 0x0000000000528814 in PyEval_EvalFrameEx ()\r\n#21 0x000000000052d2e3 in ?? ()\r\n#22 0x0000000000528eee in PyEval_EvalFrameEx ()\r\n#23 0x000000000052d2e3 in ?? ()\r\n#24 0x000000000052dfdf in PyEval_EvalCode ()\r\n#25 0x00000000005c7b85 in ?? ()\r\n#26 0x00000000004e9b9f in PyCFunction_Call ()\r\n#27 0x000000000052b595 in PyEval_EvalFrameEx ()\r\n#28 0x000000000052d2e3 in ?? ()\r\n#29 0x0000000000528eee in PyEval_EvalFrameEx ()\r\n#30 0x000000000052d2e3 in ?? ()\r\n#31 0x0000000000528eee in PyEval_EvalFrameEx ()\r\n#32 0x000000000052d2e3 in ?? ()\r\n#33 0x000000000052dfdf in PyEval_EvalCode ()\r\n#34 0x00000000005fd2c2 in ?? ()\r\n#35 0x00000000005ff76a in PyRun_FileExFlags ()\r\n#36 0x00000000005ff95c in PyRun_SimpleFileExFlags ()\r\n#37 0x000000000063e7d6 in Py_Main ()\r\n#38 0x00000000004cfe41 in main ()\r\n```", "@yuanbyu any idea? Why would replacing `tf.constant(5)` with `5` make a difference for `while_loop`", "OK, I can reproduce the hang (I was mistakenly running with CUDA_VISIBLE_DEVICES= which makes it pass). This suggests that `with tf.device(\"/cpu:0\")` tries to place some parts of the computation on GPU which causes the hang", "I think that this has been fixed in the HEAD. Re-open if it is not the case. "]}, {"number": 7145, "title": "GPU not registrering after pip update to 0.12 from 0.10", "body": "Since upgrading via pip, tensorflow does not use my GPU.\r\n\r\n```\r\n>>> from tensorflow.python.client import device_lib\r\n>>> [x.name for x in device_lib.list_local_devices()]\r\n['/cpu:0']\r\n>>>\r\n```\r\n\r\nDevice looks correctly installed\r\n```\r\n/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 970\"\r\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\r\n  CUDA Capability Major/Minor version number:    5.2\r\n  Total amount of global memory:                 4036 MBytes (4231528448 bytes)\r\n  (13) Multiprocessors, (128) CUDA Cores/MP:     1664 CUDA Cores\r\n  GPU Max Clock rate:                            1216 MHz (1.22 GHz)\r\n  Memory Clock rate:                             3505 Mhz\r\n  Memory Bus Width:                              256-bit\r\n  L2 Cache Size:                                 1835008 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     No\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 970\r\nResult = PASS\r\n```\r\n\r\nTheano works fine\r\n\r\n```\r\n> python -c \"import theano\"\r\nUsing gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5105)\r\n```\r\n\r\nAdded the following to ~/.bashrc\r\n```\r\nexport CUDA_HOME=/usr/local/cuda-8.0\r\nexport CUDA_ROOT=/usr/local/cuda-8.0\r\nexport PATH=$PATH:$CUDA_ROOT/bin\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_ROOT/lib64:$CUDA_ROOT/extras/CUPTI/lib64\r\n```\r\n\r\nAnybody have an idea how to figure this out? I could off cause try to re-install everything, but I would rather figure out why this isn't working.\r\n\r\nthanks in advance :)\r\n \r\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nNone\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nUbuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nCuda 8.0, cuDNN 5.1\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\n0.12.1\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nreinstalling cuDNN\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Never mind, solved it"]}, {"number": 7144, "title": "for review", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 7143, "title": "for review", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 7142, "title": "AttributeError: 'GFile' object has no attribute 'tell'", "body": "I'm using python 2.7.6, pip 9.0.1 and tensorflow 0.12.1 under Ubuntu 14.04. \r\n\r\nWhen I ran the script using this line,\r\n\r\nimport input_data\r\nmnist_images = input_data.read_data_sets( \"MNIST_data/\", one_hot=True )\r\n\r\nI got message like this:\r\n\r\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\r\nExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nTraceback (most recent call last):\r\n  File \"mnist.py\", line 5, in <module>\r\n    mnist_images = input_data.read_data_sets( \"MNIST_data/\", one_hot=True )\r\n  File \"~/machine_learn/input_data.py\", line 194, in read_data_sets\r\n    train_images = extract_images(local_file)\r\n  File \"~/machine_learn/input_data.py\", line 54, in extract_images\r\n    magic = _read32(bytestream)\r\n  File \"~/machine_learn/input_data.py\", line 47, in _read32\r\n    return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\r\n  File \"/usr/lib/python2.7/gzip.py\", line 261, in read\r\n    self._read(readsize)\r\n  File \"/usr/lib/python2.7/gzip.py\", line 288, in _read\r\n    pos = self.fileobj.tell()   # Save current position\r\nAttributeError: 'GFile' object has no attribute 'tell'\r\n\r\nAnd the script \"input_data.py\" is from https://github.com/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py \r\n\r\n", "comments": []}, {"number": 7141, "title": "iOS example missing #include \"tensorflow/core/framework/types.pb.h\"", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: iOS 10.2\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): not related it is iOS\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["@kwccoin Does this issue persist?  Looks like this fell through the cracks (cough, @petewarden, cough).", "There's no enough information on this bug yet unfortunately. Could you confirm you successfully followed the steps here?\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios\r\n\r\nIf that's true, please post reproduction steps so we can see the same error here.", "No response received after several weeks, so I'm closing for now. Please reopen with more information if this is incorrect.", "Getting the issue here as well when building for iOS!"]}, {"number": 7140, "title": "Invert bijector in tf.contrib.distributions fails to generate samples", "body": "Sampling from the example provided in the docstring fails with recursion errors.\r\n```python\r\nds = tf.contrib.distributions\r\n\r\nexp_gamma = ds.TransformedDistribution(\r\n  distribution=ds.Gamma(1.0, 2.0),\r\n  bijector=ds.bijector.Invert(ds.bijector.Exp()))\r\n\r\nsess = tf.Session()\r\nsess.run(exp_gamma.sample())\r\n  File \"/Users/dvt/Envs/venv/lib/python2.7/site-packages/tensorflow/contrib/distributions/python/ops/bijector.py\", line 556, in _get_inverse_event_shape\r\n    return self._get_inverse_event_shape(tensor_shape.TensorShape(output_shape))\r\n  ..\r\n  File \"/Users/dvt/Envs/venv/lib/python2.7/site-packages/tensorflow/contrib/distributions/python/ops/bijector.py\", line 556, in _get_inverse_event_shape\r\n    return self._get_inverse_event_shape(tensor_shape.TensorShape(output_shape))\r\n  File \"/Users/dvt/Envs/venv/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 436, in __init__\r\n    elif isinstance(dims, compat.bytes_or_text_types):\r\nRuntimeError: maximum recursion depth exceeded while calling a Python object\r\n```\r\nI run into similar errors when using the Invert bijector for other distributions/bijectors.\r\n\r\nI am using TensorFlow v1.0.1 and Python 2.7.\r\n\r\n@jvdillon", "comments": ["Fixed in https://github.com/tensorflow/tensorflow/commit/c87b17f996bde34027d515415b28514a38c41c9a."]}, {"number": 7139, "title": "R0.10", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 7138, "title": "The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.", "body": "Hello, \r\n\r\nMy CPU is AMD Phenom II x6 1090t, I don't know if that's relevant.\r\nI have an issue with my tensorflow, I have tried a few things and nothing is working. Here is the error I'm getting when I run my script. \r\n\r\n```\r\nchad@chad-GA-990XA-UD3:~/tensorflow$ ./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]:\r\nPlease specify optimization flags to use during compilation [Default is -march=native]:\r\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]\r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\n```\r\n\r\nHere is the error i get when i run my script.\r\n```\r\n2017-01-30 00:45:59: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\n2017-01-30 00:46:00: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\n2017-01-30 00:46:00: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\n2017-01-30 00:46:00: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\n2017-01-30 00:46:00: I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n2017-01-30 00:46:00: F tensorflow/core/platform/cpu_feature_guard.cc:35] The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.\r\nAborted (core dumped)\r\n```\r\n\r\nI followed this tutorial generally https://alliseesolutions.wordpress.com/2016/09/08/install-gpu-tensorflow-from-sources-w-ubuntu-16-04-and-cuda-8-0-rc/\r\n\r\nCan anyone help me?", "comments": []}, {"number": 7137, "title": "[Java] Don't strip symbols from C library when compiling in debug mode", "body": "When building the Java client with \"compilation_mode=dbg\", the symbols in the C++ library should not be stripped otherwise we won't be able to attach a GDB to the java process for core debugging.\r\n\r\nAlso, I thought that knowing the active compilation mode might be something useful in general so I declared the \"debug\" and \"optimize\" config settings in the parent BUILD file.", "comments": ["Can one of the admins verify this patch?", "Assigning @gunan who probably knows more about this area of the build than me.", "@asimshankar for Java related changes.\r\nI have no objection to the new config_settings defined in tensorflow/BUILD. But I am not sure about the modified default flags.", "Jenkins, test this please.", "> Jenkins, test this please.\r\n\r\nEeh, I'll be really surprised if my 2-lines patch really broke all sanity checks, looking at the Jenkins console it seems that the process has been aborted or something else went wrong. @gunan or anyone, can you please have a look at it?\r\n```\r\nBuild was aborted\r\nAborted by unknown\r\nUnable to get pull request builder trigger!!\r\nSetting status of 5d48a946f02184a6f82d556238e6c2b3db1c5fdb to FAILURE with url https://ci.tensorflow.org/job/tensorflow-pull-requests-android/3425/ and message: 'FAILURE\r\n...\r\n```\r\n", "The failure is in \"Sanity\" build, which runs pylint and buildifier.\r\nLooks like there is a buildifier error:\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/2895/console\r\n\r\n", "Jenkins, test this please.", "It looks like this is ready to merge, @gunan can you confirm?", "I think all of the comments from @jart are addressed, too.", "Can one of the admins verify this patch?"]}, {"number": 7136, "title": "../genop/main.go:15: running \"sh\": exit status 1", "body": "I am unable to get the Go binding for TensorFlow working on OS X 10.12. I followed the installation instructions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/go.\r\n\r\nThings go wrong when generating the wrapper functions for TensorFlow ops:\r\ngo generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\n\r\nThe output from the above command is:\r\n../genop/main.go:15: running \"sh\": exit status 1\r\nop/generate.go:15: running \"go\": exit status 1\r\n\r\nWhen browsing the sources i see an imported package\r\n\"github.com/tensorflow/tensorflow/tensorflow/go/genop/internal/proto/tensorflow/core/framework\"\r\nwhich isn't there. Maybe that is causing the issue?\r\n", "comments": ["I figured out that this issue was caused by having a GOPATH that consists of multiple directories, for instance mine is: GOPATH=$HOME/gocode/extern:$HOME/gocode/jpad;\r\n\r\nThis confuses generate.sh in locating PROTOC and eventually PATH. I fixed the issue by setting GOPATH to the top level directory that contains the source of TensorFlow, in my case  GOPATH=$HOME/gocode/extern\r\n\r\nI'm not a .sh script expert enough to fix generate.sh to make it handle A GOPATH with multiple top level entries. \r\n", "Sorry for the trouble and thanks for catching it. Yup, that generate script does assume a single directory in GOPATH. \r\n\r\nContributions to fix this are welcome, as are ideas to make the whole process smoother.\r\n(For example, avoiding the need for `go generate` by committing the generated code to the git repository is something we're thinking of but haven't started on)", "Yes 'go generate' is for the package maintainer(s) to call, not for the end user who wishes to install the package. As long as the maintainer(s) know that generate.sh only works with a single-directory GOPATH all is fine. \r\nI did some searching to figure out how to robustly find the directory that a shell script is in, so that it could find PROTOC from there. There seems to be no reliable cross-platform cross-shell solution though :(\r\n", "@notnot @asimshankar Created a PR #8331 to try to address this issue. Please take a look."]}, {"number": 7135, "title": "Java: Do no strip symbols from C library when compiling in debug mode", "body": "When building the Java client, the linker should not strip symbols from the C library if we are compiling in debug mode, otherwise we won't be able to attach GDB to the java process for core debugging.\r\n\r\nI thought that knowing the compilation mode might be something useful in general so I declared the \"debug\" and \"optimize\" config settings in the parent BUILD file.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> :memo: Please visit https://cla.developers.google.com/ to sign.\r\n> \r\n> Once you've signed, please reply here (e.g. I signed it!) and we'll verify. Thanks.\r\n\r\nI signed it", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "I signed it\n\n\nOn 2017-01-29 03:40 PM, googlebot wrote:\n>\n> We found a Contributor License Agreement for you (the sender of this \n> pull request), but were unable to find agreements for the commit \n> author(s). If you authored these, maybe you used a different email \n> address in the git commits than was used to sign the CLA (login here \n> <https://cla.developers.google.com/> to double check)? If these were \n> authored by someone else, then they will need to sign a CLA as well, \n> and confirm that they're okay with these being contributed to Google.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub \n> <https://github.com/tensorflow/tensorflow/pull/7135#issuecomment-275944134>, \n> or mute the thread \n> <https://github.com/notifications/unsubscribe-auth/AJpCXj0z6rXlZNq6P6VYw14ImSxN6UlHks5rXPkjgaJpZM4Lw4sR>.\n>\n\n", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I've commited with the wrong email address... This should be fixed by now, since I replaced all commiter/author address with the right one (i.e. with the signed CLA)."]}, {"number": 7134, "title": "[Java] [Feature] Load from SavedModel", "body": "Make it possible for the Java library to load exported TF models in SavedModel format.   \r\n\r\nOutline of the proposed design:\r\n1. Define a new class `SavedModelBundle` to represent the loaded saved model.  Properties include the graph, session, and metagraphdef.\r\n2. Define a static method on `SavedModelBundle` to load from disk, given an export path and some tags.\r\n\r\n```\r\nclass SavedModelBundle implements AutoCloseable { \r\n  public Graph graph() { ... }\r\n  public Session session() { ... }\r\n  public byte[] metaGraphDef() { ... }\r\n  public void close() { /* close the session and graph */ }\r\n  public static SavedModelBundle loadSavedModel(String exportDir, Set<String> tags) { ... }\r\n}\r\n```\r\n\r\n3. Write a JNI method to support loading, based on `TF_LoadSessionFromSavedModel` from the C API.", "comments": ["Here's a WIP - do tell if there's any objections to the approach, otherwise I'll write some tests and submit.\r\nhttps://github.com/cookieai/tensorflow/commit/64360fc51bd5ce48b06f52901e032313b68dfacd\r\n", "@jhseu : Weren't you looking into this? Is @EronWright 's plan above in sync with yours?", "Ah, yeah, I was going to do it last week but illness prevented me. Seems like it saved me some time :)\r\n\r\n@EronWright happy to review the pull request when you think it's ready.", "@EronWright some feedback on the code: I was imagining we'd use a static factory method on the Session class. Is there a reason to make a new SavedModelBundle class instead (note that the C++ equivalent isn't ideal and may change)?\r\n\r\nSomething like:\r\n`public static Session loadSavedModel({String or Path for the type} path)` with a variant that also retrieves the metagraphdef.", "@jhseu I thought that too but it didn't work in practice.   `TF_LoadSessionFromSavedModel` produces both a session and a graph that the caller takes ownership of.   The session never takes ownership of the graph.   Meanwhile, the JNI method may produce only a single return value.   All together, a `SavedModelBundle`  was the obvious solution.\r\n\r\nRegarding the `metagraphdef`, a saved model is not very useful without it because it contains the `signaturedef`s.", "That looks like a good approach to the issue. Is there any part of the implementation still missing in https://github.com/cookieai/tensorflow/commit/64360fc51bd5ce48b06f52901e032313b68dfacd, or it just needs tests? :)", "@Enet4 thanks, and feel free to try the updated patch posted above.", "@EronWright @jhseu I'm sure I will get some flak for this but as the documentation is a bit lacking...\r\n\r\nI am trying to use `SavedModel` like so:\r\n\r\n`SavedModelBundle.load(\"/path/to/directory\");`\r\n\r\nbut am getting an `UnsatisfiedLinkError`. My directory contains the following files which were saved using the `saver.save` python API: ![directory](https://puu.sh/uC4fq/ad18591acb.png)\r\n\r\nAm I using `SavedModel` incorrectly? I will add some documentation after I figure out what the issue is here! Thanks in advance.", "@nirajpatel My hunch would be that the JVM is failing to link with the native library. What is the message carried by that exception?\r\n\r\nBut there is one more thing you need to fix, though. You should use the [saved_model](https://www.tensorflow.org/api_docs/python/tf/saved_model) API for the saved model functionality, not `tf.train.Saver`. Although the formats for checkpoints and saved models share several similarities, I don't believe they're interchangeable.", "@Enet4 thank you for replying!\r\n\r\nThe exception I am seeing is:\r\n```\r\njava.lang.UnsatisfiedLinkError: org.tensorflow.SavedModelBundle.load(Ljava/lang/String;[Ljava/lang/String;[B)Lorg/tensorflow/SavedModelBundle;\r\n\tat org.tensorflow.SavedModelBundle.load(Native Method)\r\n\tat org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:37)\r\n```\r\n\r\nI was originally seeing this because I didn't link to the native library:\r\n```\r\nTensorFlow Java API methods will throw an UnsatisfiedLinkError unless native code shared libraries are loaded\r\n```\r\n\r\nbut now I am running with the JNI I believe:\r\n\r\n![VM Options](https://puu.sh/uCGut/c04c641b11.png)\r\n![Project Structure](https://puu.sh/uCGwE/ba35337d9c.png)\r\n\r\n> But there is one more thing you need to fix, though. You should use the saved_model API for the saved model functionality, not tf.train.Saver\r\n\r\nAh! That would explain it. Is the `saved_model` API newer or preferred to `tf.train.Saver`?", "> Ah! That would explain it. Is the saved_model API newer or preferred to tf.train.Saver?\r\n\r\nThe `saved_model` API is more recent, but to my understanding, it does not invalidate the other one. If you want to save the graph and all its variables for use in other programs and tools, for a variety of purposes (serving, fine-tuning, etc.), `saved_model` is more indicated. To keep checkpoints of the training process, using `tf.train.Saver` is more appropriate since it also allows you to specify a global step and the maximum number of checkpoints to keep.\r\n\r\nAs for the message, I cannot tell for sure why that happens. It might be that you are still using the jni dynamic library from a previous version of TensorFlow.\r\n", "Good point @Enet4! I am using the **PREVIEW1** JNI but I compiled the TensorFlow jar from source in order to get the latest changes (including this one). Is there currently a way to build the JNI from source? The only option I see in the readme is https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java#quickstart step number 2.\r\n\r\n> The saved_model API is more recent, but to my understanding, it does not invalidate the other one.\r\n\r\nThis makes sense! I will start using `saved_model`.", "Nevermind, the JNI is in my build directory! I will use that. I really appeciate the help @Enet4. Thank you. I will send a PR to update the readme soon."]}, {"number": 7133, "title": "Loading Files with New Tensorflow", "body": "Using newest version of Tensorflow on Linux.\r\n\r\nOk so I had a working Saver.restore going for literally months and everyone was fine:\r\nsaver = tf.train.Saver()\r\nsaver.restore(sess, \"deep_tweet_lstm_w-300000\")\r\n\r\ndeep_tweet_lstm_w-300000 was the name of the file with the data points.\r\n\r\nEver since updating my Tensorflow I get this error: \r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_tweet_lstm_w-300000\r\n\r\nI honestly find this change infuriating, how in the world do I load this file with the new Tensorflow?  ", "comments": ["1. Can you be more specific with the versions\r\n2. Could you try to switch back to older version and see if the problem persists (use virtualenv or conda env to easily switch between versions)", "I'm using 0.12.1 while before I used 0.11", "Can you try with tf 0.11 from inside virtual env?\r\n\r\nIE, if you use conda, \r\n\r\n```\r\nconda create -n tf11-2 python=3.5 \r\nsource activate tf11-2\r\npip install -I --upgrade setuptools\r\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc0-cp35-cp35m-linux_x86_64.whl\r\npip install --upgrade $TF_BINARY_URL\r\n\r\n```", "I have the exact same Issue with tensorflow version 0.12.1", "\n    \nI solved it by just downgrading in the end.\n\n\nSent from my Samsung device\n\n-------- Original message --------\nFrom: Ignacio Carlucho <notifications@github.com> \nDate: 2017-02-02  9:30 AM  (GMT-05:00) \nTo: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: danielmogilny <danielmogilny@gmail.com>, Author <author@noreply.github.com> \nSubject: Re: [tensorflow/tensorflow] Loading Files with New Tensorflow (#7133) \n\nI have the exact same Issue with tensorflow version 0.12.1\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n  \n  \n\n\n\n\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@IgnacioCarlucho in #7133: I have the exact same Issue with tensorflow version 0.12.1\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/tensorflow/tensorflow/issues/7133#issuecomment-276972318\"}}}", "It certainly sounds like there was a regression here, but we'd need more detail to debug.\r\n\r\n@rohan100jain Is it possible your change in cl/134036016 broke TensorSliceReader for globs without wildcards?", "I have the same problem. I'm using the Tensorflow 1.0 with GPU on Windows 10. I tried some suggest in other issues, such as remove the special chars in checkpoint name, using absolute path. But still have this problem. Cloud you tell me how to solve this? Thank you.\r\n\r\nSome output infomation are as follow:\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/workspace/keras_summary/src/classificatio/preprocess.py\", line 107, in <module>\r\n    saver.restore(sess, \"D:\\\\workspace\\\\keras_summary\\\\abstract\\\\model_ckpt\")\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1439, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for D:\\workspace\\keras_summary\\abstract\\model_ckpt\r\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_4/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_132_save/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op 'save/RestoreV2_11', defined at:\r\n  File \"D:/workspace/keras_summary/src/classificatio/preprocess.py\", line 106, in <module>\r\n    saver = tf.train.Saver()\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1051, in __init__\r\n    self.build()\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1081, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 675, in build\r\n    restore_sequentially, reshape)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 402, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 242, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 668, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"D:\\workspace\\keras_summary\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for D:\\workspace\\keras_summary\\abstract\\model_ckpt\r\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_4/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_132_save/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n", "I had the same issue, but I notice that tensorflow does not save the file as I define it. \r\nFor instance if I save it as: \r\n\r\n`saver = tf.train.Saver()`\r\n`save_path = saver.save(sess, 'dropout.ckpt', global_step = 0)`\r\n \r\nThen there will be no file called \"dropout.ckpt\" \r\nBut there will be a file: \"dropout.ckpt-0.meta\" . And loading this file successfully loads the tensorflow model. Therefore I will load it as: \r\n\r\n`new_saver = tf.train.import_meta_graph(\"dropout.ckpt-0.meta\")`\r\n`new_saver.restore(sess, tf.train.latest_checkpoint('./'))`\r\n\r\nIn your case, I think you are using keras.. In that case you can load and save using: \r\n\r\n`model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'`\r\n`del model  # deletes the existing model`\r\n`model = load_model('my_model.h5') # and loads it`\r\n\r\n\r\n", "deep_tweet_lstm_w-300000 does look like a valid prefix path that should be loadable. The latest_checkpoint function as recommended by Ignacio should work but would be good to see why reference to a specific checkpoint doesn't work.\r\n\r\nCould you print out the ls result from the working directory? Would be good to see what files are on disk. ", "Actually https://github.com/tensorflow/tensorflow/issues/6893 might give us a hint as to what might be going on...\r\n\r\nif you put ./ in front of the path, does it work? ", "@rohan100jain `./` doesn't work on Windows 10. But I found when I using `model_ckpt-10000` which contains the global step number, tensorflow can load the parameters successfully.", "@rohan100jain What's the status?", "@gsh199449  could you tell me about how to deal with this problem detailedly\uff1fI have the same problem too", "@IceCubePill Add global step number after the model name, like \"model_ckpt-10000\". 10000 is the global step number. Use this file name in the load function.", "My issue happened between updates when Tensorflow changed its save system. I fixed it by downgrading to the old Tensorflow\n> On Oct 17, 2017, at 10:48 PM, IceCubePill <notifications@github.com> wrote:\n> \n> @gsh199449 <https://github.com/gsh199449> could you tell me about how to deal with this problem detailedly\uff1fI have the same problem too\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/7133#issuecomment-337444600>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ATUqz0pNHVI5gVqzHUqWmwn4s_W4eQUyks5stWb3gaJpZM4Lw3Z2>.\n> \n\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 7132, "title": "change log dir to /tmp/tensorflow/mnist/logs/mnist_with_summaries", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "On Sun, 29 Jan 2017 at 7:25 PM, googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> verify. Thanks.\n>\ni signed it\n\n> ------------------------------\n>\n>    - If you've already signed a CLA, it's possible we don't have your\n>    GitHub username or you're using a different email address. Check your\n>    existing CLA data <https://cla.developers.google.com/clas> and verify\n>    that your email is set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - If you signed the CLA as a corporation, please let us know the\n>    company's name.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7132#issuecomment-275915250>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJ6PcWFh5yCheDKcMvIWPeTjD3WeN1Peks5rXJpCgaJpZM4Lwy6X>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 7131, "title": "Adding checks for broken bottleneck files", "body": "An exception is raised when a broken cached bottleneck files is read. Such a file can be created as a result of sudden system failure. \r\n\r\nThis commit refers the issue #2296 (https://github.com/tensorflow/tensorflow/issues/2296). Although closed but the problem still persists. Please view comments by @rizasif92 at the end. The changes contain nothing but error handling.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@petewarden I agree with your solution and was thinking to implement it. I have made the changes as suggested, and tested them as well; I am attaching a screenshot of the output. Kindly review and let me know if anything else is required.\r\nThank you :)\r\n\r\n![capture](https://cloud.githubusercontent.com/assets/8410351/22466834/dae8d6f2-e7e3-11e6-978c-6ebe8fc2a617.PNG)\r\n ", "@petewarden done", "@tensorflow-jenkins test this please", "@rizasif it looks like you added some 4 character indents, which breaks the sanity check. TF uses 2 character indents. Please fix.\r\n\r\nSee: https://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/2923/console", "Indentation changes made, kindly re-run the tests. Thanks :)", "@tensorflow-jenkins test this please", "Thanks @rizasif. @petewarden can you take another look? If the logics right to you, approve and I'll get it merged.", "Did the tests pass? :/", "@rizasif it looks like you still have some bad indents, e.g.\r\n\r\nFAIL: Found 1 non-whitelited pylint errors:\r\ntensorflow/examples/image_retraining/retrain.py:353: [E0001(syntax-error), ] unexpected indent\r\n", "@rmlarsen the code seems to be working at my end; so we might have to do this a few more times to resolve these indentation issues. I hope this commit works fine. @tensorflow-jenkins please test :)", "@rizasif Thanks :) \r\n\r\n@tensorflow-jenkins test this please", "@rizasif thanks for the contribution!", "Pleasure's all mine @rmlarsen \r\nThank you so much for all the support. Hope to see you guys again. Take Care :) "]}, {"number": 7130, "title": "Possible bug in inception_v1 in slim networks library", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nThis question is probably not relevant to this issue. I did a Google search and didn't find any. \r\n\r\n### Environment info\r\nOperating System:\r\n\r\n**Windows 7 - 64 bit**\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n**None.**\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n`<                 branch_2, 32, [3, 3], scope='Conv2d_0b_3x3')`\r\n`---`\r\n`>                 branch_2, 32, [5, 5], scope='Conv2d_0b_5x5')`\r\n\r\n\r\nThe inception_v1.py in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/inception_v1.py, the inception layer is different from the paper. In the paper there is a 3x3 conv2d and a 5x5 conv2d module. I see that other frameworks have a 5x5 module and only here there are 2 3x3 modules instead.\r\n\r\nIs this intentional or a bug ?\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Agreed. This sounds like a bug. Do you mind taking a PR for this please? Thanks. :)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I went ahead and signed the CLA. I had to get corporate approval to do the process. Should I go ahead and create a new PR ? Or the old PR that I posted above can be reopened and pulled from ?"]}, {"number": 7129, "title": "Possible bug in ctc_beam_search_test.cc ?", "body": "Hello,\r\n\r\nI've found something very confusing in the above file, I can't see how [line number 54](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_beam_search_test.cc#L54) can work correctly.\r\n\r\n```\r\n to_state->labels.push_back(to_label);\r\n```\r\n\r\nFrom what I can make out each child beam entry has a new state associated with it, so the `to_state` being passed to the `ExpandState` method should only ever be called with a single label, representing the current class at that time.\r\n\r\nI'm attempting to integrate a full n-gram language model into a beam scorer and this certainly seems to be the case. In order to build a string of all characters in the beam I must make a reference back to `from_state` in my `HistoryBeamState` and traverse back up the tree.\r\n\r\nThis is not the case in the unit test though, and in fact if I log some output there I can see the `to_state` being reused with different `to_label` values. Hence the test does pass.\r\n\r\nHave I greatly misunderstood something here or is this not what the expected behaviour should be? I notice the test has a beam width less that the number of classes in the input tensor, which I guess is not so realistic? Perhaps I'm seeing an artifact of this?\r\n\r\nAny feedback would be great, I think understanding is correct but can't make sense of this unit test.", "comments": ["That file hasn't been touched in 9 months, not sure if anyone has state on it, but cc @ebrevdo just in case", "Will try to look this week.", "@ebrevdo Are there any updates?\r\nIs this fixed?", "Eugene, do you think this issue is still relevant? Should it be changed to contributions welcome?", "Nagging Assignee @ebrevdo: It has been 227 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 242 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "From the test author: , I don't think it's a bug, rather an overly simplified test (where state management isn't really done)."]}, {"number": 7128, "title": "QR decomposition is slow", "body": "We are doing a bunch of of QR decompositions in numpy. I did preliminary investigation of moving them to TF, but TF version is slow compared to numpy.\r\n\r\nBelow is a benchmark script that runs QR decomposition of 4096x4096 matrix. It took 7.3 seconds in TF and 1.93 in numpy MKL. Numpy MKL is the default numpy that comes when installing Anaconda.\r\n\r\nversion: HEAD from last week, built with `--config=cuda --config=opt`\r\ncpu: 32 core Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz\r\nhttps://github.com/yaroslavvb/stuff/blob/master/tiny_runs/qr_test.py\r\n\r\nNote that `pip install --upgrade $TF_BINARY_URL` will overwrite MKL numpy with OpenBLAS numpy that is actually slower than TF version. The way to check is to look at `np.__config__.show()` and look for strings like `mkl_intel_lp64`. You can get MKL version back by uninstalling numpy and doing `conda install numpy`\r\n\r\n@rmlarsen \r\n", "comments": ["@rmlarsen is there some planned work, or should I mark this as contributions welcome?", "@yaroslavvb The current TF op is using the single-threaded (CPU) Householder QR in Eigen. Does the MKL version run multi-threaded? ", "Yes, MKL version seems to be using 800-900% CPU", "I'll working on this!", "I find MKL is already supported in the latest tf/eigen code...", "@yaroslavvb , I both installed mkl_dnn 2018 and full mkl 2018, add\r\n```\r\n#ifdef INTEL_MKL\r\n#define EIGEN_USE_MKL_ALL\r\n#endif // INTEL_MKL\r\n```\r\nto `tensorflow/core/kernels/qr_op_impl.h`, run `bazel build --config=opt --config=cuda --define=using_mkl=true //tensorflow/tools/pip_package:build_pip_package` to build, got\r\n```\r\nTF QR on 4096 by 4096 matrix in 2.59 seconds\r\nnumpy QR on 4096 by 4096 matrix in 2.64 seconds\r\n```", "Oh interesting! PS, I thought latest MKL is 2017 update 2. At least that's the version I get when I download latest official Intel for Python distribution from Intel.\r\n\r\nYou can get MKL version using this snippet\r\n\r\n```\r\nimport ctypes\r\nimport numpy as np\r\n\r\ndef mklVersion():\r\n    ver = np.zeros(199, dtype=np.uint8)\r\n    mkl = ctypes.cdll.LoadLibrary(\"libmkl_rt.so\")\r\n    mkl.MKL_Get_Version_String(ver.ctypes.data_as(ctypes.c_char_p), 198)\r\n    return ver[ver != 0].tostring()\r\n\r\nmklVersion()\r\n```\r\n\r\nCan you also use SVD\u00a0from MKL in TF? The MKL version seems to be pretty efficient and the TF version had some correctness issues -- https://github.com/tensorflow/tensorflow/issues/8905\r\n\r\nhttps://github.com/yaroslavvb/stuff/blob/master/svd_benchmark.py", "@yaroslavvb , I use 2018 beta version of MKL only for building c++ code. I find tf use `BDCSVD` in eigen which doesn't have `LAPACKE` version.", "@yaroslavvb What's the status here?", "@girving I haven't tested it, but @suiyuan2009 says this can be fixed with 3 line change to `qr_op_impl.h`", "@suiyuan2009 Interested in submitting a PR? :)", "@girving It seems this issue can be closed since #11116, which fixed but didn't close this issue automatically, is merged.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Closing per qmick@'s last comment.", "QR is still very slow using intel optimized tf2.0 from anaconda. QR calls don't use mkl routine (shown by set `export MKL_VERBOSE=1`), for float64 random uniform matrix with size 4096 * 4096, the time in mkl linked numpy and tf2.0 cpu is 2.35s vs 28.5s on 2*Xeon 5120 CPU. tf QR  (Eigen implementation) is more than 10 times slower than mkl. \r\nActually the PR enabling MKL for QR op is reverted in https://github.com/tensorflow/tensorflow/pull/12219. It seems that only some basic ops can be patched by intel mkl via mkl-dnn. And mkl support for eigen (-DEIGEN_USE_MKL_ALL) is not supported at all for current tensorflow setup. \r\nTherefore, for now, so called \"intel optimized\" or \"mkl enabled\" tensorflow is very limited in terms of  mkl operations, only matrix multiplication or convolution types of things are actually optimized by mkl-dnn. QR, SVD and other involved ops are still using Eigen implementation which is slow since it is default to single thread."]}, {"number": 7127, "title": "graph nodes inside sess.run() brackets should be garbage-collected", "body": "My input pipeline returns current epoch, and batch of images.\r\n\r\nepoch,label_batch,image_batch  = my_input_pipeline(.....)\r\n.....\r\n\r\nTwo examples:\r\n`sess.run(epoch[0],train_step_run)`\r\ngives 15 examples per second and RAM get filled over time very slowly.\r\n`\r\nsess.run(epoch,train_step_run)`\r\nruns 100 examples per second and is stable. \r\n\r\nIt would be great to make sess.run brackets \"special\" so that some TF function within it does not construct an infinite graph.\r\n", "comments": ["Can you try\r\n```\r\na = epoch[0]\r\nsess.run(a,train_step_run)\r\n```\r\n\r\nFrom your description it sounds like `sess.run(a)` is slow and leaks memory, but `sess.run([a])` doesn't, which is a bug if `a` is a `Tensor` object. If it's not a `Tensor` object, it may still be a bug, it would be useful to see what `my_input_pipeline` is doing", "I did not explain myself right. sess.run([a]) and sess.run(a) are same in my example, just tested this. Creating \r\n```\r\na = epoch[0]\r\nsess.run(a,train_step_run) \r\n```\r\nalso works fine. a is a tensor object. \r\n\r\nThe thing that would not work is:\r\n`sess.run(a[0]) `\r\nor \r\n`sess.run([a[0]])`\r\n", "Ah, right, `a[0]` adds a `strided_slice` op to the graph. It's the same problem if you did `sess.run(a+b)`, every time you run it, an `Add` op is added.\r\n \r\nThe way to prevent these kinds of errors is to run `tf.get_default_graph().finalize()` before the first session run call\r\n\r\nIf you do learning through higher level frameworks like `tf.slim` or `MonitoredSession` or `estimator`, those  already modify the graph for you, but I guess it's a potential hazard if you stay in the low-level API", "`tf.get_default_graph().finalize() `is indeed a good way to treat errors of this kind. Thank you for clarifications.", "Hi, Need help with this sort of issue, I am using YOLOV3 implementation in keras and facing the same issue. \r\n\r\nWhen i try to finalize it states \r\nRuntimeError: Graph is finalized and cannot be modified.\r\nWhat to do ? \r\n", "You must have implicitly or explicitly called tf.something after tf.get_default_graph().finalize(). Check out your error line"]}, {"number": 7126, "title": "No module named tensorflow", "body": "System: macos sierra\r\nPython 3.5.2 via anaconda, a special env `tensorflow` created and used (`source activate tensorflow`)\r\n\r\nHere is how I installed the package:\r\n\r\n```\r\n  export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.1-py3-none-any.whl\r\n  pip install --ignore-installed --upgrade $TF_BINARY_URL\r\n```\r\n\r\npip says all packages have been successfully installed, but if I try to import tensorflow, python says there is no such module. \r\n\r\nIt seems the module is named `tensorflow_gpu`:\r\n\r\n```\r\n(tensorflow) kaiyin@kaiyins-mbp 13:19:02 | ~ =>\r\npip show tensorflow\r\n(tensorflow) kaiyin@kaiyins-mbp 13:19:09 | ~ =>\r\npip show tensorflow_gpu\r\nName: tensorflow-gpu\r\nVersion: 0.12.1\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: http://tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /Users/kaiyin/anaconda3/envs/tensorflow/lib/python3.5/site-packages\r\nRequires: wheel, numpy, protobuf, six\r\n```\r\n\r\nAlthough `tensorflow_gpu` couldn't be imported, either. \r\n\r\nAny idea what's going on here? \r\n", "comments": ["@gunan any idea?", "@kindlychung this could be a message produced by Python package loader because it can't find the packages, or it can be caused by `pywraptensorflow.so` crashing with an exception. One way to tell which one it is, is to run under strace (sudo dtruss on Mac), and see what files it's opening, and that it eventually opens TensorFlow files from the correct site-packages directory \r\n", "I did a few things:\r\n\r\n```\r\npip install ipython\r\ncd /usr/local/cuda/lib\r\nln -s libcuda.dylib libcuda.1.dylib\r\n```\r\n\r\nAnd now I can load tensorflow without a problem. Not sure which of the above solved it. ", "It's the `pip install ipython` line. If you don't install `ipython`, then using ipython from your env will use ipython from outside your env, and hence switch the load paths to be outside of your env (hence no tensorflow)\r\n\r\nThis issue has been diagnosed by an earlier user who updated documentation to help future users avoid this problem in\r\nhttps://github.com/tensorflow/tensorflow/pull/3514", "The same problem in Windows 7. \r\nEverything works well before the test command, \"import tensorflow as tf\".\r\nD:\\Python35\\Scripts>pip show tensorflow\r\n---\r\nMetadata-Version: 2.0\r\nName: tensorflow\r\nVersion: 1.0.1\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: http://tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nInstaller: pip\r\nLicense: Apache 2.0\r\nLocation: d:\\python35\\lib\\site-packages\r\nRequires: numpy, six, protobuf, wheel\r\nClassifiers:\r\n  Development Status :: 4 - Beta\r\n  Intended Audience :: Developers\r\n  Intended Audience :: Education\r\n  Intended Audience :: Science/Research\r\n  License :: OSI Approved :: Apache Software License\r\n  Programming Language :: Python :: 2.7\r\n  Topic :: Scientific/Engineering :: Mathematics\r\n  Topic :: Software Development :: Libraries :: Python Modules\r\n  Topic :: Software Development :: Libraries\r\nEntry-points:\r\n  [console_scripts]\r\n  tensorboard = tensorflow.tensorboard.tensorboard:main\r\nYou are using pip version 8.1.1, however version 9.0.1 is available.\r\nYou should consider upgrading via the 'python -m pip install --upgrade pip' comm\r\nand.\r\n", "and this\r\nD:\\Python35\\Scripts>pip list\r\nappdirs (1.4.3)\r\nnumpy (1.12.1)\r\npackaging (16.8)\r\npip (8.1.1)\r\nprotobuf (3.2.0)\r\npyparsing (2.2.0)\r\nsetuptools (34.3.2)\r\nsix (1.10.0)\r\ntensorflow (1.0.1)\r\nwheel (0.29.0)\r\nYou are using pip version 8.1.1, however version 9.0.1 is available.\r\nYou should consider upgrading via the 'python -m pip install --upgrade pip' comm\r\nand.", "This is an already resolved issue.\r\nPlease try the suggestions above. If they do not work, please file a new issue filling in the full issue template."]}, {"number": 7125, "title": "R1.0", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Looks like a misoperation. Closing the PR."]}, {"number": 7124, "title": "Let dso_loader handle variations in the name of libcuda better on Mac", "body": "", "comments": []}, {"number": 7123, "title": "try ... catch like structure when loading tfrecords?", "body": "When transferring tfrecords from place to place, some of them might be damaged or become incomplete. In this case, tensorflow will just return a queue error. \r\n\r\nIs it possible to put some try...catch structure into the data loading process to avoid the interuption?\r\n\r\nSome of the core errors:\r\n`W tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Could not parse example inpu`\r\n\r\n`tensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\r\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_INT64, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\n\r\nCaused by op u'batch', defined at:\r\n  File \"check_tf_records.py\", line 34, in <module>`\r\n\r\n`OutOfRangeError (see above for traceback): FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\r\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_INT64, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]`\r\n", "comments": ["@sheeym is there a simple solution to this?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7122, "title": "Corrected capitalization of TensorFlow", "body": "Changed instances of \"Tensorflow\" to \"TensorFlow\".", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 7121, "title": "Disable two failing tensor_forest tests in windows.", "body": "", "comments": []}, {"number": 7120, "title": "Branch 145839627", "body": "Merging internal changes. ", "comments": ["@tensorflow-jenkins, test this please.", "Need change 145852218 to fix python 3 build, maybe even more.", "Perhaps we can discard this?", "Sure. Thanks\n\nOn Mon, Jan 30, 2017 at 10:59 AM, Rasmus Munk Larsen <\nnotifications@github.com> wrote:\n\n> Perhaps we can discard this?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7120#issuecomment-276155827>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APAgTuC28r0qok77SU3ClnY8JVdtRg9tks5rXjMsgaJpZM4LwVYM>\n> .\n>\n", "Discarding this CL"]}, {"number": 7119, "title": "Conversion script update (adding concat_dim to axis rename for tf.concat and tf.pack renames)", "body": "Two updates to the conversion script for 1.0:\r\n- Rename 'concat_dim' argument in tf.concat to 'axis'\r\n- Rename tf.pack/tf.unpack to tf.stack/tf.unstack", "comments": ["@tensorflow-jenkins test this please", "Jenkins, test this please."]}, {"number": 7118, "title": "Cannot run TensorFlow on GPU - RHEL 6", "body": "Hello,\r\nI have been trying for days to take advantage of the in one of the machines I have access to. \r\nGiven that **I have no root**  access I had to compile everything from source. \r\nI tried both the last stable release and the current master branch but I had no luck at running TensorFlow on the GPU. \r\n\r\nMy setup is the following : \r\nRed Hat EL 6.8 (no root access)\r\nPython 2.7.8\r\nvirtualenv 13.1.0\r\ndevtoolset-4 (GCC 5.3.1)\r\nBazel 0.4.3 (built from source)\r\nGeForce GTX680 (compute capability 3.0)\r\nCuda Toolkit 8.0\r\ncuDNN 5.1\r\n\r\nI had to modify few configuration files such that the configure script could complete successfully : \r\n```diff\r\ndiff --git a/configure b/configure\r\nindex a8e7bb773..002094aba 100755\r\n--- a/configure\r\n+++ b/configure\r\n@@ -39,7 +39,7 @@ function bazel_clean_and_fetch() {\r\n   # bazel clean --expunge currently doesn't work on Windows\r\n   # TODO(pcloudy): Re-enable it after bazel clean --expunge is fixed.\r\n   if ! is_windows; then\r\n-    bazel clean --expunge\r\n+    bazel clean --expunge_async\r\n   fi\r\n   bazel fetch \"//tensorflow/... -//tensorflow/examples/android/...\"\r\n }\r\n\r\n\r\ndiff --git a/tensorflow/core/platform/default/build_config.bzl b/tensorflow/core/platform/default/build_config.bzl\r\nindex ebf835d11..824471640 100644\r\n--- a/tensorflow/core/platform/default/build_config.bzl\r\n+++ b/tensorflow/core/platform/default/build_config.bzl\r\n@@ -8,7 +8,7 @@ load(\"//tensorflow:tensorflow.bzl\", \"if_not_mobile\")\r\n WITH_GCP_SUPPORT = False\r\n WITH_HDFS_SUPPORT = False\r\n WITH_XLA_SUPPORT = False\r\n-WITH_JEMALLOC = True\r\n+WITH_JEMALLOC = False\r\n \r\n # Appends a suffix to a list of deps.\r\n def tf_deps(deps, suffix):\r\n\r\n\r\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex 7fa7e4a91..ef41f5cd9 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -714,7 +714,8 @@ def tf_custom_op_library(name, srcs=[], gpu_srcs=[], deps=[]):\r\n   )\r\n \r\n def tf_extension_linkopts():\r\n-  return []  # No extension link opts\r\n+  #return []  # No extension link opts\r\n+  return [\"-lrt\"] \r\n \r\n def tf_extension_copts():\r\n   return []  # No extension c opts\r\n\r\n\r\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL.tpl b/third_party/gpus/crosstool/CROSSTOOL.tpl\r\nindex b77a45c32..e1fb068a2 100644\r\n--- a/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n+++ b/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n@@ -56,6 +56,8 @@ toolchain {\r\n   cxx_flag: \"-std=c++11\"\r\n   linker_flag: \"-Wl,-no-as-needed\"\r\n   linker_flag: \"-lstdc++\"\r\n+  linker_flag: \"-lm\"\r\n+  linker_flag: \"-lrt\"\r\n   linker_flag: \"-B/usr/bin/\"\r\n```\r\n\r\nAt the point in which I have to ask bazel to build TensorFlow I face a weird problem. \r\nIf I use [--config=cuda8.0](https://github.com/tensorflow/tensorflow/issues/4944) the building process completes but the gpu is never used nor detected. \r\n\r\nIf I use --config=cuda the building process fails with the following error \r\n\r\n```bazel\r\nERROR: /home/emt1627/.cache/bazel/_bazel_emt1627/aeec3eab67314b40e280b02ed0028dfc/external/nasm/BUILD:8:1: undeclared inclusion(s) in rule '@nasm//:nasm':\r\nthis rule is missing dependency declarations for the following files included by 'external/nasm/regvals.c':\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stddef.h'\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdarg.h'\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n \r\nIf I run it again I get a similar error \r\n\r\n```bazel\r\nERROR: /home/emt1627/.cache/bazel/_bazel_emt1627/aeec3eab67314b40e280b02ed0028dfc/external/nasm/BUILD:8:1: undeclared inclusion(s) in rule '@nasm//:nasm':\r\nthis rule is missing dependency declarations for the following files included by 'external/nasm/iflag.c':\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stddef.h'\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdarg.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\nI have also tried different configurations of Cuda toolkit and cuDNN library, but those all led nowhere near the solution.\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["We do not have official support for RHEL. (However, I think I have a solution below)\r\nBazel is complaining that \"nasm\" package tensorflow depends on is looking for explicit build dependencies for the listed headers. The problem looks unrelated to CUDA or TensorFlow.\r\nmaybe it can be related to this build file, but for core system libraries and headers, bazel should not be asking for explicit dependencies.\r\n\r\nA quick search shows me that this error looks very similar to this one: https://github.com/tensorflow/tensorflow/issues/3431#issuecomment-234131699\r\n\r\nSo in your case, let's try this. Right after this line:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/crosstool/CROSSTOOL.tpl#L124\r\ncould you try adding:\r\n`cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include\"\r\n\r\nThen run configure and build again.\r\nPlease let me know if it works or not.", "@gunan thank you for your reply!\r\nI did as you suggested and that error has not shown up anymore. \r\n\r\nI have now a new error I have just started to troubleshoot : \r\n\r\n```bazel\r\nERROR: /home/emt1627/.cache/bazel/_bazel_emt1627/aeec3eab67314b40e280b02ed0028dfc/external/nasm/BUILD:8:1: Linking of rule '@nasm//:nasm' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /home/emt1627/.cache/bazel/_bazel_emt1627/aeec3eab67314b40e280b02ed0028dfc/execroot/tensorflow-nightly && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/home/emt1627/opt/cudnn-8.0-linux-x64-v5.1:/usr/lib64/nvidia:/home/emt1627/opt/cuda-8.0/lib64:/opt/rh/devtoolset-4/root/usr/lib64:/opt/rh/devtoolset-4/root/usr/lib:/opt/rh/python27/root/usr/lib64 \\\r\n    PATH=/home/emt1627/virtualenv/tensorflow-nightly-GPU/bin:/home/emt1627/opt/cuda-8.0/bin:/home/emt1627/opt/git-2.11/bin:/home/emt1627/opt/htop-2.0.2/bin:/home/emt1627/opt/jdk1.8.0_112/bin:/home/emt1627/opt/bazel-0.4.3-dist/output:/sbin:/usr/sbin:/usr/local/sbin:/opt/rh/devtoolset-4/root/usr/bin:/opt/rh/rh-java-common/root/usr/bin:/opt/rh/python27/root/usr/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/external/nasm/nasm -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections -Wl,@bazel-out/host/bin/external/nasm/nasm-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n/usr/bin/ld: unrecognized option '-plugin'\r\n/usr/bin/ld: use the --help option for usage information\r\ncollect2: error: ld returned 1 exit status\r\n\r\n```", "Not sure what is going on there.\r\nMaybe this helps?\r\nhttp://stackoverflow.com/questions/24890865/usr-bin-ld-unrecognized-option-plugin-error", "I ended up using this solution : https://github.com/bazelbuild/bazel/issues/361\r\n\r\nI managed to compile the nightly version of tensorflow, now I am rebuilding r0.12.1 to try some of the bundled examples (e.g. models/images/mnist/convolutional.py) .\r\n\r\nI tried to run those with the nightly version but I ended up experiencing this issue : https://github.com/tensorflow/models/issues/857\r\n\r\nAs soon as I manage to run that example properly I will post my diff.", "I managed to build TensorFlow 0.12.1 with GPU support on the following configuration : \r\n\r\nRed Hat EL 6.8 (no root access)\r\nPython 2.7.8\r\nvirtualenv 13.1.0\r\ndevtoolset-4 (GCC 5.3.1)\r\nBazel 0.4.3 (built from source)\r\nGeForce GTX680 (compute capability 3.0)\r\nCuda Toolkit 8.0\r\ncuDNN 5.1\r\n\r\nThis is my final diff : \r\n\r\n```diff\r\ndiff --git a/configure b/configure\r\nindex 3fc0b5909..33e73b8d0 100755\r\n--- a/configure\r\n+++ b/configure\r\n@@ -22,7 +22,7 @@ function bazel_clean_and_fetch() {\r\n   # bazel clean --expunge currently doesn't work on Windows\r\n   # TODO(pcloudy): Re-enable it after bazel clean --expunge is fixed.\r\n   if ! is_windows; then\r\n-    bazel clean --expunge\r\n+    bazel clean --expunge_async\r\n   fi\r\n   bazel fetch //tensorflow/...\r\n }\r\n\r\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex d78cb7b57..42bf7c8b6 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -792,7 +792,7 @@ def tf_custom_op_library(name, srcs=[], gpu_srcs=[], deps=[]):\r\n   )\r\n\r\n def tf_extension_linkopts():\r\n-  return []  # No extension link opts\r\n+  return [\"-lrt\"]\r\n\r\n def tf_extension_copts():\r\n   return []  # No extension c opts\r\n\r\ndiff --git a/tensorflow/workspace.bzl b/tensorflow/workspace.bzl\r\nindex 06e16cdb0..d1ac0544e 100644\r\n--- a/tensorflow/workspace.bzl\r\n+++ b/tensorflow/workspace.bzl\r\n@@ -228,7 +228,7 @@ def tf_workspace(path_prefix = \"\", tf_repo_name = \"\"):\r\n\r\n   native.new_http_archive(\r\n     name = \"zlib_archive\",\r\n-    url = \"http://zlib.net/zlib-1.2.8.tar.gz\",\r\n+    url = \"http://zlib.net/fossils/zlib-1.2.8.tar.gz\",\r\n     sha256 = \"36658cb768a54c1d4dec43c3116c27ed893e88b02ecfcb44f2166f9c0b7f2a0d\",\r\n     strip_prefix = \"zlib-1.2.8\",\r\n     build_file = str(Label(\"//:zlib.BUILD\")),\r\n\r\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL.tpl b/third_party/gpus/crosstool/CROSSTOOL.tpl\r\nindex 3ce6b74a5..06e572691 100644\r\n--- a/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n+++ b/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n@@ -55,7 +55,9 @@ toolchain {\r\n   # and the device compiler to use \"-std=c++11\".\r\n   cxx_flag: \"-std=c++11\"\r\n   linker_flag: \"-lstdc++\"\r\n-  linker_flag: \"-B/usr/bin/\"\r\n+  linker_flag: \"-lm\"\r\n+  linker_flag: \"-lrt\"\r\n+  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin\"\r\n\r\n %{gcc_host_compiler_includes}\r\n   tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\r\n@@ -121,6 +123,8 @@ toolchain {\r\n\r\n   # Include directory for cuda headers.\r\n   cxx_builtin_include_directory: \"%{cuda_include_path}\"\r\n+  cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/lib\"\r\n+  cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/include\"\r\n\r\n   compilation_mode_flags {\r\n     mode: DBG\r\n```\r\n\r\nI hope this helps and thank you @gunan !\r\n", "I will try to see if I can add this to either an FAQ in our docs, or incorporate the modifications through our bazel switches.\r\nI will keep the issue open until then.", "Thanks for reporting this bug!", "@Sinan81, I hope this saved you some time!\r\n", "Looks like this problem is resolved.\r\nI suspect some of the problems we ran into here have been due to you not having full access to the system. I was able to test build on a centos docker container without any modifications. But I will try to see if I can reproduce your problems.\r\n\r\nThanks for patiently working through all the issues and documenting your steps here!"]}, {"number": 7117, "title": "Let dso_loader handle variations in the name of libcuda better on Mac", "body": "", "comments": ["Also tested on Mac GPU using experimental job (Jenkins login required to view log):\r\nhttp://ci.tensorflow.org/job/experimental-cais-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-mac/2/console", "Fixes #6693 ", "@martinwicke, does this look good to you?", "It looks fantastic."]}]