[{"number": 19014, "title": "How to quantize Mobilenet v2 ? ", "body": "## System information\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):Source\r\n- TensorFlow version (use command below):1.8.0rc0\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): 0.12.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version:cuda-9.0/7.0\r\n- GPU model and memory:GeForce GTX 1080/8105MiB\r\n- Phone: xiaomi5 (Snapdragon 820)\r\n\r\n## Describe the problem\r\nUsing **tf.contrib.quantize.create_training_graph()** and **tf.contrib.quantize.create_eval_graph()**,  I \r\nquantized training  Mobilenet v2,  and  export inference graph,  but  when toco pb to tflite,  I encountered the following error:\r\n\r\n2018-05-02 10:26:27.215975: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array MobilenetV2/expanded_conv_2/add, which is an input to the Conv operator producing the output array MobilenetV2/expanded_conv_3/expand/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\n\r\nThis layer MobilenetV2/expanded_conv_2/add  cannot be quantized ? \r\n\r\nWho can explain why ? \r\n\r\n## Source code / logs\r\n\r\nbazel run --config=opt \\\r\n>   //tensorflow/contrib/lite/toco:toco -- \\\r\n>   --input_file=${TRAIN_DIR}/frozen_graph.pb \\\r\n>   --output_file=${TRAIN_DIR}/tflite_model.tflite \\\r\n>   --input_format=TENSORFLOW_GRAPHDEF \\\r\n>   --output_format=TFLITE \\\r\n>   --inference_type=QUANTIZED_UINT8 \\\r\n>   --input_shape=1,224,224,3 \\\r\n>   --input_array=input \\\r\n>   --output_array=MobilenetV2/Predictions/Reshape_1 \\\r\n>   --std_value=127 \\\r\n>   --mean_value=128 \\\r\n>   --dump_graphviz=${TRAIN_DIR}\r\n\r\n```\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/apuser/tmp/models/flowers/mobilenet_v2_1.0_224_quan/frozen_graph.pb' '--output_file=/home/apuser/tmp/models/flowers/mobilenet_v2_1.0_224_quan/tflite_model.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=QUANTIZED_UINT8' '--input_shape=1,224,224,3' '--input_array=input' '--output_array=MobilenetV2/Predictions/Reshape_1' '--std_value=127' '--mean_value=128' '--dump_graphviz=/home/apuser/tmp/models/flowers/mobilenet_v2_1.0_224_quan'\r\n2018-05-02 10:26:26.887728: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1207 operators, 1752 arrays (0 quantized)\r\n2018-05-02 10:26:26.934465: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1207 operators, 1752 arrays (0 quantized)\r\n2018-05-02 10:26:27.211718: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 120 operators, 228 arrays (1 quantized)\r\n2018-05-02 10:26:27.214013: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 120 operators, 228 arrays (1 quantized)\r\n2018-05-02 10:26:27.215023: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 67 operators, 175 arrays (1 quantized)\r\n2018-05-02 10:26:27.215975: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array MobilenetV2/expanded_conv_2/add, which is an input to the Conv operator producing the output array MobilenetV2/expanded_conv_3/expand/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\n```\r\n\r\n", "comments": ["I used the same method, toco quantized mobilenet_v1 is no problem.\r\nI don't know where the problem is .\r\nWho can help ?", "This looks like a recent breakage. I will get a fix soon. Thanks!", "@suharshs , Thanks , I am looking forward to your reply!", "@suharshs, Has not the issue been resolved yet?\r\n\r\nI'm looking forward to fix the issue as soon as possible.\r\n\r\nIf the issue has not been resolved yet, How long does it take to fix the problem?\r\n\r\nAnd we got a message after the following commands,\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\nbazel run --config=opt   //tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb   \\\r\n--output_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/kanul.tflite \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_shape=1,513,513,3 \\\r\n--input_array=sub_7 \\\r\n--output_array=logits/semantic/BiasAdd\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\nUnimplemented: this graph contains an operator of type SpaceToBatchND for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).", "Hi @kanul,\r\n\r\nThe issue originally described should be resolved.\r\n\r\nIt seems that you are using a mobilenet_v2 implementation contains an unsupported operation. What mobilenet_v2 implementation are you using? The code I have tried out is here: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet_v2.py .\r\n\r\nMake sure you are freezing an eval graph and not a training graph and provide the correct input and output nodes when freezing as well.", "@suharshs, \r\n\r\nI want to develop segmentation mask based on mobilnetV2 for deeplabV3\r\n\r\nMy interested task is not classification but image segmentation\r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\r\nCheckpoint name: mobilenetv2_coco_voc_trainaug\r\n\r\nAnd where can I find the lists of operations supported from tensorflow lite?", "In the conversion of mobilenet v2, I encountered the same problem with @WenguoLi ,but the mobilenetv1 is ok, how do you solve it? @suharshs ", "Hi @OdingdongO , this should be fixed in 01a70dc. What TF version are you using? ", "I can confirm there are no errors with TF https://github.com/tensorflow/tensorflow/commit/8ff46ce4691e730a5303d328fa7bd634b746d5ae from ~May 21st and the image-classification version of MobileNetV2.\r\nI used the following commands https://github.com/parvizp/models/blob/b097785bbc5fc96ecf59605cb4a6d04e8b65e017/research/slim/scripts/quantize_mobilenet_v2_on_imagenet.sh .", "i update the tf-nightly-gpu by pip,but i got a error when i use the create_eval_ graph() in mobilenetv2\r\n,but the mobilenetv1 is  ok . @suharshs \r\n\r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key MobilenetV2/expanded_conv_11/post_activation_bypass_quant/max not found in checkpoint\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_306_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]", "@OdingdongO Where are you getting the checkpoint? Is it possible to provide a repro case?", "i can quant the mobilev2 by According to @parvizp tips now,thank you all @suharshs @parvizp ", "@OdingdongO Fantastic! Glad it is working for you now :)", "Hi @parvizp, I followed your steps in the script and when I tried to convert the model to tflite using toco I got the following error:\r\n\r\n2018-06-07 09:16:43.140917: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1206 operators, 1752 arrays (0 quantized)\r\n2018-06-07 09:16:43.202703: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1206 operators, 1752 arrays (0 quantized)\r\n2018-06-07 09:16:43.470889: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 120 operators, 227 arrays (1 quantized)\r\n2018-06-07 09:16:43.473547: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 120 operators, 227 arrays (1 quantized)\r\n2018-06-07 09:16:43.474518: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 67 operators, 174 arrays (1 quantized)\r\n2018-06-07 09:16:43.475388: F tensorflow/contrib/lite/toco/tooling_util.cc:1320] Array MobilenetV2/expanded_conv_2/add, which is an input to the Conv operator producing the output array MobilenetV2/expanded_conv_3/expand/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n\r\nI inspected the checkpoint and there are min/max for activations and weights.\r\n\r\nDo you have any idea how to solve this?", "I also kept on getting similar errors with using a MobileNetV2 backbone for my network.\r\n\r\nTo solve my issue, I made sure to create the training quantization nodes (`tf.contrib.quantize.create_training_graph(quant_delay=quant_delay)`) in my training graph with MobileNetV2 training scope:\r\n```\r\nwith tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):\r\n    <create mobilenetv2 based network>\r\n```\r\n\r\nWhere when I created my eval graph with quantization nodes (`tf.contrib.quantize.create_eval_graph()`), I made sure to load my MobileNetv2 model **without** the above training scope. This solved all of my errors of having nodes without having min/max information. \r\n\r\nI separated my training and evaluation into different scripts/functions in order to make it easier to separate the two graphs. \r\n\r\nI then [froze](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) my saved checkpoint weights from training with the graph from evaluation, then optimized them for [inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py), and finally converted to TFLite with [TOCO](https://github.com/tensorflow/tensorflow/blob/bfcfad55b7b3fa4a1093fa748d4241f9457b2a84/tensorflow/contrib/lite/python/tflite_convert.py) to get a quantized tflite file.\r\n\r\nHope this helps.", "i get this error ,when i use export inference graph.py to produce eval.pbtxt,i found whether i use tf.contrib.quantize.create_eval_graph() or not ,the produced eval.pbtxt are totally the same ,the function tf.contrib.quantize.create_eval_graph() not work at all !!", "@G-mel Thank you for your experiment! I am training a network whose backbone is mobilenetV2.\r\nWhen you use tf.contrib.quantize.create_training_graph(quant_delay=quant_delay), how many GPUs do you use? ", "@guvcolie My work was with only 1 GPU", "I use 0.8 gpu, do this has influence to the quantization?", "@parvizp I am currently working on quantization and try to run your script. However, there is a huge accuracy drop (~7%) after quantization. I am wondering how much performance drop your model suffers. Thank you!", "Im trying to convert pb to tflite, i run my model using Mobilenet v2, \r\nwhen trying to convert im getting the following error.\r\n\r\nbazel-bin/tensorflow/contrib/lite/toco/toco --input_file=/home/dell/TFObject-detection/tensorflow/models/research/object_detection/Output/frozen_inference_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=frozen_inference_graph.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=ImageTensor --output_arrays=SemanticPredictions --input_shapes=1,512,512,3 --allow_nonexistent_arrays\r\n\r\n\r\n2018-11-15 09:54:38.341689: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 0 operators, 2 arrays (0 quantized)\r\n2018-11-15 09:54:38.341711: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:135] Model is empty!!!\r\n2018-11-15 09:54:38.341737: W tensorflow/contrib/lite/toco/tooling_util.cc:1246] Fixing constant output array SemanticPredictions by inserting a copy. This is not optimal.\r\n2018-11-15 09:54:38.341749: F ./tensorflow/contrib/lite/toco/model.h:1984] Check failed: has_shape() \r\nAborted (core dumped)\r\n\r\n\r\nis that related to this issue? any hint?", "![default](https://user-images.githubusercontent.com/35597616/49368198-0be3d300-f729-11e8-89b3-b05ab3767ea1.png)\r\ni use\" tf.contrib.quantize.create_training_graph(input_graph=g,quant_delay=100)\" to train model and \"tf.contrib.quantize.create_eval_graph(input_graph=g)\" to eval model, but still need min and max\uff0ci don\u2018t kown why\uff1f @suharshs ", "@WindQAQ  hi,dou u successfully use parvizp's script,could you tell me which version of tensorflow do you ues. I use parvizp's script, it also occured the error\"lacking min and max information for depthwise/Relu6\"", "> I also kept on getting similar errors with using a MobileNetV2 backbone for my network.\r\n> \r\n> To solve my issue, I made sure to create the training quantization nodes (`tf.contrib.quantize.create_training_graph(quant_delay=quant_delay)`) in my training graph with MobileNetV2 training scope:\r\n> \r\n> ```\r\n> with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):\r\n>     <create mobilenetv2 based network>\r\n> ```\r\n> Where when I created my eval graph with quantization nodes (`tf.contrib.quantize.create_eval_graph()`), I made sure to load my MobileNetv2 model **without** the above training scope. This solved all of my errors of having nodes without having min/max information.\r\n> \r\n> I separated my training and evaluation into different scripts/functions in order to make it easier to separate the two graphs.\r\n> \r\n> I then [froze](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) my saved checkpoint weights from training with the graph from evaluation, then optimized them for [inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py), and finally converted to TFLite with [TOCO](https://github.com/tensorflow/tensorflow/blob/bfcfad55b7b3fa4a1093fa748d4241f9457b2a84/tensorflow/contrib/lite/python/tflite_convert.py) to get a quantized tflite file.\r\n> \r\n> Hope this helps.\r\n\r\nI found this response sufficient to resolve this issue. It is important to remember, however, that restoring the eval graph should be done **after** create_eval_graph() has been called\r\nhttps://github.com/tensorflow/tensorflow/issues/18919#issuecomment-386771852", "> Who can help ?\r\n\r\n\u60a8\u597d\uff0c\u3000\u4f60\u7684\u95ee\u9898\u89e3\u51b3\u4e86\u5417\uff1f\uff1f\uff1f", "> Hi @OdingdongO , this should be fixed in [01a70dc](https://github.com/tensorflow/tensorflow/commit/01a70dc43d32eb5add5f1cb5de2d6c98ed88dd83). What TF version are you using?\r\n\r\n\"What TF\" << I read that differently than intended ;)"]}, {"number": 19013, "title": "[Feature Request] Reuse curl handle in CurlHttpRequest class", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.12.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.1)\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nIn the [libcurl programming tutorial](https://curl.haxx.se/libcurl/c/libcurl-tutorial.html) under the section \"Persistence Is The Way to Happiness\" it notes that re-cycling the same easy handle can give several benefits. This could lead to performance improvements when using remote filesystems that utilise this class (e.g. gcs file system and I've been working on azure blob storage). Currently it seems that a single instance of the `CurlHttpRequest` and hence curl handle can only be used once and must be instantiated per request.\r\n\r\nIs this worth investigating to integrate some sort of 'reset' method to this class along with [curl_easy_reset](https://curl.haxx.se/libcurl/c/curl_easy_reset.html) plus extract defaults set in the constructor into a 'setup defaults' method? Plus some profiling to ensure the change is better?", "comments": ["@mrry, could yoou PTAL?", "I'm no curl expert, but this sounds like a contribution we'd welcome.", "Hi, imho I could handle this issue but im not sure what needs to be done here. It's about make CurlHttpRequest class as singleton?", "@mskwarek wouldn't need to be a singleton, but a way to reset the state so a subsequent request could be made with the same `tensorflow::CurlHttpRequest` instance (or really curl handle under that instance)", "`tensorflow::HttpRequest`, parent class of `CurlHttpRequest`, stats that it's not designed to be reused.\r\n```\r\n  /// \\brief Sends the formed request.\r\n  ///\r\n  /// If the result buffer was defined, the response will be written there.\r\n  /// The object is not designed to be re-used after Send() is executed.\r\n  virtual Status Send() = 0;\r\n\r\n```\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/cloud/http_request.h#L171", "With most of the io modules that would probably use this moving to tensorflow/io I'll close this here"]}, {"number": 19012, "title": "how many steps that are required to train the model>", "body": "I've trained the model for more than 12 hours and it is still training. How many steps that machine needs to complete the process?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Ubuntu 16.04\r\nTensorflow installed from Virtualenv\r\nTensorflow 1.7\r\nBazel 0.12\r\nCUDA/cuDNN 9.0\r\nGPU 1080 Ti\r\n\r\nbazel-bin/$examples_dir/cifar10/cifar10_train --pruning_hparams=name=cifar10_pruning,begin_pruning_step=10000,end_pruning_step=100000,target_sparsity=0.9,sparsity_function_begin_step=10000,sparsity_function_end_step=100000\r\n\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 19011, "title": "[Intel MKL] Enable Mac build on MKL", "body": "", "comments": ["Duplicated PR with https://github.com/tensorflow/tensorflow/pull/18726\r\n@claynerobison should we close this PR.", "Nagging Assignee @protoget: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I was able to verify that MKL build now works on macos. Should we close this PR?", "@opencici2006 Closing per Gunhan's suggestion."]}, {"number": 19010, "title": "Tensorflow r1.8  ImportError: dlopen: cannot load any more object with static TLS", "body": "Have I written custom code: No\r\nOS Platform and Distribution: Debian 8.10\r\nTensorFlow installed from: Source\r\nTensorFlow version: r1.8\r\nBazel version: 0.13.0\r\nCUDA/cuDNN version: n/a\r\nGPU model and memory: n/a\r\nExact command to reproduce:\r\n\r\nImporting Tensorflow r1.8 **after** some libraries (specifically cv2) results in: \r\n`ImportError: dlopen: cannot load any more object with static TLS`\r\n\r\n\r\n\r\nA temporary fix seems to be to import Tensorflow before any other libraries. \r\nHas this shown up before? Any other information I can provide?\r\n\r\n\r\nhttps://github.com/Kaggle/docker-python/issues/206\r\nhttps://www.kaggle.com/kmader/library-overload\r\n\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n/opt/conda/lib/python3.6/imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\n/opt/conda/lib/python3.6/imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: dlopen: cannot load any more object with static TLS\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-2-41389fad42b5> in <module>()\r\n----> 1 import tensorflow as tf\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 # pylint: disable=wildcard-import\r\n     26 from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/opt/conda/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/opt/conda/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen: cannot load any more object with static TLS\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Added information to the original post", "I've seen this problem in Ubuntu 14.04 which was solved by upgrading to 16.04 which raises static TLS limit. Basically each dynamically loaded .so can request a number of static TLS slots, and kernel sets limit on total number. I don't have explanation why changing import order can get around the TLS restriction", "\r\ni am also having similar issue\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\numpy\\__init__.py\", line 158, in <module>\r\n    from . import add_newdocs\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\numpy\\add_newdocs.py\", line 13, in <module>\r\n    from numpy.lib import add_newdoc\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\numpy\\lib\\__init__.py\", line 8, in <module>\r\n    from .type_check import *\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\numpy\\lib\\type_check.py\", line 11, in <module>\r\n    import numpy.core.numeric as _nx\r\n  File \"C:\\Users\\abc\\Anaconda3\\envs\\MYML\\lib\\site-packages\\numpy\\core\\__init__.py\", line 26, in <module>\r\n    raise ImportError(msg)", "Nagging Assignee @asimshankar: It has been 89 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Marking as \"Contributions Welcome\" since I don't believe anyone is actively looking at this at the moment.", "Same issue happened to me today with a fresh install of Keras. order of importing didn't make any difference. \r\nThe fix was updating it\r\n```\r\nconda upgrade -c conda-forge keras \r\n```", "Please try to use 1.15, 2.0, 2.1 or 2.2. 1.8 is not supported.\r\n\r\nIn fact, I think we should close this issue as no longer supported and open a new one if there are problems in the supported versions listed at the beginning of this comment", "Closing this issue as `TF1.8` is no longer support. \r\n\r\nFeel free to open a new issue if this issue persists with recent TF versions. Thanks! "]}, {"number": 19009, "title": "Incorrect results if set \"-c 100\" in TFLite label_image example", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution: Android:\r\n- **TensorFlow installed from binary:\r\n- **TensorFlow version: 1.6:\r\n- **Python version 2.7: \r\n- **Bazel version: 0.11.1:\r\n- **CUDA/cuDNN version: N/A\r\n- **GPU model and memory: N/A\r\n- **GCC/Compiler version: gcc-5:\r\n- **Exact command to reproduce**:\r\nlabel_image -b 128 -s 128 -i example.bmp -l labels_mobilenet_quant_v1_224.txt -m mobilenet_quant_v1_224.tflite -c 100\r\n\r\n### Describe the problem\r\nIncorrect results if set \"-c 100\" in TFLite label_image example. If only loop once, the result is correct, but if loop more than once, then the results somehow are all incorrect.\r\n\r\n### Source code / logs\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/label_image/label_image.cc#L194\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nCUDA/cuDNN version\nGPU model and memory", "Thanks, @terrydlca - can you provide further details as to how the you determined the results to be incorrect? What was output, and what were you expecting?", "Hi @terrydlca  We are tracking this internally as TF Lite shouldn't destroy (overwrite with intermediates) input tensors even on self-allocated buffers. Meanwhile, you can use -c 100 to measure overall performance, but accuracy of repeated inference without refreshing the input buffers will be incorrect.", "@karmel, for any input image, if run with (-c 1), the predicted class matched the ground truth, but if run with (-c 100), the predicted class is incorrect. But \"-c\" is just a loop count, so the result should be consistent no matter how many loops.", "@andrehentz, that make sense, thanks for helping to fix this.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Should be fixed now. Please reopen if problem persists."]}, {"number": 19008, "title": "Add conditions:default to mkl build", "body": "If building on a system that is not darwin, linux_x86_64, or\r\nwindows, the select statement in third_party/mkl/BUILD fails to\r\nfind a match and fails. Need to use no mkl libraries for non-x86\r\nsystems\r\n\r\nFixes #18084", "comments": []}, {"number": 19007, "title": "Using different optimizers on a trained model leads to poor test accuracy.", "body": "I have trained a convolutional neural network model using `AdamOptimizer`. The test accuracy is pretty good. This was expected since the validation loss was decreasing while training.\r\n\r\nNow I restored the model weights using `saver.restore()` method, but this time I built the model with `RMSPropOptimizer` just for experimenting. Please note that I **DID NOT RETRAIN THE MODEL**. To my surprise, the test accuracy was horrible with the new optimizer. The accuracy becomes good again when I use the previously used `AdamOptimizer`.\r\n\r\nThis is peculiar in the sense that the train_op should not affect the test data results.\r\n\r\nBelow is the sample code I used for calculating the test accuracy. Please note I did not run the `train_op` here.\r\n\r\n```\r\naccuracies = []\r\n\r\n# Data generator\r\nfor batchx, batchy in dataLoader.next_validation():\r\n    # Run the graph.\r\n    pred = sess.run(model['prediction'], \r\n                        feed_dict={\r\n                            model['sensor_data']: batchx,\r\n                            model['label']: batchy\r\n                        })\r\n        \r\n    accuracies.append(np.count_nonzero(pred == label) / pred.shape[0] * 100)\r\n\r\naccuracies = np.array(accuracies)\r\nprint(\"Average Validation set accuracy: {} %\".format(accuracies.mean()))\r\n```\r\n\r\nAm I missing something here? Or is this a possible bug?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: YES\r\nOS Platform and Distribution: Ubuntu 16.04\r\nTensorFlow installed from pip3\r\nTensorFlow version : 1.6.0\r\nBazel version: NA\r\nCUDA/cuDNN version: Cuda Toolkit 9.0, cuDNN v7.0\r\nGPU model and memory: GeForce GTX 860M (4GB)\r\n\r\nExact command to reproduce: The code is quite large :(\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 19006, "title": "TF serving for TensorFlow 1.7 or more", "body": "Dear all,\r\n\r\nMy machine is a MacBook Pro with  macOS HighSierra 10.13.1 and I am using tf 1.7.  I am trying to use tensorflow serving without any results since the [doc](https://www.tensorflow.org/serving/docker) is not updated for Tensorflow 1.7. The doc says to \r\n\r\n```\r\ngit clone --recurse-submodules https://github.com/tensorflow/serving\r\ncd serving/tensorflow\r\n./configure\r\ncd ..\r\nbazel test tensorflow_serving/...\r\n```\r\nBut there is no `serving/tensorflow` folder in the container. Following the doc I did:\r\n1) Create the container\r\n\r\n```\r\ndocker build --pull -t $USER/tensorflow-serving-devel -f Dockerfile.devel .\r\n```\r\nWhere the docker file is the one provided by the doc\r\n2) Run it\r\n```\r\ndocker run -it $USER/tensorflow-serving-devel\r\n```\r\n3)Try to build tf serving\r\n\r\n```\r\nroot@5db9a099bd77:/# git clone --recurse-submodules https://github.com/tensorflow/serving\r\nCloning into 'serving'...\r\n\r\nremote: Counting objects: 6476, done.\r\nremote: Compressing objects: 100% (16/16), done.\r\nremote: Total 6476 (delta 7), reused 17 (delta 7), pack-reused 6452\r\nReceiving objects: 100% (6476/6476), 2.43 MiB | 1.07 MiB/s, done.\r\nResolving deltas: 100% (4628/4628), done.\r\nChecking connectivity... done.\r\nroot@5db9a099bd77:/# cd serving/tensorflow\r\nbash: cd: serving/tensorflow: No such file or directory\r\n```\r\n\r\nSo, basically, how can I run my model in production? I also think that you should maintain a docker image with TF serving already built on it to make it easier for the community to use it.\r\n\r\nCheers,\r\n\r\nFrancesco Saverio Zuppichini", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "@jart It is a bug, the doc is wrong. If you read carefully I have explained that the tutorial that is in the doc does not work since the actual folder structure is different. Thank you for answer", "I confirm this. Structure is changed and now I have no idea how to build serving...", "@FrancescoSaverioZuppichini \r\nI encountered a similar issue when do the tensorflow-serving 1.7 compilation with a specified python.\r\nhttps://github.com/tensorflow/serving/issues/921.\r\nThe file structure is changed, and I'm finding a way to pass the include path of python to compilation."]}, {"number": 19005, "title": "TFLite conversation failed", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MAC OSX\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **CUDA/cuDNN version**: 9/7\r\n- **GPU model and memory**: 1080Ti 12G\r\n- **Exact command to reproduce**: N/A\r\n\r\nI wrote a code for mobile net and generated model. Converted model from keras(.h5) to frozen graph(.pb) Summary of graph is \r\n```\r\n$ ./bazel-bin/tensorflow/tools/graph_transforms/summarize_graph   --in_graph=s.pb\r\nFound 1 possible inputs: (name=input_1, type=float(1), shape=[?,224,224,3]) \r\nNo variables spotted.\r\nFound 1 possible outputs: (name=dense_1/Sigmoid, op=Sigmoid) \r\nFound 4254887 (4.25M) const parameters, 0 (0) variable parameters, and 4 control_edges\r\nOp types used: 164 Switch, 154 Const, 84 Mul, 56 Add, 28 Sub, 28 Merge, 27 Relu, 27 Minimum, 27 FusedBatchNorm, 27 Rsqrt, 15 Conv2D, 14 Pad, 13 DepthwiseConv2dNative, 3 Shape, 2 BiasAdd, 2 StridedSlice, 2 Pack, 2 Reshape, 2 RealDiv, 1 Max, 1 RandomUniform, 1 MatMul, 1 Floor, 1 Sigmoid, 1 Mean, 1 Exp, 1 Sum, 1 Placeholder\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=s.pb --show_flops --input_layer=input_1 --input_layer_type=float --input_layer_shape=-1,224,224,3 --output_layer=dense_1/Sigmoid\r\n```\r\nWhen I try to convert it into tflite it gives me following error:\r\n```\r\n$ ./bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=s.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=train-1.tflite --inference_type=FLOAT --input_arrays=input_1 --output_arrays=dense_1/Sigmoid --v=2\r\n2018-05-01 14:13:50.005925: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: RandomUniform\r\n2018-05-01 14:13:50.233921: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 640 operators, 986 arrays (0 quantized)\r\n2018-05-01 14:13:50.454878: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 639 operators, 984 arrays (0 quantized)\r\n2018-05-01 14:13:50.696498: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 639 operators, 984 arrays (0 quantized)\r\n2018-05-01 14:13:50.861230: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:86] Check failed: mean_shape.dims() == multiplier_shape.dims() \r\nAborted\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 19004, "title": "Windows build fails with unresolved externals", "body": "I followed the instructions to build on Windows (Windows 10, Visual Studio 2017 version 15.6.7, CPU only), but the following projects fail to build:\r\ntf_python_api\r\ngrpc_tensorflow_server\r\nbenchmark_model\r\ntf_tutorials_example_trainer\r\ntf_label_image_example\r\ncompare_graphs\r\ntransform_graph\r\nsummarize_graph\r\n\r\nWith the same four unresolved externals:\r\nLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n\r\nLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\t\r\n\r\nLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n\r\nLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I also get the completely same error at the same day loL\r\nOS:Windows 10 \r\nInstall MKL from Intel official website\r\nTensorflow install from:git\r\nTensorflow version: this github\r\nno GPU, CPU only\r\nBuild by cmake and compile by VS 14\r\nInstall command:\r\nC:\\...\\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\nMore? -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12/swig.exe ^\r\nMore? -DPYTHON_EXECUTABLE=C:/Users/dear9/Anaconda3/envs/py35/python.exe ^\r\nMore? -DPYTHON_LIBRARIES=C:/Users/dear9/Anaconda3/envs/py35/libs/python35.lib ^\r\nMore? -Dtensorflow_ENABLE_MKL_SUPPORT=ON ^\r\nMore? -DMKL_HOME=\"C:\\Program Files (x86)\\IntelSWTools\\compilers_and_libraries\"\r\nMore? -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX\r\n\r\nthe  configuration has no error. Then\r\n\r\nC:\\...\\build>MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj\r\n\r\nthe error comes out\r\nDo you need more information?", "I have got same issue using\r\n\r\n-Have I written custom code (as opposed to using a stock example script provided in TensorFlow) : NO\r\n- OS Platform and Distribution : WINDOWS 10\r\n-TensorFlow installed from (source or binary) : git clone\r\n-  TensorFlow version (use command below) : \r\nlast commit: \r\ncommit 8cb6e535f6ea14b380aa86d425169adad682cb8c (HEAD -> master, origin/master, origin/HEAD)\r\nMerge: d0f5bc1756 29cd3f9632\r\nAuthor: Joel Shor <joel-shor@users.noreply.github.com>\r\nDate:   Wed May 2 03:08:57 2018 +0300\r\n\r\n-  Python version : 3.6.4\r\n-  Bazel version (if compiling from source) : NO using CMAKE 3.11.0\r\n- GCC/Compiler version (if compiling from source): VS 2017 version 15.6.3\r\n- CUDA/cuDNN version: no only cpu version\r\n- GPU model and memory : NOT USE\r\n- Exact command to reproduce :\r\n\r\nUse cmake : cmakecache is \r\n[CMakeCache.txt](https://github.com/tensorflow/tensorflow/files/1967505/CMakeCache.txt)\r\n\r\nIn vs 2017 errors are : \r\n```\r\n1>------ Build started: Project: zlib, Configuration: Release x64 ------\r\n2>------ Build started: Project: nsync, Configuration: Release x64 ------\r\n3>------ Build started: Project: farmhash, Configuration: Release x64 ------\r\n4>------ Build started: Project: highwayhash, Configuration: Release x64 ------\r\n5>------ Build started: Project: jpeg, Configuration: Release x64 ------\r\n6>------ Build started: Project: gif, Configuration: Release x64 ------\r\n7>------ Build started: Project: sqlite, Configuration: Release x64 ------\r\n8>------ Build started: Project: lmdb, Configuration: Release x64 ------\r\n9>------ Build started: Project: fft2d, Configuration: Release x64 ------\r\n10>------ Build started: Project: snappy, Configuration: Release x64 ------\r\n1>Performing update step for 'zlib'\r\n2>Performing update step for 'nsync'\r\n4>Performing update step for 'highwayhash'\r\n11>------ Build started: Project: farmhash_create_destination_dir, Configuration: Release x64 ------\r\n12>------ Build started: Project: jpeg_create_destination_dir, Configuration: Release x64 ------\r\n13>------ Build started: Project: gif_create_destination_dir, Configuration: Release x64 ------\r\n14>------ Build started: Project: sqlite_create_destination_dir, Configuration: Release x64 ------\r\n15>------ Build started: Project: lmdb_create_destination_dir, Configuration: Release x64 ------\r\n16>------ Build started: Project: double_conversion, Configuration: Release x64 ------\r\n17>------ Build started: Project: png, Configuration: Release x64 ------\r\n18>------ Build started: Project: protobuf, Configuration: Release x64 ------\r\n19>------ Build started: Project: nsync_create_destination_dir, Configuration: Release x64 ------\r\n20>------ Build started: Project: zlib_create_destination_dir, Configuration: Release x64 ------\r\n21>------ Build started: Project: highwayhash_create_destination_dir, Configuration: Release x64 ------\r\n22>------ Build started: Project: gemmlowp, Configuration: Release x64 ------\r\n16>Performing update step for 'double_conversion'\r\n23>------ Build started: Project: lmdb_copy_headers_to_destination, Configuration: Release x64 ------\r\n24>------ Build started: Project: sqlite_copy_headers_to_destination, Configuration: Release x64 ------\r\n18>Performing update step for 'protobuf'\r\n25>------ Build started: Project: png_create_destination_dir, Configuration: Release x64 ------\r\n26>------ Build started: Project: eigen, Configuration: Release x64 ------\r\n27>------ Build started: Project: gif_copy_headers_to_destination, Configuration: Release x64 ------\r\n28>------ Build started: Project: zlib_copy_headers_to_destination, Configuration: Release x64 ------\r\n29>------ Build started: Project: highwayhash_copy_headers_to_destination, Configuration: Release x64 ------\r\n30>------ Build started: Project: grpc, Configuration: Release x64 ------\r\n31>------ Build started: Project: farmhash_copy_headers_to_destination, Configuration: Release x64 ------\r\n32>------ Build started: Project: png_copy_headers_to_destination, Configuration: Release x64 ------\r\n33>------ Build started: Project: re2, Configuration: Release x64 ------\r\n34>------ Build started: Project: cub, Configuration: Release x64 ------\r\n35>------ Build started: Project: jpeg_copy_headers_to_destination, Configuration: Release x64 ------\r\n36>------ Build started: Project: nsync_copy_headers_to_destination, Configuration: Release x64 ------\r\n30>Performing update step for 'grpc'\r\n33>Performing update step for 're2'\r\n37>------ Build started: Project: jsoncpp, Configuration: Release x64 ------\r\n38>------ Build started: Project: create_cc_ops_header_dir, Configuration: Release x64 ------\r\n39>------ Build started: Project: force_rebuild_target, Configuration: Release x64 ------\r\n40>------ Build started: Project: tf_python_copy_scripts_to_destination, Configuration: Release x64 ------\r\n10>Performing update step for 'snappy'\r\n37>Performing update step for 'jsoncpp'\r\n39>Generating __force_rebuild\r\n39>\r\n39>Generating F:/lib/tensorflow/tensorflow/core/util/version_info.cc\r\n41>------ Build started: Project: tf_core_lib, Configuration: Release x64 ------\r\n41>mutex.cc\r\n41>random_distributions.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n41>tf_core_lib.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_lib.dir\\Release\\tf_core_lib.lib\r\n41>Done building project \"tf_core_lib.vcxproj\".\r\n42>------ Build started: Project: proto_text, Configuration: Release x64 ------\r\n42>proto_text.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\proto_text.exe\r\n43>------ Build started: Project: tf_core_framework, Configuration: Release x64 ------\r\n43>Generating __force_rebuild\r\n43>\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/example/example.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/example/feature.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/allocation_description.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/attr_value.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/cost_graph.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/device_attributes.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/function.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/graph.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/graph_transfer_info.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/kernel_def.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/log_memory.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/node_def.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/op_def.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/remote_fused_graph_execute_info.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/resource_handle.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/step_stats.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/summary.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/tensor.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/tensor_description.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/tensor_shape.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/tensor_slice.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/types.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/framework/versions.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/lib/core/error_codes.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/cluster.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/config.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/debug.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/device_properties.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/rewriter_config.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/tensor_bundle.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/protobuf/saver.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/util/memmapped_file_system.proto\r\n43>Running C++ protocol buffer text compiler (proto_text) on tensorflow/core/util/saved_tensor_slice.proto\r\n43>Generating F:/lib/tensorflow/tensorflow/core/util/version_info.cc\r\n43>example.pb_text.cc\r\n43>feature.pb_text.cc\r\n43>allocation_description.pb_text.cc\r\n43>attr_value.pb_text.cc\r\n43>cost_graph.pb_text.cc\r\n43>device_attributes.pb_text.cc\r\n43>function.pb_text.cc\r\n43>graph.pb_text.cc\r\n43>graph_transfer_info.pb_text.cc\r\n43>kernel_def.pb_text.cc\r\n43>log_memory.pb_text.cc\r\n43>node_def.pb_text.cc\r\n43>op_def.pb_text.cc\r\n43>remote_fused_graph_execute_info.pb_text.cc\r\n43>resource_handle.pb_text.cc\r\n43>step_stats.pb_text.cc\r\n43>summary.pb_text.cc\r\n43>tensor.pb_text.cc\r\n43>tensor_description.pb_text.cc\r\n43>tensor_shape.pb_text.cc\r\n43>tensor_slice.pb_text.cc\r\n43>types.pb_text.cc\r\n43>versions.pb_text.cc\r\n43>error_codes.pb_text.cc\r\n43>cluster.pb_text.cc\r\n43>config.pb_text.cc\r\n43>debug.pb_text.cc\r\n43>device_properties.pb_text.cc\r\n43>rewriter_config.pb_text.cc\r\n43>saver.pb_text.cc\r\n43>tensor_bundle.pb_text.cc\r\n43>memmapped_file_system.pb_text.cc\r\n43>saved_tensor_slice.pb_text.cc\r\n43>session_factory.cc\r\n43>attr_value_util.cc\r\n43>function.cc\r\n43>graph_def_util.cc\r\n43>kernel_def_builder.cc\r\n43>log_memory.cc\r\n43>node_def_util.cc\r\n43>op_def_util.cc\r\n43>op_kernel.cc\r\n43>shape_inference.cc\r\n43>example_proto_fast_parsing.cc\r\n43>example_proto_helper.cc\r\n43>tensor_bundle.cc\r\n43>tensor_slice_reader.cc\r\n43>tensor_slice_writer.cc\r\n43>version_info.cc\r\n43>tf_core_framework.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_framework.dir\\Release\\tf_core_framework.lib\r\n44>------ Build started: Project: tf_cc_op_gen_main, Configuration: Release x64 ------\r\n45>------ Build started: Project: tf_core_cpu, Configuration: Release x64 ------\r\n46>------ Build started: Project: tf_cc_framework, Configuration: Release x64 ------\r\n47>------ Build started: Project: tf_python_op_gen_main, Configuration: Release x64 ------\r\n44>cc_op_gen.cc\r\n46>scope.cc\r\n47>python_eager_op_gen.cc\r\n47>python_op_gen.cc\r\n45>accumulate_n_optimizer.cc\r\n45>base_collective_executor.cc\r\n45>broadcaster.cc\r\n45>buf_rendezvous.cc\r\n45>collective_executor_mgr.cc\r\n45>collective_param_resolver_local.cc\r\n45>collective_rma_local.cc\r\n45>copy_tensor.cc\r\n45>debugger_state_interface.cc\r\n45>device.cc\r\n45>device_mgr.cc\r\n45>device_resolver_local.cc\r\n45>device_set.cc\r\n45>context.cc\r\n45>eager_executor.cc\r\n45>eager_operation.cc\r\n45>execute.cc\r\n45>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\core\\common_runtime\\eager\\eager_operation.cc)\r\n45>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\core\\common_runtime\\eager\\eager_operation.cc)\r\n45>kernel_and_device.cc\r\n45>tensor_handle.cc\r\n45>eval_const_tensor.cc\r\n45>executor.cc\r\n45>function.cc\r\n45>graph_execution_state.cc\r\n44>tf_cc_op_gen_main.vcxproj -> F:\\lib\\build\\tensorflow\\tf_cc_op_gen_main.dir\\Release\\tf_cc_op_gen_main.lib\r\n47>tf_python_op_gen_main.vcxproj -> F:\\lib\\build\\tensorflow\\tf_python_op_gen_main.dir\\Release\\tf_python_op_gen_main.lib\r\n48>------ Build started: Project: string_ops_gen_cc, Configuration: Release x64 ------\r\n49>------ Build started: Project: stateless_random_ops_gen_cc, Configuration: Release x64 ------\r\n50>------ Build started: Project: state_ops_gen_cc, Configuration: Release x64 ------\r\n51>------ Build started: Project: array_ops_gen_cc, Configuration: Release x64 ------\r\n52>------ Build started: Project: audio_ops_gen_cc, Configuration: Release x64 ------\r\n53>------ Build started: Project: set_ops_gen_cc, Configuration: Release x64 ------\r\n54>------ Build started: Project: batch_ops_gen_cc, Configuration: Release x64 ------\r\n46>tf_cc_framework.vcxproj -> F:\\lib\\build\\tensorflow\\tf_cc_framework.dir\\Release\\tf_cc_framework.lib\r\n55>------ Build started: Project: functional_ops_gen_cc, Configuration: Release x64 ------\r\n56>------ Build started: Project: spectral_ops_gen_cc, Configuration: Release x64 ------\r\n45>graph_optimizer.cc\r\n56>   Creating library F:/lib/build/tensorflow/Release/spectral_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/spectral_ops_gen_cc.exp\r\n51>   Creating library F:/lib/build/tensorflow/Release/array_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/array_ops_gen_cc.exp\r\n49>   Creating library F:/lib/build/tensorflow/Release/stateless_random_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/stateless_random_ops_gen_cc.exp\r\n48>   Creating library F:/lib/build/tensorflow/Release/string_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/string_ops_gen_cc.exp\r\n55>   Creating library F:/lib/build/tensorflow/Release/functional_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/functional_ops_gen_cc.exp\r\n45>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\core\\common_runtime\\eager\\execute.cc)\r\n45>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\core\\common_runtime\\eager\\execute.cc)\r\n54>   Creating library F:/lib/build/tensorflow/Release/batch_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/batch_ops_gen_cc.exp\r\n45>graph_runner.cc\r\n50>   Creating library F:/lib/build/tensorflow/Release/state_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/state_ops_gen_cc.exp\r\n48>string_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\string_ops_gen_cc.exe\r\n56>spectral_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\spectral_ops_gen_cc.exe\r\n45>local_device.cc\r\n51>array_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\array_ops_gen_cc.exe\r\n49>stateless_random_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\stateless_random_ops_gen_cc.exe\r\n55>functional_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\functional_ops_gen_cc.exe\r\n50>state_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\state_ops_gen_cc.exe\r\n57>------ Build started: Project: bitwise_ops_gen_cc, Configuration: Release x64 ------\r\n58>------ Build started: Project: boosted_trees_ops_gen_cc, Configuration: Release x64 ------\r\n59>------ Build started: Project: candidate_sampling_ops_gen_cc, Configuration: Release x64 ------\r\n45>optimization_registry.cc\r\n54>batch_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\batch_ops_gen_cc.exe\r\n60>------ Build started: Project: checkpoint_ops_gen_cc, Configuration: Release x64 ------\r\n61>------ Build started: Project: sparse_ops_gen_cc, Configuration: Release x64 ------\r\n62>------ Build started: Project: sendrecv_ops_gen_cc, Configuration: Release x64 ------\r\n45>parallel_concat_optimizer.cc\r\n63>------ Build started: Project: image_ops_gen_cc, Configuration: Release x64 ------\r\n53>   Creating library F:/lib/build/tensorflow/Release/set_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/set_ops_gen_cc.exp\r\n57>   Creating library F:/lib/build/tensorflow/Release/bitwise_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/bitwise_ops_gen_cc.exp\r\n45>placer.cc\r\n45>process_function_library_runtime.cc\r\n45>renamed_device.cc\r\n59>   Creating library F:/lib/build/tensorflow/Release/candidate_sampling_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/candidate_sampling_ops_gen_cc.exp\r\n45>rendezvous_mgr.cc\r\n62>   Creating library F:/lib/build/tensorflow/Release/sendrecv_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/sendrecv_ops_gen_cc.exp\r\n63>   Creating library F:/lib/build/tensorflow/Release/image_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/image_ops_gen_cc.exp\r\n45>ring_reducer.cc\r\n53>set_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\set_ops_gen_cc.exe\r\n58>   Creating library F:/lib/build/tensorflow/Release/boosted_trees_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/boosted_trees_ops_gen_cc.exp\r\n57>bitwise_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\bitwise_ops_gen_cc.exe\r\n59>candidate_sampling_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\candidate_sampling_ops_gen_cc.exe\r\n45>shape_refiner.cc\r\n63>image_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\image_ops_gen_cc.exe\r\n62>sendrecv_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\sendrecv_ops_gen_cc.exe\r\n64>------ Build started: Project: io_ops_gen_cc, Configuration: Release x64 ------\r\n65>------ Build started: Project: script_ops_gen_cc, Configuration: Release x64 ------\r\n66>------ Build started: Project: linalg_ops_gen_cc, Configuration: Release x64 ------\r\n67>------ Build started: Project: list_ops_gen_cc, Configuration: Release x64 ------\r\n45>threadpool_device.cc\r\n52>   Creating library F:/lib/build/tensorflow/Release/audio_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/audio_ops_gen_cc.exp\r\n45>threadpool_device_factory.cc\r\n58>boosted_trees_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\boosted_trees_ops_gen_cc.exe\r\n68>------ Build started: Project: decode_proto_ops_gen_cc, Configuration: Release x64 ------\r\n60>   Creating library F:/lib/build/tensorflow/Release/checkpoint_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/checkpoint_ops_gen_cc.exp\r\n45>debug.cc\r\n45>debug_gateway.cc\r\n45>debug_graph_utils.cc\r\n65>   Creating library F:/lib/build/tensorflow/Release/script_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/script_ops_gen_cc.exp\r\n64>   Creating library F:/lib/build/tensorflow/Release/io_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/io_ops_gen_cc.exp\r\n52>audio_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\audio_ops_gen_cc.exe\r\n69>------ Build started: Project: logging_ops_gen_cc, Configuration: Release x64 ------\r\n45>debugger_state_impl.cc\r\n45>gradients.cc\r\n60>checkpoint_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\checkpoint_ops_gen_cc.exe\r\n70>------ Build started: Project: sdca_ops_gen_cc, Configuration: Release x64 ------\r\n68>   Creating library F:/lib/build/tensorflow/Release/decode_proto_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/decode_proto_ops_gen_cc.exp\r\n64>io_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\io_ops_gen_cc.exe\r\n65>script_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\script_ops_gen_cc.exe\r\n45>graph_constructor.cc\r\n71>------ Build started: Project: lookup_ops_gen_cc, Configuration: Release x64 ------\r\n72>------ Build started: Project: rpc_ops_gen_cc, Configuration: Release x64 ------\r\n45>quantize_training.cc\r\n45>cluster.cc\r\n66>   Creating library F:/lib/build/tensorflow/Release/linalg_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/linalg_ops_gen_cc.exp\r\n61>   Creating library F:/lib/build/tensorflow/Release/sparse_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/sparse_ops_gen_cc.exp\r\n45>virtual_cluster.cc\r\n68>decode_proto_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\decode_proto_ops_gen_cc.exe\r\n70>   Creating library F:/lib/build/tensorflow/Release/sdca_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/sdca_ops_gen_cc.exp\r\n67>   Creating library F:/lib/build/tensorflow/Release/list_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/list_ops_gen_cc.exp\r\n72>   Creating library F:/lib/build/tensorflow/Release/rpc_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/rpc_ops_gen_cc.exp\r\n45>analytical_cost_estimator.cc\r\n73>------ Build started: Project: manip_ops_gen_cc, Configuration: Release x64 ------\r\n66>linalg_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\linalg_ops_gen_cc.exe\r\n69>   Creating library F:/lib/build/tensorflow/Release/logging_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/logging_ops_gen_cc.exp\r\n61>sparse_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\sparse_ops_gen_cc.exe\r\n74>------ Build started: Project: random_ops_gen_cc, Configuration: Release x64 ------\r\n75>------ Build started: Project: math_ops_gen_cc, Configuration: Release x64 ------\r\n45>graph_memory.cc\r\n76>------ Build started: Project: resource_variable_ops_gen_cc, Configuration: Release x64 ------\r\n45>graph_properties.cc\r\n70>sdca_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\sdca_ops_gen_cc.exe\r\n67>list_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\list_ops_gen_cc.exe\r\n45>measuring_cost_estimator.cc\r\n72>rpc_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\rpc_ops_gen_cc.exe\r\n69>logging_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\logging_ops_gen_cc.exe\r\n45>virtual_placer.cc\r\n77>------ Build started: Project: control_flow_ops_gen_cc, Configuration: Release x64 ------\r\n78>------ Build started: Project: nn_ops_gen_cc, Configuration: Release x64 ------\r\n74>   Creating library F:/lib/build/tensorflow/Release/random_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/random_ops_gen_cc.exp\r\n73>   Creating library F:/lib/build/tensorflow/Release/manip_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/manip_ops_gen_cc.exp\r\n79>------ Build started: Project: ctc_ops_gen_cc, Configuration: Release x64 ------\r\n71>   Creating library F:/lib/build/tensorflow/Release/lookup_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/lookup_ops_gen_cc.exp\r\n45>virtual_scheduler.cc\r\n75>   Creating library F:/lib/build/tensorflow/Release/math_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/math_ops_gen_cc.exp\r\n45>grappler_item_builder.cc\r\n74>random_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\random_ops_gen_cc.exe\r\n73>manip_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\manip_ops_gen_cc.exe\r\n77>   Creating library F:/lib/build/tensorflow/Release/control_flow_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/control_flow_ops_gen_cc.exp\r\n71>lookup_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\lookup_ops_gen_cc.exe\r\n80>------ Build started: Project: cudnn_rnn_ops_gen_cc, Configuration: Release x64 ------\r\n45>arithmetic_optimizer.cc\r\n45>auto_parallel.cc\r\n78>   Creating library F:/lib/build/tensorflow/Release/nn_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/nn_ops_gen_cc.exp\r\n81>------ Build started: Project: no_op_gen_cc, Configuration: Release x64 ------\r\n82>------ Build started: Project: data_flow_ops_gen_cc, Configuration: Release x64 ------\r\n75>math_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\math_ops_gen_cc.exe\r\n76>   Creating library F:/lib/build/tensorflow/Release/resource_variable_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/resource_variable_ops_gen_cc.exp\r\n77>control_flow_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\control_flow_ops_gen_cc.exe\r\n78>nn_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\nn_ops_gen_cc.exe\r\n83>------ Build started: Project: dataset_ops_gen_cc, Configuration: Release x64 ------\r\n84>------ Build started: Project: parsing_ops_gen_cc, Configuration: Release x64 ------\r\n45>debug_stripper.cc\r\n85>------ Build started: Project: encode_proto_ops_gen_cc, Configuration: Release x64 ------\r\n76>resource_variable_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\resource_variable_ops_gen_cc.exe\r\n45>dependency_optimizer.cc\r\n86>------ Build started: Project: remote_fused_graph_ops_gen_cc, Configuration: Release x64 ------\r\n87>------ Build started: Project: training_ops_gen_cc, Configuration: Release x64 ------\r\n80>   Creating library F:/lib/build/tensorflow/Release/cudnn_rnn_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/cudnn_rnn_ops_gen_cc.exp\r\n45>function_optimizer.cc\r\n81>   Creating library F:/lib/build/tensorflow/Release/no_op_gen_cc.lib and object F:/lib/build/tensorflow/Release/no_op_gen_cc.exp\r\n84>   Creating library F:/lib/build/tensorflow/Release/parsing_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/parsing_ops_gen_cc.exp\r\n79>   Creating library F:/lib/build/tensorflow/Release/ctc_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/ctc_ops_gen_cc.exp\r\n81>no_op_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\no_op_gen_cc.exe\r\n45>gpu_swapping_kernels.cc\r\n45>graph_optimizer_stage.cc\r\n80>cudnn_rnn_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\cudnn_rnn_ops_gen_cc.exe\r\n88>------ Build started: Project: user_ops_gen_cc, Configuration: Release x64 ------\r\n45>layout_optimizer.cc\r\n87>   Creating library F:/lib/build/tensorflow/Release/training_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/training_ops_gen_cc.exp\r\n89>------ Build started: Project: summary_ops_gen_cc, Configuration: Release x64 ------\r\n84>parsing_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\parsing_ops_gen_cc.exe\r\n79>ctc_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\ctc_ops_gen_cc.exe\r\n83>   Creating library F:/lib/build/tensorflow/Release/dataset_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/dataset_ops_gen_cc.exp\r\n90>------ Build started: Project: contrib_seq2seq_beam_search_ops_gen_python, Configuration: Release x64 ------\r\n45>loop_optimizer.cc\r\n87>training_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\training_ops_gen_cc.exe\r\n88>   Creating library F:/lib/build/tensorflow/Release/user_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/user_ops_gen_cc.exp\r\n86>   Creating library F:/lib/build/tensorflow/Release/remote_fused_graph_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/remote_fused_graph_ops_gen_cc.exp\r\n89>   Creating library F:/lib/build/tensorflow/Release/summary_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/summary_ops_gen_cc.exp\r\n82>   Creating library F:/lib/build/tensorflow/Release/data_flow_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/data_flow_ops_gen_cc.exp\r\n45>memory_optimizer.cc\r\n83>dataset_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\dataset_ops_gen_cc.exe\r\n88>user_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\user_ops_gen_cc.exe\r\n45>meta_optimizer.cc\r\n45>static_schedule.cc\r\n89>summary_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\summary_ops_gen_cc.exe\r\n86>remote_fused_graph_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\remote_fused_graph_ops_gen_cc.exe\r\n91>------ Build started: Project: contrib_tensor_forest_hybrid_ops_gen_python, Configuration: Release x64 ------\r\n82>data_flow_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\data_flow_ops_gen_cc.exe\r\n92>------ Build started: Project: contrib_tensor_forest_model_ops_gen_python, Configuration: Release x64 ------\r\n85>   Creating library F:/lib/build/tensorflow/Release/encode_proto_ops_gen_cc.lib and object F:/lib/build/tensorflow/Release/encode_proto_ops_gen_cc.exp\r\n93>------ Build started: Project: contrib_tensor_forest_ops_gen_python, Configuration: Release x64 ------\r\n94>------ Build started: Project: contrib_tensor_forest_stats_ops_gen_python, Configuration: Release x64 ------\r\n95>------ Build started: Project: contrib_text_skip_gram_ops_gen_python, Configuration: Release x64 ------\r\n96>------ Build started: Project: control_flow_ops_gen_python, Configuration: Release x64 ------\r\n85>encode_proto_ops_gen_cc.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\encode_proto_ops_gen_cc.exe\r\n97>------ Build started: Project: ctc_ops_gen_python, Configuration: Release x64 ------\r\n90>   Creating library F:/lib/build/tensorflow/Release/contrib_seq2seq_beam_search_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_seq2seq_beam_search_ops_gen_python.exp\r\n95>   Creating library F:/lib/build/tensorflow/Release/contrib_text_skip_gram_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_text_skip_gram_ops_gen_python.exp\r\n96>   Creating library F:/lib/build/tensorflow/Release/control_flow_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/control_flow_ops_gen_python.exp\r\n91>   Creating library F:/lib/build/tensorflow/Release/contrib_tensor_forest_hybrid_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_tensor_forest_hybrid_ops_gen_python.exp\r\n94>   Creating library F:/lib/build/tensorflow/Release/contrib_tensor_forest_stats_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_tensor_forest_stats_ops_gen_python.exp\r\n97>   Creating library F:/lib/build/tensorflow/Release/ctc_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/ctc_ops_gen_python.exp\r\n90>contrib_seq2seq_beam_search_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_seq2seq_beam_search_ops_gen_python.exe\r\n93>   Creating library F:/lib/build/tensorflow/Release/contrib_tensor_forest_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_tensor_forest_ops_gen_python.exp\r\n95>contrib_text_skip_gram_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_text_skip_gram_ops_gen_python.exe\r\n94>contrib_tensor_forest_stats_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_tensor_forest_stats_ops_gen_python.exe\r\n91>contrib_tensor_forest_hybrid_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_tensor_forest_hybrid_ops_gen_python.exe\r\n96>control_flow_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\control_flow_ops_gen_python.exe\r\n98>------ Build started: Project: cudnn_rnn_ops_gen_python, Configuration: Release x64 ------\r\n99>------ Build started: Project: data_flow_ops_gen_python, Configuration: Release x64 ------\r\n100>------ Build started: Project: dataset_ops_gen_python, Configuration: Release x64 ------\r\n101>------ Build started: Project: debug_ops_gen_python, Configuration: Release x64 ------\r\n97>ctc_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\ctc_ops_gen_python.exe\r\n102>------ Build started: Project: decode_proto_ops_gen_python, Configuration: Release x64 ------\r\n103>------ Build started: Project: tf_cc_ops, Configuration: Release x64 ------\r\n93>contrib_tensor_forest_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_tensor_forest_ops_gen_python.exe\r\n92>   Creating library F:/lib/build/tensorflow/Release/contrib_tensor_forest_model_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_tensor_forest_model_ops_gen_python.exp\r\n104>------ Build started: Project: encode_proto_ops_gen_python, Configuration: Release x64 ------\r\n98>   Creating library F:/lib/build/tensorflow/Release/cudnn_rnn_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/cudnn_rnn_ops_gen_python.exp\r\n99>   Creating library F:/lib/build/tensorflow/Release/data_flow_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/data_flow_ops_gen_python.exp\r\n100>   Creating library F:/lib/build/tensorflow/Release/dataset_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/dataset_ops_gen_python.exp\r\n101>   Creating library F:/lib/build/tensorflow/Release/debug_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/debug_ops_gen_python.exp\r\n102>   Creating library F:/lib/build/tensorflow/Release/decode_proto_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/decode_proto_ops_gen_python.exp\r\n104>   Creating library F:/lib/build/tensorflow/Release/encode_proto_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/encode_proto_ops_gen_python.exp\r\n92>contrib_tensor_forest_model_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_tensor_forest_model_ops_gen_python.exe\r\n105>------ Build started: Project: functional_ops_gen_python, Configuration: Release x64 ------\r\n98>cudnn_rnn_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\cudnn_rnn_ops_gen_python.exe\r\n99>data_flow_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\data_flow_ops_gen_python.exe\r\n101>debug_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\debug_ops_gen_python.exe\r\n106>------ Build started: Project: image_ops_gen_python, Configuration: Release x64 ------\r\n107>------ Build started: Project: io_ops_gen_python, Configuration: Release x64 ------\r\n100>dataset_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\dataset_ops_gen_python.exe\r\n108>------ Build started: Project: linalg_ops_gen_python, Configuration: Release x64 ------\r\n109>------ Build started: Project: list_ops_gen_python, Configuration: Release x64 ------\r\n102>decode_proto_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\decode_proto_ops_gen_python.exe\r\n110>------ Build started: Project: logging_ops_gen_python, Configuration: Release x64 ------\r\n104>encode_proto_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\encode_proto_ops_gen_python.exe\r\n111>------ Build started: Project: lookup_ops_gen_python, Configuration: Release x64 ------\r\n106>   Creating library F:/lib/build/tensorflow/Release/image_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/image_ops_gen_python.exp\r\n105>   Creating library F:/lib/build/tensorflow/Release/functional_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/functional_ops_gen_python.exp\r\n108>   Creating library F:/lib/build/tensorflow/Release/linalg_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/linalg_ops_gen_python.exp\r\n107>   Creating library F:/lib/build/tensorflow/Release/io_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/io_ops_gen_python.exp\r\n109>   Creating library F:/lib/build/tensorflow/Release/list_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/list_ops_gen_python.exp\r\n110>   Creating library F:/lib/build/tensorflow/Release/logging_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/logging_ops_gen_python.exp\r\n111>   Creating library F:/lib/build/tensorflow/Release/lookup_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/lookup_ops_gen_python.exp\r\n106>image_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\image_ops_gen_python.exe\r\n112>------ Build started: Project: manip_ops_gen_python, Configuration: Release x64 ------\r\n113>------ Build started: Project: math_ops_gen_python, Configuration: Release x64 ------\r\n108>linalg_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\linalg_ops_gen_python.exe\r\n105>functional_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\functional_ops_gen_python.exe\r\n114>------ Build started: Project: nn_ops_gen_python, Configuration: Release x64 ------\r\n115>------ Build started: Project: parsing_ops_gen_python, Configuration: Release x64 ------\r\n107>io_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\io_ops_gen_python.exe\r\n116>------ Build started: Project: random_ops_gen_python, Configuration: Release x64 ------\r\n109>list_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\list_ops_gen_python.exe\r\n117>------ Build started: Project: remote_fused_graph_ops_gen_python, Configuration: Release x64 ------\r\n111>lookup_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\lookup_ops_gen_python.exe\r\n110>logging_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\logging_ops_gen_python.exe\r\n118>------ Build started: Project: resource_variable_ops_gen_python, Configuration: Release x64 ------\r\n119>------ Build started: Project: rpc_ops_gen_python, Configuration: Release x64 ------\r\n113>   Creating library F:/lib/build/tensorflow/Release/math_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/math_ops_gen_python.exp\r\n112>   Creating library F:/lib/build/tensorflow/Release/manip_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/manip_ops_gen_python.exp\r\n115>   Creating library F:/lib/build/tensorflow/Release/parsing_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/parsing_ops_gen_python.exp\r\n116>   Creating library F:/lib/build/tensorflow/Release/random_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/random_ops_gen_python.exp\r\n117>   Creating library F:/lib/build/tensorflow/Release/remote_fused_graph_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/remote_fused_graph_ops_gen_python.exp\r\n118>   Creating library F:/lib/build/tensorflow/Release/resource_variable_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/resource_variable_ops_gen_python.exp\r\n119>   Creating library F:/lib/build/tensorflow/Release/rpc_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/rpc_ops_gen_python.exp\r\n113>math_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\math_ops_gen_python.exe\r\n115>parsing_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\parsing_ops_gen_python.exe\r\n112>manip_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\manip_ops_gen_python.exe\r\n120>------ Build started: Project: contrib_factorization_factorization_ops_gen_python, Configuration: Release x64 ------\r\n121>------ Build started: Project: script_ops_gen_python, Configuration: Release x64 ------\r\n122>------ Build started: Project: sdca_ops_gen_python, Configuration: Release x64 ------\r\n123>------ Build started: Project: set_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/audio_ops.h, tensorflow/cc/ops/audio_ops.cc, tensorflow/cc/ops/audio_ops_internal.h, tensorflow/cc/ops/audio_ops_internal.cc\r\n116>random_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\random_ops_gen_python.exe\r\n124>------ Build started: Project: sparse_ops_gen_python, Configuration: Release x64 ------\r\n117>remote_fused_graph_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\remote_fused_graph_ops_gen_python.exe\r\n125>------ Build started: Project: spectral_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/array_ops.h, tensorflow/cc/ops/array_ops.cc, tensorflow/cc/ops/array_ops_internal.h, tensorflow/cc/ops/array_ops_internal.cc\r\n118>resource_variable_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\resource_variable_ops_gen_python.exe\r\n126>------ Build started: Project: state_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/batch_ops.h, tensorflow/cc/ops/batch_ops.cc, tensorflow/cc/ops/batch_ops_internal.h, tensorflow/cc/ops/batch_ops_internal.cc\r\n119>rpc_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\rpc_ops_gen_python.exe\r\n127>------ Build started: Project: stateless_random_ops_gen_python, Configuration: Release x64 ------\r\n121>   Creating library F:/lib/build/tensorflow/Release/script_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/script_ops_gen_python.exp\r\n123>   Creating library F:/lib/build/tensorflow/Release/set_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/set_ops_gen_python.exp\r\n122>   Creating library F:/lib/build/tensorflow/Release/sdca_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/sdca_ops_gen_python.exp\r\n120>   Creating library F:/lib/build/tensorflow/Release/contrib_factorization_factorization_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_factorization_factorization_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/bitwise_ops.h, tensorflow/cc/ops/bitwise_ops.cc, tensorflow/cc/ops/bitwise_ops_internal.h, tensorflow/cc/ops/bitwise_ops_internal.cc\r\n124>   Creating library F:/lib/build/tensorflow/Release/sparse_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/sparse_ops_gen_python.exp\r\n125>   Creating library F:/lib/build/tensorflow/Release/spectral_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/spectral_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/boosted_trees_ops.h, tensorflow/cc/ops/boosted_trees_ops.cc, tensorflow/cc/ops/boosted_trees_ops_internal.h, tensorflow/cc/ops/boosted_trees_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/candidate_sampling_ops.h, tensorflow/cc/ops/candidate_sampling_ops.cc, tensorflow/cc/ops/candidate_sampling_ops_internal.h, tensorflow/cc/ops/candidate_sampling_ops_internal.cc\r\n126>   Creating library F:/lib/build/tensorflow/Release/state_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/state_ops_gen_python.exp\r\n127>   Creating library F:/lib/build/tensorflow/Release/stateless_random_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/stateless_random_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/checkpoint_ops.h, tensorflow/cc/ops/checkpoint_ops.cc, tensorflow/cc/ops/checkpoint_ops_internal.h, tensorflow/cc/ops/checkpoint_ops_internal.cc\r\n123>set_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\set_ops_gen_python.exe\r\n121>script_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\script_ops_gen_python.exe\r\n122>sdca_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\sdca_ops_gen_python.exe\r\n128>------ Build started: Project: string_ops_gen_python, Configuration: Release x64 ------\r\n129>------ Build started: Project: array_ops_gen_python, Configuration: Release x64 ------\r\n130>------ Build started: Project: summary_ops_gen_python, Configuration: Release x64 ------\r\n120>contrib_factorization_factorization_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_factorization_factorization_ops_gen_python.exe\r\n124>sparse_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\sparse_ops_gen_python.exe\r\n131>------ Build started: Project: audio_ops_gen_python, Configuration: Release x64 ------\r\n125>spectral_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\spectral_ops_gen_python.exe\r\n132>------ Build started: Project: batch_ops_gen_python, Configuration: Release x64 ------\r\n128>   Creating library F:/lib/build/tensorflow/Release/string_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/string_ops_gen_python.exp\r\n129>   Creating library F:/lib/build/tensorflow/Release/array_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/array_ops_gen_python.exp\r\n131>   Creating library F:/lib/build/tensorflow/Release/audio_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/audio_ops_gen_python.exp\r\n130>   Creating library F:/lib/build/tensorflow/Release/summary_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/summary_ops_gen_python.exp\r\n132>   Creating library F:/lib/build/tensorflow/Release/batch_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/batch_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/control_flow_ops.h, tensorflow/cc/ops/control_flow_ops.cc, tensorflow/cc/ops/control_flow_ops_internal.h, tensorflow/cc/ops/control_flow_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/ctc_ops.h, tensorflow/cc/ops/ctc_ops.cc, tensorflow/cc/ops/ctc_ops_internal.h, tensorflow/cc/ops/ctc_ops_internal.cc\r\n133>------ Build started: Project: bitwise_ops_gen_python, Configuration: Release x64 ------\r\n126>state_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\state_ops_gen_python.exe\r\n45>constant_folding.cc\r\n134>------ Build started: Project: boosted_trees_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/cudnn_rnn_ops.h, tensorflow/cc/ops/cudnn_rnn_ops.cc, tensorflow/cc/ops/cudnn_rnn_ops_internal.h, tensorflow/cc/ops/cudnn_rnn_ops_internal.cc\r\n127>stateless_random_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\stateless_random_ops_gen_python.exe\r\n135>------ Build started: Project: candidate_sampling_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/data_flow_ops.h, tensorflow/cc/ops/data_flow_ops.cc, tensorflow/cc/ops/data_flow_ops_internal.h, tensorflow/cc/ops/data_flow_ops_internal.cc\r\n128>string_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\string_ops_gen_python.exe\r\n136>------ Build started: Project: checkpoint_ops_gen_python, Configuration: Release x64 ------\r\n131>audio_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\audio_ops_gen_python.exe\r\n130>summary_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\summary_ops_gen_python.exe\r\n129>array_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\array_ops_gen_python.exe\r\n137>------ Build started: Project: contrib_bigquery_reader_ops_gen_python, Configuration: Release x64 ------\r\n138>------ Build started: Project: contrib_boosted_trees_model_ops_gen_python, Configuration: Release x64 ------\r\n139>------ Build started: Project: contrib_boosted_trees_prediction_ops_gen_python, Configuration: Release x64 ------\r\n132>batch_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\batch_ops_gen_python.exe\r\n140>------ Build started: Project: contrib_boosted_trees_quantiles_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/dataset_ops.h, tensorflow/cc/ops/dataset_ops.cc, tensorflow/cc/ops/dataset_ops_internal.h, tensorflow/cc/ops/dataset_ops_internal.cc\r\n133>   Creating library F:/lib/build/tensorflow/Release/bitwise_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/bitwise_ops_gen_python.exp\r\n134>   Creating library F:/lib/build/tensorflow/Release/boosted_trees_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/boosted_trees_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/decode_proto_ops.h, tensorflow/cc/ops/decode_proto_ops.cc, tensorflow/cc/ops/decode_proto_ops_internal.h, tensorflow/cc/ops/decode_proto_ops_internal.cc\r\n135>   Creating library F:/lib/build/tensorflow/Release/candidate_sampling_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/candidate_sampling_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/encode_proto_ops.h, tensorflow/cc/ops/encode_proto_ops.cc, tensorflow/cc/ops/encode_proto_ops_internal.h, tensorflow/cc/ops/encode_proto_ops_internal.cc\r\n136>   Creating library F:/lib/build/tensorflow/Release/checkpoint_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/checkpoint_ops_gen_python.exp\r\n138>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_model_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_model_ops_gen_python.exp\r\n139>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_prediction_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_prediction_ops_gen_python.exp\r\n137>   Creating library F:/lib/build/tensorflow/Release/contrib_bigquery_reader_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_bigquery_reader_ops_gen_python.exp\r\n140>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_quantiles_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_quantiles_ops_gen_python.exp\r\n133>bitwise_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\bitwise_ops_gen_python.exe\r\n141>------ Build started: Project: contrib_boosted_trees_split_handler_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/functional_ops.h, tensorflow/cc/ops/functional_ops.cc, tensorflow/cc/ops/functional_ops_internal.h, tensorflow/cc/ops/functional_ops_internal.cc\r\n134>boosted_trees_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\boosted_trees_ops_gen_python.exe\r\n142>------ Build started: Project: contrib_boosted_trees_stats_accumulator_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/image_ops.h, tensorflow/cc/ops/image_ops.cc, tensorflow/cc/ops/image_ops_internal.h, tensorflow/cc/ops/image_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/io_ops.h, tensorflow/cc/ops/io_ops.cc, tensorflow/cc/ops/io_ops_internal.h, tensorflow/cc/ops/io_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/linalg_ops.h, tensorflow/cc/ops/linalg_ops.cc, tensorflow/cc/ops/linalg_ops_internal.h, tensorflow/cc/ops/linalg_ops_internal.cc\r\n135>candidate_sampling_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\candidate_sampling_ops_gen_python.exe\r\n138>contrib_boosted_trees_model_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_model_ops_gen_python.exe\r\n136>checkpoint_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\checkpoint_ops_gen_python.exe\r\n143>------ Build started: Project: contrib_boosted_trees_training_ops_gen_python, Configuration: Release x64 ------\r\n144>------ Build started: Project: contrib_coder_ops_gen_python, Configuration: Release x64 ------\r\n139>contrib_boosted_trees_prediction_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_prediction_ops_gen_python.exe\r\n137>contrib_bigquery_reader_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_bigquery_reader_ops_gen_python.exe\r\n145>------ Build started: Project: contrib_data_dataset_ops_gen_python, Configuration: Release x64 ------\r\n146>------ Build started: Project: contrib_factorization_clustering_ops_gen_python, Configuration: Release x64 ------\r\n147>------ Build started: Project: contrib_framework_variable_ops_gen_python, Configuration: Release x64 ------\r\n141>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_split_handler_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_split_handler_ops_gen_python.exp\r\n140>contrib_boosted_trees_quantiles_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_quantiles_ops_gen_python.exe\r\n142>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_stats_accumulator_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_stats_accumulator_ops_gen_python.exp\r\n148>------ Build started: Project: contrib_image_distort_image_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/list_ops.h, tensorflow/cc/ops/list_ops.cc, tensorflow/cc/ops/list_ops_internal.h, tensorflow/cc/ops/list_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/lookup_ops.h, tensorflow/cc/ops/lookup_ops.cc, tensorflow/cc/ops/lookup_ops_internal.h, tensorflow/cc/ops/lookup_ops_internal.cc\r\n145>   Creating library F:/lib/build/tensorflow/Release/contrib_data_dataset_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_data_dataset_ops_gen_python.exp\r\n143>   Creating library F:/lib/build/tensorflow/Release/contrib_boosted_trees_training_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_boosted_trees_training_ops_gen_python.exp\r\n144>   Creating library F:/lib/build/tensorflow/Release/contrib_coder_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_coder_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/logging_ops.h, tensorflow/cc/ops/logging_ops.cc, tensorflow/cc/ops/logging_ops_internal.h, tensorflow/cc/ops/logging_ops_internal.cc\r\n148>   Creating library F:/lib/build/tensorflow/Release/contrib_image_distort_image_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_image_distort_image_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/manip_ops.h, tensorflow/cc/ops/manip_ops.cc, tensorflow/cc/ops/manip_ops_internal.h, tensorflow/cc/ops/manip_ops_internal.cc\r\n141>contrib_boosted_trees_split_handler_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_split_handler_ops_gen_python.exe\r\n142>contrib_boosted_trees_stats_accumulator_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_stats_accumulator_ops_gen_python.exe\r\n149>------ Build started: Project: contrib_image_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/math_ops.h, tensorflow/cc/ops/math_ops.cc, tensorflow/cc/ops/math_ops_internal.h, tensorflow/cc/ops/math_ops_internal.cc\r\n150>------ Build started: Project: contrib_image_sirds_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/nn_ops.h, tensorflow/cc/ops/nn_ops.cc, tensorflow/cc/ops/nn_ops_internal.h, tensorflow/cc/ops/nn_ops_internal.cc\r\n144>contrib_coder_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_coder_ops_gen_python.exe\r\n143>contrib_boosted_trees_training_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_boosted_trees_training_ops_gen_python.exe\r\n145>contrib_data_dataset_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_data_dataset_ops_gen_python.exe\r\n151>------ Build started: Project: contrib_input_pipeline_ops_gen_python, Configuration: Release x64 ------\r\n148>contrib_image_distort_image_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_image_distort_image_ops_gen_python.exe\r\n152>------ Build started: Project: contrib_layers_sparse_feature_cross_ops_gen_python, Configuration: Release x64 ------\r\n149>   Creating library F:/lib/build/tensorflow/Release/contrib_image_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_image_ops_gen_python.exp\r\n150>   Creating library F:/lib/build/tensorflow/Release/contrib_image_sirds_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_image_sirds_ops_gen_python.exp\r\n146>   Creating library F:/lib/build/tensorflow/Release/contrib_factorization_clustering_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_factorization_clustering_ops_gen_python.exp\r\n147>   Creating library F:/lib/build/tensorflow/Release/contrib_framework_variable_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_framework_variable_ops_gen_python.exp\r\n151>   Creating library F:/lib/build/tensorflow/Release/contrib_input_pipeline_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_input_pipeline_ops_gen_python.exp\r\n152>   Creating library F:/lib/build/tensorflow/Release/contrib_layers_sparse_feature_cross_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_layers_sparse_feature_cross_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/no_op.h, tensorflow/cc/ops/no_op.cc, tensorflow/cc/ops/no_op_internal.h, tensorflow/cc/ops/no_op_internal.cc\r\n150>contrib_image_sirds_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_image_sirds_ops_gen_python.exe\r\n149>contrib_image_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_image_ops_gen_python.exe\r\n153>------ Build started: Project: contrib_memory_stats_ops_gen_python, Configuration: Release x64 ------\r\n154>------ Build started: Project: contrib_nccl_ops_gen_python, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/parsing_ops.h, tensorflow/cc/ops/parsing_ops.cc, tensorflow/cc/ops/parsing_ops_internal.h, tensorflow/cc/ops/parsing_ops_internal.cc\r\n153>   Creating library F:/lib/build/tensorflow/Release/contrib_memory_stats_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_memory_stats_ops_gen_python.exp\r\n147>contrib_framework_variable_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_framework_variable_ops_gen_python.exe\r\n155>------ Build started: Project: contrib_nearest_neighbor_ops_gen_python, Configuration: Release x64 ------\r\n154>   Creating library F:/lib/build/tensorflow/Release/contrib_nccl_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_nccl_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/random_ops.h, tensorflow/cc/ops/random_ops.cc, tensorflow/cc/ops/random_ops_internal.h, tensorflow/cc/ops/random_ops_internal.cc\r\n146>contrib_factorization_clustering_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_factorization_clustering_ops_gen_python.exe\r\n151>contrib_input_pipeline_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_input_pipeline_ops_gen_python.exe\r\n152>contrib_layers_sparse_feature_cross_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_layers_sparse_feature_cross_ops_gen_python.exe\r\n156>------ Build started: Project: training_ops_gen_python, Configuration: Release x64 ------\r\n157>------ Build started: Project: contrib_periodic_resample_ops_gen_python, Configuration: Release x64 ------\r\n158>------ Build started: Project: user_ops_gen_python, Configuration: Release x64 ------\r\n159>------ Build started: Project: contrib_resampler_ops_gen_python, Configuration: Release x64 ------\r\n160>------ Build started: Project: contrib_rnn_gru_ops_gen_python, Configuration: Release x64 ------\r\n155>   Creating library F:/lib/build/tensorflow/Release/contrib_nearest_neighbor_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_nearest_neighbor_ops_gen_python.exp\r\n156>   Creating library F:/lib/build/tensorflow/Release/training_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/training_ops_gen_python.exp\r\n158>   Creating library F:/lib/build/tensorflow/Release/user_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/user_ops_gen_python.exp\r\n157>   Creating library F:/lib/build/tensorflow/Release/contrib_periodic_resample_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_periodic_resample_ops_gen_python.exp\r\n159>   Creating library F:/lib/build/tensorflow/Release/contrib_resampler_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_resampler_ops_gen_python.exp\r\n160>   Creating library F:/lib/build/tensorflow/Release/contrib_rnn_gru_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_rnn_gru_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/remote_fused_graph_ops.h, tensorflow/cc/ops/remote_fused_graph_ops.cc, tensorflow/cc/ops/remote_fused_graph_ops_internal.h, tensorflow/cc/ops/remote_fused_graph_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/resource_variable_ops.h, tensorflow/cc/ops/resource_variable_ops.cc, tensorflow/cc/ops/resource_variable_ops_internal.h, tensorflow/cc/ops/resource_variable_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/rpc_ops.h, tensorflow/cc/ops/rpc_ops.cc, tensorflow/cc/ops/rpc_ops_internal.h, tensorflow/cc/ops/rpc_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/script_ops.h, tensorflow/cc/ops/script_ops.cc, tensorflow/cc/ops/script_ops_internal.h, tensorflow/cc/ops/script_ops_internal.cc\r\n153>contrib_memory_stats_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_memory_stats_ops_gen_python.exe\r\n154>contrib_nccl_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_nccl_ops_gen_python.exe\r\n103>Generating tensorflow/cc/ops/sdca_ops.h, tensorflow/cc/ops/sdca_ops.cc, tensorflow/cc/ops/sdca_ops_internal.h, tensorflow/cc/ops/sdca_ops_internal.cc\r\n156>training_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\training_ops_gen_python.exe\r\n155>contrib_nearest_neighbor_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_nearest_neighbor_ops_gen_python.exe\r\n158>user_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\user_ops_gen_python.exe\r\n161>------ Build started: Project: contrib_rnn_lstm_ops_gen_python, Configuration: Release x64 ------\r\n160>contrib_rnn_gru_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_rnn_gru_ops_gen_python.exe\r\n159>contrib_resampler_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_resampler_ops_gen_python.exe\r\n157>contrib_periodic_resample_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_periodic_resample_ops_gen_python.exe\r\n45>constant_folding.cc\r\n103>Generating tensorflow/cc/ops/set_ops.h, tensorflow/cc/ops/set_ops.cc, tensorflow/cc/ops/set_ops_internal.h, tensorflow/cc/ops/set_ops_internal.cc\r\n161>   Creating library F:/lib/build/tensorflow/Release/contrib_rnn_lstm_ops_gen_python.lib and object F:/lib/build/tensorflow/Release/contrib_rnn_lstm_ops_gen_python.exp\r\n103>Generating tensorflow/cc/ops/sendrecv_ops.h, tensorflow/cc/ops/sendrecv_ops.cc, tensorflow/cc/ops/sendrecv_ops_internal.h, tensorflow/cc/ops/sendrecv_ops_internal.cc\r\n161>contrib_rnn_lstm_ops_gen_python.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\contrib_rnn_lstm_ops_gen_python.exe\r\n162>------ Build started: Project: tf_python_ops, Configuration: Release x64 ------\r\n103>Generating tensorflow/cc/ops/sparse_ops.h, tensorflow/cc/ops/sparse_ops.cc, tensorflow/cc/ops/sparse_ops_internal.h, tensorflow/cc/ops/sparse_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/spectral_ops.h, tensorflow/cc/ops/spectral_ops.cc, tensorflow/cc/ops/spectral_ops_internal.h, tensorflow/cc/ops/spectral_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/state_ops.h, tensorflow/cc/ops/state_ops.cc, tensorflow/cc/ops/state_ops_internal.h, tensorflow/cc/ops/state_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/stateless_random_ops.h, tensorflow/cc/ops/stateless_random_ops.cc, tensorflow/cc/ops/stateless_random_ops_internal.h, tensorflow/cc/ops/stateless_random_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/string_ops.h, tensorflow/cc/ops/string_ops.cc, tensorflow/cc/ops/string_ops_internal.h, tensorflow/cc/ops/string_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/summary_ops.h, tensorflow/cc/ops/summary_ops.cc, tensorflow/cc/ops/summary_ops_internal.h, tensorflow/cc/ops/summary_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/training_ops.h, tensorflow/cc/ops/training_ops.cc, tensorflow/cc/ops/training_ops_internal.h, tensorflow/cc/ops/training_ops_internal.cc\r\n103>Generating tensorflow/cc/ops/user_ops.h, tensorflow/cc/ops/user_ops.cc, tensorflow/cc/ops/user_ops_internal.h, tensorflow/cc/ops/user_ops_internal.cc\r\n103>array_ops.cc\r\n103>array_ops_internal.cc\r\n103>audio_ops.cc\r\n103>audio_ops_internal.cc\r\n103>batch_ops.cc\r\n103>batch_ops_internal.cc\r\n103>bitwise_ops.cc\r\n103>bitwise_ops_internal.cc\r\n103>boosted_trees_ops.cc\r\n103>boosted_trees_ops_internal.cc\r\n103>candidate_sampling_ops.cc\r\n103>candidate_sampling_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_audio_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_array_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_batch_ops.py\r\n103>checkpoint_ops.cc\r\n103>checkpoint_ops_internal.cc\r\n103>control_flow_ops.cc\r\n103>control_flow_ops_internal.cc\r\n103>ctc_ops.cc\r\n103>ctc_ops_internal.cc\r\n103>cudnn_rnn_ops.cc\r\n103>cudnn_rnn_ops_internal.cc\r\n103>data_flow_ops.cc\r\n103>data_flow_ops_internal.cc\r\n103>dataset_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_bitwise_ops.py\r\n103>dataset_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_boosted_trees_ops.py\r\n103>decode_proto_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_math_ops.py\r\n103>decode_proto_ops_internal.cc\r\n103>encode_proto_ops.cc\r\n103>encode_proto_ops_internal.cc\r\n103>functional_ops.cc\r\n103>functional_ops_internal.cc\r\n103>image_ops.cc\r\n103>image_ops_internal.cc\r\n103>io_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_functional_ops.py\r\n103>io_ops_internal.cc\r\n103>linalg_ops.cc\r\n103>linalg_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_candidate_sampling_ops.py\r\n103>list_ops.cc\r\n103>list_ops_internal.cc\r\n103>logging_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_checkpoint_ops.py\r\n103>logging_ops_internal.cc\r\n103>lookup_ops.cc\r\n103>lookup_ops_internal.cc\r\n103>manip_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_control_flow_ops.py\r\n103>manip_ops_internal.cc\r\n103>math_ops.cc\r\n103>math_ops_internal.cc\r\n103>nn_ops.cc\r\n103>nn_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_ctc_ops.py\r\n103>no_op.cc\r\n103>no_op_internal.cc\r\n103>parsing_ops.cc\r\n103>parsing_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_cudnn_rnn_ops.py\r\n103>random_ops.cc\r\n103>random_ops_internal.cc\r\n103>remote_fused_graph_ops.cc\r\n103>remote_fused_graph_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_data_flow_ops.py\r\n103>resource_variable_ops.cc\r\n103>resource_variable_ops_internal.cc\r\n103>rpc_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_dataset_ops.py\r\n103>rpc_ops_internal.cc\r\n103>script_ops.cc\r\n103>script_ops_internal.cc\r\n103>sdca_ops.cc\r\n162>Generating tf_python/tensorflow/contrib/proto/python/ops/gen_decode_proto_op.py\r\n103>sdca_ops_internal.cc\r\n103>sendrecv_ops.cc\r\n103>sendrecv_ops_internal.cc\r\n103>set_ops.cc\r\n162>Generating tf_python/tensorflow/contrib/proto/python/ops/gen_encode_proto_op.py\r\n103>set_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_image_ops.py\r\n103>sparse_ops.cc\r\n103>sparse_ops_internal.cc\r\n103>spectral_ops.cc\r\n103>spectral_ops_internal.cc\r\n103>state_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_io_ops.py\r\n103>state_ops_internal.cc\r\n103>stateless_random_ops.cc\r\n103>stateless_random_ops_internal.cc\r\n103>string_ops.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_linalg_ops.py\r\n103>string_ops_internal.cc\r\n103>summary_ops.cc\r\n103>summary_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_list_ops.py\r\n103>training_ops.cc\r\n103>training_ops_internal.cc\r\n103>user_ops.cc\r\n103>user_ops_internal.cc\r\n162>Generating tf_python/tensorflow/python/ops/gen_logging_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_lookup_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_nn_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_manip_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_parsing_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_random_ops.py\r\n162>Generating tf_python/tensorflow/contrib/remote_fused_graph/pylib/python/ops/gen_remote_fused_graph_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_resource_variable_ops.py\r\n162>Generating tf_python/tensorflow/contrib/rpc/python/ops/gen_rpc_op.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_script_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_sdca_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_set_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_state_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_sparse_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_spectral_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_string_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_summary_ops.py\r\n162>Generating tf_python/tensorflow/python/ops/gen_user_ops.py\r\n162>Generating tf_python/tensorflow/python/training/gen_training_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_model_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_split_handler_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_training_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_prediction_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_quantile_ops.py\r\n162>Generating tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_stats_accumulator_ops.py\r\n162>Generating tf_python/tensorflow/contrib/coder/python/ops/gen_coder_ops.py\r\n162>Generating tf_python/tensorflow/contrib/data/python/ops/gen_dataset_ops.py\r\n162>Generating tf_python/tensorflow/contrib/factorization/python/ops/gen_clustering_ops.py\r\n162>Generating tf_python/tensorflow/contrib/factorization/python/ops/gen_factorization_ops.py\r\n162>Generating tf_python/tensorflow/contrib/framework/python/ops/gen_variable_ops.py\r\n162>Generating tf_python/tensorflow/contrib/input_pipeline/ops/gen_input_pipeline_ops.py\r\n162>Generating tf_python/tensorflow/contrib/image/ops/gen_image_ops.py\r\n162>Generating tf_python/tensorflow/contrib/image/ops/gen_distort_image_ops.py\r\n162>Generating tf_python/tensorflow/contrib/image/ops/gen_single_image_random_dot_stereograms_ops.py\r\n162>Generating tf_python/tensorflow/contrib/layers/ops/gen_sparse_feature_cross_op.py\r\n162>Generating tf_python/tensorflow/contrib/memory_stats/ops/gen_memory_stats_ops.py\r\n162>Generating tf_python/tensorflow/contrib/nccl/ops/gen_nccl_ops.py\r\n162>Generating tf_python/tensorflow/contrib/periodic_resample/python/ops/gen_periodic_resample_op.py\r\n162>Generating tf_python/tensorflow/contrib/nearest_neighbor/ops/gen_nearest_neighbor_ops.py\r\n162>Generating tf_python/tensorflow/contrib/resampler/ops/gen_resampler_ops.py\r\n162>Generating tf_python/tensorflow/contrib/rnn/ops/gen_gru_ops.py\r\n162>Generating tf_python/tensorflow/contrib/rnn/ops/gen_lstm_ops.py\r\n162>Generating tf_python/tensorflow/contrib/seq2seq/ops/gen_beam_search_ops.py\r\n162>Generating tf_python/tensorflow/contrib/tensor_forest/python/ops/gen_tensor_forest_ops.py\r\n162>Generating tf_python/tensorflow/contrib/tensor_forest/hybrid/ops/gen_training_ops.py\r\n162>Generating tf_python/tensorflow/contrib/tensor_forest/python/ops/gen_model_ops.py\r\n162>Generating tf_python/tensorflow/contrib/tensor_forest/python/ops/gen_stats_ops.py\r\n162>Generating tf_python/tensorflow/contrib/text/python/ops/gen_skip_gram_ops.py\r\n162>Generating tf_python/tensorflow/contrib/cloud/python/ops/gen_bigquery_reader_ops.py\r\n162>Generating tf_python/tensorflow/contrib/stateless/gen_stateless_random_ops.py\r\n162>Generating tf_python/tensorflow/python/debug/ops/gen_debug_ops.py\r\n45>tf_core_cpu.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_cpu.dir\\Release\\tf_core_cpu.lib\r\n45>Done building project \"tf_core_cpu.vcxproj\".\r\n103>user_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>summary_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>string_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>stateless_random_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>state_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>spectral_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>sparse_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>sendrecv_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>set_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>sdca_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>script_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>rpc_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>resource_variable_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>remote_fused_graph_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>random_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>parsing_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>no_op_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>manip_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>logging_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>lookup_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>list_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>io_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>functional_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>encode_proto_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>decode_proto_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>data_flow_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>ctc_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>checkpoint_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>candidate_sampling_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>boosted_trees_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>bitwise_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>batch_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>audio_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n103>tf_cc_ops.vcxproj -> F:\\lib\\build\\tensorflow\\tf_cc_ops.dir\\Release\\tf_cc_ops.lib\r\n103>Done building project \"tf_cc_ops.vcxproj\".\r\n163>------ Build started: Project: tf_core_kernels, Configuration: Release x64 ------\r\n164>------ Build started: Project: tf_grappler, Configuration: Release x64 ------\r\n165>------ Build started: Project: tf_core_distributed_runtime, Configuration: Release x64 ------\r\n166>------ Build started: Project: tf_core_direct_session, Configuration: Release x64 ------\r\n167>------ Build started: Project: tf_cc_while_loop, Configuration: Release x64 ------\r\n168>------ Build started: Project: tf_cc, Configuration: Release x64 ------\r\n164>single_machine.cc\r\n166>direct_session.cc\r\n167>while_loop.cc\r\n164>cost_analyzer.cc\r\n164>model_analyzer.cc\r\n168>gradient_checker.cc\r\n165>base_rendezvous_mgr.cc\r\n165>cluster_function_library_runtime.cc\r\n168>gradients.cc\r\n168>while_gradients.cc\r\n168>array_grad.cc\r\n168>data_flow_grad.cc\r\n168>math_grad.cc\r\n168>nn_grad.cc\r\n165>graph_mgr.cc\r\n165>local_master.cc\r\n165>master.cc\r\n165>master_session.cc\r\n165>message_wrappers.cc\r\n165>partial_run_mgr.cc\r\n165>remote_device.cc\r\n165>grpc_master_service.cc\r\n165>grpc_remote_master.cc\r\n165>grpc_remote_worker.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>prefetching_kernels.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>cast_op.cc\r\n163>conv_ops_fused.cc\r\n163>conv_ops_using_gemm.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>captured_function.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>dataset_utils.cc\r\n163>filter_dataset_op.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>flat_map_dataset_op.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>group_by_window_dataset_op.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>interleave_dataset_op.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>iterator_ops.cc\r\n163>cl : Command line warning D9002: ignoring unknown option '/fs'\r\n163>map_and_batch_dataset_op.cc\r\n165>grpc_server_lib.cc\r\n165>grpc_session.cc\r\n165>grpc_worker_cache.cc\r\n165>grpc_worker_service.cc\r\n165>rpc_rendezvous_mgr.cc\r\n165>scheduler.cc\r\n163>map_dataset_op.cc\r\n165>session_mgr.cc\r\n163>parallel_interleave_dataset_op.cc\r\n165>tensor_coding.cc\r\n163>parallel_map_dataset_op.cc\r\n165>worker.cc\r\n165>worker_cache_partial.cc\r\n163>scan_dataset_op.cc\r\n163>dilation_ops.cc\r\n163>edit_distance_op.cc\r\n163>example_parsing_ops.cc\r\n163>function_ops.cc\r\n167>tf_cc_while_loop.vcxproj -> F:\\lib\\build\\tensorflow\\tf_cc_while_loop.dir\\Release\\tf_cc_while_loop.lib\r\n165>worker_session.cc\r\n163>maxpooling_op.cc\r\n169>------ Build started: Project: tf_c, Configuration: Release x64 ------\r\n164>tf_grappler.vcxproj -> F:\\lib\\build\\tensorflow\\tf_grappler.dir\\Release\\tf_grappler.lib\r\n163>partitioned_function_ops.cc\r\n163>pooling_ops_common.cc\r\n168>tf_cc.vcxproj -> F:\\lib\\build\\tensorflow\\tf_cc.dir\\Release\\tf_cc.lib\r\n163>remote_fused_graph_execute_utils.cc\r\n169>c_api.cc\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n163>restore_op.cc\r\n163>save_op.cc\r\n166>tf_core_direct_session.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_direct_session.dir\\Release\\tf_core_direct_session.lib\r\n163>save_restore_tensor.cc\r\n163>save_restore_v2_ops.cc\r\n163>session_ops.cc\r\n163>sparse_matmul_op.cc\r\n163>stack_ops.cc\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.cc(272): warning C4190: 'TF_StringDecode_Impl' has C-linkage specified, but returns UDT 'tensorflow::Status' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\core\\lib\\core\\status.h(37): note: see declaration of 'tensorflow::Status'\r\n163>string_to_hash_bucket_op.cc\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.cc(2193): warning C4190: 'CopyGraph' has C-linkage specified, but returns UDT 'tensorflow::Status' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\core\\lib\\core\\status.h(37): note: see declaration of 'tensorflow::Status'\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.cc(2269): warning C4190: 'EmptyWhileParams' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.cc(2277): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n165>tf_core_distributed_runtime.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_distributed_runtime.dir\\Release\\tf_core_distributed_runtime.lib\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.cc(1595): warning C4700: uninitialized local variable 'metadata' used\r\n169>c_api_function.cc\r\n169>runtime.cc\r\n169>tf_status_helper.cc\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\tf_status_helper.cc)\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\tf_status_helper.cc)\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\c_api_function.cc)\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\c_api_function.cc)\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\eager\\runtime.cc)\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\c\\eager\\runtime.cc)\r\n169>c_api.cc\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n169>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n169>tf_c.vcxproj -> F:\\lib\\build\\tensorflow\\tf_c.dir\\Release\\tf_c.lib\r\n169>Done building project \"tf_c.vcxproj\".\r\n170>------ Build started: Project: tf_c_python_api, Configuration: Release x64 ------\r\n170>python_api.cc\r\n170>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n170>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n170>tf_c_python_api.vcxproj -> F:\\lib\\build\\tensorflow\\tf_c_python_api.dir\\Release\\tf_c_python_api.lib\r\n170>Done building project \"tf_c_python_api.vcxproj\".\r\n163>strided_slice_op_define_grad.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>scatter_functor.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>i_remote_fused_graph_ops_definitions.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>gather_functor.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>cudnn_rnn_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>cudnn_pooling_gpu.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>conv_ops_using_gemm.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>concat_lib_gpu.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n163>tf_core_kernels.vcxproj -> F:\\lib\\build\\tensorflow\\tf_core_kernels.dir\\Release\\tf_core_kernels.lib\r\n163>Done building project \"tf_core_kernels.vcxproj\".\r\n171>------ Build started: Project: tf_tools_transform_graph_lib, Configuration: Release x64 ------\r\n172>------ Build started: Project: tf_label_image_example, Configuration: Release x64 ------\r\n173>------ Build started: Project: grpc_tensorflow_server, Configuration: Release x64 ------\r\n174>------ Build started: Project: benchmark_model, Configuration: Release x64 ------\r\n175>------ Build started: Project: tf_tutorials_example_trainer, Configuration: Release x64 ------\r\n172>main.cc\r\n175>example_trainer.cc\r\n171>backports.cc\r\n171>fold_batch_norms.cc\r\n171>fold_constants_lib.cc\r\n171>fold_old_batch_norms.cc\r\n171>fuse_convolutions.cc\r\n171>insert_logging.cc\r\n171>obfuscate_names.cc\r\n171>quantize_nodes.cc\r\n171>quantize_weights.cc\r\n171>remove_attribute.cc\r\n171>remove_device.cc\r\n171>remove_nodes.cc\r\n171>rename_attribute.cc\r\n174>   Creating library F:/lib/build/tensorflow/Release/benchmark_model.lib and object F:/lib/build/tensorflow/Release/benchmark_model.exp\r\n171>rename_op.cc\r\n173>   Creating library F:/lib/build/tensorflow/Release/grpc_tensorflow_server.lib and object F:/lib/build/tensorflow/Release/grpc_tensorflow_server.exp\r\n171>round_weights.cc\r\n171>sort_by_execution_order.cc\r\n171>strip_unused_nodes.cc\r\n174>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n174>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n174>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n174>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n174>F:\\lib\\build\\tensorflow\\Release\\benchmark_model.exe : fatal error LNK1120: 4 unresolved externals\r\n174>Done building project \"benchmark_model.vcxproj\" -- FAILED.\r\n173>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n173>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n173>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n173>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n173>F:\\lib\\build\\tensorflow\\Release\\grpc_tensorflow_server.exe : fatal error LNK1120: 4 unresolved externals\r\n173>Done building project \"grpc_tensorflow_server.vcxproj\" -- FAILED.\r\n172>   Creating library F:/lib/build/tensorflow/Release/tf_label_image_example.lib and object F:/lib/build/tensorflow/Release/tf_label_image_example.exp\r\n175>   Creating library F:/lib/build/tensorflow/Release/tf_tutorials_example_trainer.lib and object F:/lib/build/tensorflow/Release/tf_tutorials_example_trainer.exp\r\n172>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n172>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n172>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n172>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n175>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n175>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n175>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n175>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n175>F:\\lib\\build\\tensorflow\\Release\\tf_tutorials_example_trainer.exe : fatal error LNK1120: 4 unresolved externals\r\n172>F:\\lib\\build\\tensorflow\\Release\\tf_label_image_example.exe : fatal error LNK1120: 4 unresolved externals\r\n172>Done building project \"tf_label_image_example.vcxproj\" -- FAILED.\r\n175>Done building project \"tf_tutorials_example_trainer.vcxproj\" -- FAILED.\r\n171>tf_tools_transform_graph_lib.vcxproj -> F:\\lib\\build\\tensorflow\\tf_tools_transform_graph_lib.dir\\Release\\tf_tools_transform_graph_lib.lib\r\n176>------ Build started: Project: pywrap_tensorflow_internal_static, Configuration: Release x64 ------\r\n177>------ Build started: Project: compare_graphs, Configuration: Release x64 ------\r\n178>------ Build started: Project: summarize_graph, Configuration: Release x64 ------\r\n179>------ Build started: Project: transform_graph, Configuration: Release x64 ------\r\n176>Generating __force_rebuild\r\n176>\r\n176>Running SWIG to generate Python wrappers\r\n176>python_eager_op_gen.cc\r\n176>pywrap_tensorflow_internal.cc\r\n176>python_op_gen.cc\r\n176>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc)\r\n176>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc)\r\n177>   Creating library F:/lib/build/tensorflow/Release/compare_graphs.lib and object F:/lib/build/tensorflow/Release/compare_graphs.exp\r\n179>   Creating library F:/lib/build/tensorflow/Release/transform_graph.lib and object F:/lib/build/tensorflow/Release/transform_graph.exp\r\n178>   Creating library F:/lib/build/tensorflow/Release/summarize_graph.lib and object F:/lib/build/tensorflow/Release/summarize_graph.exp\r\n177>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n177>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n177>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n177>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n177>F:\\lib\\build\\tensorflow\\Release\\compare_graphs.exe : fatal error LNK1120: 4 unresolved externals\r\n179>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n179>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n179>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n179>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n179>F:\\lib\\build\\tensorflow\\Release\\transform_graph.exe : fatal error LNK1120: 4 unresolved externals\r\n177>Done building project \"compare_graphs.vcxproj\" -- FAILED.\r\n179>Done building project \"transform_graph.vcxproj\" -- FAILED.\r\n178>eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\r\n178>execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n178>execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n178>execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\r\n178>F:\\lib\\build\\tensorflow\\Release\\summarize_graph.exe : fatal error LNK1120: 4 unresolved externals\r\n178>Done building project \"summarize_graph.vcxproj\" -- FAILED.\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5266): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5401): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5448): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5487): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5594): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5639): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5706): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5778): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5830): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5914): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(6312): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(7370): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9211): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9290): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9436): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9876): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9951): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(10021): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11039): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11118): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11197): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11267): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11339): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11405): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11598): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11717): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12173): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12237): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12320): warning C4101: 'status8': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12410): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12480): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12553): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12623): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12696): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12766): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12839): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12909): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12985): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13070): warning C4101: 'status8': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13161): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13231): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13304): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13374): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13447): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13591): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13647): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13706): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14302): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14373): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14449): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14513): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14603): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14665): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14733): warning C4101: 'status7': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14852): warning C4101: 'status13': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14972): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15023): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15082): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15155): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15246): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15316): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15388): warning C4101: 'status8': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15473): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15519): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15593): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15640): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15686): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15738): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15862): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15909): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16010): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16066): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16122): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16178): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16298): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16377): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16444): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16558): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16676): warning C4101: 'status4': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16818): warning C4101: 'status2': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16914): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18144): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18243): warning C4101: 'status8': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18365): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18461): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18717): warning C4101: 'status10': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18881): warning C4101: 'status6': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(19033): warning C4101: 'status5': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(19151): warning C4101: 'status3': unreferenced local variable\r\n176>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(22101): warning C4101: 'status3': unreferenced local variable\r\n176>strided_slice_op_define_grad.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>scatter_functor.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>i_remote_fused_graph_ops_definitions.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>gather_functor.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>cudnn_rnn_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>cudnn_pooling_gpu.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>conv_ops_using_gemm.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>concat_lib_gpu.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>random_grad.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>no_op.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>user_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>summary_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>string_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>stateless_random_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>state_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>spectral_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>sparse_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>sendrecv_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>set_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>sdca_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>script_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>rpc_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>resource_variable_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>remote_fused_graph_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>random_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>parsing_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>no_op_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>manip_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>logging_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>lookup_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>list_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>io_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>functional_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>encode_proto_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>decode_proto_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>data_flow_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>ctc_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>checkpoint_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>candidate_sampling_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>boosted_trees_ops.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>bitwise_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>batch_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>audio_ops_internal.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>random_distributions.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\n176>pywrap_tensorflow_internal_static.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal_static.lib\r\n176>symbols=175814, taken=48956, dupes=1714\r\n176>Done building project \"pywrap_tensorflow_internal_static.vcxproj\".\r\n180>------ Build started: Project: pywrap_tensorflow_internal, Configuration: Release x64 ------\r\n180>Generating __force_rebuild\r\n180>\r\n180>Running SWIG to generate Python wrappers\r\n180>pywrap_tensorflow_internal.cc\r\n180>scope.cc\r\n180>tf_session_helper.cc\r\n180>python_eager_op_gen.cc\r\n180>pywrap_tfe_src.cc\r\n180>python_op_gen.cc\r\n180>py_func.cc\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n180>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams' (compiling source file F:\\lib\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5266): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5401): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5448): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5487): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5594): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5639): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5706): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5778): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5830): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(5914): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(6312): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(7370): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9211): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9290): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9436): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9876): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(9951): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(10021): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11039): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11118): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11197): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11267): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11339): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11405): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11598): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(11717): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12173): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12237): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12320): warning C4101: 'status8': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12410): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12480): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12553): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12623): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12696): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12766): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12839): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12909): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(12985): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13070): warning C4101: 'status8': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13161): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13231): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13304): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13374): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13447): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13591): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13647): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(13706): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14302): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14373): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14449): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14513): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14603): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14665): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14733): warning C4101: 'status7': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14852): warning C4101: 'status13': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(14972): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15023): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15082): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15155): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15246): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15316): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15388): warning C4101: 'status8': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15473): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15519): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15593): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15640): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15686): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15738): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15862): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(15909): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16010): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16066): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16122): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16178): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16298): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16377): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16444): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16558): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16676): warning C4101: 'status4': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16818): warning C4101: 'status2': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(16914): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18144): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18243): warning C4101: 'status8': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18365): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18461): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18717): warning C4101: 'status10': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(18881): warning C4101: 'status6': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(19033): warning C4101: 'status5': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(19151): warning C4101: 'status3': unreferenced local variable\r\n180>f:\\lib\\build\\tensorflow\\pywrap_tensorflow_internal.cc(22101): warning C4101: 'status3': unreferenced local variable\r\n180>   Creating library F:/lib/build/tensorflow/Release/pywrap_tensorflow_internal.lib and object F:/lib/build/tensorflow/Release/pywrap_tensorflow_internal.exp\r\n180>pywrap_tensorflow_internal.exp : warning LNK4070: /OUT:_pywrap_tensorflow_internal.pyd directive in .EXP differs from output filename 'F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal.dll'; ignoring directive\r\n180>pywrap_tensorflow_internal.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal.dll\r\n180>Done building project \"pywrap_tensorflow_internal.vcxproj\".\r\n181>------ Build started: Project: _periodic_resample_op, Configuration: Release x64 ------\r\n182>------ Build started: Project: _nearest_neighbor_ops, Configuration: Release x64 ------\r\n183>------ Build started: Project: _lstm_ops, Configuration: Release x64 ------\r\n184>------ Build started: Project: _gru_ops, Configuration: Release x64 ------\r\n185>------ Build started: Project: _beam_search_ops, Configuration: Release x64 ------\r\n181>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n181>Done building project \"_periodic_resample_op.vcxproj\" -- FAILED.\r\n182>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n182>Done building project \"_nearest_neighbor_ops.vcxproj\" -- FAILED.\r\n184>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n184>Done building project \"_gru_ops.vcxproj\" -- FAILED.\r\n185>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n185>Done building project \"_beam_search_ops.vcxproj\" -- FAILED.\r\n183>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n183>Done building project \"_lstm_ops.vcxproj\" -- FAILED.\r\n186>------ Build started: Project: tf_python_api, Configuration: Release x64 ------\r\n187>------ Skipped Build: Project: INSTALL, Configuration: Release x64 ------\r\n187>Project not selected to build for this solution configuration \r\n186>Generating __init__.py files for Python API.\r\n188>------ Skipped Build: Project: tf_python_build_pip_package, Configuration: Release x64 ------\r\n188>Project not selected to build for this solution configuration \r\n========== Build: 174 succeeded, 12 failed, 82 up-to-date, 2 skipped ==========\r\n\r\n\r\n\r\n\r\n\r\n```", "Pretty much the same as the other two, but since you asked:\r\n\r\nHave I written custom code:  No\r\nOS Platform and Distribution:  Windows 10\r\nTensorFlow installed from: git\r\nTensorFlow version:  latest in github (as of 4/27/2018)\r\nBazel version:  don't know what this is\r\nCUDA/cuDNN version:  CPU only\r\nGPU model and memory:  N/A\r\nExact command to reproduce:  cmake-gui to generate the Visual Studio solution/projects from CMakeLists.txt and then Build Solution in Visual Studio 2017 (Release)", "I pulled the latest code last night and the build worked overnight.", "Not for me.\r\n@ctraina can youy post your cmakecache.txt and full link command line in tf_label_image_example (in Project property pages)?"]}, {"number": 19003, "title": "Dockerfile.gpu keeps the pip package", "body": "```\r\n$ docker run --rm tensorflow/tensorflow:nightly-gpu-py3 sh -c 'ls -lh /*.whl'\r\n-rw-rw-r-- 1 root root 207M May  1 04:54 /tf_nightly_gpu-1.9.0.dev20180429-cp35-cp35m-manylinux1_x86_64.whl\r\n```\r\nThis is 200MB we should get rid of.\r\n\r\nIn Dockerfile.gpu we have this:\r\nhttps://github.com/tensorflow/tensorflow/blob/d0f5bc17560fc97bcc7de9164aa3b237a8d5221d/tensorflow/tools/docker/Dockerfile.gpu#L47-L56\r\n\r\nIn `parameterized_docker_build.sh` this block is replaced this way:\r\nhttps://github.com/tensorflow/tensorflow/blob/d0f5bc17560fc97bcc7de9164aa3b237a8d5221d/tensorflow/tools/docker/parameterized_docker_build.sh#L260-L263\r\n\r\nWe don't have the `RUN rm -f /_PIP_FILE_` but it doesn't really matter for the size of the image. Since the `COPY` is necessarily a different layer than the `RUN`, see my commit message here: https://github.com/tensorflow/tensorflow/commit/9da73dedfc14861a7efcd44a9943d28ced038dc5\r\n\r\nThere is no simple solution here, multi-stage builds won't help, I will spare you the black magic technique since we have another option right in front of us:\r\nhttps://github.com/tensorflow/tensorflow/blob/d0f5bc17560fc97bcc7de9164aa3b237a8d5221d/tensorflow/tools/docker/Dockerfile.gpu#L53-L55\r\nWhat prevents us from modifying the parameters passed to `parameterized_docker_build.sh` to download the pip package? I think a 200MB improvement is worth it. \r\n\r\ncc @gunan ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "ping @gunan @aselle ", "@av8ramit looks like this is a problem with the local pip package installation.\r\nCould you take a look, we should avoid keeping the file in image if possible.", "Upon further evaluation, this is not an easy fix, since not all of our builds are uploaded to GCS when we use parameterized_docker_build.sh and as you mentioned adding a RUN delete keeps it in the top layer. I'll look into this soon.", "Nightlies can have the extra 200MB I think that's fine, but for releases only it might be easier to do, right?", "Will take another look at this when I get cycles as it's not breaking anyone at the moment.", "I've recently proposed a change to TensorFlow that obsoletes parameterized_docker_build.sh, which should help alleviate this issue (it will be easier to maintain many slim images). If anyone following this thread is interested in making TensorFlow's Dockerfile story better for everyone, [please take a look at the RFC](https://github.com/tensorflow/community/pull/8).", "@angersson will your new proposal fix this issue?\r\n", "@av8ramit Yeah. Actually, the implementation of the proposal (linked from the proposal) does fix this.", "This is resolved, since our new images do not retain the pip package."]}, {"number": 19002, "title": "Could anybody help check this problem? I've been stuck in two days and didn't find the solution.", "body": "I'm using the tf.Dataset API as follows: Suppose I have 10 `*.tfrecords` files (named `trn-001.tfrecords`,`trn-002.tfrecords`,etc.). There are 128 samples in each of these tfrecords. Suppose the samples in the first 5 tfrecords belong to class 0 and the remaining 5 tfrecords belong to class 1. In my case, the data provider should first random select 2 tfrecords for each class from those 5 tfrecords, then select fixed number of samples from each of the selected tfrecords and combine them to generate one balanced batch data to feed into the network for training. For example, for class 0, select `trn-000.tfrecords` and `trn-001.tfrecords`; for class 1, select `trn-006.tfrecords` and `trn-009.tfrecords`; then for each of the four selected tfrecords, randomly select 1 sample from each of them and combine the `1+1+1+1` samples to generate one batch data. My script to initialize the dataset operations is like this:\r\n\r\n    trn0_filenames = ['trn-000.tfrecords','trn-001.tfrecords','trn-002.tfrecords','trn-003.tfrecords','trn-004.tfrecords']\r\n    trn1_filenames = ['trn-005.tfrecords','trn-006.tfrecords','trn-007.tfrecords','trn-008.tfrecords','trn-009.tfrecords']\r\n\r\n    half_batch_size = int(BATCH_SIZE / 2)\r\n    trn0_count = len(trn0_filenames)\r\n    trn1_count = len(trn1_filenames)\r\n    features0_ops = []\r\n    labels0_ops = []\r\n    for trn0_filename in trn0_filenames:\r\n        feature_op, label_op, = dataset_input_from_tfrecords([trn0_filename], batch_size=1, num_epochs=50000, shuffle=True, image_mean=None)\r\n        features0_ops.append(feature_op)\r\n        labels0_ops.append(label_op)\r\n    \r\n    features1_ops = []\r\n    labels1_ops = []\r\n    for trn1_filename in trn1_filenames:\r\n        feature_op, label_op = dataset_input_from_tfrecords([trn1_filename], batch_size=1, num_epochs=50000, shuffle=True, image_mean=None)\r\n        features1_ops.append(feature_op)\r\n        label_ops.append(label_op)\r\n\r\nThen during training, the script to generate the batch data is like this:\r\n\r\n    features = np.zeros((BATCH_SIZE, HEIGHT, WIDTH, 3), dtype=np.float32)\r\n    labels = np.zeros((BATCH_SIZE,), dtype=np.int64)\r\n    \r\n    while not coord.should_stop():\r\n        ind0 = np.random.choice(trn0_count, half_batch_size)\r\n        ind1 = np.random.choice(trn1_count, half_batch_size)\r\n        batch_idx = 0\r\n        for idx in ind0:\r\n            temp1,temp2 = sess.run([features0_ops[idx],\r\n                                                labels0_ops[idx]])\r\n            features[batch_idx] = temp1[0]\r\n            labels[batch_idx] = temp2[0]\r\n            batch_idx+=1\r\n        for idx in ind1:\r\n            temp1,temp2 = sess.run([features1_ops[idx],\r\n                                    labels1_ops[idx]])\r\n            features[batch_idx] = temp1[0]\r\n            labels[batch_idx] = temp2[0]\r\n            batch_idx+=1\r\n\r\nand then feed the batch data into network for training:\r\n\r\n    summary,_,loss_total,loss,loss_reg = sess.run([summary_op, train_op, \r\n                                   loss_total_op,loss_op,loss_reg_op], \r\n                                  feed_dict={x_tensor: features, y_tensor: labels})\r\n\r\n\r\nThe problem is: during training, I found that the memory usage of the process is consistently increasing. Please check the following screenshot. The process 3208 is the running process. At first, the memory usage is about `10%`, but at the moment when I taken this picture, the memory usage has increased to `41.6%`. So my question is: is this a memory problem? What's wrong? I cannot find the problem. If the memory usage is increasing to some certain amount, the computer will be halt down then I need to restart.\r\n\r\n[![memory usage][1]][1]\r\n\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/WaPkI.png", "comments": ["Can you please share the code for the `dataset_input_from_tfrecords()` function, as well as what exact version of TensorFlow you're using?", "Hi @mrry , the TensorFlow version is `1.6.0`. The `dataset_input_from_tfrecords` is:\r\n\r\n    def dataset_input_from_tfrecords(filenames, batch_size=1, num_epochs=1, shuffle=True, image_mean=None):\r\n    # filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\r\n    dataset = tf.data.TFRecordDataset(filenames)\r\n    \r\n    # Use `tf.parse_single_example()` to extract data from a `tf.Example`\r\n    # protocol buffer, and perform any additional per-record preprocessing.\r\n    def parser(record):\r\n        keys_to_features = {\r\n            'image_raw': tf.FixedLenFeature([], tf.string),\r\n            'label': tf.FixedLenFeature([], tf.int64),\r\n        }\r\n        parsed = tf.parse_single_example(record, keys_to_features)\r\n        \r\n        # Perform additional preprocessing on the parsed data.\r\n        image = tf.cast(tf.decode_raw(parsed['image_raw'], tf.uint8), tf.float32) / 128 - 1.0\r\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\r\n        label = tf.cast(parsed['label'], tf.int64)\r\n        \r\n        if image_mean != None:\r\n            image -= image_mean\r\n        \r\n        return image, label\r\n    \r\n    # Use `Dataset.map()` to build a pair of a feature dictionary and a label \r\n    # tensor for each example.\r\n    dataset = dataset.map(parser)\r\n    if shuffle:\r\n        dataset = dataset.shuffle(buffer_size=1024)\r\n    dataset = dataset.batch(batch_size)\r\n    # dataset = dataset.padded_batch(batch_size, padded_shapes=([HEIGHT, WIDTH, 3], []))\r\n    # dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    dataset = dataset.repeat(num_epochs)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    \r\n    features, labels = iterator.get_next()\r\n    return features, labels", "Hi @mrry , if I use the ordinary version without randomly use the python `list` to save the ops (feature_op, label_op), and use the following:\r\n\r\n    trn_filenames = trn0_filenames +trn1_filenames\r\n    features_op, labels_op = dataset_input_from_tfrecords(trn_filenames, batch_size=4, num_epochs=50000, shuffle=True, image_mean=None)\r\n\r\nThen everything works fine, which means the `dataset_input_from_tfrecords` is fine. But in my case I want to make the class distribution balanced and just one sample from one tfrecords file. I'm not sure if the `Dataset` API has this functionality, thus I generated many Datasets operations and did the work like that described above.", "@mrry Sorry, the problem may not lie in the Dataset API. Maybe lie in the following:  After one epoch, I conduct the prediction on validation set like this:\r\n\r\n    if step%NUM_TRAIN_STEPS_ONE_EPOCH==0:\r\n        val_features_op, val_labels_op = dataset_input_from_tfrecords(val_filenames, batch_size=1, num_epochs=50000, shuffle=True, image_mean=None)\r\n        ....\r\n        val_features, val_labels = sess.run([val_features_op, val_labels_op])\r\n        ....\r\n    \r\nSo the `val_features_op, val_labels_op` will add to the whole graph for many times during the loop, right? Maybe this is the problem, which makes the graph bigger and bigger.", "@mrry , that's the problem. After I commented the validation code, the memory usage is reasonable during training. Sorry for disturbing you!", "Thanks for confirming! Yes, that call to `dataset_input_from_tfrecords()` inside the training loop would cause the graph to grow. ", "@mrry , thanks a lot for your confirmation!", "@mrry , maybe the TF engine could automatically detect those invalid operators and remove them, like the garbage collection. Or during the graph construction, the engine can detect the possible invalid subgraph. Not sure if this is a need."]}, {"number": 19001, "title": "multiple traceback error  (import tensorflow as tf)..... [I am using Python 3.6.5 x64)", "body": "Issue with (import tensorflow as tf)..... details of error given below [I am using Python 3.6.5 x64)\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\anilt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It looks like it's an installation error. Did you follow the instructions? It's typically because the DLL is missing some dependency, like the right CUDA version.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 19000, "title": "Feature Request: get Estimator from binary model (.pb file)", "body": "### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS High Sierra 10.13.4\r\n- **TensorFlow installed from (source or binary)**: binary (through pip)\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: not using CUDA, just CPU for now\r\n- **GPU model and memory**: - \r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nI am using the Estimator interface to train and evaluate  my model. It is really cool.\r\nHowever, since I am developing for mobile, after training I must also freeze, optimize, quantize the model and then port it to TFLite.  \r\nIn these steps, my model must be in binary format (.pb).\r\n\r\nIt would be nice to build an Estimator from a .pb file to allow evaluation of binary models.\r\nFor instance, I need to check how much accuracy I am losing after the quantization step.\r\nHowever, I believe that at the moment it is not possible to instantiate an Estimator from a binary model.\r\n\r\nI have done some research before opening this issue:\r\n- I have searched the TF documentation but did not find anything about loading a binary model into an Estimator;\r\n- I have tried to ask this question on StackOverflow three weeks ago (here is [the link](https://stackoverflow.com/questions/49736537/load-a-frozen-model-into-a-tensorflow-estimator)), but got no answers.\r\n\r\nAs a consequence, at the moment I am just using the old GraphDef and feed_dict interface to perform evaluation and prediction with binary models. \r\nHowever using different interfaces for literally the same tasks just seems a bit... off.\r\n\r\nEstimators probably use GraphDef under the hood. So it should be really easy to allow instantiation from a binary model.\r\n\r\nAm I missing something? If not, can you implement this feature please?\r\n\r\nThanks for your support!\r\nAndrea", "comments": ["@karmel is this related to saved model based Estimator you're working on?", "Thanks, @ispirmustafa and @AndRossi -- we are indeed currently working on this, with the intended result being that an Estimator can load from a SavedModel directory (which contains the variables and the graph binary). Note that the SavedModel is not the same as a FrozenGraph/TFLite flatbuffer, but is usually a pre-requisite for those. \r\n\r\nWe are aiming to have support in tf.contrib this quarter. Assigning to @k-w-w for now; stay tuned.", "Is there any way to save a given Estimator object as a .pb file directly? I've been jumping between links for quite some time now, and nothing seems to work.", "@iamgroot42 Currently, you can export prediction outputs using the [`export_savedmodel`](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_savedmodel) function. A function for exporting the train and evaluation graphs is in TensorFlow v1.9: https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/export_all_saved_models", "@k-w-w  thanks for the pointer! The error I was facing was because of some missing import statements which are explicitly required in some cases (thanks to dynamic imports for Tensorflow).", "This exists now: https://www.tensorflow.org/versions/r1.11/api_docs/python/tf/contrib/estimator/SavedModelEstimator\r\n\r\nPlease check it out and let us know if it works for your use-case.", "Nagging Assignees @karmel, @k-w-w: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Assuming that the answer is yes; please open a new issue if you encounter any trouble."]}, {"number": 18999, "title": "R0.7", "body": "test", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 18998, "title": "numeric_column with shape other than (1,)", "body": "```\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nfcs = [tf.feature_column.numeric_column('images',shape=(1,1),dtype=tf.DType)]\r\nmydf=pd.DataFrame({'images':[[-1,-1],[-2,-2],[-3,-3],[2,2],[3,3],[4,4]],'labels':[0,0,0,1,1,1]})\r\n\r\ninfn = tf.estimator.inputs.pandas_input_fn(x=mydf,y=mydf['labels'],batch_size=6,num_epochs=None,shuffle=False)\r\nestimator = tf.estimator.LinearClassifier(feature_columns=fcs)\r\nestimator.train(input_fn=infn,steps=200)\r\n```\r\n\r\nerror i get is \r\n\r\n```\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InternalError'>, Unable to get element as bytes.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpe64_mf9a/model.ckpt.\r\n\r\nInternalError: Unable to get element as bytes.\r\n```\r\n\r\nif i change my Dataframe to \r\n\r\n```\r\nmydf=pd.DataFrame({'images':[-1,-2,-3,2,3,4],'labels':[0,0,0,1,1,1]})\r\n``` \r\nit works", "comments": ["@maswadkar: Not sure it makes sense to use a list as a [numeric_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column).  Is there a reason why you wouldn't separate the `images` column into two separate columns in `mydf`?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nYou can repost this there, and, in the meantime, a quick look indicates the shape you passed in when defining the numeric column does not match the shape in the DataFrame.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Hi @Benyuel,\r\nin my real problem, the 'images' column is array of 300,300 dimension. \r\nto simplify the problem, i made it 1,1 \r\n", "Unsubscribe\n\nOn Wed, 2 May 2018, 11:53 pm Karmel Allison, <notifications@github.com>\nwrote:\n\n> This question is better asked on StackOverflow\n> <http://stackoverflow.com/questions/tagged/tensorflow> since it is not a\n> bug or feature request. There is also a larger community that reads\n> questions there.\n>\n> You can repost this there, and, in the meantime, a quick look indicates\n> the shape you passed in when defining the numeric column does not match the\n> shape in the DataFrame.\n>\n> If you think we've misinterpreted a bug, please comment again with a clear\n> explanation, as well as all of the information requested in the issue\n> template <https://github.com/tensorflow/tensorflow/issues/new>. Thanks!\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18998#issuecomment-386073359>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AYMLKFMYHg4yn_gqffc0_sRxCwcQYFAvks5tufm6gaJpZM4TtvJg>\n> .\n>\n", "Hi @maswadkar \r\n\r\nHave you found a solution to the problem? I'm in exactly the same situation."]}, {"number": 18997, "title": "Please Tell me \uff0c Can I brazel Tensorflow Android in windows paltom ? ", "body": "I brazel Android Apk in windows 10, but Always makes Errors \uff0c Can I brazel Tensorflow Android in windows paltom ? ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 18996, "title": "Problems when implementing double backpropagation on BatchNormalization layer in residual block of ResNet", "body": "### System information\r\n- **OS Platform and Distribution: Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-87-generic x86_64)**:\r\n- **TensorFlow version: 1.7.0**:\r\n- **Python version: 3.6.4**: \r\n- **GCC/Compiler version: 7.2.0**:\r\n- **CUDA/cuDNN version: CUDA 9.1.85**:\r\n- **Exact command to reproduce: python train_adv_cifar.py**:\r\n\r\n### Describe the problem\r\nI met a problem when implementing double back-propagation when training my ResNet-20-V1 model to classify CIFAR10 images. Double back-propagation means to add a regularization term to the normal loss function. The regularization term is usually the gradient of the normal loss function W.R.T. the input tensor. The following codes are for reference. The problem happens when the following sentence is executed.\r\n`train_step = tf.train.AdamOptimizer(learning_rate=0.0002, epsilon=1e-4).minimize(total_loss, global_step=global_step)`\r\n![image](https://user-images.githubusercontent.com/30309087/39464412-b3b3c84e-4d4f-11e8-93ce-3655c568ec14.png)\r\n\r\nAll the BN layers in the residual block have such problems. \r\nAnd then it goes like this:\r\n![image](https://user-images.githubusercontent.com/30309087/39464422-c6fb2e24-4d4f-11e8-9f9c-a46908a0e50e.png)\r\nThe above traceback is very long and it seems like the program is trapped there in a loop when constructing gradients in Tf Graph.\r\nHowever, if I remove the BN layers in the residual block, the program works well. I also have BN layers as sequential parts of my model architecture and it works well. The residual block itself also works well. The problem happens only when there are BN layers in the residual block. But in custom ResNet architectures, there are usually BN layers in residual block. I couldn't figure out the solution.\r\n\r\n### Source code / logs\r\nHere is my main code:\r\n`\r\nimport sys\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom cifar_model_tf import Model_cifar\r\n\r\nmodel = Model_cifar(mode='train')\r\n\r\nx_nat = tf.placeholder(tf.float32,(None,32,32,3))\r\n\r\ny = tf.placeholder(tf.float32,(None,10))\r\n\r\nlamda = 100\r\nlogits_nat = model._build_model(x_nat)\r\npreds_nat = tf.nn.softmax(logits_nat)\r\n\r\nloss_1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits_nat))\r\nloss_2 = tf.nn.l2_loss(tf.gradients(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits_nat)), x_nat)[0])\r\ntotal_loss = loss_1 + loss_2 * lamda\r\n\r\ntrain_step = tf.train.AdamOptimizer(learning_rate=0.0002, epsilon=1e-4).minimize(total_loss, global_step=global_step)\r\n\r\n`\r\n\r\nAnd here is the code in my model file \"cifar_model_tf.py\":\r\n`import numpy as np\r\nimport tensorflow as tf\r\n\r\nclass Model_cifar(object):\r\n  \"\"\"ResNet model.\"\"\"\r\n  def __init__(self, mode='eval'):\r\n    \"\"\"ResNet constructor.\"\"\"\r\n    self.mode = mode\r\n     \r\n  def _stride_arr(self, stride):\r\n    \"\"\"Map a stride scalar to the stride array for tf.nn.conv2d.\"\"\"\r\n    return [1, stride, stride, 1]\r\n\r\n  def _build_model(self, x_input):\r\n    with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\r\n      with tf.variable_scope('input'):\r\n        ch = x_input.get_shape().as_list()[3]\r\n        x = self._conv('init_conv', x_input, 3, ch, 16, self._stride_arr(1))\r\n        x = self._batch_norm('init_bn', x)\r\n        x = self._relu(x)\r\n      res_func = self._residual\r\n      filters = [16, 32, 64]\r\n      with tf.variable_scope('unit_1'):\r\n        with tf.variable_scope('unit_1_1'):\r\n          x = res_func(x, filters[0], filters[0], self._stride_arr(1))\r\n        with tf.variable_scope('unit_1_2'):\r\n          x = res_func(x, filters[0], filters[0], self._stride_arr(1))\r\n        with tf.variable_scope('unit_1_3'):\r\n          x = res_func(x, filters[0], filters[0], self._stride_arr(1))\r\n      with tf.variable_scope('unit_2'):\r\n        with tf.variable_scope('unit_2_1'):\r\n          x = res_func(x, filters[0], filters[1], self._stride_arr(2))\r\n        with tf.variable_scope('unit_2_2'):\r\n          x = res_func(x, filters[1], filters[1], self._stride_arr(1))\r\n        with tf.variable_scope('unit_2_3'):\r\n          x = res_func(x, filters[1], filters[1], self._stride_arr(1))\r\n      with tf.variable_scope('unit_3'):\r\n        with tf.variable_scope('unit_3_1'):\r\n          x = res_func(x, filters[1], filters[2], self._stride_arr(2))\r\n        with tf.variable_scope('unit_3_2'):\r\n          x = res_func(x, filters[2], filters[2], self._stride_arr(1))\r\n        with tf.variable_scope('unit_3_3'):\r\n          x = res_func(x, filters[2], filters[2], self._stride_arr(1))\r\n      \r\n      with tf.variable_scope('unit_last'):\r\n        x = self._avg_pool(x, 8)\r\n      with tf.variable_scope('logit'):\r\n        x = self._fully_connected(x, 10)\r\n      \r\n      return x \r\n  \r\n  def _batch_norm(self, name, x):\r\n    \"\"\"Batch normalization.\"\"\"\r\n    with tf.name_scope(name):\r\n      return tf.layers.batch_normalization(\r\n          inputs=x,\r\n          training=(self.mode == 'train'))\r\n  \r\n\r\n  def _residual(self, x, in_filter, out_filter, stride):\r\n    \"\"\"Residual unit with 2 sub layers.\"\"\"\r\n    orig_x = x\r\n    with tf.variable_scope('sub1'):\r\n      x = self._conv('conv1', x, 3, in_filter, out_filter, stride)\r\n      x = self._batch_norm('bn1', x)\r\n      x = self._relu(x)\r\n    with tf.variable_scope('sub2'):\r\n      x = self._conv('conv2', x, 3, out_filter, out_filter, self._stride_arr(1))\r\n      #x = self._batch_norm('bn2', x)\r\n    with tf.variable_scope('sub_add'):\r\n      if in_filter != out_filter:\r\n        y = self._conv('conv_match', orig_x, 1, in_filter, out_filter, stride)\r\n      else:\r\n        y = orig_x\r\n      z = x + y\r\n      z = self._relu(z)\r\n\r\n    return z\r\n\r\n  def _conv(self, name, x, filter_size, in_filters, out_filters, strides):\r\n    \"\"\"Convolution.\"\"\"\r\n    with tf.variable_scope(name):\r\n      n = filter_size * filter_size * out_filters\r\n      kernel = tf.get_variable('DW', [filter_size, filter_size, in_filters, out_filters],tf.float32, initializer=tf.keras.initializers.he_normal(), regularizer=tf.keras.regularizers.l2(l=1e-4))\r\n      bias = tf.get_variable('biases', [out_filters], initializer=tf.constant_initializer())\r\n      conv = tf.nn.conv2d(x, kernel, strides, padding='SAME')\r\n      result = conv + bias\r\n      return result\r\n\r\n  def _relu(self, x, leakiness=0.0):\r\n    \"\"\"Relu, with optional leaky support.\"\"\"\r\n    return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')\r\n\r\n  def _fully_connected(self, x, out_dim):\r\n    \"\"\"FullyConnected layer for final output.\"\"\"\r\n    num_non_batch_dimensions = len(x.shape)\r\n    prod_non_batch_dimensions = 1\r\n    for ii in range(num_non_batch_dimensions - 1):\r\n      prod_non_batch_dimensions *= int(x.shape[ii + 1])\r\n    x = tf.reshape(x, [tf.shape(x)[0], -1])\r\n    w = tf.get_variable(\r\n        'DW', [prod_non_batch_dimensions, out_dim],\r\n        initializer=tf.keras.initializers.he_normal())\r\n    b = tf.get_variable('biases', [out_dim],\r\n                        initializer=tf.constant_initializer())\r\n    result = tf.nn.xw_plus_b(x, w, b)\r\n    return result\r\n\r\n  def _avg_pool(self, x, pool_size):\r\n    return tf.nn.avg_pool(x, ksize=[1,pool_size,pool_size,1], strides=[1,pool_size,pool_size,1], padding='VALID')`\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow installed from\nBazel version\nGPU model and memory", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18995, "title": "compiling c++ code with TFLite library gives error with cstring", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: N/A (using only source files)\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.13.0\r\n- **GCC/Compiler version (if compiling from source)**: g++ 5.4.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm trying to compile custom c++ code with command\r\n`g++ -std=c++11 -Itensorflow/contrib/lite -I. -Lbazel-bin/tensorflow/contrib/lite -tflite test.cpp -o test`\r\n\r\nand it gives some error that some functions in cstring cannot be found.\r\n\r\nWhen I delete line `#include <cstring>` from flatbuffers/base.h, errors from cstring disappear but others remain. Including cstring in flatbuffers.h also gives same errors.\r\nI'm using flatbuffers cloned from git google flatbuffers repository. Is this can be a problem?\r\n\r\n\r\nI've made c++ tensorflow lite library with command\r\n`bagel build //tensorflow/contrib/lite:framework`\r\nwith lite/BUILD including\r\n`cc_binary(\r\n    name = \"libtflite.so\",\r\n    deps = [\r\n        \":framework\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\"],\r\n    ]\r\n)\r\n`\r\n\r\n\r\nThanks.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n#### C++ Code\r\n```\r\n  1 #include <stdio.h>\r\n  2 \r\n  3 #include \"tensorflow/contrib/lite/kernels/register.h\"\r\n  4 #include \"tensorflow/contrib/lite/model.h\"\r\n  5 #include \"tensorflow/contrib/lite/string_util.h\"\r\n  6 #include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\r\n  7 \r\n  8 \r\n  9 \r\n 10 int main(){\r\n 11     const char* graph_path = \"xorGate.lite\";\r\n 12     const int num_threads = 1;\r\n 13     std::string input_layer_type = \"float\";\r\n 14     float x,y;\r\n 15 \r\n 16     std::unique_ptr<tflite::FlatBufferModel> model(\r\n 17         tflite::FlatBufferModel::BuildFromFile(graph_path));\r\n 18 \r\n 19     if(!model){\r\n 20         printf(\"Failed to mmap model\\n\");\r\n 21         exit(0);\r\n 22     }\r\n 23 \r\n 24     tflite::ops::builtin::BuiltinOpResolver resolver;\r\n 25     std::unique_ptr<tflite::Interpreter> interpreter;\r\n 26     tflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n 27 \r\n 28     if(!interpreter){\r\n 29         printf(\"Failed to construct interpreter\\n\");\r\n 30         exit(0);\r\n 31     }\r\n 32 \r\n 33     if(num_threads != 1){\r\n 34         interpreter->SetNumThreads(num_threads);\r\n 35     }\r\n 36 \r\n 37     float* input = interpreter->typed_input_tensor<float>(0);\r\n 38 \r\n 39     if(interpreter->AllocateTensors() != kTfLiteOk){\r\n 40         printf(\"Failed to allocate tensors\\n\");\r\n 41         exit(0);\r\n 42     }\r\n 43 \r\n 44     //read two numbers\r\n 45     std::printf(\"Type two float numbers : \");\r\n 46     std::scanf(\"%f %f\", &x, &y);\r\n 47     input[0] = x;\r\n 48     input[1] = y;\r\n 49 \r\n 50     if(interpreter->Invoke() != kTfLiteOk){\r\n 51         std::printf(\"Failed to invoke!\\n\");\r\n 52         exit(0);\r\n 53     }\r\n 54     float* output = interpreter->typed_output_tensor<float>(0);\r\n 55     printf(\"output = %f\\n\", output[0]);\r\n 56     return 0;\r\n 57 }\r\n```\r\n\r\n#### Log\r\n```\r\nIn file included from ./flatbuffers/base.h:2:0,\r\n                 from ./flatbuffers/flatbuffers.h:18,\r\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n/usr/include/c++/5/cstring:75:11: error: \u2018::memchr\u2019 has not been declared\r\n   using ::memchr;\r\n/usr/include/c++/5/cstring:76:11: error: \u2018::memcmp\u2019 has not been declared\r\n   using ::memcmp;\r\n/usr/include/c++/5/cstring:77:11: error: \u2018::memcpy\u2019 has not been declared\r\n   using ::memcpy;\r\n/usr/include/c++/5/cstring:78:11: error: \u2018::memmove\u2019 has not been declared\r\n   using ::memmove;\r\n/usr/include/c++/5/cstring:79:11: error: \u2018::memset\u2019 has not been declared\r\n   using ::memset;\r\n/usr/include/c++/5/cstring:80:11: error: \u2018::strcat\u2019 has not been declared\r\n   using ::strcat;\r\n\r\n...\r\nsame error from different functions\r\n...\r\n   \r\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::String::operator<(const flatbuffers::String&) const\u2019:\r\n./flatbuffers/flatbuffers.h:346:12: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\r\n     return std::strcmp(c_str(), o.c_str()) < 0;\r\n            ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::Allocator::memcpy_downward(uint8_t*, size_t, uint8_t*, size_t, size_t, size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:387:23: error: \u2018memcpy\u2019 was not declared in this scope\r\n            in_use_back);\r\n                       ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::push(const uint8_t*, size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:628:39: error: \u2018memcpy\u2019 was not declared in this scope\r\n     memcpy(make_space(num), bytes, num);\r\n                                       ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::fill_big(size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:652:57: error: \u2018memset\u2019 was not declared in this scope\r\n     memset(make_space(zero_pad_bytes), 0, zero_pad_bytes);\r\n                                                         ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::uoffset_t flatbuffers::FlatBufferBuilder::EndTable(flatbuffers::uoffset_t)\u2019:\r\n./flatbuffers/flatbuffers.h:982:62: error: \u2018memcmp\u2019 was not declared in this scope\r\n         if (vt1_size != vt2_size || memcmp(vt2, vt1, vt1_size)) continue;\r\n                                                              ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1061:40: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateString(str, strlen(str));\r\n                                        ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1068:40: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateString(str, strlen(str));\r\n                                        ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateSharedString(const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1124:46: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateSharedString(str, strlen(str));\r\n                                              ^\r\nIn file included from ./flatbuffers/base.h:12:0,\r\n                 from ./flatbuffers/flatbuffers.h:18,\r\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::FlatBufferBuilder::Finish(flatbuffers::uoffset_t, const char*, bool)\u2019:\r\n./flatbuffers/flatbuffers.h:1563:48: error: \u2018strlen\u2019 was not declared in this scope\r\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\r\n                                                ^\r\n./flatbuffers/flatbuffers.h:1563:7: note: in expansion of macro \u2018FLATBUFFERS_ASSERT\u2019\r\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\r\n       ^\r\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::FlatBufferBuilder::StringOffsetCompare::operator()(const flatbuffers::Offset<flatbuffers::String>&, const flatbuffers::Offset<flatbuffers::String>&) const\u2019:\r\n./flatbuffers/flatbuffers.h:1604:64: error: \u2018strncmp\u2019 was not declared in this scope\r\n                      (std::min)(stra->size(), strb->size()) + 1) < 0;\r\n                                                                ^\r\n./flatbuffers/flatbuffers.h: In function \u2018bool flatbuffers::BufferHasIdentifier(const void*, const char*, bool)\u2019:\r\n./flatbuffers/flatbuffers.h:1676:58: error: \u2018strncmp\u2019 was not declared in this scope\r\n                  FlatBufferBuilder::kFileIdentifierLength) == 0;\r\n                                                          ^\r\n./flatbuffers/flatbuffers.h: In function \u2018int flatbuffers::LookupEnum(const char**, const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:2119:10: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\r\n     if (!std::strcmp(*p, name)) return static_cast<int>(p - names);\r\n```", "comments": ["Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@timedilation  Have you  solved this problem?", "I am also getting this same error.\r\nAny idea in how to solve this error?", "Same error too, need help.......", "Don't know how to solve this issue, but there is another \"string.h\" file in folder \"tensorflow/lite\" and it seems that the compiler use this file instead.", "> Don't know how to solve this issue, but there is another \"string.h\" file in folder \"tensorflow/lite\" and it seems that the compiler use this file instead.\r\n\r\nNot sure if this is the proper way, but removing the `string.h` under `tensorflow/lite` will at least pass the build", "Not sure if applicable but please see if my resolution is helpful for your case. For me, the issue disappeared once I removed the `tensorflow/lite` from include paths.\r\n\r\nEarlier compile command (with the same errors as author):\r\n`g++ -std=c++11 -Itensorflow-1.13.1 -Itensorflow-1.13.1/tensorflow/lite -Itensorflow-1.13.1/tensorflow/lite/tools/make/downloads/flatbuffers/include main.cpp -o main.out -ltensorflow-lite`\r\n\r\nAdjusted compile command (with issue resolved):\r\n`g++ -std=c++11 -Itensorflow-1.13.1 -Itensorflow-1.13.1/tensorflow/lite/tools/make/downloads/flatbuffers/include main.cpp -o main.out -ltensorflow-lite`", "> Not sure if applicable but please see if my resolution is helpful for your case. For me, the issue disappeared once I removed the `tensorflow/lite` from include paths.\r\n> \r\n> Earlier compile command (with the same errors as author):\r\n> `g++ -std=c++11 -Itensorflow-1.13.1 -Itensorflow-1.13.1/tensorflow/lite -Itensorflow-1.13.1/tensorflow/lite/tools/make/downloads/flatbuffers/include main.cpp -o main.out -ltensorflow-lite`\r\n> \r\n> Adjusted compile command (with issue resolved):\r\n> `g++ -std=c++11 -Itensorflow-1.13.1 -Itensorflow-1.13.1/tensorflow/lite/tools/make/downloads/flatbuffers/include main.cpp -o main.out -ltensorflow-lite`\r\n\r\nThis solution worked for me. The issue may be caused by the string.h implemented by TF. The string.h in tensorflow/lite doesn't define \"memcpy memset......\". Thus, remove tensorflow/lite from include_directories. \r\nThanks a lot. "]}, {"number": 18994, "title": "[r1.7][TensorRT] Will it be able to use TRT to optimized the GraphDef that gained from a TF saved_model?", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\r\n- **TensorFlow installed from (source or binary)**: pip (python 2.7)\r\n- **TensorFlow version (use command below)**: tensorflow-gpu==1.7.0\r\n- **Python version**:  python 2.7\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.3\r\n- **CUDA/cuDNN version**: CUDA9.0, cuDNN7.0.5\r\n- **GPU model and memory**: Tesla P4, 8GB\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nI tried to load the saved_model and optimize it by integrated TensorRT to do the prediction. The TensorRT will optimize the GraphDef and eventually get about 50% throughput speed-up. I verified this on frozen model, but when trying to apply that on the saved_model, I encountered an error during the graph conversion like below:\r\n```\r\n2018-05-01 11:36:30.553143: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\r\n2018-05-01 11:36:41.562979: W tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2524] Type conversion failed for InceptionV3/Conv2d_2a_3x3/BatchNorm/moving_mean\r\n2018-05-01 11:36:41.563063: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:412] subgraph conversion error for subgraph_index:0 due to: \"Invalid argument: Unsupported data type float_ref\" SKIPPING......( 803 nodes)\r\nTensor(\"input:0\", shape=(?, 299, 299, 3), dtype=float32)\r\n```\r\nI printed out the GraphDef but not found key name \"float_ref\", so not quite sure how to address this issue. \r\n\r\n### Source code / logs\r\nSome essential part of my script:\r\n```\r\n    with tf.Graph().as_default():                                                                                                            \r\n        with tf.Session(graph=tf.Graph()) as sess:\r\n            if args.image:\r\n                import numpy as np\r\n                func = TestKit.preprocess_func['tensorflow'][args.network]\r\n                img = func(args.image)\r\n                img = np.expand_dims(img, axis = 0)                                                                  \r\n            inp, out = importer.import_graph_def(graph_def=sess.graph_def, return_elements=['input','InceptionV3/Logits/SpatialSqueeze'])\r\n            t0 = time.time()                                                                                                                                   \r\n            print sess.graph_def\r\n            f32_graph = trt.create_inference_graph(    #<<<<< Breakpoint\r\n                input_graph_def=sess.graph_def,\r\n                #outputs=[logits],                                                                                                                                              \r\n                outputs=['InceptionV3/Logits/SpatialSqueeze'],\r\n                #  max_batch_size = int(input_dims[0]),                                                                                                                         \r\n                max_batch_size = 1,\r\n                max_workspace_size_bytes=1 << 20,\r\n                precision_mode=\"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"                                                                                          \r\n                minimum_segment_size=2  # minimum number of nodes in an engine      \r\n            )                                                                                                                                         \r\n        features_tensor = sess.graph.get_tensor_by_name(\"InceptionV3/Logits/SpatialSqueeze:0\")\r\n        data_input = sess.graph.get_tensor_by_name(\"input:0\")\r\n        print data_input\r\n    init_g = tf.global_variables_initializer()\r\n    init_l = tf.local_variables_initializer()\r\n    g = ops.Graph()\r\n```\r\n\r\nAny idea will be welcome.\r\nThanks,\r\n\r\n", "comments": ["@oscarriddle TRT is an inference engine. So you need to try to convert frozen models and it won't work on training graphs. The graph you are trying to convert is probably not frozen. Can you ensure that you ran freeze_graph.py on the model you want to import?\r\n\r\nThanks,\r\nSami", "Hi @samikama ,\r\n\r\nThanks for your replay.\r\n\r\nI'm actually trying to speed-up the inference, so nothing to do with training for now. My idea is to use the TF 1.7 with TRT GraphDef optimization API to optimize a trained model, and then use the TF to do the prediction on the optimized GraphDef. The TRT UFF model conversion or TRT inference engine are not used.\r\n\r\nI've successfully done this procedure on the frozen model (#18548). But since the online serving is using the saved_model, I tried to load a saved_model and extract its graph_def, and use TRT to optimize it. But Error occurs here.\r\n\r\nThanks,", "@oscarriddle,\r\n\r\nUnfortunately, saved_model is not frozen. freeze_graph.py convert variables to constants and removes training nodes that are not used in inference as well as may apply a couple of optimizations. graph_def from saved model still contains training nodes and variables. If you want to call TRT optimization on saved_model, graphdef you need to first freeze it. You can call freeze_graph() in your script. Check freeze_graph.py.\r\n\r\nCheers,", "Hi @samikama ,\r\n\r\nThanks for your reply. I will try your advice soon.\r\nToday I tried another way of doing this, that I loaded a frozen model, then TRT optimized it, then exported it as a saved_model.\r\nBut when I tried to restore this saved_model, an ERROR popped up, that seems the node 'TRTEngineOp' is not recognized:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 219, in load\r\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1927, in import_meta_graph\r\n    **kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 741, in import_scoped_meta_graph\r\n    producer_op_list=producer_op_list)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 457, in import_graph_def\r\n    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 227, in _RemoveDefaultAttrs\r\n    op_def = op_dict[node.op]\r\nKeyError: u'TRTEngineOp'\r\n>>> tf.__version__\r\n'1.7.0'\r\n\r\n```\r\nI traced the source code, the 'TRTEngineOp' seems a subclass of the OpKernel, so I'm a little confused why it can't be restored in a standard way. Could you share some comment on this? \r\n\r\nThanks,", "@oscarriddle , you need to import tensorflow.contrib.tensorrt for TRTEngine op to become available to TensorFlow.\r\n\r\nCheers,\r\nSami\r\n", "Hi @samikama \r\n\r\nI imported the tensorrt and now the saved_model can be loaded. \r\nBut when do the sess.run, a CUDA malloc related error popped up.\r\n```\r\nimport/PermConstNCHWToNHWC-LayoutOptimizer\r\nimport/PermConstNHWCToNCHW-LayoutOptimizer\r\nimport/Placeholder\r\nimport/InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer\r\nimport/InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\r\nimport/InceptionV3/Logits/SpatialSqueeze\r\nimport/InceptionV3/my_trt_op0\r\nShape\r\n2018-05-03 10:08:14.007927: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger resources.cpp (199) - Cuda Error in gieCudaMalloc: 2\r\nterminate called after throwing an instance of 'nvinfer1::CudaError'\r\n```\r\n\r\nMy script:\r\n```\r\n    with tf.Session(graph=tf.Graph()) as sess:\r\n        tf.saved_model.loader.load(sess, ['serve'], './fs2')\r\n        graph = tf.get_default_graph()\r\n        for op in tf.get_default_graph().get_operations():\r\n            print str(op.name)                                                                                                                           \r\n        inp = graph.get_tensor_by_name(\"import/Placeholder:0\")\r\n        oup = graph.get_tensor_by_name(\"import/InceptionV3/Logits/SpatialSqueeze:0\")\r\n        sess.run(oup, {inp: batch_input})\r\n```\r\n\r\nThis seems to be a TRT related issue, I'm also trying to figure it out. \r\nIf you could share some comments, it will be much grateful.\r\n\r\nThanks,", "@oscarriddle , unfortunately this is a nuisance on our part and we will take care of it when TRT4.0 comes out. It is happening because of memory allocation incompatibility between TRT3 and TF. In order to workaround it you need to tell TF to leave some memory for TRT. You can do this by passing GPUOptions to session configuration like below. But since TF allocation policy defines the amount of allocated memory at first call, you have to make sure that you set the memory fraction at the first session call. I would suggest you to create a dummy session without any graph or anything right after you import tensorflow, before doing anything else. Of course, you have to tune the fraction to accommodate your model and memory size you are passing to TensorRT during the conversion call.\r\n\r\n```python\r\n  sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.50)))\r\n```\r\nLet me know if this helps.\r\nCheers,\r\n", "Hi @samikama \r\n\r\nThanks for your reply, it helps me understand the behind mechanism.\r\nI added this line to partition the available memory in creating a session, and now previous error disappeared, but a new one popped that:\r\n`tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./fs2/variables/variables`\r\n\r\nI noticed the saved_model, which is generated based on a optimized frozen model, is in a different format from normal saved_models. The new saved_model has below file list:\r\n```\r\n-rw-r--r-- 1 web_server users 85M 5\u6708   2 14:54 saved_model.pb\r\ndrwxr-xr-x 2 web_server users   6 5\u6708   2 14:54 variables\r\n```\r\nAnd the folder \"varibales\" is actually empty. This is different from normal saved_models that generated from the original model:\r\n```\r\n-rw-r--r-- 1 web_server users      1.8M 4\u6708  16 17:09 saved_model.pb\r\ndrwxr-xr-x 2 web_server users        66 4\u6708  17 17:08 variables\r\n```\r\nAnd in ./variables/*\r\n```\r\n-rw-r--r-- 1 web_server users 95M 4\u6708  16 18:57 variables.data-00000-of-00001\r\n-rw-r--r-- 1 web_server users 17K 4\u6708  16 18:57 variables.index\r\n```\r\n\r\nI'm not quite familiar with the saved_model mechanism, but I suggests this difference comes from the source model is a TRT optimized frozen model, but not the original one.\r\n\r\nHowever, seems that saved_model loader is unable to load this \"saved_model\" in this format. \r\n\r\nLet me share the log:\r\n```\r\n2018-05-03 11:10:03.502930: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-05-03 11:10:04.112785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-05-03 11:10:04.113087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \r\nname: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\r\npciBusID: 0000:00:08.0\r\ntotalMemory: 7.43GiB freeMemory: 7.31GiB\r\n2018-05-03 11:10:04.113124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n2018-05-03 11:10:04.566803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-03 11:10:04.566852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n2018-05-03 11:10:04.566861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n2018-05-03 11:10:04.567079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3805 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:08.0, compute capability: 6.1)\r\n2018-05-03 11:10:06.909755: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at save_restore_tensor.cc:170 : Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./fs2/variables/variables\r\nTraceback (most recent call last):\r\n  File \"trt_run_saved.py\", line 115, in <module>\r\n    _main()\r\n  File \"trt_run_saved.py\", line 103, in _main\r\n    tf.saved_model.loader.load(sess, ['serve'], './fs2')\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 229, in load\r\n    saver.restore(sess, variables_path)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1775, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1140, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    run_metadata)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./fs2/variables/variables\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_306_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op u'save/RestoreV2', defined at:\r\n  File \"trt_run_saved.py\", line 115, in <module>\r\n    _main()\r\n  File \"trt_run_saved.py\", line 103, in _main\r\n    tf.saved_model.loader.load(sess, ['serve'], './fs2')\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 219, in load\r\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1933, in import_meta_graph\r\n    return Saver()\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\r\n    self.build()\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 448, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 860, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1458, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./fs2/variables/variables\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_306_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n```\r\n\r\nThanks,\r\n", "@oscarridle, when you freeze the graph you remove the Variable nodes from the graph so you can not save and restore variables with saved model at least not without changing graph and saver. I am not an expert but AFAIK saver can not save frozen graphs. If you want to serialize the converted model you need to save it as graph_def. Please take a look at the tensorrt example in model zoo or the https://devblogs.nvidia.com/tensorrt-integration-speeds-tensorflow-inference/ on how to  serialize converted graph.", "@samikama \r\nThanks for your reply. That makes sense, so I think it's time to make a conclusion. \r\n\r\n1. TRT optimization engine can only support the graph def that gained from frozen model. Saved_model cannot be directly loaded and optimized. \r\n2. The procedure restore a frozen model, then TRT optimize it, and then save it to saved_model is not feasible.\r\n3. Then I tried to restore previously trained frozen model, then TRT optimize it, and then export the optimized graph to a new frozen model. And the new one can be successfully restored and executed. This procedure is OK, though my online Tensorflow serving environment need to be recompiled from utilizing saved_model to frozen_model.\r\n\r\nThanks for your help and patience.\r\nCheers~", "@oscarriddle how to export the optimized graph using TRT to a new forzen model ? From my point of view ,the optimized graph is already a frozen graph . ", "@caibobit yep, it is already a frozen graph so you can export it to file in regular way. The nodes of the new frozen model will be replaced by TRTEngineOp.", "@oscarriddle i tried your solution\uff0cand use the mnist to test ,but the tensorflow_serving can't recognize the forzen graph ,and the error occurs, the following  is the logs:\r\n```shell\r\n2018-07-05 18:57:34.846301: I tensorflow_serving/model_servers/main.cc:153] Building single TensorFlow model file config:  model_name: mnist model_base_path: /home/caibo/tmp/mnist_model\r\n2018-07-05 18:57:34.846479: I tensorflow_serving/model_servers/server_core.cc:459] Adding/updating models.\r\n2018-07-05 18:57:34.846504: I tensorflow_serving/model_servers/server_core.cc:514]  (Re-)adding model: mnist\r\n2018-07-05 18:57:34.946753: I tensorflow_serving/core/basic_manager.cc:716] Successfully reserved resources to load servable {name: mnist version: 5}\r\n2018-07-05 18:57:34.946784: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: mnist version: 5}\r\n2018-07-05 18:57:34.946799: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: mnist version: 5}\r\n2018-07-05 18:57:34.946819: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /home/caibo/tmp/mnist_model/5\r\n2018-07-05 18:57:34.946837: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { serve }; from: /home/caibo/tmp/mnist_model/5\r\n2018-07-05 18:57:34.946953: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { serve }; Status: fail. Took 113 microseconds.\r\n2018-07-05 18:57:34.946973: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: mnist version: 5} failed: Not found: Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\r\n```\r\n----------------------------------------------------------------\r\n```shell\r\ncaibo@ubuntu:~/PycharmProjects/untitled1/my/output$ ls\r\nfrozen_graph.pb  log.txt  trt_mnist_fp16.pb  trt_mnist_fp32.pb\r\n```\r\nand also i convert the trt_graph to the saved_model.pb and put the into the model_base_path ,still the same error ,  that is \" could not find meta graph def matching supplied tags\"\r\n\r\ni wonder if  the way i bazel build the tensorflow serving is wrong , or something else.", "@oscarriddle sorry to misunderstand you . \r\nAs you say \"\r\nThen I tried to restore previously trained frozen model, then TRT optimize it, and then export the optimized graph to a new frozen model. And the new one can be successfully restored and executed. This procedure is OK, though my online Tensorflow serving environment need to be recompiled from utilizing saved_model to frozen_model.\"\r\nYou mean that we need to recomplie the tensorflow serving environment that can recognizes the frozen graph . Can you talk about the specific compilation steps? \r\nThanks ~ ", "@caibobit \r\nFirst of all, I think you need to clarify the difference between frozen model and the saved_model. They are almost the same but saved_model provided signatureDef that you need to take care.\r\n\r\nWhen you export a saved model, it requires to set a tag for signaturedef, and later when you load it, you have to specify the tag. From your log, I think you can check the tag of your saved model, by using saved_model_cli:\r\n```\r\n2018-07-05 18:57:34.946953: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { serve }; Status: fail. Took 113 microseconds.\r\n2018-07-05 18:57:34.946973: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: mnist version: 5} failed: Not found: Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\r\n```\r\nFor the second, the c++ tensorflow shall already support loading serialized model, you can check this: [https://medium.com/jim-fleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f](url)\r\n\r\nThe frozen model can be converted to saved model and vice versa, because they are both serialized ones.\r\n\r\nThanks,", "@oscarriddle \r\nI referenced the build process in the official [dockerfile](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile.devel-gpu) and successfully compiled tf_serving, tensorrt, and cuda together. The original tf_serving is inferred on the CPU. In this way, it can be inferred on the GPU. Whether multi-machine multi-card can be inferred is still under study.\r\nThanks\r\n", "thank ", "@oscarriddle Hi. I just wonder how did your tensorflow serving load frozen model ? It seems that TensorRT could only optimize frozen model to frozen model. Did you recompile your serving to support tensorRT or do something to transfer frozen model to saved model?\r\nThanks.", "@elvys-zhang \r\nHave you known how to export a savedModel for tf-serving?\r\nI have the same question.", "> @oscarriddle\uff0c\u9057\u61be\u7684\u662f\u8fd9\u5bf9\u6211\u4eec\u6765\u8bf4\u662f\u4e00\u4ef6\u9ebb\u70e6\u4e8b\uff0c\u6211\u4eec\u5c06\u5728TRT4.0\u53d1\u5e03\u65f6\u5bf9\u5176\u8fdb\u884c\u5904\u7406\u3002\u8fd9\u662f\u7531\u4e8eTRT3\u548cTF\u4e4b\u95f4\u7684\u5185\u5b58\u5206\u914d\u4e0d\u517c\u5bb9\u800c\u53d1\u751f\u7684\u3002\u4e3a\u4e86\u89e3\u51b3\u5b83\uff0c\u4f60\u9700\u8981\u544a\u8bc9TF\u4e3aTRT\u7559\u4e0b\u4e00\u4e9b\u5185\u5b58\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u5c06GPUOptions\u4f20\u9012\u7ed9\u4f1a\u8bdd\u914d\u7f6e\u6765\u5b8c\u6210\u6b64\u64cd\u4f5c\uff0c\u5982\u4e0b\u6240\u793a\u3002\u4f46\u7531\u4e8eTF\u5206\u914d\u7b56\u7565\u5b9a\u4e49\u4e86\u7b2c\u4e00\u6b21\u8c03\u7528\u65f6\u5206\u914d\u7684\u5185\u5b58\u91cf\uff0c\u56e0\u6b64\u5fc5\u987b\u786e\u4fdd\u5728\u7b2c\u4e00\u6b21\u4f1a\u8bdd\u8c03\u7528\u65f6\u8bbe\u7f6e\u5185\u5b58\u5206\u6570\u3002\u5728\u505a\u5176\u4ed6\u4efb\u4f55\u4e8b\u60c5\u4e4b\u524d\uff0c\u6211\u5efa\u8bae\u4f60\u5728\u5bfc\u5165tensorflow\u540e\u7acb\u5373\u521b\u5efa\u4e00\u4e2a\u6ca1\u6709\u4efb\u4f55\u56fe\u5f62\u6216\u865a\u62df\u4f1a\u8bdd\u7684\u865a\u62df\u4f1a\u8bdd\u3002\u5f53\u7136\uff0c\u60a8\u5fc5\u987b\u8c03\u6574\u5206\u6570\u4ee5\u9002\u5e94\u60a8\u5728\u8f6c\u6362\u8c03\u7528\u671f\u95f4\u4f20\u9012\u7ed9TensorRT\u7684\u6a21\u578b\u548c\u5185\u5b58\u5927\u5c0f\u3002\r\n> \r\n> ```python\r\n>   sess = tf.Session\uff08config = tf.ConfigProto\uff08gpu_options = tf.GPUOptions\uff08per_process_gpu_memory_fraction = 0.50\uff09\uff09\uff09\r\n> ```\r\n> \r\n> \u5982\u679c\u8fd9\u6709\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002\r\n\r\n\r\nUse the method you provide,I succeeded in solving it.\r\nthankyou,verymuch!!\r\n\r\n\r\n\r\n"]}, {"number": 18993, "title": "Why not support passing extras tensors from input_fn to model_fn in estimator?", "body": "Sometimes input_fn may create some tensors that are useful in model_fn, these tensors can't be create outside input_fn to ensure they are in the same graph as tensors in models. \r\n\r\nIt seems that we can put those tensors to 'labels' returned by input_fn, but because these tensors are same across batch samples, so it will cause problems when we use replicate_model_fn. (replicate_model_fn will split each tensors in 'features' or 'labels' to each GPU, but those tensors stay same across all batch samples )", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18992, "title": "fix cmake windows py27 import fail", "body": "fix cmake windows py27 import fail", "comments": ["Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @protoget: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @protoget: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @protoget: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "update to 1.9.0, please review.", "Nagging Assignee @protoget: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18991, "title": "fix cmake windows py27 import fail", "body": "fix cmake windows py27 import fail", "comments": []}, {"number": 18990, "title": "Is the expected_shape argument of tf.Variable still useable/useful?", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nInstalled with Anaconda\r\n- **TensorFlow version (use command below)**:\r\nb'v1.8.0-0-g93bc2e2072' 1.8.0\r\n- **Python version**: \r\n3.6.5\r\n\r\nI know this might be a small docs fix which doesn't fit the issue policy. But I'm not sure and I don't really know how to fix it. I'm sorry. But it seems that the `expected_shape` argument of `tf.Variable` has been deprecated for a long time (since v1.0.0). Is it still useable/useful? Is there a reason [it is still in the documentation](https://www.tensorflow.org/api_docs/python/tf/Variable#__init__)?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/8753e2ebde6c58b56675cc19ab7ff83072824a62/tensorflow/python/ops/variables.py#L284", "comments": ["It's not yet deprecated in the latest released version, which is what docs point to\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/variables.py\r\n\r\nThe code you point to is from master, so this change will make its way to official docs once it's part of a release\r\n\r\n", "@yaroslavvb Thank you for confirming the deprecation. It's really helpful in clarifying a few confusing problems.\r\n\r\nIf I understand the code correctly, the constructor of `tf.Variable` pretty much passes everything, including `expected_shape`, to the protected method `_init_from_args`, which has deprecated `expected_shape` in the code (line 298 of your link) as well as documenting it as deprecated (line 284 of your link). I do understand it is better to use `tf.get_variable` whenever it's possible. However, it can be confusing when people actually use `tf.Variable`, as reported both here, #18653, and on [stackoverflow](https://stackoverflow.com/questions/50103262/tensorflow-tf-variable-initialize-shape-bug). I just want to kindly point it out in case you guys forget about it since this has been the case (doc'ed in `tf.Variable` while actually deprecated in `_init_from_args`) since v1.0.0.\r\n\r\nThank you all again for building and opening this great tool!", "Documentation is automatically generated from source code, so it will automatically be updated at next release", "@yaroslavvb Thanks. I'll close this issue now. \r\n\r\nJust to clarify, it's not yet documented as deprecated in master (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variables.py#L187-L188) as for now."]}, {"number": 18989, "title": "Grammar fixes in BENCHMARKS.md", "body": "", "comments": ["The CI build fail is in regards to //tensorflow/contrib/opt:model_average_optimizer_test, which is not related to this documentation fix at all."]}, {"number": 18988, "title": "Tensorflow input pipeline & performance - images - memory", "body": "Best,\r\n\r\n# system properties:\r\n\r\n- windows 10\r\n- intel core i7-6820HQ CPU | 2.70GHZ 8CPUs\r\n- 16GB ram\r\n- 64bit \r\n- NVIDIA Quadro M1000M\r\n   - approx. total memory: 10093 MB\r\n   - Display memory (VRAM): 2019 MB\r\n   - Shared Memory: 8073 MB\r\n \r\n- Tensorflow 1.8\r\n- Python 3.5.2\r\n \r\n- images (i've 36k images):\r\n   - train: 3000 x (720x1280x3)\r\n   - valid: 500 x (720x1280x3)\r\n   - test : 500 x (720x1280x3)\r\n\r\n \r\n### My story & strugles\r\nFirst of all, I would like to say that I really like machine learning, specially neural networks. But most of the time, when I'm working with Tensorflow, I've the feeling that it is backstabbing me the entirely time. (like for example, the speed of those releases... (1.8 :O )) & Sometimes I even don't know any more if I'm doing it right or wrong? (Or can I do it better?)\r\n\r\nTherefore, my main question is: **How do you create a proper input pipeline!**\r\npreferable with tensorflow gpu\r\n\r\nBecause come one, it should be easy as $*%\u20ack no? Especially, **can't you cover 90% of all the input pipelines into 1, 2 or 3 template pipelines?** (I think it is +/- possible, (a giant image with a cat is still an image | matrix))\r\nand if it is possible, why can't we have an optimized template/base for it?\r\n\r\n\r\nas you would have noticed, I've provided my system properties and info about the data which I'm using. My goals are:\r\n\r\n - Create a GAN-network (GPU)(doesn't have to be a gan for this question)\r\n - Use the TF-estimator api (with custom features)\r\n - Use TF-records !\r\n - Use TF-dataset !\r\n\r\nBut Unfortunately, most of the time, I'll receive errors like for example that I'm out of memory :'(\r\nAnd the more I look things up, the more I start to hesitate...\r\n\r\n\r\n## Step 1: create TF-records\r\nIn my first step, I create a tf-record (train). And as you can see, I loop over the images (from a certain folder) and write all the data into 1 tf-record.\r\n```python \r\n# Helper-function for wrapping an integer so it can be saved to the TFRecords file\r\ndef wrap_int64(value):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n\r\n# Helper-function for wrapping raw bytes so they can be saved to the TFRecords file.\r\n\r\ndef wrap_bytes(value):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\n\r\n#from skimage.transform import rescale, resize, downscale_local_mean\r\n\r\ndef convert(image_paths, out_path):\r\n    # Args:\r\n    # image_paths   List of file-paths for the images.\r\n    # labels        Class-labels for the images.\r\n    # out_path      File-path for the TFRecords output file.\r\n\r\n    print(\"Converting: \" + out_path)\r\n\r\n    # Number of images. Used when printing the progress.\r\n    num_images = len(image_paths)\r\n\r\n    # Open a TFRecordWriter for the output-file.\r\n    with tf.python_io.TFRecordWriter(out_path) as writer:\r\n\r\n        # Iterate over all the image-paths and class-labels.\r\n        for i, path in enumerate(image_paths):\r\n\r\n            # Print the percentage-progress.\r\n            print_progress(count=i+1, total=num_images)\r\n\r\n            # Load the image-file using matplotlib's imread function.\r\n            img_bytes_sharp = load_images(path)\r\n\r\n            # Convert the image to raw bytes.\r\n            img_bytes_sharp = tf.compat.as_bytes(img_bytes_sharp.tostring())\r\n\r\n            # Create a dict with the data we want to save in the\r\n            # TFRecords file. You can add more relevant data here.\r\n            data = \\\r\n                {\r\n                    'x': wrap_bytes(img_bytes_sharp)\r\n                }\r\n\r\n            # Wrap the data as TensorFlow Features.\r\n            feature = tf.train.Features(feature=data)\r\n\r\n            # Wrap again as a TensorFlow Example.\r\n            example = tf.train.Example(features=feature)\r\n\r\n            # Serialize the data.\r\n            serialized = example.SerializeToString()\r\n\r\n            # Write the serialized data to the TFRecords file.\r\n            writer.write(serialized)\r\n```\r\n\r\nabout the tf-record:\r\n- size: 6 GB\r\n- 3000 images\r\n- preprocessed:\r\n   - RGB values between: 0 and 1\r\n    - type: float32\r\n\r\n\r\n\r\n## Step 2: Load TF-records (parser)\r\n\r\n```python\r\ndef parse(serialized):\r\n    # Define a dict with the data-names and types we expect to\r\n    # find in the TFRecords file.\r\n    # It is a bit awkward that this needs to be specified again,\r\n    # because it could have been written in the header of the\r\n    # TFRecords file instead.\r\n    features = \\\r\n        {\r\n            'x': tf.FixedLenFeature([], tf.string)\r\n        }\r\n\r\n    # Parse the serialized data so we get a dict with our data.\r\n    parsed_example = tf.parse_single_example(serialized=serialized,\r\n                                             features=features)\r\n\r\n\r\n    # Decode the raw bytes so it becomes a tensor with type.\r\n    image_x = tf.decode_raw(parsed_example['x'], tf.float32)\r\n\r\n    # The type is now uint8 but we need it to be float.\r\n    #image_x = tf.cast(image_x, tf.float32)\r\n\r\n    return image_x\r\n```\r\n\r\n\r\n\r\n## Step 2+1: Load TF-records (for real)\r\n```python\r\ndef input_fn(filenames, train, batch_size=32, buffer_size=2048):\r\n    # Args:\r\n    # filenames:   Filenames for the TFRecords files.\r\n    # train:       Boolean whether training (True) or testing (False).\r\n    # batch_size:  Return batches of this size.\r\n    # buffer_size: Read buffers of this size. The random shuffling\r\n    #              is done on the buffer, so it must be big enough.\r\n\r\n    # Create a TensorFlow Dataset-object which has functionality\r\n    # for reading and shuffling data from TFRecords files.\r\n    dataset = tf.data.TFRecordDataset(filenames=filenames)\r\n\r\n    # Parse the serialized data in the TFRecords files.\r\n    # This returns TensorFlow tensors for the image and labels.\r\n    dataset = dataset.map(parse)\r\n\r\n    if train:\r\n        # If training then read a buffer of the given size and\r\n        # randomly shuffle it.\r\n        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n\r\n        # Allow infinite reading of the data.\r\n        num_repeat = None\r\n    else:\r\n        # If testing then don't shuffle the data.\r\n\r\n        # Only go through the data once.\r\n        num_repeat = 1\r\n\r\n    # Repeat the dataset the given number of times.\r\n    dataset = dataset.repeat(num_repeat)\r\n\r\n    # Get a batch of data with the given size.\r\n    dataset = dataset.batch(batch_size)\r\n\r\n    # Create an iterator for the dataset and the above modifications.\r\n    iterator = dataset.make_one_shot_iterator()\r\n\r\n    # Get the next batch of images and labels.\r\n    images_batch = iterator.get_next()\r\n\r\n    # The input-function must return a dict wrapping the images.\r\n    x = {'image': images_batch}\r\n\r\n    return x\r\n```\r\n\r\n\r\n\r\n# But but but but\r\nalthough, I think that the above set-up is quite clear, as soon as I get rid of the mnist dataset (32x32 images), I receive memory issues. (can't even perform a batch-size of 2)\r\n+ Also when I'm trying to solve this and watch/read the tensorflow summit videos (2018), I even wonder if I'm doing it correctly at the first place :s\r\n\r\nFor example:  \r\n![alt image from ppt summet](https://i.stack.imgur.com/OdHI0.png \"code\")\r\n\r\n\r\n1. First of all, how to deal with memory issues? I really can understand that I've a memory issue, when TF tries to store, the whole tf-record 6-7gig in its memory (video-card memory)? but I also would think that it is smarter then that ... (doesn't it work like a generator? add only x values in memory + their location)\r\n    1.1 I really would like to keep the tf-records because they promises us that it is faster then e.g. the placeholders (actually it is also easier to use)\r\n\r\n2. In the image, you see at the beginning: `Dataset.list_files` the question which I've with this is. Is this just 1 file, or does this mean that each image which I've is a **new** tf.record? (do I've) to create 3000 tf records?)(and is this the reason why I might have memory issues?)\r\n\r\n3. The image returns a dataset and not a iterator (like in my piece of code), any clue where they might do it (this is necessary right?), when they are using the tf-estimator api?\r\n\r\n\r\n\r\n\r\nAnd that is basically it.\r\n**underlying question i**s: How can I work & play with Tensorflow|tf-records|tf-estimator **on** _BIG_ images. (even bigger than 720p)\r\n\r\n\r\n_extra info:_\r\n(https://www.youtube.com/watch?v=SxOsJPaxHME https://www.tensorflow.org/versions/master/performance/datasets_performance)\r\n", "comments": ["@verbeemen Is using TF GPU your only option when you encounter memory limitation? https://www.tensorflow.org/performance/performance_guide may provide you some other options I guess :) ", "@wei-v-wang - mostly yes, when i downsize everything to black and white images, and size it to 32x32 pxls then I receive some results. But the thing is. I've the feeling that tensorflow is more like a bike from the IKEA, whereby you've too many spare parts. You can build a lot of things but actually you don't know if your basic bike can ride properly. \r\nWhat i'm really looking for is, a good (or even the best possible) template... (I even want to blog about it). But as it is, (And 1 month further), I can't find anything decent. 80% of the examples are based on mnist or 32x32 images, and the other 20% are snippets which will work in theory but they don't show you their actual setup.\r\nAnd I do like the estimator api and tf records, because it makes life easier, but when i want to upscale to larger images, i receive those struggles. And I also think that 720x1280 aren't the biggest  images.... \r\n+ I also don't really know what happens intern in tf_estimator. when does it uses the cpu and gpu?\r\nAnd what about those `Dataset.list_files()` - does this means that each images is an tf-records?\r\nbecause now I store my while training set in one big tf-record... ", "@verbeemen: You may want to check out [Mask RCNN](https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/config.py).  It uses 1024x1024 dim images.\r\n\r\nWith regard to when does `tf.estimator` use cpu vs gpu, you can always use [`log_device_placement=True`](https://www.tensorflow.org/programmers_guide/using_gpu).", "Nagging Assignee @tatianashp: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18987, "title": "Update xla README", "body": "Beef up the README a bit and add a logo", "comments": []}, {"number": 18986, "title": " Remove whitespace characters from tf_cuda_compute_capabilities user \u2026", "body": "\u2026string\r\n\r\nRemove all whitespace characters from the user specified tf_cuda_compute_capabilities string as this can results in errors during the split operation, and is easy for users to do as it is natural to insert a space after a comma", "comments": []}, {"number": 18985, "title": "No module named tensorFlow when trying to import it through Neptune", "body": "\r\n### System information\r\n- I am following the instructions found [here](https://blog.deepsense.ai/region-of-interest-pooling-in-tensorflow-example) in order to create a roi pooling using Neptune and tensorflow:\r\n-  Linux Ubuntu 16.04\r\n- **TensorFlow installed from** binary, using virtual environment\r\n- **TensorFlow version (use command below)**:1.7\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA\r\n- **GPU model and memory**: working with CPU\r\n- **Exact command to reproduce**: \r\n```neptune run             --parameter im_folder:$PWD/../data/images             --parameter roidb:$PWD/../data/roidb             --parameter pretrained_path:$PWD/../data/vgg16-20160129.tfmodel```\r\n\r\n\r\n### Describe the problem\r\n\r\nWhen trying to run the previous command, I get the `ImportError: No module named tensorflow` error while the environment is activated. If I try to import it with a  normal python command it works perfectly.\r\n\r\n\r\n### Source code / logs\r\n```\r\n(tensorflow3) ignacio@ignacio-Swift-SF314-52:~/Escritorio/nacho/AVIVA/roi-pooling/code$ neptune run             --parameter im_folder:$PWD/../data/images             --parameter roidb:$PWD/../data/roidb             --parameter pretrained_path:$PWD/../data/vgg16-20160129.tfmodel\r\n>\r\n> Experiment enqueued, id: SAN-43\r\n>\r\n> To browse the experiment, follow:\r\n> https://app.neptune.ml/dashboard/experiment/d28dc701-8477-4dee-9281-def81feddc8f?getStartedState=folded\r\n>\r\n\r\nCalculated experiment snapshot size: 44.82 kB   \r\nSending sources to server: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44.8k/44.8k [00:00<00:00, 170kB/s]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/deepsense/neptune/job_wrapper.py\", line 107, in <module>\r\n    execute()\r\n  File \"/usr/local/lib/python2.7/dist-packages/deepsense/neptune/job_wrapper.py\", line 103, in execute\r\n    execfile(job_filepath, job_globals)\r\n  File \"main.py\", line 4, in <module>\r\n    from trainer import Trainer\r\n  File \"trainer.py\", line 8, in <module>\r\n    import tensorflow as tf\r\nImportError: No module named tensorflow\r\nCalculated experiment snapshot size: 0 Bytes   \r\nProcess exited with return code 1.\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution", "Hi, I have updated the issue. Thanks!", "Any hints? I tried also with the native pip installation but I get the same output", "Nagging Assignee @tatatodd: It has been 22 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 36 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 51 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 66 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 81 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 96 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}]