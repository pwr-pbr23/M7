[{"number": 33104, "title": "Prediction on batch values vary with batch size.", "body": "When I predict on batches, e.g. with *predict_on_batch()*, I get different predictions depending on the batch size I am using. The differnce is sometimes as early as on the 4th digit. At first I thought it was due to batch normalization, but then I tried with pretrained VGG16 which I believe do not include batch normalization. This holds on all system settings I have tired:\r\n\r\nUbuntu and Windows\r\nTF 1.1, 1.4 and 2.0\r\nPre-trained on Imagenet and trained from scratch Inception V3\r\nPre-trained on Imagenet VGG16 (code bellow)\r\npredict_on_batch(), flow_from_directory(), and flow_from_dataframe()\r\n\r\nSince it is constistent on all systems I guess it is not a bug but a known artefact of TF. I have Googled och searched the repository but not found out why this happens.\r\n\r\n```{python}\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.applications.VGG16(input_shape=(224, 224, 3),\r\n                                    include_top=True,\r\n                                    weights='imagenet')\r\n\r\npath = \"path_to_some_image\"  # Use any image you got.\r\nimg = tf.keras.preprocessing.image.load_img(path, target_size=(224, 224))\r\n\r\nbatch_size = 32  # Changing this to, say, 3 gives different predictions.\r\nbatch_holder = np.zeros((batch_size, 224, 224, 3))\r\nfor i in range(batch_size):\r\n    batch_holder[i] = img\r\n\r\npredictions = model.predict_on_batch(batch_holder)\r\nprint(predictions[:, 0])\r\n```\r\n", "comments": ["In addition, there is inconsistency within a batch even if it is full. For example having a batch size of 31 with 31 identical images will give a different result on the last prediction in the batch. Or having a batch size of 31 with 32 identical images will give different results on the two last predictions. Here is some sample code to reproduce the error. I did this on windows with tf 1.11, but it is still there for 1.14 and 2.0 as well, like @PeterStrom pointed out. \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport shutil\r\nimport os\r\n\r\nmodel = tf.keras.applications.VGG16(input_shape=(224, 224, 3),\r\n                                    include_top=True,\r\n                                    weights='imagenet')\r\n\r\npath = \"path_to_img\"  # Use any image you got.\r\n\r\n# Create file structure needed for flow_from_directory() and copy image many times.\r\ntmp_dir = os.path.join(os.getcwd(),\"tempdir\")\r\ntmp_sub_dir = os.path.join(tmp_dir,\"subdir\")\r\n\r\nif not os.path.isdir(tmp_dir):\r\n    os.mkdir(tmp_dir)\r\nif not os.path.isdir(tmp_sub_dir):\r\n    os.mkdir(tmp_sub_dir)\r\n\r\n_, img_ext = os.path.splitext(path)\r\n\r\nnum_copies=31 #32\r\nfor i in range(num_copies):\r\n    shutil.copyfile(path,os.path.join(tmp_sub_dir,\"copy\"+str(i)+img_ext))\r\n\r\n\r\n# Predict using flow_from_directory and print result\r\nimage_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n\r\nbatch_size = 31\r\nimg_generator = image_data_generator.flow_from_directory(tmp_dir,target_size=(224,224),batch_size=batch_size)\r\n\r\npredictions = model.predict_generator(img_generator,steps=len(img_generator.filenames)/batch_size)\r\nprint(predictions[:, 0])\r\n#shutil.rmtree(tmp_sub_dir)\r\n```", "Could reproduce it with TF Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/78927f8c619a6e62beffd9e5697987ca/33104.ipynb). Thanks!", "@PeterStrom I can reproduce the issue but the change is only in 13th digit. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/4f0e6a1dea8e3ba43d3d36462b98653f/untitled598.ipynb). I have tried with different batch size also. Thanks!", "@eobw Similarly, I can reproduce the issue but the change is only in 10th digit. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/b8f0239c589f923af5cb2f5685eb60d8/33104.ipynb). I am trying to understand, are you looking for even higher precision? Thanks!", "I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33104\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33104\">No</a>\n", "I had the same issue and I think it's connected to the GPU's non-determinism - on the CPU the results were identical, on the GPU (RTX 2080Ti and RTX 3090) they were not. I couldn't solve it (using deterministic options for GPU didn't work).", "Same as @e-dzia, on CPU the results were identical, but on GPU there were huge variations (3rd digit). "]}, {"number": 33103, "title": "TPU, model.fit : 2GB of RAM limit", "body": "\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThere is an error (\"Session is not found\"), when trying to use a dataset with the size more than 2GB of RAM.\r\nError is reproducible for different step size (256,1024,8192).\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error when feeding a dataset which is more than 2GB of RAM.\r\n\r\n**Code to reproduce the issue**\r\n\r\nTo reproduce, just copy the following code to Colab with TPU enabled.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nimport distutils\r\nif distutils.version.LooseVersion(tf.__version__) < '1.14':\r\n    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\r\n\r\nimport os\r\n\r\nresolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.contrib.distribute.initialize_tpu_system(resolver)\r\nstrategy = tf.contrib.distribute.TPUStrategy(resolver)\r\n\r\noptimizer = tf.contrib.tpu.CrossShardOptimizer(tf.train.GradientDescentOptimizer(0.01))\r\n\r\nwith strategy.scope():\r\n  model = tf.keras.applications.VGG16(input_shape=(32,32,3),classes=10, weights=None)#  create_model()\r\n  model.compile(\r\n      optimizer=optimizer,\r\n      loss='mse',\r\n      metrics=['mse'])\r\n\r\n# 1024*192 * 32*32*3 * 4bytes = 2 415 919 104 bytes\r\nX = np.zeros((1024*192, 32,32,3),dtype=np.float32)\r\ny = np.ones((1024*192, 10),dtype=np.float32)\r\n\r\nmodel.fit(\r\n    X,y,\r\n    epochs=10,\r\n    steps_per_epoch=1024, #batch size is 192 per TPU\r\n)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nAbortedError                              Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1355     try:\r\n-> 1356       return fn(*args)\r\n   1357     except errors.OpError as e:\r\n\r\n13 frames\r\n\r\nAbortedError: Session 14acf315e768e91c is not found.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAbortedError                              Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1368           pass\r\n   1369       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1370       raise type(e)(node_def, op, message)\r\n   1371 \r\n   1372   def _extend_graph(self):\r\n\r\nAbortedError: Session 14acf315e768e91c is not found.\r\n```\r\n\r\n```\r\nprint(tf.GIT_VERSION)\r\nv1.14.0-0-g87989f6959\r\nprint(tf.VERSION)\r\n1.14.0\r\n```", "comments": ["Could reproduce the error in Google Colab with Runtime as TPU and TF Version 1.14. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/8ae1e4821a6cfbd56c9f408427f4cccb/33103.ipynb).", "The bug can happen due to 2GB limit in protobuf (since tensorflow relies on it).\r\nhttps://stackoverflow.com/questions/34128872/google-protobuf-maximum-size", "Yes, you'll likely have to switch to tf.data inputs if you have that large of datasets.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "The error still persists. I changed the code to work on 2.x version. 2GB is still a limit.\r\nAttached a screenshot of Colab logs.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nimport distutils\r\nif distutils.version.LooseVersion(tf.__version__) < '1.14':\r\n    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\r\n\r\nimport os\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\n# This is the TPU initialization code that has to be at the beginning.\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n\r\n# optimizer = tf.tpu.CrossShardOptimizer(tf.train.GradientDescentOptimizer(0.01))\r\n\r\nstrategy = tf.distribute.TPUStrategy(resolver)\r\n\r\nwith strategy.scope():\r\n  model = tf.keras.applications.VGG16(input_shape=(32,32,3),classes=10, weights=None)#  create_model()\r\n  optimizer = tf.keras.optimizers.Adam()\r\n  model.compile(\r\n      optimizer=optimizer,\r\n      loss='mse',\r\n      metrics=['mse'])\r\n  \r\n  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\r\n  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\r\n      'training_accuracy', dtype=tf.float32)\r\n\r\n# with strategy.scope():\r\n\r\n\r\n# 1024*192 * 32*32*3 * 4bytes = 2 415 919 104 bytes\r\n# ~ 2GB. \"Session crashed for unknown reason\"\r\nX = np.zeros((1024*192, 32,32,3),dtype=np.float32)\r\ny = np.ones((1024*192, 10),dtype=np.float32)\r\n\r\n# ~ 1GB. Works\r\n# X = np.zeros((1024*192//2, 32,32,3),dtype=np.float32)\r\n# y = np.ones((1024*192//2, 10),dtype=np.float32)\r\n\r\nmodel.fit(\r\n    X,y,\r\n    epochs=10,\r\n    steps_per_epoch=1024, #batch size is 192 per TPU\r\n)\r\n```\r\n![screen](https://user-images.githubusercontent.com/27484172/106828116-a4958500-66dd-11eb-9ae6-06606e561bc4.PNG)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33103\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33103\">No</a>\n"]}, {"number": 33102, "title": "How can I update my existing tensorflow to 2.0?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:1.13.0-rc2 --->2.0\r\n- Python version:3.7.1\r\n- Installed using virtualenv? pip? conda?:pip/conda\r\n- Bazel version (if compiling from source):\\\r\n- GCC/Compiler version (if compiling from source):\\\r\n- CUDA/cuDNN version:\\\r\n- GPU model and memory:\\\r\n\r\n\r\n\r\n**Describe the problem**\r\n \r\nWell, I have installed the tensorflow 1.13 before, and since the newest version 2.0 is open, I wanna to update my old tf to the new one, but I do not know how to do it stably. \r\nCan you help me?\r\nVery THX! :)\r\n\r\n", "comments": ["You should be able to simply `pip install --user tensorflow==2.0.0` (or `tensorflow-gpu==2.0.0`).\r\n\r\nThat being said, if you have some code depending on the former TF1.13 version, you might not want to wipe the latter out entirely. It may therefore be useful to set up a virtual environment (`python3 -m venv your_venv_path`), activate it (`source your_venv_path/bin/activate`) and then pip install any version of tensorflow within this environment. This way you can have multiple TF versions on your computer, and use whichever is suited for you current project by switching between venvs.", "Thank you @pandrey-fr for pitching in. \r\n@AllenWu18,\r\nCan you please let us know if @pandrey-fr's comment has helped you. Thanks!  ", "You can also see the [`tf_upgrade_v2` script](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility) to upgrade existing code", "OK I'll have a try under the advice of @pandrey-fr, and I wanna to build a virtual python environment firstly. Should I build it in the Anaconda environment?", "> You can also see the [`tf_upgrade_v2` script](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility) to upgrade existing code\r\n\r\nMost of my code was written under Keras, and I want to know has Keras been updated at the same time the TF 2.0 was opened??", "> Most of my code was written under Keras, and I want to know has Keras been updated at the same time the TF 2.0 was opened??\r\n\r\nIn 2.0, tensorflow embarks an implementation of the keras API under the `tensorflow.keras` submodule, thus you no longer need to use the separate keras package, and should simply adjust your code to use the embarked API.\r\n\r\n> I wanna to build a virtual python environment firstly. Should I build it in the Anaconda environment?\r\nYou can either use `conda` or `venv` (or other virtual environment management tools) to create your virtual environment. If you usually use anaconda to install packages, using it to manage virtual environments seems logical ; at any rate, do not mix the ways you manage your environments and pacakge, otherwise it may be hard to keep track of what is installed where :-)", "@AllenWu18, Follow these steps to install tensorflow 2.0 with PIP virtualenv\r\n```\r\n$pip install virtualenv\r\n$virtualenv tf_2.0.0   # tf_2.0.0 is virtual env name\r\n$source tf_2.0.0/bin/activate\r\ntf_2.0.0 $ pip install tensorflow==2.0.0\r\n\r\n```", "@AllenWu18, Is this still an issue? Thanks", "Sorry I forgot to reply.It works. Thank you very much!\n:)\n\n\n| |\nallenwu18\n\u90ae\u7bb1\uff1aallenwu18@163.com\n|\n\nSignature is customized by Netease Mail Master\n\nOn 10/24/2019 17:30, gadagashwini wrote:\n\n@AllenWu18, Is this still an issue? Thanks\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or unsubscribe.", "Thank you. closing", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33102\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33102\">No</a>\n", "You can also follow these steps to install tensorflow2.0 (GPU version) for conda environment.\r\n\r\n```\r\n$conda create -n new_tf2_env python=3.7\r\n$conda activate new_tf2_env\r\n$pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190526\r\n```"]}, {"number": 33101, "title": "TF2.0: tf.print doesn't work in tensorflow keras", "body": "System information\r\n\r\nOS Platform and Distribution\r\nMac os (10.14.6)\r\nTensorFlow installed from (source or binary):\r\nbinary\r\nTensorFlow version (use command below):\r\n2.0.0rc1\r\nPython version:\r\nPython 3.6.4\r\n\r\nI want to print intermediate tensor in model constructed by tensorflow keras functional api, but i got error.  code bellows\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninputs = keras.Input(shape=(128,), name='digits')\r\nx = layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\nx = layers.Dense(64, activation='relu', name='dense_2')(x)\r\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\ntf.print(\"outputs\",outputs)\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n\r\nmodel.compile(optimizer=keras.optimizers.RMSprop(),loss=keras.losses.SparseCategoricalCrossentropy())\r\n\r\nx_train = np.random.random_sample((100,128))\r\ny_train = np.random.randint(0,10, (100,))\r\nmodel.fit(x_train, y_train,epochs=10)\r\n```\r\nerror informations bellows:\r\n\r\n```\r\n_FallbackException                        Traceback (most recent call last)\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_string_ops.py in string_format(inputs, template, placeholder, summarize, name)\r\n    810         \"template\", template, \"placeholder\", placeholder, \"summarize\",\r\n--> 811         summarize)\r\n    812       return _result\r\n\r\n_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-106-84d972d9b93b> in <module>\r\n      3 x = layers.Dense(64, activation='relu', name='dense_2')(x)\r\n      4 outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\n----> 5 tf.print(\"x_train\",outputs)\r\n      6 x = keras.backend.print_tensor(outputs, 'outputs')\r\n      7 # tf.Print(\"x_train\",x)\r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/logging_ops.py in print_v2(*inputs, **kwargs)\r\n    371         placeholder=placeholder,\r\n    372         summarize=summarize,\r\n--> 373         name=format_name)\r\n    374 \r\n    375   if compat.forward_compatible(2019, 5, 27):\r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/string_ops.py in string_format(template, inputs, placeholder, summarize, name)\r\n    190                                       placeholder=placeholder,\r\n    191                                       summarize=summarize,\r\n--> 192                                       name=name)\r\n    193 \r\n    194 \r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_string_ops.py in string_format(inputs, template, placeholder, summarize, name)\r\n    815         return string_format_eager_fallback(\r\n    816             inputs, template=template, placeholder=placeholder,\r\n--> 817             summarize=summarize, name=name, ctx=_ctx)\r\n    818       except _core._SymbolicException:\r\n    819         pass  # Add nodes to the TensorFlow graph.\r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_string_ops.py in string_format_eager_fallback(inputs, template, placeholder, summarize, name, ctx)\r\n    869     summarize = 3\r\n    870   summarize = _execute.make_int(summarize, \"summarize\")\r\n--> 871   _attr_T, inputs = _execute.convert_to_mixed_eager_tensors(inputs, _ctx)\r\n    872   _inputs_flat = list(inputs)\r\n    873   _attrs = (\"T\", _attr_T, \"template\", template, \"placeholder\", placeholder,\r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in convert_to_mixed_eager_tensors(values, ctx)\r\n    275 def convert_to_mixed_eager_tensors(values, ctx):\r\n    276   v = [ops.internal_convert_to_tensor(t, ctx=ctx) for t in values]\r\n--> 277   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access\r\n    278   return types, v\r\n    279 \r\n\r\n~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in <listcomp>(.0)\r\n    275 def convert_to_mixed_eager_tensors(values, ctx):\r\n    276   v = [ops.internal_convert_to_tensor(t, ctx=ctx) for t in values]\r\n--> 277   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access\r\n    278   return types, v\r\n    279 \r\n\r\nAttributeError: 'Tensor' object has no attribute '_datatype_enum'\r\n```\r\n\r\n", "comments": ["@payne4handsome,\r\nFrom the explanation provided below in [this link](https://www.tensorflow.org/api_docs/python/tf/print), `tf.print` prints `Printable Python Objects` and I am not sure if Layers object falls under that category.\r\n\r\n> *inputs: Positional arguments that are the inputs to print. Inputs in the printed output will be separated by spaces. Inputs may be python primitives, tensors, data structures such as dicts and lists that may contain tensors (with the data structures possibly nested in arbitrary ways), and printable python objects. \r\n\r\nIt works properly if we try printing Tensors. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/1e4ddf426822dd37ef318f81eb327515/33101.ipynb).\r\n\r\n", "@rmothukuru I know how to print tensors. My really question is how to print intermediate tensor in model constructed by tensorflow keras functional api. My real intention is to print **outputs object** when the model iterates that at below codes. I hope the model is iterated once and the intermediate value is printed once(just like bellow code tf.print(\"outputs\",outputs) )\r\n\r\n```\r\ninputs = keras.Input(shape=(128,), name='digits')\r\nx = layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\nx = layers.Dense(64, activation='relu', name='dense_2')(x)\r\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\ntf.print(\"outputs\",outputs)\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n```", "Could reproduce this issue with Tensorflow Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/ad3918cd8c445472e631ec21840c6dbc/33101.ipynb). Thanks!", "Is there any solution for the issue?", "@payne4handsome It clearly shows the error `_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.`. This requires input to be one of the following as mentioned in [TF website](https://www.tensorflow.org/api_docs/python/tf/print).\r\n\r\n>  Positional arguments that are the inputs to print. Inputs in the printed output will be separated by spaces. Inputs may be python primitives, tensors, data structures such as dicts and lists that may contain tensors (with the data structures possibly nested in arbitrary ways), and printable python objects.\r\n\r\nCurrently, you are providing a graph tensor. Please close the issue if it is resolved. Thanks!", "I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!", "Wrap the `tf.print()` in a Lambda layer (works on tf 2.x)\r\n\r\nExample:\r\n```\r\n    def log_pre_softmax(x):\r\n        tf.print(\"Pre softmax, min/max\", tf.reduce_min(x),tf.reduce_max(x))\r\n        tf.debugging.check_numerics(x,\"Nan in pre softmax\")\r\n        return x\r\n\r\n    o = layers.Conv2D(num_classes, 1, padding=\"same\")(o)\r\n    o = layers.Lambda(log_pre_softmax)(o)\r\n    o = layers.Softmax(axis=-1, dtype='float32', name='predictions')(o)\r\n```"]}, {"number": 33100, "title": "Error saving Keras optimizer, TensorFlow 2.0", "body": "[Related](https://github.com/keras-team/keras/issues/13402), minimal reproducible example below. Opened a [PR](https://github.com/tensorflow/tensorflow/pull/33097), but doesn't fix this problem.\r\n\r\n<hr>\r\n\r\n**DOESN'T WORK:**\r\n\r\n```python\r\nfrom tensorflow.python.keras.layers import Input, Dense\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.optimizers import Nadam # [3]\r\n\r\nimport numpy as np\r\nipt = Input(shape=(4,))\r\nout = Dense(1, activation='sigmoid')(ipt)\r\n\r\nmodel = Model(ipt, out)\r\nmodel.compile(optimizer=Nadam(lr=1e-4), loss='binary_crossentropy')\r\n\r\nX = np.random.randn(32,4)\r\nY = np.random.randint(0,2,(32,1))\r\nmodel.train_on_batch(X,Y)\r\n\r\nmodelpath = \"folder/model.h5\"\r\nmodel.save(modelpath)\r\n```\r\n\r\n<hr>\r\n\r\n**WORKS**:  remove `.python` from above's imports, OR, `model.save(.., include_optimizer=False)`. Also works if `.python` is removed only from import `# [3]`.\r\n\r\n<hr>\r\n\r\n**Full error trace**:\r\n\r\n```python\r\n\r\n  File \"<ipython-input-1-fedd4f332165>\", line 23, in <module>\r\n    model.save(modelpath)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 975, in save\r\n    signatures, options)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\", line 112, in save_model\r\n    model, filepath, overwrite, include_optimizer)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 115, in save_model_to_hdf5\r\n    save_optimizer_weights_to_hdf5_group(f, model.optimizer)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 587, in save_optimizer_weights_to_hdf5_group\r\n    name, val.shape, dtype=val.dtype)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\h5py\\_hl\\group.py\", line 139, in create_dataset\r\n    self[name] = dset\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\h5py\\_hl\\group.py\", line 371, in __setitem__\r\n    h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)\r\n\r\n  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n\r\n  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n\r\n  File \"h5py\\h5o.pyx\", line 202, in h5py.h5o.link\r\n\r\nRuntimeError: Unable to create link (name already exists)\r\n```", "comments": ["@OverLordGoldDragon,\r\nWhen I tried reproducing your error, I got a different error, as shown below.\r\n\r\n`ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.`\r\n\r\nPlease find the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/efa2c0e43322822fb4b7b1d8af6eaecb/33100.ipynb). \r\n\r\nCan you please help me to reproduce the issue. Thanks!", "@rmothukuru Right, that's _another_ problem for which I started a [Pull Request](https://github.com/tensorflow/tensorflow/pull/33097) - you can implement the fix manually in the meantime.", "[Solved](https://stackoverflow.com/questions/58279628/what-is-the-difference-between-tf-keras-and-tf-python-keras#answer-58279629). TL;DR - `.python` isn't meant to be used for this purpose."]}, {"number": 33099, "title": "possible file name typo in raspberry pi example", "body": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi\r\n\r\n## Description of issue (what needs changing):\r\nNear the bottom of the instruction on speeding up inference it reads\r\n```python3 classify_picamera.py \\```\r\n\r\nBased on the files in that example folder should that instead read\r\n```python3 detect_picamera.py \\```\r\n\r\n### Clear description\r\nIf my assumption above is incorrect, then its unclear where the file ```classify_pycamera.py``` is coming from, and should maybe be explicitly mentioned.\r\n\r\n### Submit a pull request?\r\nI didnt plan to since its possibly a simple typo. But I can if you'd like.", "comments": ["Thanks @glw, \r\n\r\nI'm sending a fix, but in the future remember that you can too. Github's edit button makes  PRs for simple fixes like this with out leaving your browser.", "@MarkDaoust - ahh I wasnt aware of that. Thanks! I will do that for future minor issues. ", "@MarkDaoust this issue seems to be solved. ", "Thanks."]}, {"number": 33098, "title": "TF2.0 gradient result with some minor difference", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- I have written very simple custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Mac OS 10.13.16 and Windows 10):\r\n- No mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source with tag of v2.0.0 ):\r\n- TensorFlow version (use command below):\r\n- Python version: 3.7\r\n- Bazel version (0.26.1 & 0.25.3):\r\n- GCC/Compiler version (Apple LLVM version 9.1.0 (clang-902.0.39.2)):\r\n- CUDA/cuDNN version: CUDA 10.0 and cuDNN 7.4.x\r\n- GPU model and memory: ()\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/3695438/tf_env.txt)\r\n\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ntf.Tensor(31.999998, shape=(), dtype=float32) tf.Tensor(30.0, shape=(), dtype=float32) tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\r\n\r\n**Describe the expected behavior**\r\nAs dy/dx = a^2 + b, I expect result of 32.0 for dy_dx\r\n\r\n**Code to reproduce the issue**\r\nimport tensorflow as tf \r\n\r\n\r\nx = tf.constant(3.0)\r\na = tf.constant(5.0)\r\nb = tf.constant(7.0)\r\nc = tf.constant(9.0)\r\n\r\n\r\nwith tf.GradientTape() as tape:\r\n\ttape.watch([x, a, b, c])\r\n\ty = a**2 * x + b * x + c\r\n\r\n\r\n[dy_dx, dy_da, dy_db, dy_dc] = tape.gradient(y, [x, a, b, c])\r\nprint(dy_dx, dy_da, dy_db, dy_dc)\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@XiagenFeng,\r\nI am not sure if that can be reproduced because, I have executed the same code and I got the Tensor Value as 32.0. Please find the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/d34dd3a6acad78e9a196a705dd718403/33098.ipynb). \r\nCan you please try multiple times and report us the results. Thanks!", "@rmothukuru ,\r\nThanks for reply.\r\nI try with cpu and gpu and found this minor difference ***ONLY exist when use tf2.0 with CUDA***(CC3.0@750m and CC6.1@1080Ti).\r\nWhen use with CPU, I also got correct Tensor Value of 32.0.\r\n\r\nSo would you try to run it with CUDA GPU?\r\n\r\n\r\n**Content of autograd.py**\r\nSamuelFdeMacBook-Pro:mnist sfeng$ cat autograd.py\r\nimport tensorflow as tf \r\n\r\n\r\nx = tf.constant(3.0)\r\na = tf.constant(5.0)\r\nb = tf.constant(7.0)\r\nc = tf.constant(9.0)\r\n\r\n\r\nwith tf.GradientTape() as tape:\r\n\ttape.watch([x, a, b, c])\r\n\ty = a**2 * x + b * x + c\r\n\r\n\r\n[dy_dx, dy_da, dy_db, dy_dc] = tape.gradient(y, [x, a, b, c])\r\nprint(dy_dx, dy_da, dy_db, dy_dc)\r\n\r\nprint(dy_dx.device)\r\n\r\n**Run with GPU@MacOSX(tf v2.0.0)**\r\nSamuelFdeMacBook-Pro:mnist sfeng$CUDA_VISIBLE_DEVICES=0 python autograd.py\r\n2019-10-07 18:26:19.552406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.10.0.dylib\r\n2019-10-07 18:26:21.340009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.dylib\r\n2019-10-07 18:26:21.347508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.347696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.9255\r\npciBusID: 0000:01:00.0\r\n2019-10-07 18:26:21.347880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.10.0.dylib\r\n2019-10-07 18:26:21.351715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.10.0.dylib\r\n2019-10-07 18:26:21.354972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.10.0.dylib\r\n2019-10-07 18:26:21.356208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.10.0.dylib\r\n2019-10-07 18:26:21.361820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.10.0.dylib\r\n2019-10-07 18:26:21.366090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.10.0.dylib\r\n2019-10-07 18:26:21.372595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.7.dylib\r\n2019-10-07 18:26:21.372776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.373155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.373318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-07 18:26:21.373967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.374142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.9255\r\npciBusID: 0000:01:00.0\r\n2019-10-07 18:26:21.374364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.10.0.dylib\r\n2019-10-07 18:26:21.374525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.10.0.dylib\r\n2019-10-07 18:26:21.374715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.10.0.dylib\r\n2019-10-07 18:26:21.374889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.10.0.dylib\r\n2019-10-07 18:26:21.375074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.10.0.dylib\r\n2019-10-07 18:26:21.375247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.10.0.dylib\r\n2019-10-07 18:26:21.375406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.7.dylib\r\n2019-10-07 18:26:21.375545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.375809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.375958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-07 18:26:21.376139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.10.0.dylib\r\n2019-10-07 18:26:21.885787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-07 18:26:21.885829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-10-07 18:26:21.885834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-10-07 18:26:21.886074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.886406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.886706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] OS X does not support NUMA - returning NUMA node zero\r\n2019-10-07 18:26:21.886914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8 MB memory) -> physical GPU (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\ntf.Tensor(***31.999998***, shape=(), dtype=float32) tf.Tensor(30.0, shape=(), dtype=float32) tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\r\n/job:localhost/replica:0/task:0/device:GPU:0\r\n\r\n**Run with CPU@MacOSX(tf v2.0.0)**\r\nSamuelFdeMacBook-Pro:mnist sfeng$ CUDA_VISIBLE_DEVICES=-1 python autograd.py\r\n2019-10-07 18:26:28.805237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.10.0.dylib\r\n2019-10-07 18:26:30.595050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.dylib\r\n2019-10-07 18:26:30.598664: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2019-10-07 18:26:30.599183: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: SamuelFdeMacBook-Pro.local\r\n2019-10-07 18:26:30.599234: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: SamuelFdeMacBook-Pro.local\r\n2019-10-07 18:26:30.599610: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 387.10.0\r\n2019-10-07 18:26:30.599940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: Invalid argument: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got \"\"\r\ntf.Tensor(32.0, shape=(), dtype=float32) tf.Tensor(30.0, shape=(), dtype=float32) tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\r\n/job:localhost/replica:0/task:0/device:CPU:0\r\nSamuelFdeMacBook-Pro:mnist sfeng$ \r\n\r\n**Run with GPU@Win10(tf v2.0.0)**\r\nG:\\PR2\\TensorFlow-2.x-Tutorials>set CUDA_VISIBLE_DEVICES=0\r\nset CUDA_VISIBLE_DEVICES=0\r\n\r\nG:\\PR2\\TensorFlow-2.x-Tutorials>python autograd.py \r\npython autograd.py \r\n2019-10-07 18:44:15.400734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2019-10-07 18:44:24.491463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-10-07 18:44:25.017411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:05:00.0\r\n2019-10-07 18:44:25.017965: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-07 18:44:25.020200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-07 18:44:25.590600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:05:00.0\r\n2019-10-07 18:44:25.591094: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-10-07 18:44:25.593234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-10-07 18:44:28.000587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-07 18:44:28.000972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-10-07 18:44:28.001201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-10-07 18:44:28.003798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8784 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\ntf.Tensor(***31.999998***, shape=(), dtype=float32) tf.Tensor(30.0, shape=(), dtype=float32) tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\r\n/job:localhost/replica:0/task:0/device:GPU:0\r\n\r\n**Run with CPU@Win10(tf v2.0.0)**\r\nG:\\PR2\\TensorFlow-2.x-Tutorials>set CUDA_VISIBLE_DEVICES=-1\r\nset CUDA_VISIBLE_DEVICES=-1\r\n\r\nG:\\PR2\\TensorFlow-2.x-Tutorials>python autograd.py \r\npython autograd.py \r\n2019-10-07 18:43:48.903557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2019-10-07 18:43:59.934012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-10-07 18:44:00.440798: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2019-10-07 18:44:00.447878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DSWin\r\n2019-10-07 18:44:00.448430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DSWin\r\ntf.Tensor(32.0, shape=(), dtype=float32) tf.Tensor(30.0, shape=(), dtype=float32) tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\r\n/job:localhost/replica:0/task:0/device:CPU:0\r\n\r\nPS. I built the Windows GPU version of tensor flow v2.0.0 and replaced the v2.0.0rc1 with v2.0.0, but this problem exist in Windows v2.0.0 with CUDA gpu.", "@XiagenFeng I could reproduce the issue. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/dc99bb6a319753c33bdbf04264918655/33098.ipynb) is the gist. Thanks!", "@jvishnuvardhan That is great!", "Unless I'm missing something 31.999998 is  when considering floating point precision. If you want further precision you can change the constants to be `dtype=tf.float64` and you'll get 32.0.", "@jaingaurav Thanks for your insight!\r\n\r\nAfter change from\r\nx = tf.constant(3.0)\r\nto\r\nx = tf.constant(3.0, dtype=tf.float64)\r\n\r\nThe GPU result is exactly 32.0"]}, {"number": 33097, "title": "Fix grad check compatibility", "body": "Current code uses a conflicting check on `grads` during optimizer compilation - the fix addresses it. Below is a minimal reproducible example + full error trace. Full details at [SO question](https://stackoverflow.com/questions/58261348/valueerror-tried-to-convert-y-to-a-tensor-and-failed-error-none-values-not).\r\n\r\n<hr>\r\n\r\n**DOESN'T WORK**:\r\n\r\n```python\r\nfrom tensorflow.python.keras.layers import Input, Dense\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.optimizers import Nadam\r\nimport numpy as np\r\n\r\nipt = Input(shape=(4,))\r\nout = Dense(1, activation='sigmoid')(ipt)\r\n\r\nmodel = Model(ipt, out)\r\nmodel.compile(optimizer=Nadam(lr=1e-4), loss='binary_crossentropy')\r\n\r\nX = np.random.randn(32,4)\r\nY = np.random.randint(0,2,(32,1))\r\nmodel.train_on_batch(X,Y)\r\n```\r\n\r\n**WORKS**: remove `.python` from above's imports. \r\n\r\n<hr>\r\n\r\n**Full error trace:**\r\n\r\n```python\r\n  File \"<ipython-input-1-2db039c052cf>\", line 20, in <module>\r\n    model.train_on_batch(X,Y)\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1017, in train_on_batch\r\n    self._make_train_function()\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2116, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizers.py\", line 653, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizers.py\", line 92, in get_gradients\r\n    if None in grads:\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 1336, in tensor_equals\r\n    return gen_math_ops.equal(self, other)\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 3626, in equal\r\n    name=name)\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 545, in _apply_op_helper\r\n    (input_name, err))\r\n \r\nValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.\r\n```", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33097) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33097) for more info**.\n\n<!-- ok -->"]}, {"number": 33096, "title": "Reading TF2 summary file with tf.data.TFRecordDataset", "body": "In TF1, i could use `summary_iterator` to read summary files. But now, it will throw a warning\r\n\r\n```\r\nWARNING:tensorflow: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\n```\r\n\r\nSo i'm wondering how to use `tf.data.TFRecordDataset(path)` to read tfevent files generated by TF2.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33096\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33096\">No</a>\n"]}, {"number": 33095, "title": "Tensorflow 2.0 stop_gradient cause ValueError has 'None' for gradient for tf.Optimizers.Adam", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nUbuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\npip\r\n- TensorFlow version (use command below): \r\nv2.0.0-rc2-26-g64c3d38 2.0.0 / 1.14.0\r\n- Python version: \r\n3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: \r\n7.6.0\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nFor Tensorflow 2.0, stop_gradient() doesn't seem to work properly. \r\n\r\nFor example, the code below update one model's weight using output from another model. In Tensorflow 2.0, it will try to compute gradient for the stop_gradient() model. \r\n\r\n**Describe the expected behavior**\r\n\r\nIn Tensorflow 1.14.0 and 1.13.2, it works correctly. The model only updates for model1 without any checking for model2. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\nimport sys\r\nimport time\r\n\r\nfrom tensorflow.keras.layers import Dense, Input, Add, Lambda\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.models import load_model\r\nfrom tensorflow.keras import optimizers\r\n\r\nfrom scipy.io import loadmat\r\nfrom scipy.spatial.distance import cdist\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nx = np.random.rand(100).reshape(100, 1).astype(float)\r\ny = np.array(x>0.5).reshape(100, 1).astype(float)\r\n\r\ninput1 = Input(shape=(1, ), name='input1')\r\nd1 = Dense(12, name='d11')(input1)\r\nd1 = Dense(12, name='d12')(d1)\r\nd1 = Dense(1, name='output1')(d1)\r\n\r\ninput2 = Input(shape=(1, ), name='input2')\r\nd2 = Dense(12, name = 'd21')(input2)\r\nd2 = Dense(12, name = 'd22')(d2)\r\nd2 = Dense(1, name = 'output2')(d2)\r\n\r\nlabel = Input(shape = (1, ), name = 'label')\r\n\r\nmodel1 = Model(inputs = [input1, label], outputs = d1)\r\nmodel2 = Model(inputs = input2, outputs = d2)\r\n\r\ndef cust_loss(xi, yi, yp):\r\n    loss = tf.reduce_mean((yi - yp)**2) + tf.reduce_mean(tf.stop_gradient(model2(xi)))\r\n    \r\n    return loss\r\n\r\nmodel1.add_loss(cust_loss(input1, label, d1))\r\noptimizer = optimizers.Adam(lr = 3e-4)\r\nmodel1.compile(optimizer, loss = None)\r\n\r\nmodel1.fit({'input1': x, 'label': y}, None, epochs=100)\r\n```\r\n\r\n**Other info / logs**\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-2-bb2983e16d6f> in <module>\r\n     26 model1.compile(optimizer, loss = None)\r\n     27 \r\n---> 28 model1.fit({'input1': x, 'label': y}, None, epochs=100)\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    672         validation_steps=validation_steps,\r\n    673         validation_freq=validation_freq,\r\n--> 674         steps_name='steps_per_epoch')\r\n    675 \r\n    676   def evaluate(self,\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    187   # function we recompile the metrics based on the updated\r\n    188   # sample_weight_mode value.\r\n--> 189   f = _make_execution_function(model, mode)\r\n    190 \r\n    191   # Prepare validation data. Hold references to the iterator and the input list\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py in _make_execution_function(model, mode)\r\n    563   if model._distribution_strategy:\r\n    564     return distributed_training_utils._make_execution_function(model, mode)\r\n--> 565   return model._make_execution_function(mode)\r\n    566 \r\n    567 \r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _make_execution_function(self, mode)\r\n   2182   def _make_execution_function(self, mode):\r\n   2183     if mode == ModeKeys.TRAIN:\r\n-> 2184       self._make_train_function()\r\n   2185       return self.train_function\r\n   2186     if mode == ModeKeys.TEST:\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _make_train_function(self)\r\n   2114           # Training updates\r\n   2115           updates = self.optimizer.get_updates(\r\n-> 2116               params=self._collected_trainable_weights, loss=self.total_loss)\r\n   2117           # Unconditional updates\r\n   2118           updates += self.get_updates_for(None)\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in get_updates(self, loss, params)\r\n    498 \r\n    499   def get_updates(self, loss, params):\r\n--> 500     grads = self.get_gradients(loss, params)\r\n    501     grads_and_vars = list(zip(grads, params))\r\n    502     self._assert_valid_dtypes([\r\n\r\n~/miniconda3/envs/dl_ehr_rl/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in get_gradients(self, loss, params)\r\n    396                            \"gradient defined (i.e. are differentiable). \"\r\n    397                            \"Common ops without gradient: \"\r\n--> 398                            \"K.argmax, K.round, K.eval.\".format(param))\r\n    399       if hasattr(self, \"clipnorm\"):\r\n    400         grads = [clip_ops.clip_by_norm(g, self.clipnorm) for g in grads]\r\n\r\nValueError: Variable <tf.Variable 'd21/kernel:0' shape=(1, 12) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n", "comments": ["@Nephalen,\r\nCan you please check [this link](https://github.com/tensorflow/model-optimization/issues/3#issuecomment-497151388) and let us know if it helps. Thanks! ", "> \r\n> \r\n> @Nephalen,\r\n> Can you please check [this link](https://github.com/tensorflow/model-optimization/issues/3#issuecomment-497151388) and let us know if it helps. Thanks!\r\n\r\n@rmothukuru \r\nI don't think that problem is the same as mine. The sample code that produces error in Tensorflow 2.0 runs on single machine. In addition, there is no part that can produce additional layers.\r\n\r\nI also don't think it's the problem of keras' customized loss function. If I remove stop_gradient(), the code runs fine in Tensorflow 2.0.\r\n\r\nUpon further testing, the sample code works in Tensorflow 1.14 and 1.13.2\r\n\r\nHowever, it doesn't work in Tensorflow 1.15.0rc3 and 2.0.0. \r\n\r\nTo me, it looks like stop_gradient() is not working as intended since optimizer still tries to compute the gradient of part of graph that is blocked by stop_gradient().\r\n", "Could reproduce the issue with Tensorflow Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/5b15b64917818c18b24797b962e7f452/33095.ipynb). Thanks!", "@Nephalen I think the original issue has been addressed by this [comment](https://github.com/tensorflow/tensorflow/issues/26557#issuecomment-487133316) right? As mentioned stop_gradient does not work well and please follow the suggestion mentioned in the comment. ", "> \r\n> \r\n> @Nephalen I think the original issue has been addressed by this [comment](https://github.com/tensorflow/tensorflow/issues/26557#issuecomment-487133316) right? As mentioned stop_gradient does not work well and please follow the suggestion mentioned in the comment.\r\n\r\n@gowthamkpr I'm afraid the issue is not the same. If you look at the network structure of [#26557](https://github.com/tensorflow/tensorflow/issues/26557#issue-419269658) closely, you will find the model is completely disconnected from input because of stop_gradient(). In this case, TF 1.14 will also produce a ValueError saying that no gradient has been provided.\r\n\r\nHowever, in the sample code I provided, the stop_gradient() only blocks the gradient of the second model which is not the model to be trained. In TF 1.14, it works correctly.\r\n\r\nIt is possible that it has something similar to do with [#33471](https://github.com/tensorflow/tensorflow/issues/33471#issue-508537917). Because it is clear that weight of any additional model added in add_loss() function is incorrectly treated as update target in TF2.0/1.15. In this case, it actually makes sense that the code will raise ValueError in TF2.0/1.15 because there is no gradient for model2 completely. But this is only my guess. ", "@Nephalen Thanks for the issue!\r\n\r\nThis looks fixed in the latest tf-nightly (w/ eager execution enabled). This code works for me:\r\n\r\n```python\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras import optimizers\r\n\r\nx = np.random.rand(100).reshape(100, 1).astype(float)\r\ny = np.array(x>0.5).reshape(100, 1).astype(float)\r\n\r\ninput1 = Input(shape=(1, ), name='input1')\r\nd1 = Dense(12, name='d11')(input1)\r\nd1 = Dense(12, name='d12')(d1)\r\nd1 = Dense(1, name='output1')(d1)\r\n\r\ninput2 = Input(shape=(1, ), name='input2')\r\nd2 = Dense(12, name = 'd21')(input2)\r\nd2 = Dense(12, name = 'd22')(d2)\r\nd2 = Dense(1, name = 'output2')(d2)\r\n\r\nlabel = Input(shape = (1, ), name = 'label')\r\n\r\nmodel1 = Model(inputs = [input1, label], outputs = d1)\r\nmodel2 = Model(inputs = input2, outputs = d2)\r\n\r\ndef cust_loss(xi, yi, yp):\r\n    loss = tf.reduce_mean((yi - yp)**2) + tf.reduce_mean(tf.stop_gradient(model2(xi)))\r\n    \r\n    return loss\r\n\r\nmodel1.add_loss(cust_loss(input1, label, d1))\r\noptimizer = optimizers.Adam(lr = 3e-4)\r\nmodel1.compile(optimizer, loss = None)\r\n\r\nmodel1.fit({'input1': x, 'label': y}, None, epochs=100)\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33095\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33095\">No</a>\n"]}, {"number": 33094, "title": "Tensorflow 2.0.0 / tf.keras.layers.TimeDistributed layer can't be save to saved Model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution : Colaboratory (GPU Runtime)\r\n- tensorflow version: 2.0.0\r\n- python version: 3.6.8\r\n\r\n\r\n**Describe the current behavior**\r\nThe model defined which has tf.keras.layers.timeDistributed layer cannot be save by model.save() function.\r\n\r\nIt shows the error below\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n/usr/lib/python3.6/inspect.py in getfullargspec(func)\r\n   1125                                        skip_bound_arg=False,\r\n-> 1126                                        sigcls=Signature)\r\n   1127     except Exception as ex:\r\n\r\n41 frames\r\nValueError: no signature found for builtin <tensorflow.python.keras.saving.saved_model.save_impl.LayerCall object at 0x7f74467284a8>\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/lib/python3.6/inspect.py in getfullargspec(func)\r\n   1130         # else. So to be fully backwards compatible, we catch all\r\n   1131         # possible exceptions here, and reraise a TypeError.\r\n-> 1132         raise TypeError('unsupported callable') from ex\r\n   1133 \r\n   1134     args = []\r\n\r\nTypeError: unsupported callable\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\nIn tensorflow 2.0.0 supposed the model.save model default to be saved in SavedModel format. \r\n\r\n\r\n**Code to reproduce the issue**\r\n```mirrored_strategy = tf.distribute.MirroredStrategy()\r\n\r\ndef get_data():\r\n  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\r\n  mnist_train, mnist_test = datasets['train'], datasets['test']\r\n\r\n  BUFFER_SIZE = 10000\r\n\r\n  BATCH_SIZE_PER_REPLICA = 64\r\n  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\r\n\r\n  def scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n\r\n    return image, label\r\n\r\n  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n\r\n  return train_dataset, eval_dataset\r\n\r\ndef get_model():\r\n  with mirrored_strategy.scope():\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPooling2D(),\r\n        # tf.keras.layers.Flatten(),\r\n        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='softmax')),\r\n        # tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='softmax')),\r\n        # tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n\r\n    model.compile(loss='sparse_categorical_crossentropy',\r\n                  optimizer=tf.keras.optimizers.Adam(),\r\n                  metrics=['accuracy'])\r\n    return model\r\n\r\nmodel = get_model()\r\nmodel.save(\"test_save\")\r\n```\r\n\r\n**Other info / logs**\r\nThe not only can be reproduce in Colaboratory, but also in normal Ubuntu machien which installed with tensorflow-gpu 2.0.0", "comments": ["Could reproduce this issue with TF Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/c698628e49bce4d456daac7c2ddf3bea/33094.ipynb).", "Also running into this. Here's a concise test case:\r\n```\r\nmodel = tf.keras.Sequential([tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1), input_shape=(None, 1))])\r\nmodel.save('test_save')\r\n```", "does this issues got any progress?", "Any update?\r\n", "This appears to be an error with Python 3. Submitting a fix to resolve this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33094\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33094\">No</a>\n", "so is this been fixed to tensorflow-gpu 2.0 stable build? or i have to install another build?", "@luvwinnie It was fixed in `tf-nightly` which is development version of `TF2.1` (will be released in \r\nthe near future). Thanks!"]}, {"number": 33093, "title": "deleted useless code", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33093) for more info**.\n\n<!-- need_sender_cla -->", "@aaaaadamchen thank you for your contribution, please sign CLA.", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33093) for more info**.\r\n\r\n@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33093) for more info**.\n\n<!-- ok -->", "```\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/eager/function_test.runfiles/org_tensorflow/tensorflow/python/eager/function_test.py\", line 976, in testRunMetadata\r\n    run_metadata = context.export_run_metadata()\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/eager/function_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 1970, in export_run_metadata\r\n    return context().export_run_metadata()\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/eager/function_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 1473, in export_run_metadata\r\n    with c_api_util.tf_buffer() as buffer_:\r\nNameError: name 'c_api_util' is not defined\r\n```\r\n\r\nClosing as invalid PR."]}, {"number": 33092, "title": "Prebuilt libtensorflow (C API)", "body": "The link in \r\nhttps://www.tensorflow.org/install/lang_c\r\n\r\ncontain the 1.14 library. Are there any prebuilt link for the C API for 2.0 stable?\r\n\r\nThis also holds true for the install for java page\r\n\r\n", "comments": ["When it is expected for the C API to be supported for 2.0? Is there any scheduling about it? Thanks.", "Also run into this. With the recent security issue with 1.13 we now want to upgrade but can't due to there being no libtensorflow for v2.0 and its not worth all the change to go stay on v1.\r\nWe tried to compile it ourselves, but that failed too.\r\nI also don't know if this should have the docs label.", "Multiple teams I work with at my employer require the C API, either to use in a native project, or for the Java API. We are also all wondering when the C API support will be added to TF 2.x. I've been unable to find out where this status information is kept.\r\n\r\nDoes anyone know what's broken, or what's holding this up? Are there any concrete plans on fixing those issues? I don't mind compiling myself, but I would hate to deploy something to a customer only to find out that the TensorFlow team does not support the C API officially.", "Thanks for raising this.\r\nOur guarantees on our APIs are outlined here:\r\nhttps://www.tensorflow.org/guide/versions\r\n\r\nTo summarize the C\\C++ aspect.\r\nThe headers under `tensorflow/c`, except the ones that have `internal` in the name are not expected to change. Only in cases of bugs, or extraordinary changes we expect changes here.\r\nWe are working to expand this, and add more features there.\r\nAny other headers in TF currently are not under any compatibility guarantees. While we understand that a lot of our users need to use them, they may change.\r\n\r\nFor the prebuilt packages, it is in our short term plans to fix them. Hopefully, soon after 2.2 final is released we can get to them, and push them out.", "@gunan:\r\nThanks for your comprehensive reply. We look forward to the next prepackaged update!\r\n\r\nIs the C API otherwise working for 2.0 and 2.1 if  one builds it themselves? We build TF from source for some of our projects, and as long as it's still functional we don't have to wait for the prepackaged version, though some teams do prefer those as they are standard.", "In theory, it should. We do run the tests on C API headers in our CI.\r\nIf there are any bugs, or issues  you run into, we would love to hear about them and fix them.", "@jtavrisov We are checking to see if you still need help on this issue. Could you please check with latest stable version of TF which is `TF2.7` ? please check document [link](https://www.tensorflow.org/install/lang_c) and https://github.com/tensorflow/tensorflow/issues/33092#issuecomment-613804129 . Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33091, "title": "mlir: minor spelling tweaks", "body": "", "comments": []}, {"number": 33090, "title": "model.evaluate gives unexpected results", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but very close to example code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab and Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Source and binary\r\n- TensorFlow version (use command below): `v2.0.0-rc2-26-g64c3d382ca 2.0.0` and `v2.0.0-rc2-26-g64c3d38 2.0.0`\r\n- Python version: 3.6.8 and 3.6.7\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: 10.0, 7.6\r\n- GPU model and memory: K80, V100 16GB\r\n\r\n**Describe the current behavior**\r\n\r\n- `model.fit()` works and training converges\r\n- validation during training gives effectively random performance\r\n- `model.evaluate()` on both **training** and validation set gives random performance\r\n\r\nTraining and evaluating on the same **training set** gives random evaluation performance but expected training performance. Hence, there seems to be an issue with the evaluation in TF.\r\n\r\n**Describe the expected behavior**\r\n\r\nAt very least, if I evaluate on the **training set**, I should see loss and accuracy similar to that is output during training.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCheck Colab notebook to reproduce the issue: https://colab.research.google.com/drive/1HBdfWjx3jj65wrP_a0r_Tu80genKBsw2\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nColab notebook should demonstrate everything and aid investigation.\r\n\r\nThanks in advance to anyone who can help!\r\n", "comments": ["Could reproduce the issue with Tensorflow Version 2.0. Training Loss is 0.6364 for `model.fit` but Training Loss is 4.4208 for `model.evaluate`. \r\n\r\nHere is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/f04842c98ea2332523f10b37537f0596/33090.ipynb#scrollTo=-C5i8c_Vmgwy).", "@tlkh I think this is expected as your model is using BatchNorm. There are some layers (BatchNorm, Dropout) that are enabled during training and disabled while evaluation. If you disable BatchNorm and run the training (model.fit) and Evaluation (model.evaluate), the results should be very close (not exactly same). Please check this [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/735dcb2ba93dbbfd0574214765eabffd/tf33031.ipynb). This is similar to [this issue](https://github.com/tensorflow/tensorflow/issues/33031). Thanks!\r\n\r\nI am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33090\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33090\">No</a>\n", "@jvishnuvardhan Thanks. Sorry for the late response, I was tied up with other matters. I have figured out that the actual issue is with the Keras Applications ResNet model, which has the BatchNorm layers, which **although set to not trainable, had different behavior during train and evaluate**. This results in the essentially random evaluation behavior. I will open a separate issue.", "@tlkh BatchNorm will always have different behavior b/t train and evaluate. During training, batches are normed. During inference, the trained weights are used for normalization. If you set trainable=False, these statistics will not update and so therefore will result in poor evaluation performance", "I have discovered the behavior of BatchNorm was changed specifically in TensorFlow 2.0 according to the docs in the code (which don't render correctly on the website). This answers my confusion why training that worked in TF 1.x does not work in TF 2.0\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization_v2.py#L26-L65\r\n"]}, {"number": 33089, "title": "tf silently rounding to integer when converting to PIL format", "body": "**System information**\r\n- Have I written custom code: not really, no.\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.2 LTS (Bionic Beaver)\r\n- TensorFlow installed from (source or binary): pip install (binary?)\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: - (running on cpu only)\r\n- GPU model and memory: - (running on cpu only)\r\n\r\n**Describe the current behavior**\r\nWhen converting to PIL format from array and back, tf silently rounds values to integers. (see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/array_to_img, https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array)\r\n\r\n**Describe the expected behavior**\r\nThrow a warning when silently rounding. maybe convert to float instead of integer if input is a float dtype?\r\n\r\n**Code to reproduce the issue**\r\nplease see the short example test case here: https://github.com/WildTangles/tf-issues/blob/master/tensorflow_bug_conversions/bug_demo.ipynb\r\n\r\nIn particular, see: \r\ncell 4 (random noise image, 4800 unique values) vs. \r\ncell 6 (image after conversion to PIL and back, 256 unique values)\r\n\r\n**Other info / logs**\r\nHappy to provide if necessary.", "comments": ["@WildTangles,\r\nThe Notebook in the link, https://github.com/WildTangles/tf-issues/blob/master/tensorflow_bug_conversions/bug_demo.ipynb couldn't be opened.  It is resulting in an error as shown below. Can you please share the attachment. Thanks!\r\n\r\n![image](https://user-images.githubusercontent.com/48206667/66914789-3125bb00-f035-11e9-8c19-8b7c0f126158.png)\r\n", "@rmothukuru \r\nplease see: https://nbviewer.jupyter.org/github/WildTangles/tf-issues/blob/master/tensorflow_bug_conversions/bug_demo.ipynb\r\n\r\nIt's the same notebook, just hosted on nbbiewer.jupyter.org.", "@WildTangles I agree that there are only 256 unique values after conversion. However, there is not much information lost during conversion. [Here](https://colab.research.google.com/gist/jvishnuvardhan/4f8fb11eb5979db06468b1d277e9e439/untitled89.ipynb) is a gist with `tf-nightly` for y/our reference. Thanks!", "Yes, I agree that the difference can be small. But it's still a silent rounding. I would hope/assume that the function would throw a warning when the input dtype is not int (and is going to be rounded to ints in 0-255 by the function).\r\n\r\nSpecifically, I understand that maybe if you're training a CNN on ImageNet or something like that, it does not really matter. But this approximation can lead to issues with converging in optimization problems (specifically, I ran into issues with generating adversarial examples with a boundary attack because of my oversight with this int rounding).", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33089\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33089\">No</a>\n"]}, {"number": 33088, "title": "inconsistent behavior of model after creation vs. after loading from save file", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.2 LTS (Bionic Beaver)\r\n- TensorFlow installed from (source or binary): pip install (binary?)\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: - (running on cpu only)\r\n- GPU model and memory: - (running on cpu only)\r\n\r\n**Describe the current behavior**\r\nWhen using lambda layers with parameters generated in a loop, creation-time behavior of model is different from behavior of model re-loaded from a save file.\r\n\r\n**Describe the expected behavior**\r\nConsistent behavior at creation-time of model and after re-loading from a save file.\r\n\r\n**Code to reproduce the issue**\r\nplease see the short example test case here: https://github.com/WildTangles/tf-issues/blob/master/tensorflow_bug_lambdas/bug_demo.ipynb\r\n\r\n(alternatively, please see the same notebook rendered on a different site here: https://nbviewer.jupyter.org/github/WildTangles/tf-issues/blob/master/tensorflow_bug_lambdas/bug_demo.ipynb)\r\n\r\nIn particular, see: \r\ncell 6 (expected output plotted by hand) vs. \r\ncell 7 (model behavior right after being created, matches expected) vs.\r\ncell 10 (model behavior after being saved and re-loaded, does not match expected)\r\n\r\ncell 4 (model definition, in particular, see first few lines with lambda layer parameters defined in a loop)\r\n\r\n**Other info / logs**\r\nHappy to provide if necessary.", "comments": ["@WildTangles,\r\nWhen trying to open the ipynb notebook, I am encountering the error as shown in the screenshot below:\r\n\r\n![image](https://user-images.githubusercontent.com/48206667/66305817-c9c58800-e91d-11e9-9c70-bd952d3586a7.png)\r\n\r\nCan you please link the notebook correctly and share it. Thanks!", "> @WildTangles,\r\n> When trying to open the ipynb notebook, I am encountering the error as shown in the screenshot below:\r\n> \r\n> ![image](https://user-images.githubusercontent.com/48206667/66305817-c9c58800-e91d-11e9-9c70-bd952d3586a7.png)\r\n> \r\n> Can you please link the notebook correctly and share it. Thanks!\r\n\r\n\r\n\r\n@rmothukuru \r\nPlease see: https://nbviewer.jupyter.org/github/WildTangles/tf-issues/blob/master/tensorflow_bug_lambdas/bug_demo.ipynb\r\n\r\nIt's the same notebook, just now rendered on https://nbviewer.jupyter.org/.\r\n", "Could reproduce this issue with TF Version 1.15. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/accc8dc92583c4dfc72280a95fa08734/33088.ipynb). and  [[2]](https://colab.sandbox.google.com/gist/gowthamkpr/6f64fee3d7335016ae2b9bcb2d76b461/bug_demo.ipynb)", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33088\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33088\">No</a>\n"]}, {"number": 33087, "title": "InternalError: Failed to call ThenRnnBackward", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux/google colab\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 12gb (Tesla K80)\r\n\r\n**Describe the current behavior**\r\nCurrently, I have training a simple seq2seq model using tensorflow-2.0.0-beta1.\r\n\r\nRC1 and RC2 I had some memory leak issues, so I waited for final release. However, in 2.0.0 version, I got other bug in fit_generator():\r\n\r\n``InternalError: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 162, 1024, 1, 128, 128, 0]  [Op:CudnnRNNBackprop]``\r\n\r\n**Describe the expected behavior**\r\n\r\nI back again to beta1, cause it's working fine well in this version.", "comments": ["@arthurflor23, \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Hi!\r\nThe training model:\r\n\r\n```\r\nencoder_inputs = Input(shape=(None, vocab_size))\r\ndecoder_inputs = Input(shape=(None, vocab_size))\r\n\r\nencoder_bigru = Bidirectional(GRU(units, return_sequences=True, return_state=True, dropout=dropout))\r\n\r\nencoder_out, encoder_fwd_state, encoder_back_state = encoder_bigru(encoder_inputs)\r\nencoder_states = Concatenate(axis=-1)([encoder_fwd_state, encoder_back_state])\r\n\r\ndecoder_gru = GRU(units * 2, return_sequences=True, return_state=True, dropout=dropout)\r\n\r\ndecoder_out, decoder_state = decoder_gru(decoder_inputs, initial_state=encoder_states)\r\n\r\nattn_out = Attention()([decoder_out, encoder_out])\r\ndecoder_concat_input = Concatenate(axis=-1)([decoder_out, attn_out])\r\n\r\ndense_time = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))\r\n\r\ndecoder_pred = dense_time(decoder_concat_input)\r\n\r\nmodel = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\r\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\r\n```\r\n\r\nI checked in CPU version and it's OK there..\r\n\r\nAnd the error occurs during training..\r\n\r\nComplete error output:\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1295         shuffle=shuffle,\r\n   1296         initial_epoch=initial_epoch,\r\n-> 1297         steps_name='steps_per_epoch')\r\n   1298 \r\n   1299   def evaluate_generator(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\r\n    263 \r\n    264       is_deferred = not model._is_compiled\r\n--> 265       batch_outs = batch_function(*batch_data)\r\n    266       if not isinstance(batch_outs, list):\r\n    267         batch_outs = [batch_outs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n    971       outputs = training_v2_utils.train_on_batch(\r\n    972           self, x, y=y, sample_weight=sample_weight,\r\n--> 973           class_weight=class_weight, reset_metrics=reset_metrics)\r\n    974       outputs = (outputs['total_loss'] + outputs['output_losses'] +\r\n    975                  outputs['metrics'])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)\r\n    262       y,\r\n    263       sample_weights=sample_weights,\r\n--> 264       output_loss_metrics=model._output_loss_metrics)\r\n    265 \r\n    266   if reset_metrics:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)\r\n    309           sample_weights=sample_weights,\r\n    310           training=True,\r\n--> 311           output_loss_metrics=output_loss_metrics))\r\n    312   if not isinstance(outs, list):\r\n    313     outs = [outs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)\r\n    266           model._backwards(tape, scaled_total_loss)\r\n    267         else:\r\n--> 268           grads = tape.gradient(scaled_total_loss, trainable_weights)\r\n    269           if isinstance(model.optimizer,\r\n    270                         loss_scale_optimizer.LossScaleOptimizer):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n   1012         output_gradients=output_gradients,\r\n   1013         sources_raw=flat_sources_raw,\r\n-> 1014         unconnected_gradients=unconnected_gradients)\r\n   1015 \r\n   1016     if not self._persistent:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\r\n     74       output_gradients,\r\n     75       sources_raw,\r\n---> 76       compat.as_str(unconnected_gradients.value))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\r\n    136     return [None] * num_inputs\r\n    137 \r\n--> 138   return grad_fn(mock_op, *out_grads)\r\n    139 \r\n    140 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/cudnn_rnn_grad.py in _cudnn_rnn_backward(op, *grads)\r\n     45       rnn_mode=op.get_attr(\"rnn_mode\"),\r\n     46       input_mode=op.get_attr(\"input_mode\"),\r\n---> 47       direction=op.get_attr(\"direction\"))\r\n     48 \r\n     49 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_cudnn_rnn_ops.py in cudnn_rnn_backprop(input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, rnn_mode, input_mode, direction, dropout, seed, seed2, name)\r\n    307       else:\r\n    308         message = e.message\r\n--> 309       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n    310   # Add nodes to the TensorFlow graph.\r\n    311   if rnn_mode is None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInternalError: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 162, 512, 1, 128, 128, 0]  [Op:CudnnRNNBackprop]\r\n```\r\n\r\nMaybe the model has something wrong and the beta version let it pass?", "@arthurflor23,\r\nCan you please share the complete code, along with `import` statements which will save our time in reproducing the issue. Thanks!", "Hi, sure!\r\nAll imports I use is from keras module, so:\r\n\r\n```\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.callbacks import CSVLogger, TensorBoard, ModelCheckpoint, EarlyStopping\r\nfrom tensorflow.keras.layers import Input, Concatenate, Bidirectional, GRU, TimeDistributed, Dense, Attention\r\n```\r\n\r\nThe callbacks list is CSVLogger, TensorBoard, ModelCheckpoint, EarlyStopping, with the values:\r\n\r\n```\r\ncallbacks = [\r\n  CSVLogger(filename=PATH, separator=\";\", append=True),\r\n  TensorBoard(log_dir=PATH, histogram_freq=10, profile_batch=0, write_graph=True, write_images=False, update_freq=\"epoch\"),\r\n  ModelCheckpoint(filepath=PATH, monitor=\"val_loss\", save_best_only=True, save_weights_only=True, verbose=1),\r\n  EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=40, restore_best_weights=True, verbose=1)\r\n]\r\n```\r\n\r\nTrain through fit_generator() with the inputs ```[one_hot_inputs, one_hot_decoders], one_hot_targets``` (default se2seq)", "@arthurflor23,\r\nThe error is still not reproducible. While trying to reproduce the issue, I encountered the below error.\r\n`NameError: name 'vocab_size' is not defined`. I resolved that error by giving some value to `vocab_size` but thenI encountered the error, `NameError: name 'units' is not defined` .\r\n\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Hi!\r\nI use 162 as vocab_size and 512 as units.\r\n\r\nUnfortunately the project code is still in private mode, but I'll do more tests with the model that I'm studying for more detailed information..", "@arthurflor23,\r\nMore information will surely be helpful as the error couldn't be reproduced with the present information. Thanks! ", "Hi @rmothukuru !\r\n\r\nI made some tests and I think I found the error (my bad, anyway). I started use a custom loss function inside my class, so I change to a static method and the error not show up, but now I got this error [here](https://github.com/tensorflow/tensorflow/issues/33178) instead.\r\n"]}, {"number": 33086, "title": "Distributed Keras MultiWorkerMirroredStrategy failed", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock example modified\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nError when using MultiWorkerMirroredStrategy\r\n\r\n**Describe the expected behavior**\r\nNo Error\r\n\r\n**Code to reproduce the issue**\r\n```\r\n# worker.py\r\nimport tensorflow as tf\r\nimport os\r\nimport json\r\n\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow import keras\r\n\r\n\"\"\"\r\nShell 1:\r\n\r\nTF_CONFIG='{\"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:56789\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}' python worker.py\r\n\r\nShell 2:\r\nTF_CONFIG='{\"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:56789\"]}, \"task\": {\"index\": 1, \"type\": \"worker\"}}' python worker.py\r\n\"\"\"\r\n\r\nprint('tf {}'.format(tf.__version__))\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\ntfds.disable_progress_bar()\r\n\r\nBUFFER_SIZE = 10000\r\nNUM_WORKERS = 2\r\nGLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\r\n\r\ndef scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n    return image, label\r\n\r\ndatasets, info = tfds.load(name='mnist',\r\n                           with_info=True,\r\n                           as_supervised=True)\r\n\r\ntrain_datasets_unbatched = datasets['train'].map(scale).shuffle(BUFFER_SIZE)\r\n\r\ntrain_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)\r\n\r\ndef build_and_compile_cnn_model():\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(32,3,activation='relu',input_shape=(28,28,1)),\r\n        tf.keras.layers.MaxPooling2D(),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(64,activation='relu'),\r\n        tf.keras.layers.Dense(10,activation='softmax')\r\n    ])\r\n    model.compile(\r\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n        metrics=['accuracy'])\r\n    return model\r\n\r\n\r\nwith strategy.scope():\r\n    model =  build_and_compile_cnn_model()\r\n\r\n    model.fit(x=train_datasets, epochs=3)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2019-10-06 15:34:50.454016: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-06 15:34:50.786372: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb6d700010 executing computations on platform Host. Devices:\r\n2019-10-06 15:34:50.786394: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-10-06 15:34:50.839300: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345, 1 -> localhost:56789}\r\n2019-10-06 15:34:50.840100: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:12345\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW1006 15:34:53.847770 4649092544 distribute_coordinator.py:825] `eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nW1006 15:34:53.857074 4649092544 distribute_coordinator.py:829] `eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nW1006 15:34:53.870861 4649092544 distributed_training_utils.py:1163] ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.\r\nEpoch 1/3\r\n    469/Unknown - 20s 42ms/step - loss: 2.1887 - accuracy: 0.28872019-10-06 15:35:13.827666: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n469/469 [==============================] - 20s 42ms/step - loss: 2.1887 - accuracy: 0.2887\r\nEpoch 2/3\r\n2019-10-06 15:35:15.788116: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.788143: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.788208: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.788223: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[allreduce_1/CollectiveReduce]]\r\n2019-10-06 15:35:15.789211: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789231: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789219: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789318: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789573: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789589: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.789635: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.790304: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.790362: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.797384: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.797403: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-10-06 15:35:15.797452: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n  1/469 [..............................] - ETA: 14:26Traceback (most recent call last):\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 487, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.OutOfRangeError:  [_Derived_]End of sequence\r\n\t [[node IteratorGetNext (defined at /Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n\t [[allreduce_1/CollectiveReduce]] [Op:__inference_distributed_function_950]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"worker.py\", line 59, in <module>\r\n    model.fit(x=train_datasets, epochs=3)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 789, in fit\r\n    *args, **kwargs)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 776, in wrapper\r\n    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 853, in run_distribute_coordinator\r\n    task_id, session_config, rpc_layer)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 360, in _run_single_worker\r\n    return worker_fn(strategy)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 771, in _worker_fn\r\n    return method(model, **kwargs)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/Users/xx/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 146, in run_one_epoch\r\n    total_epochs * steps_per_epoch))\r\nTypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\r\n2019-10-06 15:35:16.209044: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.\r\n```\r\n", "comments": ["Make these changes, should work\r\n```\r\ntrain_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE).repeat()\r\n```\r\n```\r\nmodel.fit(x=train_datasets, epochs=3, steps_per_epoch=...)\r\n```\r\nIdeally `steps_per_epoch` should be equal to `total_samples//batch_size`", "Thank you\r\n\r\nIt works", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33086\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33086\">No</a>\n", "Should you put `train_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)` inside the strategy's scope?", "> Should you put `train_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)` inside the strategy's scope?\r\n\r\noutside and after.\r\n```\r\nstrategy = tf.strategy()\r\ntrain_dataset = get _dataset()\r\nwith stragey..scope():\r\n  model = get_model()\r\nmodel.fit()\r\n```\r\nMake sure you are using TF2.2.0.rec3"]}, {"number": 33085, "title": "Calling tf.keras.models.load_model / model.save twice fails", "body": "Please see [CoLab](https://colab.research.google.com/drive/1dXgiJZDbGHdQFrquvtMBblgz_5O1WSlD) or [Github Gist](https://gist.github.com/srfrnk/713765b44dd6677ba3e26ff4ac46f68b#file-save-load-bug-ipynb) to see live demo.\r\n\r\nSteps to reproduce:\r\n1) Create model,compile and fit\r\n2) Save model\r\n3) Load model and fit\r\n4) Save model\r\n5) Load model\r\n\r\nGet error: `ValueError: Passing a dictionary input to a Sequential Model which doesn't have FeatureLayer as the first layer is an error.`\r\n\r\nExpected: Model that was loaded and saved again should be loaded without error.", "comments": ["@srfrnk,\r\nI have executed your code in Tensorflow Version 2.0 and it worked fine. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/602f614b31dba5ef5e98026d317caa89/33085.ipynb).\r\n\r\nThanks! ", "I have tested again using this [CoLab](https://colab.research.google.com/drive/1dXgiJZDbGHdQFrquvtMBblgz_5O1WSlD) just now.\r\nThe issue is reproduced. You can verify by running the CoLab yourself.\r\n\r\nSince CoLab runs remotely I hardly think it can be something in my local environment.\r\nI also printed the output of the CoLab here:\r\n[Save-Load-Bug - Colaboratory.pdf](https://github.com/tensorflow/tensorflow/files/3696934/Save-Load-Bug.-.Colaboratory.pdf)\r\n\r\nWDYT?", "@srfrnk,\r\nTried executing the Colab but facing the error, `OSError: Unable to create file (unable to open file: name = './data/titanic_model', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242) `.\r\n\r\nCan you please provide complete information so that we can reproduce it at our end. Thanks!", "@rmothukuru \r\nAre you sure you executed the steps in order and didn't miss any?\r\nThe error you are facing indicates trying to read the files at step 5 with `model = tf.keras.models.load_model('./data/titanic_model')`\r\nHowever the files should have been created by step 4 with `model.save('./data/titanic_model')`\r\nPerhaps you can check that step 4 executed correctly?", "@srfrnk,\r\nThank you for your input. Now I could run your colab without any error. Please find the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/bfaa5d4418f49947c41fc467fc50c3be/33085.ipynb). Can you please recheck at your end. Thanks!", "I am getting the same results still - it fails with the CoLab I create.\r\nHowever the CoLab you sent passes for me - yet I can't see any difference.\r\nIt's very strange as CoLab should behave the same for both of us as it is not run locally.\r\nI am trying to find another (maybe more stable) environment that can replicate the issue.\r\n", "@srfrnk,\r\nCan you please confirm if you have restarted your Run Time of Google Colab and if Possible, restart your machine and check if the issue still persists. Thanks! ", "I can confirm having done so several times.\r\nI've tried something new.\r\nFirst I've switched from `model.save` to the static `tf.keras.models.save_model` to be symmetric to the loading mechanism\r\nAlso I combined the cells into one and renamed the model filepath.\r\nMaybe that would help to make a more stable test case.\r\n\r\nHopefully this time we can both get the same output for the same input.\r\nIf that won't help I can think of using a docker container... WDYT?\r\n\r\n## Steps to reproduce:\r\nGo to [CoLab](https://colab.research.google.com) and click the following button at the bottom right corner:\r\n![screenshot-colab research google com-2019 10 11-10-38-10](https://user-images.githubusercontent.com/1501654/66633316-3b018580-ec13-11e9-9542-7dc453abf34a.png)\r\n\r\nWithin the new notebook that opens - paste the following code inside single cell:\r\n```\r\n!pip3 install --user tensorflow==2.0.0 numpy==1.17.2 gast==0.2.2 matplotlib pandas pathlib pyyaml h5py\r\n!rm -rf ./model\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pathlib\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport functools\r\nfrom collections import OrderedDict\r\n\r\nprint(tf.version.VERSION)\r\nprint(tf.keras.__version__)\r\nprint(np.__version__)\r\n\r\npd.set_option('display.max_rows', 1000)\r\n\r\nds = tf.data.Dataset.from_tensor_slices(\r\n    (OrderedDict([('Feature',tf.ones(shape=(1000)))]),tf.ones(shape=(1000)))\r\n).batch(10).repeat()\r\n\r\nmodel = tf.keras.Sequential([\r\n    layers.DenseFeatures([tf.feature_column.numeric_column('Feature')], name='features'),\r\n    layers.Dense(100, activation='relu', name='hidden3'),\r\n    layers.Dense(1, activation='sigmoid', name='outputs')\r\n])\r\n\r\nmodel.compile(optimizer=keras.optimizers.Adam(),\r\n              loss=keras.losses.BinaryCrossentropy(),\r\n              metrics=[keras.metrics.BinaryAccuracy()])\r\nmodel.fit(ds, epochs=1, steps_per_epoch=10)\r\ntf.keras.models.save_model(\r\n    model=model,\r\n    filepath='./model',\r\n    overwrite=True,\r\n    include_optimizer=True,\r\n    save_format='tf')\r\n\r\nmodel = tf.keras.models.load_model('./model')\r\nmodel.fit(ds, epochs=1, steps_per_epoch=10)\r\ntf.keras.models.save_model(\r\n    model=model,\r\n    filepath='./model',\r\n    overwrite=True,\r\n    include_optimizer=True,\r\n    save_format='tf')\r\n\r\nmodel = tf.keras.models.load_model('./model')\r\nmodel.fit(ds, epochs=1, steps_per_epoch=10)\r\ntf.keras.models.save_model(\r\n    model=model,\r\n    filepath='./model',\r\n    overwrite=True,\r\n    include_optimizer=True,\r\n    save_format='tf')\r\n```\r\n\r\n\r\nRun the cell, wait until it shows the following and click the button :\r\n![screenshot-colab research google com-2019 10 11-10-41-48](https://user-images.githubusercontent.com/1501654/66633569-c7ac4380-ec13-11e9-8fdc-6d1bb4045e80.png)\r\n\r\nAfter notebook reconnects, run the cell again until completion.\r\n\r\nYou should see he following:\r\n![screenshot-colab research google com-2019 10 11-10-56-50](https://user-images.githubusercontent.com/1501654/66634493-ddbb0380-ec15-11e9-89a5-9422a1f81824.png)\r\n", "@srfrnk,\r\nI could reproduce the issue now. Can you please refer [this link](https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model)  and let us know if it helps. Thanks!", "@rmothukuru \r\nThanks for your input.\r\nI can't see how the link relates to this issue.\r\nI don't see they use load/save in any way and other then that the code very similar. \r\nCould you please elaborate?", "Could reproduce the issue with TF Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/27bd49c7c30c290e14324bbe1e634787/33085.ipynb). Thanks!", "@srfrnk I think this is not related to model saving. I have tried with the simple and official tensorflow model, and I dont see any issue in loading, training, and saving multiple times. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/eaa7d0c57faa6016016164e9e72f56da/keras_model_saving_multipletimes.ipynb).\r\n\r\nHaving said that, I think this is more related to usage of `tf.data.dataset` or `FeatureLayer`. Thanks!\r\n", "@jvishnuvardhan \r\nCan you suggest a workaround?\r\nAs far as I understand both `tf.data.dataset` and `FeatureLayer` are still supported in TF2.0 am I missing something?\r\nShould saving and loading a model using these not be consistent?", "I can verify that I have the same issue using a model with DenseFeatures with feature_columns.", "Can confirm this reproduces in TF2.0 on macOS, and that the second fit call isn't necessary to reproduce, i.e. save->load->save->load breaks.", "@kevinykuo Did you use `tf.data.dataset` and `Feature_columns` in your code? Can you please share a standalone code to reproduce the issue? Thanks!", "I'm encountering this issue with TF 2.1 and getting a different traceback from the ones posted here, but this is just on trying to save twice. Check out this [gist](https://gist.github.com/zmjjmz/ade6ecb5eaf011788b1da62db4413cad)\r\n\r\nNot sure if being on Python 3.5 is a problem, but I'm also using feature columns here. While saving twice doesn't seem like a real usecase, it comes up inherently in some DAG caching logic this model is a part of.\r\n\r\nSo there's two things I find frustrating about this:\r\n1) It seems like the `save` function is mutating the state of the in-memory object, which I'm not sure is intentional and if it is it's, IMO, bad semantics\r\n2) For the same reason I'm running into this, I can't use `copy.deepcopy` as a workaround because it apparently relies on pickling behavior\r\n\r\nHas there been any progress on this issue?", "@srfrnk using the colab gist posted [here](https://github.com/tensorflow/tensorflow/issues/33085#issuecomment-541718214)\r\nand tensorflow==2.2.0-rc1, I do not see the multiple save/load issue anymore. \r\n\r\nCan you please verify on your end and close this issue if it works for your use case ?\r\n\r\n@zmjjmz please file a new GitHub issue with a standalone repro snippet. Thanks!", "@srfrnk closing this issue as we believe it is fixed with 2.2.0-rc1 and the latest tf-nightly. PLease feel free to reopen if the issue is not resolved for you. Thanks!", "I'm trying it with today's (apr 1st 2020) nightly build. Still seeing this issue. "]}, {"number": 33084, "title": "how to change version of protobuf when I compile source code of tensorflow1.9 by bazel", "body": "I want to compile source code of tensorflow-1.9 for c library. When I compile the source code of tensorflow1.9 through bazel, it downloaded and used protobuf3.5 during the compilation process. How to modify the code can be downloaded and used protobuf3.4.1 during the compilation process.", "comments": ["@liupengkd,\r\nCan you please let us know the operating system which you are using. Also, can you please provide reproducible code. Can you please let us know the specific reason why you want to use Tensorflow 1.9, and why you are not using Tensorflow 1.14 or 1.15. Thanks!", "My operating system is ubuntu 16.04.The reason why I use tensorflow 1.9 is client needs\u3002\r\nsource code tensorflow1.9/tensorflow/workspace.bzl:\r\n  tf_http_archive(\r\n      name = \"protobuf_archive\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n      ],\r\n      sha256 = \"846d907acf472ae233ec0882ef3a2d24edbbe834b80c305e867ac65a1f2c59e3\",\r\n      strip_prefix = \"protobuf-396336eb961b75f03b25824fe86cf6490fb75e3a\",\r\n  )\r\n\r\n  # We need to import the protobuf library under the names com_google_protobuf\r\n  # and com_google_protobuf_cc to enable proto_library support in bazel.\r\n  # Unfortunately there is no way to alias http_archives at the moment.\r\n  tf_http_archive(\r\n      name = \"com_google_protobuf\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n      ],\r\n      sha256 = \"846d907acf472ae233ec0882ef3a2d24edbbe834b80c305e867ac65a1f2c59e3\",\r\n      strip_prefix = \"protobuf-396336eb961b75f03b25824fe86cf6490fb75e3a\",\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_google_protobuf_cc\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n      ],\r\n      sha256 = \"846d907acf472ae233ec0882ef3a2d24edbbe834b80c305e867ac65a1f2c59e3\",\r\n      strip_prefix = \"protobuf-396336eb961b75f03b25824fe86cf6490fb75e3a\",\r\n  )", "Please post code snippets using proper markdown format, so that they are easy to read.\r\n\r\nIn this particular case, as protobuf is tied with Bazel version, you have to use [the same Bazel version as that one used to build 1.9](https://www.tensorflow.org/install/source#linux)", "@tensorflowbutler I have used the default protobuf\u2018version-3.5 not used 3.4", "So this is solved?", "I think I skipped this question. I originally wanted to change the version of protobuf used to compile tensorflow by modifying the workspace.bzl file inside tensorflow.", "@liupengkd Is this still an issue for you? Can you please try new TF version and let us know whether it is an issue with new version also? Thanks!\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33084\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33084\">No</a>\n"]}, {"number": 33083, "title": "hub.module_v2.load() returns a non-callable object", "body": "**System information**\r\n- tf version: 2.0.0 gpu\r\n- tf_hub version: 0.6\r\n- python: 3.7 with Anaconda\r\n\r\n```python\r\nmodel = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/3\" # MobileNetV2\r\n# both lines below cannot work\r\nlayer = hub.KerasLayer(model)\r\nlayer = hub.KerasLayer(model, tags=\"train\")\r\n```\r\nError messages are long, but those related to the issue are below:\r\n```python\r\n~\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_hub\\keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)\r\n    102       self._func = handle\r\n    103     else:\r\n--> 104       self._func = module_v2.load(handle)\r\n    105       if not callable(self._func):\r\n    106         raise ValueError(\"Non-callable result from hub.load('%s')\" %\r\n```\r\n```python\r\nValueError: Importing a SavedModel with tf.saved_model.load requires a 'tags=' argument if there is more than one MetaGraph. Got 'tags=None', but there are 2 MetaGraphs in the SavedModel with tag sets [[], ['train']]. Pass a 'tags=' argument to load this SavedModel.\r\n```\r\nthen I realized if we just directly use `hub.KerasLayer()`, the `'tags='` argument will not be passed to `module_v2.load()`, which causes this error.\r\nSo then I modified the codes as below:\r\n```python\r\nmodel = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/3\"\r\nmod = hub.module_v2.load(model,tags=['train']) # this line works fine\r\nlayer = hub.KerasLayer(mod) # error here\r\n```\r\nHowerver, this won't work, either. The error messages related to the error are:\r\n```\r\n~\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_hub\\keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)\r\n    102       self._func = handle\r\n    103     else:\r\n--> 104       self._func = module_v2.load(handle)\r\n    105       if not callable(self._func):\r\n    106         raise ValueError(\"Non-callable result from hub.load('%s')\" %\r\n```\r\nand\r\n```python\r\nAttributeError: 'AutoTrackable' object has no attribute 'startswith'\r\n```\r\nIt seems that it is related to the code in `keras_layer.py` and specificly codes below:\r\n```python\r\ndef __init__(self, handle, trainable=False, arguments=None, **kwargs):\r\n    self._handle = handle\r\n    # Resolve the handle to a callable `func`.\r\n    if callable(handle):\r\n      self._func = handle\r\n    else:\r\n      self._func = module_v2.load(handle)\r\n      if not callable(self._func):\r\n           raise ValueError(\"Non-callable result from hub.load('%s')\" %\r\n                         str(handle))\r\n```\r\nWhen I pass the `mod` object to `hub.KerasLayer()`, the code in `if` branch is expected to be executed, but the code in `else` branch is executed, which means the `mod` object returned by  `module_v2.load()` is not `callable`. That doesn't make sense. \r\nSo I wonder maybe it is a bug or there's something wrong with the `MobileNet` model or it just that the model doesn't fit in TF2.0.", "comments": ["@ifsheldon,\r\nThis issue is not related to Tensorflow, but it is related to Tensorflow Hub. Request you to raise an issue in [Tensorflow Hub Repo](https://github.com/tensorflow/hub/issues).  Thanks!", "> @ifsheldon,\r\n> This issue is not related to Tensorflow, but it is related to Tensorflow Hub. Request you to raise an issue in [Tensorflow Hub Repo](https://github.com/tensorflow/hub/issues). Thanks!\r\n\r\nSorry, and thanks."]}, {"number": 33082, "title": "tf.data.Dataset.from_generator is not executing eagerly ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2\r\n- Python version: 3\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.data.Dataset.from_generator` method is not hydrating the dataset eagerly.  When a dataset is created using this method an instance of `DatasetV1Adapter` is returned rather than `DataSet`. \r\n\r\n**Describe the expected behavior**\r\n\r\nShould return a `Dataset` [Reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L510)\r\n\r\n**Code to reproduce the issue**\r\n\r\n[Colab link](https://colab.research.google.com/drive/1jPS1oVrFlWOzJmUFCaDMFwVUVbg9V1NK)\r\n\r\n```\r\n\r\n# Set up and ensure tf is executing eagerly\r\n\r\n\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\nprint(tf.executing_eagerly())\r\n\r\n# Define a generator function and create dataset\r\n# you would expect ds have data after from_generator method as it's expected to execute eagerly, but data generation logs are not printed\r\n\r\ndef gen():\r\n  print('Log: generating data')\r\n  for i in range(0,5):\r\n    yield (i, [1] * i)\r\n\r\nds = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), (tf.TensorShape([]), tf.TensorShape([None])))\r\ntf.print(ds)\r\n\r\n# Use dataset\r\n# Logs are printed here\r\n\r\nfor (x,y) in ds:\r\n  tf.print(x, y)\r\n\r\n# Use ds one more time\r\n# Now ds is hydrated but generator function is invoked again\r\n\r\nx = ds.take(3)\r\nprint(x)\r\nfor value in x:\r\n  tf.print(value)\r\n\r\n```", "comments": ["@muleyprasad,\r\n`DatasetV1Adapter` is representation of `Dataset`.\r\n\r\nPlease refer [this code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L1916-L1918),  Thanks!", "Ok. Then I believe DatasetV1Adapter is just holding the reference of the generator function so data can be generated for any iter like operation rather than loading it eagerly inline as other load data methods would do, is it correct?", "Could reproduce with Tensorflow Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/0a08de564446dddc5d3f519ec4460e54/33082.ipynb#scrollTo=wTIeK-qM8wox).", "@muleyprasad `tf.data.Dataset.from_generator ` Creates a Dataset whose elements are generated by generator. And Dataset is always loaded lazily as you can see [here](# Loaded lazily due to a circular dependency (roughly). So, its not a surprise here and the answer for your question is \"yes\"."]}, {"number": 33081, "title": "why my coco_output.txt (output of evaluation coco object detection with tflite models)is empty!!!!!! ", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:samsung s8 pluse\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.15\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.26.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:NO CUDA\r\n- GPU model and memory:NO GPU\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@Davari393,\r\n In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33080, "title": "Until Tensorflow 2.0, there had been an instance norm layer in tf.contrib.layers - please bring it back", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0:\r\n- Are you willing to contribute it: Yes:\r\n\r\nThere's already the code for this layer in tensorflow 1.14, and (with a bit less parameter choice) in pix2pix example in tensorflow 2.0, It's trivial to add this layer to tensorflow.keras.layers, and I'm willing to do it.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nInstance norm was found to be[ more effective](https://arxiv.org/abs/1607.08022) than any other form of normalization for convolutional neural networks with small batches.\r\n\r\nIt is used in tensorflow's [official example for pix2pix ](https://www.tensorflow.org/tutorials/generative/pix2pix), and was present in tf.contrib.layers in [tensorflow 1.14](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/contrib/layers/instance_norm).\r\n\r\nInstance norm is normalizes each channel according to the channel's spatial mean and standard deviation. \r\n\r\n**Will this change the current api? How?**\r\nAdd tensorflow.keras.layers.InstanceNormalization\r\n\r\n**Who will benefit with this feature?**\r\nAnyone who's working on a CNN with small batches.\r\n\r\n", "comments": ["Hello, instance normalization layer has been moved to tensorflow-addons.\r\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/normalizations.py#L277", "@WindQAQ does not support Windows...", "@feature-engineer,\r\nCan you please let us know if @WindQAQ's comment has answered your query. If not, can you please give more details. Thanks!  ", "@rmothukuru If tensorflow-addons was working on Windows, it would have been a viable solution. As it stands, windows users of tensorflow face a regression from the 1.14 version.", "@feature-engineer Is this https://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/normalizations.py#L277\r\n\r\nnot working on windows?", "@gowthamkpr Not yet:\r\n\r\nhttps://github.com/tensorflow/addons/issues/173", "@gowthamkpr \r\nbesides `tf.contrib.layers` everything that was moved to `tensorflow-addons` causes a blocking regression for people that used it on windows and would otherwise move to `tf@2`", "@amitport @feature-engineer Thanks for the report. Will  keep you updated on this part.", "@seanpmorgan Any updates on the support to windows. Thanks!", "> @seanpmorgan Any updates on the support to windows. Thanks!\r\n\r\nHi @gowthamkpr please follow this issue for updates: https://github.com/tensorflow/custom-op/issues/24\r\n\r\nThere has been a to-do list proposed to make windows custom-ops work.. just waiting for the issue to be complete and then addons will follow suit.", " I am  closing this issue as of now as it has been tracked already. Please follow the issue mentioned by Sean and we will update you as soon as the work is done. Thanks!"]}, {"number": 33079, "title": "make_csv_dataset with num_epochs=1,2,... (finite) produces (None,) shape tensors", "body": "The following CoLab and Github Gist show the issue:\r\n[CoLab](https://colab.research.google.com/gist/srfrnk/5744026f803b57254b5ba6162dd16bf8/csv.ipynb)\r\n[Github Gist](https://gist.github.com/srfrnk/5744026f803b57254b5ba6162dd16bf8#file-csv-ipynb)\r\n\r\nIt is expected that the same shape will be returned regardless of num_epochs.\r\nCurrently if num_epochs=1 the returned tensors all have shape (None,)\r\nOnly when num_epochs=None meaning infinite repeat will the correct shape be returned.\r\n", "comments": ["From the docstring:\r\n> A dataset, where each element is a (features, labels) tuple that corresponds\r\n    to a batch of `batch_size` CSV rows.\r\n\r\nSo I guess you would expect to have elements with shape `batch_size`?\r\n\r\n-- The following is explained more concisely (and precisely for your case) [here](https://github.com/tensorflow/tensorflow/blob/4aa790771fef28b68cb7703e72a0824e12c3732a/tensorflow/python/data/experimental/ops/readers.py#L547) in the source code. Shape inference has lots to do with buffered reading and prefetching, in order to achieve good performance, but I won't get into details. You can find more [here](https://www.tensorflow.org/guide/data_performance), for example. --\r\n\r\nOn the one hand, when `num_epochs` is `None`, the dataset loops indefinitely, so shape inference can be done at this step: one can be certain there will not be any incomplete batch since there is a potentially infinite amount of data rows. Thus, every batch will contain exactly `batch_size` elements (static, constant shape).\r\nOn the other hand, when `num_epochs` is an integer, one cannot be sure every batch will have exactly `batch_size` elements (e.g. the last batch in your epoch), so the shape is dynamic, and hence the use of `None`.\r\n\r\nMoreover, when using the elements from, for example, the `TakeDataset` you have created in your example, shape is dynamically inferred and shown:\r\n\r\n```python\r\n>>> for el in ds1: print(el)\r\nOrderedDict([('PassengerId', <tf.Tensor: id=2278, shape=(1,), ...])\r\n```\r\n\r\nCould you explain why this would be an issue/bad practice in a common use case?", "@CarMiranda Thanks for your  input.\r\nIndeed I would expect the tensors to be of shape (`batch_size`,..)\r\nThe `batch_size` should be already defined he same way for when `num_epochs` is None or a finite number am I wrong?\r\nIf so - the tensors returned should at least have the `batch_size` as a \"known\" dimension. You might argue about the other dimensions for sure but not the first one. Am I wrong?\r\n\r\nIn my case I was using the tensor shape to create a zeros tensor with the same shape.\r\nThis code worked for the train set - read with repeat - but failed for the prediction set which was read without repeat.\r\n\r\nI did solve my issue by using the tensorflow.shape(...) function which returned a dynamic shape and I passed that into tensorflow.zeros(...) instead. \r\n\r\nI still think this is a bug that might hinder someone in the future.", "> If so - the tensors returned should at least have the `batch_size` as a \"known\" dimension. You might argue about the other dimensions for sure but not the first one. Am I wrong?\r\n\r\nActually, in most cases, I personally would expect all of the other dimensions to be known, but not the batch size... For example, when loading the MNIST data set from `tensorflow_datasets` and using `batch(N)`, the batch dimension is `None`, not `N`. In fact, columns/variables/features/image dimensions are something that remain constant over time, while the number of rows in a data set does not.\r\n\r\nThe method `make_csv_dataset` behaves like `tf.data.Dataset.batch(batch_size, drop_remainder=False)` when `num_epochs` is set (so it uses dynamic shaping) and like `tf.data.Dataset.bacth(batch_size, drop_remainder=True)` when `num_epoch=None`, which is the expected/standard behaviour. You can see [this](https://github.com/tensorflow/tensorflow/issues/18226) issue (#18226) which led to the `drop_remainder` option.\r\n\r\nSome more practical considerations: Say my data set contains 10 columns and 10 000 rows. I set batch_size=64 because that's a nice value in my case (e.g. taking hardware into account). After 156 batches, my model has seen 9 984 rows, training on fully-sized batches of 64 rows. But right at the end, the last batch has only 16 rows. What do we fill the rest of the tensor with? Zeros? Ones? Random rows? Or should we just drop these from the training? (which is an option in the `tf.data.Dataset.batch(batch_size, drop_remainder)` method, from which `make_csv_dataset` makes use). Well, with dynamic batch size, that is no problem, we just set `batch_size=16` when needed.\r\n\r\nBut hey, I could set `batch_size=50`, or any other divisor of 10 000 and the problem is gone. However, I would be bounding the model training to a specific (version of the) data set. If the data set evolves and adds 1234 rows, then I would have to change the `batch_size`. I could even get more rows in the dataset _while_ training, between epochs: in production, number of rows can vary as data comes in.\r\n\r\n---\r\n\r\n> In my case I was using the tensor shape to create a zeros tensor with the same shape.\r\n\r\nIs there any reason not to use `new_tensor = tf.zeros_like(tensor_to_copy)`?", "So basically you mean that tensor shapes should be undetermined with various use cases. I would think it should be mentioned in the docs at least?", "@srfrnk Sorry for the late response. Is this still an issue for you? If this was already resolved for you then please close the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33078, "title": "Issue while compiling with AdamOptimizer", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `model.compile(optimizer=tf.train.AdamOptimizer(),\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy']) `\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): Tensorflow -gpu from Anaconda\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: Nvidia GeForce 1050Ti 4gb DDR5 VRAM\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n`\r\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From convo.py:27: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n**Describe the expected behavior**\r\nNot expected warnings in the usage of AdamOptimizer. The code executed is working yet error is thrown on every execution\r\n`\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Have you tried :\r\n`model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`", "As of 2.0, optimizers have been unified under the keras submodule; you therefore should use `tf.keras.optimizers.Adam` instead of the deprecated `tf.train.AdamOptimizer`. This is also what happens if you use `optimizer='adam'` as suggested by @hagianga21 although instantiating the optimizer yourself allows you to tweak its parameters.", "@iamknownstranger, Use `tf.compat.v1.train.AdamOptimizer` instead of `tf.train.AdamOptimizer`.\r\n`tf.train.AdamOptimizer` is deprecated. Thanks!  \r\nPlease change the code as\r\n`model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])`.\r\nThanks!\r\n", "@iamknownstranger, Is this still an issue. Thanks!", "Closing this issue since its resolved. Thanks!"]}, {"number": 33077, "title": "TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution ( Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.14\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):0.19\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0  7\r\n- GPU model and memory: V100 32G\r\n\r\nYou can collect some of this information using our environment capture\r\n\r\nNGC images 1904\r\n\r\n**Describe the current behavior**\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\n\r\ndef _train(total_loss, global_step):\r\n  \"\"\"Train CIFAR-10 model.\r\n\r\n  Create an optimizer and apply to all trainable variables. Add moving\r\n  average for all trainable variables.\r\n\r\n  Args:\r\n    total_loss: Total loss from loss().\r\n    global_step: Integer Variable counting the number of training steps\r\n      processed.\r\n  Returns:\r\n    train_op: op for training.\r\n  \"\"\"\r\n  # Variables that affect learning rate.\r\n  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\r\n  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\r\n\r\n  # Decay the learning rate exponentially based on the number of steps.\r\n  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\r\n                                  global_step,\r\n                                  decay_steps,\r\n                                  LEARNING_RATE_DECAY_FACTOR,\r\n                                  staircase=True)\r\n  tf.summary.scalar('learning_rate', lr)\r\n\r\n  # Generate moving averages of all losses and associated summaries.\r\n  #loss_averages_op = _add_loss_summaries(total_loss)\r\n  loss_averages_op = total_loss\r\n\r\n  # Compute gradients.\r\n  with tf.control_dependencies([loss_averages_op]):\r\n    opt = tf.train.GradientDescentOptimizer(lr)\r\n    opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\r\n    grads = opt.compute_gradients(total_loss)\r\n\r\n  # Apply gradients.\r\n  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\r\n  #apply_gradient_op=opt.minimize(total_loss)\r\n  #apply_gradient_op = tf.train.GradientDescentOptimizer(lr).minimize(total_loss,global_step=global_step)\r\n\r\n  # Add histograms for trainable variables.\r\n  for var in tf.trainable_variables():\r\n    tf.summary.histogram(var.op.name, var)\r\n\r\n  # Add histograms for gradients.\r\n  #for grad, var in grads:\r\n  #  if grad is not None:\r\n  #    tf.summary.histogram(var.op.name + '/gradients', grad)\r\n\r\n  # Track the moving averages of all trainable variables.\r\n  variable_averages = tf.train.ExponentialMovingAverage(\r\n      MOVING_AVERAGE_DECAY, global_step)\r\n  with tf.control_dependencies([apply_gradient_op]):\r\n    variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n\r\n  return variables_averages_op\r\n**Other info / logs**\r\n\r\nTraceback (most recent call last):\r\n  File \"cifar_for_common_cnn.py\", line 566, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"cifar_for_common_cnn.py\", line 562, in main\r\n    train()\r\n  File \"cifar_for_common_cnn.py\", line 495, in train\r\n    train_op = _train(loss, global_step)\r\n  File \"cifar_for_common_cnn.py\", line 421, in _train\r\n    grads = opt.compute_gradients(total_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/experimental/loss_scale_optimizer.py\", line 116, in compute_gradients\r\n    loss = self._scale_loss(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/experimental/loss_scale_optimizer.py\", line 134, in _scale_loss\r\n    return loss * loss_scale\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 897, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1180, in _mul_dispatch\r\n    return gen_math_ops.mul(x, y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 6490, in mul\r\n    \"Mul\", x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 563, in _apply_op_helper\r\n    inferred_from[input_arg.type_attr]))\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n", "comments": ["@wpf19911118, Please provide the standalone code to reproduce the reported issue. Thanks!", "@wpf19911118, Please provide more information to reproduce the reported issue. Thanks!", "`import tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.datasets import mnist\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n    try:\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUS,\", len(logical_gpus), \"Logical GPUS\")\r\n    except RuntimeError as e:\r\n        print(e)\r\n\r\ntf.keras.backend.set_floatx('float16')\r\ntf.keras.backend.set_epsilon(1e-4)\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\r\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\r\n\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\r\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\r\n\r\nmodel.summary()\r\n\r\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n\r\ntrain_images = train_images.reshape((60000, 28, 28, 1))\r\ntrain_images = train_images.astype(np.float16) / 255\r\n\r\ntest_images = test_images.reshape((10000, 28, 28, 1))\r\ntest_images = test_images.astype(np.float16) / 255\r\n\r\ntrain_labels = tf.keras.utils.to_categorical(train_labels, dtype='float16')\r\ntest_labels = tf.keras.utils.to_categorical(test_labels, dtype='float16')\r\n\r\nopt = tf.keras.optimizers.RMSprop()\r\nopt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, \"dynamic\")\r\n\r\nmodel.compile(optimizer=opt,\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(tf.dtypes.cast(train_images, tf.float16), tf.dtypes.cast(train_labels, tf.float16), epochs=50, batch_size=64, steps_per_epoch=200)\r\n\r\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\r\n\r\ntest_acc`\r\nThis code will reproduce the issue with tensorflow 2.0", "@mattbernardini, Is this similar issue [#33484](https://github.com/tensorflow/tensorflow/issues/33484). Thanks", "This is the error message that i get when i run the code if that is what you are asking, so i would assume that they are similar.", "@wpf19911118,Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\n@mattbernardini, Will track the resolution [#33484](https://github.com/tensorflow/tensorflow/issues/33484). Thanks!", "The error points to this line of code:\r\n\r\ncross_entropy = -y_true * K.log(y_pred)\r\nand is being thrown from the multiply function in math_ops.py within the tensorflow package. Digging into that file it is found that this summary for the argument requirements.\r\n\r\n \r\n\r\nArgs:\r\n    x: A Tensor. Must be one of the following types: `bfloat16`,\r\n      `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\r\n      `int16`, `int32`, `int64`, `complex64`, `complex128`.\r\n    y: A `Tensor`. Must have the same type as `x`.\r\n    name: A name for the operation (optional).\r\n  Returns:\r\n  A `Tensor`.  Has the same type as `x`.\r\n  Raises:\r\n   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types\r\n\r\nThis means that -y_true is 'y' and K.log(y_pred) is 'x'. To perform this operations you'll have to cast -y_true to a float32 or cast K.log(y_pred) to an int64 or cast them both into any other type as long as they match. .\r\n\r\nIt is Working now by doing ``` y_true = tf.cast(y_true, tf.float32) ``` > \r\n", "> The error points to this line of code:\r\n> \r\n> cross_entropy = -y_true * K.log(y_pred)\r\n> and is being thrown from the multiply function in math_ops.py within the tensorflow package. Digging into that file it is found that this summary for the argument requirements.\r\n> \r\n> Args:\r\n> x: A Tensor. Must be one of the following types: `bfloat16`,\r\n> `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\r\n> `int16`, `int32`, `int64`, `complex64`, `complex128`.\r\n> y: A `Tensor`. Must have the same type as `x`.\r\n> name: A name for the operation (optional).\r\n> Returns:\r\n> A `Tensor`. Has the same type as `x`.\r\n> Raises:\r\n> \r\n> * InvalidArgumentError: When `x` and `y` have incompatible shapes or types\r\n> \r\n> This means that -y_true is 'y' and K.log(y_pred) is 'x'. To perform this operations you'll have to cast -y_true to a float32 or cast K.log(y_pred) to an int64 or cast them both into any other type as long as they match. .\r\n> \r\n> It is Working now by doing `y_true = tf.cast(y_true, tf.float32)` >\r\n\r\n", "> > The error points to this line of code:\r\n> > cross_entropy = -y_true * K.log(y_pred)\r\n> > and is being thrown from the multiply function in math_ops.py within the tensorflow package. Digging into that file it is found that this summary for the argument requirements.\r\n> > Args:\r\n> > x: A Tensor. Must be one of the following types: `bfloat16`,\r\n> > `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\r\n> > `int16`, `int32`, `int64`, `complex64`, `complex128`.\r\n> > y: A `Tensor`. Must have the same type as `x`.\r\n> > name: A name for the operation (optional).\r\n> > Returns:\r\n> > A `Tensor`. Has the same type as `x`.\r\n> > Raises:\r\n> > \r\n> > * InvalidArgumentError: When `x` and `y` have incompatible shapes or types\r\n> > \r\n> > This means that -y_true is 'y' and K.log(y_pred) is 'x'. To perform this operations you'll have to cast -y_true to a float32 or cast K.log(y_pred) to an int64 or cast them both into any other type as long as they match. .\r\n> > It is Working now by doing `y_true = tf.cast(y_true, tf.float32)` >\r\n\r\nI try to cast K.log(y_pred) to int32 but it did not work. here is the error message\r\nSyntaxError: can't assign to function call\r\n\r\nanybody knows why? please i need help"]}, {"number": 33076, "title": "Cannot understand class_weight", "body": "**Describe the current behavior**\r\nHi, how actually does class_weight in model.fit works? Does it multiple to loss function? I cannot find it in source code. If I set class_weight = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9:0}. The loss is not equal 0.\r\n", "comments": ["@hagianga21,\r\nPlease provide the standalone code to reproduce the issue. and also provide the Tensorflow version. Thanks!", "@hagianga21, Provide more information about issue like code snippet and Tf version.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33075, "title": "tf.keras works, tf.python.keras doesn't", "body": "**DOESN'T WORK**:\r\n```python\r\nfrom tensorflow.python.keras.layers import Input, Dense\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.optimizers import Nadam\r\n\r\nipt = Input(shape=(4,))\r\nout = Dense(1, activation='sigmoid')(ipt)\r\n\r\nmodel = Model(ipt, out)\r\nmodel.compile(optimizer=Nadam(lr=1e-4), loss='binary_crossentropy')\r\n\r\nX = np.random.randn(32,4)\r\nY = np.random.randint(0,2,(32,1))\r\nmodel.train_on_batch(X,Y)\r\n```\r\n**WORKS**: remove `.python` from above's imports. Above's error trace below.\r\n\r\nKeras 2.3.0 and TensorFlow 2.0.0 freshly-installed via Anaconda, older versions uninstalled. Why the difference?\r\n\r\n<hr>\r\n\r\n```python\r\n\r\n  File \"<ipython-input-7-1e86d21d8fc4>\", line 13, in <module>\r\n    model.train_on_batch(X,Y)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1017, in train_on_batch\r\n    self._make_train_function()\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2116, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizers.py\", line 653, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizers.py\", line 92, in get_gradients\r\n    if None in grads:\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 1336, in tensor_equals\r\n    return gen_math_ops.equal(self, other)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 3627, in equal\r\n    name=name)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 545, in _apply_op_helper\r\n    (input_name, err))\r\n\r\nValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.\r\n```\r\n<hr>\r\n\r\n**UPDATE:** Debugging the two side-by-side, while both use the [same files](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L1008), execution diverges fairly quickly:\r\n\r\n```python\r\n# .\\tensorflow_core\\python\\keras\\engine\\training.py\r\n\r\n### TF.KERAS\r\n    if self._experimental_run_tf_function: #  TRUE\r\n\t\r\n### TF.PYTHON.KERAS\r\n    if self._experimental_run_tf_function: #  FALSE\r\n```\r\nFormer proceeds to call `training_v2_utils.train_on_batch(...)` and returns thereafter, latter `self._standardize_user_data(...)` and others before ultimately failing. \r\n\r\nOne difference I noted between linked file and mine is, latter's short by ~100 lines - though I installed TF 2 via pip after the file's last update 12 days ago according to Github.", "comments": ["The \"one difference\" was the key; pip failed - downloaded manually. Looking forward to Anaconda support.", "Nope, wasn't it - somehow made it temporarily work, then something else broke, then couldn't get it to work again with several fresh re-installs. Pip also fails to fetch Github's TensorFlow master branch. Likely a bug. Related [SO](https://stackoverflow.com/questions/58261348/valueerror-tried-to-convert-y-to-a-tensor-and-failed-error-none-values-not)", "> `Keras 2.3.0 and TensorFlow 2.0.0 freshly-installed`\r\n\r\nThis is a side note to your issue, but with tensorflow 2.0 you are not using the separate keras package (instead, you are using the keras implementation embarked within tensorflow).\r\n\r\nThat being said, the imports should work, both with and without specifying `.python.`. In general, if you place yourself as a user, I think you had better import from `tensorflow.keras`, which is the intended public display of tensorflow's submodules (if you simply `import tensorflow`, you have access to `tensorflow.keras`, but not to `tensorflow.python`). The `python` term in the imports refers to the source code organization, and is therefore preferably used when writing source code (which then uses utility functions to reformat its public naming at import time), although you may sometimes need to use it to access specific back-end functionalities which are normally not made public.", "@OverLordGoldDragon,\r\nPlease use tf.keras instead of tf.python.keras. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/5913c06c783100a1c1b9c9fb5d8bf2bc/untitled184.ipynb). Thanks! ", "@gadagashwini Your gist is already in my original post - my question concerns _why_ `tf.python.keras` fails (it shouldn't)", "TL;DR: The API import is in the root of the package. Any other import is just Python allowing you to access privates with no consideration for good coding practices.\r\n\r\nLong story short:\r\n\r\nThe only way that imports should be are \r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.keras....\r\n```\r\n\r\nWe also provide support for\r\n\r\n```python\r\nfrom tensorflow.keras import ...\r\n```\r\n\r\nthough this is brittle and can break as we keep refactoring.\r\n\r\nImporting from `tensorflow.python` or any other modules (including `import tensorflow_core...`) is not supported, and can break unannounced.", "@mihaimaruseac That's fair, except `tf.keras` itself is full of imports from `tf.python.keras` - and making custom optimizers often requires imports from either of the two, which still ultimately import from `tf.python.keras`. It occurred with me while building a custom optimizer - making it compatible with `optimizer_v2` thus implies dealing with `tf.python.keras` and all its music. So even if it's dev-only, dev's still bug-prone - and I've opened a [PR](https://github.com/tensorflow/tensorflow/pull/33097) per this thread's bug.\r\n\r\nRegardless, your answer may be the real one here; so to confirm, `tf.python.keras` is _private_, intended for _development_, rather than public use? Thanks", "> Regardless, your answer may be the real one here; so to confirm, tf.python.keras is private, intended for development, rather than public use? Thanks\r\n\r\nYes, that's exactly the case. Anything under `tf.python` is private", "Surely something which can silently do different behavior needs warning signs all over it\r\n```\r\nimport tensorflow.keras.backend as K\r\n````\r\nImports keras\\api\\\\_v2\r\n\r\nvs\r\n\r\n```\r\nimport tensorflow as tf\r\nK = tf.keras.backend\r\n```\r\nImports keras\\api\\\\_v1\r\n\r\nThis is in V1.15.3", "@LukeBolly Fair suggestion; this can be done by overriding `__getattr__`:\r\n\r\n```\r\n# insert at bottom of `tensorflow/__init__.py`\r\n_keras = keras\r\ndel keras\r\n\r\ndef __getattr__(name):\r\n    if name == 'keras':\r\n        import warnings\r\n        warnings.warn(\"Using `tf.keras` is not recommended; use \"\r\n                      \"`from tensorflow.keras import` instead.\")\r\n        return _keras\r\n    raise AttributeError(\"module `tensorflow` has no attribute %s\" % name)\r\n```\r\n(Note: `del keras` is to bypass Python's [special lookup](https://docs.python.org/3/reference/datamodel.html#special-lookup))"]}]