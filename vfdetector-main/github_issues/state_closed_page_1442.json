[{"number": 9703, "title": "pkg-config file generation", "body": "Hi! I was wondering if a pkg-config file for the tensorflow library (`libtensorflow.so`) could be added so that depending projects could use it more easily.\r\n\r\nFor the current stable version (`1.1.0`), if we installed it into `/usr` (which should be configurable), the generated pkg-config file `tensorflow.pc` should look something like:\r\n```\r\nprefix=/usr\r\nexec_prefix=${prefix}\r\nlibdir=${exec_prefix}/lib\r\nincludedir=${prefix}/include\r\nmodules=1\r\n\r\nName: tensorflow\r\nVersion: 1.1.0\r\nDescription: Library for computation using data flow graphs for scalable machine learning\r\nRequires:\r\nLibs: -L${libdir} -ltensorflow -lstdc++\r\nCflags: -I${includedir}/tensorflow\r\n```\r\nThanks in advance :)", "comments": ["I'd like to make a pull request, but I don't know how you would prefer this to be implemented.\r\nI've just written a small shell script that generates this pkconfig file for a given prefix.\r\nIt coud be run as `./generate-pc.sh /usr`:\r\n```bash\r\n#!/usr/bin/env bash\r\n\r\nTF_VERSION=`grep Release RELEASE.md | head -1 | sed -e 's/# Release //g'`\r\n\r\nif [[ $# == 0 ]]\r\nthen\r\n\techo \"Usage:\"\r\n\techo -e \"\\t$0 install_prefix\"\r\n\texit\r\nfi\r\n\r\nTF_PREFIX=$1\r\n\r\necho \"Generating pkgconfig file for TensorFlow $TF_VERSION in $TF_PREFIX\"\r\n\r\ncat << EOF > tensorflow.pc\r\nprefix=${TF_PREFIX}\r\nexec_prefix=\\${prefix}\r\nlibdir=\\${exec_prefix}/lib\r\nincludedir=\\${prefix}/include\r\nmodules=1\r\n\r\nName: TensorFlow\r\nVersion: ${TF_VERSION}\r\nDescription: Library for computation using data flow graphs for scalable machine learning\r\nRequires:\r\nLibs: -L\\${libdir} -ltensorflow -lstdc++\r\nCflags: -I\\${includedir}/tensorflow\r\nEOF\r\n```\r\nYes, I know, the way I get the version is not the best...", "@yifeif is that something we'd like to have or should it be in a separate repo?", "@asimshankar who knows more about C API distribution :). ", "@arrufat : Thanks for the suggestion. This would be useful for building packaged distributions. Feel free to send a pull request adding your script and we can discuss further there. I would suggest explicitly taking the version as an argument instead of using `grep` over `RELEASE.md` and maybe an appropriate location for this script would be `tensorflow/c/generate-pc.sh`.\r\n\r\nFYI, on OS X using [homebrew](https://brew.sh/), @kali and @ilovezfs have been kind enough to make installation as simple as `brew install libtensorflow` that [includes the pkg-config](https://github.com/Homebrew/homebrew-core/blob/master/Formula/libtensorflow.rb)\r\n", "I guess this can be closed now. Thanks everyone!", "Great!"]}, {"number": 9702, "title": "Installation instructions for conda install tensorflow in the root environment", "body": "The [instructions](https://www.tensorflow.org/install/install_linux#InstallingAnaconda) say to \r\n1. create a new **empty** environment \r\n2. activate it\r\n3. install tensorflow via pip. \r\n\r\nBut pip is not installed in the new environment, so the third command will call the first pip inside the PATH system variable, that usually is the pip installed in the root conda environment. The ultimate result is that tensorflow is installed in the root environment.\r\n\r\nTo solve this issue, it's sufficient to install pip in the new environment:\r\n`conda create --name tensorflow pip`\r\n", "comments": ["I ran into this issue as well, please review my [PR](https://github.com/tensorflow/tensorflow/pull/13554) for fix.", "This PR has been merged.  I'm closing this."]}, {"number": 9701, "title": "Tensorboard does not show any scalers or graphs ", "body": "System information\r\n\r\n    Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\r\n    TensorFlow installed from (source or binary): binary, installed via pip\r\n    TensorFlow version (use command below): 1.1.0\r\n    Bazel version (if compiling from source):na\r\n    CUDA/cuDNN version: na\r\n    GPU model and memory: na\r\n    Exact command to reproduce:?\r\n\r\n\r\n### Describe the problem\r\nInitially I was working with tensorflow 1.0.0 and tensorboard seemed to work just fine. I have updated to 1.1.0 and now it appears it does not display anything anymore. However, I get the warning 'WARNING:tensorflow:path ../external\\data/plugin/text/runs not found, sending 404'. I have also downgraded tensorflow to 1.0.0 and now it also stopped working. \r\n\r\n### Source code / logs\r\n```\r\ntensorboard --inspect --logdir=model_dir\r\nFound event files in: model_dir\r\n\r\nThese tags are in model_dir:\r\naudio -\r\nhistograms\r\n   dnn/dnn/hiddenlayer_0_activation\r\n   dnn/dnn/hiddenlayer_10_activation\r\n   dnn/dnn/hiddenlayer_11_activation\r\n   dnn/dnn/hiddenlayer_1_activation\r\n   dnn/dnn/hiddenlayer_2_activation\r\n   dnn/dnn/hiddenlayer_3_activation\r\n   dnn/dnn/hiddenlayer_4_activation\r\n   dnn/dnn/hiddenlayer_5_activation\r\n   dnn/dnn/hiddenlayer_6_activation\r\n   dnn/dnn/hiddenlayer_7_activation\r\n   dnn/dnn/hiddenlayer_8_activation\r\n   dnn/dnn/hiddenlayer_9_activation\r\n   dnn/dnn/logits_activation\r\nimages -\r\nscalars\r\n   dnn/dnn/hiddenlayer_0_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_10_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_11_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_1_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_2_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_3_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_4_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_5_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_6_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_7_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_8_fraction_of_zero_values\r\n   dnn/dnn/hiddenlayer_9_fraction_of_zero_values\r\n   dnn/dnn/logits_fraction_of_zero_values\r\n   loss\r\ntensor -\r\n======================================================================\r\n\r\nEvent statistics for model_dir:\r\naudio -\r\ngraph\r\n   first_step           0\r\n   last_step            0\r\n   max_step             0\r\n   min_step             0\r\n   num_steps            1\r\n   outoforder_steps     []\r\nhistograms\r\n   first_step           1\r\n   last_step            1\r\n   max_step             1\r\n   min_step             1\r\n   num_steps            1\r\n   outoforder_steps     []\r\nimages -\r\nscalars\r\n   first_step           1\r\n   last_step            1\r\n   max_step             1\r\n   min_step             1\r\n   num_steps            1\r\n   outoforder_steps     []\r\nsessionlog:checkpoint\r\n   first_step           1\r\n   last_step            1\r\n   max_step             1\r\n   min_step             1\r\n   num_steps            1\r\n   outoforder_steps     []\r\nsessionlog:start\r\n   outoforder_steps     []\r\n   steps                [1]\r\nsessionlog:stop -\r\ntensor -\r\n======================================================================\r\n\r\n\r\ntensorboard --logdir=model_dir --host=127.0.0.1\r\nStarting TensorBoard b'47' at http://127.0.0.1:6006\r\n(Press CTRL+C to quit)\r\nWARNING:tensorflow:path ../external\\data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external\\data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external\\data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external\\data/plugin/text/runs not found, sending 404\r\n\r\n```", "comments": ["Just checking that it's not a windows issue, @guschmue @vit-stepanovs do you guys run tensorboard on windows and is it working well for you?", "Works fine on master and 1.1 as far I can tell. \r\nAbove log shows tensorboard finds one 1 scalar,  maybe the data in the scalar is not valid ? ", "I have tried  the same for a different dir which used to work but no longer returns anything. here is the log of inspect:\r\n\r\n```\r\nC:\\Users\\T430MM>tensorboard --inspect --logdir=model_dir\r\n======================================================================\r\nProcessing event files... (this can take a few minutes)\r\n======================================================================\r\n\r\nFound event files in:\r\nmodel_dir\r\nmodel_dir\\eval\r\n\r\nThese tags are in model_dir:\r\naudio -\r\nhistograms\r\n   dnn/hiddenlayer_0_activation\r\n   dnn/hiddenlayer_1_activation\r\n   dnn/hiddenlayer_2_activation\r\n   dnn/hiddenlayer_3_activation\r\n   dnn/logits_activation\r\nimages -\r\nscalars\r\n   dnn/hiddenlayer_0_fraction_of_zero_values\r\n   dnn/hiddenlayer_1_fraction_of_zero_values\r\n   dnn/hiddenlayer_2_fraction_of_zero_values\r\n   dnn/hiddenlayer_3_fraction_of_zero_values\r\n   dnn/logits_fraction_of_zero_values\r\n   global_step/sec\r\n   loss\r\ntensor -\r\n======================================================================\r\n\r\nEvent statistics for model_dir:\r\naudio -\r\ngraph\r\n   first_step           0\r\n   last_step            0\r\n   max_step             0\r\n   min_step             0\r\n   num_steps            1\r\n   outoforder_steps     []\r\nhistograms\r\n   first_step           1\r\n   last_step            9901\r\n   max_step             9901\r\n   min_step             1\r\n   num_steps            100\r\n   outoforder_steps     []\r\nimages -\r\nscalars\r\n   first_step           1\r\n   last_step            9901\r\n   max_step             9901\r\n   min_step             1\r\n   num_steps            100\r\n   outoforder_steps     []\r\nsessionlog:checkpoint\r\n   first_step           1\r\n   last_step            10000\r\n   max_step             10000\r\n   min_step             1\r\n   num_steps            2\r\n   outoforder_steps     []\r\nsessionlog:start\r\n   outoforder_steps     []\r\n   steps                [1]\r\nsessionlog:stop -\r\ntensor -\r\n======================================================================\r\n\r\nThese tags are in model_dir\\eval:\r\naudio -\r\nhistograms -\r\nimages -\r\nscalars\r\n   loss\r\ntensor -\r\n======================================================================\r\n\r\nEvent statistics for model_dir:\r\naudio -\r\ngraph\r\n   first_step           0\r\n   last_step            0\r\n   max_step             0\r\n   min_step             0\r\n   num_steps            1\r\n   outoforder_steps     []\r\nhistograms -\r\nimages -\r\nscalars\r\n   first_step           10000\r\n   last_step            10000\r\n   max_step             10000\r\n   min_step             10000\r\n   num_steps            1\r\n   outoforder_steps     []\r\nsessionlog:checkpoint -\r\nsessionlog:start -\r\nsessionlog:stop -\r\ntensor -\r\n======================================================================\r\n```\r\n\r\nThe browser loads the tensorboard page, but it displays the following error under the scalar tab:\r\n\r\n>  No scalar data was found.\r\n> \r\n> Probable causes:\r\n> \r\n>You haven't written any scalar data to your event files.\r\n>TensorBoard can't find your event files.\r\n> \r\n> If you're new to using TensorBoard, and want to find out how to add data and set up your event files, check out the README and perhaps the TensorBoard tutorial .\r\n> \r\n> If you think TensorBoard is configured properly, please see the section of the README devoted to missing data problems and consider filing an issue on GitHub. \r\n> ", "Facing the same issue as well. I am not sure if it is because of the logdir path such that it is unable to identify the Event file.", "does a simple app like https://gist.github.com/guschmue/fef2018cefb327c45f7619e26f530837 this works?", "no, not for me. The dir is not empty, I see the tfevents file in there, but once more the same error log in the browser. ", "I am also seeing the same thing :(\r\n`Starting TensorBoard 47 at http://0.0.0.0:6006\r\n(Press CTRL+C to quit)\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404`\r\nI see the tensorBoard at http://0.0.0.0:6006\r\nno event data though", "Looks like this known issue it was fix in a later version. Got mine working by -\r\n`pip uninstall tensorflow`\r\nthen\r\n`pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl`\r\nThis is for python 2.7", "well, I am not sure if downgrading to tf.__version__ <1.0.0 is the solution here. ", "Your probably right cherry picking the patch is better until next release.", "I just want this issue to be resolved, going forward it should be in the interest of everyone to achieve a more permanent fix. In the mean time #9854 has a fix for getting tensorboard working for version1.1.0.  \r\n`tensorboard --logdir==training:model_dir --host=127.0.0.1`\r\n\r\n", "My tensorboard has the same questions, and it said the \r\n```\r\n----------------------------------------\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\n```\r\nand it is useless using the \"training:model_dir\" in the command line.", "I'm also facing this same error:\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\n\r\nI'm using TFlearn on Windows 10. Tensorflow 1.1.0 (I have CUDA and all the necessary libraries installed).\r\n But my Tensorboard isn't capturing the model I built on Tflearn well. I instead get this error messages:\r\n\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\n", "I've upgraded to TF 1.1.0 64 bit but also have this error and tensorboard show nothing. (Ubuntu 14.04 64bit, python 3.4). looking forward to the fix. ", "Same here.\r\n```\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\n```", "Also i have this problem(ubuntu 16.04)\r\n\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404", "Also having same issue. Win 10 64bit", "Same issue, on Docker tensorflow image (Ubuntu)\r\n", "I too have this issue. Ubuntu 14.04 64 bit, python 2.7. Using firefox over an ssh connection.", "Faced this issue today but was able to correct it by changing the log directory to the base directory of my project instead of the checkpoint directory (another folder inside the project folder).\r\n\r\nBasically changed from:\r\n`tensorboard --logdir=/home/cc/Emotion/Emotion_checkpoints/` \r\nto\r\n`tensorboard --logdir=/home/cc/Emotion/`", "Same issue - windows10, anaconda3, python3.5, tensorflow-gpu 1.1. None of the suggested workarounds have any effect.", "Having same issue using Keras callbacks to generate the TB file I see the events file  in my logs dir and it seems to have a bunch in it (using vim to look at it)  but get nothing on TB \r\n(py36) tom@tomServal:~/Documents/InfluenceH/Working_copies/Cond_fcast_wkg$ $ tensorboard --logdir==./logs --host=127.0.0.1\r\nStarting TensorBoard b'47' at http://127.0.0.1:6006\r\n(Press CTRL+C to quit)\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\nWARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\r\n\r\nUbuntu 16.04 TF 1.1.0, 64 bit GPU installed using Pip into a Python 3.6 env on anaconda using the versions of Keras and Tensorboard in the Main Tensorflow distribution\r\nAnd I can't find a work around here!", "same issue, but\r\n`tensorboard --logdir==training:log_dir --host=127.0.0.1`\r\nworks for me (1.2.0rc1, windows 10, conda, py3.5.3) ", "Same here, on linux.\r\nI solved by renaming directory from `2017-06-02T07:5:28.864_sib0.5/logs/`\r\nto `arun/logs`\r\n", "I had the same problem. Steven's suggestion of specifying the host explicitly works for me ! Thanks :)", "@steven-hh-ding , your suggestion exactly works for me, too! Thanks.", "Same issue, mac 10.11, python3.5, TF 1.1.0. \r\nSolved by moving to the specific directory.  \r\n\r\nAfter I run\r\n`python tensorflow-1.1.0/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py`\r\nI got two floder named `train` and `test` under the `/tmp/mnist/logs/mnist_with_summaries`.  \r\n`train` and `test` contains tf event file. Then I run \r\n`tensorboard --logdir=/tmp/mnist/logs/mnist_with_summaries`\r\nAfter opening the browser, there are no scalars at all. \r\n![no info](https://cloud.githubusercontent.com/assets/10768193/26833853/94f19d3a-4b0e-11e7-8200-33f73ef0e2ef.png)\r\n\r\nBut when I move to the directory `/tmp/mnist/logs`, and run\r\n`tensorboard --logdir=mnist_with_summaries`\r\nIt works! \r\n![working properly](https://cloud.githubusercontent.com/assets/10768193/26833924/c80f9eec-4b0e-11e7-95d1-23607de7a487.png)\r\n\r\nI don't know why this works. Maybe someone can tell me. \r\n\r\n\r\n\r\n", "Even i had the same issue and i finally understood where i was wrong.\r\nIn my case I was using ubuntu and the log folder was stored inside my project directory itself.\r\nSo just navigate to the project directory from the terminal and type\r\ntensorboard --logdir=log", "@dartdog \r\nI have the exact software setup as you did, and exactly the same problem. Have you managed to figureout ? Many thanks.", "Moving from 1.2.0rc1 to rc2 the problem is gone (windows 10, windows server). No need to specify host name anymore. The `WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS` warning is gone as well. ", "Hi all,\r\n\r\nThis issue looks like it's encompassing a few different problems, some of which are workflow issues, some of which are bugs that are fixed in latest TensorBoard. So I'm going to close it.\r\n\r\nYou can pip install the latest tensorboard via `pip install tensorflow-tensorboard`.\r\nIf afterwards you still have issues, please open an issue at https://github.com/tensorflow/tensorboard.", "**BrumbleXu**, 's solution worked for me!\r\nMany thanks, I think that the issue is with addressing the directory in Windows.\r\nJust log in to your directory (one dir before your tensorboard dir) and address that directory.\r\nand use: **http://localhost:6006/** in Explorer/Chrome.\r\n\r\n", "Just move directly to the summary files' directory and then type \r\n`python -m tensorflow.tensorboard --logdir={yours directory}`\r\n\r\nIt works", "Run the code in cells 19 & 23 below to import and pre-process the data.\r\n\r\nhttps://github.com/ageron/handson-ml/blob/master/09_up_and_running_with_tensorflow.ipynb\r\n\r\nThen lines 59-64 are run to solve a linear least squares problem, whilst saving the training data for use with tensorboard.\r\n\r\nI then use Anaconda prompt to do to the directory where the log files are kept:\r\nI then use Anaconda prompt to run: tensorboard --logdir=\\tf_logs\r\nIt gives the message Starting TensorBoard b'54' at http://NW1:6006\r\n\r\nBut when I try to paste that address into a browser it doesn't work?\r\n\r\nI've tried various combinations of absolute path names etc, and other solutions suggested in this thread, such as specifying the host as 127.0.0.1, but nothing seems to work. \r\n\r\ntensorboard --logdir=\\tf_logs --host=127.0.0.1\r\n\r\nBut nothing seems to work! The webpage is completely blank.\r\n\r\nI'm running windows 8.1\r\nInternet Explorer 11\r\nAnaconda 3\r\nPython3.5\r\nTensorflow 1.1\r\n\r\nEverything was installed fresh today so should be up to date\r\n\r\nPS Just a thought but why can't tensorboard be called from tensorflow directly?", "steven-hh-ding's suggestion works for me too. Thanks!", "In my case the problem was that I created the virtual environment, and I had to run tensorboard from there!", "BrambleXu's suggestion / solution worked for me!  Thank you very much.  That was frustrating.  Now, if I could only get the histogram error to go away (File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\", line 751, in on_epoch_end\r\n    raise ValueError('If printing histograms, validation_data must be '\r\nValueError: If printing histograms, validation_data must be provided, and cannot be a generator.)", "Try Firefox. I t worked for me ! ! !\r\nOn Chrome and IE, TensorBoard would not display Graphs, Histograms or Embeddings.\r\nHowever, FireFox 55.0.0 displayed everything.\r\nMy Chrome is at 62.0.3202.94\r\nMy IE is at 11.0x\r\nOn Windows 7\r\n\r\nBTW: This issue might me the same as #10611", "same issue,  tensorflow 1.4, tensorboard 0.4.0rc, windows 7, anaconda, py3.6\r\ntensorboard --logdir==training:log_dir --host=127.0.0.1\r\nworks \r\n", "Just update the tensorflow version or try to open tensorboard in your logdir \r\ntensorboard --logdir=your_log_dir/your_speciafy_log_dir \r\nor open tensorboard in your specific logdir \r\ntensorboard --logdir=your_specific_log_dir\r\nthese two type can works, because the it depends on which path you open tensorboard", "replace \" space \" in your path location by renaming directories\r\nThat's work really well \r\n\r\nHope that will work for you guys :+1: ", "I get this problem eventually. I don't know why sometimes it works and sometimes doesn't, but the work around is opening it with Firefox.\r\n\r\nI can't really understand how a Google Product like Tensorboard doesn't work on Chrome and does it on Firefox, but that's it.\r\n\r\nSame as #10611", "Same issue. And it was working properly this morning until suddenly I get this error. I'm on Ubuntu 16.04 with python 3.6 and tensorflow 1.7.0, GPU version.\r\ntensorboard --logdir==training:log_dir --host=127.0.0.1 worked for me.  But absolutely no idea why it didn't work and why it worked. ", "Faced the same issue. I'm on Win10 with python 3.6 and tensorflow 1.6 GPU.\r\nI found the work around. \r\nIt is opening GRAPHS with Edge.\r\n![untitled](https://user-images.githubusercontent.com/36813407/39091784-03d0aa96-4638-11e8-892b-59969cc0430e.jpg)\r\n", "I was facing this problem on a Linux machine, \r\nI discovered that this happened because I was in the directory of logs folder and by going back to the parent directory, and then issuing the command \r\n`tensorboard --logdir==training:path_to_logs/logs_folder_name --host=127.0.0.1 --port=6007 `\r\nIt worked fine.", "I've done this :) and it worked for me \r\n\r\nhttps://stackoverflow.com/questions/48684755/tensorboard-doesnt-show-scalars-anymore", "Had the same problem of graphs not populating with windows 10\r\ntensorboard --logdir=training:log_dir --host=127.0.0.1\r\n\r\nHence specified just the directory containg training information\r\ntensorboard --logdir=training --host=127.0.0.1"]}, {"number": 9700, "title": "Add initializer to GRUCell, MultiRNNCell #9600", "body": "Add initializer to GRUCell, MultiRNNCell #9600", "comments": ["Can one of the admins verify this patch?", "LGTM so long as tests continue to pass.\n\nOn May 5, 2017 3:16 PM, \"Vijay Vasudevan\" <notifications@github.com> wrote:\n\n> @vrv <https://github.com/vrv> requested your review on:\n> tensorflow/tensorflow#9700\n> <https://github.com/tensorflow/tensorflow/pull/9700> Add initializer to\n> GRUCell, MultiRNNCell #9600\n> <https://github.com/tensorflow/tensorflow/issues/9600>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/9700#event-1071320794>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimwlbK835F1c8BRGD3ItiYYeiiQEvks5r25-2gaJpZM4NSUPo>\n> .\n>\n", "We should consult with Lukasz about what's common, and try to be consistent\nwith keras. The initializer arg is standard and we can always add others to\noverride specific layer behavior.  I'd check the keras code but am ooo\ntoday. Will let you make the final decision.\n\nOn May 5, 2017 3:24 PM, \"Vijay Vasudevan\" <notifications@github.com> wrote:\n\n> *@vrv* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\n> <https://github.com/tensorflow/tensorflow/pull/9700#discussion_r115098001>\n> :\n>\n> > @@ -100,11 +102,11 @@ def output_size(self):\n>\n>    def call(self, inputs, state):\n>      \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n> -    with vs.variable_scope(\"gates\"):  # Reset gate and update gate.\n> +    with vs.variable_scope(\"gates\", initializer=self._initializer):  # Reset gate and update gate.\n>\n> @ebrevdo <https://github.com/ebrevdo> are you concerned that eventually\n> someone might want to pass different initializers to these different\n> variables?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/9700#pullrequestreview-36621059>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzNcwYTcY6OLdjgwx9EktL2xj6CQks5r26GbgaJpZM4NSUPo>\n> .\n>\n", "Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 9699, "title": "RNN: InvalidArgumentError when adding InitialState", "body": "Please go to Stack Overflow for help and support:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.  The current stock examples are pre-TF1.0 and do not run.  I have already posted an issue regarding them. (https://github.com/tensorflow/tensorflow/issues/9294#issuecomment-294944970)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: TF1.1.0\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 5.1\r\n- **GPU model and memory**: p2-xlarge with 12GiB\r\n- **Exact command to reproduce**:\r\n\r\nWhen training a simple two layer RNN, if I do not include the initialstate, the graph trains properly, if I add the initialstate, then I get the following error.  \r\nBrief code (full code below):\r\n```\r\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) \r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n```\r\nError message (full message below):\r\n```\r\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\nIf I print the `initial_state` variable, I get this:\r\n```\r\n(LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\r\n```\r\nIf I print the `state` producted by `static_rnn` call:\r\n```\r\n(LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>))\r\n```\r\nHere is the full message:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-15-5e6d1756b352> in <module>()\r\n     90         Xin   : X_test,\r\n     91         Ytrue : one_hot(y_test, LabelMax),\r\n---> 92         keep_prob: 1.0\r\n     93     }\r\n     94 )\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    776     try:\r\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 778                          run_metadata_ptr)\r\n    779       if run_metadata:\r\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    980     if final_fetches or final_targets:\r\n    981       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 982                              feed_dict_string, options, run_metadata)\r\n    983     else:\r\n    984       results = []\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1030     if handle is None:\r\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1032                            target_list, options, run_metadata)\r\n   1033     else:\r\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1050         except KeyError:\r\n   1051           pass\r\n-> 1052       raise type(e)(node_def, op, message)\r\n   1053 \r\n   1054   def _extend_graph(self):\r\n\r\nInvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat', defined at:\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-14-eaca1bbf91d8>\", line 48, in <module>\r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\r\n    (output, state) = call_cell()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 953, in __call__\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\r\n    concat = _linear([inputs, h], 4 * self._num_units, True)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1048, in _linear\r\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1034, in concat\r\n    name=name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\r\n    name=name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\nHere is the network creation code:\r\n```\r\n# Clear the graph memory\r\ntf.reset_default_graph()\r\n\r\n# Graph input/output\r\nXin   = tf.placeholder(tf.float32, [None, n_steps, n_input] , name= \"Xin\")\r\nYtrue = tf.placeholder(tf.float32, [None, n_classes]        , name= \"Ytrue\")\r\n\r\n# Graph weights\r\nweights={}\r\nweights['Pre' ] = tf.Variable(tf.random_normal([n_input     , n_hiddenPre ]), name=\"Wght_Pre\") # Hidden layer weights\r\nweights['LSTM'] = tf.Variable(tf.random_normal([n_hiddenPre , n_hidden    ]), name=\"Wght_LSTM\") # Hidden layer weights\r\nweights['Post'] = tf.Variable(tf.random_normal([n_hidden    , n_hiddenPost]), name=\"Wght_Post\")\r\nweights['out' ] = tf.Variable(tf.random_normal([n_hiddenPost, n_classes   ]), name=\"Wght_Out\")\r\n\r\nbiases={}\r\nbiases['Pre' ] = tf.Variable(tf.random_normal([n_hiddenPre ]), name=\"Bias_Pre\")\r\nbiases['LSTM'] = tf.Variable(tf.random_normal([n_hidden    ]), name=\"Bias_LSTM\")\r\nbiases['Post'] = tf.Variable(tf.random_normal([n_hiddenPost]), name=\"Bias_Post\")\r\nbiases['out' ] = tf.Variable(tf.random_normal([n_classes   ]), name=\"Bias_Out\")\r\n\r\nXnew = prepareX(Xin)\r\n\r\nwith tf.name_scope('DensePre'):\r\n    Xpre = tf.matmul(Xnew, weights['Pre']) + biases['Pre']\r\n    keep_prob  = tf.placeholder(tf.float32)\r\n    Xpre_drop = tf.nn.dropout(Xpre, keep_prob)\r\n\r\n    # Linear activation\r\n    Xnew = tf.matmul(Xpre_drop, weights['LSTM']) + biases['LSTM']\r\n\r\nwith tf.name_scope('RNN'): \r\n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\r\n    Xnew = tf.split(Xnew, n_steps, axis=0) \r\n    # new shape: n_steps * (batch_size, n_hidden)\r\n\r\n    # Can use one or more LSTM layers\r\n    lstm_cell1  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    lstm_cell2  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    lstm_cells  = tf.contrib.rnn.MultiRNNCell([lstm_cell1,lstm_cell2], state_is_tuple=True)\r\n    #RNN_outputs, state = lstm_cells(Xnew, state=state)  # this code fails, so used line above without state\r\n    \r\n    # The following lines are for the bidirectional RNN, but effort was blocked due to an opaque error message\r\n    #  lstm_cell_back   = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    #  lstm_cells_back  = tf.contrib.rnn.MultiRNNCell([lstm_cell_back] * 2, state_is_tuple=True)\r\n\r\n    # Get LSTM cell output\r\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) # Not used, but should be!\r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n    #RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32)\r\n    print(initial_state)\r\n    print(state)\r\n\r\nwith tf.name_scope('DensePost'):\r\n    Xnew = tf.matmul(RNN_outputs[-1], weights['Post']) + biases['Post']\r\n    Xnew = tf.nn.dropout(Xnew, keep_prob)\r\n     \r\nwith tf.name_scope('DenseOut'):\r\n    # Linear activation\r\n    Ypred        = tf.add(tf.matmul(Xnew, weights['out']),biases['out'], name=\"Ypred_raw\")\r\n    # Compute softmax result\r\n    YpredSoftMax = tf.nn.softmax(Ypred   , dim =1, name=\"prediction\")\r\n    YpredIndex   = tf.argmax(YpredSoftMax, axis=1, name=\"predIndex\" )\r\n# Loss, optimizer and evaluation; Regularization term\r\nl2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \r\n# L2 loss prevents this overkill neural network to overfit the data\r\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ypred, labels=Ytrue)) + l2 # Softmax loss\r\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\r\n\r\ncorrect_pred = tf.equal(tf.argmax(Ypred,1), tf.argmax(Ytrue,1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n```", "comments": ["To summarize, it looks like the state is `[2500, 75]`, but the initial state expected by the code is `[20, 75]`.\r\n\r\n@ebrevdo any idea?", "Yeah, so if the `lstm_cells` object is generating its own initial state tensor, then why is it generating the wrong dimensions, or expecting the wrong dimensions?", "If I'm not incorrect, the proper initial_state tensor should be [2500,75].  Given that the mini-batch size is 2500 and the lstm cell count is 75.", "I'm seeing that you have:\r\n\r\nXnew = tf.split(Xnew, n_steps, axis=0) \r\n\r\nHow many elements are there in Xnew after this step, and what are their shapes?\r\n\r\nFurthermore, can you print(initial_state) for me?\r\n", "@ebrevdo : Thanks for replying.  `initial_state` is shown at the top of the original post here.\r\nReprinting:\r\n```\r\n(LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\r\n```", "Got it.  Did you expect to have a batch_size of 2000?  It seems like the\nbatch_size variable you passed to cell.zero_state was 2000.\n\nOn Sat, May 6, 2017 at 2:41 PM, Kevin Shaw <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> : Thanks for replying. initial_state\n> is shown at the top of the original post here.\n> Reprinting:\n>\n> (LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9699#issuecomment-299667572>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9J4HA-AJhl66gzWTr1Lscy2RvOWks5r3OkQgaJpZM4NSS3U>\n> .\n>\n", "err, 2500.\n\nOn Sat, May 6, 2017 at 2:43 PM, Eugene Brevdo <ebrevdo@google.com> wrote:\n\n> Got it.  Did you expect to have a batch_size of 2000?  It seems like the\n> batch_size variable you passed to cell.zero_state was 2000.\n>\n> On Sat, May 6, 2017 at 2:41 PM, Kevin Shaw <notifications@github.com>\n> wrote:\n>\n>> @ebrevdo <https://github.com/ebrevdo> : Thanks for replying.\n>> initial_state is shown at the top of the original post here.\n>> Reprinting:\n>>\n>> (LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/9699#issuecomment-299667572>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/ABtim9J4HA-AJhl66gzWTr1Lscy2RvOWks5r3OkQgaJpZM4NSS3U>\n>> .\n>>\n>\n>\n", "Correct the batch size is 2500.", "Perhaps a related question is: what size *should* `Xnew` be?   Given the batch size of 2500, and a frame size of (300 x 12), where the feature vector length for each time step is 12.  I've always found the method of batching frames for an RNN to be confusing.", "Sounds like Xnew should be a list of 300 tensors, each one shaped 2500x12.\n\nOn Sat, May 6, 2017 at 3:15 PM, Kevin Shaw <notifications@github.com> wrote:\n\n> Perhaps a related question is: what size *should* Xnew be? Given the\n> batch size of 2500, and a frame size of (300 x 12), where the feature\n> vector length for each time step is 12.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9699#issuecomment-299669108>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim0kPQ0dRxEBM_6voHJXjAkxF49wEks5r3PDogaJpZM4NSS3U>\n> .\n>\n", "Okay.  Let me think about this.  I'll get back tonight.  Thanks!", "Okay, after about five hours on this, I've ditched the old `static_rnn` approach and switched to a `dynamic_rnn` which eliminated those issues about input shape.  If I understand correctly, with the `dynamic_rnn`, I can feed an input Tensor of shape `[b x n x f]` where `b` is the `batch_size`, `n` is `n_steps`, and `f` is the number of features, `n_feat`, directly into the RNN object.\r\nLong story short, there is nothing like a little \"confessional debugging\" (as a friend likes to say) to solve a problem.  I wrote up a long answer here documenting everything I'd found and happened to notice that the error was showing up only on the test data, not the training data.  I'm using a smaller data set for this graph testing working and the test set is smaller than the 2500 element batch size that I'm using for the training.  Hence, for the test set, when the tensor count is smaller than the batch size, the initial state tensor will not match the state result from the RNN.  \r\nThe solution is to use a variable `batch_size` based on the size of the `Xin` value, and to then generate a variable `initial_state` dynamically based on this:\r\n```\r\nbatch_size_T  = tf.shape(Xin)[0]\r\ninitial_state = lstm_cells.zero_state(batch_size_T, tf.float32) \r\n```\r\nSo, problem solved.  Thanks for the help!!!\r\n", "In my case, I changed the batch size from 24 to 1, then problem was solved.", "@kevinashaw i am getting the same error and also the code ::initial_state = lstm_cells.zero_state(batch_size_T, tf.float32) does not work any help??"]}, {"number": 9698, "title": "Fix build scripts for MKL", "body": "", "comments": ["@vrv, yes, that's a TODO item. But it's part of the build system config, not part of the code."]}, {"number": 9697, "title": "Tensorflow build from sources fails", "body": "### System information\r\nTensorflow build from TF 1.1 sources cloned from GIT fails.  This was working a couple of days ago on the same machine.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04, kernel 4.4.0-75-generic\r\nHardware: Skylake server, nVidia P4\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\nI believe is 1.1-rc2 ... cannot get it from TF itself because unable to build in the first place\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA 8.0\r\ncuDNN 5.1.10\r\n\r\n- **GPU model and memory**:\r\nnVidia P4, 8GB\r\n\r\n- **Exact command to reproduce**:\r\nFollowed exactly the steps to build from source from - https://www.tensorflow.org/versions/master/install/install_sources\r\n\r\nDid the following:\r\n./configure - used all defaults (see attached -  \r\n[configure_nocuda.txt](https://github.com/tensorflow/tensorflow/files/979910/configure_nocuda.txt)\r\n)\r\n\r\nbazel build --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nOR\r\nbazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nBoth fail with the same issue (see below for the non cuda build)\r\n\r\nOutput from the environment collection script is attached - \r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/979900/tf_env.txt)\r\n\r\n\r\n### Describe the problem\r\nBuild fails.  I have tried it with --config=cuda also - same issue.\r\n\r\n### Source code / logs\r\nHere are the first couple of errors\r\n### System information\r\nTensorflow build from TF 1.1 sources cloned from GIT fails.  This was working a couple of days ago on the same machine.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04, kernel 4.4.0-75-generic\r\nHardware: Skylake server, nVidia P4\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\nI believe is 1.1-rc2 ... cannot get it from TF itself because unable to build in the first place\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA 8.0\r\ncuDNN 5.1.10\r\n\r\n- **GPU model and memory**:\r\nnVidia P4, 8GB\r\n\r\n- **Exact command to reproduce**:\r\nFollowed exactly the steps to build from source from - https://www.tensorflow.org/versions/master/install/install_sources\r\n\r\nDid the following:\r\n./configure - used all defaults (see attached -  \r\n[configure_nocuda.txt](https://github.com/tensorflow/tensorflow/files/979910/configure_nocuda.txt)\r\n)\r\n\r\nbazel build --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nOR\r\nbazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nBoth fail with the same issue (see below for the non cuda build)\r\n\r\nOutput from the environment collection script is attached - \r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/979900/tf_env.txt)\r\n\r\n\r\n### Describe the problem\r\nBuild fails.  I have tried it with --config=cuda also - same issue.\r\n\r\n### Source code / logs\r\nHere are the first couple of errors in bold from a non-cuda build (compete build log is attached - \r\n[tf_build_nocuda.txt](https://github.com/tensorflow/tensorflow/files/979914/tf_build_nocuda.txt)):\r\n\r\nERROR: /home/rajka/tensorflow/tensorflow/core/kernels/BUILD:2093:1: C++ compilation of rule '//tensorflow/core/kernels:self_adjoint_eig_v2_op' failed: gcc failed: error executing command \r\n  (cd /home/rajka/.cache/bazel/_bazel_rajka/28f0a9835f793d5627ca9486394f31f2/execroot/tensorflow && \\\r\n  exec env - \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-march=native' '-std=c++0x' '-march=native' '-march=native' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/jemalloc -iquote bazel-out/local-opt/genfiles/external/jemalloc -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local-opt/genfiles/external/snappy -isystem external/jemalloc/include -isystem bazel-out/local-opt/genfiles/external/jemalloc/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/kernels/self_adjoint_eig_v2_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n\r\n... snip snip ...\r\n\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\n**external/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex<double>, Eigen::internal::scalar_product_op<__vector(8) double, std::complex<double> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;**\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: **error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'**\r\n in bold from a non-cuda build (compete build log is attached - \r\n[tf_build_nocuda.txt](https://github.com/tensorflow/tensorflow/files/979914/tf_build_nocuda.txt)):\r\n\r\nERROR: /home/rajka/tensorflow/tensorflow/core/kernels/BUILD:2093:1: C++ compilation of rule '//tensorflow/core/kernels:self_adjoint_eig_v2_op' failed: gcc failed: error executing command \r\n  (cd /home/rajka/.cache/bazel/_bazel_rajka/28f0a9835f793d5627ca9486394f31f2/execroot/tensorflow && \\\r\n  exec env - \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-march=native' '-std=c++0x' '-march=native' '-march=native' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/jemalloc -iquote bazel-out/local-opt/genfiles/external/jemalloc -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local-opt/genfiles/external/snappy -isystem external/jemalloc/include -isystem bazel-out/local-opt/genfiles/external/jemalloc/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/kernels/self_adjoint_eig_v2_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n\r\n... snip snip ...\r\n\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\n**external/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex<double>, Eigen::internal::scalar_product_op<__vector(8) double, std::complex<double> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;**\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: **error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'**\r\n\r\n", "comments": ["What gcc version?\r\n\r\n/CC: @rmlarsen ", "gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)", "Also happens on\r\nGCC 7.1.0\r\nUbuntu 16.04.2", "Also happens on\r\ngcc (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406\r\nUbuntu 17.04\r\nAnd I'm on master", "Very similar problem on arm (raspberry), r1.2 branch:\r\n```\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<fl\r\noat>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::Inl\r\ninedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, Eigen::internal::scalar_product_op<__vector(4) __builtin_neon_sf, Eigen::inte\r\nrnal::Packet2cf> >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Mat\r\nrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = float]':\r\n```\r\n and\r\n```\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<fl\r\noat>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::Inl\r\ninedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:55: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                                       ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:55: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:55: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                                       ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:55: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:56: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstoreu(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:56: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:69: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstoreu(px+PacketSize, padd(pm.pmul(pc,xi1),pcj.pmul(ps,yi1)));\r\n                                                                     ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:69: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:56: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstore (py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:56: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:69: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstore (py+PacketSize, psub(pcj.pmul(pc,yi1),pm.pmul(ps,xi1)));\r\n                                                                     ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:69: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:66: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstoreu(x+peelingEnd, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                                                  ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:66: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:66: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n         pstore (y+peelingEnd, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                                                  ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:66: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:53: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                                     ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:53: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:53: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                                     ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:53: error: 'struct Eigen::internal::conj_helper<__vector(4) __builtin_neon_sf, Eigen::internal::Packet2cf, false, false>' has no member named 'pmul'\r\n```\r\n```\r\ngcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabihf/4.9/lto-wrapper\r\nTarget: arm-linux-gnueabihf\r\nConfigured with: ../src/configure -v --with-pkgversion='Raspbian 4.9.2-10' --with-bugurl=file:///usr/share/doc/gcc-4.9/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.9 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.9 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-libitm --disable-libquadmath --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.9-armhf/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.9-armhf --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.9-armhf --with-arch-directory=arm --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-sjlj-exceptions --with-arch=armv6 --with-fpu=vfp --with-float=hard --enable-checking=release --build=arm-linux-gnueabihf --host=arm-linux-gnueabihf --target=arm-linux-gnueabihf\r\nThread model: posix\r\ngcc version 4.9.2 (Raspbian 4.9.2-10)\r\n```\r\n", "I have the same problem on Raspberry pi 3 with TensorFlow 1.2.0-rc2, both gcc 4.8 and gcc 4.9.", "I met the same problem, turns out the eigen lib version is not compatible with tensorflow version. Make sure the eigen version in /tensorflow/workspace.bzl is correct.", "@luckyteddy Do you know the commit of Eigen fits for TensorFlow 1.2.0 rc2 (commit:ce1d6ec49bb0aea2ee2e5bd90e424345e6846fc8 ).\r\n\r\nI found something here:\r\nhttp://eigen.tuxfamily.org/bz_attachmentbase/attachment.cgi?id=789\r\n, which links this error to a commit of Eigen, as you have mentioned.\r\nHow to solve this, a earlier version before this commit?\r\n\r\nThanks a lot.", "Indeed, some specialisations were missing for ARM NEON, this should be fixed by the following commit:\r\n\r\nhttps://bitbucket.org/eigen/eigen/commits/d781c1de9834/\r\nSummary:     Bug 1436: fix compilation of Jacobi rotations with ARM NEON, some specializations of internal::conj_helper were missing.\r\n\r\nbut I cannot test on ARM NEON right now. Could someone try with the head of the default branch of Eigen to confirm it? If everything is green, I'll backport the fix to 3.3.\r\n\r\nthanks.", "@ggael It works on my ARM platform", "@SteveBetter Sorry, I have overload eigen to test, don't know the earlier version. But the solution @ggael gave works. Thanks to him.", "@luckyteddy thank you for the confirmation.", "It works for my Raspberry pi 3 model B also.\r\nThanks @ggael ", "I was able to get tensorflow 1.2.0 rc2 to build with this eigen commit: d781c1de9834 . That was with gcc-arm-gnueabi-5.4.", "This doesnt seem to address the original problem of building with -march=native on **skylake** - I still get build errors even with new eigen (also, the eigen dep in workspace.bzl should likely be rolled forward)\r\n\r\nSeems related to #9849 and #10689 which also report AVX 512 related errors", "Update - building r1.1 release branch with -march=native on skylake (Ubuntu 16.04) works, so this looks like a regression introduced in r1.2, likely due to depending on a different eigen commit (r1.1 is on 9c6361787292 currently)\r\n\r\n...although it looks like it actually segfaults when you try to run anything", "@benoitsteiner Is it possible that Eigen (at 9c6361787292) does not compile on skylake? \r\n\r\n@mwytock, could you change to a newer Eigen commit and check with that? ", "@martinwicke I tried eigen commit 5a0156e40feb which corresponds to version 3.3.4 released 6/15 \r\n\r\nIts unclear to me if this fixes the original issue but it seems to cause new eigen-related compilation issues\r\n\r\n```\r\nERROR: /home/mwytock/tensorflow/tensorflow/core/BUILD:1207:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 117 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/core/lib/core/threadpool.cc: In constructor 'tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&, const string&, int, bool)':\r\ntensorflow/core/lib/core/threadpool.cc:91:56: error: no matching function for call to 'Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int&, bool&, tensorflow::thread::EigenEnvironment)'\r\n             EigenEnvironment(env, thread_options, name)) {}\r\n                                                        ^\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/ThreadPool:58:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:72,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from tensorflow/core/lib/core/threadpool.cc:19:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note: candidate: Eigen::NonBlockingThreadPoolTempl<Environment>::NonBlockingThreadPoolTempl(int, Environment) [with Environment = tensorflow::thread::EigenEnvironment]\r\n   NonBlockingThreadPoolTempl(int num_threads, Environment env = Environment())\r\n   ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note:   candidate expects 2 arguments, 3 provided\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\nI suspect someone with more knowledge of eigen/tensorflow internals will need to take a look.\r\n\r\nAlso, for what its worth, I'm compiling this on vanilla Ubuntu 16.04 running on a skylake machine in GCE us-west1 so should be easy to replicate.", "I could reproduce that cross-compiling for ARMv6 on Debian Sid, both with the GCC 4.9.3 toolchain provided for RPi and with GCC6 ARM cross-compiler. Switching `eigen_archive` to https://bitbucket.org/eigen/eigen/commits/d781c1de9834/ did help, as suggested by @lime45. At least, it builds a shared object.\r\n\r\nThis was on master, https://github.com/tensorflow/tensorflow/commit/2e68836850b3cea3a67bba3ab8232804727a1b22", "@benoitsteiner, assigning you since the fix likely involves updating Eigen.", "This is still happening to me on an ARM processor with gcc 4.8.4\r\nWith more recent pull of tensorflow", "I'm also hitting this error when cross-compiling for ARM-v7a. ", "Update: while working on some OSX builds, I hit that strange error: https://tools.taskcluster.net/groups/Ma01MYVoTfKZpwxj8icetw/tasks/L9yMqsomQnKJSxu2qaHLgg/runs/0/logs/public%2Flogs%2Flive_backing.log\r\n\r\n```\r\nERROR: /Users/build-user/TaskCluster/Tasks/task_1500995015/DeepSpeech/tf/tensorflow/core/kernels/BUILD:298:1: C++ compilation of rule '//tensorflow/core/kernels:queue_base' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign ... (remaining 138 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nIn file included from tensorflow/core/kernels/queue_base.cc:16:\r\nIn file included from ./tensorflow/core/kernels/queue_base.h:19:\r\nIn file included from /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/deque:158:\r\nIn file included from /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/__split_buffer:7:\r\nIn file included from /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/algorithm:628:\r\nIn file included from /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/memory:605:\r\n/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/limits:546:64: error: no member named 'max_digits10' in 'std::__1::numeric_limits<Eigen::half>'\r\n    static _LIBCPP_CONSTEXPR const int  max_digits10 = __base::max_digits10;\r\n```\r\n\r\nAfter reverting my changes for updating Eigen and going back to `d781c1de9834`, it seems ot be working better (except that the ARM cross compilation now fails again).", "For people landing here from Google who Just Want To Build The Thing, until this is fixed properly I can around this issue by specifying `-march=broadwell` during configure.\r\n\r\nInstead I just get this warning, when trying to use the library:\r\n```\r\nThe TensorFlow library wasn't compiled to use AVX512F instructions, but these are available on your machine and could speed up CPU computations.\r\n```", "Thanks Simon!I think the intended way is to use `--config=opt` (not `-c\nopt`). It will put `-march=native`.\n\nOn Thu, Aug 17, 2017 at 11:14 AM, Simon Detheridge <notifications@github.com\n> wrote:\n\n> For people landing here from Google who Just Want To Build The Thing,\n> until this is fixed properly I can around this issue by specifying\n> -march=broadwell during configure.\n>\n> Instead I just get this warning, when trying to use the library:\n>\n> The TensorFlow library wasn't compiled to use AVX512F instructions, but these are available on your machine and could speed up CPU computations.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9697#issuecomment-323151086>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbcToW7FMr0XZXJmyf_mOpIhJF9Wgks5sZIL0gaJpZM4NSPwZ>\n> .\n>\n", "Getting this error on Intel Skylake-X 7820X processor\r\n\r\n```\r\n\r\nIn file included from external/eigen_archive/Eigen/Core:452:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:18:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h: In instantiation of 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:339:77:   required from 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex<double>, Eigen::internal::scalar_product_op<__vector(8) double, std::complex<double> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(px+PacketSize, padd(pm.pmul(pc,xi1),pcj.pmul(ps,yi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (py+PacketSize, psub(pcj.pmul(pc,yi1),pm.pmul(ps,xi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(x+peelingEnd, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (y+peelingEnd, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nIn file included from external/eigen_archive/Eigen/Core:452:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:18:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h: In instantiation of 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:339:77:   required from 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = float]'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = float; Derived = Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = float; Scalar = std::complex<float>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<float>, -1, -1>; DiagType = Eigen::Matrix<float, -1, 1>; SubDiagType = Eigen::Matrix<float, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<float>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(16) float, std::complex<float>, Eigen::internal::scalar_product_op<__vector(16) float, std::complex<float> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = float]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = float; Derived = Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = float; Scalar = std::complex<float>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<float>, -1, -1>; DiagType = Eigen::Matrix<float, -1, 1>; SubDiagType = Eigen::Matrix<float, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<float>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(px+PacketSize, padd(pm.pmul(pc,xi1),pcj.pmul(ps,yi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (py+PacketSize, psub(pcj.pmul(pc,yi1),pm.pmul(ps,xi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(x+peelingEnd, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (y+peelingEnd, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n\r\n```", "@adityapatadia I got exactly the same error as yours. \r\nI tried with the latest eigen source (bccf2d933699) but in vain.", "@adityapatadia @hbtsai \r\nThis error showed up on KNL since the beginning of 2017\r\nI try to build periodically but all failed on this error\r\nEigen fails if you build with avx512 flag", "This should be fixed now: https://bitbucket.org/eigen/eigen/commits/66ac15c52b6c/", "@ggael do you recommend using master branch?", "@adityapatadia perhaps it is safer to use the 3.3 branch, and 3.3.5 once released.", "Gives following error for 3.3 branch:\r\n\r\n```\r\ntensorflow/core/lib/core/threadpool.cc: In constructor 'tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&, const string&, int, bool)':\r\ntensorflow/core/lib/core/threadpool.cc:91:56: error: no matching function for call to 'Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int&, bool&, tensorflow::thread::EigenEnvironment)'\r\n             EigenEnvironment(env, thread_options, name)) {}\r\n                                                        ^\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/ThreadPool:58:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:72,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from tensorflow/core/lib/core/threadpool.cc:19:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note: candidate: Eigen::NonBlockingThreadPoolTempl<Environment>::NonBlockingThreadPoolTempl(int, Environment) [with Environment = tensorflow::thread::EigenEnvironment]\r\n   NonBlockingThreadPoolTempl(int num_threads, Environment env = Environment())\r\n   ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note:   candidate expects 2 arguments, 3 provided\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "@adityapatadia ok, looks like TensorFlow requires the master branch (I'm not a TensorFlow user)", "Ok, compiled with master branch and works fine.", "Sorry for the dumb question, but how can you advice bazel to build TensorFlow with a specific version of Eigen? Can I download Eigen from sources, build Eigen and then point bazel to the local Eigen build?\r\n(I'm having the same issue on a Jetson TX2 / Ubuntu 16.04)", "@Daniel451  What I did was open target/tensorflow/tensorflow/workspace.bzl and find eigen_archive and then change the values in the stanza located there. You will have to download the tar.gz file and get the sha256 sum so you can fill that in properly.", "@ggael @adityapatadia Thanks guys, master branches of  tensorflow + eigen compiled and worked well. \r\n", "I also managed to build with Eigen master and tensorflow master but with native optimizations, a skylake CPU on Ubuntu I ran into this issue: https://github.com/tensorflow/tensorflow/issues/9638", "@nylocx same issue with me. Ended up using pre-built version from ```pip```. Any help will be appreciated as I want to take advantage of SIMD instructions.", "I ran into the same issue compiling TensorFlow from source in a FireFly RK3399 aarch64 bit device. \r\nTo solve the problem edit tensorflow/workspace.bzl add the bleeding edge version of Eigen, I tried with release 3.3.4 but ran into a different problem expected number of variables given to a function didn't match. This appear to be fixed in the most current release. \r\n\r\nHope this helps:\r\n\r\n native.new_http_archive(\r\n      name = \"eigen_archive\",\r\n      urls = [\r\n          #\"http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n          #\"https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n          \"http://bitbucket.org/eigen/eigen/get/default.tar.gz\",\r\n      ],\r\n      #sha256 = \"ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4\",\r\n      sha256 = \"03a9a0e81da9085fd8af8406d9846521d1eb84a4c0e1fdac5dbe99e5cbdb8abd\",\r\n      #strip_prefix = \"eigen-eigen-f3a22f35b044\",\r\n      strip_prefix = \"eigen-eigen-940f20dd4eb3\",\r\n      build_file = str(Label(\"//third_party:eigen.BUILD\")),\r\n  )\r\n", "@skjensen I'm running into a certificate issue trying to use that eigen URL. Did you encounter this? I get:\r\n\r\n```\r\nERROR: /home/tensorflow/tensorflow/tools/pip_package/BUILD:100:1: no such package \r\n'@eigen_archive//': Error downloading [https://bitbucket.org/eigen/eigen/get/default.tar.gz]\r\nto /home/.cache/bazel/_bazel_david/9a6a3e878a69de23dea27378a84b120f/external/eigen_archive/default.tar.gz:\r\nsun.security.validator.ValidatorException: PKIX path building failed:\r\nsun.security.provider.certpath.SunCertPathBuilderException:\r\nunable to find valid certification path to requested target and referenced by\r\n'//tensorflow/tools/pip_package:licenses'.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\nINFO: Elapsed time: 15.916s\r\n```", "I had strange problems with the default.tar.gz too, so I used the real commit ID of master head. Which in my opinion is better because the hash will not change wir every new commit made to the Eigen master branch. ", "@nylocx is that with `940f20dd4eb3`? I'm getting the same certificate error on my end with that. I'll search around and see if it's a Java problem.", "I didn't experience any issues with the certificate, just check the name of the file and the sha256sum of the file you download is matching the snip of the config I showed above. \r\n\r\nDo a bazel clean before you try build it again.", "@nylocx any luck with the #9638?", "@ggael please check #9638. Please also let us know when can we expect new release tagged for eigen?", "Hi, yes I had partiall success.\r\nI had to deactivate AVX512F optimization to get rid of the errors and used the eigen Version I posted at #9638", "What is the flag to disable AVX512X?", "In the configure step I used march=broadwell for optimization instead of march=native or skylake.", "This is error it gives when I tried it.\r\n```gcc: error: broadwell: No such file or directory```", "You used this line in the configure step?\r\n\r\n> Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: -march=broadwell\r\n", "So, what is the current state of play?  How do we compile with eigen?", "I can confirm on the Raspberry Pi 3B, you need to use the Eigen development branch tarball (http://bitbucket.org/eigen/eigen/get/default.tar.gz) and change the workspace.bzl file accordingly to get TF to build successfully.\r\n\r\nAs of today, this is what worked for me:\r\n\r\n```\r\ndiff --git a/tensorflow/workspace.bzl b/tensorflow/workspace.bzl\r\nindex bb140946d..c7b66a3bc 100644\r\n--- a/tensorflow/workspace.bzl\r\n+++ b/tensorflow/workspace.bzl\r\n@@ -169,11 +169,10 @@ def tf_workspace(path_prefix=\"\", tf_repo_name=\"\"):\r\n   native.new_http_archive(\r\n       name = \"eigen_archive\",\r\n       urls = [\r\n-          \"http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n-          \"https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n+          \"http://bitbucket.org/eigen/eigen/get/default.tar.gz\",\r\n       ],\r\n-      sha256 = \"ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4\",\r\n-      strip_prefix = \"eigen-eigen-f3a22f35b044\",\r\n+      sha256 = \"d1fb5da2ef28ee3a30a3e33c2a3392a7cc3e2337e2fe86ec7b57664f23c33aab\",\r\n+      strip_prefix = \"eigen-eigen-dc83e26d8a3c\",\r\n       build_file = str(Label(\"//third_party:eigen.BUILD\")),\r\n   )\r\n```\r\n\r\nObviously, you need to check the sha256 of your tarball ('sha256sum default.tar.gz' etc.) and verify its strip_prefix ('tar -tvf default.tar.gz') before making the above changes since the Eigen development branch release can change at anytime. I also recommend watching either the Lord of the Rings Extended Editions or perhaps Stranger Things (pick a season) all the way through once you start the build. It'll be a while before a wheel pops out.", "@pisymbol Thanks that's very helpful as I'm trying to build it on the rpi3.  Which version of tf are you  using?  I'm using the r1.2 branch.\r\nYes I've just finished building bazel which took probably, oh about 18 hours or so.  And I forgot to update my manifests so installed 0.50, which I'm guessing probably means I have to stick to tf 1.2 (which takes another 24 hours to build..).  Painful stuff..", "I just built trunk successfully (a variant of 1.3). I'm on Stretch (Debian 9). See here:\r\n\r\n```\r\npisymbol@hal:~ $ python3 -c 'import tensorflow as tf; print(tf.__version__)'\r\n1.3.0\r\n```\r\n\r\nI built trunk btw because at some point a RPi #define was added to the build so you have don't have to make a lot of the \"arm\" specific build changes you read about.\r\n\r\nDon't worry, I built an older version of bazel too and then realized that TF can't use it  (requires 0.5.4+). Joy. So I had to download and built bazel again! Another upteen hours gone. And then TF failed to build several times after many hours of trial and error (trying to aggregate the many incorrect build instructions currently out on the Ether).\r\n\r\nAnyway, if you use the Eigen development branch tarball as per above, TF builds all the way through with no issue for me.\r\n\r\n\r\n\r\n", "Oh, OK thanks (sobs gently to himself)\r\n", "@pisymbol Does the r1.3 branch contain the rpi #defines?", "I can't see any reference to bazel versions in the tensorflow source compile docs. Bazel is up to 0.7.0 now.", "There **should** be a warning about old versions of Bazel. Did that not trigger for you? Is it simply out of date or is it broken?", "@martinwicke the build is automated so I wouldn't have seen it:\r\nhttps://github.com/fnoop/maverick/blob/stable/manifests/maverick-modules/maverick_intelligence/manifests/tensorflow.pp\r\n\r\nIf there's a minimum version shouldn't it fail rather than warn?  And minimum dependencies should be somewhere in the source build docs?", "My build did fail with a message I needed 0.5.4 or higher. Again this was on master. I haven't looked if the RPi3 build changes made it to r1.3 (I would suspect not, i.e. I wouldn't backport them to the maintenance branch and I think someone said RPi support would come in 1.4 but don't hold me to it).", "@pisymbol Thanks for confirming.  Sorry I tried to build r1.2 with bazel 0.5.0 which should be OK, although recent r1.2 doesn't build on the raspberry any longer - it used to.  I'm trying to build bazel 0.7.0 now with r1.3, but maybe I'll just head to the current master.  Will report back with story of success or dismal failure :)", "Aha!  There are now binary wheels for raspberry quad and single core variants which work well:\r\nhttps://petewarden.com/2017/08/20/cross-compiling-tensorflow-for-the-raspberry-pi/\r\n\r\nSorry for the noise on this issue.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Sorry, this is a pretty long thread and our build has changed substantially since May last year. IF you still have that problem, could you please open a new ticket? Thanks."]}, {"number": 9696, "title": "Epoch is not working properly for tensorflow keras -  KerasRegressor", "body": "I'm just getting start with Keras using tensorflow, In the code code I have specified **nb_epoch=100** but it's not running for 100 epoch, instead it's executing only for 10 epoch. I wonder is there any bug in my code. Also attaching the output in the bottom\r\n\r\n**Code:**\r\n\r\n```python\r\n\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.model_selection import train_test_split\r\nimport sklearn.metrics as metrics\r\nfrom utils import encode_numeric_zscore, to_xy\r\n\r\ndataset = pd.read_csv('data/boston-housing.csv', dtype=np.float32)\r\n\r\nfor col in dataset.columns:\r\n    if col != 'medv':\r\n        encode_numeric_zscore(dataset, col)\r\n\r\nfeatures, target = to_xy(dataset, 'medv')\r\n\r\nX_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.25, random_state=42)\r\n\r\n\r\ndef chart_regression(pred, y):\r\n    t = pd.DataFrame({'pred': pred, 'y': Y_test.flatten()})\r\n    t.sort_values(by=['y'], inplace=True)\r\n    a = plt.plot(t['y'].tolist(), label='expected')\r\n    b = plt.plot(t['pred'].tolist(), label='prediction')\r\n    plt.ylabel('output')\r\n    plt.legend()\r\n    plt.show()\r\n\r\n\r\nfrom tensorflow.contrib.keras.api.keras.models import Sequential\r\nfrom tensorflow.contrib.keras.api.keras.layers import Dense, Dropout\r\n\r\n\r\ndef build_nn():\r\n    model = Sequential()\r\n    model.add(Dense(75, input_shape=(13,), activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\r\n    model.add(Dense(55, activation=\"relu\"))\r\n    model.add(Dropout(0.005))\r\n    model.add(Dense(35, activation=\"relu\"))\r\n    model.add(Dropout(0.005))\r\n    model.add(Dense(11, activation=\"relu\"))\r\n    model.add(Dropout(0.005))\r\n    model.add(Dense(1, activation='relu', kernel_initializer=\"normal\"))\r\n    model.compile(loss='mean_squared_error', optimizer='adam')\r\n    return model\r\n\r\n\r\nseed = 7\r\nnp.random.seed(seed)\r\n\r\nfrom tensorflow.contrib.keras.api.keras.wrappers.scikit_learn import KerasRegressor\r\n\r\nregressor = KerasRegressor(build_fn=build_nn, nb_epoch=100, batch_size=1, verbose=1)\r\n\r\nregressor.fit(X_train, Y_train)\r\n\r\nprediction = regressor.predict(X_test, batch_size=1)\r\n\r\nscore = metrics.mean_squared_error(Y_test, prediction)\r\n\r\nprint('\\n')\r\n\r\nprint(\"Final score (MSE): {}\".format(score))\r\n\r\nprint('\\n')\r\n\r\nscore = np.sqrt(metrics.mean_squared_error(prediction, Y_test))\r\nprint(\"Final score (RMSE): {}\".format(score))\r\n\r\nchart_regression(prediction, Y_test)\r\n```\r\n\r\n**Output:**\r\n\r\n```\r\nEpoch 1/10\r\n2017-05-05 15:30:37.711608: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.711981: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.712355: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.712721: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.713094: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.713463: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.713839: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-05 15:30:37.714213: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n  1/379 [..............................] - ETA: 107s - loss: 492.8400\r\n 60/379 [===>..........................] - ETA: 1s - loss: 669.9998  \r\n109/379 [=======>......................] - ETA: 0s - loss: 625.8113\r\n172/379 [============>.................] - ETA: 0s - loss: 461.0169\r\n233/379 [=================>............] - ETA: 0s - loss: 353.9863\r\n286/379 [=====================>........] - ETA: 0s - loss: 294.3637\r\n336/379 [=========================>....] - ETA: 0s - loss: 254.4181\r\n379/379 [==============================] - 0s - loss: 230.0349     \r\nEpoch 2/10\r\n  1/379 [..............................] - ETA: 0s - loss: 8.0337\r\n 55/379 [===>..........................] - ETA: 0s - loss: 26.7809\r\n104/379 [=======>......................] - ETA: 0s - loss: 22.0314\r\n171/379 [============>.................] - ETA: 0s - loss: 25.4361\r\n219/379 [================>.............] - ETA: 0s - loss: 28.0947\r\n285/379 [=====================>........] - ETA: 0s - loss: 26.3540\r\n338/379 [=========================>....] - ETA: 0s - loss: 26.1902\r\n379/379 [==============================] - 0s - loss: 24.4095     \r\nEpoch 3/10\r\n  1/379 [..............................] - ETA: 0s - loss: 9.8365\r\n 42/379 [==>...........................] - ETA: 0s - loss: 20.2841\r\n108/379 [=======>......................] - ETA: 0s - loss: 16.0308\r\n161/379 [===========>..................] - ETA: 0s - loss: 18.4792\r\n225/379 [================>.............] - ETA: 0s - loss: 18.9558\r\n288/379 [=====================>........] - ETA: 0s - loss: 16.6939\r\n379/379 [==============================] - 0s - loss: 18.3086     \r\nEpoch 4/10\r\n  1/379 [..............................] - ETA: 0s - loss: 13.7463\r\n 59/379 [===>..........................] - ETA: 0s - loss: 12.0900\r\n115/379 [========>.....................] - ETA: 0s - loss: 18.4202\r\n181/379 [=============>................] - ETA: 0s - loss: 16.6087\r\n244/379 [==================>...........] - ETA: 0s - loss: 15.0061\r\n302/379 [======================>.......] - ETA: 0s - loss: 13.2268\r\n379/379 [==============================] - 0s - loss: 16.0613     \r\nEpoch 5/10\r\n  1/379 [..............................] - ETA: 0s - loss: 25.8912\r\n 65/379 [====>.........................] - ETA: 0s - loss: 28.8039\r\n123/379 [========>.....................] - ETA: 0s - loss: 21.3528\r\n199/379 [==============>...............] - ETA: 0s - loss: 17.8586\r\n256/379 [===================>..........] - ETA: 0s - loss: 19.4171\r\n327/379 [========================>.....] - ETA: 0s - loss: 17.9864\r\n379/379 [==============================] - 0s - loss: 18.2714     \r\nEpoch 6/10\r\n  1/379 [..............................] - ETA: 0s - loss: 2.0872\r\n 61/379 [===>..........................] - ETA: 0s - loss: 18.4408\r\n115/379 [========>.....................] - ETA: 0s - loss: 16.9127\r\n184/379 [=============>................] - ETA: 0s - loss: 16.9419\r\n247/379 [==================>...........] - ETA: 0s - loss: 16.2630\r\n314/379 [=======================>......] - ETA: 0s - loss: 14.9947\r\n379/379 [==============================] - 0s - loss: 13.5761     \r\nEpoch 7/10\r\n  1/379 [..............................] - ETA: 0s - loss: 0.3704\r\n 59/379 [===>..........................] - ETA: 0s - loss: 15.2191\r\n118/379 [========>.....................] - ETA: 0s - loss: 11.8381\r\n188/379 [=============>................] - ETA: 0s - loss: 10.9623\r\n247/379 [==================>...........] - ETA: 0s - loss: 10.0409\r\n313/379 [=======================>......] - ETA: 0s - loss: 12.4478\r\n379/379 [==============================] - 0s - loss: 13.8573     \r\nEpoch 8/10\r\n  1/379 [..............................] - ETA: 0s - loss: 1.2173\r\n 44/379 [==>...........................] - ETA: 0s - loss: 12.5116\r\n 96/379 [======>.......................] - ETA: 0s - loss: 10.2578\r\n170/379 [============>.................] - ETA: 0s - loss: 11.9057\r\n227/379 [================>.............] - ETA: 0s - loss: 12.1961\r\n287/379 [=====================>........] - ETA: 0s - loss: 14.4951\r\n341/379 [=========================>....] - ETA: 0s - loss: 13.7772\r\n379/379 [==============================] - 0s - loss: 13.2340     \r\nEpoch 9/10\r\n  1/379 [..............................] - ETA: 0s - loss: 0.1982\r\n 53/379 [===>..........................] - ETA: 0s - loss: 9.8250\r\n124/379 [========>.....................] - ETA: 0s - loss: 9.8112\r\n175/379 [============>.................] - ETA: 0s - loss: 10.9075\r\n238/379 [=================>............] - ETA: 0s - loss: 11.3589\r\n303/379 [======================>.......] - ETA: 0s - loss: 13.8970\r\n379/379 [==============================] - 0s - loss: 14.5469     \r\nEpoch 10/10\r\n  1/379 [..............................] - ETA: 0s - loss: 3.7164\r\n 49/379 [==>...........................] - ETA: 0s - loss: 14.6596\r\n116/379 [========>.....................] - ETA: 0s - loss: 15.5960\r\n172/379 [============>.................] - ETA: 0s - loss: 13.6525\r\n223/379 [================>.............] - ETA: 0s - loss: 12.9588\r\n275/379 [====================>.........] - ETA: 0s - loss: 12.4905\r\n347/379 [==========================>...] - ETA: 0s - loss: 13.5629\r\n379/379 [==============================] - 0s - loss: 13.1696     \r\n  1/127 [..............................] - ETA: 1s\r\n\r\nFinal score (MSE): 11.964310646057129\r\n\r\n\r\nFinal score (RMSE): 3.458946466445923\r\n\r\n```", "comments": ["You should use the keyword `epochs`, not `nb_epoch` (which is deprecated).", "@fchollet Thanks !!"]}, {"number": 9695, "title": "convert a tensor to matrix", "body": "Hi,\r\n output of first layer cnn , \"if  input was a image with size[100,150] then the output layer is a tensor (1,100,150,32)\"\r\nfor slicing The first image from all 32 output images, i used this code:\r\nconv1 = tf.layers.conv2d( image, filters=32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\r\nfirst_image=slice(conv1,[0,0,0,0],[1, 100, 152, 1])\r\n\r\n>>conv1 is  tensor (1, 100, 150 ,32)\r\n>>first_image is tensor (1, 100 ,150 , 1)\r\n\r\nhas the Tensorflow  a command for convert a tensor to 2-D matrix directly ?, or how can convert a tensor to matrix in Tensorflow?\r\n\r\n\r\n", "comments": ["You can reshape a tensor using `tf.reshape`, if that's what you need.\r\n\r\nThere might be a function here: https://www.tensorflow.org/api_guides/python/array_ops#Shapes_and_Shaping that might help you.\r\n\r\nThis question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9694, "title": "Possible bug in TensorFlowInferenceInterface", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.1.0rc2\r\n- **Bazel version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: Not using\r\n- **GPU model and memory**: Not using\r\n- **Exact command to reproduce**: Need to run tensorflow code in Android\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI was testing a trained my style transfer model on android. It uses depthwise separable convolution to decrease the size of neural network. When working on square images, it gives good results. But when I work with it on rectangular images, it gives weird results. Please see the result images attached. I highly doubt that this is due to my code because it is giving good results on all kinds of images on my laptop.\r\nThe style image was the famous painting 'la muse'\r\nContent image:\r\n![content](https://cloud.githubusercontent.com/assets/6660192/25755856/3ad8a43c-31e2-11e7-91f7-9758177f2002.jpg)\r\nResult image for rectangular input:\r\n![rectangular_image_result](https://cloud.githubusercontent.com/assets/6660192/25755900/600d2638-31e2-11e7-9593-890a42360f61.png)\r\nResult image for square input:\r\n![square_image_result](https://cloud.githubusercontent.com/assets/6660192/25755899/60060d8a-31e2-11e7-89c2-ce554c831e7c.png)\r\n \r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nThis is the code I used for running the network on android using TensorflowInferenceInterface\r\n  private void stylizeImage(final Bitmap bitmap) {\r\n    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n\r\n    for (int i = 0; i < intValues.length; ++i) {\r\n      final int val = intValues[i];\r\n      floatValues[i * 3] = ((val >> 16) & 0xFF) / 255.0f;\r\n      floatValues[i * 3 + 1] = ((val >> 8) & 0xFF) / 255.0f;\r\n      floatValues[i * 3 + 2] = (val & 0xFF) / 255.0f;\r\n    }\r\n\r\n    inferenceInterface.feed(\r\n        INPUT_NODE, floatValues, 1, bitmap.getWidth(), bitmap.getHeight(), 3);\r\n\r\n    inferenceInterface.run(new String[] {OUTPUT_NODE}, false);\r\n    inferenceInterface.fetch(OUTPUT_NODE, outValues);\r\n\r\n    for (int i = 0; i < intValues.length; ++i) {\r\n      intValues[i] =\r\n          0xFF000000\r\n              | ((outValues[i * 3]) << 16)\r\n              | ((outValues[i * 3 + 1]) << 8)\r\n              | (outValues[i * 3 + 2]);\r\n    }\r\n\r\n    bitmap.setPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n  }\r\n", "comments": ["@keveman This sort of behavior is expected when using non-square inputs, correct?\r\n\r\n@singlasahil14 As a workaround, you might try padding the image on top and bottom so that it is square, stylizing, and then re-cropping.", "Could it be that you mixed up the image width and height? For example, the common format is `[batch, height, width, depth]`, so you may want to check that.", "Closing due to lack of activity; please respond with additional info if the issue persists."]}, {"number": 9693, "title": "Added 2 unit tests for BasicLSTMCell to check ValueError.", "body": "- Tests that dimension 0 in both(x and m) shape must be equal.\r\n- Tests that state_size must be num_units * 2.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 9692, "title": "request for updating readme in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx", "body": "OS: Ubuntu 16.04 64bits\r\nAndroid Version: 7.1 (Nougat)\r\nNDK Version: android-ndk-r10b\r\nHEXAGON SDK: 3.1\r\nnnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib\r\n\r\nFollowing steps to get tensorflow up on hexagon from `https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx`\r\n1) Please update `git clone https://source.codeaurora.org/quic/hexagon_nn/nnlib` with \r\n`git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git` in the readme\r\n\r\n2) tensorflow/contrib/makefile/downloads/protobuf/autogen.sh:\r\n\r\nbelow autogen.sh is modified gmock ->(with) googlemock\r\nas well gtest ->(with) googletest.\r\n\r\nas `m4_include(../googletest/m4/acx_pthread.m4)` in `tensorflow/contrib/makefile/downloads/protobuf/googlemock/configure.ac` is referring to googletest.\r\n\r\n\r\n```\r\nif test ! -e googlemock; then\r\n   echo \"Google Mock not present.  Fetching gmock-1.7.0 from the web...\"\r\n   curl $curlopts -L -O https://github.com/google/googlemock/archive/release-1.7.0.zip\r\n   unzip -q release-1.7.0.zip\r\n   rm release-1.7.0.zip\r\n   mv googlemock-release-1.7.0 googlemock\r\n \r\n   curl $curlopts -L -O https://github.com/google/googletest/archive/release-1.7.0.zip\r\n   unzip -q release-1.7.0.zip\r\n   rm release-1.7.0.zip\r\n   mv googletest-release-1.7.0 googlemock/googletest\r\n fi\r\n```\r\n\r\nplease let me know gtest/gmock is getting reffered somewhere as it can be modified to googletest/googlemock in protobuf/autogen.sh\r\n\r\n\r\nthanks.", "comments": ["This looks like it's an issue inside protobuf -- which itself is downloaded by the makefile. I'd file an issue with https://github.com/google/protobuf. \r\n\r\nPlease comment to reopen if I misunderstood the issue.", "sorry, I had mentioned only issue related to autogen.sh\r\n\r\nThere was this other one,\r\n\r\nprotobuf, googletest are getting downloaded under downloads folder,\r\n when build command is issued, `protoc missing error` as it expects googletest and googlemock to be present in specific order under protobuf, {debug info was not enough to catch this at first sight}.\r\n\r\njust to make sure nobody gets stuck, please check information provided on readme is enough to get hexagon graph up and running.\r\n\r\nthanks."]}, {"number": 9691, "title": "hexagon_graph_execution runs for only one test and gets stuck there. Cannot execute until restart of target.", "body": "OS: Ubuntu 16.04 64bits\r\nAndroid Version: 7.1 (Nougat)\r\nNDK Version: android-ndk-10b\r\nHEXAGON SDK: 3.1\r\nnnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib\r\n\r\n\r\n```\r\n$ adb shell 'LD_LIBRARY_PATH=/data/hex_tf:$LD_LIBRARY_PATH' /data/hex_tf/hexagon_graph_execution\r\n WARNING: linker: Warning: unable to normalize \"\"\r\n Running main() from test_main.cc\r\n [==========] Running 1 test from 1 test case.\r\n [----------] Global test environment set-up.\r\n [----------] 1 test from GraphTransferer\r\n [ RUN      ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime\r\n native : hexagon_graph_execution_test.cc:446 Fuse and run inception v3 on hexagon with tf runtime\r\n native : hexagon_graph_execution_test.cc:72 Hexagon controller version is 90\r\n native : hexagon_graph_execution_test.cc:122 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes\r\n native : hexagon_graph_execution_test.cc:128 header size = 54\r\n native : hexagon_graph_execution_test.cc:130 image size = 40\r\n native : hexagon_graph_execution_test.cc:132 width = 299\r\n native : hexagon_graph_execution_test.cc:134 height = -299\r\n native : hexagon_graph_execution_test.cc:458 loading image finished.\r\n native : hexagon_graph_execution_test.cc:465 Build fused graph\r\n can't determine number of CPU cores: assuming 4\r\n can't determine number of CPU cores: assuming 4\r\n native : op_def_util.cc:332 Op PlaceholderV2 is deprecated. It will cease to work in GraphDef version 23. Placeholder now behaves the same as PlaceholderV2..\r\n native : hexagon_graph_execution_test.cc:122 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes\r\n native : hexagon_graph_execution_test.cc:128 header size = 54\r\n native : hexagon_graph_execution_test.cc:130 image size = 40\r\n native : hexagon_graph_execution_test.cc:132 width = 299\r\n native : hexagon_graph_execution_test.cc:134 height = -299\r\n native : hexagon_graph_execution_test.cc:262 loading image finished.\r\n native : hexagon_graph_execution_test.cc:170 loading image finished.\r\n native : hexagon_graph_execution_test.cc:174 Copy data to tensor.\r\n native : hexagon_graph_execution_test.cc:284 Run graph\r\n Init hexagon with max attributes (Controller version = 92)\r\n native : hexagon_control_wrapper.cc:252 Setup graph completed\r\n Execute graph!\r\n Execution succeeded!\r\n native : hexagon_graph_execution_test.cc:291 Output byte size = 4032\r\n native : hexagon_graph_execution_test.cc:292 Output shape = [1,1008]\r\n native : graph_transfer_utils.cc:46 === Dump ranking ===\r\n native : graph_transfer_utils.cc:49 0: 59, Yorkshire terrier, 0.829043\r\n native : graph_transfer_utils.cc:49 1: 4, Australian terrier, 0.048217\r\n native : graph_transfer_utils.cc:49 2: 89, toy terrier, 0.00723796\r\n native : graph_transfer_utils.cc:49 3: 131, silky terrier, 0.00347867\r\n native : graph_transfer_utils.cc:49 4: 43, papillon, 0.00160137\r\n native : graph_transfer_utils.cc:49 5: 145, Norwich terrier, 0.00134778\r\n native : graph_transfer_utils.cc:49 6: 160, wire-haired fox terrier, 0.000875875\r\nnative : graph_transfer_utils.cc:49 7: 926, pickelhaube, 0.000647765\r\n native : graph_transfer_utils.cc:49 8: 173, Chihuahua, 0.00062044\r\n native : graph_transfer_utils.cc:49 9: 127, affenpinscher, 0.000569199\r\n Finalize hexagon\r\n [       OK ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime (5027 ms)\r\n [----------] 1 test from GraphTransferer (5027 ms total)\r\n \r\n [----------] Global test environment tear-down\r\n [==========] 1 test from 1 test case ran. (5027 ms total)\r\n [  PASSED  ] 1 test.\r\n \r\n   YOU HAVE 4 DISABLED TESTS\r\n \r\n```\r\n \r\n---\r\n\r\nAfter this log, hvx session doesn't respond, suspicion is dsp/rpc session is not getting closed properly.\r\nkill the process and again try to run the process, it gets stuck at :\r\n\r\n\r\n```\r\nWARNING: linker: Warning: unable to normalize \"\"\r\nRunning main() from test_main.cc\r\n[==========] Running 1 test from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 1 test from GraphTransferer\r\n[ RUN      ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime\r\nnative : hexagon_graph_execution_test.cc:446 Fuse and run inception v3 on hexagon with tf runtime\r\n```\r\n\r\nplease try to reproduce.\r\n", "comments": ["Hello @satok16 , you have anything to comment on this.?", "That seems to be a qualcomm's firmware issue.  Once the firmware gets stucked, there is no way to recover from tensorflow side.", "okay, lookslike, \r\n\r\ni have few queries,\r\n```\r\n\r\n\r\n [----------] 1 test from GraphTransferer (5027 ms total)\r\n \r\n [----------] Global test environment tear-down\r\n [==========] 1 test from 1 test case ran. (5027 ms total)\r\n [  PASSED  ] 1 test.\r\n \r\n   YOU HAVE 4 DISABLED TESTS\r\n\r\n\r\n```\r\nafter this log, tf is not returning to shell (any more tests to run further?)\r\nit is stuck somewhere, maybe, \r\nhexagon de_init is not happening,\r\n\r\njust to make sure things are happening well at ARM - init/deinit of DSP, fast rpc etc.\r\n\r\nfurther will check from Qcom.\r\n\r\nthanks,\r\n\r\n", "Thanks @kzos ! Please keep us posted.", "@drpngx , @satok16 , There is double free happening in hexagon_nn_lib:do_teardowngraph function, which is causing adsp crash and won't let run the test, until next reboot, If anybody unaware, as a work around, comment teardowngraph as this allows to run test once and exit without crash. Next time run the test without reboot.\r\n\r\nfurther working on debugging hexagon_nnlib: teardown graph and remove double free\r\n\r\nthanks", "Thank you for the heads up!  I'll work with qualcomm guys to fix it.", "what is the workaround for this issue.  how is the double free happening?"]}, {"number": 9690, "title": "Make EIGEN_MAX_ALIGN_BYTES available from Python", "body": "Removing unnecessary memcpys when feeding a Numpy array with a feed_dict is a [recurring feature request](https://github.com/tensorflow/tensorflow/issues/7951) that has large performance implications.\r\n\r\nFrom what I can tell, @alextp [implemented changes](https://github.com/tensorflow/tensorflow/commit/0ffa40ee3d5fae4ff14b75c2525edcaa2f01ece7) that avoid the memcpy if the input array is ``EIGEN_MAX_ALIGN_BYTES`` aligned. For a user to definitely avoid memcpy's on feeding, they would need to make sure their arrays are aligned to ``EIGEN_MAX_ALIGN_BYTES``. Currently, there is no way to access ``EIGEN_MAX_ALIGN_BYTES`` from Python, so the user can't be sure what alignment is required. \r\n\r\nIt would be nice if there was a C API call (and a corresponding Python one) to make ``EIGEN_MAX_ALIGN_BYTES`` available. This isn't a critical feature as the user can currently be very pessimistic on alignment requirements and (probably safely) 64-byte align their inputs.", "comments": ["You can do it as a custom op callable from Python. Here's an example -- https://github.com/yaroslavvb/max_align_bytes_op  . It prints 16 on my mac. But how would you force your numpy arrays to be 16-byte aligned?", "Cool example @yaroslavvb , but it has an error. ``EIGEN_MAX_ALIGN_BYTES`` depends on the compilation flags. For instance, if I add ``-march=native`` to the compiler flags when compiling the op on my AVX compatible box, the op outputs 32 instead of 16. The value from the independently compiled op is more or less independent of the value inside of a given TF binary.\r\n\r\nAny API into this must return the same value used in the core TensorFlow lib, which means it must be compiled with the same relevant flags as the TensorFlow lib, which is easiest done if the functionality is a part of TensorFlow.\r\n\r\nGetting aligned memory from Numpy is harder than it should be: https://github.com/numpy/numpy/issues/5312 . The only way I know of to get aligned memory from Numpy is to just align it yourself:\r\n```\r\nIn [14]: a = np.empty(1000, dtype=np.float32)\r\n\r\nIn [15]: a.ctypes.data\r\nOut[15]: 48297584\r\n\r\nIn [16]: a.ctypes.data % 16\r\nOut[16]: 0\r\n\r\nIn [17]: a.ctypes.data % 32\r\nOut[17]: 16\r\n\r\nIn [18]: b = a[4:]\r\n\r\nIn [19]: b.ctypes.data\r\nOut[19]: 48297600\r\n\r\nIn [20]: b.ctypes.data % 32\r\nOut[20]: 0\r\n```\r\n\r\n```python\r\ndef empty_aligned(n, align):\r\n    \"\"\"                                                                                                                                     \r\n    Get n bytes of memory wih alignment align.                                                                                              \r\n    \"\"\"\r\n\r\n    a = np.empty(n + (align - 1), dtype=np.uint8)\r\n    data_align = a.ctypes.data % align\r\n    offset = 0 if data_align == 0 else (align - data_align)\r\n    return a[offset : offset + n]\r\n```", "Yaroslav, why an op and not a swigged python-c-api function?\n\nOn Fri, May 5, 2017 at 10:10 AM, Eric Martin <notifications@github.com>\nwrote:\n\n> I believe the value changes depending on how TensorFlow was compiled. For\n> instance, I'd guess EIGEN_MAX_ALIGN_BYTES == 16 means you compiled with\n> SSE support, and I'd expect a value of 32 for AVX or 64 for AVX-512.\n>\n> Getting aligned memory from Numpy is harder than it should be:\n> numpy/numpy#5312 <https://github.com/numpy/numpy/issues/5312> . The only\n> way I know of to get aligned memory from Numpy is to just align it yourself:\n>\n> In [14]: a = np.empty(1000, dtype=np.float32)\n>\n> In [15]: a.ctypes.data\n> Out[15]: 48297584\n>\n> In [16]: a.ctypes.data % 16\n> Out[16]: 0\n>\n> In [17]: a.ctypes.data % 32\n> Out[17]: 16\n>\n> In [18]: b = a[4:]\n>\n> In [19]: b.ctypes.data\n> Out[19]: 48297600\n>\n> In [20]: b.ctypes.data % 32\n> Out[20]: 0\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9690#issuecomment-299521465>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxQXYUTo7LSJXTkPcmrCtixFAPpiuks5r21gRgaJpZM4NSH6U>\n> .\n>\n\n\n\n-- \n - Alex\n", "@alextp Because I just forked my https://github.com/yaroslavvb/memory_probe_ops and changed 3 lines :) SWIG sounds better for reasons @eamartin  mentioned.\r\n\r\nWondering what happened to [PyClif](https://pypi.python.org/pypi/pyclif/0) the SWIG replacement ...", "@alextp A Python / C API function is the way to go. It's a nicer interface and would be tricky to be correct otherwise (for reasons explained in my sneaky edit/update of my previous comment).", "@rohan100jain do you know if it's easy to add a swig-wrapped function somewhere in contrib?", "@benoitsteiner are you planning to do this? If not, please unassign yourself and mark contributions welcome if appropriate.", "@alextp I believe we don't have an easy mechanism / process right now. All our swig wrapped stuff is in python/tensorflow.i and that is all core stuff. \r\n\r\nI guess the only path forward would be to add a SWIG target like https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/BUILD#L2748 to someplace in contrib and expose it. ", "Unfortunately creating a new SWIG target has its own pitfalls, namely that loading two SWIG libraries causes static initializers in TensorFlow to clobber each other (I went down this path once). I think all new SWIG files have to be added to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tensorflow.i in core, but the new include could be in contrib.", "For those wondering, EIGEN_MAX_ALIGN_BYTES seems to be 32 for xeon/i7 with march=native", "Nagging Assignee @skye: It has been 384 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing as this is resolved"]}, {"number": 9689, "title": "ImportError: No module named tensorflow", "body": "ImportError                               Traceback (most recent call last)\r\n<ipython-input-3-ac22e13aedab> in <module>()\r\n      1 import numpy\r\n----> 2 from keras.datasets import mnist\r\n      3 from keras.models import Sequential\r\n      4 from keras.layers import Dense\r\n      5 from keras.layers import Dropout\r\n\r\nC:\\Users\\Dilip\\Anaconda2\\lib\\site-packages\\keras\\__init__.py in <module>()\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import activations\r\n      4 from . import applications\r\n      5 from . import backend\r\n\r\nC:\\Users\\Dilip\\Anaconda2\\lib\\site-packages\\keras\\activations.py in <module>()\r\n      2 import six\r\n      3 import warnings\r\n----> 4 from . import backend as K\r\n      5 from .utils.generic_utils import deserialize_keras_object\r\n      6 from .engine import Layer\r\n\r\nC:\\Users\\Dilip\\Anaconda2\\lib\\site-packages\\keras\\backend\\__init__.py in <module>()\r\n     71 elif _BACKEND == 'tensorflow':\r\n     72     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 73     from .tensorflow_backend import *\r\n     74 else:\r\n     75     raise ValueError('Unknown backend: ' + str(_BACKEND))\r\n\r\nC:\\Users\\Dilip\\Anaconda2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>()\r\n----> 1 import tensorflow as tf\r\n      2 from tensorflow.python.training import moving_averages\r\n      3 from tensorflow.python.ops import tensor_array_ops\r\n      4 from tensorflow.python.ops import control_flow_ops\r\n      5 from tensorflow.python.ops import functional_ops\r\n\r\nImportError: No module named tensorflow\r\n", "comments": ["can anyone help me step by step process to fix the errors\r\n", "Did u install tensorflow in root directory of anaconda or created a virtual environment ? If you created a virtual environment then you need to activate it.\r\n\r\n```\r\nsource activate <environment name>\r\n```", "Have you paid attention to which version of Python (and Pip) you used during setup?", "Looks like you have a broken installation of tensorflow. Please try to re-install, and as @SrivastavaKshitij suggest, active.", "Closing due to inactivity."]}, {"number": 9688, "title": "Tensorboard \"Color by\" drop-down not showing up on multi-column .tsv", "body": "------------------------\r\n\r\n### System information\r\n- **using tensorboard to visualize some embeddings**:\r\n- **OSX 10.12.4**:\r\n- **installed from binary via pip**:\r\n- **1.1.0**:\r\n- **not using bazel for this install**:\r\n- **no CUDA**:\r\n- **no GPU**:\r\n\r\n### Describe the problem\r\nTensorboard does not display the ```Color By``` dropdown menu on multi-columnar data. ```Label by``` and ```search by``` displaying columns normally.\r\n\r\n![tensorboard dropdown issue](https://github.com/markostam/sandbox/blob/master/photos/Screenshot%202017-05-05%2011.39.26.png?raw=true)\r\n\r\n### Source code / logs\r\nSample of ```metadata.tsv``` file:\r\n```\r\nName\tGenre\r\n(Sandy) Alex G\tAlternative/Indie Rock\t\r\n*NSYNC\tPop/Rock\t\r\nAcollective\tPop/Rock\t\r\nAhmet \u00d6zhan\tInternational\t\r\nAhu\tClub/Dance\t\r\nAlex Ferreira\tPop/Rock\t\r\nAlex Winston\tPop/Rock\t\r\nAli Azimi\tPop/Rock\t\r\nAlphamama\tPop/Rock\t\r\nAmaryllis\tInternational\t\r\n...\r\nYomo Toro\tLatin\r\nYoussou N'Dour\tInternational\r\nZafra Negra\tLatin\r\nZany\tElectronic\t\r\nZeki M\u00fcren\tInternational\r\niSHi\tElectronic\t\r\n```\r\nCode to generate embeddings and metadata:\r\n```python\r\ndef list_to_tsv(filenames, metadata_dir):\r\n    with open(os.path.join(metadata_dir,'metadata.tsv'), 'w') as tsvfile:\r\n        writer = csv.writer(tsvfile, delimiter = \"\\t\")\r\n        for record in filenames:\r\n            writer.writerow(record)\r\n\r\ndef save_down_tensors(tensor_dir, name_and_embedding):\r\n    embeddings = [i[2] for i in name_and_embedding] \r\n    names = [[i[0],i[1]] for i in name_and_embedding]\r\n    names.insert(0,['Name','Genre'])\r\n    with tf.Session() as sess:\r\n        embeddings_tf = tf.Variable(np.array(embeddings), name = \"embeddings\")\r\n        tf.global_variables_initializer().run()\r\n        # save the tensor down\r\n        saver = tf.train.Saver(tf.global_variables())\r\n        saver.save(sess, tensor_dir, 0)\r\n        # associate metadata with the embedding\r\n        summary_writer = tf.summary.FileWriter(tensor_dir)\r\n        config = projector.ProjectorConfig()\r\n        embedding = config.embeddings.add()\r\n        embedding.tensor_name = embeddings_tf.name\r\n        #save filenames to tsv\r\n        list_to_tsv(names, metadata_dir)\r\n        embedding.metadata_path = os.path.join(metadata_dir, \"metadata.tsv\")\r\n        # save a configuration file that TensorBoard will read during startup.\r\n        projector.visualize_embeddings(summary_writer, config)\r\n```", "comments": ["Migrated to https://github.com/tensorflow/tensorboard"]}, {"number": 9687, "title": "Fix devel Docker image build under MKL configuration", "body": "This is a follow-up fix to PR:\r\nhttps://github.com/tensorflow/tensorflow/pull/9580", "comments": []}, {"number": 9686, "title": "Map Staging Area", "body": "I liked the idea of StagingArea but I wanted more functionality out of it. I've implemented an Associative StagingArea backed by C++ `std::map` and `std::unordered_map`.\r\n\r\nFunctionality:\r\n- Keys are int64, Values are just like StagingArea Tensors or list of Tensors.\r\n- put(key, value), get(key),  pop(key), popitem(), size(), clear() operations\r\n- Can choose ordered `std::map` (Get a basic priority queue with popitem()) or unordered `std::unordered`.\r\n- Can specify a capacity which inserts will wait on, if not, it will be unbounded.\r\n\r\nHave tested that this works on CPU + GPU in a custom op library. I haven't tested the compile on my laptop due to #9634, but I've cut and pasted the relevant sections into the tensorflow code base for your perusal.\r\n\r\nLet me know if you're keen to merge this and I can clean it up a bit further.", "comments": ["Can one of the admins verify this patch?", "Hi Simon,\r\n\r\nThanks for this nice patch.  We had a couple of thoughts for a re-organization to avoid creating multiple classes with slightly different functionality and naming conventions:\r\n\r\n1) Rather than creating new python high level ops, could we slightly modify the existing StagingArea interface by adding an optional key argument to get and put?  If the key is present, then your C++ ops would be used, otherwise the current C++ ops would be used.  The constructor could take an argument that decides on ordering.\r\n\r\n2) Your pop method would map to get and if you want to retain the ability to inspect the StagingArea without removing an element, then add a new method 'peek'.\r\n\r\n3) You can choose to add fixed capacity to the existing StagingArea or remove it from the new classes (so only unbounded).\r\n\r\nThanks,\r\nErich", "> Rather than creating new python high level ops, could we slightly modify the existing StagingArea interface by adding an optional key argument to get and put? If the key is present, then your C++ ops would be used, otherwise the current C++ ops would be used. The constructor could take an argument that decides on ordering.\r\n\r\nI disagree with this approach because two very different data structures are being exposed and I think it would be a mistake to combine their interface. They offer different [affordances](https://en.wikipedia.org/wiki/Affordance) (see Norman's [The Design of Everyday Things](https://en.wikipedia.org/wiki/The_Design_of_Everyday_Things)) to the user. Thus:\r\n\r\n1. Mixing the interfaces will be confusing for the end user. StagingArea behaves like a list while MapStagingArea behaves like a dict. \r\n2. I actually think it will be more difficult to maintain since the combination of interfaces is confusing.\r\n3. Does the data for the list exist in a different container from the dict?\r\n4. What happens if the user puts without a key and then then tries to get with a key?\r\n\r\nI think the following would be better:\r\n\r\n1. Keep the separate list (StagingArea) vs map (MapStagingArea) python classes\r\n2. Move common functionality into a Base Class (coloc op, dtype, shape, name, return value handling etc.)\r\n3. Rename `get(key)` to `peek(key)` in the dict. I dislike losing the name of the python dict method, but it probably too late to change `get()` to `pop()` in the list.\r\n4. Add `peek(index)`, `size` and `clear` methods to the list (Already got a size op for the list).\r\n\r\n> You can choose to add fixed capacity to the existing StagingArea or remove it from the new classes (so only unbounded).\r\n\r\nOK I can do this.\r\n", "That works, thanks again.\r\n\r\nRe: 3) Make sure to also change pop in the dict to get.", "> Re: 3) Make sure to also change pop in the dict to get.\r\n\r\nJust realised it may make more sense `popitem()` changed to `get()`, since `popitem`  currently takes no `key` argument (it returns a random element if unordered or the max element if ordered), while `pop(key)` returns an element based on a key. Do you agree?\r\n\r\nI also want to extend the dict methods as follows:\r\n\r\n- `peek(key, default=None)`\r\n- `pop(key, default=None)`\r\n- `setdefault(key, value, default=None)`\r\n\r\nwhere the specified default is returned if no element associated with the key is found.\r\n\r\nAlso I remember someone (maybe @girving) mentioning somewhere that there's a way of placing an int32 input for a GPU op on the CPU (not through HostMemory). IIRC its not really supported but forcing the int64 key to the CPU is a good case for it. Could someone point me to code that does this?", "Maybe if popitem(key=None) == pop() just popitem -> get and \"get\" rid of pop ?\r\n\r\nI don't think is what you want, since it does use HostMemory: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/split_v_op.cc#L383\r\nbut I'm not sure what mechanism @girving was thinking of.\r\n\r\nWhy not do it this way?  You could force the int64 case only to the CPU.", "Hm, are integer types even supported on GPU? There's [this line](https://github.com/tensorflow/tensorflow/blob/a304537954a865752ad1b18461e6bd67b36082db/tensorflow/core/framework/register_types.h#L171) in register_types\r\n\r\n```\r\n// Call \"m\" on all types supported on GPU.\r\n#define TF_CALL_GPU_NUMBER_TYPES(m) \\\r\n  TF_CALL_half(m) TF_CALL_float(m) TF_CALL_double(m)\r\n\r\n```\r\n", "OK I think this is ready for review.\r\n\r\nPlease take note of https://github.com/tensorflow/tensorflow/pull/9686/commits/92d4d732cab8c6b8db83a38166298ed9a4e8961c. I've made StagingArea.peek(index), MapStagingArea.peek(key) and MapStagingArea.get(key) block until the requested index/key is present in the staging area. This means that bounds checks/key lookups may frequently occur in waiting getters when inserters insert their data and notify the getters.", "Just had a thought that it might be good to move the C++ StagingArea and MapStagingArea classes into separate header and source files so that they can be reused as primitives in other ops. I'll try do this soon.", "Can one of the admins verify this patch?", "I've added support for a memory limit in the Staging Areas. I thought that would be useful for constraining memory in GPU Staging Areas.\r\n\r\nI've also added support for partial inserts in the MapStagingArea, similar to the heavyweight Barrier. e.g.\r\n\r\n```python\r\nstage = data_flow_ops.MapStagingArea([tf.float32, tf.int32, tf.float32],\r\n                                                        names=['x', 'y', 'z'])\r\n\r\ninsert_xy = stage.put(0, {'x' : 0, 'y' :1})\r\ninsert_z = stage.put(0,  {'z':2})\r\nget_xyz = stage.get(0)\r\n\r\nassert session.run(get_xyz) == [0, { 'x':0, 'y':1, 'z':2 }]\r\n```\r\n\r\nI didn't get around to the refactor and I can't spend much more time on this so I'll stop with the features at this point.", "One question. I see that structures like FIFOQueue use PersistentTensors, presumably for reasons suggested [here](https://github.com/tensorflow/tensorflow/blob/554b57f74a99ea18baf616ae5e3cff8b137430e6/tensorflow/core/framework/op_kernel.h#L193-L198):\r\n\r\n```c++\r\n// Wraps a tensor that is held by an Op across calls to Compute(). For\r\n// memory safety when using asynchronous devices like GPUs, the system\r\n// must be notified when a Tensor is used inside an Op execution. The\r\n// wrapper ensures that all uses of the Tensor are tracked, because in\r\n// order to retrieve the Tensor the caller must use AccessTensor which\r\n// notifies the context.\r\nclass PersistentTensor { ... };\r\n```\r\n\r\n1. Should the tensors in the Staging Area be wrapped in PersistentTensors?\r\n2. Also, should they be wrapped in PersistentTensors so that they can live in the container across multiple Sessions?\r\n\r\nThe answer to\r\n\r\n1. Might be maybe, because peek() provides access to Tensors inside the container...\r\n2. I think is no.", "@ekelsen could you please take another look and  address @sjperkins's questions?", "Regarding using PersistentTensor, I think PersistentTensor is poorly named and that that comment is a bit out-of-date.  Just using Tensors should be fine.  The PersistentTensor existed to deal with synchronization between multiple GPU streams.", "@tensorflow-jenkins test this please", "@sjperkins Can you address the lint and BUILD file formatting errors here:\r\n\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/4336/consoleFull", "Fixed", "@sjperkins Thanks!\r\n@tensorflow-jenkins test this please\r\n", "@sjperkins it looks like you missed a few.", "@rmlarsen I ran buildifier on the source tree, but it mentions a different extra line (2306) than that mentioned in the log (2355 below). \r\n\r\n```bash\r\n=== Sanity check step 3 of 8: do_buildifier (buildifier check) ===\r\n\r\nRunning do_buildifier on 287 files\r\n\r\ntensorflow/python/kernel_tests/BUILD # reformat \r\n\r\nbuildifier took 0 s\r\n\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n2355d2354\r\n< \r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```\r\n\r\nWould you test again please?", "BTW, can you expand on your use case for the map version of the staging area?  Just out of curiosity...", "@tensorflow-jenkins test this please", "Taking another look", "> BTW, can you expand on your use case for the map version of the staging area? Just out of curiosity...\r\n\r\n1. Partial inserts. Feeding one Staging Area (key, tuple) from multiple (possibly, distributed) locations. i.e. scatter portions of the problem from master/chief and feed other portions of the problem on a local worker. I've a [data source](https://github.com/ska-sa/montblanc/blob/75e47e5a4ee8e7f599b6e5805333a39754beadd8/montblanc/impl/rime/tensorflow/sources/ms_source_provider.py#L84-L213) interface to my computation and I want to allow my users to feed data in multiple places.\r\n2. Capacity and Memory Budget. Feeding a potentially very large set of Tensors onto the GPU asynchronously and making sure that only a restricted portion of the set is on the Staging Area at one time.\r\n3. Peek functionality. Caching Tensors on GPU for the duration of other operations (i.e. point 2).\r\n4. Ordering. I'm grouping data (and computation) by a integer key defined by data tile extents. There's a partial ordering here thats useful to me. Ultimately I want to use this key for [DHT](https://en.wikipedia.org/wiki/Distributed_hash_table) functionality, but a priority queue is always useful.\r\n5. Holding ref-counted Tensors, rather than memcpying tensors slices around.\r\n\r\nIn general, having a stateful hash table in the Graph, logically grouping ref-counted Tensor objects together on either CPUs or GPUs is pretty useful. The Queues always seemed heavyweight (https://github.com/tensorflow/tensorflow/issues/3009, https://github.com/tensorflow/tensorflow/issues/5907, https://github.com/tensorflow/tensorflow/issues/6845) so I wanted to avoid memcpys. I saw some tensor slicing memcpys in Barrier, and it's not always clear what's happening lower down in the PriorityQueue/FIFOQueue level.\r\n\r\n", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "Thanks for the contribution. This is pretty cool stuff!", "@rmlarsen @ekelsen Thanks for the reviews and accepting the PR.", "Ditto on the thanks - this is a great contribution.", "Will this be included in the 1.2.0 release?", "1.2 seems likely, but I can't say for sure.\r\n\r\nBut one minor request - the staging_op_test now takes a bit too long for a \"small\" test.  Can you submit a minor PR that bumps the test from small -> medium?  I'll review and approve quickly.  Thanks!", "Could also consider making the test have a shard count of 2. \"shard_count = 2,\"", "> 1.2 seems likely, but I can't say for sure.\r\n\r\nIt would be helpful if it made it in, as I'm developing with the Map Staging Area as a dependency.", "It seems that this PR has caused the staging_op_test to become flaky.  Sometimes it passes in 30s, sometimes it fails and times out in 300s.  My original intuition to increase the test time was incorrect.  Can you look into a possible race condition?", "(This is blocking merging now, so it is rather important to fix the root cause of the hanging test.)", "We'll likely revert this change for now to unblock merging. Feel free to resend the pull request with the fix.", "@jhseu I suspect the fix is in #10276 as I've done 5000 runs on `stage_op_test` and have seen no errors. `map_stage_op_test` is on 572/5000 runs on  now. "]}, {"number": 9685, "title": "[Java][Suggestion] Add Enum with all Operations", "body": "Currently it is hard for beginners to start with the Java API of TF. Mostly because the function names staed in the python tutorial do not apply to the Operation names used in Java. It would be nice if we had an Enum Containing all standart possible Operations.\r\n\r\n`grapth.opBuilder(type, name)`\r\n\r\nI am currently struggling to find out what the correct name of \"Multiply\" is.\r\nI have digged my way thorgh the code and most of the operations are registered trought `REGISTER_OP` and I could trace down the java methods to ` TF_OperationDescription(TF_Graph* g, const char* op_type, const char* node_name)` in c_api_internal.h. But I absolutly dont know were the operations are storred. \r\n\r\nAlso nice would be a table \"python function name\" to \"internal operation name\"", "comments": ["Given that attribute names may also generally differ, the only \"principled\" way to do this would be to either automatically generate code for constructing ops (which can be ugly) or manually add functions that create all supported ops. The Python API currently uses a mixed approach. If you can be a little patient, I have been working on a Scala API that does that and adds a lot more of the Python API functionality (e.g., gradients). It's not ready to be released yet, but I will have a usable version soon. It is written Scala though and uses some \"Scala-specific\" features, but it shouldn't be hard to create a Java compatibility layer then.", "ohh that would be great. It is currently realy annoing to not know what op names are. for example I could not find anything what \"tf.global_variables_initializer\" would be in java.", "@asimshankar for Java. \r\n\r\nThe variables etc are registered in the graph. You'd need access to the collections from the Graph class, I believe.\r\n", "As @eaplatanios pointed out, I don't think that an enum would be appropriate and code generation for all the operations (which happens for Python, C++ and Go right now) is the right way to go.\r\n\r\nI believe @karllessard and @kbsriram are looking into this as part of resolving #7149, so I'm going to close this issue out and recommend comments/follow ups on #7149 instead.\r\n\r\nThanks!", "But the method solution is much more complex and enums are the right way to do it, like OpenGL does it.", "An enum might describe the list if operations, but we'd still need to describe all the inputs, their types, any attributes, default values - essentially all the contents of the [`OpDef` protocol buffer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op_def.proto) that is created with the `REGISTER_OP` macro calls, so merely listing out the operations without describing how to use them seems insufficient, no?\r\n\r\nI might be misunderstanding, but it sounds like you're searching for an enum to encapsulate what `grep REGISTER_OP` in the codebase will do right now?\r\n", "well enum cann do this in java do (we can give them an input definition as DataType array) and the Exceptions are helpfull so the hardest thing currently is guessing the name, if you have the name the excpetiuons tell you what you need.", "I do believe that the code generation is the appropriate thing to do regardless, but yes, it will take time.\r\n\r\nI'm not fully convinced about the value of the enum. Yes, it may help with discovery of operations, but once the code generation is in place, then that would be a better means of discovery? Note that operations can also be added at runtime (e.g., [Adding a New Op](https://www.tensorflow.org/extend/adding_an_op)), so the enum will not be sufficient.\r\n\r\nThat said, one minor change seems to be a pre-requisite for discovery whether using code generation or an enum. That would be to make  [`TF_GetAllOpList`](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/c/c_api.h#L1136) available in the Java API, the output of which can be parsed into an [`OpList`](http://static.javadoc.io/org.tensorflow/proto/1.1.0/org/tensorflow/framework/OpList.html) Java object.\r\n\r\nI'd be happy to add that. With it you should be able to generate your own enum if you want and if after using it you still feel convinced that it is appropriate, we could discuss the possibility of merging it in.\r\n\r\nSound fair?", "Ok if you will add all this stuff then yeah the enum is pretty out of place and not needed. With alot of bloddy magic it is possible to add enum at runtime but a solution wiht methods is by far better."]}, {"number": 9684, "title": "Misspellings on the saved_model_cli.py", "body": "information => information", "comments": ["Can one of the admins verify this patch?"]}, {"number": 9683, "title": "tf.avg_pool fails for data format \"NCHW\" on ppc64le", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04 ppc64le\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n'v1.0.1-0-ge895d5c-dirty'\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.4.4-2017-04-13 (@80a07b5)\r\n- **CUDA/cuDNN version**:\r\nNo GPU\r\n- **GPU model and memory**:\r\nNo GPU\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm trying to run tf.nn.avg_pool (https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool) by passing in NCHW as the data format on a CPU (no GPU) but see the error: \r\n\r\n\" Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC.\"\r\n\r\nThe API documentation mentions both NHWC and NCHW are supported. Please see logs below for complete details\r\n\r\n**Query: Does avg_pool support NCHW for CPUs?**\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nNote: Below, NHWCToNCHW defined standard func to convert from one form to another (but not shown in this snippet)\r\n\r\n>>> x\r\narray([[[[  1.,   2.,   3.],\r\n         [  4.,   5.,   6.],\r\n         [  7.,   8.,   9.]],\r\n\r\n        [[ 10.,  11.,  12.],\r\n         [ 13.,  14.,  15.],\r\n         [ 16.,  17.,  18.]]]], dtype=float32)\r\n>>> t = tf.placeholder(tf.float32)\r\n>>> t = NHWCToNCHW(t)\r\n>>> t = tf.nn.avg_pool(t,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\",data_format=\"NCHW\")\r\n>>> actual = sess.run(t, {inputs: x})\r\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC.\r\n         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](AvgPool)]]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC.\r\n         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](AvgPool)]]\r\n\r\nCaused by op u'AvgPool_1', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1765, in avg_pool\r\n    name=name)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 50, in _avg_pool\r\n    data_format=data_format, name=name)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Default AvgPoolingOp only supports NHWC.\r\n         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](AvgPool)]]\r\n\r\n", "comments": ["@npanpaliya any comment on this?", "Please see #2660 for a discussion about the same issue in MaxPooling operation\r\n\r\n> MaxPool on GPU supports NCHW and NHWC\r\n> MaxPool on CPU only supports NHWC.\r\n", "Closing this issue due to lack of recent activity. Create a new issue if still facing the same problem. Thanks!\r\n"]}, {"number": 9682, "title": "Unable to run GMM estimator in TF 1.1 but I can run in TF 1.0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 64 bit\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.1 (tensorflow-1.1.0-cp35-cp35m-win_amd64)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: Run the below code in Python IDLE\r\n- Used PIP installation for CPU only\r\n\r\n### Describe the problem\r\nI have used following code in TF 1.0 and TF 1.1. In TF 1.0, it executes and crashes in TF 1.1. In TF 1.0, I dont know any way to get weights(or prior probabilities) for each component in a given GMM. Changes related to weights are added in TF 1.1. Hence I need to run TF 1.1\r\n```\r\nfrom tensorflow.contrib.factorization.python.ops import gmm as gmm_lib \r\nimport random \r\nimport numpy as np\r\nimport tensorflow as tf\r\nmu, sigma = 0, 0.1\r\nx_1d = 10*np.random.randn(100000, 1).astype('f') + 50\r\ngmm = gmm_lib.GMM(1,random_seed=0) \r\ngmm.fit(x_1d)\r\n```\r\n\r\n\r\n### Source code / logs\r\nI got the below crash in TF 1.1\r\n\r\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\HVINAY~1.COR\\AppData\\Local\\Temp\\tmptpejli7d\r\n\r\nWarning (from warnings module):\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 248\r\n    equality = a == b\r\nFutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\r\nWARNING:tensorflow:From C:\\Users\\hvinay.CORP\\Documents\\TF\\GMMEst.py:11: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nTraceback (most recent call last):\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1039, in _do_call\r\n    return fn(*args)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1021, in _run_fn\r\n    status, run_metadata)\r\n  File \"<Python Installed Directory>\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input' with dtype float\r\n\t [[Node: input = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hvinay.CORP\\Documents\\TF\\GMMEst.py\", line 11, in <module>\r\n    gmm.fit(x_1d)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 414, in fit\r\n    SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1317, in fit\r\n    monitors=all_monitors)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 430, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 974, in _train_model\r\n    config=config_pb2.ConfigProto(allow_soft_placement=True)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 333, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 627, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 456, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 805, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 517, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 393, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\", line 262, in prepare_session\r\n    sess.run(init_op, feed_dict=init_feed_dict)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 778, in run\r\n    run_metadata_ptr)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 982, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1032, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1052, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input' with dtype float\r\n\t [[Node: input = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'input', defined at:\r\n  File \"<string>\", line 1, in <module>\r\n  File \"<Python Installed Directory>\\lib\\idlelib\\run.py\", line 124, in main\r\n    ret = method(*args, **kwargs)\r\n  File \"<Python Installed Directory>\\lib\\idlelib\\run.py\", line 351, in runcode\r\n    exec(code, self.locals)\r\n  File \"C:\\Users\\hvinay.CORP\\Documents\\TF\\GMMEst.py\", line 11, in <module>\r\n    gmm.fit(x_1d)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 414, in fit\r\n    SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1317, in fit\r\n    monitors=all_monitors)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 430, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 925, in _train_model\r\n    features, labels = input_fn()\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py\", line 430, in input_builder\r\n    self._input_dtype, 'input')\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py\", line 426, in get_placeholder\r\n    dtypes.as_dtype(dtype), [None] + shape[1:], name=name_prepend)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1507, in placeholder\r\n    name=name)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1997, in _placeholder\r\n    name=name)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"<Python Installed Directory>\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input' with dtype float\r\n\t [[Node: input = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]", "comments": ["Ashish, can you take a look?", "@xavigonzalvo could you take a look? Thanks!", "Please use input_fn not data directly.\n\nOn Jun 16, 2017 6:26 PM, \"Yifei Feng\" <notifications@github.com> wrote:\n\n> @xavigonzalvo <https://github.com/xavigonzalvo> could you take a look?\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9682#issuecomment-309148071>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEVsoRu4XChJVAFst_G10sxTSdC5U079ks5sEwD3gaJpZM4NRubF>\n> .\n>\n", "Thanks. I will try this.\n\nOn Sat, Jun 17, 2017 at 5:05 AM, Xavi <notifications@github.com> wrote:\n\n> Please use input_fn not data directly.\n>\n> On Jun 16, 2017 6:26 PM, \"Yifei Feng\" <notifications@github.com> wrote:\n>\n> > @xavigonzalvo <https://github.com/xavigonzalvo> could you take a look?\n> > Thanks!\n> >\n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > <https://github.com/tensorflow/tensorflow/issues/\n> 9682#issuecomment-309148071>,\n> > or mute the thread\n> > <https://github.com/notifications/unsubscribe-auth/AEVsoRu4XChJVAFst_\n> G10sxTSdC5U079ks5sEwD3gaJpZM4NRubF>\n> > .\n>\n> >\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9682#issuecomment-309161954>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Aa-9ErUTygy3af9w4USZeAC_3d_zpXRXks5sExE-gaJpZM4NRubF>\n> .\n>\n"]}, {"number": 9681, "title": "Tensorboard Graph vizualisation crashes with Chrome/Safari", "body": "### Server system information\r\n```\r\n== dockerfile image =============================================\r\nFROM tensorflow/tensorflow:latest-gpu\r\nRUN pip install tensorflow --upgrade\r\nRUN pip install tensorflow-gpu --upgrade\r\n\r\n== cat /etc/issue ===============================================\r\nLinux 479a65b403e2 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"14.04.5 LTS, Trusty Tahr\"\r\nVERSION_ID=\"14.04\"\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n== uname -a =====================================================\r\nLinux 479a65b403e2 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.1.0)\r\ntensorflow-gpu (1.1.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.1.0\r\ntf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\ntf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri May  5 08:50:12 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 0000:01:00.0     Off |                  N/A |\r\n| 24%   40C    P2    56W / 250W |   1793MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\r\n| 25%   45C    P2    55W / 250W |    312MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN X (Pascal)    Off  | 0000:03:00.0     Off |                  N/A |\r\n| 24%   43C    P2    53W / 250W |    312MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN X (Pascal)    Off  | 0000:04:00.0     Off |                  N/A |\r\n| 25%   44C    P2    53W / 250W |    312MiB / 12186MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.44\r\n```\r\n\r\n### Local machine information\r\n```\r\nMacOS Sierra 10.12.4 (16E195)\r\nGoogle Chrome 58.0.3029.96 (64-bit)\r\nSafari 10.1 (12603.1.30.0.34)\r\n```\r\n\r\n### Describe the problem\r\nI'm running Tensorboard on a server and visualizing the graph on my local machine.\r\n\r\nWith the attached file that I generated using a custom script, Tensorboard crashes after a while of just moving the graph around or when I try to remove some modules from the main graph (100% crash after 4 modules removed).\r\n\r\nMore specifically:\r\n- In Safari only the browser freezes but I can still close it.\r\n- In Chrome the browser freezes and then the whole OS, I don't even have haptic feedback anymore. On the otherhand Tensorboard is still running on the server and the Tensorboard webpage can be accessed by other computers.\r\n\r\n\r\n### Source code / logs\r\nHere is the log-file containing just the graph that reproduces this issue 100% time on my end.\r\n[events.out.tfevents.1493971052.c941b31be93a.zip](https://github.com/tensorflow/tensorflow/files/978532/events.out.tfevents.1493971052.c941b31be93a.zip)\r\n", "comments": ["Thanks for the detailed report!", "Migrated this to the TensorBoard repo."]}, {"number": 9680, "title": "I am not able to install tensorflow", "body": ">pip install tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n\r\nFor info I am using Window 10 and Python 3.5.2\r\nplease help", "comments": ["Hi I am have currently the same problem. It helped to follow the steps [here](http://stackoverflow.com/questions/38896424/tensorflow-not-found-in-pip). But now I am having the problem `import tensorflow` crashes.", "Use anaconda. it is much easier to maintain dependencies . ", "Please reopen if the referenced steps on StackOverflow did not resolve the issue.", "@SrivastavaKshitij  I am facing the same problem also on anaconda after installing the those two packages", "C:\\Users\\Sudhit>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-window.whl\r\ntensorflow-1.1.0-cp35-cp35m-window.whl is not a supported wheel on this platform.\r\n\r\nhow will I know which will be supported wheel for my platform?\r\n", "cp35 is for python 3.5 . I hope you are using the correct version. \r\nAlso, I hope you are creating a virtual environment inside anaconda for tensorflow.\r\n\r\nUse the procedure here. https://www.tensorflow.org/install/install_windows\r\n\r\nI dont think there could be any problem installing tensorflow with anaconda. It is one of the cleanest way to install TF", "@SrivastavaKshitij \r\n(tensorflow) C:\\Users\\Sudhit>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whl\r\ntensorflow-1.1.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.  \r\n\r\n![screenshot 19](https://cloud.githubusercontent.com/assets/25053295/25775784/cfa239ae-32c6-11e7-9459-fe16f4d9398e.png)\r\n  \r\n\r\nStill having this return message, what should I do now??", "try installing version 1.0.1 instead of 1.1.0 using anaconda. \r\n\r\nhttps://www.tensorflow.org/versions/r1.0/install/install_windows", "@sudhirshahu51 \r\ncould you please tell me where get your desktop background picture?\r\n", "@Xiangyi1996  I got this from Bing Images search, if you want I can mail it to you :)", "I am having the same error. Is there a list of all requirements of tensorboard?", "I'm also getting the same error.\r\ntensorflow-1.1.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\r\n\r\nEven for version 1.0.1 , same error is coming", "@leslyarun @sudhirshahu51 : I dont work on windows. So I can't be of real help now. I hope someone who works on windows can help you out !", "Anything yet? Same error here too. Struggling since a few hours. ", "Hi, if you create a environment using anaconda, try this:\r\nconda create -n tensorflow python=3.5\r\nactivate tensorflow\r\npip install --ignore-installed --upgrade https://......\r\n", "@vilero  It worked. Thanks man. ", "I tried pip3 not pip, and it worked. Hope it will help.", "@pranavred can you tell me what you are getting after giving this command \r\n`python -c \"from pip import pep425tags;print(pep425tags.supported_tags)\"`\r\n", "@Adamage give the above command you will get knowledge about what your system supports.", "Well guys, the thing is Im a total idiot - I thought this topic is about tensorboard, as it gives the same error when you try to install it on PIP. Actually tensorboard is shipped with tensorflow... sorry. I did not have any issue", "@vilero worked like a charm.\r\nI had python 3.6 in my system. Just found out it will work with 3.5 version alone and not any version above 3.5", "same with @Louis1994 , used pip3 and the installation worked. Also using windows 10 and \r\npython 3.5", "For me, TF 1.0 pip3 install works fine with py35 and not py36. Had installed py35 and followed tf documentation and was able to install.", "I installed python3.6.5 64bit from python.org website on my windows. Following commands works fine without any issues on Windows 7 and Windows 10.\r\n\r\n`pip3 install --upgrade tensorflow`\r\n\r\nIn addition I also ran following command for installing jupyter notebooks and other useful packages\r\n\r\n`pip3 install jupyter pandas matplotlib scikit-learn`\r\n\r\nMost likely the issue might be user has 32 bit python installed on windows. By default when you download python from python.org,  you are downloading 32 bit and not 64-bit.   Download 64 bit python and try again.\r\n", "Hello, I was having the same problem and was searching internet for same problem. In my case upgrading pip from 7.1.2 to 10.0.1 (the latest one) worked. \r\nUse the following command and then try again. \r\n\r\n1. python -m pip install --upgrade pip\r\n2. pip3 install --upgrade tensorflow", "I just had this problem because latest `conda` is already installing Python 3.7. Just downgrade to 3.6:\r\n```\r\nconda install python=3.6\r\npip install tensorflow\r\n```", "After searching a lot and trying to install and reinstall Python, i found the solution was very simple\r\n\r\nuse the following for windows\r\n\r\npython -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n\r\nchange to following on mac\r\n\r\npython3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n\r\nfor Anaconda use corresponding conda", "> @vilero worked like a charm.\r\n> I had python 3.6 in my system. Just found out it will work with 3.5 version alone and not any version above 3.5\r\n\r\nhttps://stackoverflow.com/questions/46842398/is-it-true-that-tensorflow-only-work-on-python3-5-2", "This worked for me.\r\n> python -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n\r\nHowever, I'm trying to use plaidbranch with Python 3.7. However, the following message appears:\r\n`PS C:\\Users\\darlan-pc\\Documents\\PlaidML\\plaidbench>  python .\\plaidbench.py --no-plaid resnet50\r\nUsing TensorFlow backend.\r\nError: Missing needed packages for benchmark; to fix, pip install keras tensorflow`\r\n\r\nI will try to run with version 3.6... or as @amitection had said 3.5, but according to the Tensorflow documentation version 3.6.x works\r\n\r\n\r\n\r\n\r\n", "Tensorflow is not compatible with python3.7 and spyder3.3.1\r\n\r\nTo work with stable tensorflow  version\r\n\r\nfollow the procedure\r\n\r\n> windows-->search-->Anaconda prompt-->right click -->click Run as adminstrator\r\n\r\nBelow command create the virtual environment which does not disturb existing projects\r\n\r\n    conda create -n projectname \r\n\r\nBelow command activates your virtual environment within this directory installed package will not disturb your existing project.\r\n\r\n    activate projectname\r\n\r\nBelow command installs python 3.6.7 and spyder 3.2.3 as well\r\n\r\n    conda install spyder=3.2.3\r\n\r\nBelow mentioned tensorflow version works without any error. As per your need, you can install tensorflow version specifically.\r\n\r\n    pip install tensorflow==1.3.0\r\n\r\nTo open spyder\r\n\r\n    spyder\r\n\r\nTo exit form Virtual environment\r\n\r\n    deactivate\r\n", "> Tensorflow is not compatible with python3.7 and spyder3.3.1\r\n> \r\n> To work with stable tensorflow version\r\n> \r\n> follow the procedure\r\n> \r\n> > windows-->search-->Anaconda prompt-->right click -->click Run as adminstrator\r\n> \r\n> Below command create the virtual environment which does not disturb existing projects\r\n> \r\n> ```\r\n> conda create -n projectname \r\n> ```\r\n> Below command activates your virtual environment within this directory installed package will not disturb your existing project.\r\n> \r\n> ```\r\n> activate projectname\r\n> ```\r\n> Below command installs python 3.6.7 and spyder 3.2.3 as well\r\n> \r\n> ```\r\n> conda install spyder=3.2.3\r\n> ```\r\n> Below mentioned tensorflow version works without any error. As per your need, you can install tensorflow version specifically.\r\n> \r\n> ```\r\n> pip install tensorflow==1.3.0\r\n> ```\r\n> To open spyder\r\n> \r\n> ```\r\n> spyder\r\n> ```\r\n> To exit form Virtual environment\r\n> \r\n> ```\r\n> deactivate\r\n> ```\r\n\r\nReally? TF isn't compatible with the latest version of Python? :(", "So far. Variable used in tf are marked as reserved keywords in python 3.7\n\nOn Thu 8 Nov, 2018, 10:18 PM Idan, <notifications@github.com> wrote:\n\n> Tensorflow is not compatible with python3.7 and spyder3.3.1\n>\n> To work with stable tensorflow version\n>\n> follow the procedure\n>\n> windows-->search-->Anaconda prompt-->right click -->click Run as\n> adminstrator\n>\n> Below command create the virtual environment which does not disturb\n> existing projects\n>\n> conda create -n projectname\n>\n> Below command activates your virtual environment within this directory\n> installed package will not disturb your existing project.\n>\n> activate projectname\n>\n> Below command installs python 3.6.7 and spyder 3.2.3 as well\n>\n> conda install spyder=3.2.3\n>\n> Below mentioned tensorflow version works without any error. As per your\n> need, you can install tensorflow version specifically.\n>\n> pip install tensorflow==1.3.0\n>\n> To open spyder\n>\n> spyder\n>\n> To exit form Virtual environment\n>\n> deactivate\n>\n> Really? TF isn't compatible with the latest version of Python? :(\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9680#issuecomment-437069982>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Aqnz-TB4P7adsp3PCWhfliiqJlpPzHZdks5utGBwgaJpZM4NRo4G>\n> .\n>\n", "> Hi, if you create a environment using anaconda, try this:\r\n> conda create -n tensorflow python=3.5\r\n> activate tensorflow\r\n> pip install --ignore-installed --upgrade https://......\r\n\r\nit worked like charm ", "Hi,\r\nI try to install tensorflow with GPU support : I utilized pip install tensorflow-gpu with different versions.\r\nI utilized a Tesla K40 GPU model as avirtual machine, where those are  already existed:\r\n-Python Version: 2.7\r\n-Cuda compilation tools, release 9.1, V9.1.85,\r\n-locate libcudnn.so:\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.6\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.6.0.21\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.7\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.7.0.5\r\n\r\nEvery time , i find the same error: ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n", "> Use anaconda. it is much easier to maintain dependencies .\r\n\r\nUnsatisfiableError: The following specifications were found to be in conflict:\r\n  - anaconda==2018.12=py37_0 -> bleach==3.0.2=py37_0\r\n  - anaconda==2018.12=py37_0 -> mkl-service==1.1.2=py37hb782905_5\r\n  - anaconda==2018.12=py37_0 -> numexpr==2.6.8=py37hdce8814_0\r\n  - anaconda==2018.12=py37_0 -> scikit-learn==0.20.1=py37h343c172_0\r\n  - tensorflow\r\nUse \"conda info <package>\" to see the dependencies for each package.\r\n\r\nHow to fix it.", "I am also facing exactly the same problem \u2026 please help me \u2026 although in anaconda navigator and by using spyder I am able to import tensorflow but in command prompt it is unable to import tensorflow\u2026\r\n\r\nPlease help me!!! ", "@SohiniChaudhuri \r\n\r\nPlease check the Virtual Environmental.\r\nFor example, if u have installed Tensorflow in AA Environment, then it will not reflect in the base Environment. \r\nIf you are trying in a command prompt, it takes the base environment. so try to do in the respective environment.\r\nAnaconda\r\n(base)c:\\ activate AA\r\n(AA)c:\\ \r\n\r\n", "try ' conda install tensorflow ' in cmd", "@smzahir \r\n\r\nAre you trying to install in command prompt or anaconda cmd prompt?\r\nwhat is the error message?\r\n\r\n", "Try in command prompt", "@smzahir \r\n\r\nplease say the error message.\r\n", "When i used ' pip install tensorflow ' its shows the error message as:\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\nThen i used  ' conda install tensorflow ' command in Command prompt which really worked.", "@smzahir \r\n As per your statement, conda install tensorflow has worked. ''pip install always check with python version.\r\nso whats is your python version.\r\n\r\n", "@RamishaRaniK \r\nI think tensorflow works with python version upto 3.6 while mine is 3.7", "> After searching a lot and trying to install and reinstall Python, i found the solution was very simple\r\n> \r\n> use the following for windows\r\n> \r\n> python -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n> \r\n> change to following on mac\r\n> \r\n> python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n> \r\n> for Anaconda use corresponding conda\r\n\r\no m g u saved me an hour of googling! thankyouu"]}, {"number": 9679, "title": "*tf_gen_op_libs* BUILD rule uses host toolchain even when crosstool wrappers are provided.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\n     Yes. I have done the following changes.\r\n\r\n     - I pulled the tensorflow branch - **v1.0.1**       \r\n     - [An ugly hack to compile on Tegra X1 /w Jetpack 2.3.1 release.](https://github.com/rwightman/tensorflow/commit/a1cde1d55f76a1d4eb806ba81d7c63fe72466e6d) - Added this for trying to cross compile tensorflow on NVIDIA Jetson Tx1\r\n      - Modified **BUILD.tpl** and **CROSSTOOL.tpl** in `third_party/gpus/crosstool/` for cross building for aarch64 as mentioned in [Bazel build wiki for custom toolchain](https://github.com/bazelbuild/bazel/wiki/Building-with-a-custom-toolchain)\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\n    Linux Ubuntu 16.04.1 - x86_64\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\n    Trying to cross compile for NVIDIA Jetson TX1 from source\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n    v1.0.1 branch\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\n    v 0.4.5\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\n     CUDA - 8.0.34\r\n     cuDNN - 5.1.5\r\n\r\n- **Exact command to reproduce**:\r\n\r\n### Problem description\r\nI am trying to cross compile tensorflow with GPU support for NVIDIA Jetson TX1. I have setup the crosstool file for using the cross-build tools which I downloaded from the Linaro Website ( I followed the instructions from the bazel wiki on how to do so). My code compiles fine till it reaches the stage where the `tf_gen_op_libs` BUILD rule is reached (`tensorflow/cc/BUILD:314`). All of the ops mentioned in the rule fails to build. To be more precise, if fails in the linking stage with the following error\r\n```\r\n /home/jetsontx1/Softwares/tensorflow/tensorflow/cc/BUILD:314:1: Couldn't build file tensorflow/cc/ops/no_op_gen_cc: Linking of rule '//tensorflow/cc:ops/no_op_gen_cc' failed: gcc failed: error executing command \r\n  (cd /home/jetsontx1/.cache/bazel/_bazel_jetsontx1/aebd32d6c3050c56aab9d4678f2e4fce/execroot/tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64: \\\r\n    PATH=/usr/local/cuda-8.0/bin:/home/jetsontx1/bin:/home/jetsontx1/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n  /usr/bin/gcc -o bazel-out/host/bin/tensorflow/cc/ops/no_op_gen_cc -Lbazel-out/host/bin/_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/../../../_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' -pthread -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -pass-exit-codes -Wl,-S -Wl,--gc-sections -Wl,@bazel-out/host/bin/tensorflow/cc/ops/no_op_gen_cc-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n/usr/bin/ld.gold: fatal error: bazel-out/host/bin/_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib/libcudart.so.8.0: unsupported ELF machine number 183\r\ncollect2: error: ld returned 1 exit status\r\n```\r\nSo what I don't understand is, I have specified my crosstool toolchain to build all the tensorflow libs. But it is using the host compiler (/usr/bin/gcc) for this particular stage alone. Shouldn't it use the wrapper I specified in the crosstool file?\r\n\r\nTo put in another way - Why is the rule `tf_gen_op_libs` building the ops mentioned in the BUILD rule with the host compiler and not my crosstool? Is this a BUG?", "comments": ["@davidzchen @jart any idea?\r\n\r\nCould you share your source tree with the custom modifications (particularly building with a custom crosstool) maybe on a github fork?", "I could share it but I feel it would add more confusion as I hard-coded certain paths in `third_party/gpus/cuda_configure.bzl` for pointing to paths of the executables  `nvcc` and `nvvm`. On giving the toolkit path, the build process chooses the `nvcc` and `nvvm` from inside it. Since I am cross compiling, I would need the host executables `nvcc` and `nvvm`  but the target libraries. I will put things together tomorrow and share them.\r\n\r\nI have also tried to dig in and see why host cuda runtime is being required. I bazel queried the graph and saw that it is trying to generate `xyz_ops_gen_cc`, a binary which is being generated and is linking against cuda runtime of the host because of the dependency\r\n`xyz_ops_genrule` -> `xyz_ops_gen_cc` -> `xyz_ops_op_lib` -> `core:framework`. I found this in  `tensorflow/tensorflow.bzl` and used in `tensorflow/cc/BUILD` \r\n\r\nI also came across this [link](https://github.com/bazelbuild/bazel/issues/464#issuecomment-141708071) on bazelbuild as to how it switches to host toolchain with `genrule`. Thus, I globally exported the library path for host cuda libraries in the toolchain section for \"k8\" cpu  in the CROSSTOOL.tpl file (in third_party/gpus/crosstool) using `linker_flag` options and passed this toolchain as `host_crosstool_top` instead of the default bazel cpp toolchain and it compiled. From the compilation of code point of view, I think it is safe to close this issue.\r\n\r\nBut if supporting cross-compilation is in your plan, then we need two CUDA toolkit paths - one for host and one for target since the host_crosstool looks for host cuda runtime while generating the wrappers and we need target libraries for linking with target_crosstool. \r\n\r\nPS; I also dont understand why the `xxx_op_gen_cc` needs to be linked against cuda runtime though. If anybody can explain, it would be nice.", "@davidzchen could you take a look? Thanks!", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Closing due to inactivity. Please comment with new information and I will reopen."]}, {"number": 9678, "title": "Convert magenta/image_stylization model on Android, but doesn't work", "body": "I try [TF Stylize on Android](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android) and it works perfectly.  Also I find the training code of this [image stylization model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/StylizeActivity.java#L70). Its name is [magenta/image_stylization](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization) and provides two pre-trained models: [Monet](http://download.magenta.tensorflow.org/models/multistyle-pastiche-generator-monet.ckpt) and [Varied](http://download.magenta.tensorflow.org/models/multistyle-pastiche-generator-varied.ckpt). The first one had 10 styles and second has 32.\r\n\r\nSo my idea it to use them to replace [image stylization model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/StylizeActivity.java#L74).\r\n\r\nHere is what I did.\r\n1 Save `*.ckpt` model to `*.pb`  \r\nSave graph  \r\n```\r\nimport tensorflow as tf\r\nimport model\r\nimport ops\r\n\r\nnum_styles = 10\r\nimgWidth = 216\r\nimgHeight = 216\r\nchannel = 3\r\ncheckpoint = \"models/multistyle-pastiche-generator-monet.ckpt\"\r\n\r\ninputImage = tf.placeholder(tf.float32,shape=[None,imgWidth,imgHeight,channel],name=\"input\")\r\nstyles = tf.placeholder(tf.float32,shape=[num_styles],name=\"style_num\")\r\n\r\nwith tf.name_scope(\"\"):\r\n    transform = model.transform(inputImage,\r\n                            normalizer_fn=ops.weighted_instance_norm,\r\n                            normalizer_params={\r\n                                # 'weights': tf.constant(mixture),\r\n                                'weights' : styles,\r\n                                'num_categories': num_styles,\r\n                                'center': True,\r\n                                'scale': True})\r\n\r\nmodel_saver = tf.train.Saver(tf.global_variables())\r\n\r\nwith tf.Session() as sess:\r\n    tf.train.write_graph(sess.graph_def, \"models/\", \"input.pb\")\r\n```\r\n\r\nFreeze Graph\r\n```\r\nbazel-bin/tensorflow/python/tools/freeze_graph \\\r\n --input_graph=input.pb --input_checkpoint=multistyle-pastiche-generator-monet.ckpt \\\r\n --output_node_names=transformer/expand/conv3/conv/Sigmoid --input_binary=False \\\r\n --output_graph=frozen.pb\r\n```\r\n\r\nInference\r\n```\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n--input=frozen.pb --output=inference.pb \\\r\n--input_names=input --output_names=transformer/expand/conv3/conv/Sigmoid \\\r\n--frozen_graph=True\r\n```\r\n\r\nQuantize\r\n```\r\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n--input=inference.pb \\\r\n--output=quantize_graph.pb \\\r\n--output_node_names=transformer/expand/conv3/conv/Sigmoid  \\\r\n--mode=weights_rounded\r\n```\r\n\r\n2 Replace model with `quantize_graph.pb`\r\n\r\nThen I got an issue.\r\nI can see there are 10 styles and they display on the screen :\r\n![screenshot_2017-05-05-14-10-21](https://cloud.githubusercontent.com/assets/8957771/25735287/d52a1700-319c-11e7-86e1-642ad06539e7.jpg)\r\n\r\nHowever, the image is not transformed.  There's no style on the image. It's the just original image.\r\nTF version is 1.1.0. Android is 6.0.1\r\n\r\nAnyone met the same issue or anyone knew how exactly to convert these two models  and use on mobile?\r\n\r\n", "comments": ["I have the same problem.", "Mark~", "Similar problem.", "When I use [image stylization model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/StylizeActivity.java#L74), I got this log and looks correct:\r\n```\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for '_arg_input_0_0\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution_eightbit_reshape_transformer/contract/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution_eightbit_quantize_transformer/contract/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/Relu_eightbit_reshape_transformer/contract/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/Relu_eightbit_quantize_transformer/contract/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/Relu\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution_eightbit_reshape_transformer/contract/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution_eightbit_quantize_transformer/contract/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/Relu_eightbit_reshape_transformer/contract/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/Relu_eightbit_quantize_transformer/contract/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/Relu_eightbit_quantized\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/Relu\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/MirrorPad_2\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution_eightbit_reshape_transformer/contract/MirrorPad_2\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution_eightbit_quantize_transformer/contract/MirrorPad_2\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution_eightbit_requantize\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/Relu_eightbit_reshape_transformer/contract/conv3/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/Relu_eightbit_quantize_transformer/contract/conv3/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/Relu_eightbit_quantized\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/Relu\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution_eightbit_reshape_transformer/residual/residual1/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution_eightbit_quantize_transformer/residual/residual1/MirrorPad\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/Relu_eightbit_reshape_transformer/residual/residual1/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/Relu_eightbit_quantize_transformer/residual/residual1/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/Relu\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution_eightbit_reshape_transformer/residual/residual1/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution_eightbit_quantize_transformer/residual/residual1/MirrorPad_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/add\\\r\n05-05 16:21:39.482 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution_eightbit_reshape_transformer/residual/residual2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution_eightbit_quantize_transformer/residual/residual2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/Relu_eightbit_reshape_transformer/residual/residual2/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/Relu_eightbit_quantize_transformer/residual/residual2/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution_eightbit_reshape_transformer/residual/residual2/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution_eightbit_quantize_transformer/residual/residual2/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/add\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution_eightbit_reshape_transformer/residual/residual3/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution_eightbit_quantize_transformer/residual/residual3/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/Relu_eightbit_reshape_transformer/residual/residual3/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/Relu_eightbit_quantize_transformer/residual/residual3/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution_eightbit_reshape_transformer/residual/residual3/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution_eightbit_quantize_transformer/residual/residual3/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/add\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution_eightbit_reshape_transformer/residual/residual4/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution_eightbit_quantize_transformer/residual/residual4/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/Relu_eightbit_reshape_transformer/residual/residual4/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/Relu_eightbit_quantize_transformer/residual/residual4/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution_eightbit_reshape_transformer/residual/residual4/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution_eightbit_quantize_transformer/residual/residual4/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/add\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution_eightbit_reshape_transformer/residual/residual5/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution_eightbit_quantize_transformer/residual/residual5/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/Relu_eightbit_reshape_transformer/residual/residual5/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/Relu_eightbit_quantize_transformer/residual/residual5/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution_eightbit_reshape_transformer/residual/residual5/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution_eightbit_quantize_transformer/residual/residual5/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/add\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/convolution_eightbit_reshape_transformer/residual/residual6/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/convolution_eightbit_quantize_transformer/residual/residual6/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/Relu_eightbit_reshape_transformer/residual/residual6/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/Relu_eightbit_quantize_transformer/residual/residual6/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv1/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/convolution_eightbit_reshape_transformer/residual/residual6/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/convolution_eightbit_quantize_transformer/residual/residual6/MirrorPad_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual6/add\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/ResizeNearestNeighbor\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/convolution_eightbit_reshape_transformer/expand/conv1/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/convolution_eightbit_quantize_transformer/expand/conv1/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/Relu_eightbit_reshape_transformer/expand/conv1/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/Relu_eightbit_quantize_transformer/expand/conv1/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv1/conv/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/ResizeNearestNeighbor\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/convolution_eightbit_reshape_transformer/expand/conv2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/convolution_eightbit_quantize_transformer/expand/conv2/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/convolution_eightbit_requantize\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/convolution\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/Relu_eightbit_reshape_transformer/expand/conv2/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/Relu_eightbit_quantize_transformer/expand/conv2/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/Relu_eightbit_quantized\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv2/conv/Relu\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/ResizeNearestNeighbor\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/MirrorPad\\\r\n05-05 16:21:39.492 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/convolution_eightbit_reshape_transformer/expand/conv3/MirrorPad\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/convolution_eightbit_quantize_transformer/expand/conv3/MirrorPad\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/convolution_eightbit_quantized_conv\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/convolution_eightbit_requantize\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/convolution\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/InstanceNorm/moments/sufficient_statistics/Square\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:21:39.502 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/expand/conv3/conv/Sigmoid\\\r\n```\r\n\r\nThis is when I use mine. not right...\r\n```\r\n05-05 16:26:59.162 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for '_arg_input_0_0\\\r\n05-05 16:26:59.162 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/convolution\\\r\n05-05 16:26:59.162 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.162 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv2/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/contract/conv3/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual1/add\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual2/add\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual3/add\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual4/add\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv1/Relu\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/convolution\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/moments/sufficient_statistics/SquaredDifference\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/moments/sufficient_statistics/Sub\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/batchnorm/mul_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/conv2/InstanceNorm/batchnorm/add_1\\\r\n05-05 16:26:59.172 6107-9753/org.tensorflow.demo W/native: stat_summarizer.cc:64 Output tensor changed between runs for 'transformer/residual/residual5/add\\\r\n```", "@haikuoyao The stat_summarizer spam might be due to changing the input size while the debug mode is active (making the sizes of all the tensors change). Is this the case? If so you can safely ignore those log messages.\r\n\r\nDo you see anything else in the log that might indicate an issue?\r\n\r\n@guanlicome @funzhang @SnailTyan To be clear you're all experiencing the same problem after following the steps @haikuoyao describes above? Just trying to understand how so many people are suddenly seeing the same issue :)", "Thanks. @andrewharp \r\n\r\nI didn't see anything else in my log and don't find any doc about how to convert `ckpt` model to `stylize_quantized.pb`?\r\n\r\nI wonder did I use the correct way to this?\r\nAnd [magenta/image_stylization](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization) is the training code of this model, right ?\r\n\r\nI saw `residual6 ` in log but I didn't see this layer in https://github.com/tensorflow/magenta/blob/master/magenta/models/image_stylization/model.py#L53-L66\r\n", "There are some **Nans** in the **ckpt** you downloaded from the wed.\r\nYou should get rid of them. Then you will get right outputs on the mobile device.", "Thanks. @JiaoLiu It works now.", "\r\nI also met this question (on ios),  but I am not very clear  about : \"There are some Nans in the ckpt you downloaded from the wed.You should get rid of them. Then you will get right outputs on the mobile device.\"\r\n\r\nso , how to do that...? ", "@haikuoyao I have followed the scripts in your first post, but when i use the generated quantize_graph.pb to transfer style with magenta/models/image_stylization/image_stylization_transform.py, i got the following error:\r\n....\r\n2017-12-11 14:30:08.818967: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to open table file models/quantize_graph.pb: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\nTraceback (most recent call last):\r\n  File \"image_stylization_transform.py\", line 148, in <module>\r\n    console_entry_point()\r\n  File \"image_stylization_transform.py\", line 144, in console_entry_point\r\n    tf.app.run(main)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"image_stylization_transform.py\", line 135, in main\r\n    _multiple_images(image, which_styles, output_dir)\r\n  File \"image_stylization_transform.py\", line 94, in _multiple_images\r\n    _load_checkpoint(sess, FLAGS.checkpoint)\r\n  File \"image_stylization_transform.py\", line 57, in _load_checkpoint\r\n    model_saver.restore(sess, checkpoint)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1666, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.DataLossError: Unable to open table file models/quantize_graph.pb: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n\t [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_29/_59 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_158_save/RestoreV2_29\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op u'save/RestoreV2_2', defined at:\r\n  File \"image_stylization_transform.py\", line 148, in <module>\r\n    console_entry_point()\r\n  File \"image_stylization_transform.py\", line 144, in console_entry_point\r\n    tf.app.run(main)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"image_stylization_transform.py\", line 135, in main\r\n    _multiple_images(image, which_styles, output_dir)\r\n  File \"image_stylization_transform.py\", line 94, in _multiple_images\r\n    _load_checkpoint(sess, FLAGS.checkpoint)\r\n  File \"image_stylization_transform.py\", line 52, in _load_checkpoint\r\n    model_saver = tf.train.Saver(tf.global_variables())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1227, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1263, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nDataLossError (see above for traceback): Unable to open table file models/quantize_graph.pb: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n\t [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_29/_59 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_158_save/RestoreV2_29\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nMy environment is ubuntu 16.04/tensorflow 1.4/python 2.7.\r\n\r\nActually, i have trained the model myself, i got the following output:\r\n\u251c\u2500\u2500 checkpoint\r\n\u251c\u2500\u2500 events.out.tfevents.1512703812.Y920\r\n\u251c\u2500\u2500 graph.pbtxt\r\n\u251c\u2500\u2500 model.ckpt-39954.data-00000-of-00001\r\n\u251c\u2500\u2500 model.ckpt-39954.index\r\n\u251c\u2500\u2500 model.ckpt-39954.meta\r\n\u251c\u2500\u2500 model.ckpt-39966.data-00000-of-00001\r\n\u251c\u2500\u2500 model.ckpt-39966.index\r\n\u251c\u2500\u2500 model.ckpt-39966.meta\r\n\u251c\u2500\u2500 model.ckpt-39978.data-00000-of-00001\r\n\u251c\u2500\u2500 model.ckpt-39978.index\r\n\u251c\u2500\u2500 model.ckpt-39978.meta\r\n\u251c\u2500\u2500 model.ckpt-39990.data-00000-of-00001\r\n\u251c\u2500\u2500 model.ckpt-39990.index\r\n\u251c\u2500\u2500 model.ckpt-39990.meta\r\n\u251c\u2500\u2500 model.ckpt-40000.data-00000-of-00001\r\n\u251c\u2500\u2500 model.ckpt-40000.index\r\n\u251c\u2500\u2500 model.ckpt-40000.meta\r\n\r\nAnd i use above trained model and get the same error message.\r\n\r\nI can use above model to transfer style with magenta/models/image_stylization/image_stylization_transform.py, but i failed to convert the trained model(checkpoint) to quantized_graph.pb\r\n\r\nThanks for any help!", "Hi @chenhxbj I got some advice from @JiaoLiu  I think you can try to contact him.\r\nActually, I got a transfer script from him and it works. \r\nBut I don't know if it's ok to post it here.  Because he has the copyright.\r\nAnyway, you can send a message to him. \r\nThanks.", "Any solution on this? Still trying to freeze ckpt"]}, {"number": 9677, "title": "Branch 155159972", "body": "", "comments": ["seems like a flaky test.  merging."]}, {"number": 9676, "title": "Bug when trying to restore training from Inception-3 checkpoint with different trainable variables", "body": "I have the pretty common use case of freezing the bottom layers of Inception and training only the first two layers, after which I lower the learning rate and fine tune the entire Inception model.\r\n\r\nHere is my code for running the first part\r\n\r\n```python\r\ntrain_dir='/home/ubuntu/pynb/TF play/log-inceptionv3flowers'\r\nwith tf.Graph().as_default():\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    \r\n    dataset = get_dataset()\r\n    images, _, labels = load_batch(dataset, batch_size=32)\r\n    \r\n    # Create the model, use the default arg scope to configure the batch norm parameters.\r\n    with slim.arg_scope(inception.inception_v3_arg_scope()):\r\n        logits, _ = inception.inception_v3(images, num_classes=5, is_training=True)\r\n        \r\n    # Specify the loss function:\r\n    one_hot_labels = slim.one_hot_encoding(labels, 5)\r\n    tf.losses.softmax_cross_entropy(one_hot_labels, logits)\r\n    total_loss = tf.losses.get_total_loss()\r\n\r\n    # Create some summaries to visualize the training process:\r\n    tf.summary.scalar('losses/Total Loss', total_loss)\r\n  \r\n    # Specify the optimizer and create the train op:\r\n    optimizer = tf.train.RMSPropOptimizer(0.001, 0.9,\r\n                                    momentum=0.9, epsilon=1.0)\r\n    train_op = slim.learning.create_train_op(total_loss, optimizer, variables_to_train=get_variables_to_train())\r\n    \r\n    # Run the training:\r\n    final_loss = slim.learning.train(\r\n        train_op,\r\n        logdir=train_dir,\r\n        init_fn=get_init_fn(),\r\n        number_of_steps=4500,\r\n        save_summaries_secs=30,\r\n        save_interval_secs=30,\r\n        session_config=tf.ConfigProto(gpu_options=gpu_options))\r\n        \r\nprint('Finished training. Last batch loss %f' % final_loss)\r\n```\r\n\r\nwhich runs properly, then my code for running the second part\r\n\r\n```python\r\ntrain_dir='/home/ubuntu/pynb/TF play/log-inceptionv3flowers'\r\nwith tf.Graph().as_default():\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    \r\n    dataset = get_dataset()\r\n    images, _, labels = load_batch(dataset, batch_size=32)\r\n    \r\n    # Create the model, use the default arg scope to configure the batch norm parameters.\r\n    with slim.arg_scope(inception.inception_v3_arg_scope()):\r\n        logits, _ = inception.inception_v3(images, num_classes=5, is_training=True)\r\n        \r\n    # Specify the loss function:\r\n    one_hot_labels = slim.one_hot_encoding(labels, 5)\r\n    tf.losses.softmax_cross_entropy(one_hot_labels, logits)\r\n    total_loss = tf.losses.get_total_loss()\r\n\r\n    # Create some summaries to visualize the training process:\r\n    tf.summary.scalar('losses/Total Loss', total_loss)\r\n  \r\n    # Specify the optimizer and create the train op:\r\n    optimizer = tf.train.RMSPropOptimizer(0.0001, 0.9,\r\n                                    momentum=0.9, epsilon=1.0)\r\n    train_op = slim.learning.create_train_op(total_loss, optimizer)\r\n    \r\n    # Run the training:\r\n    final_loss = slim.learning.train(\r\n        train_op,\r\n        logdir=train_dir,\r\n        init_fn=get_init_fn(),\r\n        number_of_steps=10000,\r\n        save_summaries_secs=30,\r\n        save_interval_secs=30,\r\n        session_config=tf.ConfigProto(gpu_options=gpu_options))\r\n        \r\nprint('Finished training. Last batch loss %f' % final_loss)\r\n```\r\n\r\nNotice that in the second part, I do not pass anything into `create_train_op`'s `variables_to_train` parameter. This error is then shown\r\n\r\n```\r\nNotFoundError (see above for traceback): Key InceptionV3/Conv2d_4a_3x3/BatchNorm/beta/RMSProp not found in checkpoint\r\n\t [[Node: save_1/RestoreV2_49 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_49/tensor_names, save_1/RestoreV2_49/shape_and_slices)]]\r\n\t [[Node: save_1/Assign_774/_1550 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_2911_save_1/Assign_774\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\n```\r\n\r\nI suspect that it's looking for the RMSProp variables for the InceptionV3/Conv2d_4a_3x3 layer, which is non-existent, because I didn't train that layer in the previous checkpoint. I'm not sure how to achieve what I want, as I can see no examples in the documentation about how to do this.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9675, "title": "The tfrecords file is 8 times larger than raw image data", "body": "I try to write a tfrecords file, but the file is larger than raw data. \r\n```python (type)\r\nimg = Image.open('img_file')  # this image file size: 24 kb\r\nb = img.tobytes()  # the len(b) is 24 kb, this is right\r\nfeats = tf.train.Features(feature={'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[2])), \r\n'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b]))})\r\nexample_string = example.SerializeToString()\r\nlen(example_string) / 8 / 1024  # the output == 24.0057373046875 kb, look like well\r\n```\r\nbut I write this 'example_string' to tfrecords file , the tfrecords file size become 192 kb, I cann`t understand why tfrecords file size serval times larger than 'example_string' and raw image data", "comments": ["Because you use Int64List.", "@ppwwyyxx , but he uses BytesList for the image, not  Int64. \r\nThe only int64 value in 1 integer label.\r\nI have the problem of blowing up tfrecords as well. My images are 30G when stored in jpg, but 280G when I write them in tfrecord \r\n\r\n        img = np.asarray(Image.open(img_path))\r\n        img_raw = img.tostring()\r\n\r\n        height = img.shape[0]\r\n        width = img.shape[1]\r\n        example = tf.train.Example(features=tf.train.Features(feature={\r\n            'height': _int64_feature(height), # single integer\r\n            'width': _int64_feature(width),  # single integer\r\n            'image_raw': _bytes_feature(img_raw), # image\r\n            }))\r\n\r\nI think we should reopen issue.", "`30G when wtored in jpg, but 280G when I write them in tfrecord`.. do you mean they are __not__ jpeg when stored in tfrecord?", "@ppwwyyxx , Probably the are not jpeg anymore when stored in tfrecord.  I **edited** my code in the previous post.\r\nWhen I used leveldb binaries with caffe, they didn't blow up so much comparing to original data.\r\nLooks like it stores raw, without any encoding?", "Then it definitely will be several times larger and the factor depends on how well JPEG works on your images. The factor is 5.x on the whole ImageNet, btw ([reference](https://github.com/ppwwyyxx/tensorpack/issues/124#issuecomment-277206505)).\r\nTFRecord stores bytes so you can do any encoding you want.", "Is it because tfrecords stores decompressed images? \r\nIs it possible to to store compressed? Do you think it will make everything much slower?", "TFRecord stores bytes so you can do any encoding you want.\r\nThe easiest thing you can do is just `img_raw = open(img_path).read()` to use the original encoding.\r\nThe decompression time is usually much smaller than training, and could be completely hidden if the preprocessing runs in parallel with training. Then it will only make everything faster (as in the link I posted).\r\n", "@ppwwyyxx  This solution really reduces the size. But  when use` image = tf.decode_raw(features['image_raw'], tf.uint8)` to decode the image, the image size is much smaller. Do you know how can I read from the tfrecord to get the original image?", "I find the solution\r\n`tf.image.decode_jpeg(image_raw_data)` or\r\n`cv2.imdecode(np.fromstring(image_raw_data, dtype=np.uint8), -1)`\r\nwill solve the problem.\r\n", "For anyone who is confused how serialization of digital images works, this is a pretty wonderful explanation of \"why the size of TFRecords might be larger\" than the original image, from the ground up. Here: https://planspace.org/20170403-images_and_tfrecords/\r\n"]}, {"number": 9674, "title": "Register variable's proto function with key 'LOCAL_VARIABLES'", "body": "When export/input meta graph, user expect all collections\r\nbeen rebuilded on target graph, but it turns out local variables\r\non target collection is not Variable but Tensor because local variable\r\ndo not have it's proto fn registered", "comments": ["Can one of the admins verify this patch?", "Sadly we can't accept this as-is because it breaks the capability of loading any meta graphs which were saved before this change.\r\n\r\nInstead for now it's safer to put the registration in your model core.", "Well then, Let's change it into a issue, cause it looks like one."]}]