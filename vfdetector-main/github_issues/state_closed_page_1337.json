[{"number": 12983, "title": "support passing in a source url to the mnist.read_data_sets function", "body": "It would be great to be able to pass in an alternate source url to the mnist.read_data_sets function, to make it easier to use 'fashion mnist' etc.\r\nDoes this seem like a reasonable way to do it?\r\n", "comments": ["@amygdala, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ilblackdragon, @tensorflower-gardener and @rohan100jain to be potential reviewers.", "Can one of the admins verify this patch?"]}, {"number": 12982, "title": "Update docs symposium", "body": "", "comments": ["@av8ramit, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @vrv and @tfboyd to be potential reviewers.", "Jenkins, test this please."]}, {"number": 12981, "title": "Windows script docs", "body": "", "comments": []}, {"number": 12980, "title": "Blocking of tf.contrib.StagingArea get() and put() operations", "body": "**Work Environment**\r\nTensorFlow release version : 1.3.0-rc2\r\nTensorFlow git version : v1.3.0-rc1-994-gb93fd37\r\nOperating System : CentOS Linux release 7.2.1511 (Core)\r\n\r\nI am using TensorFlow StagingArea ops for increasing the efficiency of my input pipeline. Here is a part of my code snippet which constructs the input pipeline :\r\n```\r\n    train_put_op_list = []\r\n    train_get_op_list = []\r\n    val_put_op_list = []\r\n    val_get_op_list = []\r\n    with tf.variable_scope(tf.get_variable_scope()) as vscope:\r\n        for i in range(4):\r\n            with tf.device('/gpu:%d'%i):\r\n                with tf.name_scope('GPU-Tower-%d'%i) as scope:\r\n                    trainstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\r\n                                                                 shapes=[[64, 221, 221, 3],[64]],\r\n                                                                      capacity=0)\r\n                    valstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\r\n                                                                      shapes=[[128, 221, 221, 3],[128]],\r\n                                                                      capacity=0)\r\n                    train_put_op_list.append(trainstagingarea.put(train_iterator.get_next()))\r\n                    val_put_op_list.append(valstagingarea.put(val_iterator.get_next()))\r\n                    train_get_op_list.append(trainstagingarea.get())\r\n                    val_get_op_list.append(valstagingarea.get())\r\n                    with tf.device('/cpu:0'):\r\n                        worktype = tf.get_variable(\"wt\",[], initializer=tf.zeros_initializer(), trainable=False)\r\n                    workcondition = tf.equal(worktype, 1)\r\n                    #elem = tf.cond(workcondition, lambda: train_iterator.get_next(), lambda: val_iterator.get_next())\r\n                    elem = tf.cond(workcondition, lambda: train_get_op_list[i], lambda: val_get_op_list[i])\r\n                    # This is followed by the network construction and optimizer \r\n```\r\nNow at the time of execution, I first run the put() ops a couple of times and then go on to run the iterations. It is shown below :\r\n```\r\nwith tf.Session(config=config) as sess:\r\n        sess.run(init_op)\r\n        sess.run(iterator_training_op)\r\n        sess.run(iterator_validation_op)\r\n        sess.run(tf.assign(worktype, 0))\r\n        for i in range(4):\r\n            sess.run(train_put_op_list)\r\n            sess.run(val_put_op_list)\r\n        writer = tf.summary.FileWriter('.', graph=tf.get_default_graph())\r\n        epoch = 0\r\n        iter = 0\r\n        previous = 0\r\n        while(epoch<10):\r\n            try:\r\n                if(PROCESSINGTYPE is 'validation'):\r\n                    sess.run(val_put_op_list)\r\n                    [val_accu, summaries, numsamp] = sess.run([running_accuracy, validation_summary_op, processed])\r\n                    previous+=numsamp\r\n                    print(\"Running Accuracy = {} : Number of sample processed = {} \".format(val_accu, previous))\r\n                else:\r\n                    sess.run(train_put_op_list)\r\n                    [loss_value, _, train_accu, summaries, batch_accu, numsamp] = sess.run([total_loss, apply_gradient_op, running_accuracy, training_summary_op, batch_accuracy, pr\\\r\nocessed])\r\n                    #Remaining part of the code (not important for question)\r\n\r\n```\r\nThe use of StagingArea improves the speed substantially (almost 3-4 times). However, the code hangs due to some block. I am not sure if the block comes from get() or put() operations. Here is the actual output :\r\n```\r\n\r\n# Validation is done first and the following is the output\r\nRunning Accuracy = 0.0 : Number of sample processed = 512\r\nRunning Accuracy = 0.00390625 : Number of sample processed = 1024\r\nRunning Accuracy = 0.0 : Number of sample processed = 1536\r\nRunning Accuracy = 0.001953125 : Number of sample processed = 2048\r\n# The code hangs here\r\n```\r\nYou can notice that in the beginning of `tf.Session() as sess:`, the `get()` and `put()` ops were run for `4` times. The output is limited to 4 lines as well. This means that, \r\n`sess.run(val_put_op_list)` within the `while` loop does not do anything. So, when the `get()` is called by `sess.run(running_accuracy)...`, the `StagingArea` is found empty after `4` lines and hence a blocking happens.\r\n\r\n - Am I correct in my analysis of the problem ?\r\n - What is the correct way to use the `get()` and `put()` ops here ?\r\n - If `StagingArea` is full and `put()` is blocked, would that also block the whole code ? TensorFlow documentation does not say anything about it.", "comments": ["Did you find a solution?", "No. I did not. I am still waiting. I am still waiting for a solution. I am reopening this.", "@mrry are you familiar with StagingArea, or do you know who is?", "Not particularly! That's one for @ekelsen.", "I think in one of the posts on GitHub, @mrry mentioned that StagingArea is no longer being worked on and that it is to be directly integrated to Dataset API. Can anyone confirm this ?\r\nThe code for High Performance Models is written without any comments and description. A cleanup of it would actually resolve most of these use-case scenarios.", "There's work in progress on a `Dataset`-based replacement here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/prefetching_ops.py\r\n\r\nCurrently the only use is in TF Eager (as an option to `tf.contrib.eager.Iterator`) but it should be possible to apply it to graph-mode models as well.\r\n\r\n/cc @rohan100jain ", "Is this issue resolved with v1.5.0-rc0?", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 12979, "title": "bazel compiliation is broken! build failure due to github checksums changing", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: Python 3.6.2\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: `bazel build --verbose_failures //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a`\r\n\r\n### Describe the problem\r\n\r\nGitHub tarball checksums have changed making it impossible to build tensorflow since the checksums don't match any more.\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/3722\r\n\r\n### Source code / logs\r\n\r\n```\r\nERROR: /home/travis/tensorflow/tensorflow/contrib/android/BUILD:72:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': java.io.IOException: Error downloading [https://github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz, http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz] to /home/travis/.cache/bazel/_bazel_travis/c397b760afc31b444fffb10b0086dea5/external/protobuf/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: Checksum was e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d but wanted 6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93 and referenced by '//tensorflow/contrib/android:libtensorflow_inference.so'\r\n```\r\n\r\n```\r\n /tmp/foo \ue0b0 curl -L https://github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz | sha256sum\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   157    0   157    0     0    157      0 --:--:-- --:--:-- --:--:--   301\r\n100 4274k  100 4274k    0     0  4274k      0  0:00:01  0:00:01 --:--:-- 8710k\r\ne5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d  -\r\n /tmp/foo \ue0b0 curl http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz | sha256sum\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100 4274k  100 4274k    0     0  4274k      0  0:00:01 --:--:--  0:00:01 6177k\r\n6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93  -\r\n```", "comments": ["As a short-term workaround, you can force the sha256sum to match by removing the github.com entry.", "Temporary fix:\r\n```\r\nsed -i '\\@https://github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz@d' tensorflow/workspace.bzl\r\n```", "Would anyone happen to know if it's an expected behavior from Github? What is going to happen for the tarball hosted on the mirror.bazel.build, are they going to be updated ? Should we trust that new sha256 ? I have spotted that the URL I use for RPi3 toolchain download is impacted as well:\r\n```\r\nERROR: /home/build-user/DeepSpeech/tf/tools/arm_compiler/BUILD:116:1: no such package '@GccArmRpi//': Error downloading [https://github.com/raspberrypi/tools/archive/0e906ebc527eab1cdbf7adabff5b474da9562e9f.tar.gz] to /home/build-user/.cache/bazel/_bazel_build-user/c049635af10109d54fe54c6ebd9031b2/external/GccArmRpi/0e906ebc527eab1cdbf7adabff5b474da9562e9f.tar.gz: Checksum was 4c622a5c7b9feb9615d4723b03a13142a7f3f813f9296861d5401282b9fbea96 but wanted 970285762565c7890c6c087d262b0a18286e7d0384f13a37786d8521773bc969 and referenced by '//tools/arm_compiler:gcc_linux_linker_files'.\r\n```", "As a workaround just comment the sha256 checksum lines in `tensorflow/workspace.bzl`. The checksums changed probably due to some library change on GitHub side.", "Answer to myself: https://github.com/libgit2/libgit2/issues/4343#issuecomment-328631745\r\nTL;DR it does confirm that Github changes the code to produce tarball, and that the way they are used is fundamentaly risky.", "There should probably be a new tensorflow release with those fixes since currently no one can build the latest release.", "I've hit this, too.  Unfortunately I removed my bazel cache as I was trying to figure it out.\r\nNow it seems to fail early on 'gemmlowp'. \r\n\r\nShould I just comment out all sha256 lines?  Is there a better workaround?\r\n\r\n> $ bazel build ${BAZEL_OPTS} tensorflow_serving/...\r\n> WARNING: ignoring http_proxy in environment.\r\n> WARNING: /home/troy/.cache/bazel/_bazel_troy/d52b2ff19a6bd234d2c10cb6bf93de82/external/org_tensorflow/third_party/py/python_configure.bzl:30:3: Python Configuration Warning: 'PYTHON_LIB_PATH' environment variable is not set, using '/usr/local/lib/python2.7/dist-packages' as default.\r\n> ERROR: /home/troy/.cache/bazel/_bazel_troy/d52b2ff19a6bd234d2c10cb6bf93de82/external/org_tensorflow/tensorflow/core/kernels/neon/BUILD:27:1: no such package '@gemmlowp//': Error downloading [http://mirror.bazel.build/github.com/google/gemmlowp/archive/010bb3e71a26ca1d0884a167081d092b43563996.tar.gz, https://github.com/google/gemmlowp/archive/010bb3e71a26ca1d0884a167081d092b43563996.tar.gz] to /home/troy/.cache/bazel/_bazel_troy/d52b2ff19a6bd234d2c10cb6bf93de82/external/gemmlowp/010bb3e71a26ca1d0884a167081d092b43563996.tar.gz: Checksum was 861cc6d9d902861f54fd77e1ab79286477dcc559b2a283e75b9c22d37b61f6ae but wanted 0d7a44327e26b622ee08faaea10f8d10b439bcfda622f9c98be1c036bc645cad and referenced by '@org_tensorflow//tensorflow/core/kernels/neon:neon_depthwise_conv_op'.\r\n> ERROR: Analysis of target '//tensorflow_serving/sources/storage_path:file_system_storage_path_source' failed; build aborted.\r\n> INFO: Elapsed time: 9.370s\r\n> ", "@tlc I added the following (temporary) line to one of my Dockerfiles. Note that this completely disables checksum validation, so this is probably a _really_ stupid idea \u2014 you have been warned...\r\n\r\n```\r\nsed -ri \"/^\\W+sha256 = \\\"[^\\\"]+\\\"\\W+$/d\" tensorflow/workspace.bzl\r\n``` ", "The # of things to comment out is currently small.  \r\n\r\nBuilding TensorFlow Serving, I only had to comment out 'gemmlowp'.\r\n\r\nBuilding tensorflow/tools/pip_package:build_pip_package, I only had to comment out 'boringssl'.", "#12979 #13080 ", "Ack.\r\nLooks like we have to mirror all github URLs ourselves and not link github. Apparently git has no guarantees for checksums of the archives they provide.", "There's no technical reason why they *couldn't* provide archives with consistent checksums. The inputs used to create the tarballs are constant for any given commit/tag hash (same timestamps, other metadata and content), so it should be feasible to create archives with consistent hashes. Have we investigated what the actual differences *are*? Is the compression somehow introducing the variability? Perhaps hashing the uncompressed .tar files would be more reliable?", "https://github.com/libgit2/libgit2/issues/4343#issuecomment-328631745 is the explanation.\r\n\r\nWe on TF end are bound by the feature provided to us by bazel to check the archive checksum after downloading it. We can ask a new feature from bazel to check the source tree checksum, but it will take until the next bazel release to land, and we need to fix things before then. So the quickest solution seems to be the self-mirroring solution.", "I didn't mean source tree checksums, although that'd be reasonable too I guess. I meant just `cat foo.tar.gz | gzip -d | sha256sum -`", "Is my case related?\r\n\r\n```\r\n$ bazel build --config=opt --config=cuda --config=mkl //tensorflow/tools/pip_package:build_pip_package                                                                        \r\nERROR: /home/linzi/Downloads/tensorflow-1.4.1/tensorflow/tools/pip_package/BUILD:139:1: error loading package 'tensorflow': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': java.io.IOException: Error downloading [http://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz] to /home/linzi/.cache/bazel/_bazel_linzi/68376711a6e4ce84b78bea12ff84978f/external/protobuf_archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz: sun.security.validator.ValidatorException: End user tried to act as a CA and referenced by '//tensorflow/tools/pip_package:build_pip_package'\r\nERROR: /home/linzi/Downloads/tensorflow-1.4.1/tensorflow/tools/pip_package/BUILD:139:1: error loading package 'tensorflow': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': java.io.IOException: Error downloading [http://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz] to /home/linzi/.cache/bazel/_bazel_linzi/68376711a6e4ce84b78bea12ff84978f/external/protobuf_archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz: sun.security.validator.ValidatorException: End user tried to act as a CA and referenced by '//tensorflow/tools/pip_package:build_pip_package'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: error loading package 'tensorflow': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': java.io.IOException: Error downloading [http://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz] to /home/linzi/.cache/bazel/_bazel_linzi/68376711a6e4ce84b78bea12ff84978f/external/protobuf_archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz: sun.security.validator.ValidatorException: End user tried to act as a CA\r\nINFO: Elapsed time: 13.775s\r\nFAILED: Build did NOT complete successfully (5 packages loaded)\r\n    currently loading: tensorflow\r\n```", "No, in your case you have an issue with your certificates on your system.", "@gunan Using the master HEAD instead of 1.4.1 resolves the issue but I don't know why."]}, {"number": 12978, "title": "Bazel & cmake compilations for Windows are completely broken", "body": "Can't compile tensorflow revision 1.3 using Bazel (revision of the last successful nightly build using cmake). Error is the following:\r\n\r\n```\r\nERROR: C:/tensorflow-1.3rc1/tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 2): cl.exe failed: error executing command\r\n  cd C:/msys64/tmp/_bazel_dmitry/ehgyfc-k/execroot/org_tensorflow\r\n  SET CUDA_COMPUTE_CAPABILITIE=None\r\n    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\r\n    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\shared;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\um;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64;\r\n    SET NO_WHOLE_ARCHIVE_OPTION=1\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\msys64\\mingw64\\bin;C:\\msys64\\usr\\local\\bin;C:\\msys64\\usr\\bin;C:\\msys64\\usr\\bin;C:\\Windows\\System32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\msys64\\usr\\bin\\site_perl;C:\\msys64\\usr\\bin\\vendor_perl;C:\\msys64\\usr\\bin\\core_perl;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/Dmitry/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/Dmitry/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\Dmitry\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2\r\n    SET TF_CUDA_VERSION=8.0\r\n    SET TF_CUDNN_VERSION=6\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL=0\r\n    SET TMP=C:\\Users\\Dmitry\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 -march=native -march=native /nologo /I. /Ibazel-out/msvc_x64-py3-opt/genfiles /Iexternal/bazel_tools /Ibazel-out/msvc_x64-py3-opt/genfiles/external/bazel_tools /Iexternal/protobuf /Ibazel-out/msvc_x64-py3-opt/genfiles/external/protobuf /Iexternal/eigen_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/msvc_x64-py3-opt/genfiles/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/gif_archive /Iexternal/jpeg /Ibazel-out/msvc_x64-py3-opt/genfiles/external/jpeg /Iexternal/com_googlesource_code_re2 /Ibazel-out/msvc_x64-py3-opt/genfiles/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/msvc_x64-py3-opt/genfiles/external/fft2d /Iexternal/highwayhash /Ibazel-out/msvc_x64-py3-opt/genfiles/external/highwayhash /Iexternal/png_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/png_archive /Iexternal/zlib_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/zlib_archive /Iexternal/snappy /Ibazel-out/msvc_x64-py3-opt/genfiles/external/snappy /Iexternal/local_config_cuda /Ibazel-out/msvc_x64-py3-opt/genfiles/external/local_config_cuda /Iexternal/bazel_tools/tools/cpp/gcc3 /Iexternal/protobuf/src /Ibazel-out/msvc_x64-py3-opt/genfiles/external/protobuf/src /Iexternal/eigen_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/eigen_archive /Iexternal/gif_archive/lib /Ibazel-out/msvc_x64-py3-opt/genfiles/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/msvc_x64-py3-opt/genfiles/external/gif_archive/windows /Iexternal/farmhash_archive/src /Ibazel-out/msvc_x64-py3-opt/genfiles/external/farmhash_archive/src /Iexternal/png_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/png_archive /Iexternal/zlib_archive /Ibazel-out/msvc_x64-py3-opt/genfiles/external/zlib_archive /Iexternal/local_config_cuda/cuda /Ibazel-out/msvc_x64-py3-opt/genfiles/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/msvc_x64-py3-opt/genfiles/external/local_config_cuda/cuda/cuda/include /showIncludes /DEIGEN_MPL2_ONLY /DSNAPPY /MT /O2 /c tensorflow/stream_executor/cuda/cuda_gpu_executor.cc /Fobazel-out/msvc_x64-py3-opt/bin/tensorflow/stream_executor/_objs/cuda_platform/tensorflow/stream_executor/cuda/cuda_gpu_executor.o.\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(274): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(274): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(289): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(289): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(372): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(372): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(620): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(620): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(639): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(639): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(666): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(666): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(680): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(680): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(694): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(694): error C2059: syntax error: '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(708): error C2589: 'constant': illegal token on right side of '::'\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc(708): error C2059: syntax error: '::'\r\ncl : Command line warning D9002 : ignoring unknown option '-march=native'\r\ncl : Command line warning D9002 : ignoring unknown option '-march=native'\r\n____Building complete.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n____Elapsed time: 216.281s, Critical Path: 141.66s\r\n```\r\n\r\nIf you try to compile master revision then compilation even won't start with the error:\r\n\r\n```\r\nERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:1932:1: C++ compilation of rule '//tensorflow/core/kernels:resize_bilinear_op_gpu' failed (Exit 2).\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(359): error C3861: 'atomicAdd': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(360): error C3861: 'atomicAdd': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(361): error C3861: 'atomicAdd': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(362): error C3861: 'atomicAdd': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(365): error C3861: 'atomicMax': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(366): error C3861: 'atomicMax': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(378): error C3861: 'max': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(378): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(394): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(394): error C3861: '__double_as_longlong': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(393): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(399): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(445): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(462): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(498): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(507): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(516): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(527): error C3861: '__int_as_float': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(527): error C3861: '__float_as_int': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(526): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(529): error C3861: '__int_as_float': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(538): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(538): error C3861: '__double_as_longlong': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(537): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(540): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(548): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(557): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(566): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(577): error C3861: '__int_as_float': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(577): error C3861: '__float_as_int': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(576): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(579): error C3861: '__int_as_float': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(588): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(588): error C3861: '__double_as_longlong': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(587): error C3861: 'atomicCAS': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(590): error C3861: '__longlong_as_double': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(617): error C2065: 'warpSize': undeclared identifier\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(619): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(620): error C3861: '__shfl': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(621): error C3861: '__shfl': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(622): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(637): error C2065: 'warpSize': undeclared identifier\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(639): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(640): error C3861: '__shfl_up': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(641): error C3861: '__shfl_up': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(642): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(657): error C2065: 'warpSize': undeclared identifier\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(659): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(660): error C3861: '__shfl_down': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(661): error C3861: '__shfl_down': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(662): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(677): error C2065: 'warpSize': undeclared identifier\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(679): error C2059: syntax error: 'volatile'\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(680): error C3861: '__shfl_xor': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(681): error C3861: '__shfl_xor': identifier not found\r\n.\\tensorflow/core/util/cuda_kernel_helper.h(682): error C2059: syntax error: 'volatile'\r\ncl : Command line warning D9002 : ignoring unknown option '-march=native'\r\ncl : Command line warning D9002 : ignoring unknown option '-march=native'\r\ncl : Command line warning D9002 : ignoring unknown option '-x'\r\ncl : Command line warning D9002 : ignoring unknown option '-nvcc_options=relaxed-constexpr'\r\ncl : Command line warning D9002 : ignoring unknown option '-nvcc_options=ftz=true'\r\ncl : Command line warning D9024 : unrecognized source file type 'cuda', object file assumed\r\ncl : Command line warning D9027 : source file 'cuda' ignored\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n____Elapsed time: 3817.327s, Critical Path: 143.61s\r\n```\r\n\r\nI'll be glad to help to fix the issues. But I absolutely has no idea what's going on here. Can anybody help to fix Windows compilation please? Currently here is no build for Windows with AVX, AVX2 support in the whole world!", "comments": ["The atomicAdd errors at least might be due to a missing -latomic flag in the linkopts of the relevant binary. Maybe something got added to the cmake build and left out of bazel? (but I'm not sure how fully Bazel builds on Windows are supported)", "What's your bazel version?  You may need to turn on wrappers.\r\nPlease take a look at the last comments in \r\nhttps://github.com/bazelbuild/bazel/issues/2075\r\n\r\nBTW, we have no CI build for windows-bazel-GPU config. So, I don't think it is well supported.  It may break often.\r\n", "Version: bazel-0.5.4-windows-x86_64.", "Hi @zyavrik ,\r\n\r\nPlease set USE_MSVC_WRAPPER=1\r\n\r\ne.g. \r\n```\r\nbazel --output_base C:\\t build --action_env=USE_MSVC_WRAPPER=1 //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n", "**snnn**, thanks for help! It helped with the described error in 1.3 revision. Also I fixed the following error: https://github.com/tensorflow/tensorflow/issues/12979 But then another error appeared:\r\n\r\n```\r\n____Loading package: @pcre//\r\n____Loading package: tensorflow/contrib/saved_model\r\n____Found 1 target...\r\n____Building...\r\n____[0 / 6] Creating source manifest for //tensorflow/tools/pip_package:build_pip_package\r\n____[13 / 205] Writing file tensorflow/python/tools/saved_model_cli.zip-2.params\r\n____[16 / 214] Writing file external/snappy/libsnappy.a-2.params [for host]\r\n____[20 / 244] Writing file tensorflow/python/gen_sparse_ops_py_wrappers_cc.exe-2.params [for host]\r\n____[34 / 481] Writing file external/jpeg/libjpeg.a-2.params [for host]\r\n____From Compiling tensorflow/core/lib/hash/crc32c_accelerate.cc [for host]:\r\nusage: cl [ option... ] filename... [ /link linkoption... ]\r\nWarning: Unmatched arguments: -msse3\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\nERROR: C:/tensorflow-r1.3/tensorflow/core/BUILD:1350:1: output 'tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o' was not created.\r\nERROR: C:/tensorflow-r1.3/tensorflow/core/BUILD:1350:1: not all outputs were created or valid.\r\n____Building complete.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n____Elapsed time: 3629.194s, Critical Path: 0.29s\r\n```\r\n\r\nI just run it again and got another error (why???):\r\n\r\n```\r\nDmitry@Desktop MINGW64 /c/tensorflow-r1.3\r\n$ bazel.exe build --config=opt --config=win-cuda --action_env=USE_MSVC_WRAPPER=1 //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n____Loading complete.  Analyzing...\r\n____Found 1 target...\r\n____Building...\r\n____[1 / 40] Executing genrule @gif_archive//:windows_unistd_h [for host]\r\n____[19 / 162] Creating source manifest for //tensorflow/python:gen_training_ops_py_wrappers_cc [for host]\r\n____[24 / 274] Expanding template tensorflow/python/tools/freeze_graph.cmd\r\n____[25 / 280] Writing file tensorflow/core/liblinalg_ops_op_lib.lo-2.params [for host]\r\n____[37 / 305] Creating source manifest for //tensorflow/python:gen_random_ops_py_wrappers_cc [for host]\r\n____[41 / 312] Executing genrule //third_party/py/numpy:dummy\r\n____[41 / 315] Expanding template external/jpeg/jconfigint_win.h\r\n____[44 / 318] Writing file tensorflow/python/tools/freeze_graph.zip-2.params\r\n____[56 / 347] Creating source manifest for //tensorflow/python:gen_state_ops_py_wrappers_cc [for host]\r\n____[59 / 353] Expanding template tensorflow/python/debug/offline_analyzer.cmd\r\n____[61 / 357] Writing file tensorflow/core/libuser_ops_op_lib.lo-2.params [for host]\r\n____[64 / 364] Executing genrule @local_config_cuda//cuda:cuda-extras\r\n____[70 / 389] Writing file tensorflow/core/libparsing_ops_op_lib.lo-2.params [for host]\r\n____[77 / 405] Writing file tensorflow/core/liblogging_ops_op_lib.lo-2.params [for host]\r\n____[96 / 451] Writing file tensorflow/cc/ops/random_ops_gen_cc.exe-2.params [for host]\r\n____[101 / 474] Writing file tensorflow/cc/ops/data_flow_ops_gen_cc.exe-2.params [for host]\r\n____[110 / 492] Creating source manifest for //tensorflow/cc:ops/linalg_ops_gen_cc [for host]\r\n____[112 / 510] Writing file external/swig/swig.exe-2.params [for host]\r\n____[125 / 592] Compiling external/pcre/pcre_config.c [for host]\r\n____From Compiling external/pcre/pcre_globals.c [for host]:\r\nusage: cl [ option... ] filename... [ /link linkoption... ]\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/pcre/BUILD.bazel:5:1: output 'external/pcre/_objs/pcre/external/pcre/pcre_globals.o' was not created.\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/pcre/BUILD.bazel:5:1: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n____Elapsed time: 8.557s, Critical Path: 2.01s\r\n```\r\n\r\nOne more try - and error is different again. What's going on here?\r\n\r\n```\r\nDmitry@Desktop MINGW64 /c/tensorflow-r1.3\r\n$ bazel.exe build --config=opt --config=win-cuda --action_env=USE_MSVC_WRAPPER=1 //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n____Loading complete.  Analyzing...\r\n____Found 1 target...\r\n____Building...\r\n____[1 / 296] Compiling external/pcre/pcre_version.c [for host]\r\n____From Compiling external/swig/Source/Preprocessor/cpp.c [for host]:\r\nusage: cl [ option... ] filename... [ /link linkoption... ]\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n____From Compiling external/pcre/pcre_get.c [for host]:\r\nusage: cl [ option... ] filename... [ /link linkoption... ]\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n____From Compiling external/swig/Source/Swig/naming.c [for host]:\r\nusage: cl [ option... ] filename... [ /link linkoption... ]\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/pcre/BUILD.bazel:5:1: output 'external/pcre/_objs/pcre/external/pcre/pcre_get.o' was not created.\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/swig/BUILD.bazel:5:1: output 'external/swig/_objs/swig/external/swig/Source/Preprocessor/cpp.o' was not created.\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/pcre/BUILD.bazel:5:1: not all outputs were created or valid.\r\nERROR: C:/msys64/tmp/_bazel_dmitry/lla8twkh/external/swig/BUILD.bazel:5:1: output 'external/swig/_objs/swig/external/swig/Source/Swig/naming.o' was not created.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n____Elapsed time: 2.194s, Critical Path: 0.62s\r\n```\r\n\r\nAnd so on... **Each time different error!**", "You get different error for different runs because: there are many errors, not only one.  This is very like invoking gmake with \"-j\".\r\n\r\nPlease add \" --verbose_failures\" to your build command,  so we can see more logs.\r\n\r\nBTW, the code under r1.3 branch is not compilable right now, because of the sha256sum issue. \r\n\r\n\r\n", "I fixed sga256sum issue. The errors are different. Output is with `--verbose_failures` already.", "Just FYI, I've successfully compile v1.3 with CMake + Visual Studio 2015 + CUDA 8 + CUDNN 6.1 on Windows 10. Had to include various hacks to fix several compilation error related to Eigen and CUDA though \ud83d\ude12  But at least it works now \ud83d\ude04  Feel free to ask me about issues you run into if you are compiling with similar set up.\r\n\r\nI follow this post to get started, but it doesn't show how to fix the errors I got.\r\nhttps://joe-antognini.github.io/machine-learning/build-windows-tf\r\nThis post is also very helpful for the next step if you want to build a standalone application:\r\nhttps://joe-antognini.github.io/machine-learning/windows-tf-project", "@phg1024, can you please describe your hacks? I'm going to try to compile it tomorrow.", "@zyavrik These are the changes I can find in the code: https://github.com/phg1024/tensorflow/commit/291f29533a510797f64e1f646b38aeea62238389\r\n\r\nThere are also some configuration changes about the VS project settings to resolve undefined symbols in the linking stage. You can follow take a look at https://joe-antognini.github.io/machine-learning/windows-tf-project to get some sense about how to resolve those.", "Can anybody create pull request for those fixes?", "@zyavrik Did those fixes work for you? They need to be cleaned up for a pull request though. I don't have much time to do that right now...", "@phg1024, your fixes in the code helped with some errors. Now I get the following errors:\r\n\r\n```\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\" (default target) (3) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (129) ->\r\n(CustomBuild target) ->\r\n  C:/tensorflow/tensorflow/core/kernels/bias_op_gpu.cu.cc(178): error : identifier \"__syncwarp\" is undefined [C:\\tensor\r\nflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\n  C:/tensorflow/tensorflow/core/kernels/bias_op_gpu.cu.cc(178): error : identifier \"__syncwarp\" is undefined [C:\\tensor\r\nflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\n  C:/tensorflow/tensorflow/core/kernels/bias_op_gpu.cu.cc(178): error : identifier \"__syncwarp\" is undefined [C:\\tensor\r\nflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\n```\r\nAlso I don't understand yet how \"Building a standalone C++ Tensorflow program on Windows\" hints can help to build python package.\r\n", "When you use cmake to config the project, did you enable GPU? `__syncwarp` should be defined in `tensorflow/tensorflow/core/util/cuda_kernel_helper.h` already.\r\n\r\nFor the windows related post, you can get some idea about how to resolve undefined symbols issues if you ever want to build a c++ program using the compiled tensorflow library. It won't help you much if you only need to use the python API.", "Yes, I did. My cmake command:\r\n\r\n```\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\nMore? -DSWIG_EXECUTABLE=C:/swigwin/swig.exe ^\r\nMore? -DPYTHON_EXECUTABLE=C:/Users/Dmitry/AppData/Local/Programs/Python/Python36/python.exe ^\r\nMore? -DPYTHON_LIBRARIES=C:/Users/Dmitry/AppData/Local/Programs/Python/Python36/libs/python36.lib ^\r\nMore? -Dtensorflow_ENABLE_GPU=ON ^\r\nMore? -DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\"\r\n\r\n```", "Looks like `C:/tensorflow/tensorflow/core/kernels/bias_op_gpu.cu.cc` didn't include `tensorflow/tensorflow/core/util/cuda_kernel_helper.h`? Did you check if `tensorflow/tensorflow/core/util/cuda_kernel_helper.h` has `__syncwarp` defined?", "I incorrectly merged your changes to the repository. The same files were changed recently. Thanks for your help!", "Still get errors :(\r\n\r\n```\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\" (default target) (3) ->\r\n(Link target) ->\r\n  maxpooling_op.obj : error LNK2001: unresolved external symbol \"public: bool __cdecl tensorflow::functor::MaxPoolForwa\r\nrdWithOptionalArgmax<struct Eigen::QInt8>::operator()(struct Eigen::QInt8 const *,int,int,int,int,int,int,int,int,int,i\r\nnt,int,int,struct Eigen::QInt8 *,__int64 *,struct Eigen::GpuDevice const &)\" (??R?$MaxPoolForwardWithOptionalArgmax@UQI\r\nnt8@Eigen@@@functor@tensorflow@@QEAA_NPEBUQInt8@Eigen@@HHHHHHHHHHHHPEAU34@PEA_JAEBUGpuDevice@4@@Z) [C:\\tensorflow\\tenso\r\nrflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj]\r\n  C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\Release\\pywrap_tensorflow_internal.dll : fatal error LNK1120: 1 unresolv\r\ned externals [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj]\r\n```", "I fixed this error in https://github.com/phg1024/tensorflow/commit/291f29533a510797f64e1f646b38aeea62238389\r\n\r\nYou need to explicitly instantiate it\r\n```\r\ntemplate struct MaxPoolForwardWithOptionalArgmax<Eigen::QInt8>;\r\n```\r\nThen you can just compile this very file in Visual studio and see if you get other errors. If not, go ahead and do the linking stage only.\r\n", "Sorry for my mistake again! But still can't compile it... :(\r\n\r\n```\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_extension_ops.vcxproj\" (default target) (130) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_gru_ops.vcxproj\" (default target) (220) ->\r\n(Link target) ->\r\n  blas_gemm.obj : error LNK2019: unresolved external symbol \"void __cdecl nsync::nsync_mu_rlock(struct nsync::nsync_mu_\r\ns_ *)\" (?nsync_mu_rlock@nsync@@YAXPEAUnsync_mu_s_@1@@Z) referenced in function \"public: void __cdecl tensorflow::functo\r\nr::TensorCuBlasGemm<float>::operator()(class tensorflow::OpKernelContext *,bool,bool,unsigned __int64,unsigned __int64,\r\nunsigned __int64,float,float const *,int,float const *,int,float,float *,int)\" (??R?$TensorCuBlasGemm@M@functor@tensorf\r\nlow@@QEAAXPEAVOpKernelContext@2@_N1_K22MPEBMH3HMPEAMH@Z) [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_gru_ops.vcxproj\r\n]\r\n  blas_gemm.obj : error LNK2019: unresolved external symbol \"void __cdecl nsync::nsync_mu_runlock(struct nsync::nsync_m\r\nu_s_ *)\" (?nsync_mu_runlock@nsync@@YAXPEAUnsync_mu_s_@1@@Z) referenced in function \"public: void __cdecl tensorflow::fu\r\nnctor::TensorCuBlasGemm<float>::operator()(class tensorflow::OpKernelContext *,bool,bool,unsigned __int64,unsigned __in\r\nt64,unsigned __int64,float,float const *,int,float const *,int,float,float *,int)\" (??R?$TensorCuBlasGemm@M@functor@ten\r\nsorflow@@QEAAXPEAVOpKernelContext@2@_N1_K22MPEBMH3HMPEAMH@Z) [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_gru_ops.vcx\r\nproj]\r\n  C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\Release\\_gru_ops.dll : fatal error LNK1120: 2 unresolved externals [C:\\t\r\nensorflow\\tensorflow\\contrib\\cmake\\build\\_gru_ops.vcxproj]\r\n\r\n\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_extension_ops.vcxproj\" (default target) (130) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_lstm_ops.vcxproj\" (default target) (221) ->\r\n  blas_gemm.obj : error LNK2019: unresolved external symbol \"void __cdecl nsync::nsync_mu_rlock(struct nsync::nsync_mu_\r\ns_ *)\" (?nsync_mu_rlock@nsync@@YAXPEAUnsync_mu_s_@1@@Z) referenced in function \"public: void __cdecl tensorflow::functo\r\nr::TensorCuBlasGemm<float>::operator()(class tensorflow::OpKernelContext *,bool,bool,unsigned __int64,unsigned __int64,\r\nunsigned __int64,float,float const *,int,float const *,int,float,float *,int)\" (??R?$TensorCuBlasGemm@M@functor@tensorf\r\nlow@@QEAAXPEAVOpKernelContext@2@_N1_K22MPEBMH3HMPEAMH@Z) [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_lstm_ops.vcxpro\r\nj]\r\n  blas_gemm.obj : error LNK2019: unresolved external symbol \"void __cdecl nsync::nsync_mu_runlock(struct nsync::nsync_m\r\nu_s_ *)\" (?nsync_mu_runlock@nsync@@YAXPEAUnsync_mu_s_@1@@Z) referenced in function \"public: void __cdecl tensorflow::fu\r\nnctor::TensorCuBlasGemm<float>::operator()(class tensorflow::OpKernelContext *,bool,bool,unsigned __int64,unsigned __in\r\nt64,unsigned __int64,float,float const *,int,float const *,int,float,float *,int)\" (??R?$TensorCuBlasGemm@M@functor@ten\r\nsorflow@@QEAAXPEAVOpKernelContext@2@_N1_K22MPEBMH3HMPEAMH@Z) [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_lstm_ops.vc\r\nxproj]\r\n  C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\Release\\_lstm_ops.dll : fatal error LNK1120: 2 unresolved externals [C:\\\r\ntensorflow\\tensorflow\\contrib\\cmake\\build\\_lstm_ops.vcxproj]\r\n```", "`nsync_mu_rlock` is used in `tensorflow/core/platform/default/mutex.h` but never declared in the project. It looks like it's from the Google's `nsync` project: https://github.com/google/nsync/blob/master/public/nsync_mu.h", "Similar issue on Linux: https://github.com/tensorflow/tensorflow/issues/12810", "It's one of the external dependencies. Try to find nsync under `cmake\\build\\external` and also the `cmake\\build\\nsync`. You should be able to find compiled `.lib` files and header files. Link them to the library you were trying to compile.", "You are right - .h file and nsync.lib are there. But how can I link them? Sorry, I'm not C++ programmer, just trying to recompile tensorflow with AVX and AVX2 support to use with Python... Thanks a lot for your help.", "Does anybody have success to compile tensorflow with GPU support for Windows?", "Hi @zyavrik\r\n\r\nSure. I do it every day. For TF 1.3 release, you don't need any patch to make it work (except the sha256sum). Master branch often breaks.  But, you'd better use Python 3.5 instead, as the support for Python 3.6 is relatively new.", "It's impossible to build 1.3 release on CPU with AVX512 support because of different errors.", "Hi @zyavrik\r\n\r\nThen you may disable it first.  TF can only pass the tests while AVX is disabled, so I choose to not enable AVX.", "The only one reason to compile it is to enable AVX, AVX2 support...", "I don't think \"Bazel & cmake compilations for Windows are completely broken\" is true. Maybe it lacks something for you, but it is not completely broken. TF has a large userbase on Windows. If the build system is completely broken,  how can they use it? Google has a philosophy that every build should be reproducible.   You can get known how google build TF from http://ci.tensorflow.org/.  These build scripts are maintained in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build \r\n\r\nPlease describe your problem precisely: which is broken, under what kind of situation? So the others can help you. In the same time, if you know where the problem is and you can fix it, contributions are welcomed. \r\n", "Master revision doesn't work at all - both with bazel and cmake. Errors were provided. Revision 1.3 doesn't work on CPU with AVX512 support (even when AVX512 isn't used).", "@gunan, could you look at what could be done to streamline/fix this to work out of the box?", "We are sorry about the negative experience you have been seeing.\r\nBazel support out of the box on windows is still WIP. I will recommend using cmake build for all users on windows. We are hoping early in 2018 we will be able to declare out of the box bazel support working.\r\nIn the meantime, I recommend sticking with the build scripts @snnn pointed out.\r\n\r\nAVX, AVX2 support we have are weak, and AVX512 support is definitely missing. That is because we did not have the cycles, and we had other priorities. We are sorry about the inconvenience. But in case you would like to contribute fixes to these, I am happy to accept your Pull Requests. After all, TF is an open source project for all of us to improve.\r\n\r\nWindows has been a difficult platform to support for us because our primary platform is almost always linux, and the build systems and compilers we need to use are very different on two platforms. We hope to be able to triage most of the reported issues, but unfortunately we have limited bandwidth.", "My personal view: I always perfer to use bazel than cmake for building tensorflow on Windows, because it can do incremental build very well.  At this time, bazel on Windows works well except it can't build the custom ops under tf.contrib, thus all stuffs under tf.contrib are missing.  We won't get it until https://github.com/bazelbuild/bazel/issues/1920 is fixed.  I wish bazel team could put more resources on this issue. After that, we can deprecate cmake and unify the build systems, reduce the extra maintain cost.  The more build systems we have, the harder to add a new file in tensorflow. \r\n\r\n@meteorcloudy ", "This has been fixed. but we still need to tidy up our bazel build.\r\nI will close this issue as the main problem here is fixed.", "@snnn I think you would be interested in https://github.com/meteorcloudy/tensorflow/commits/fix_contrib_with_cc_import\r\n\r\nI can now use Bazel@HEAD to build tensorflow on Windows with `//tensorflow/contrib/...` enabled.\r\n\r\nThe fix requires a new rule, `cc_import`, that will come out with Bazel 0.10.0, so I'll send to PR to fix tensorflow/contrib/... after 0.10,0 is released.", "@meteorcloudy That's awesome! Thank you!", "@meteorcloudy would that also enable custom op support on windows?\r\nOnce that is tackled, our official builds on windows will be converted to bazel.", "@gunan , Yes, exactly as what you said. Now they are working Bazel 0.9.0, and Bazel 0.10.0 will be released in later Jan.  \r\n\r\n", "@snnn is absolutely correct!", "Is the **MKL** option on ./configure working on windows too (using bazel)?\r\nI know it is working well on linux, but I am trying to compile tensorflow-cpu with **MKL** on windows and the contrib/cmake does not support it.", "No.\r\nMKL only works on linux right now/", "Hi @zyavrik ,have you solved this problem?This problem also confused me a lot.", "For anyone stumbling on this while googling `ignoring unknown option '-march=native'`, the issue is because `march=native` is a `gcc` flag. I've got my TF+GPU 1.14 to build in Windows by using `/arch:AVX2`. See [MSVC docs](https://docs.microsoft.com/en-us/cpp/build/reference/arch-x64?view=vs-2019)"]}, {"number": 12977, "title": "Cmake nightly builds for Windows are broken for more than a month!", "body": "Cmake nightly builds for Windows are broken for more than a month!\r\nWill tensorflow ever support Windows again?", "comments": ["The master revision fails with the error (compiling **with GPU support**):\r\n\r\n`C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.ta\u200c\u200brgets(171,5): error MSB6006: \"cmd.exe\" e xited with code 1. [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\cub.vcxproj]\r\n`\r\n\r\nThe revision on the moment of the last successful nightly build fails as well (why?) with the error:\r\n\r\n`\r\nC:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.ta\u200c\u200brgets(171,5): error MSB6006: \"cmd.exe\" e xited with code 1. [C:\\tensorflow-cmake\\tensorflow\\contrib\\cmake\\build\\gemmlowp\u200c\u200b.vcxproj]`", "/CC @mrry", "btw, AVX optimized Windows binary wheel is the most requested wheel on https://github.com/yaroslavvb/tensorflow-community-wheels/issues", "@ekelsen Erich: The current build failure (see e.g. [here](http://ci.tensorflow.org/job/tf-master-win-gpu-cmake/979/console)) looks like it might be caused by the GPU reduction code you added in 42fcbb196052823c4393a4d5d8682ca425253f6a. It looks like MSVC can't infer the template arguments for `BlockReduce()` and `WarpReduce()`... can you please take a look?", "I have a fix internally, going in today.", "@ekelsen, did you fix it? Nightly builds are still broken...", "well, I did fix one problem, but it looks like there's another one.  These tests don't run internally, so it can be hard to tell sometimes...  There is a PR with a fix for this issue here: https://github.com/tensorflow/tensorflow/pull/12920/files\r\n\r\nI'll accelerate getting that part of that CL that solves this issue submitted.", "Why have you closed it? The problem is still not resolved!"]}, {"number": 12976, "title": "Add half-precision support for `DepthwiseConv2dNative`", "body": "This fix tries to address the request raised in #12327 so that float16 is supported for `DepthwiseConv2dNative`\r\n\r\nThis fix fixes #12327.\r\n\r\nThis fix fixes #11502.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@drpngx Thanks for the review. The PR has been updated. Please take a look and let me know if there are any issues.", "Jenkins, test this please.", "Sorry to be dense, but where is the float16 test disabled, and can you report what the differences are?", "Strange, it seems to fail on Mac on `import enum`.", "@drpngx Thanks for the review.\r\n\r\nThe PR didn't `disable` the float16, but rather `not enable` the float16 tests for `testDepthwiseConv2DInputGrad` and `testDepthwiseConv2DFilterGrad`.\r\n\r\nBefore this PR, in `testDepthwiseConv2DInputGrad` (Ln 371):\r\n```\r\n      for data_type in [dtypes.float32, dtypes.float64]:\r\n        self._ConstructAndTestGradient(\r\n            input_size,\r\n            filter_size,\r\n            output_size,\r\n            stride,\r\n            padding,\r\n            data_type,\r\n            test_input=True,\r\n            use_gpu=True)\r\n```\r\n\r\nAfter this PR, the `dtypes.float16` was **not added** to the above. Instead, a comment was added to specify that `dtypes.float16` is not enabled (yet).\r\n\r\nIf we enable `dtypes.float16`, then here is the error message:\r\n```\r\n======================================================================\r\nFAIL: testDepthwiseConv2DInputGrad (__main__.DepthwiseConv2DTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 387, in testDepthwiseConv2DInputGrad\r\n    use_gpu=True)\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 368, in _ConstructAndTestGradient\r\n    self.assertLess(err, tolerance)\r\nAssertionError: 3.373046875 not less than 0.002\r\n\r\n----------------------------------------------------------------------\r\nRan 10 tests in 21.389s\r\n\r\nFAILED (failures=1)\r\n```\r\n\r\nPlease take a look.", "@yongtang a lot of the tests seemed to fail with `ImportError: No module named enum` can you address that to keep the review moving forward.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/debug/examples/debug_fibonacci.py\", line 25, in <module>\r\n    import tensorflow as tf\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 102, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 30, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 36, in <module>\r\n    from tensorflow.python.ops import variable_scope as vs\r\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/darwin_x86_64-opt/bin/tensorflow/python/debug/examples_test.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py\", line 24, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\n```\r\n", "As it is not your change, you might just have to rebase.", "Thanks @sb2nov. I rebased the PR and also fixed several compilation errors on GPU. The tests should pass now. Please take a look.", "Jenkins, test this please.", "The Jenkins failure for `Linux CPU Test Makefile` seems to be related to permissions on Jenkins server?\r\n```\r\nrm -rf /workspace/tensorflow/contrib/makefile/gen\r\nrm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/mkl_tfconversion_pass.o': Permission denied\r\nrm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/graph_partition.o': Permission denied\r\nrm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/mkl_layout_pass.o': Permission denied\r\n```", "Transient error. Jenkins, test this please\n\nOn Sep 26, 2017 4:43 AM, \"Yong Tang\" <notifications@github.com> wrote:\n\n> The Jenkins failure for Linux CPU Test Makefile seems to be related to\n> permissions on Jenkins server?\n>\n> rm -rf /workspace/tensorflow/contrib/makefile/gen\n> rm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/mkl_tfconversion_pass.o': Permission denied\n> rm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/graph_partition.o': Permission denied\n> rm: cannot remove '/workspace/tensorflow/contrib/makefile/gen/obj/tensorflow/core/graph/mkl_layout_pass.o': Permission denied\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12976#issuecomment-332171579>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbXwI996ILYdw9ZOR3xA_MaYyRhU9ks5smONMgaJpZM4PTjjk>\n> .\n>\n", "How imprecise is the `float16` result?", "@drpngx The `depthwise_conv2d_native` op itself is fine. The imprecise is for the `gradient` and the error is pretty large:\r\n\r\n\r\n```\r\n======================================================================\r\nFAIL: testDepthwiseConv2DFilterGrad (__main__.DepthwiseConv2DTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 427, in testDepthwiseConv2DFilterGrad\r\n    use_gpu=True)\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 368, in _ConstructAndTestGradient\r\n    self.assertLess(err, tolerance)\r\nAssertionError: 3.29296875 not less than 0.002\r\n\r\n======================================================================\r\nFAIL: testDepthwiseConv2DInputGrad (__main__.DepthwiseConv2DTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 387, in testDepthwiseConv2DInputGrad\r\n    use_gpu=True)\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/depthwise_conv_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/depthwise_conv_op_test.py\", line 368, in _ConstructAndTestGradient\r\n    self.assertLess(err, tolerance)\r\nAssertionError: 3.373046875 not less than 0.002\r\n\r\n----------------------------------------------------------------------\r\n```", "That seems a little too large. Maybe it's a bug? I'm afraid that people will get confused if they try to train with it. Can we just disable it for float16?", "@drpngx The gradient of `DepthwiseConv2dNative` for float16 has been disabled. Please take a look.", "Jenkins, test this please.", "Jenkins, test this please.\r\n\r\nI should have fixed the MacOS and XLA failures."]}, {"number": 12975, "title": "Also accept non-k8 CPU types in build pip package.", "body": "Fixes #12735", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @tensorflower-gardener to be potential reviewers.", "There is a silent python3 error AFAICT.", "Actually building pip package failed on python3.\r\nI will see what is going on.", "Failure seems to be unrelated, and happens in another pending merge.", "Also seen internally, root caused to an anomaly in gemmlowp repository.\r\nHave a change waiting to submit to fix the issue.", "Thank you @gunan !"]}, {"number": 12974, "title": "Feature missing? Ability to get Tensorboard output from provided \"estimators\"", "body": "This is opened here since it relates to Estimator and canned estimator models not providing a method to get output for TB\r\n\r\n3. It shouldn't be a TensorBoard issue. And I attempted to get an answer at Stackoverflow.. (here https://stackoverflow.com/questions/46064056/no-easy-way-to-add-tensorboard-output-to-pre-defined-estimator-functions-dnnclas/46065066#46065066 )\r\n\r\nI have been using the estimator interface in TF 1.3 including the creation of the data input function:\r\n\r\n`training_input_fn = tf.estimator.inputs.pandas_input_fn(x=training_data, y=training_label, batch_size=64, shuffle=True, num_epochs=None)`\r\n\r\nand building the NN:\r\n\r\n`dnnclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=dnn_features,\r\n    hidden_units=[1024, 500, 100],\r\n    n_classes=2, \r\n    model_dir='./tmp/ccsprop',\r\n    optimizer=tf.train.ProximalAdagradOptimizer(\r\n      learning_rate=0.001,\r\n      l1_regularization_strength=0.01\r\n    ))`\r\n\r\nand executing it\r\n\r\n`dnnclassifier.train(input_fn=training_input_fn, steps=1500)`\r\n\r\nAfter much searching I see no easy way to add tensorboard output without resorting to recreating the model from scratch and indicated here https://www.tensorflow.org/extend/estimators\r\n\r\nFollowing some of the help on SO:\r\n\r\n` TBcall=tf.train.SummarySaverHook(save_steps=10, output_dir='./tb', summary_op=tf.summary.merge_all())`\r\n\r\n`dnnclassifier.train(input_fn=training_input_fn, steps=1500, hooks=TBcall)`\r\n\r\nthat gives this error: Exactly one of scaffold or summary_op must be provided\r\n\r\nThe answer on SO has now been edited to show code from creating a model from scratch it seems.. So is there no way to get basic info from  tf.estimator.DNNClassifier to Tensorboard? And more generically from other tf.estimators ?? One would expect the canned estimators to provide this? For model introspection and tuning.\r\n\r\n\r\n", "comments": ["@dandelionmane would you please comment or refer someone?", "@jart @chihuahua Can you take a look at this? We are thinking about adding a hook to a garden model that uses a canned estimator.", "@martinwicke @ispirmustafa I think there's essentially a missing API on the Estimator side for allowing TensorBoard integration. Is there a solution for this?\r\n\r\nWhen I was playing with Estimators earlier I was able to get some coordination between TensorBoard and Estimators by creating a SummarySaverHook when defining my model code, and then passing that into the tf.estimator.EstimatorSpec. But I don't think that works in this case where you use an off-the-shelf estimator. ", "Unless I'm totally off, this would be extraordinarily surprising: Estimator (incl. DNNEstimator) uses MonitoredTrainingSession, which automatically creates a SummarySaverHook, by default every 10 minutes or 100 steps, whichever happens first. You can adjust this using the config constructor argument.\r\n\r\nThese summaries are saved to the model_dir.\r\n\r\n", "It is entirely possible that it is indeed a documentation/user issue, nonetheless, How does one create and use the summarySaverhook? but also as noticed seemingly not possible using the canned models?", "Hi @dartdog,\r\nSummarySaverHook is created for you automatically in estimators. You should not worry about it.\r\nAll the summaries should be automatically dumped to model_dir. ", "Please note the original question which indicates something is not working!! @ispirmustafa Generating error message not output! And no documentation. I do not believe that this should have been closed.. @dandelionmane dandelionmane", "@dartdog Unless I am totally mistaken, you are generating an error because you are passing a summarysaverHook to the estimator, when it already has one generated internally upon creation.\r\n\r\nWhat you could do is passing a tf.estimator.RunConfig() object directly when you instantiate the estimator. Using your own code it would look like\r\n\r\n`dnnclassifier = tf.estimator.DNNClassifier(feature_columns=dnn_features, hidden_units=[1024, 500, 100], n_classes=2, model_dir='./tmp/ccsprop', optimizer=tf.train.ProximalAdagradOptimizer( learning_rate=0.001, l1_regularization_strength=0.01, config=tf.estimator.RunConfig().replace(save_summary_steps=10) ))`\r\n\r\nYou do not have to include a summary_merge statement because the estimator will do that for you.", "I'll give it a go and respond..\r\n", "That did not work,  using :\r\n\r\n    `dnnclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=dnn_features,\r\n    hidden_units=[1024, 500, 100],\r\n    n_classes=2, \r\n    model_dir='./tmp/ccsprop',\r\n    optimizer=tf.train.ProximalAdagradOptimizer(\r\n      learning_rate=0.001,\r\n      l1_regularization_strength=0.01,\r\n      config=tf.estimator.RunConfig().replace(save_summary_steps=10)\r\n    ))`\r\nI just got:\r\n\r\n    `     11       l1_regularization_strength=0.01,\r\n    ---> 12       config=tf.estimator.RunConfig().replace(save_summary_steps=10)\r\n         13     ))\r\n         14 #note reducing the learning rate does seem to help!\r\n\r\n      TypeError: __init__() got an unexpected keyword argument 'config'\r\n", "Note now trying with corrected syntax..:\r\n\r\n\r\n    dnnclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=dnn_features,\r\n    hidden_units=[1024, 500, 100],\r\n    n_classes=2, \r\n    model_dir='./tmp/ccsprop',\r\n    optimizer=tf.train.ProximalAdagradOptimizer(\r\n      learning_rate=0.001,\r\n      l1_regularization_strength=0.01),\r\n      config=tf.estimator.RunConfig().replace(save_summary_steps=10)\r\n    )", "That now generates some seemingly useful Tensorboard output! Thank you so much. Anyway to modify the output Using Tensorboard commands or am I stuck with the standard output the canned model defines?", "For the canned ones, you are stuck with what they provide. If you write a custom one (by writing a model_fn to give to Estimator) you can do whatever you want.", "FWIW some Doc addition would probably be nice :-)", "What's the place in which you would have benefited most from additional documentation? \r\n\r\nIf you send a PR, that would be great too.", "@dartdog Sorry about that, I missed the fact that you called an optimizer directly. Great to hear that you got it to work.\r\n\r\nI think you are stuck with what the canned models are defining in terms of metrics, but perhaps you can use the SessionRunHooks to log your own metrics that way?", "Hello does this solution still work for the current version of tf.estimator? I implemented the code structure and i get \"No scalar data was found\", \"No graph definition files were found.\" It there another way I should do this?\r\nBelow is my code:\r\noutdir = './gp_trained'\r\nshutil.rmtree(outdir, ignore_errors = True) # start fresh each time\r\nmyopt = tf.train.AdamOptimizer(learning_rate = 0.01, beta1=0.9,beta2=0.999) #AdamOptimizer\r\nmodel = tf.estimator.DNNRegressor(model_dir = outdir,\r\n                                hidden_units = [50],\r\n                                feature_columns = featcols.values(),\r\n                                optimizer = myopt,\r\n                                dropout = 0.1,\r\n                                config=tf.estimator.RunConfig().replace(save_summary_steps=10))\r\nNSTEPS = (100 * len(df_train)) / BATCH_SIZE\r\nmodel.train(input_fn = train_input_fn, steps = NSTEPS)\r\nprint_rmse(model, 'eval', eval_input_fn)\r\nThank you.", "Hmm. I am using the lab from the google/coursera class shown in this [directory](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/03_tensorflow).  as a template for a DNNClassifier (binary).  Specifically I am using the notebook d_traineval.ipynb as my guide.  I also have the error with no data.\r\n\r\nI used the approach above to but still nothing.  Here is my actual code for this step:\r\n\r\n  ```\r\n# To convert a model to distributed train and evaluate do four things\r\n  estimator = tf.estimator.DNNClassifier(                         # 1. Estimator\r\n                          model_dir = output_dir,\r\n                          feature_columns = feature_cols, \r\n                          hidden_units=[160, 80, 40, 20],\r\n                          n_classes=2,\r\n                          optimizer=tf.train.ProximalAdagradOptimizer(   \r\n                            learning_rate=0.001,\r\n                            l1_regularization_strength=0.01),\r\n                          config=tf.estimator.RunConfig().replace(save_summary_steps=10)  # 2. run config\r\n                                                                                          # ODD. he mentions we need a run config in the videos, but it was missing in the lab\r\n                                                                                          # notebook.  Later I found the bug report which gave me this bit of code.\r\n                          )# \r\n\r\n\r\n```", "Hmm. I modified the above code remove the optimizer parameter and I adjusted the save_summary_steps=10 to be save_summary_steps=2.  The result is that now I can see the accuracy and accuracy_baseline graphs.  Possibly my problem was that I have small dataset 802 total samples with 15 features and that the save summary steps was to big. ", "Hmm. further still. This specifically fixed it.\r\n```\r\nOUTDIR = './model_trained'\r\nTensorBoard().start(OUTDIR)\r\n```\r\n\r\nOriginally, I had it without the leading './' for the outdir specification."]}, {"number": 12973, "title": "Default keras initializers parameters have changed", "body": "At least in Tensorflow 1.3, some of the Keras initializers have changed they default parameters since Tensorflow 1.1:\r\n\r\nIn Tensorflow 1.1:\r\n\r\n``\r\nfrom tensorflow.contrib.keras.python.keras.initializers import TruncatedNormal\r\nTruncatedNormal().stddev  # returns 0.05\r\n``\r\n\r\nIn Tensorflow 1.3:\r\n``\r\nfrom tensorflow.contrib.keras.python.keras.initializers import TruncatedNormal\r\nTruncatedNormal().stddev  # returns 1\r\n``\r\n\r\nI assume this was not intentional since this is a breaking change and I did not see it documented in the release notes.", "comments": ["@fchollet can you comment?", "In TF 1.2, we removed the Keras `TruncatedNormal` initializer and instead simply imported the core version (from `init_ops`). The core version has a different default `stddev` value, hence the change. This was an oversight.\r\n\r\nCode in contrib is subject to changes. Now the Keras API has moved to core, so such changes will not happen in the future.\r\n\r\nIn general, I would recommend not using `TruncatedNormal` (prefer scaling initializers such as glorot, etc) and I would recommend always specifying `stddev` if you are using it."]}, {"number": 12972, "title": "Dataset API fromGenerator Functionality", "body": "@mrry I was looking at the code for the `fromGenerator` function and I notice that you do `iter(generator())` to create multiple parallel iterators over the same generator. Maybe I'm not too familiar with the semantics of a Python generator, but my impression was that it represents a continuation and it's not necessarily repeatable, meaning that you would have to cache all the elements you get in order to reproduce them. For example, let's say a generator is querying an online service and yielding a different tensor at each time point, dependent on the answer it gets from that service. This would not be repeatable without caching those tensors. So, in that case, how would your implementation behave? And in more general, what does the `iter()` function applied in this setting mean?\r\n\r\nRegarding the caching of elements, I think that if there is a problem with the current implementation, then the right way to do this would be something along the lines of:\r\n1. Create a dataset from a generator, as it's currently done, but also store a flag in it specifying it's a `GeneratorDataset` (could also be subclassing dataset to make things simpler).\r\n2. When `repeat` is called on such a dataset, convert the generator to something like a Scala stream, which simply memoizes elements as you obtain them, but lazily evaluates the tail of your sequence (sort of like an iterator but with memoization) and then return a dataset that uses that stream as its source.\r\n\r\nIt may be totally unnecessary depending on the semantics of the `iter()` function, but based on a quick search I did, I couldn't find enough information for this setting.", "comments": ["Pure (stateless) generator brings more opportunities for optimization but non-pure generator is indeed quite common. Maybe it's best to mention in the document what dataset features require purity. ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Catching up on old issues: @eaplatanios Indeed, there is no guarantee that two iterators over the same generator will yield the same result. Use `Dataset.cache()` on the resulting `Dataset` if you need to memoize the results. We've updated the documentation for `Dataset.from_generator()` and I think it's clearer now, but feel free to submit a documentation PR if it could be improved further!"]}, {"number": 12971, "title": "Add utf8 support for string_split", "body": "This fix is an effort to try to address the request raised in #11399 where it was not possible to split utf8 strings with `tf.string_split`.\r\n\r\nThis fix adds an additional attr of `encoding` so that `utf8` could be specified for `string_split`.\r\n\r\nThis fix fixes #11399.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Thanks @drpngx for the review. The PR has been updated with comments addressed. Please take a look.", "Jenkins, test this please.\n\nOn Sep 14, 2017 9:17 PM, \"Yong Tang\" <notifications@github.com> wrote:\n\n> Thanks @drpngx <https://github.com/drpngx> for the review. The PR has\n> been updated with comments addressed. Please take a look.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12971#issuecomment-329676587>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbV-wjL_qPMRw1Jn7PG3S1fA7qRpGks5sifpUgaJpZM4PTdqy>\n> .\n>\n", "One Jenkins failure is `//tensorflow/tools/api/tests:api_compatibility_test` which is expected (API Change).\r\n\r\nAnother Jenkins failure is `//tensorflow/python/kernel_tests:fft_ops_test`. I am wondering if it is untreated? (saw this failure in other PRs as well).", "Oh you need to rebase, we've fixed the `api_compatibility_test`. The `fft_ops_test` is fixed internally, I will push that later.", "Thanks @drpngx  for the review. The PR has been rebased and updated. Please take a look.", "Jenkins, test this please.", "Sounds fair. Note that since we have it in `str_util`, it's no longer sufficient to check at the single call site, since there might be a different part of the code calling us now.\r\n\r\nJenkins, test this please.", "Thanks @drpngx for the help. I updated the PR with `PREDICT_FALSE` -> `TF_PREDICT_FALSE`.", "Thanks! Jenkins, test this please.\n\nOn Sep 16, 2017 12:29 PM, \"Yong Tang\" <notifications@github.com> wrote:\n\n> Thanks @drpngx <https://github.com/drpngx> for the help. I updated the PR\n> with PREDICT_FALSE -> TF_PREDICT_FALSE.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12971#issuecomment-329989638>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbYkV-UiGo-VoZyVbE8EGyp9Kaz4Vks5sjCGNgaJpZM4PTdqy>\n> .\n>\n", "@asimshankar Thanks for the review. The PR has been updated. Currently, the implementation of this PR is to:\r\n\r\nIn case an UTF8 encoding is used, then either an empty string or a one character UTF8 (actually ASCII as there is only one char) is allowed to be specified as a delimiter. Properly encoding is validated now as well.\r\n\r\nThe reason for only allowing one char in UTF8 case is that, the `StringSplit` OP was defined such that only one char is allowed. If we expand the ops to take more than one chars, I think backward-compatibility may not be maintained.\r\n\r\nFor that it might make sense to introduce another OP instead of adding additional `encoding` attribute to `StringSplit`. I can update the PR if the other option is preferred. Please let me know.", "@asimshankar ping", "@yongtang : A separate op sounds preferable as it will be the more complete solution (like wanting to split on a multi-byte character). Let's do that instead.  Thanks!", "@asimshankar Thanks. I will update the PR.", "Thanks for the review @asimshankar. The PR has been updated with a new OP `string_utf8_split` added, which supports multi-bytes delimiter. Please take a look and let me know if there are any issues.", "Thanks @asimshankar for the detailed review. The PR has been updated. Please take a look and let me know if there are any issues.", "Thanks @asimshankar for the review. Will updated the PR shortly.", "Thanks @asimshankar for the review. The PR has been updated with review comments addressed. Please take a look.", "@asimshankar Thanks for the review. The PR has been updated. Please take a look.", "@asimshankar can you look at the new changes?", "Thanks @asimshankar for the review and help. The PR has been updated. Please take a look.", "Thanks @asimshankar for the help and review. The PR has been updated. Please take a look.", "There seems to have failed tests. Will update the PR shortly.", "FAILURE\n \n", "SUCCESS\n \n", "FAILURE\n \n", "The failure is about Windows and the rest of builds seem pass. I don't have a Windows dev machine setup yet, but will try to take a look and see what I could do to fix it.", "@asimshankar can you take another look? I triggered the tests.", "I was under the impression that @yongtang was digging into the test failures on Windows. Looking at the failures I see:\r\n\r\n```\r\nFAIL: testStringSplitWithUtf8AndEmptyDelimiter (__main__.StringSplitOpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:/tf_jenkins/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/string_split_op_test.py\", line 221, in testStringSplitWithUtf8AndEmptyDelimiter\r\n    b\"\\xE4\\xB8\\x96\", b\"\\xE7\\x95\\x8C\"])\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1148, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 871, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 796, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nArrays are not equal\r\n\r\n(mismatch 100.0%)\r\n x: array([b'\\x00\\x82\\xa8', b'\\x00\\xa5\\xbd', b'\\x00\\xb8\\x96', b'\\x00\\x95\\x8c'], dtype=object)\r\n y: array([b'\\xe6\\x82\\xa8', b'\\xe5\\xa5\\xbd', b'\\xe4\\xb8\\x96', b'\\xe7\\x95\\x8c'], \r\n      dtype='|S3')\r\n```\r\n\r\nSuggesting things about the `dtype` of numpy arrays of strings that I am not well versed in.\r\nWill have to look into it. If anyone has ideas, much appreciated. Otherwise will ask around internally as well.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yongtang did you investigate this any further?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The PR has been rebased to resolve the merge conflict. The Windows issue may still exist.\r\n\r\nI finally managed to find a Windows VM image from Microsoft:\r\nhttps://developer.microsoft.com/en-us/windows/downloads/virtual-machines\r\n\r\nI will spend some time to see if I could fix the Windows issue.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yongtang : Any progress in fixing things up on Windows?", "@asimshankar Sorry for lack of updates.\r\n\r\nI was able to find a Windows VM with Visual Studio 2017 preinstalled license  from https://developer.microsoft.com/en-us/windows/downloads/virtual-machines (license will expire in 05/13).\r\n\r\nHowever, it appears that TensorFlow currently does not work well with Visual Studio 2017 build.\r\n\r\nI have tried multiple times but still could not get a successful Windows build first (either with cmake or with bazel). Therefore unable to move forward to debug the issue of utf8 string with Windows.\r\n\r\nGIven the current status I think it might make sense to close this PR or label it as `stalled` for now. I will give it another try and if I am able to move forward again, will open the new PR.\r\n\r\nThanks for the help during the process and sorry for the inconvenience.", "@guschmue does anything jump at you?", "Re-running tests to get the logs out.", "I have not build for some time but can give it a try.", "Nagging Assignee @asimshankar: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 32 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I feel really ashamed to not be able to fix the Windows test failure after so long. It shouldn't be very hard.\r\n\r\nHowever, I still couldn't even build the tensorflow from source with a Windows 10 VM machine (and Visual Studio 2017), after another attempt. Without that I just could not debug the issue. (Don't have a Windows machine).\r\n\r\nI have created an issue #19583 to list the detailed steps for my failure encountered. Would appreciate any help to make tensorflow build on Windows 10 + VS2017.", "No worries! It's always hard to debug if you don't have access to a system. For the record, the failures are:\r\n\r\n```\r\n======================================================================\r\nFAIL: testStringSplitWithUtf8AndEmptyDelimiter (__main__.StringSplitOpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"T:/src/github/tensorflow/tensorflow/python/kernel_tests/string_split_op_test.py\", line 221, in testStringSplitWithUtf8AndEmptyDelimiter\r\n    b\"\\xE4\\xB8\\x96\", b\"\\xE7\\x95\\x8C\"])\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1460, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=msg)\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 813, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 739, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nArrays are not equal\r\n(mismatch 100.0%)\r\n x: array([b'\\x00\\x82\\xa8', b'\\x00\\xa5\\xbd', b'\\x00\\xb8\\x96', b'\\x00\\x95\\x8c'], dtype=object)\r\n y: array([b'\\xe6\\x82\\xa8', b'\\xe5\\xa5\\xbd', b'\\xe4\\xb8\\x96', b'\\xe7\\x95\\x8c'],\r\n      dtype='|S3')\r\n======================================================================\r\nFAIL: testStringSplitWithUtf8AndNonSkipEmpty (__main__.StringSplitOpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"T:/src/github/tensorflow/tensorflow/python/kernel_tests/string_split_op_test.py\", line 170, in testStringSplitWithUtf8AndNonSkipEmpty\r\n    b\"\", b\"\\xE7\\x95\\x8C\"])\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1460, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=msg)\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 813, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 739, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nArrays are not equal\r\n(mismatch 50.0%)\r\n x: array([b'\\x00\\xa5\\xbd', b'', b'', b'\\x00\\x95\\x8c'], dtype=object)\r\n y: array([b'\\xe5\\xa5\\xbd', b'', b'', b'\\xe7\\x95\\x8c'],\r\n      dtype='|S3')\r\n======================================================================\r\nFAIL: testStringSplitWithUtf8AndSkipEmpty (__main__.StringSplitOpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"T:/src/github/tensorflow/tensorflow/python/kernel_tests/string_split_op_test.py\", line 157, in testStringSplitWithUtf8AndSkipEmpty\r\n    self.assertAllEqual(values, [b\"\\xE5\\xA5\\xBD\", b\"\\xE7\\x95\\x8C\"])\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1460, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=msg)\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 813, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 739, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nArrays are not equal\r\n(mismatch 100.0%)\r\n x: array([b'\\x00\\xa5\\xbd', b'\\x00\\x95\\x8c'], dtype=object)\r\n y: array([b'\\xe5\\xa5\\xbd', b'\\xe7\\x95\\x8c'],\r\n      dtype='|S3')\r\n======================================================================\r\nFAIL: testStringSplitWithUtf8AndUtf8MultiBytesDelimiter (__main__.StringSplitOpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"T:/src/github/tensorflow/tensorflow/python/kernel_tests/string_split_op_test.py\", line 235, in testStringSplitWithUtf8AndUtf8MultiBytesDelimiter\r\n    b\"\\xE4\\xB8\\x96\\xE7\\x95\\x8C\", b\"\\xE5\\xA5\\xBD\"])\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1460, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=msg)\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 813, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"C:\\Python35\\lib\\site-packages\\numpy\\testing\\utils.py\", line 739, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nArrays are not equal\r\n(mismatch 100.0%)\r\n x: array([b'\\x00\\xa5\\xbd', b'\\x00\\xb8\\x96\\xe7\\x95\\x8c',\r\n       b'\\x00\\xb8\\x96\\xe7\\x95\\x8c', b'\\x00\\xa5\\xbd'], dtype=object)\r\n y: array([b'\\xe5\\xa5\\xbd', b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\r\n       b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c', b'\\xe5\\xa5\\xbd'],\r\n      dtype='|S6')\r\n```\r\nand the MacOS errors are:\r\n```\r\n[ RUN      ] SplitUTF8.Basic\r\ntensorflow/core/lib/strings/str_util_test.cc:470: Failure\r\n      Expected: result[3]\r\n      Which is: \"\\0\"\r\nTo be equal to: \"a\"\r\ntensorflow/core/lib/strings/str_util_test.cc:479: Failure\r\n      Expected: result[2]\r\n      Which is: \"\\0\"\r\nTo be equal to: \"a\"\r\ntensorflow/core/lib/strings/str_util_test.cc:481: Failure\r\n      Expected: result[4]\r\n      Which is: \"\\0\"\r\nTo be equal to: \"b\"\r\ntensorflow/core/lib/strings/str_util_test.cc:483: Failure\r\n      Expected: result[6]\r\n      Which is: \"\\0\"\r\nTo be equal to: \"c\"\r\ntensorflow/core/lib/strings/str_util_test.cc:495: Failure\r\n      Expected: str_util::Join(result, \"|\")\r\n      Which is: \"\\0\"\r\nTo be equal to: \"a\"\r\ntensorflow/core/lib/strings/str_util_test.cc:501: Failure\r\n      Expected: str_util::Join(result, \"|\")\r\n      Which is: \"\\0|\\0|\\0\"\r\nTo be equal to: \"a|b|c\"\r\ntensorflow/core/lib/strings/str_util_test.cc:505: Failure\r\n      Expected: str_util::Join(result, \"|\")\r\n      Which is: \"\\0|||\\0||\\0|\"\r\nTo be equal to: \"a|||b||c|\"\r\ntensorflow/core/lib/strings/str_util_test.cc:508: Failure\r\n      Expected: str_util::Join(result, \"|\")\r\n      Which is: \"\\0|\\0|\\0\"\r\n```", "Basically, it looks like there is something wrong with the logic. It seems to return `\\x0` instead of the original substrings.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes.", "Is there any progress on this or is it just stalled forever?", "@marhlder My last attempt to resolve the issue was some time ago. As far as I could see the only remaining issue was that on Windows the tests could not pass.\r\n\r\nHowever, I don't have access to a Windows machine with Visual Studio installed so mostly I was guessing around the potential ways to fix it. It was not that productive so the PR was stalled.\r\n\r\nThere is no progress at the moment. Though if I have access to Windows+VisualStudio then I may give it a try again. In the meantime, if anyone could help resolve the Windows test issue that would be greatly appreciated as well."]}, {"number": 12970, "title": "Updating default version for building from master source.", "body": "Making the default build from source version 1.4.0dev. The whl files that are built will be 1.3.0devDDMMYYYY.", "comments": ["```\r\n//tensorflow/python:framework_versions_test                              FAILED in 2.2s\r\n```", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 12969, "title": "All tf.sets.* ops fail to reproduce their own official examples.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a \r\n- **Exact command to reproduce**: n/a\r\n\r\n### Context:\r\n`tf.sets.*` ops documentation declares that: '_All but the last dimension of a and b must match._'.\r\nAlso, the example is provided:\r\n```\r\na = [\r\n    [\r\n      [\r\n        [1, 2],\r\n        [3],\r\n      ],\r\n      [\r\n        [4],\r\n        [5, 6],\r\n      ],\r\n    ],\r\n  ]\r\n  b = [\r\n    [\r\n      [\r\n        [1, 3],\r\n        [2],\r\n      ],\r\n      [\r\n        [4, 5],\r\n        [5, 6, 7, 8],\r\n      ],\r\n    ],\r\n  ]\r\ntf.sets.set_intersection(a, b)\r\ntf.sets. set_union(a, b)\r\ntf.sets.set_size(a)\r\ntf.sets.set_difference(a, b, aminusb=True)\r\n```\r\n\r\n### Problem:\r\nWhen using `tf.sets.*` ops, the following error occurs:\r\n```\r\nValueError: Argument must be a dense tensor: [[[[1, 2], [3]], [[4], [5, 6]]]] - got shape [1, 2, 2], but wanted [1, 2, 2, 2].\r\n```\r\nFrom this error it is deducible, that a dense tensor is needed. This statement contradicts the description of methods. Also, logically we would not want to have a dense tensor or any kind of padding in sets (this leads to excessive padding elements in sets - which defies the purpose).\r\n\r\n### Statement:\r\nEither the functionality or the description of `tf.sets` must be fixed.", "comments": ["@honkentuber can you comment? The documentation is confusing since each row of a tensor must have the same number of elements, which is not the case in the example.", "@dr4b @MarkDaoust can you look at this documentation issue? I don't know how pervasive this is, but it could affect all the sparse tensor ops.", "Sounds like Mark is going to take a stab at rewriting the samples.  We don't think this affects all of the sparse tensor ops, for now.", "The docs for sparse tensors contain some non-runnable text representations, but they don't look like they're meant to run (as this one does)."]}, {"number": 12967, "title": "Could not find `backports.weakref` while installing TensorFlow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: -\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6\r\n- **TensorFlow installed from (source or binary)**: (Trying to install through package manager pip2)\r\n- **TensorFlow version (use command below)**: 1.2.0\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: `pip2 install tensorflow==1.2.0`\r\n\r\n### Describe the problem\r\nWhile I try to install TF (1.2.0) on Python2.7 through the package manager Pip (`pip2 install tensorflow==1.2.0`) I get the following error:\r\n```\r\nCollecting tensorflow==1.2.0\r\n  Downloading https://build.hubteam.com/pypi-mirror/packages/bf/a8/e98871dc5bfbe590ed41a38058fab1391647dc0553d5034f5fd6746f0a37/tensorflow-1.2.0-cp27-cp27m-macosx_10_11_x86_64.whl (33.6MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33.6MB 37kB/s\r\nRequirement already satisfied: wheel in /usr/local/lib/python2.7/site-packages (from tensorflow==1.2.0)\r\nCollecting backports.weakref==1.0rc1 (from tensorflow==1.2.0)\r\n  Could not find a version that satisfies the requirement backports.weakref==1.0rc1 (from tensorflow==1.2.0) (from versions: )\r\nNo matching distribution found for backports.weakref==1.0rc1 (from tensorflow==1.2.0)\r\n```\r\n\r\nSo it doesn't find the `backports.weakref` package in PyPl (even if I can see it [here](https://pypi.python.org/pypi/backports.weakref)).\r\n\r\nIs this a known issue? What can I do to install this dependency manually?", "comments": ["/CC @gunan", "@yifeif, any ideas?\r\n\r\n@andybergon What version of pip are you using?\r\n`pip2 --version` should be the command to show the version.\r\n", "Could you try `pip install backports.weakref==1.0rc1` first?", "This was an internal problem. Sorry about the noise.\r\n`pip2 install --index-url https://pypi.python.org/simple tensorflow==1.2.0` worked."]}, {"number": 12966, "title": "Error when following official installation instructions ", "body": "INFO: Found 1 target...\r\nERROR: /opt/tensorflow/tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/cjliux/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=8.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/cuda_platform/tensorflow/stream_executor/cuda/cuda_dnn.pic.d '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/cuda_platform/tensorflow/stream_executor/cuda/cuda_dnn.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/nsync -iquote bazel-out/local_linux-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jemalloc -iquote bazel-out/local_linux-opt/genfiles/external/jemalloc -iquote external/protobuf_archive -iquote bazel-out/local_linux-opt/genfiles/external/protobuf_archive -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -iquote external/local_config_cuda -iquote bazel-out/local_linux-opt/genfiles/external/local_config_cuda -isystem external/nsync/public -isystem bazel-out/local_linux-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jemalloc/include -isystem bazel-out/local_linux-opt/genfiles/external/jemalloc/include -isystem external/protobuf_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/cuda_platform/tensorflow/stream_executor/cuda/cuda_dnn.pic.o)\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::wrap::WrapperShim__cudnnSetRNNDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnRNNStruct*, int, int, cudnnDropoutStruct*, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t}]':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1017:50:   required from here\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:139:38: error: cannot convert 'cudnnRNNStruct*' to 'cudnnHandle_t {aka cudnnContext*}' for argument '1' to 'cudnnStatus_t cudnnSetRNNDescriptor(cudnnHandle_t, cudnnRNNDescriptor_t, int, int, cudnnDropoutDescriptor_t, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnRNNAlgo_t, cudnnDataType_t)'\r\n       cudnnStatus_t retval = ::__name(args...);                    \\\r\n                                      ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:233:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'\r\n   __macro(cudnnSetRNNDescriptor)                              \\\r\n   ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:238:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R5'\r\n CUDNN_DNN_ROUTINE_EACH_R5(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cuda_dnn.cc:42:0:\r\nbazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/cuda/include/cudnn.h:1553:8: note: class type 'cudnnRNNStruct' is incomplete\r\n struct cudnnRNNStruct;\r\n        ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'int perftools::gputools::cuda::{anonymous}::CudnnDataTypeToByteSize(cudnnDataType_t)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:858:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'int perftools::gputools::cuda::CudnnRnnParamsDescriptor::GetRegionCountPerLayer() const':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1200:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNInputMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnInputMode(perftools::gputools::dnn::RnnInputMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:821:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDirectionMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnDirectionMode(perftools::gputools::dnn::RnnDirectionMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:833:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnMode(perftools::gputools::dnn::RnnMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:845:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDataType_t perftools::gputools::cuda::{anonymous}::ToCudnnDataType(perftools::gputools::dnn::DataType, perftools::gputools::dnn::DataLayout)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:809:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:283:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:305:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdFilterAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardFilterAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:327:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: At global scope:\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:128:26: warning: 'tensorflow::thread::ThreadPool* perftools::gputools::cuda::wrap::GetCudaThreadpool()' defined but not used [-Wunused-function]\r\n static port::ThreadPool* GetCudaThreadpool() {\r\n                          ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 22.367s, Critical Path: 10.38s\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\nI have configure nvcc to be the cuda compiler, so I have no idea why the aforementioned message means. Can any one help?", "comments": ["your architecture/platform where you running??\r\n", "Looks like an issue in your cuDNN version.", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 12965, "title": "Fix minor typo in Programmers guide", "body": "Fix \r\n\r\n> However, you may also specify a grpc:// URL to specify the address of a TensorFlow server, which gives the session access to all devices on machines that that server controls.\r\n\r\nto\r\n\r\n>  However, you may also specify a grpc:// URL to specify the address of a TensorFlow server, which gives the session access to all devices on machines that server controls.\r\n\r\nin `Graphs and Session`", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 12963, "title": "Cover the numpy-ndarray bug on s390x", "body": "NumPy's low-level method for instantiating an array (ndarray constructor) is behaving differently for s390x architecture. Providing the data type of the array's elements explicitly is solving the issue. Please refer to [issue#11431](https://github.com/tensorflow/tensorflow/issues/11431) for the detailed discussion. Though this a bug with NumPy implementation, adding data type for array elements should be safe.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "Some transient error on Linux GPU. \r\n\r\nJenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "Sixth time's the charm.\r\n\r\nJenkins, test this please.", "Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 12962, "title": "Error building freeze_graph", "body": "I am trying to build freeze_graph with bazel like this : \r\n\r\n` bazel build tensorflow/python/tools:freeze_graph\r\n`\r\n\r\nand I am getting this error : \r\n\r\n```\r\nERROR: /home/konmon01/tensorflow/tensorflow/BUILD:187:1: //tensorflow:all_files: invalid label ']' in element 2 of attribute 'srcs' in 'filegroup' rule: invalid target name ']': target names may not contain ']'\r\nERROR: /home/konmon01/tensorflow/tensorflow/python/BUILD:3736:12: Target '//tensorflow:internal' contains an error and its package is in error (this is usually caused by a missing package group in the package-level visibility declaration)\r\nERROR: /home/konmon01/tensorflow/tensorflow/python/BUILD:97:1: Target '//tensorflow:internal' contains an error and its package is in error and referenced by '//tensorflow/python:platform'\r\nERROR: /home/konmon01/tensorflow/tensorflow/python/BUILD:97:1: Target '//tensorflow:internal' contains an error and its package is in error and referenced by '//tensorflow/python:platform'\r\nERROR: Analysis of target '//tensorflow/python/tools:freeze_graph' failed; build aborted\r\nINFO: Elapsed time: 0.281s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n```\r\n\r\nI installed bazel from scratch but did not give a solution. Any suggestions on that ??\r\n\r\n> bazel version\r\n\r\n> Build label: 0.5.4\r\n> Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n> Build time: Fri Aug 25 10:00:00 2017 (1503655200)\r\n> Build timestamp: 1503655200\r\n> Build timestamp as int: 1503655200\r\n\r\nAs it turns out I cannot build any script with bazel (????)", "comments": ["Corrupted version of TF. Closing .."]}, {"number": 12961, "title": "Different confidence with same model.pb from android and python", "body": "I trained a model.pb with python, and put it in android. \r\nwell, I find the confidence score that in android is always lower than python application  on my PC.\r\nAFAIK, for android model.pb, I did not use DecodeJpeg because it not support on Android.\r\n\r\nIs there anything wrong or different with DecodeJpeg in android example when processing image?\r\n\r\n\r\n\r\n        Trace.beginSection(\"preprocessBitmap\");\r\n        // Preprocess the image data from 0-255 int to normalized float based\r\n        // on the provided parameters.\r\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n        for (int i = 0; i < intValues.length; ++i) {\r\n            final int val = intValues[i];\r\n            floatValues[i * 3 + 0] = (((val >> 16) & 0xFF) - imageMean) / imageStd;\r\n            floatValues[i * 3 + 1] = (((val >> 8) & 0xFF) - imageMean) / imageStd;\r\n            floatValues[i * 3 + 2] = ((val & 0xFF) - imageMean) / imageStd;\r\n        }\r\n        Trace.endSection();\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12960, "title": "does new dataset api support pre read data?", "body": "I found that currently dataset api does not support pre read data as old reading data api. If we have so much train data the feature, the speed of reading data is critical.", "comments": ["The easiest way to prefetch data is to use [`dataset = dataset.prefetch(BUFFER_SIZE)`](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/Dataset#prefetch), which is available in the nightly build. If you're using a release, you can get the same effect with `dataset = dataset.map(lambda x, y, z, ...: return (x, y, z, ...), num_threads=1, output_buffer_size=BUFFER_SIZE)`.", "I already try to add  thread num and buffer size param to dataset method map, but it doed not speed up.  It seems that the two params  does not  used for pre read data accoding to the docs.\r\n\r\nMy problem is when I have multiple gpu in one machine, I want  data parallism to speed up training speed. So I add multiple dataset node in the tensorflow graph  one for a gpu, but it seems that multiple dataset read data seqnencely and in one dataset there's no data pre reading. Multiple gpu can not be fully used as reading data into tf takes so much time.\r\n", "They certainly are used for prefetching. It's hard to say what the source of slowness is, without seeing the entire pipeline. It's possible that the input source (I'm guessing from files?) is limiting your overall throughput."]}, {"number": 12959, "title": "Python tests in //tensorflow/python/keras/... are failing on Windows", "body": "http://ci.tensorflow.org/job/tf-master-win-bzl/1552/console\r\n```\r\n11:11:55 //py_test_dir/tensorflow/python/keras:callbacks_test                     FAILED in 126.1s\r\n11:11:55   C:/tmp/_bazel_system/424zmya1/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/keras/callbacks_test/test.log\r\n11:11:55 //py_test_dir/tensorflow/python/keras:data_utils_test                    FAILED in 20.3s\r\n11:11:55   C:/tmp/_bazel_system/424zmya1/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/keras/data_utils_test/test.log\r\n11:11:55 //py_test_dir/tensorflow/python/keras:io_utils_test                      FAILED in 9.1s\r\n11:11:55   C:/tmp/_bazel_system/424zmya1/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/keras/io_utils_test/test.log\r\n11:11:55 //py_test_dir/tensorflow/python/keras:models_test                        FAILED in 33.0s\r\n11:11:55   C:/tmp/_bazel_system/424zmya1/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/keras/models_test/test.log\r\n11:11:55 //py_test_dir/tensorflow/python/keras:training_test                      FAILED in 53.9s\r\n11:11:55   C:/tmp/_bazel_system/424zmya1/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/keras/training_test/test.log\r\n```\r\n\r\nSome of the error messages:\r\n```\r\n11:11:55 ERROR: test_LambdaCallback (__main__.KerasCallbacksTest)\r\n11:11:55 ----------------------------------------------------------------------\r\n11:11:55 Traceback (most recent call last):\r\n11:11:55   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_uxjtk119\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\keras\\_impl\\keras\\callbacks_test.py\", line 798, in test_LambdaCallback\r\n11:11:55     p.start()\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\r\n11:11:55     self._popen = self._Popen(self)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\context.py\", line 212, in _Popen\r\n11:11:55     return _default_context.get_context().Process._Popen(process_obj)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\context.py\", line 313, in _Popen\r\n11:11:55     return Popen(process_obj)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\r\n11:11:55     reduction.dump(process_obj, to_child)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 59, in dump\r\n11:11:55     ForkingPickler(file, protocol).dump(obj)\r\n11:11:55 AttributeError: Can't pickle local object 'KerasCallbacksTest.test_LambdaCallback.<locals>.target'\r\n11:11:55 \r\n11:11:55 ======================================================================\r\n11:11:55 ERROR: test_TensorBoard_histogram_freq_must_have_validation_data (__main__.KerasCallbacksTest)\r\n11:11:55 ----------------------------------------------------------------------\r\n11:11:55 Traceback (most recent call last):\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\shutil.py\", line 488, in rmtree\r\n11:11:55     return _rmtree_unsafe(path, onerror)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\shutil.py\", line 378, in _rmtree_unsafe\r\n11:11:55     _rmtree_unsafe(fullname, onerror)\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\shutil.py\", line 387, in _rmtree_unsafe\r\n11:11:55     onerror(os.rmdir, path, sys.exc_info())\r\n11:11:55   File \"C:\\Program Files\\Anaconda3\\lib\\shutil.py\", line 385, in _rmtree_unsafe\r\n11:11:55     os.rmdir(path)\r\n11:11:55 OSError: [WinError 145] The directory is not empty: 'C:\\\\tmp\\\\callbacks_test1q3mfkyu\\\\tmp9rjq7egq\\\\logs'\r\n11:11:55 \r\n11:11:55 ======================================================================\r\n11:11:55 FAIL: test_stop_training_csv (__main__.KerasCallbacksTest)\r\n11:11:55 ----------------------------------------------------------------------\r\n11:11:55 Traceback (most recent call last):\r\n11:11:55   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_uxjtk119\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\keras\\_impl\\keras\\callbacks_test.py\", line 502, in test_stop_training_csv\r\n11:11:55     assert 'nan' in values[-1], 'The last epoch was not logged.'\r\n11:11:55 AssertionError: The last epoch was not logged.\r\n```\r\n\r\nTheses tests are not running in CMake build on Windows, so it's only detected by Bazel.", "comments": ["@mrry do you know why these tests fail on Windows?", "No, I'm not familiar with those tests.\r\n\r\nThe first one looks like it's getting caught up because Python's trying to simulate `fork()` on Windows by pickling the environment. Looking at the source of the test, I'm not sure why it uses a subprocess rather than a thread-and-event pair to detect that the callback has been called.\r\n\r\nFor the second one, perhaps `shutil.rmtree(..., ignore_errors=True)` would work, according to [this Stack Overflow answer](https://stackoverflow.com/a/21966211/3574081)?\r\n\r\nFor the third one, maybe a bug in `CSVLogger` (but I can't see anything obvious)?\r\n\r\n/cc @fchollet ", "I think at least some of these are due to open file handles. I will try to see how I can overcome these, and also add these in cmake tests.", "OK, I fixed most of the failures. There are a few more remaining now.\r\nHowever the following one I have no idea how to tackle:\r\n\r\n- tensorflow/python/keras/_impl/keras/engine/training_test.py\r\n- tensorflow/python/keras/_impl/keras/utils/data_utils_test.py\r\n\r\nThe error:\r\n```\r\n...\r\n00:36:47.092   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\context.py\", line 313, in _Popen\r\n00:36:47.092     return Popen(process_obj)\r\n00:36:47.092   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\r\n00:36:47.092     reduction.dump(process_obj, to_child)\r\n00:36:47.092   File \"C:\\Program Files\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 59, in dump\r\n00:36:47.092     ForkingPickler(file, protocol).dump(obj)\r\n00:36:47.092 AttributeError: Can't pickle local object 'GeneratorEnqueuer.start.<locals>.data_generator_task'\r\n```\r\nSeems to happen when we have a locally defined function we would like to run a new thread using the multiprocessing library. This seems to work fine in linux, but we see this error on windows.\r\nI think for threading, multiprocessing library uses a different code path on windows, which needs \"pickling\" stuff.\r\n\r\nAny ideas, @mrry, @pcloudy, @fchollet ", "I think Python `multiprocessing` depends on POSIX `fork()` semantics, so on Linux it can use `fork()`, but on Windows it has to fake it out in software by pickling some amount of process state. These errors seem to come from attempting to pickle a Python function, which I didn't think was supported by the standard `pickle` module. Is it possible that `use_multiprocessing=True` just doesn't work on Windows? ", "> These errors seem to come from attempting to pickle a Python function, which I didn't think was supported by the standard pickle module\r\n\r\nI think that should work in most circumstances. It would be interesting to see why exactly `GeneratorEnqueuer.start.<locals>.data_generator_task'` is not picklable.\r\n\r\n> Is it possible that use_multiprocessing=True just doesn't work on Windows?\r\n\r\nThat's an acceptable outcome. It would need to be documented.\r\n", "I think I got all the issues. I elected to disable use_multiprocessing tests on windows for now. But maybe we can add checks into the code itself for use_multiprocessing, on windows?\r\n\r\nAnyway, the PR is out for review, I also enabled python/keras tests for cmake build, we should see if I was really able to catch all failures."]}, {"number": 12958, "title": "R1.3", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 12957, "title": "ValueError in CTCLoss", "body": "TF version 1.1.0, Ubunu 16.04 Cuda 8.0, Cudnn 6\r\n\r\nloss = tf.nn.ctc_loss(targets, logits, maxT, time_major=False)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow /python/ops/ctc_ops.py\", line 145, in ctc_loss\r\n    ctc_merge_repeated=ctc_merge_repeated)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_ctc_ops.py\", line 165, in _ctc_loss\r\n    name=name)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2339, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1719, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1669, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/home/ilab/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shape must be rank 1 but is rank 0 for 'CTCLoss' (op: 'CTCLoss') with input shapes: [?,64,23], [?,?], [?], [].\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12956, "title": "Branch 168186374", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @tfboyd and @vrv to be potential reviewers.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "\"Could not start gRPC server\"\r\n\r\nJenkins, test this please."]}, {"number": 12955, "title": "AttributeError: 'NoneType' object has no attribute 'get_tensor_by_name'**", "body": "I trained mnist model and then create one .pb file by freeze that model. then i want  to load this freeze model  ... so my code is for load the freeze graph\r\n\r\n    import tensorflow as tf\r\n    import argparse \r\n    from tensorflow.python.platform import gfile\r\n\r\n    def load_graph(model_filename):\r\n\twith tf.Session() as sess:\r\n\t\tmodel_filename ='output_graph.pb'\r\n\t\twith gfile.FastGFile(model_filename, 'rb') as f:\r\n\t\t\tgraph_def = tf.GraphDef()\r\n\t\t\tgraph_def.ParseFromString(f.read())\r\n\t\t\tg_in = tf.import_graph_def(graph_def)\r\n\r\n     if __name__ == '__main__':\r\n    \r\n\t parser = argparse.ArgumentParser()\r\n\t parser.add_argument(\"--model_filename\", default=\"results/output_graph.pb\", type=str, \r\n                                                    help=\"model_filename to import\")\r\n\t args = parser.parse_args()\r\n\t\r\n\tprint('Loading the model')\r\n\tgraph = load_graph(args.model_filename)\r\n\t\t\r\n\tx = graph.get_tensor_by_name(\"x:0\")\r\n\ty = graph.get_tensor_by_name(\"op1:0\")\r\n\twith tf.Session(graph=graph) as sess:\r\n\t\t data = np.vectorize(lambda x: 255 - x)(np.ndarray.flatten(scipy.ndimage.imread\r\n                                                                                    (\"C:/Users/HP/Desktop/digi.jpg\", flatten=True)))\r\n\t         result = sess.run(tf.argmax(y,1), feed_dict={x: [data]})\r\n                 print (' '.join(map(str, result)))\r\n\r\n\r\nHalf of the code is run successfully but in last get the error of no attribute 'get_tensor_by_name''\r\n\r\n***Loading the model\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\Desktop\\programs\\TensorFlow\\save_export_fie.py\", line 29, in <module>\r\n    x = graph.get_tensor_by_name(\"x:0\")\r\nAttributeError: 'NoneType' object has no attribute 'get_tensor_by_name'****\r\n\r\nwhat is issue with my code..?????", "comments": ["You should have asked at Stackoverflow.\r\nDidn't test you code, but `load_graph(model_filename)` does not have a return-statement so maybe add\r\n`return g_in`.\r\nAnd  the `model_filename` parameter is useless, because you overwrite it in the next line....", "Closing this as more appropriate for Stack Overflow."]}, {"number": 12954, "title": "Naming issue of tensorflow.python.layers.core.Dense", "body": "Since I think this issue has nothing to do with the system information, I would temporarily ignore them.\r\n\r\n- **TensorFlow version (use command below)**:v1.2.1-4-g4acb96a 1.2.1\r\n\r\n\r\n### Describe the problem\r\nThe `Dense` layers defined in `tensorflow.python.layers.core` build `kernel` and `bias` in `build` function, while the `build` function is called in `__call__` function. The may cause that sometime one define a layer, but not call it immediately which causes an unexpected variable naming issue.\r\n\r\n### Source code / logs\r\nFor example, when I try to implement a toy seq2seq model, the following code\r\n\r\n```\r\n            with tf.variable_scope('output'):\r\n                self._output_layer = _core_layers.Dense(\r\n                    self._vocab_size, name='output_layer')\r\n\r\n            if targets is not None: # TRAINING\r\n                embedding_targets = tf.nn.embedding_lookup(\r\n                    self._embedding, targets)\r\n\r\n                outputs, final_state, = tf.nn.dynamic_rnn(\r\n                    cell=self._cell,\r\n                    inputs=embedding_targets,\r\n                    sequence_length=lengths,\r\n                    dtype=_FLOAT,\r\n                    time_major=True)\r\n\r\n                logits = self._output_layer(outputs)\r\n            else: # INFER, or sampling\r\n                _, batch_size, _ = tf.unstack(tf.shape(encoder_outputs))\r\n                eos_ids = tf.ones([batch_size], dtype=tf.int32, name='EOS')\r\n                eos_step_embedded = tf.nn.embedding_lookup(\r\n                    self._embedding, eos_ids)\r\n\r\n                def loop_fn_transition(time, cell_output, cell_state,\r\n                                       loop_state):\r\n\r\n                    def get_input():\r\n                        output_logits = self._output_layer(cell_output)  #<----- kernel/bias of dense defined here\r\n                        predictions = tf.argmax(output_logits, axis=1)\r\n                        next_input = tf.nn.embedding_lookup(\r\n                            self._embedding, predictions)\r\n                        return next_input\r\n\r\n                    elements_finished = (time >= lengths)\r\n                    emit_output = cell_output\r\n                    cell_state = cell_state\r\n                    loop_state = None\r\n\r\n                    return (elements_finished, get_input(), cell_state,\r\n                            emit_output, loop_state)\r\n\r\n                def loop_fn(time, cell_output, cell_state, loop_state):\r\n                    if cell_state is None:\r\n                        elements_finished = (0 >= lengths)\r\n                        next_input = eos_step_embedded\r\n                        cell_state = encoder_final_state\r\n                        emit_output = None\r\n                        loop_state = None\r\n\r\n                        return (elements_finished, next_input, cell_state,\r\n                                emit_output, loop_state)\r\n                    else:\r\n                        return loop_fn_transition(time, cell_output, cell_state,\r\n                                                  loop_state)\r\n\r\n                cell_outputs, final_state, _ = tf.nn.raw_rnn(\r\n                    self._cell, loop_fn)\r\n```\r\n\r\nI got (by inspecting the checkpoint file)\r\n\r\n```\r\nbasic_seq2seq/decoder/output_layer/bias (DT_FLOAT) [1301]\r\nbasic_seq2seq/decoder/output_layer/kernel (DT_FLOAT) [200,1301]\r\n```\r\nin training mode while got \r\n\r\n```\r\nbasic_seq2seq/decoder/rnn/output_layer/bias (DT_FLOAT) [1301]\r\nbasic_seq2seq/decoder/rnn/output_layer/kernel (DT_FLOAT) [200,1301]\r\n```\r\nin inference mode. So I can't restore a training checkpoint when inference due to `NotFoundError (see above for traceback): Key basic_seq2seq/decoder/rnn/output_layer/kernel not found in checkpoint`\r\n", "comments": ["How about using ` tf.layers.dense`?", "I am experiencing this too, I can't restore my saved session for inference.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It is an issue for me. But maybe the community does not care about this. I've given up tf so I think this has no reason to remain open.", "I met the same problem when constructing the graph differently in different mode.\r\nCould you please try:\r\n```\r\nwith tf.variable_scope('output') as output_scope:\r\n  self._output_layer = _core_layers.Dense(self._vocab_size, name='output_layer', _scope=output_scope,)\r\n```\r\nIt will fix the scope."]}, {"number": 12953, "title": "PIC flag for Makefile-built Android Static Library", "body": "Currently if we build a shared lib with ndk = r12b and android-api = 21, and the shared lib is linking Makefile-built tensorflow android static library, the android ndk hints that the tensorflow and nsync lib is not complied with -fPIC option, this PR fix the problem. It only impacts the android build.", "comments": ["@resec, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.", "Can one of the admins verify this patch?", "@petewarden please review ", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Jenkins, test this please!\r\n\r\n", "(CLA is fine, it's just me)", "Can one of the admins verify this patch?"]}, {"number": 12952, "title": "Add support of `axis` for `tf.unique`", "body": "This fix tries to address the request from #11575 where `axis` was not supported for `tf.unique`. \r\n\r\nThis fix adds support of `axis` for `tf.unique`. In this fix, the additional input `axis` has been specified as an `1D` vector so that it is possible to optionally provide an `axis` or not. In case `axis=[]` is provided, no axis is used. In case `axis=[x]` is used, `axis` for `tf.unique` is `x`. (ref  https://stackoverflow.com/questions/42754965/marking-input-as-optional-in-tensorflow)\r\n\r\nThis fix fixes #11575\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @lukeiwanski and @tensorflower-gardener to be potential reviewers.", "@a-dai could you take a look?", "Gentle ping, @a-dai ?", "Thanks @a-dai for the review. The PR has been updated. Please take a look and let me know if there are any issues.", "Jenkins, test this please.", "@caisq @a-dai @drpngx It seems that the Jenkins build is not starting automatically. Any chance to forceful start a Jenkins build so that the PR could be merged once Jenkins passes?", "Jenkins, test this please.", "Some kind of signature fail during docker build, it looks like. Jenkins, test this please.", "The Jenkins tests passed. The other tests I think it will need to label the PR `kokoro:run`?", "@gunan Not sure why some of the tests are failing on Jenkins as I could not reproduce on my dev machine. I based the PR and pushed again. Hopefully it will resolve some of the Jenkins issues. Can you relabel `kokoro:force-run` to give it a try again?", "Jenkins, test this please.", "It looks like the issues are related to this PR. Maybe a change in the behaviour of unique OP?", "Thanks @gunan. Let me double check and see if I could fix it.", "@gunan I have updated the PR and fixed the issue. The issue is that `forward_input_or_allocate_output` should be changed to `allocate_output`.\r\n\r\nI have tested locally and the following failed tests passes now:\r\n```\r\n//tensorflow/python/debug:analyzer_cli_test\r\n//tensorflow/python/debug:session_debug_file_test\r\n//tensorflow/python/feature_column:feature_column_test\r\n```\r\n\r\nCan you start the Jenkins again? Thanks a lot for the help.", "Jenkins, test this please."]}]