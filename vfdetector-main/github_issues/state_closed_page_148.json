[{"number": 50421, "title": "When you use math symbols instead of tf.math, tensorflow.keras.load_model does not properly load model for stuff like not equal", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): on mac 10.14.6  but on colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): default colab install\r\n- TensorFlow version (use command below): 2.5 \r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen I used some stuff such as != or == in code and save graph, I am not able to load the graph\r\nbut when I use tf.math I am able too. \r\n**Describe the expected behavior**\r\nI expect to be able to use that behavior and load the model. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1gm5DujworX-7X1z01qUToOlzE8qLbfPO?usp=sharing\r\nPlease toggle on and off the commented line\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue  in TF 2.5. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/a25b0e2b0736c1123f880c65e81a8b82/forgithub.ipynb).Thanks!", "As of now Tensorflow does not support those operations directly, adding **==** or **!=** would break lot of code, instead it's  suggested to use Tensorflow symbols like `tf.math.not_equal`. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50421\">No</a>\n"]}, {"number": 50420, "title": "[ROCm] creating a wrapper for the rocblas lib, and updating all calls to use the wrapper", "body": "/cc @cheshire @chsigg ", "comments": ["@deven-amd  Can you please resolve conflicts? Thanks!", "@gbaned done.  rebased PR to resolve the merge conflicts"]}, {"number": 50419, "title": "Simple TFLITE Quant uint8 model does not work properly on TFLITE-MICRO", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 5.10.42-1-MANJARO\r\n- TensorFlow installed from (source or binary):  Both:\r\nIn python : Pip\r\nTflite-micro code\r\n```\r\n  Fetch URL: https://github.com/tensorflow/tflite-micro.git\r\n  commit 217ad9fcb5d44028570923b411783457b127c291\r\n```\r\n- Tensorflow version (commit SHA if source): 2.5.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): RISCV Virtual Prototype\r\n\r\nHi,\r\nI have created a simple MobileNetV2 model with tensorflow_model_maker for object detection with the following code:\r\n```\r\nimport os\r\n\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nassert tf.__version__.startswith('2')\r\n\r\nfrom tflite_model_maker import model_spec\r\nfrom tflite_model_maker import image_classifier\r\nfrom tflite_model_maker.config import ExportFormat\r\nfrom tflite_model_maker.config import QuantizationConfig\r\nfrom tflite_model_maker.image_classifier import DataLoader\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\n# %%\r\n\r\ndata = DataLoader.from_folder(\"data/train\")\r\ntrain_data, rest_data = data.split(0.8)\r\nvalidation_data, test_data = rest_data.split(0.5)\r\n\r\n# %%\r\n#mobilenet_v3_spec = image_classifier.ModelSpec(uri=\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\")\r\n#mobilenet_v3_spec.input_image_shape = [224, 224]\r\nmodel = image_classifier.create(train_data, validation_data=validation_data, model_spec=\"mobilenet_v2\")\r\n\r\n# %%\r\nloss, accuracy = model.evaluate(test_data)\r\n\r\npost_quant_conf = QuantizationConfig.for_int8(representative_data=train_data)\r\n\r\nmodel.export(export_dir='export', tflite_filename=\"model_mobilenetv2_quant.tflite\", export_format=ExportFormat.TFLITE, quantization_config=post_quant_conf)\r\n\r\nmodel.evaluate_tflite('export/model_mobilenetv2_quant.tflite', test_data\r\n```\r\n\r\nFurthermore i exported this model with \r\n```\r\nxxd -i model_mobilenetv2_quant.tflite > model.cc\r\n```\r\nto run it in a tflite-micro environment.\r\n\r\nThe following code is a modification of the hello_world which initializes the tflite-micro environment end allocates the tensors:\r\n```\r\n    tflite::InitializeTarget();\r\n\r\n    static tflite::MicroErrorReporter micro_error_reporter;\r\n    error_reporter = &micro_error_reporter;\r\n\r\n    // Map the model into a usable data structure. This doesn't involve any\r\n    // copying or parsing, it's a very lightweight operation.\r\n    model = tflite::GetModel(g_model);\r\n    if(model->version() != TFLITE_SCHEMA_VERSION) {\r\n        TF_LITE_REPORT_ERROR(error_reporter,\r\n                             \"Model provided is schema version %d not equal \"\r\n                             \"to supported version %d.\",\r\n                             model->version(), TFLITE_SCHEMA_VERSION);\r\n        return;\r\n    }\r\n\r\n    static tflite::AllOpsResolver resolver;\r\n\r\n    // Build an interpreter to run the model with.\r\n    static tflite::MicroInterpreter static_interpreter(\r\n            model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\r\n    interpreter = &static_interpreter;\r\n\r\n    // Allocate memory from the tensor_arena for the model's tensors.\r\n    TfLiteStatus allocate_status = interpreter->AllocateTensors();\r\n    if(allocate_status != kTfLiteOk) {\r\n        TF_LITE_REPORT_ERROR(error_reporter, \"AllocateTensors() failed\");\r\n        return;\r\n    }\r\n\r\n    // Obtain pointers to the model's input and output tensors.\r\n    input = interpreter->input(0);\r\n\r\n    output = interpreter->output(0);\r\n\r\n    std::cout << \"Input type: \" << TfLiteTypeGetName(input->type) << std::endl;\r\n```\r\n\r\nThis code fails with the following error:\r\n```\r\ntensorflow/lite/micro/kernels/quantize_common.cc:51 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 || input->type == kTfLiteInt8 was not true.\r\n\r\nNode QUANTIZE (number 0f) failed to prepare with status 1\r\n```\r\n\r\nThe input-type of the Node is kTfLiteUInt8 which is not in the list of expected types but I don't know why. As far as I know, tflite-micro supports uint8 quantization. The ```tf.lite.converter``` in tensorflow_model_maker forces the input to be ``` tf.uint8``` which is okay because it is an image classifier. Moreover, the line\r\n```\r\n    std::cout << \"Input type\" << TfLiteTypeGetName(input->type) << std::endl;\r\n```\r\nproduces the output: ```Input type: FLOAT32```\r\nwhich is a surprise because the model should have an input_type of \"uint8\" according to the converters parameters.\r\nHowever, in python this input-type has the correct type, where\r\n```\r\ninterpreter = tf.lite.Interpreter(model_path=\"export/model_mobilenetv3_quant.tflite\")\r\ninterpreter.allocate_tensors()\r\ninterpreter.get_input_details()\r\n```\r\nresults in:\r\n```\r\n[{'name': 'input_1',\r\n  'index': 0,\r\n  'shape': array([  1, 224, 224,   3], dtype=int32),\r\n  'shape_signature': array([ -1, 224, 224,   3], dtype=int32),\r\n  'dtype': numpy.int8,\r\n  'quantization': (0.003921568859368563, -128),\r\n  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\r\n   'zero_points': array([-128], dtype=int32),\r\n   'quantized_dimension': 0},\r\n  'sparsity_parameters': {}}]\r\n\r\n```\r\nCan anybody explain this behavior to me? Maybe I missed some documented behavior or forgot something. As a workaround I converted the model to int8 which seems to work for the first error. The input_type in the micro environment however is also wrong. Moreover, with this i have to convert my input to int8 which I would rather not do manually because it is not really transparent which preprocessing the model does by itself.\r\n\r\n\r\n\r\nThx for your help.\r\n\r\n", "comments": ["tflite-micro is incrementally removing support for uint8:  https://github.com/tensorflow/tensorflow/issues/44912\r\n\r\nOur recommendation is to use int8 quatized models with TFLM."]}, {"number": 50416, "title": "[MLIR][DISC] canonicalize hlo reduce op for codegen", "body": "This pass canonicalize `mhlo.ReduceOp` to the suitable forms, so that we can simplify the codegen process", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50416) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "This is marked \"WIP\", is this ready for review?", "> This is marked \"WIP\", is this ready for review?\r\n\r\nok, it's ready now, please help us review it, thanks.", "Merged in 6114f66e57db5446a7f7995d801bb59a6e882d04"]}, {"number": 50415, "title": "image.pad_to_bounding_box throws unexpectedly", "body": "I'm trying to add an arbitrary amount of padding to images in a preprocessing Apache Beam pipeline. \r\n\r\nI calculate the amount of padding needed and if it's greater than 0 I call `tf.image.pad_to_bounding_box()` as follows:\r\n\r\n```python\r\nif padding > 0:\r\n    try:\r\n        target_height = int(org_height + (2 * padding))\r\n        target_width = int(org_width + (2 * padding))\r\n        image_decoded = tf.image.pad_to_bounding_box(\r\n            image=image_decoded,\r\n            offset_height=padding,\r\n            offset_width=padding,\r\n            target_height=target_height,\r\n            target_width=target_width,\r\n        )\r\n    except Exception as e:\r\n        print(\"/*/*/*/*/*/*/*/*/*/*/*/*/*/*/*/\")\r\n        print(\"padding failed\")\r\n        print(\r\n            f\"\"\"\r\n        {e}\r\n        org height: {org_height}\r\n        org width: {org_width}\r\n\r\n        after padding height: {target_height - padding - org_height}\r\n        after padding width: {target_width - padding - org_width}\r\n\r\n        target width: {int(org_width + (2 * padding))}\r\n        target height: {int(org_height + (2 * padding))}\r\n\r\n        padding: {padding}\r\n        \"\"\"\r\n        )\r\n        print(\"/*/*/*/*/*/*/*/*/*/*/*/*/*/*/*/\")\r\n```\r\n\r\nan example of an unexpected exception looks like this:\r\n\r\n```\r\n/*/*/*/*/*/*/*/*/*/*/*/*/*/*/*/\r\npadding failed\r\n\r\n                        width must be <= target - offset\r\n                        org height: 3744\r\n                        org width: 5616\r\n\r\n                        after padding height: 126\r\n                        after padding width: 126\r\n\r\n                        target width: 5868\r\n                        target height: 3996\r\n\r\n                        padding: 126\r\n                        \r\n/*/*/*/*/*/*/*/*/*/*/*/*/*/*/*/\r\n```\r\n\r\nClearly the \"after padding width\" is greater than 0, so I do not understand why it throws here.\r\n\r\nany help is greatly appreciated.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/ops/image_ops_impl.py#L1078", "comments": ["@smedegaard,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Sorry for the late response. \r\nThe error appeared in a loop. since then I changed the script and I no longer get the error.\r\n\r\nMight be due to how Beam iterates over PCollections?\r\n\r\nThe working code is here: https://gitlab.com/smedegaard/birds_to_tfrecords/-/blob/trunk/src/i2t/transforms/par_dos.py#L78\r\n\r\nBut it still puzzels me that the error was thrown since I'm printing \r\n```\r\n after padding height: 126\r\n after padding width: 126\r\n```\r\nThose are calculated the same way as in the assert in image_ops_impl.py"]}, {"number": 50414, "title": "Bazel build ERROR with TF2.4 Cuda11.0 Cudnn8 Python3.8 MSVC2019 bazel 3.1.0", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform : Win10\r\n- TensorFlow installed from (source or binary): TF2.4\r\n- TensorFlow version:TF2.4 and TF-GPU2.4\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: no, yes, no\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0/8\r\n- GPU model and memory: Nvidia GeForce 840M\r\n\r\n\r\n\r\n**Describe the problem**\r\nBazel does not build my TF\r\nI followed all these information: https://www.tensorflow.org/install/source_windows\r\nAnd I have this:\r\ntensorflow-2.4.0\tpython3.8\tMSVC 2019\tBazel 3.1.0\r\ntensorflow_gpu-2.4.0\tpython3.8\tMSVC 2019\tBazel 3.1.0\t8.0\t11.0\r\nI saw people indicating the same problem, but I did not find any solution anywhere.\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nusing\r\nbazel build //tensorflow/tools/pip_package:build_pip_package\r\nor\r\nbazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nGive the same result ! Error!\r\n\r\n\r\n\r\n**Any other info / logs**\r\n\r\n**ERROR: An error occurred during the fetch of repository 'local_config_cuda':**\r\n   Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1400\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1075, in _create_local_cuda_repository\r\n                _find_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 606, in _find_libs\r\n                _check_cuda_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 501, in _check_cuda_libs\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"C:/tensorflow/third_party/remote_config/common.bzl\", line 217, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\n'C:/Program' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n**ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda':** Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1400\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1075, in _create_local_cuda_repository\r\n                _find_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 606, in _find_libs\r\n                _check_cuda_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 501, in _check_cuda_libs\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"C:/tensorflow/third_party/remote_config/common.bzl\", line 217, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\n'C:/Program' is not recognized as an internal or external command,\r\noperable program or batch file.\r\nWARNING: Target pattern parsing failed.\r\n**ERROR: no such package '@local_config_cuda//cuda':** Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1400\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1075, in _create_local_cuda_repository\r\n                _find_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 606, in _find_libs\r\n                _check_cuda_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 501, in _check_cuda_libs\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"C:/tensorflow/third_party/remote_config/common.bzl\", line 217, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\n**'C:/Program' is not recognized as an internal or external command,\r\noperable program or batch file.**\r\nINFO: Elapsed time: 2.304s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n\r\n\r\n**FIRST PART OF THE LOG**\r\n\r\nC:\\tensorflow>**bazel build //tensorflow/tools/pip_package:build_pip_package**\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Program Files/Python38/python.exe\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Program Files/Python38/python.exe --action_env PYTHON_LIB_PATH=C:/Program Files/Python38/lib/site-packages --python_path=C:/Program Files/Python38/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.0 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file c:\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file c:\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:windows in file c:\\tensorflow\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository local_config_cuda instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule cuda_configure defined at:\r\n  C:/tensorflow/third_party/gpus/cuda_configure.bzl:1430:18: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1400\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1075, in _create_local_cuda_repository\r\n                _find_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 606, in _find_libs\r\n                _check_cuda_libs(repository_ctx, <2 more arguments>)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 501, in _check_cuda_libs\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"C:/tensorflow/third_party/remote_config/common.bzl\", line 217, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\n'C:/Program' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n**OR** with\r\n\r\nC:\\tensorflow>**bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package**\r\nWARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Program Files/Python38/python.exe\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Program Files/Python38/python.exe --action_env PYTHON_LIB_PATH=C:/Program Files/Python38/lib/site-packages --python_path=C:/Program Files/Python38/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.0 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file c:\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file c:\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:opt in file c:\\tensorflow\\.tf_configure.bazelrc: --copt=/arch:AVX --host_copt=/arch:AVX --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:windows in file c:\\tensorflow\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository local_config_cuda instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule cuda_configure defined at:\r\n  C:/tensorflow/third_party/gpus/cuda_configure.bzl:1430:18: in <toplevel>", "comments": ["@ctrouillefou \r\nCould you please try : ```sudo apt-get purge bazel``` followed by installation of binaries and let us know.\r\nYou may also refer to:l[ink](https://github.com/tensorflow/tensorflow/issues/11859), #47042 , [link](https://stackoverflow.com/questions/64650756/bazel-build-error-with-cuda-on-windows-10-how-resolve-it)", "Hi,\r\nI can not do \"sudo apt-get purge bazel\" on Win10; but I installed bazel 4.1.0 and obtained the same result.\r\nThe 3 links provided didn't help to solve the problem.", "Any idea of what is the problem ?", "@ctrouillefou,\r\nTry changing Python file path\r\n`\r\npython_path=C:/Program Files/Python3/python.exe -> this to C:/Python3/python.exe`\r\nCheck msys64 is  `C:\\msys64\\usr\\bin` mast be present in your PATH variable.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50414\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50414\">No</a>\n"]}, {"number": 50413, "title": "Image transformations require Scipy but Scipy already installed", "body": "Hello, I\u2019m running Tensorflow 2.4.1 on a Windows 10 computer (system info below). I\u2019m having problems trying to launch a CNN model using the ImageDataGenerator feeding from a Pandas dataframe. After defining the data generator and the model, I get the following error when running model.fit: **Image transformations require SciPy. Install SciPy.** However, when I can confirm that Scipy is installed by running \u201cimport scipy\u201d without errors.\r\n\r\nImage generator is defined as follows:\r\n`\r\ntrain_datagen = ImageDataGenerator(horizontal_flip=False,\r\n                                   vertical_flip=False,\r\n                                   rescale=1/255.0).flow_from_dataframe(dataframe=X,\r\n                                                                        x_col='image_name',\r\n                                                                        y_col='response',\r\n                                                                        shuffle=False, \r\n                                                                        directory=src_path,\r\n                                                                        target_size=(128, 128),\r\n                                                                        class_mode=None\r\n                                                                       )\r\n`\r\nThe error occurs when running:\r\n`\r\nmodel.fit(train_datagen, epochs=5)\r\n`\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: 11.3/ 8.2.1\r\n- GPU model and memory: NVIDIA GeForce RTX 2060", "comments": ["PS. I believe the error results from my GPU configuration. I am running a CPU version of the code and training is running (although extremely slow). I had to change my imagegenerator declaration to:\r\n`\r\nclass_mode='raw',\r\n`\r\nas I am running a regression model.", "@hernandezurbina   Please let is know if you are still facing the issue on GPU. Thanks!", "@saikumarchalla On GPU yes. On CPU not.", "@hernandezurbina  If possible could you please create a simple reproducible code/colab with the dataset you are using and share with us. Thanks!", "@saikumarchalla Dataset is huge (thus, the need to use a image generator) so I am not sure if I can create a colab notebook to reproduce the error. The code that I am running is the following:\r\n\r\n`\r\nif tf.test.gpu_device_name():\r\n    print('Default GPU device: {}'.format(tf.test.gpu_device_name()))\r\nelse:\r\n    print('You need to install GPU version of TF') \r\n#returns Default GPU device: /device:GPU:0\r\n\r\nX = pd.read_csv('temp_cnn_gpu_data.csv')\r\nX.head()\r\n\r\ndef createCNN():\r\n    model = Sequential()\r\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)))\r\n    model.add(layers.MaxPooling2D((2, 2)))\r\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n    model.add(layers.Flatten())\r\n    model.add(layers.Dense(64, activation='relu'))\r\n    model.add(layers.Dense(1))\r\n    \r\n    optimizer = tf.keras.optimizers.RMSprop(0.001)\r\n    \r\n    model.compile(optimizer=optimizer,\r\n                  loss='mse',\r\n                  metrics=['mae', 'mse'])\r\n\r\n    return model\r\n\r\nsrc_path = 'Data - SetA_Final/'\r\n\r\ntrain_datagen = ImageDataGenerator(horizontal_flip=False,\r\n                                   vertical_flip=False,\r\n                                   rescale=1/255.0).flow_from_dataframe(dataframe=X,\r\n                                                                        x_col='image_name',\r\n                                                                        y_col='response_valence',\r\n                                                                        shuffle=False, \r\n                                                                        directory=src_path,\r\n                                                                        target_size=(128, 128),\r\n                                                                        class_mode='raw',\r\n                                                                        batch_size=32\r\n                                                                       )\r\n#returns Found 455190 validated image filenames.\r\n\r\nmodel = createCNN()\r\nhistory = model.fit(train_datagen, epochs=2)\r\n`\r\n\r\nNow, the error that I am getting today is different than in the previous time. Now, I get a \"Epoch 1/2\" but then after a few seconds I get a notification from jupyter that the notebook has died and will restart. No other messages appear in the notebook.\r\nThanks!\r\n", "@saikumarchalla All sorted now. I look it up elsewhere and it seems that I was running out of memory when running the code in jupyter. Changed everything to a script and it's running fine. :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50413\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50413\">No</a>\n", "@hernandezurbina Glad to hear that the issue is resolved for you."]}, {"number": 50412, "title": "Tensorflow build is failing on Bazel@HEAD (Bazel CI)", "body": "rules_apple need to be upgraded to the latest version 0.31.2\r\n\r\n**System information**\r\nLink to failed build:\r\nhttps://buildkite.com/bazel/bazel-at-head-plus-downstream/builds/2077#409bdb15-84cf-45b2-8fcc-7aeb2dc56c1e\r\n\r\n**Describe the problem**\r\n2021-05-03 apple_common.objc_proto_aspect was removed from Bazel (https://github.com/bazelbuild/bazel/commit/d6830672311d54c8072e0b48c440c2edde65314d)\r\n\r\nThe problem was only detected in today's build, because it was obscured by other breakages.\r\n\r\n**Fix**\r\nrules_apple need to be upgraded to the latest version 0.31.2 (which doesn't call that function)\r\n\r\n/cc @allevato", "comments": ["Sorry, I see this issue was already reported and there was an attempt to fix in  https://github.com/tensorflow/tensorflow/pull/49040", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50412\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50412\">No</a>\n"]}, {"number": 50411, "title": "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8 model showing error on Tensorflow 2.5", "body": "I am using python3.8 and Tensorflow 2.5.  I am trying to use faster_rcnn_resnet101_v1_640x640_coco17_tpu-8 model to do object detection but it is showing me following error\r\nI0623 11:55:46.608306  5796 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nTraceback (most recent call last):\r\n  File \"Tensorflow\\models\\research\\object_detection\\model_main_tf2.py\", line 113, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"C:\\Users\\priyabrata\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\absl\\app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"Tensorflow\\models\\research\\object_detection\\model_main_tf2.py\", line 104, in main\r\n    model_lib_v2.train_loop(\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\model_lib_v2.py\", line 535, in train_loop\r\n    detection_model = MODEL_BUILD_UTIL_MAP['detection_model_fn_base'](\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\model_builder.py\", line 1199, in build\r\n    return build_func(getattr(model_config, meta_architecture), is_training,\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\model_builder.py\", line 391, in _build_ssd_model\r\n    _check_feature_extractor_exists(ssd_config.feature_extractor.type)\r\n  File \"C:\\Users\\priyabrata\\anaconda3\\envs\\new_tfod_env\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\model_builder.py\", line 263, in _check_feature_extractor_exists\r\n    raise ValueError('{} is not supported. See `model_builder.py` for features '\r\nValueError:  is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\r\n", "comments": ["@Priyabrata409 ,\r\n\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50411\">No</a>\n"]}, {"number": 50410, "title": "[ROCm] Updating ROCm implementation for the GpuVersion type in XLA", "body": "porting the changes by @ekuznetsov139 in the ROCm TF fork.\r\n\r\n-----------------------------\r\n\r\n/cc @cheshire @chsigg", "comments": ["Seems auto-merge is not happening but the changes are now committed, so we can close this. Thank you for the PR."]}, {"number": 50409, "title": "[ROCm] Enable unique op on the ROCm platform.", "body": "porting the implementation by @ekuznetsov139 in the ROCm TF fork.\r\n\r\n\r\n----------------------------------------\r\n\r\n\r\n/cc @cheshire @chsigg ", "comments": ["The failure in `Linux GPU` does not seem to be related to the changes in this PR\r\n\r\nerror from `Linux GPU` log \r\n```\r\ntensorflow/core/kernels/cwise_op_mod.cc: In member function 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorCwiseBinaryOp<Eigen::internal::safe_div_or_mod_op<long int, Eigen::internal::scalar_mod2_op<long int> >, const Eigen::TensorBroadcastingOp<const Eigen::array<long int, 4>, const Eigen::TensorMap<Eigen::Tensor<const long int, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::TensorBroadcastingOp<const Eigen::array<long int, 4>, const Eigen::TensorMap<Eigen::Tensor<const long int, 4, 1, long int>, 16, Eigen::MakePointer> > >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<long int, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::ThreadPoolDevice]':\r\ntensorflow/core/kernels/cwise_op_mod.cc:43:1: internal compiler error: Illegal instruction\r\n }  // namespace tensorflow\r\n ^\r\n0xb019af crash_signal\r\n\t/dt7-src/gcc/toplev.c:340\r\n0xb6c08a op_iter_init\r\n\t/dt7-src/gcc/ssa-iterators.h:601\r\n0xb6c08a op_iter_init_tree\r\n\t/dt7-src/gcc/ssa-iterators.h:661\r\n0xb6c08a mark_def_sites\r\n\t/dt7-src/gcc/tree-into-ssa.c:681\r\n0xb6c08a mark_def_dom_walker::before_dom_children(basic_block_def*)\r\n\t/dt7-src/gcc/tree-into-ssa.c:2340\r\n0x110a5aa dom_walker::walk(basic_block_def*)\r\n\t/dt7-src/gcc/domwalk.c:265\r\n0xb7185d execute\r\n\t/dt7-src/gcc/tree-into-ssa.c:2452\r\n```", "@deven-amd somehow we see those ICEs all the time now, usually it passes after a few runs. Not sure where are they coming from sadly.", "@gbaned gentle ping. this PR seems to have gotten stuck in the merge pipeline", "@gbaned ... this PR seems to have gotten merged and then rolled-back (without the \"rolling back\" comment that typically accompanies such rollbacks)....any idea what is happening here?", "It broke Windows.\r\n\r\nSorry we are really struggling maintaining the MSVC build. The error messages we get are usually really cryptic. This time we got:\r\n\r\n```\r\n.\\tensorflow/core/kernels/unique_op_gpu.cu.h(463): fatal error C1070: mismatched #if/#endif pair in file 'T:\\tmp\\nsz6drem\\execroot\\org_tensorflow\\tensorflow\\core\\kernels\\unique_op_gpu.cu.h'\r\n\r\n```", "@cheshire :(\r\n\r\nThe line number in the error message is pointing to the end of the file, so that is not very helpful.\r\n\r\nIf we look at the changes in that file ( `.\\tensorflow/core/kernels/unique_op_gpu.cu.h` ), \r\n* the [first one]( https://github.com/tensorflow/tensorflow/pull/50409/files#diff-1fafec84a77aafd71aae71878e5b751b9671c8bdf60632eb2c5a8cfd48a82846R19 ) has many similar instances throughout the TF codebase, so doubt that is triggering the error\r\n* the other two ( [this one](https://github.com/tensorflow/tensorflow/pull/50409/files#diff-1fafec84a77aafd71aae71878e5b751b9671c8bdf60632eb2c5a8cfd48a82846R335-R339) , and [this one](https://github.com/tensorflow/tensorflow/pull/50409/files#diff-1fafec84a77aafd71aae71878e5b751b9671c8bdf60632eb2c5a8cfd48a82846R384-R390) ), both introduce \"#if\"s that are contained within a statement, and one or both of them are most likely causing the error.\r\n\r\nCan I push out a commit  that essentially makes those two \"#if\"s contain full statements, and we can test out whether that change fixes the error? Would it be better to do that in this PR...or abandon this one and file a new one?"]}, {"number": 50408, "title": "Extend the algorithm selector to consider a list of allowed and disallowed tactics", "body": "This PR extends the StaticAlgorithmSelector to keep a list of allowed tactics and a list of disallowed tactics. The list of allowed tactics is used to implemented the existing mechanism of selecting one tactics through environment variable TF_TRT_FIXED_ALGORITHM_ID. The list of disallowed tactics is currently used to exclude the known bad tactics in TensorRT version 7.x.\r\n\r\nThis PR also excludes any tactics that implement SHUFFLE layer for CHW32 format in TensorRT 7.\r\n\r\nTagging Bixia @Bixia1, @DEKHTIARJonathan, and Tamas @tfeher for visibility.", "comments": ["let's change the title of this PR from \"Add Algorithm rejector to reject known bad tactics\" to \"Extend the algorithm selector to consider a list of allowed and disallowed tactics.\"\r\n\r\nlet's also change the PR description from \"This PR adds a Flaky Algorithm Rejector class to reject bad known tactics. Current rejection logic is for known bad tactics for TensorRT versions before 8.0.\" to this:\r\n\r\nThis PR extends the StaticAlgorithmSelector to keep a list of allowed tactics and a list of disallowed tactics. The list of allowed tactics is used to implemented the existing mechanism of selecting one tactics through environment variable TF_TRT_FIXED_ALGORITHM_ID. The list of disallowed tactics is currently used to exclude the known bad tactics in TensorRT version 7.x.\r\n\r\nThis PR also excludes any tactics that implement SHUFFLE layer for CHW32 format in TensorRT 7.\r\n", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50408) for more info**.\n\n<!-- need_author_consent -->", "After applying this change:\r\n\r\n1) Rejecting disallowed tactic\r\n`2021-06-23 19:45:19.486270: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1639] Rejecting a disallowed tactic: 0 for node /my_shuffle-shuffle_0:SHUFFLE with implementation 16 and input format 5\r\n2021-06-23 19:45:19.486300: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1639] Rejecting a disallowed tactic: 1 for node /my_shuffle-shuffle_0:SHUFFLE with implementation 16 and input format 5\r\n2021-06-23 19:45:19.504057: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1639] Rejecting a disallowed tactic: 0 for node /my_shuffle-shuffle_1:SHUFFLE with implementation 16 and input format 5\r\n2021-06-23 19:45:19.504081: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1639] Rejecting a disallowed tactic: 1 for node /my_shuffle-shuffle_1:SHUFFLE with implementation 16 and input format 5`\r\n\r\n2) Forcing a single allowed tactic by setting env variable `TF_TRT_FIXED_ALGORITHM_ID`\r\n`2021-06-23 20:05:13.088821: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1652] Forcing TRT algorithm selection to: ID=0\r\n2021-06-23 20:05:13.106577: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1652] Forcing TRT algorithm selection to: ID=0`\r\n\r\n3) Sanity check for disjoint allowed and disallowed tactics\r\n`2021-06-23 20:11:55.478857: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1583] Intersection of allowed and disallowed tactics found be non-empty.\r\n2021-06-23 20:11:55.478860: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1585] List of allowed tactcis:\r\n2021-06-23 20:11:55.478863: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1587] -959009792490796596,\r\n2021-06-23 20:11:55.478866: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1589] List of disallowed tactcis:\r\n2021-06-23 20:11:55.478869: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1591] -959009792490796596,\r\n2021-06-23 20:11:55.478871: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1591] -3848538574386518527,\r\n2021-06-23 20:11:55.478874: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1591] -5927686925093575778,\r\n2021-06-23 20:11:55.478876: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1593] List of tactics common to both allowed and disallowed tactics:\r\n2021-06-23 20:11:55.478879: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1596] -959009792490796596,\r\n2021-06-23 20:11:55.478882: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1598] Aborting.`", "Can you please respond to the comments by replying to it, here is an example, but there could be more:\r\nhttps://github.com/tensorflow/tensorflow/pull/50408#issuecomment-866998130\r\n", "@bixia1 I fixed all your comments but one. If you can give it a look to clear that everything except this comment is good: https://github.com/tensorflow/tensorflow/pull/50408#discussion_r657491034\r\n\r\nCC: @jhalakp-nvidia for the last comment ", "@xbeatzsec I had to push again to fix a typo. If you can re-give it a look. Thanks ;)", "@bixia1 could you give the failing tests ?\r\n\r\nSo far with TRT 7.2.3.4 I can't reproduce, I'm compiling with TRT 7.1.3 right now.\r\n\r\n```\r\nINFO: Elapsed time: 65.278s, Critical Path: 50.45s                                                                                                                                                 [1369/8433]\r\nINFO: 220 processes: 90 internal, 130 local.\r\nINFO: Build completed successfully, 220 total actions\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test                   PASSED in 35.8s\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test_gpu               PASSED in 34.6s\r\n\r\nINFO: Build completed successfully, 220 total actions\r\nroot@Jonathan-NVWS:/opt/tensorflow/tensorflow-source# ./run_tftrt_py_unittests.sh \r\nRunning ./tensorflow/python/compiler/tensorrt/test/annotate_max_batch_sizes_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/base_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/batch_matmul_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/biasadd_matmul_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/binary_tensor_weight_broadcast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/cast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/combined_nms_test.py ... [FAILURE]   # ** Known different issue, unrelated **\r\nRunning ./tensorflow/python/compiler/tensorrt/test/concatenation_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/const_broadcast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/conv2d_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/dynamic_input_shapes_test.py ... [IGNORED]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/identity_output_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/int32_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/lru_cache_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/memory_alignment_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/multi_connection_neighbor_engine_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/neighboring_engine_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/quantization_mnist_test.py ... [IGNORED]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/quantization_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/rank_two_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/reshape_transpose_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/tf_function_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/topk_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/trt_mode_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/unary_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/vgg_block_nchw_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/vgg_block_test.py ... [SUCCESS]\r\n1 / 25 tests FAILED\r\n```\r\n", "Impossible to reproduce with TRT 7.1.3:\r\n\r\n```bash\r\nINFO: Build completed successfully, 3 total actions\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test                   PASSED in 25.7s\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test_gpu               PASSED in 25.9s\r\n\r\nRunning ./tensorflow/python/compiler/tensorrt/test/annotate_max_batch_sizes_test.py ... [SUCCESS].\r\nRunning ./tensorflow/python/compiler/tensorrt/test/base_test.py ... [FAILURE]  # ** known cuDNN error  **\r\nRunning ./tensorflow/python/compiler/tensorrt/test/batch_matmul_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/biasadd_matmul_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/binary_tensor_weight_broadcast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/cast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/combined_nms_test.py ... [FAILURE]   # ** Known different issue, unrelated **\r\nRunning ./tensorflow/python/compiler/tensorrt/test/concatenation_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/const_broadcast_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/conv2d_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/dynamic_input_shapes_test.py ... [IGNORED]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/identity_output_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/int32_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/lru_cache_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/memory_alignment_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/multi_connection_neighbor_engine_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/neighboring_engine_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/quantization_mnist_test.py ... [IGNORED]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/quantization_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/rank_two_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/reshape_transpose_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/tf_function_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/topk_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/trt_mode_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/unary_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/vgg_block_nchw_test.py ... [SUCCESS]\r\nRunning ./tensorflow/python/compiler/tensorrt/test/vgg_block_test.py ... [SUCCESS]\r\n2 / 25 tests FAILED\r\n```\r\n\r\n@bixia1 I'm gonna need additional information to debug this, impossible to reproduce", "I can reproduce the problem by running base_test.py subtest ConstDataInputMultipleEnginesTest.testTfTrt_OfflineConversion_DynamicEngine_INT8_UseCalibration.\r\n\r\nI can even reproduce the problem by making selectionAlgorithm to NOT filter anything, that is:\r\n```\r\n  int32_t selectAlgorithms(const nvinfer1::IAlgorithmContext& algoContext,\r\n                           const nvinfer1::IAlgorithm* const* algoChoices,\r\n                           int32_t nbChoices, int32_t* selection) override {\r\n    for (int i = 0; i < nbChoices; i++) {\r\n      selection[i] = i;\r\n    }\r\n    return nbChoices;\r\n}\r\n```\r\nSo I tend to believe that the NVIDIA binaries somewhere have a bug, the PR here itself doesn't seem to do anything wrong to me.\r\n\r\nMy test env, as you can also see in the full log I will attach here:\r\nTITAN V computeCapability: 7.0\r\nTensorFlow compiled with CUDA 11.3 and cuDNN 8.2.1\r\n\r\nAlso, if you can't reproduce it straightforwardly, don't forget the fact that we use STATIC TensorRT libs.\r\n", "[tt.log](https://github.com/tensorflow/tensorflow/files/6717437/tt.log)\r\n", "Investigating, will update ASAP", "@jhalakp-nvidia  Can you please check @bixia1's comments and keep us posted ? Thanks!", "@jhalakp-nvidia  Any update on this PR? Please. Thanks!\r\n", "@jhalakp-nvidia Any update on this PR? Please. Thanks!", "Please do not close.\r\n@jhalakp-nvidia  could you check Bixia's comment\r\n", "@bixia1 Addressed requested change. Please let me know if any more changes are required. Thanks a lot for reviewing this."]}, {"number": 50406, "title": "Tensorflow shuffle leak memory", "body": "My tensorflow pipeline use shuffle and it always end up with OOM. I try to follow solution at https://github.com/tensorflow/tensorflow/issues/44176 but it did not work for me. My tensorflow version is 2.3.0. ANyone know how to fix this?", "comments": ["@Yurushia1998  Could you please provide the simple standalone code/ colab link to reproduce the issue at our end.Also, Please test in TF 2.5 Version as well and let us know.", "> @Yurushia1998 Could you please provide the simple standalone code/ colab link to reproduce the issue at our end.Also, Please test in TF 2.5 Version as well and let us know.\r\n\r\nHi saikumarchlla, it's a bit hard to provide the full code since it's our ongoing project.\r\nBelow is what my input pipeline looks like:\r\ntrain_holder,label_holder = tf.placeholder(tf.float32, [None, 32, 32, 3],name = \u201ctrain_holder\u201d), tf.placeholder(tf.int32, [None],name = \u201clabel_holder\u201d)\r\ninput_tuple = (self.train_holder, self.label_holder)\r\nds = tf.data.Dataset.from_tensor_slices(data)\r\nmap_fn = lambda x, y: (cifar_process(x, is_train), y)\r\ntrain_dataflow = ds.map(map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n\r\ntrain_ds = train_dataflow.repeat().batch(\r\nself.batch_size, drop_remainder=True\r\n).map(\r\nautoaug_batch_process_map_fn,\r\nnum_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\r\nbuffer_size=tf.data.experimental.AUTOTUNE)\r\ntrain_input_iterator = (\r\nself.strategy.experimental_distribute_dataset(\r\ntrain_ds).make_initializable_iterator())\r\n\r\nEach time I reinitialize this pipeline with new input by feedict:\r\nself.sess.run([train_input_iterator.initializer],feed_dict = \u2026)\r\n\r\n\r\nMy dataset is has shape (5000,32,32,3), feeded to train_holder, label is a list of shape (50000,)\r\nI need to run self.sess.run([train_input_iterator.initializer],feed_dict = \u2026) many times during training,\r\nSometimes the memory increase rapidly and I get OOM at this exact step, so I know it's wrong there. This happen only sometimes, and not on my local machine, but when I use a remote cluster with GPU\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@Yurushia1998 Are you using TF1.x or TF2.x. I am asking it because you are using `tf.placeholder` (which is TF1.x) and mentioned above that you are using `TF2.3` (which is TF2.x). Please note that we are not supporting `TF1.x` anymore.\r\n\r\nIf you are using TF2.x, can you please try with any open source data or use random data from numpy to show the issue? Also, there were some memory issues with `TF2.3` and `TF2.4` that got resolved in `TF2.5` and `tf-nightly`. If possible use recent TF version and share a standalone code to reproduce the issue. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50405, "title": "How to remove custom signature of savedmodel and re-export the model", "body": "Hello,\r\n\r\nI currently have a saved model, it is using a custom signature, but it needs to have serving_default signature def, so it should look like this: \r\n`signature_def['serving_default'].`\r\n\r\nIf I do saved_model_cli show it currently shows\r\n\r\n```\r\nsignature_def['image_quality']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['input_image'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 224, 224, 3)\r\n        name: input_1:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['quality_prediction'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: dense_1/Softmax:0\r\n  Method name is: tensorflow/serving/predict\r\n```\r\nIs there a way to remove the custom name and re-export the model in tensorflow v2 in order to have the serving_default signature?\r\n", "comments": ["@haylie-murray \r\nCould you please refer [this](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=2ujwmMQg7OUo) and let us know if  it  helps.Thanks", "@UsharaniPagadala \r\n\r\nI was looking at this document, and it is sort of like that. Except instead of creating a custom model, I was hoping to learn how to revert the custom model back to default signatures. Do you know how to read in the custom model, and then re-export the model to default? ", "Would it be something like:\r\n\r\nread in the custom model\r\n`custom_mod = tf.saved_model.load(path_to_custom_model)`\r\n\r\nset the signatures to default\r\n`signatures = {\"serving_default\": ['serving_default']}`\r\n\r\nSave the new model that has default signatures\r\n`tf.saved_model.save(new_model, module_output_path ,signatures=signatures)`\r\n\r\nI am looking for something like this. Or if it is possible to revert? \r\nI would like to try to remove the custom name of the signature definition of 'image_quality' and change it to 'serving_default'\r\n", "@haylie-murray \r\n\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) or TF [Forum](https://discuss.tensorflow.org/).There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks\r\n", "I posted the question here as well: https://stackoverflow.com/questions/68086885/tf2-how-to-remove-custom-signature-of-savedmodel-and-re-exporting-the-model ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@haylie-murray \r\nPlease follow [this guide](https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export), as this is not a bug or feature request kindly move this to closed status.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50404, "title": "Update Template", "body": "Update template to include discourse link", "comments": []}, {"number": 50403, "title": "Issue in using tfio.experimental.filter.sobel in Keras model.fit with Colab TPU", "body": "Hello,\r\n\r\nI am training a GAN for image inpainting. I am computing the Sobel edges of my generator's output and giving them as an input to the discriminator. \r\n1. I am using tfio.experimental.filter.sobel function.\r\n2. I have also tried tf.image.sobel_edges but it is not compatible with TPU.\r\n2. I have defined this as a tf.keras.Model class and then doing the training using model.fit function.\r\n3. I am training this on Google Colab's TPU.\r\n\r\nWhenever, I give the sobel edges of the generator's output to the discriminator, the training loss goes to \"NaN\". I have checked that the computed sobel edges don't contain any NaN and my dataset also doesn't contain any NaN. If I don't give this sobel edges as an input to discriminator then the code works fine without leading to NaN.\r\n\r\nHas anyone faced any such similar situation before? Please let me know how can I debug it. If you have faced something similar then, please let me know the solution. Any help is appreciated. Thank you.", "comments": ["@vinits5 ,\r\n\r\nPlease refer this link for information on sobel images.[link1](https://www.tensorflow.org/api_docs/python/tf/image/sobel_edges),[link2](https://www.tensorflow.org/io/api_docs/python/tfio/experimental/filter/sobel).\r\nAlso,In order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50402, "title": "[TFLite] Add quantization support for SQUARED_DIFFERENCE using the MLIR-based quantizer", "body": "Hello,\r\n\r\nThe int8 quantization for the SQUARED_DIFFERENCE operator was added a couple of months ago in commit c7b8cbaf60871882b4310c42ef2656d17c5dd2cc and it's working fine with the old quantizer by setting `converter.experimental_new_quantizer = False`  but it isn't working with the new default MLIR-based quantizer as the operator has the `NoQuantizableResult` trait.\r\n\r\nThe PR just removes the `NoQuantizableResult` trait which is sufficient to make it works but I can eventually add some extra tests.\r\n\r\nThibaut", "comments": []}, {"number": 50399, "title": "Pip installation error ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 \r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 1.15 (but affects any version i try)\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip, in a venv\r\n\r\n\r\n**Describe the problem**\r\nTrying to Install TensorFlow using pip yields the following error, I'm specifically trying to install 1.15 but I've tried 2.x also and the same happens. I have checked similar issues and am definitely using 64bit python 3.6; I know not using the correct version of python can cause this error, but the error still persists. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n(venv) ubuntu@dde1f763d711:~$ pip install --user --upgrade tensorflow==1.15\r\nERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: none)\r\nERROR: No matching distribution found for tensorflow==1.15\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@connorb573 \r\nWe see that you are using a old version of tf that is not actively supported, please upgrade to tf 2.x and let us know.\r\nAlso verify the system requirements, your OS and python is 64 bits, check you[ pip version and upgrade it and try.](https://github.com/tensorflow/tensorflow/issues/47151#issuecomment-778939251)\r\nAlso try :\r\n```$ sudo pip3 install setuptools --upgrade```", "Hi @Saduf2019 as I said, if I attempt to install 2.x the same issue occurs. OS and Python are both 64 bits, and pip is 21.1.2, python is 3.6.9. \r\n\r\nAlso tried the command given in your comment and this makes no change. \r\n\r\nThanks. ", "@connorb573 \r\nCould you please try the virtual env and let us know if it still an issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50399\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50399\">No</a>\n"]}, {"number": 50398, "title": "TypeError: An op outside of the function building code is being passed a \"Graph\" tensor.", "body": "Hi I got following error when including a customized DropConnectDense layer. The Error seems to be related to the update of  kernel and bias.  Any helps will be appreciated.  Thanks.\r\n\r\nTraceback (most recent call last):\r\n\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: MLRM_TFNN_DROPCONNECT/den2_1/dropout/Mul_1:0\r\n\r\nThe DropConnectDense class I have:\r\n```\r\nfrom tensorflow.python.ops import gen_math_ops\r\nfrom tensorflow.python.ops import nn_ops\r\n\r\nclass DropConnectDense(Dense):\r\n    def __init__(self, *args, **kwargs):\r\n        self.rate = kwargs.pop('rate', 0.5)\r\n        if 0. < self.rate < 1.:\r\n            self.uses_learning_phase = True\r\n\r\n        super(DropConnectDense, self).__init__(*args, **kwargs)\r\n\r\n    def call(self, inputs):\r\n\r\n        if 0. < self.rate < 1.:\r\n            kernel = K.in_train_phase(nn_ops.dropout(self.kernel, rate = self.rate), self.kernel)\r\n            bias = K.in_train_phase(nn_ops.dropout(self.bias, rate = self.rate), self.bias)\r\n        else:\r\n            kernel = self.kernel\r\n            bias = self.bias\r\n            self.kernel = kernel\r\n            self.bias = bias\r\n\r\n        outputs = gen_math_ops.MatMul(a = inputs, b = kernel)\r\n        if self.use_bias:\r\n          outputs = nn_ops.bias_add(outputs, bias)\r\n\r\n        if self.activation is not None:\r\n          outputs = self.activation(outputs)\r\n        return outputs\r\n\r\n\r\n    def get_config(self):\r\n        config = super(DropConnectDense, self).get_config()\r\n        config.update({\r\n            'rate': self.rate,\r\n            'uses_learning_phase': self.uses_learning_phase,\r\n        })\r\n\r\n        return config\r\n```\r\n\r\n", "comments": ["Could you please fill the issue template.Also Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "Looks like I can get it worked with \r\n`            tf.compat.v1.disable_eager_execution()\r\n`\r\nbefore the model is built.", "@ckhuangf  Could you please go ahead and close the issue if you don't have any further queries. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "I had the same issue. How did you rectify this?"]}, {"number": 50397, "title": "Crash in Backward-Pass of grouped Conv1D", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\nBackward-Pass of grouped Convolution (Conv1D) crashes:\r\n```\r\nInvalidArgumentError:  filter_size does not have enough elements, requested 896, got 224\r\n\t [[node gradient_tape/sequential/conv1d/conv1d/Conv2DBackpropFilter (defined at <ipython-input-6-c99a994f0883>:1) ]] [Op:__inference_train_function_898]\r\n```\r\n\r\nForward-Pass (simple call) works.\r\n\r\nCode is available at Colab:\r\n\r\nhttps://colab.research.google.com/drive/1yyxtQCeM81cEUAVA6_z1PdtEY2P5kZ2C?usp=sharing", "comments": ["Possibly related to https://github.com/tensorflow/tensorflow/issues/49147, and https://github.com/tensorflow/tensorflow/issues/41107", "@ChWick \r\n\r\n`groups` controls the connections between inputs and outputs. `in_channels` and `out_channels` must both be divisible by `groups` \r\n For example,\r\n\r\n1. At groups=1, all inputs are convolved to all outputs.\r\n\r\n2. At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.\r\n\r\n3. At groups= `in_channels`, each input channel is convolved with its own set of filters (of size(out_channels/in_channels)\r\n\r\nThanks\r\n\r\n", "As you can see in my example code: `in_channels==out_channels==groups==4` (case 3 from your list).\r\n\r\nNote, that the Forward-pass (normal call during prediction) is working properly (see code):\r\n```\r\nprint(model(np.zeros((1, 28, 28))))\r\n```\r\n\r\nThe error occurs during training only (`model.fit`). This is probably related to computing the correct gradients when using groups > 1.", "@Saduf2019 \r\n\r\nI was able to replicate the issue reported .Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/146e4503c0b2167a4f9cb350b3e58d2b/untitled0.ipynb) here.Thanks", "@ChWick \r\nCan you please refer to [this link](https://stackoverflow.com/questions/66415623/group-convolution-in-keras).", "The link has nothing to do with the reported issue. In the link there is a problem, that the grouped convolution operation was not present at all for the CPU in the former 2.4.1 version of tensorflow.\r\nI am using Tensorflow 2.5.x, and the CPU operation exists now. However, I am only able to use grouped convolutions in the forward pass, but (probably) not the backward pass (computing gradients).\\\r\nIn the provided gits, you can see that `model(inputs)`, i. e. `model.predcit(inputs)` is working with the grouped convolution, however `model.fit` crashes with an error message:  `gradient_tape/sequential/conv1d/conv1d/Conv2DBackpropFilter`. Due to `gradient_tape` and `Conv2DBackpropFilter` I assume that this should be related to the gradiet computation and the backward pass.", "Cross posting this issue to stand alone keras-team/keras repo for further investigation. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50397\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50397\">No</a>\n"]}, {"number": 50396, "title": "TFlite shape", "body": "hello\uff0c\r\nComputer environment:window 10 ;tensorflow 1.13.0; python3.6 ; tflite-runtime  2.1.0.post1; \r\nsave tflite code\r\n    **_def save(self):\r\n        converter = tf.lite.TFLiteConverter.from_session(self.session, [self.ts.x, self.ts.x_peak], [self.ts.logits])\r\n        tflite_model = converter.convert()\r\n        with open(\"model/\" + cfg.name + '/model.tflite', \"wb\") as f:\r\n            f.write(tflite_model)\r\n        print('model is in {}'.format(self.save_path))_**\r\nwhen I set the  the x ( input model) shape is [10, 1801, 2], it product tflite is right ,and   in the tflite input_details is [10, 1801, 2],however, I need the shape is [1, 1801, 2];So, when I set the x shape is [None, 1801, 2] ; but when I train the model, it is error that as follows\r\n**_Traceback (most recent call last):\r\n  File \"C:/Users/Administrator/Desktop/mix/train.py\", line 400, in <module>\r\n    app.train(train_data, val_data)\r\n  File \"C:/Users/Administrator/Desktop/mix/train.py\", line 265, in train\r\n    ts.train_summary, ts.loss_summary], feed)\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\r\n    str(subfeed_t.get_shape())))\r\nValueError: Cannot feed value of shape (10, 1801, 2) for Tensor 'self.x:0', which has shape '(1, 1801, 2)'_**\r\n\r\nI know the reason is that producting tflite cause x that change it's shape \uff1bbut I don't know how to solve it ;I sincerely hope you can understand my poor English\uff01Thanks\uff01\uff01\uff01\r\n", "comments": ["@xzy-666 ,\r\n\r\nCan you please, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Also, We see that you are using tf version 1.x which is not actively supported, please update to 2.x and in order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "+1 to the idea of upgrading to TensorFlow 2.x. TensorFlow Lite in TensorFlow 2.x should have good support of dynamic shape. \r\n\r\nOn the other hand, it seems you're running to some shape issues in your training script, which is not directly relevant to TensorFlow Lite. It's hard to help you without knowing what's the actually code you're running. ", "\r\n\r\n\r\n\r\n\r\n> +1 to the idea of upgrading to TensorFlow 2.x. TensorFlow Lite in TensorFlow 2.x should have good support of dynamic shape.\r\n> \r\n> On the other hand, it seems you're running to some shape issues in your training script, which is not directly relevant to TensorFlow Lite. It's hard to help you without knowing what's the actually code you're running.\r\n\r\nhello, miaout17, thanks\uff01\uff01\uff01\r\n The problem is that the tflite-runtime does not adapt well to tensorflow1.x .So, I've converted offline and saved it as tflite model . however, I want to know why TensorFlow 1.x not  good support of dynamic shape.", "@xzy-666 ,\r\n\r\nAs mentioned above tf v1.x is not actively supported, can you please try to execute the code in tf v2.x and let us know if you are facing same issue.Thanks!", "> @xzy-666 ,\r\n> \r\n> As mentioned above tf v1.x is not actively supported, can you please try to execute the code in tf v2.x and let us know if you are facing same issue.Thanks!\r\n\r\n@tilakrayal, hello\r\nShame to say, I'm not familiar with tensorflow 2.x. Can you provide some materials for learning tensorflow 2.0? I will master it as soon as possible.thanks!!!", "@xzy-666 ,\r\n\r\nPlease refer this tensorflow website which provides the information on tensorflow latest versions.[Link](https://www.tensorflow.org/lite/tutorials).\r\n\r\nPlease free free to move the issue to closed status as the issue has resolved.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50396\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50396\">No</a>\n"]}, {"number": 50395, "title": "Model.fit halts/freezes when using GPU in tensorflow-macos on M1", "body": "I'm not sure if this is the right place to report this but the Apple repo is marked archive and I'm not sure who is maintaining tensorflow-macos\r\n\r\n**System information**\r\n- I have a somewhat straightforward autoencoder which uses build in layers and models of tensorflow\r\n- macOS 12.0 Beta\r\n- TensorFlow installed from binary through MiniForge and conda:\r\n- TensorFlow-macos version 2.5.0 tensorflow-metal 0.1.1:\r\n- Python version: 3.9\r\n- GPU model and memory: M1 iMac 8 core\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running model.fit while using the GPU it will run fine for a random amount of iterations than suddenly stop and when looking at the activity monitor i can see that GPU% goes down to zero, also sometimes a sub-model of my autoencoder returns a tensor twice it's normal size (my assumption is that the cpu and gpu are conflicting and returning the same values so it results in a double tensor, although i have no idea if that is correct). The memory usage is very high and of course i only have 8gb of memory (which in general is way to little), but when running model.fit without the gpu the computer does just fine, although much slower, but it does not freeze up.\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is for the gpu to not freeze up and stop running.\r\n\r\n**Standalone code to reproduce the issue**\r\nI can provide all of my code if requested i think i have not tried a bare minimum but I'm assuming this is related to memory usage and gpu exhaustion, so i haven't bothered with testing it on a smaller case.\r\n\r\n**Other info / logs**\r\nI have run it with verbose=1 and it doesn't output differrently, the execution seems to just stop.\r\n\r\nI have tried limiting the memory usage of the GPU using:\r\ntensorflow.experimental.per_process_gpu_memory_fraction = 0.75\r\ntensorflow.experimental.per_process_memory_growth = True\r\n\r\nand have tried this with various memory values:\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n\r\nbut it has not worked. The only thing that works is disabling the GPU and that kind of defeats the purpose.", "comments": ["@siggi90  Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "The best i can do for now is post my entire code (full of commented out code and hardcoded file paths), i can possibly clean it up a bit and generalize it later.  As you can see if you look at the code i made it work by alternating between the CPU and GPU when training. I have yet to install the latest update to macOS 12 so i will have to see if that makes any difference.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\nimport os\r\nimport config\r\nimport random\r\nimport csv\r\nimport time\r\n\r\nfrom tensorflow.python.lib.io import _pywrap_record_io\r\n\r\n\"\"\"\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n   [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=128)])\r\n   \r\n#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\r\n\r\ntf.config.experimental.per_process_gpu_memory_fraction = 0.9\r\ntf.config.experimental.per_process_memory_growth = True\r\n\"\"\"\r\n\r\n#gpus = tf.config.experimental.list_physical_devices('CPU')\r\n\r\n#tf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n#   [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\r\n\r\n\r\nclass Autoencoder(tf.keras.Model):\r\n    \r\n    def __init__(self):\r\n        super(Autoencoder, self).__init__()\r\n        \"\"\"\r\n        self.encoder_a = tf.keras.Sequential([\r\n            tf.keras.layers.Input(shape=(448, 448, 1)),\r\n            #tf.keras.layers.Flatten(),\r\n            tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1, 2, 2, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 2, 2, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\"),\r\n            #tf.keras.layers.Dense(512, activation=\"sigmoid\")\r\n        ])\r\n        \r\n        self.encoder_b = tf.keras.Sequential([\r\n            #tf.keras.layers.Input(shape=(448, 448, 1)),\r\n            #input_shape=(),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 2, 2, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 2, 2, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1, 1, 1), padding=\"same\", activation=\"tanh\"),\r\n            tf.keras.layers.Dense(1024, activation=\"swish\"),\r\n            tf.keras.layers.Dense(512, activation=\"swish\"),\r\n            tf.keras.layers.Dense(256, activation=\"swish\")\r\n        ])\r\n        \"\"\"\r\n        self.encoder_a = tf.keras.Sequential([\r\n            #tf.keras.layers.InputLayer(input_shape=(1), batch_size=2),\r\n            #tf.keras.layers.Flatten(),\r\n            tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )),\r\n            #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\"),\r\n            #tf.keras.layers.Dense(512, activation=\"sigmoid\")\r\n        ])\r\n        \r\n        self.encoder_b = tf.keras.Sequential([\r\n            #tf.keras.layers.Input(shape=(448, 448, 1)),\r\n            #input_shape=(),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Dense(1024, activation=\"swish\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.04),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Dense(512, activation=\"swish\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.04),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                ),\r\n            ), #, activation=\"relu\"\r\n            tf.keras.layers.Dense(256, activation=\"swish\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.04),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                ),\r\n            ) #, activation=\"relu\" #swish?\r\n        ])\r\n        \r\n        self.decoder = tf.keras.Sequential([\r\n            #input_shape=(),\r\n            tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"tanh\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n            tf.keras.layers.Conv2DTranspose(filters=2, kernel_size=(3,3), strides=(1, 1), padding=\"same\", activation=\"sigmoid\",\r\n                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\r\n                bias_initializer=tf.keras.initializers.Constant(\r\n                    value=0.1\r\n                )\r\n            ),\r\n        ])\r\n        \r\n    def set_initial_values(self):\r\n        for layer in self.encoder_a.layers:\r\n            #print(np.layer.get_weights().shape)\r\n            print(\"layer weights\")\r\n            for weight in layer.get_weights():\r\n                print(weight)\r\n            #weights = tf.random.normal(shape=(), mean=0.1, stddev=0.1)\r\n            #layer.set_weights(weights)\r\n        \"\"\"\r\n        for layer in self.encoder_b.layers:\r\n            print(layer.get_weights().shape)\r\n            #weights = tf.random.normal(shape=(), mean=0.1, stddev=0.1)\r\n            #layer.set_weights(weights)\r\n            \r\n        for layer in self.decoder.layers:\r\n            print(layer.get_weights().shape)\r\n            #weights = tf.random.normal(shape=(), mean=0.1, stddev=0.1)\r\n            #layer.set_weights(weights)\r\n        \"\"\"\r\n    \r\n    def call(self, x):\r\n        encoded_a = self.encoder_a(x)\r\n        print(\"shape a\")\r\n        print(encoded_a.get_shape())\r\n        encoded_b = self.encoder_b(encoded_a)\r\n        print(\"shape b\")\r\n        print(encoded_b.get_shape())\r\n        #print(encoded_a.shape)\r\n        fusion = self.fusion(encoded_a, encoded_b)\r\n        print(fusion.get_shape())\r\n        decoded = self.decoder(fusion)\r\n        print(decoded.get_shape())\r\n        #decoded = tf.image.resize(decoded, [448, 448], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n        return decoded\r\n        \r\n    def fusion_alt(self, mid_features, global_features):\r\n        print(\"fusion shapes\")\r\n        print(global_features.get_shape())\r\n        print(mid_features.get_shape())\r\n        mid_features_shape = mid_features.get_shape().as_list()\r\n        mid_features_reshaped = tf.reshape(mid_features, [1, mid_features_shape[1]*mid_features_shape[2], 256])\r\n        fusion_level = []\r\n        for j in range(mid_features_reshaped.shape[0]):\r\n            for i in range(mid_features_reshaped.shape[1]):\r\n                see_mid = mid_features_reshaped[j, i, :]\r\n                see_mid_shape = see_mid.get_shape().as_list()\r\n                see_mid = tf.reshape(see_mid, [1, see_mid_shape[0]])\r\n                global_features_shape = global_features[j, :].get_shape().as_list()\r\n                see_global = tf.reshape(global_features[j, :], [1, global_features_shape[0]])\r\n                fusion = tf.concat([see_mid, see_global], 1)\r\n                fusion_level.append(fusion)\r\n        fusion_level = tf.stack(fusion_level, 1)\r\n        #fusion_level = tf.reshape(fusion_level, [config.BATCH_SIZE, 28, 28, 512])\r\n        #fusion_level = tf.reshape(fusion_level, [-1, 28, 28, 512])\r\n                \r\n        #fusion_level = tf.reshape(fusion_level, [4, 28, 28, 512])\r\n        #fusion_level = tf.reshape(fusion_level, [config.BATCH_SIZE, 28, 28, 2048])\r\n        fusion_level = tf.reshape(fusion_level, [1, mid_features_shape[1], mid_features_shape[2], 512])\r\n        return fusion_level\r\n    \r\n    def fusion(self, a, b):\r\n        \"\"\"\r\n        a_shape = a.get_shape().as_list()\r\n        print(a_shape)\r\n        shapes = [a_shape[1], a_shape[2]]\r\n        #for shape_value in a_shape:\r\n        #    if(shape_value != 512):\r\n        #        shapes.append(shape_value)\r\n        last_shape = (256/(shapes[0]*shapes[1]))\r\n        print(\"last shape\")\r\n        print(last_shape)\r\n        last_shape = int(last_shape)\r\n        tf.reshape(b, (shapes[0], shapes[1], last_shape))\r\n        #b.reshape(shapes[0], shapes[1], last_shape)\r\n        #return a, b\r\n        #self.fusion_layer = tf.keras.Sequential([\r\n        \"\"\"\r\n        return tf.keras.layers.Concatenate(axis=3)([a, b])\r\n        #])\r\n        #return self.fusion_layer\r\n        \r\n    \r\nclass DATA():\r\n    def __init__(self):\r\n        self.test = 0\r\n    \r\n    def write_tf_record(self, dirname):\r\n        self.dir_path = os.path.join(config.DATA_DIR, dirname)\r\n        filelist = os.listdir(self.dir_path)\r\n        filelist = self.listdir_nohidden(filelist)\r\n        random.shuffle(filelist)\r\n        record_file = '/Users/siggi/VideoColor/videocolor/DATASET/TV/TFRECORD/images.tfrecords'\r\n        with tf.io.TFRecordWriter(record_file) as writer:\r\n            for filename in filelist:\r\n                filename = os.path.join(dirname, filename)\r\n                print(filename)\r\n                img = cv2.imread(filename, 1)\r\n                #img = cv2.resize(img, (config.IMAGE_SIZE, config.IMAGE_SIZE))\r\n                labimg = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\r\n                gray_image = np.reshape(labimg[:,:,0], (config.IMAGE_SIZE, config.IMAGE_SIZE, 1))\r\n                color_image = labimg[:, :, 1:]\r\n                #example = tf.train.Example(\r\n                #   features=tf.train.Features(\r\n                #\r\n                #    )\r\n                #)\r\n                example_proto = {\r\n                    \"image_l\": self._float_feature(gray_image.flatten()),\r\n                    \"image_ab\": self._float_feature(color_image.flatten())\r\n                }\r\n                #print(example_proto)\r\n                #feature_description = {\r\n                    #\"image_name\": self._bytes_feature(img_file),\r\n                #    \"image_l\": tf.io.FixedLenFeature([], tf.float32),\r\n                #    \"image_ab\": tf.io.FixedLenFeature([], tf.float32),\r\n                    #\"image_embedding\": self._float32_list(img_embedding.flatten()),\r\n                #}\r\n                \r\n                example_proto = tf.train.Example(features=tf.train.Features(feature=example_proto))\r\n                writer.write(example_proto.SerializeToString())\r\n\r\n                #example = tf.io.parse_single_example(example_proto, feature_description)\r\n\r\n                #self.write(example.SerializeToString())\r\n                #image_string = open(filename, 'rb').read()\r\n                #tf_example = image_example(image_string, label)\r\n                #writer.write(example.SerializeToString())\r\n        \r\n            \r\n    def read_tf_record_init(self):\r\n        self.offset = 0\r\n        record_file = '/Users/siggi/VideoColor/videocolor/DATASET/TV/TFRECORD/images.tfrecords'\r\n        self.raw_data = _pywrap_record_io.RandomRecordReader(record_file)\r\n        \r\n    def index_tf_record(self):\r\n        self.read_tf_record_init()\r\n        with open('/Users/siggi/VideoColor/videocolor/DATASET/TV/TFRECORD/index.txt', 'w') as f:\r\n            do_loop = True\r\n            while(do_loop):\r\n                try:\r\n                    example, offset = self.raw_data.read(self.offset)\r\n                    self.offset = offset\r\n                    f.write(str(offset)+',')\r\n                except:\r\n                    print(\"end of file\")\r\n                    do_loop = False\r\n    \r\n    def read_indicies(self):\r\n        with open('/Users/siggi/VideoColor/videocolor/DATASET/TV/TFRECORD/index.txt', mode='r') as file:\r\n            csv_index = list(csv.reader(file))[0]\r\n            random.shuffle(csv_index)\r\n            self.csv_index = csv_index\r\n            self.csv_index_offset = 0\r\n            #print(csv_index)\r\n            return csv_index\r\n        \r\n    def get_random_images(self):\r\n        images = []\r\n        i = 0\r\n        while(i < 1):\r\n            index = i+self.csv_index_offset\r\n            offset = self.csv_index[index]\r\n            if(offset == ''):\r\n                index = i+self.csv_index_offset+1\r\n                offset = self.csv_index[index]\r\n            self.offset = int(offset)\r\n            images.append(self.read_tf_record_alt_2())\r\n            i = i + 1\r\n        self.csv_index_offset = self.csv_index_offset+1\r\n        return images\r\n        \r\n        \r\n        \r\n\r\n    def read_tf_record_alt_2(self):\r\n        feature_description = {\r\n            #\"image_name\": self._bytes_feature(img_file),\r\n            \"image_l\": tf.io.FixedLenFeature([448*448], tf.float32),\r\n            \"image_ab\": tf.io.FixedLenFeature([448*448*2], tf.float32),\r\n            #\"image_embedding\": self._float32_list(img_embedding.flatten()),\r\n        }\r\n        \r\n        def _parse_function(example_proto):\r\n            feature = tf.io.parse_single_example(example_proto, feature_description)\r\n            \r\n            image_l = feature[\"image_l\"]\r\n            image_ab = feature[\"image_ab\"]\r\n            \r\n            image_l = image_l.numpy().reshape(448, 448, 1)\r\n            image_ab = image_ab.numpy().reshape(448, 448, 2)\r\n            \r\n            #image_l = image_l.eval(session=tf.compat.v1.Session()).reshape(448, 448, 1)\r\n            #image_ab = image_ab.eval(session=tf.compat.v1.Session()).reshape(448, 448, 2)\r\n            \r\n            \r\n            image_l = np.asarray(image_l)/255\r\n            image_ab = np.asarray(image_ab)/255\r\n            \r\n            return image_l, image_ab\r\n            \r\n        parsed_dataset = []\r\n        \r\n                \r\n        raw_dataset = []\r\n        counter = 0\r\n        offset = self.offset #200\r\n        interval = 1 #20\r\n        add_count = 0\r\n        interval_counter = 1\r\n        \r\n        #self.offset = self.offset + 1\r\n        \r\n        print(self.offset)\r\n        example, offset = self.raw_data.read(self.offset)\r\n        \r\n        self.offset = offset\r\n        \r\n        return _parse_function(example)\r\n        \r\n\r\n    def read_img(self, filename):\r\n        print(filename)\r\n        img = cv2.imread(filename, 1)\r\n        height, width, channels = img.shape\r\n        labimg = cv2.cvtColor(img, cv2.COLOR_BGR2Lab) #cv2.resize(img, (config.IMAGE_SIZE, config.IMAGE_SIZE)\r\n        l, ab = np.reshape(labimg[:,:,0], (config.IMAGE_SIZE, config.IMAGE_SIZE, 1)), labimg[:, :, 1:]\r\n        l = np.asarray(l)/255\r\n        ab = np.asarray(ab)/255\r\n        return l, ab\r\n        \r\n    def deprocess(self, imgs):\r\n        imgs = imgs * 255\r\n        imgs[imgs > 255] = 255\r\n        imgs[imgs < 0] = 0\r\n        return imgs.astype(np.uint8)\r\n        \r\n    def print_image(self, gray_image, color_image):\r\n        color_unaltered = color_image\r\n        whole_image = np.concatenate((gray_image, color_image), axis=2)\r\n        color_image = self.deprocess(color_image)\r\n        gray_image = self.deprocess(gray_image)\r\n        print(gray_image)\r\n        print(color_image)\r\n        result = np.concatenate((gray_image, color_image), axis=2)\r\n        #whole_image = result\r\n        print(\"batch shapes\")\r\n        print(result.shape)\r\n        #result = np.concatenate((batchX, predictedY), axis=2)\r\n        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\r\n        save_path = os.path.join(config.OUT_DIR,  \"_reconstructed.png\")\r\n        print(save_path)\r\n        cv2.imwrite(save_path, result)\r\n        print(\"written\")\r\n        zeros = np.ones(shape=(448, 448, 1), dtype=np.uint8)*127\r\n        #zeros = zeros / 2\r\n        result = np.concatenate((zeros, color_image), axis=2)\r\n        print(result.shape)\r\n        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\r\n        save_path = os.path.join(config.OUT_DIR, \"_reconstructed_just_colors.png\")\r\n        print(save_path)\r\n        cv2.imwrite(save_path, result)\r\n        print(\"written\")\r\n        zeros = np.ones(shape=(448, 448, 2), dtype=np.uint8)*127\r\n        #zeros = zeros / 2\r\n        result = np.concatenate((gray_image, zeros), axis=2)\r\n        print(result.shape)\r\n        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\r\n        save_path = os.path.join(config.OUT_DIR, \"_reconstructed_just_grayscale.png\")\r\n        print(save_path)\r\n        cv2.imwrite(save_path, result)\r\n        \r\n        random_values = np.random.rand(448, 448, 2)\r\n        #random_values = self.deprocess(random_values)\r\n        \r\n        loss = tf.reduce_mean(input_tensor=tf.math.squared_difference(random_values, color_unaltered)).numpy\r\n        #loss = loss.eval(session=tf.compat.v1.Session())\r\n        print(\"random loss: \")\r\n        print(loss)\r\n        \r\n    def reconstruct(self, batchX, predictedY, filelist):\r\n        #for i in range(config.BATCH_SIZE):\r\n        batchX = self.deprocess(batchX)\r\n        predictedY = self.deprocess(predictedY)\r\n        print(\"batch shapes\")\r\n        print(batchX.shape)\r\n        print(predictedY.shape)\r\n        print(predictedY)\r\n        result = np.concatenate((batchX, predictedY), axis=2)\r\n        #result = np.concatenate((batchX, predictedY), axis=2)\r\n        print(result.shape)\r\n        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\r\n        save_path = os.path.join(config.OUT_DIR, \"reconstructed.png\")\r\n        print(save_path)\r\n        cv2.imwrite(save_path, result)\r\n        print(\"written\")\r\n        zeros = np.ones(shape=(448, 448, 1), dtype=np.uint8)*127\r\n        #zeros = zeros / 2\r\n        result = np.concatenate((zeros, predictedY), axis=2)\r\n        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\r\n        save_path = os.path.join(config.OUT_DIR, \"reconstructed_just_colors.png\")\r\n        print(save_path)\r\n        cv2.imwrite(save_path, result)\r\n    \r\nmodel_a = Autoencoder()\r\n#model_a.build()\r\nmodel_a.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=tf.keras.losses.MeanSquaredError())\r\n\r\n\r\n#checkpoint_path = \"cp/variables/variables\"\r\n#checkpoint_dir = os.path.join(config.MODEL_DIR, checkpoint_path) #os.path.dirname(checkpoint_path)\r\n\r\ncheckpoint_path = \"checkpoint\"\r\ncheckpoint_dir = os.path.join(config.MODEL_DIR, checkpoint_path) #os.path.dirname(checkpoint_path)\r\n\r\ndata = DATA()\r\n#data.index_tf_record()\r\n\r\ndata.read_tf_record_init()\r\ndata.read_indicies()\r\n\r\nmodel_a.load_weights(checkpoint_dir)\r\n\r\n\r\ncounter = 0\r\ninterlope = 0\r\nwhile(counter < 20000):\r\n\r\n    images = data.get_random_images()\r\n\r\n\r\n    values = []\r\n    output = []\r\n\r\n    #print(images)\r\n\r\n\r\n    for l, ab in images:\r\n        values.append(l)\r\n        output.append(ab)\r\n\r\n\r\n    values = np.array(values)\r\n    output = np.array(output)\r\n\r\n    print(values.shape)\r\n    print(output.shape)\r\n\r\n    \"\"\"\r\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir,\r\n                                                     save_weights_only=True,\r\n                                                     verbose=1,\r\n                                                     save_freq=4\r\n                                                     )\r\n    \"\"\"\r\n    #\r\n    if interlope == 0:\r\n        with tf.device(\"/device:GPU:0\"):\r\n            model_a.fit(values, output, batch_size=1, epochs=1, shuffle=False)\r\n    else:\r\n        with tf.device(\"/device:CPU:0\"):\r\n            model_a.fit(values, output, batch_size=1, epochs=1, shuffle=False)\r\n            \r\n    print(\"fit complete\")\r\n    counter = counter + 1\r\n    time.sleep(5)\r\n    \r\n    if interlope == 0:\r\n        interlope = 1\r\n    else:\r\n        interlope = 0\r\n        \r\n    if counter % 10 == 0:\r\n        model_a.save_weights(checkpoint_dir)\r\n        #model_a.save(checkpoint_dir)\r\n        print(\"saved\")\r\n        \r\n\r\n\r\n\"\"\"\r\nl, ab = data.read_img(\"/Users/siggi/VideoColor/videocolor/DATASET/TV/TRAIN/File 7792.png\")\r\n\r\n#data.print_image(l, ab)\r\n\r\n\r\nvalues = np.array([l])\r\noutput = np.array([ab])\r\n\r\nprint(values.shape)\r\nprint(output.shape)\r\n#return\r\n        \r\n#values_2 = np.random.rand(448, 448, 1)\r\n\r\n\r\n\r\n# Create a callback that saves the model's weights\r\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir,\r\n                                                 save_weights_only=True,\r\n                                                 verbose=1,\r\n                                                 save_freq=16\r\n                                                 )\r\n\r\nload = False\r\n\r\n#output_ = np.random.rand(448, 1)\r\nwith tf.device(\"/device:CPU:0\"):\r\n    if load:\r\n        model_a.load_weights(checkpoint_dir) #change to\r\n    #else:\r\n        #model_a.set_initial_values()\r\n    model_a.fit(values, output, epochs=6400, shuffle=False, callbacks=[cp_callback])\r\n\"\"\"\r\n\r\n\"\"\"\r\nl, ab = data.read_img(\"/Users/siggi/VideoColor/videocolor/DATASET/TV/TRAIN/File 7792.png\")\r\n\r\nvalues = np.array([l])\r\noutput = np.array([ab])\r\n    \r\nwith tf.device(\"/device:CPU:0\"):\r\n    model_a.load_weights(checkpoint_dir) #change to\r\n    ab_arr = model_a.predict(values)\r\n\r\n\r\ndata.reconstruct(values[0,:,:,:], ab_arr[0,:,:,:], [1])\r\n\"\"\"\r\n    \r\n`````````````````````\r\n\r\n\r\n", "@siggi90 Generally we don't support debugging long codes. Can you please simplify the code and find a root-cause of this error. Please share simple standalone code to reproduce the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50395\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50395\">No</a>\n"]}, {"number": 50391, "title": "GPU resource can not be found in tensorlfow-gpu2.3.0", "body": "When I upgrade tensorflow from 2.1.0 to 2.3.0, the GPU can not be found.\r\nMy old environment: python3.6+CUDA10.2+Tensorflow-gpu2.1.0, I can successfully run my code using this environemnt, both in graph mode and non-Graph mode.\r\n\r\nThen, I created a new environment: python3.7+Tensorflow-gpu2.3.0, and run my code using this environment. I found, the GPU resource could not be found (the output of the commound \"tf.config.experimental.list_physical_devices('GPU'\") is [ ]).\r\nI think it's caused by the version of CUDA at the first glance. Then I upgrade CUDA from 10.2 to 11.0, but the issue remains unsolved.\r\n\r\nCan anyone help solving this issue?", "comments": ["@v3551G \r\n\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abug&template=00-bug-issue.md) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nalso refer [this](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb) and let us know if it helps\r\n\r\nThanks\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50391\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50391\">No</a>\n"]}, {"number": 50390, "title": "Compitable with CUDA, Can not find GPU resource", "body": "When I upgrade tensorflow from 2.1.0 to 2.3.0, the GPU can not be found.\r\nMy old environment: python3.6+CUDA10.2+Tensorflow-gpu2.1.0, I can successfully run my code using this environemnt, both in graph mode and non-Graph mode.\r\n\r\nThen, I created a new environment: python3.7+Tensorflow-gpu2.3.0, and run my code using this environment. I found, the GPU resource could not be found (the output of the commound \"tf.config.experimental.list_physical_devices('GPU'\") is [ ]).\r\nI think it's caused by the version of CUDA at the first glance. Then I upgrade CUDA from 10.2 to 11.0, but the issue remains unsolved.\r\n\r\nCan anyone help solving this issue?", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50390) for more info**.\n\n<!-- need_sender_cla -->", "@v3551G We don't merge release branches back into master.  Thank you for your interest. \r\nCC @mihaimaruseac"]}, {"number": 50389, "title": "Rename template IN / OUT to INPUT / OUTPUT for Windows on ARM", "body": "It build failed in Windows on ARM because the IN / OUT is defined in windows.h(minwindef.h)\r\n```\r\n#ifndef IN\r\n#define IN\r\n#endif\r\n\r\n#ifndef OUT\r\n#define OUT\r\n#endif\r\n```\r\nSo I replace it to INPUT / OUTPUT", "comments": []}, {"number": 50388, "title": "[ROCm] Update profiler support for rocm", "body": "These changes add the following capabilities to the TF profiler for ROCm\r\n\r\n* Makes all the profiler views in TensorBoard valid for AMD GPUs\r\n* Add host API tracing to the traceviewer\r\n* Add some new HIP APIs to track in the profiler\r\n* Solve some of the previously known issues:\r\n  * Assigning correct physical device ID\r\n  * Fix events being dropped", "comments": ["@chsigg, @jbaiocchi, gentle ping!", "@reza-amd  Can you please resolve conflicts? Thanks!", "> Thanks! Let's submit and see how it goes.\r\n\r\nI see that \"Windows Bazel\" CI job has failed. I checked the log and It seems it is not related to my changes.", "@jbaiocchi , could you please take a look at the \"Windows Bazel GPU\" logs and see if any change is needed from my side?"]}, {"number": 50387, "title": "Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato r ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void * )' to 'PyUFuncGenericFunction'", "body": "ERROR:.../pycharmprojects/pythonproject/tensorflow/tensorflow/python/BUILD:437:1: C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (\r\nExit 2)\r\ntensorflow/python/lib/core/bfloat16.cc(635): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(635): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\ntensorflow/python/lib/core/bfloat16.cc(639): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(639): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\ntensorflow/python/lib/core/bfloat16.cc(643): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(643): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\ntensorflow/python/lib/core/bfloat16.cc(646): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(646): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\ntensorflow/python/lib/core/bfloat16.cc(650): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(650): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\ntensorflow/python/lib/core/bfloat16.cc(654): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::operato\r\nr ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *\r\n)' to 'PyUFuncGenericFunction'\r\ntensorflow/python/lib/core/bfloat16.cc(654): note: None of the functions with this name in scope match the target type\r\ntensorflow/python/lib/core/bfloat16.cc(629): note: see declaration of 'tensorflow::`anonymous-namespace'::Initialize::<lambda_a7b8b31d992e5b5e4dc9d84f5f519c90>::\r\noperator ()'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 12840.328s, Critical Path: 449.09s\r\nINFO: 7087 processes: 7087 local.\r\nFAILED: Build did NOT complete successfully\r\n///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\r\nTested build configuration \r\ncpu  tensorflow-2.2.0\tpython3.7\tMSVC 2019\tBazel 2.0.0\r\n", "comments": ["I see multiple issues created, as requested earlier please fii in the issue template:#50356,#50369\r\nPlease verify:\r\n1)if you have latest MSVC compiler\r\n2)python & os of 64 bits\r\n3)compatibility issues , system requirements\r\n4)please try to change your numpy version and let us know if the issue exist, [run bazel clean after downgrading ur numpy if in case]\r\nwe will not be able to help you unless issue template is filled a sit helps us analyse the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50387\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50387\">No</a>\n"]}, {"number": 50386, "title": "ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  windows 10\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):   Tensorflow 2.5.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):  ARM\r\n\r\n**Describe the problem**\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nAfter a long search in other forums for my problem, any solution fund won\u2019t work for me. I hope that you can help me to overcome this problem.\r\nthe problem is while doing post-training integer quantization of a GRU model, it gives me the following error :\r\n**ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.**\r\nI tried TensorFlow 2.4.1, tf-nightly, but no one works.\r\nI think the problem is with my **representative_dataset** , but it works with CNN 1D.\r\n**My code:**\r\n\r\n`converter = tf.lite.TFLiteConverter.from_saved_model(LSTMMODEL_TF)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ndef representative_dataset_gen():\r\n\tfor sample in XX_data:\r\n\t    sample = np.expand_dims(sample.astype(np.float32), axis=0)\r\n\t    yield [sample]\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8\r\nconverter.inference_output_type = tf.int8\r\n\r\nconverter.representative_dataset = repr_data_gen\r\nmodel_tflite = converter.convert()\r\n\r\nopen(LSTMODEL_TFLITE, \"wb\").write(model_tflite)`\r\n\r\n\r\n\r\n", "comments": ["@ElectroSkills-channel  Could you please submit a new issue [here](https://github.com/tensorflow/tflite-micro/issues/new) since all micro related issues are handled separately.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50386\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50386\">No</a>\n"]}, {"number": 50385, "title": "[INTEL_MKL] Windows OpenMP support", "body": "Enable Windows OpenMP support for Intel-MKL to improve performance on CPUs", "comments": ["@penpornk bazel throes some error: Error in cc_binary: cc_binary 'name' attribute must be a string. Is there a suggested fix for this?\r\n`ERROR: Traceback (most recent call last):\r\n        File \"/localdisk/bani/inteltf1-build/3de45b8df3514ee70c6c7e96234456ef/external/llvm_openmp/BUILD.bazel\", line 226, column 10, in <tople\r\n                cc_binary(\r\n        File \"/localdisk/bani/inteltf1-build/3de45b8df3514ee70c6c7e96234456ef/external/rules_cc/cc/defs.bzl\", line 39, column 21, in cc_binary\r\n                native.cc_binary(**_add_tags(attrs))\r\nError in cc_binary: cc_binary 'name' attribute must be a string\r\n`", "@bani-intelaipg Ah, we probably need to generate the rules like you did then. (Sorry about that. I'm not a bazel expert either.)\r\nCan we do this? Define a genrule in `openmp.bzl` and call it from the `BUILD` file:\r\nopenmp.bzl:\r\n```\r\ndef tf_gen_libiomp(name, sources, common_includes):\r\n    # Linux and MacOS\r\n    for ext in [\".so\", \".dylib\"]:\r\n        cc_binary(\r\n            name = name + ext,\r\n            srcs = sources + [\r\n                \"runtime/src/z_Linux_util.cpp\",\r\n                \"runtime/src/kmp_gsupport.cpp\",\r\n                \"runtime/src/z_Linux_asm.S\",\r\n            ],\r\n            additional_linker_inputs = [\"ldscript\"],\r\n            copts = [\"-Domp_EXPORTS -D_GNU_SOURCE -D_REENTRANT\"],\r\n            includes = common_includes,\r\n            linkopts = [\"-lpthread -ldl -Wl,--version-script=$(location :ldscript)\"],\r\n            linkshared = True,\r\n            visibility = [\"//visibility:public\"],\r\n        )\r\n\r\n    # Windows\r\n    cc_binary(\r\n        name = name + \".dll\",\r\n        srcs = sources + [\r\n            \"runtime/src/z_Windows_NT_util.cpp\",\r\n            \"runtime/src/z_Windows_NT-586_util.cpp\",\r\n            \":openmp_asm\",\r\n        ],\r\n        additional_linker_inputs = [\":generate_def\"],\r\n        copts = [\"/Domp_EXPORTS /D_M_AMD64 /DOMPT_SUPPORT=0 /D_WINDOWS /D_WINNT /D_USRDLL\"],\r\n        includes = common_includes,\r\n        linkopts = [\"/MACHINE:X64\"],\r\n        linkshared = True,\r\n        visibility = [\"//visibility:public\"],\r\n        win_def_file = \":generate_def\",\r\n    )\r\n```\r\n\r\nBUILD file:\r\n```\r\ntf_gen_libiomp(\r\n    name = \"libiomp5\",\r\n    common_includes = common_includes,\r\n    sources = cppsources + srcdeps + headers,\r\n)\r\n```\r\n\r\nIf this doesn't work, please feel free to go back to your original changes which you have tested (since we are short on time) but use the `select_os_specific_2` to avoid duplicate strings between linux and mac.", "We are reverting as you suggested. Will push the commit soon.", "Thank you! \r\nDoes your original commit build for you? I tried building the `libiomp5.so` target on Ubuntu and got this error:\r\n```\r\nERROR: /root/windows/tensorflow/third_party/llvm_openmp/BUILD:129:18: in genrule rule //third_party/llvm_openmp:config_omp: target '//third_party/llvm:expand_cmake_vars' is not visible from target '//third_party/llvm_openmp:config_omp'. Check the visibility declaration of the former target if you think the dependency is legitimate\r\nERROR: Analysis of target '//third_party/llvm_openmp:libiomp5.so' failed; build aborted: Analysis of target '//third_party/llvm_openmp:config_omp' failed\r\n```", "Hi @penpornk after reverting the changes the build passes in both Linux and Windows.", "@penpornk Please let us know if anything remains to be done before including this PR.", "@bani-intelaipg I have pulled this PR in yesterday and fixed additional issues from internal tests (internally) this morning. It is not merged yet because of some infra issues. I'm not sure if it will get merged in time, but I'll keep trying the merge.", "@bani-intelaipg Seems like the merge just went through. The PR should be updated shortly. :)"]}, {"number": 50384, "title": "Ability to prevent a metric from accumulating during training", "body": "I want a metric that computes the mean value over other metrics. E.g. something like the following:\r\n\r\n```\r\ndef construct_mean_accuracy(metrics):\r\n    ''' Pass in a list of all other metrics to compute the mean value over all of them. '''\r\n\r\n    def mean_accuracy(y_true, y_pred, sample_weight=None):\r\n        return tf.math.reduce_mean([m.result() for m in metrics])\r\n\r\n    return mean_accuracy\r\n```\r\n\r\nThe metrics that I'm computing the mean over here are themselves accumulated (i.e. 'streamed') accuracy values that build up over an epoch. The `mean_accuracy` value printed by TensorFlow during `Model.fit()` is wrong, because TF is automatically accumulating the batch-wise metric values of `mean_accuracy` through a rolling mean (I think). This behaviour has caused confusion for people in the past (see #9498, #15115, #42994), and I couldn't find any documentation on it. Is there a way to prevent the accumulation behaviour and just return the batch-wise value? The desired final `on_epoch_end` value for `mean_accuracy` should just be the mean over the metrics in the final batch (because the other metrics are themselves accumulated metrics).\r\n\r\nLet me know if I can make this any clearer.\r\n", "comments": ["@tom-andersson \r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Afeature&template=30-feature-request.md) has not been filled, could you please do so as it helps us analyse the issue .Thanks", "@tom-andersson Thanks for creating the issue. `keras` moved to a [new repository](https://github.com/keras-team/keras/issues) and that repo is dedicated for `keras` development. Earlier `keras` team published about the move in TF forum. The link is given below.\r\n\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n\r\nCan you please create a new issue in that repository. When you create issue, can you please share a simple standalone code to reproduce the issue. Standalone code helps to resolve the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]