[{"number": 33226, "title": "python3-pip missing from container image", "body": "# Issue\r\nPython 2.7 is being deprecated in 2020, Python 3.6+ is included but is lacking pip3.  \r\nSome [Python examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/python) don't work without having to manually install it.\r\n\r\n## Fix\r\nInstall python3-pip as a dependency", "comments": ["@BobyMCbobs I tried with `docker run -i -t tensorflow/tensorflow:2.0.0-py3` and pip3 is inside.", "> @BobyMCbobs I tried with `docker run -i -t tensorflow/tensorflow:2.0.0-py3` and pip3 is inside.\r\n\r\nShouldn't this image be the default one?", "@BobyMCbobs, our current images do default to Python 2, and probably will continue to do so until Python 2.7 reaches EOL in January 2020. Until then, you'll need to use one of the `-py3` images if you wish to use Python 3.\r\n\r\nIf you've discovered this problem with one of those Python 3 images, could you post a demonstration command line example, please?", "> @BobyMCbobs, our current images do default to Python 2, and probably will continue to do so until Python 2.7 reaches EOL in January 2020. Until then, you'll need to use one of the `-py3` images if you wish to use Python 3.\r\n\r\nOK, this is good to know. I'll close the issue.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33226\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33226\">No</a>\n"]}, {"number": 33225, "title": "Fix deprecated warning caused by shuffle_and_repeat when using make_csv_dataset", "body": "This fix fixes unnecessary deprecated warning caused by shuffle_and_repeat when using make_csv_dataset:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:215: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\r\n```\r\n\r\nNote the fix doesn't use shuffle().repeat() as was suggested in the warning message, instead this fix keeps the original implementation to avoid potential performance issues.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @jsimsa for the review. There was a test failure (passed a typo name). I have updated the PR and pushed. Can you look and approve again if everything is still fine? Sorry for the extra inconvenience."]}, {"number": 33224, "title": "[Intel MKL] Update MKLDNN to v0.21.2", "body": "", "comments": []}, {"number": 33223, "title": "tf.summary.image log spam", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0, 7.6.2\r\n- GPU model and memory: Tesla v100 16GiB (AWS EC2 p3.2x instance).\r\n\r\n**Describe the current behavior**\r\n\r\nI'm running TF in a lazy mode by calling tf.compat.v1.disable_v2_behavior().\r\n\r\nI have code that calls tf.summary.image in a trivial way:\r\n  tf.summary.image(\"name\", sometensor)\r\n\r\nTF shows a following error message. TF continues functioning properly, but these messages are eyesore.\r\n\r\n```\r\nERROR:tensorflow:==================================                                                                                                                                           \r\nObject was never used (type <class 'tensorflow.python.framework.ops.Operation'>):                                                                                                             \r\n<tf.Operation 'channel_multiplicity/assert_non_negative/assert_less_equal/Assert/Assert' type=Assert>                                                                                         \r\nIf you want to mark it as used call its \"mark_used()\" method.                                                                                                                                 \r\nIt was originally created here:                                                                                                                                                               \r\n  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorboard/plugins/image/summary_v2.py\", line 72, in image                                                                           \r\n    tf.debugging.assert_non_negative(max_outputs)  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/check_ops.py\", line 302, in assert_non_negative_v2        \r\n    name=name)  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/check_ops.py\", line 345, in assert_non_negative                                              \r\n    return assert_less_equal(zero, x, data=data, summarize=summarize)  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/check_ops.py\", line 952, in assert_le\\\r\nss_equal                                                                                                                                                                                      \r\n    return control_flow_ops.Assert(condition, data, summarize=summarize)  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py\", line 198, in w\\\r\nrapped                                                                                                                                                                                        \r\n    return _add_should_use_warning(fn(*args, **kwargs))                                                                                                                                       \r\n==================================                           \r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThese error messages shouldn't be shown.\r\n\r\n**Code to reproduce the issue**\r\nI can create a repro if needed.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@yasushi-saito, Please provide the standalone to reproduce the reported issue. Thanks!", "Sure.\r\n\r\n```\r\nimport tensorflow as tf                                                                                                              \r\ntf.compat.v1.disable_eager_execution()                                                                                               \r\n                                                                                                                                     \r\nprint(tf.__version__)                                                                                                                \r\nx = tf.constant(0, shape=(2,2,2,2))                                                                                                  \r\ntf.summary.image(name=\"foo\", data=x)                                                                                                 \r\n```\r\n\r\nIt produces\r\n\r\n```\r\nE1011 10:57:24.039931 140608927717120 tf_should_use.py:76] ==================================                                        \r\nObject was never used (type <class 'tensorflow.python.framework.ops.Operation'>):                                                    \r\n<tf.Operation 'foo/assert_non_negative/assert_less_equal/Assert/Assert' type=Assert>                                                 \r\nIf you want to mark it as used call its \"mark_used()\" method.                                                                        \r\nIt was originally created here:                                                                                                      \r\n  File \"/home/ysaito/.local/lib/python3.7/site-packages/tensorboard/plugins/image/summary_v2.py\", line 72, in image                  \r\n    tf.debugging.assert_non_negative(max_outputs)  File \"/home/ysaito/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/\\\r\ncheck_ops.py\", line 302, in assert_non_negative_v2                                                                                   \r\n    name=name)  File \"/home/ysaito/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/check_ops.py\", line 345, in assert_\\\r\nnon_negative                                                                                                                         \r\n    return assert_less_equal(zero, x, data=data, summarize=summarize)  File \"/home/ysaito/.local/lib/python3.7/site-packages/tensorf\\\r\nlow_core/python/ops/check_ops.py\", line 952, in assert_less_equal                                                                    \r\n    return control_flow_ops.Assert(condition, data, summarize=summarize)  File \"/home/ysaito/.local/lib/python3.7/site-packages/tens\\\r\norflow_core/python/util/tf_should_use.py\", line 198, in wrapped                                                                      \r\n    return _add_should_use_warning(fn(*args, **kwargs))                                                                              \r\n==================================       \r\n```\r\n\r\nRemoving the second line causes these messages to disappear.", "@yasushi-saito, I tried executing your code on colab with Tensorflow 2.0.0, it resulted in few warning messages and i could reproduce the issue.. Please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/578b0867653db57f09480f9f52c25816/untitled198.ipynb). Thanks! ", "@yasushi-saito \r\n\r\nI am not seeing any error message in TF version 2.2.rc3(!pip install tensorflow==2.2-rc3 ).Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/3e6fb2d02fb9d66f316e28ea38eaa90c/untitled818.ipynb).Please verify once and close the issue. Thanks!", "Ok, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33223\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33223\">No</a>\n"]}, {"number": 33222, "title": "TF 2.0: Can't authenticate with google storage in colab", "body": "I'm trying to use the TPU in colab so I have to authenticate to my google storage account to feed the data (as I understood from past tutorials on using TPUs on colab). When I'm trying to authenticate I get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-1f759c1655bd> in <module>()\r\n      1 from google.colab import auth\r\n----> 2 auth.authenticate_user()\r\n\r\n/usr/local/lib/python3.6/dist-packages/google/colab/auth.py in authenticate_user(clear_output)\r\n    154       with tf.compat.v1.Session('grpc://{}'.format(colab_tpu_addr)) as sess:\r\n    155         with open(_get_adc_path()) as auth_info:\r\n--> 156           tf.contrib.cloud.configure_gcs(\r\n    157               sess, credentials=_json.load(auth_info))\r\n    158   if _check_adc():\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'contrib'\r\n```\r\n\r\nThe code I run is:\r\n\r\n```\r\n!pip install tensorflow-gpu\r\nfrom google.colab import auth\r\nauth.authenticate_user()\r\n```\r\nThe following link contains the code to reproduce the error https://colab.research.google.com/drive/1LQ_SuPoetIUBTBhohVbFJnatkyKNb1G9\r\n", "comments": ["This is a know issue. You can look at this [comment](https://github.com/googlecolab/colabtools/issues/602#issuecomment-503189066) which should help you understand the situation but you're still likely to hit trouble with TPUs + TF2\r\n\r\nAlso please take a look at this [gist](https://colab.sandbox.google.com/gist/gowthamkpr/7dbbf30d6bbdd264aafa6b2b77f24991/untitled181.ipynb) where I was able to skip the failing code and succeeded.\r\n\r\n@georgealexandruvlad For more clarificaion regarding this issue, You can post your issue in [googlecolab/colabtools](https://github.com/googlecolab/colabtools/issues). \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33222\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33222\">No</a>\n"]}, {"number": 33221, "title": "Update api_def_Unique.pbtxt", "body": "The documentation of `tf.unique` is unclear because it shows the input as an already sorted list. A result for a non-sorted list should be shown to clarify the operation.", "comments": ["Checks seem to be frozen."]}, {"number": 33220, "title": "Fix SIGABRT on `tf.image.encode_png` with empty tensor", "body": "This fix address the issue raised in #31429 where SIGABRT was thrown on `tf.image.encode_png` with empty tensor.\r\n\r\nInstead of thrown out SIGABRT, this fix adds the error checking so that InvalidArgument was returned gracefully.\r\n\r\nThis fix fixes #31429\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@rthadur sorry for the late reply. The email notification before slip through. I have rebased and update the PR. Can you give it a try and see if the issue still exist?", "@rthadur Sorry for the late reply as I was mostly out of office year end (was back last week). I will take a look at the errors shortly.", "@mihaimaruseac I had been trying to find where the test failure is from, but couldn't figure out from the traceback error message. I tried to search the source tree but could not find `testPartExecutor` that showed up in error message.\r\n\r\nI guess this test might from some previous version setup? Could it be that test was from an old version of TF setup (like 1.14 or earlier) against master 2.1?\r\n\r\nWondering if you have any clue about the background information with the test error?\r\n\r\n```\r\nTraceback (most recent call last): \r\n\r\n/unittest/case.py\", line 59, \r\n\r\nin testPartExecutor yield /unittest/case.py\", line 605, \r\n\r\nin run testMethod() File \"/google3/runfiles/google3/third_party/tensorflow/python/ops/image_ops_test.py\", line 4079,\r\n\r\nin testEmptyTensor png = image_ops.encode_png(image) File \"contextlib.py\", line 88, \r\n\r\nin __exit__ next(self.gen) File \"google3/runfiles/google3/third_party/tensorflow/python/framework/test_util.py\", line 2819,\r\n\r\nin assertRaisesWithPredicateMatch (str(type(e)), str(e))) AssertionError: Exception of type <class 'AssertionError'>: OpError not raised\r\n```", "I will have to look into this. I'll update the PR over the weekend. Sorry for the delay", "Thanks @mihaimaruseac \ud83d\udc4d , let me know if there is anything I can help.", "@yongtang Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 33219, "title": "regularization parameter being ignored in tf.keras dense layer initialization", "body": "An example of this issue can easily be seen on the TF 2.0 colab advanced quickstart tutorial: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#scrollTo=i-2pkctU_Ci7\r\n\r\nChanging the code block from\r\n\r\n```\r\n`class MyModel(Model):\r\n  def __init__(self):\r\n    super(MyModel, self).__init__()\r\n    self.conv1 = Conv2D(32, 3, activation='relu')\r\n    self.flatten = Flatten()\r\n    self.d1 = Dense(128, activation='relu')\r\n    self.d2 = Dense(10, activation='softmax')\r\n\r\n  def call(self, x):\r\n    x = self.conv1(x)\r\n    x = self.flatten(x)\r\n    x = self.d1(x)\r\n    return self.d2(x)\r\nmodel = MyModel()`\r\n```\r\n\r\nTo \r\n\r\n```\r\n`class MyModel(Model):\r\n  def __init__(self):\r\n    super(MyModel, self).__init__()\r\n    self.conv1 = Conv2D(32, 3, activation='relu',activity_regularizer=tf.keras.regularizers.l2(100000.))\r\n    self.flatten = Flatten()\r\n    self.d1 = Dense(128, activation='relu',activity_regularizer=tf.keras.regularizers.l2(100000.))\r\n    self.d2 = Dense(10, activation='softmax',activity_regularizer=tf.keras.regularizers.l2(100000.))\r\n  def call(self, x):\r\n    x = self.conv1(x)\r\n    x = self.flatten(x)\r\n    x = self.d1(x)\r\n    return self.d2(x)\r\nmodel = MyModel()`\r\n```\r\n    \r\nhas no effect, despite the regularization parameter being inordinately large (we should expect learning to completely stop in this case, as the penalization should force outputs to 0). \r\nThis is also true for kernel_regularizer.\r\nManually adding tf.keras.layers.ActivityRegularization also has no effect. \r\n\r\n", "comments": ["As explained no error is faced after code is replaced, Thanks!", "The code in that file does not collect the regularisation losses.\r\nI think that you need to write:\r\n`loss += tf.add_n(model.losses)`\r\nin the `train_step` function.", "@mikeymezher Let us know whether @georgesterpu suggestion helped you in resolving the issue? Thanks!", "Thanks @georgesterpu, that recommendation worked. In retrospect, I understand why this step is needed, since regularization wouldn't effect the predict method of the model so loss due to regularization has to be added separately; but I couldn't find any documentation for this. \r\n\r\nMight be worth mentioning/providing an example of this somewhere in the tf.keras.regularizers api-docs. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33219\">No</a>\n"]}, {"number": 33218, "title": "TF 2.0: Functions and packages autocomplete broken in PyCharm", "body": "from tensorflow.**_keras_** import **_callbacks_**\r\nfrom tensorflow._**keras.optimizers**_ import **_Adam_**\r\n\r\nThe packages in bold are just a few examples that are not recognized in PyCharm. The issue was first spotted and reported in rc release. At that time we've been told to wait for the release of 2.0 because the issue is a bit more complex. The 2.0 is now here and as far as I am concerned the issue still persists. There are any configurations to be made in order to work or this problem is still an unresolved issue?\r\n\r\nPyCharm gives the following complaint: \r\n```Cannot find reference 'keras' in '__init__.py'```", "comments": ["@georgealexandruvlad \r\n\r\nLooks like similar issue  #31973.Please let us know. Thanks!", "@ravikyram Yes, it's similar, but there the title contains \"[TF 2.0.0-rc0]\" which I find confusing for people searching for this exact issue. There are different releases and I thought the issue should refer to the current one. If you consider this is redundant feel free to close it and I will follow the other one.\r\nAlso, there is any date by which we could expect this to be solved or it's ASAP?", "The recommended way to import is the following:\r\n```\r\nimport tensorflow as tf\r\n....\r\n#usage\r\ntf.keras.callbacks.\u2014\r\ntf.keras.optimizers.\u2014\r\n```\r\nAlso for me the PyCharm 2019.3 EAP helped with resolving the references in the stable release, and since using it, I had no further issue. That said, I use the format from above.", "Try this simple solution for current situation (tf: 2.0) :\r\n\r\n- Go to dir `/python3/site-packages/` and change the name of `/tensorflow/` to `/tensorflow_back`, then change the name of `/tensorflow_core/` to `/tensorflow/` (only use core api)\r\n\r\n- Go to file `/tensorflow/__init__.py` (which was in `/tensorflow_core/` ), add the following codes:\r\n`from .python.keras.api._v2 import keras`\r\n`from tensorflow_estimator.python.estimator.api._v2 import estimator`\r\n\r\nTF2.0 use lazy import, so this solution works in vscode, and maybe works in pycharm.\r\n(https://github.com/tensorflow/tensorflow/issues/32982#issuecomment-541286669)", "The issue was resolved by using @angeliand 's solution. It seems PyCharm EAP works with tf2.0. @Mulns  thank you for your response as well, if I will encounter the same issue in the future I will consider trying your solution. As the problem has been solved I will close the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33218\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33218\">No</a>\n", "> That said, I use the format from above.\r\n\r\n\r\n\r\n> The recommended way to import is the following:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> ....\r\n> #usage\r\n> tf.keras.callbacks.\u2014\r\n> tf.keras.optimizers.\u2014\r\n> ```\r\n> \r\n> Also for me the PyCharm 2019.3 EAP helped with resolving the references in the stable release, and since using it, I had no further issue. That said, I use the format from above.\r\n\r\nThanks man, that really worked for me.", "PyCharm 2019.3 EAP version worked! \r\nhttps://www.jetbrains.com/pycharm/nextversion/?_ga=2.221720863.623821984.1573808626-1607002874.1573808626", "Even with latest PyCharm, some of the TF 1.15 imports are still not recognized, such as tf.saved_model, tf.error, ...", "@jnd77 \r\n> Even with latest PyCharm, some of the TF 1.15 imports are still not recognized, such as tf.saved_model, tf.error, ...\r\n\r\nI found that this hack makes PyCharm somehow happy with tensorflow 1.15.\r\n```python\r\nfrom typing import TYPE_CHECKING\r\nif TYPE_CHECKING:\r\n    import tensorflow_core.python as tf\r\nelse:\r\n    import tensorflow as tf\r\n```\r\nHowever, there are cons."]}, {"number": 33217, "title": "TF2.0: TypeError when intializting Variable using constant_initializer", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- TensorFlow installed from (source or binary): **binary (pip)**\r\n- TensorFlow version (use command below): **2.0.0**\r\n- Python version: **3.7**\r\n- CUDA/cuDNN version: **10.2**\r\n- GPU model and memory: **GTX 1060, 6GB**\r\n\r\n**Describe the current behavior**\r\n\r\nI get an a `TypeError` execption when I try to initialize `tf.Variable` using `constant_initializer`.\r\nError: `TypeError: __call__() missing 1 required positional argument: 'shape'`\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninput_init = tf.constant_initializer(np.random.uniform(low=-1, high=1, size=(300, 300)))\r\ninput_weights = tf.Variable(input_init, shape=(300, 300))\r\n```\r\n\r\n\r\n**Other info / logs (Traceback)**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/ibrahimsharaf/workspace/GenSen/GenSen/garab.py\", line 38, in <module>\r\n    input_weights = tf.Variable(input_init, shape=(300, 300))\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 260, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 254, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 235, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2556, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/home/ibrahimsharaf/miniconda3/envs/gensen-tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1537, in _init_from_args\r\n    initial_value() if init_from_fn else initial_value,\r\nTypeError: __call__() missing 1 required positional argument: 'shape'\r\n```\r\n", "comments": ["Issue replicating for TF-2.0, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/b178e109b9b0269ae19aaf8b310d0083/33217.ipynb) of colab. Thanks!", "@ibrahimsharaf,\r\nThe error disappears if you use `tf.constant` instead of `tf.constant_initializer`. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/d32c881d8ec26ce4a325a32f94a69b43/33217.ipynb). \r\n\r\nFor more details about this concept, please refer [this link](https://stackoverflow.com/a/38820162/11530462). Thanks!", "Thanks @oanush & @rmothukuru! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33217\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33217\">No</a>\n"]}, {"number": 33216, "title": "[TF 2.0.0] Training keras Model on tf.data.Dataset causes small bug in logging", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **-**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.0.0**\r\n- Python version: **3.6.x**\r\n- CUDA/cuDNN version: **10.0/7.6.1**\r\n- GPU model and memory: \r\n\r\n\r\n---\r\n**Describe the current behavior**\r\n\r\nWhen fitting (.fit) a keras Model on a tf.data.Dataset, the dataset size is not inferred. Because of this, when setting `verbose=1`, during the first epoch the log becomes `current_step/Unknown`. Also the following is thrown (though it does not cause crashing):\r\n```\r\n[[{{node IteratorGetNext}}]]\r\n\t [[IteratorGetNext/_2]]\r\n2019-10-10 18:41:50.728985: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n```\r\n**Describe the expected behavior**\r\n\r\nI would expect to see the number of samples/batches/etc.\r\n\r\n**Code to reproduce the issue**\r\n\r\nI created a small Colab notebook to demonstrate the issue: https://colab.research.google.com/drive/1-S787cE6BWhXJ_0BeAb6EGq4GaXAFwmu\r\nI recommend downloading the .py file and running it in command line (so colab logging doesn't interfere), because after the epoch is done, the correct batch number is found. The problem is during the epoch.\r\n \r\n**Other info / logs**\r\n\r\nI found that the dataset size inferring is actually run, but the returned value is not stored or used anywhere, it is only to throw a warning if the initialization made by the user is faulty in some way.\r\nI am referring to this line: [https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training_v2.py#L247](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training_v2.py#L247)\r\nThe above problem would be eliminated with something like this (or the like):\r\n```\r\nsteps_per_epoch = training_utils.infer_steps_for_dataset(training_dataset, steps_per_epoch, \r\n                                                                                 steps_name='steps_per_epoch',epochs=0) \r\n                                                                            if steps_per_epoch is None else steps_per_epoch\r\n```\r\n", "comments": ["@angeliand \r\nI am able to successfully execute Colab notebook provided by you with a warning message.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/d23afdb38149eeb3fc179a6e30d20721/untitled254.ipynb).Please, let me know is this still an issue?.Thanks!", "As I have said, the problem is with what gets logged **during** the epoch. Not after. In your notebook you did not interrupt the training to view the printed log during the epoch. If interrupted the described behaviour can still be seen.\r\nAlso, I recommend running the script in command line (or anywhere, where the output is printed line by line), where the problem can be viewed without stopping the training.", "@angeliand \r\nI tried running in command line and i am able to execute the .py file successfully. Please find the log file in the attachment.Is this the expected output?\r\n[text.txt.tar.gz](https://github.com/tensorflow/tensorflow/files/3716797/text.txt.tar.gz).I could reproduce the issue in colab when i interrupted during training.Thanks!\r\n", "As I have stated in the original post, the bug does not cause crashing, but it is still inconvenient and can be avoided easily with a minor fix (I have also offered a solution).\r\nIf logging is line by line (so when it doesn\u2019t refresh) eg. in PyCharm or when logging to file, the problem can be viewed easier. It appears during the first epoch and ceases when that is done. (Probably because after the first epoch, we know the number of steps.) This is why training has to be interrupted in colab to view the issue (or you can check the runtime logs in colab!).\r\nAlso the IteratorGetNext warning appears at the end of the first epoch before validating steps. This is because the training loop does not know the number of steps to take (\u2014> times to \u201cquery\u201d the dataset) and the dataset runs out. \r\n\r\nAll in all, this is not huge but still not what would be the expected behaviour. \r\nI will provide a log file from PyCharm in a few hours. ", "PyCharm output is line-by-line, so the problem can be seen better. Here is the output without the proposed solution: \r\n[keras_bug_op.txt](https://github.com/tensorflow/tensorflow/files/3717600/keras_bug_op.txt)\r\nAnd here is the correct (expected) output after using the proposed solution:\r\n[keras_bug_sol.txt](https://github.com/tensorflow/tensorflow/files/3717605/keras_bug_sol.txt)\r\nHope this helps.\r\n", "@angeliand Are you willing to contribute through PR to update relevant codes? Thanks!", "Sure. I'm busy in the next few days, but I will do it after that.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33216\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33216\">No</a>\n"]}, {"number": 33215, "title": "[TF2]'Tensor' object has no attribute '_keras_history'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7\r\n\r\n\r\n### Problem\r\nin TF2.0 use Keras to save model.h5 ,then load model.h5.\r\n\r\nI have saved model.h5 from official.nlp.bert_models.py by use model.save(\"model.h5\") .\r\neverything is ok , but when I load the model.h5 there have some problems.\r\n```python\r\nmodel =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})\r\n\r\n```\r\nemmmmm, how to solve this problem????\r\nI am not sure this is BUG, but in this link someone say this maybe is a bug.\r\nhttps://github.com/tensorflow/models/issues/7643\r\n\r\n### Traceback\r\nTraceback (most recent call last):\r\nFile \"/Users/lollipop/Documents/tf2g/false_news/test.py\", line 30, in\r\nmodel =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 146, in load_model\r\nreturn hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 168, in load_model_from_hdf5\r\ncustom_objects=custom_objects)\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 55, in model_from_config\r\nreturn deserialize(config, custom_objects=custom_objects)\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 102, in deserialize\r\nprintable_module_name='layer')\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 191, in deserialize_keras_object\r\nlist(custom_objects.items())))\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 906, in from_config\r\nconfig, custom_objects)\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1852, in reconstruct_from_config\r\nprocess_node(layer, node_data)\r\nFile \"/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1802, in process_node\r\noutput_index = nest.flatten(output_tensors)[0]._keras_history.node_index\r\nAttributeError: 'Tensor' object has no attribute '_keras_history'\r\n\r\nProcess finished with exit code 1", "comments": ["Did you try this [comment](https://github.com/tensorflow/models/issues/7643#issuecomment-540684664)? Let me know if it solves the issue. Thanks!", "Hi, even if tf format can be a workaround, this seems to be an issue that TF team need to take a look. @gowthamkpr could we find an owner?", "@gowthamkpr  @saberkun \r\n\r\nyes, **tf.saved_model.save** successed save and load. but I think it is too complex. \r\nI hope **tf.keras.models.load_model**  can works.\r\n\r\n### code\r\n```python\r\ntf.saved_model.save(model, \"./outmodel/\")\r\n\r\ntest_input_ids   = np.load('./data/test/input_ids.npy')[:10]\r\ntest_input_masks = np.load('./data/test/input_masks.npy')[:10]\r\ntest_segment_ids = np.load('./data/test/segment_ids.npy')[:10]\r\n\r\ntest_input_word_ids  =tf.convert_to_tensor(test_input_ids, dtype=tf.int32)\r\ntest_input_mask        =tf.convert_to_tensor(test_input_masks, dtype=tf.int32)\r\ntest_input_type_ids   =tf.convert_to_tensor(test_segment_ids, dtype=tf.int32)\r\n\r\n\r\nloaded = tf.saved_model.load('./outmodel')\r\n\r\n# print(list(loaded.signatures.keys()))\r\ninfer = loaded.signatures[\"serving_default\"]\r\n# print(infer.structured_outputs)\r\nprint(infer(input_mask=test_input_mask,input_type_ids=test_input_type_ids,input_word_ids=test_input_word_ids))\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "@SmileTM @saberkun Can you please try using tf-nightly and let me know if the issue still persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33215\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33215\">No</a>\n"]}, {"number": 33214, "title": "Unable to use the save model for prediction", "body": "", "comments": ["I am trying to use Transformer model with distributed training. The codes are available in this [repository](https://github.com/kuetuofa/Transformer).  I can train the model by running following command `python distributed_train.py` after training It's saving the model in the model dir as the pictures shows.\r\n![Capture](https://user-images.githubusercontent.com/51720321/66590364-9e7dab80-eb5e-11e9-85a3-4b63ed64d336.JPG)\r\n\r\nI am trying to load the model from saved model and send some data for prediction but I am ended up getting an error shown in the screenshot below \r\n![Capture1](https://user-images.githubusercontent.com/51720321/66591134-3f209b00-eb60-11e9-8224-94bafec43deb.JPG)\r\n\r\nI am interested to know how should I send data for prediction?\r\nAny help regarding this will be greatly appreciated ", "@kuetuofa ,\r\nCan you share a simple and standalone code to reproduce the issue reported here? Thanks!", "Hi @oanush Thanks for responding. Unfortunately the code is not simple that's why I put it in the following [repository](https://github.com/kuetuofa/Transformer). Will you able to check it out from there? It's a public repo.\r\n", "@kuetuofa This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33213, "title": "[Intel Mkl] Upgrading MKL-DNN to 0.20.6 to fix SGEMM regression", "body": "This PR to r1.15 is an alternative to reverting mkl-dnn to v0.18.  It fixes SGEMM regressions as well as issues that were originally fixed by the mkl-dnn upgrade to 0.20.3 (see https://github.com/tensorflow/tensorflow/pull/31910 and https://github.com/intel/mkl-dnn/releases/tag/v0.20.6). @martinwicke, @penpornk, @goldiegadde Can you verify whether this fixes the issues for you?", "comments": ["@agramesh1 ", "Since there are other issues with .18, this looks good to me, as long as\nwe're sure this fixes the regression.\n"]}, {"number": 33212, "title": "\"module 'tensorflow' has no attribute <anything>\" if tensorflow_core imported first", "body": "**System information**\r\n- OS Platform and Distribution: Linux Manjaro 18\r\n- TensorFlow installed from: pip install tensorflow-gpu==2.0.0\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nIf I import something from **tensorflow_core** before importing **tensorflow**, the **tensorflow** doens't work properly.\r\n\r\n**Describe the expected behavior**\r\nBeing able to import from tensorflow_core (eg: from tensorflow_core.python.keras.engine.training import Model) with no problem.\r\n\r\n**Code to reproduce the issue**\r\n\r\n\r\n```\r\nfrom tensorflow_core.python.keras.engine.training import Model\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n```\r\nAttributeError: module 'tensorflow' has no attribute '__version__'\r\n\r\nThe following works:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow_core.python.keras.engine.training import Model\r\n\r\nprint(tf.__version__)\r\n```", "comments": ["Was able to reproduce it. Heres my [gist](https://colab.sandbox.google.com/gist/gowthamkpr/0176703e3dfd1937d4116a9ea35f4e53/untitled180.ipynb#scrollTo=eTPuCu9-Yam9).\r\n\r\nThe issue is that module wrapping hides all symbols starts with `_` from `__all__` so `__version__` is hided as well. A PR #30778 has been created for previous version for the fix, but the issue still persists in tf 2.0 and tb-nightly-2.1.0a20191010", "Never import `tensorflow_core`. That is an internal implementation detail.\r\n\r\nWe don't support fixing issues that are caused by not using the API as is designed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33212\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33212\">No</a>\n"]}, {"number": 33211, "title": "Fail build librensorflow_cc.so with cuda support", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Debian 10\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): nvcc (gcc-7)\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce RTX 2070 SUPER, 8192 MB\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen I try compile tensorflow I get error: `nvcc fatal   : Unknown option 'MD'`. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nWhile configuring I allow only: `python3`, compilation with `cuda` and cuda compiler as `nvcc` (with complete path to it). After it I try run `bazel` for build `libtensorflow_cc.so` but, almost immediately I get the error: `nvcc fatal   : Unknown option 'MD'`\r\n\r\n\r\n**Any other info / logs**\r\n```bash\r\nbazel build --config=cuda //tensorflow:libtensorflow_cc.so --verbose_failures\r\n\r\n...\r\n\r\nINFO: Analyzed target //tensorflow:libtensorflow_cc.so (1 packages loaded, 2 targets configured).\r\nINFO: Found 1 target...\r\nWARNING: failed to create one or more convenience symlinks for prefix 'bazel-':\r\n  cannot create symbolic link bazel-bin -> /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow/bazel-out/k8-opt/bin:  /tmp/tensorflow_dir/bazel-bin (Permission denied)\r\n  cannot create symbolic link bazel-testlogs -> /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow/bazel-out/k8-opt/testlogs:  /tmp/tensorflow_dir/bazel-testlogs (Permission denied)\r\n  cannot create symbolic link bazel-genfiles -> /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow/bazel-out/k8-opt/bin:  /tmp/tensorflow_dir/bazel-genfiles (Permission denied)\r\n  cannot create symbolic link bazel-out -> /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow/bazel-out:  /tmp/tensorflow_dir/bazel-out (Permission denied)\r\n  cannot create symbolic link bazel-tensorflow_dir -> /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow:  /tmp/tensorflow_dir/bazel-tensorflow_dir (Permission denied)\r\nERROR: /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/external/com_google_protobuf/BUILD:294:1: C++ compilation of rule '@com_google_protobuf//:protoc_lib' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/levkovitch/.cache/bazel/_bazel_levkovitch/81f9c3cb5093a9779b51fe05f62c9c35/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/tmp/bazel_dir/bin:/usr/sbin:/usr/local/sbin:/usr/local/cuda-10.1/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/com_google_protobuf/_objs/protoc_lib/code_generator.d '-frandom-seed=bazel-out/host/bin/external/com_google_protobuf/_objs/protoc_lib/code_generator.o' -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 -g0 -DHAVE_PTHREAD -DHAVE_ZLIB -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-write-strings -c external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc -o bazel-out/host/bin/external/com_google_protobuf/_objs/protoc_lib/code_generator.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nnvcc fatal   : Unknown option 'MD'\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 0.421s, Critical Path: 0.04s\r\nINFO: 2 processes: 2 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@andrejlevkovitch, can you try with GCC 4.8 and Let us know if that resolves your issue. Thanks!", "@gadagashwini you mean use nvcc based on gcc4.8? ", "> @gadagashwini you mean use nvcc based on gcc4.8?\r\n\r\nYes. Please see the [tested build configurations](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "@andrejlevkovitch, Were you able to resolve this? Thanks!", "@gadagashwini unfortunately no, because I can not get nvcc based on gcc4.8. But, I sow tensorflow can be builded with [clang](https://www.tensorflow.org/install/source#tested_build_configurations), which uses for build with gpu support. So now I wanna try compile tensorflow with latest clang (9.0), with support cuda10", "@andrejlevkovitch, Did you build the Tensorflow with CUDA support. Thanks!", "@gadagashwini No. I load latest `clang` (`9`), install latest `CUDA` (`10.1`) with `CuDNN` (`7`), but after configuring I have error:\r\n\r\n```\r\nERROR: /tmp/tensorflow_dir/tensorflow/c/BUILD:92:1: Illegal ambiguous match on configurable attribute \"copts\" in //tensorflow/c:c_api:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nERROR: Analysis of target '//tensorflow:libtensorflow_cc.so' failed; build aborted: \r\n\r\n/tmp/tensorflow_dir/tensorflow/c/BUILD:92:1: Illegal ambiguous match on configurable attribute \"copts\" in //tensorflow/c:c_api:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nINFO: Elapsed time: 14.358s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (21 packages loaded, 72 targets co\\\r\nnfigured)\r\n```\r\n\r\nWhile configuring I set `clang` as cuda compiler, not `nvcc`. Compilation start by:\r\n```\r\nbazel build --config=v2 --config=cuda //tensorflow:libtensorflow_cc.so\r\n```", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33211\">No</a>\n"]}, {"number": 33210, "title": "Error using TensorBoard callback with histogram_freq > 0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): installed with pip \r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: Python 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda_10.1.243_426.00_win10, cudnn-10.1-windows10-x64-v7.6.3.30\r\n- GPU model and memory: GeForce GTX 1060, 6GB dedicated\r\n\r\n**Describe the current behavior**\r\nThe code in the section bellow results in an error on this line:\r\nhttps://github.com/tensorflow/tensorflow/blob/025365a736ed10185c1a68c2c896cf5c54b9f69f/tensorflow/python/keras/callbacks_v1.py#L385\r\n\r\nThe test_function does not have fetch_callbacks defined. The error I get is:\r\n```Python\r\ntensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks_v1.py\", line 386, in on_epoch_begin\r\n    self.merged] = self._fetch_callback\r\nAttributeError: 'Function' object has no attribute 'fetch_callbacks'\r\n```\r\n**Describe the expected behavior**\r\nThere should be no error. The code works only when ```histogram_freq=0```\r\n**Code to reproduce the issue**\r\n```python \r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom keras.layers import Input, Dense\r\nfrom keras.models import Model\r\n\r\nfrom keras.optimizers import SGD\r\n\r\nnum_features = 100\r\ntrain_x = np.random.rand(40, num_features)\r\ntrain_y = np.random.randint(2, size=40)\r\n\r\n# The input layer\r\ninput_layer = Input(shape=(num_features,), name=\"Input\")\r\noutput = Dense(10, activation='sigmoid', name=\"Hidden_1\")(input_layer)\r\noutput = Dense(1, activation='sigmoid', name=\"Output\")(output)\r\nmodel = Model(inputs=input_layer, outputs=output)\r\n\r\nsgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\r\nmodel.compile(loss='binary_crossentropy',\r\n                     optimizer=sgd,\r\n                      metrics=['accuracy'])\r\n\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\r\n            log_dir=os.path.join(\"out_dir\", datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\r\n            histogram_freq=2, write_graph=True, write_images=True)\r\nmy_callbacks = [tensorboard_callback]\r\n\r\nmodel.fit(x=train_x, y=train_y,\r\n                  validation_split=.2,\r\n                  epochs=5,\r\n                  callbacks=my_callbacks)\r\n```\r\n**Other info / logs**\r\nmodel summary \r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nInput (InputLayer)           (None, 100)               0         \r\n_________________________________________________________________\r\nHidden_1 (Dense)             (None, 10)                1010      \r\n_________________________________________________________________\r\nOutput (Dense)               (None, 1)                 11        \r\n=================================================================\r\nTotal params: 1,021\r\nTrainable params: 1,021\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```", "comments": ["Looks like code is incomplete.In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "> \r\n> \r\n> Looks like code is incomplete.In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!\r\n\r\nI have added a small toy code that replicates the error on my system. Thanks for looking into this.", "I have tried on colab with TF version 1.14.0 ,1.15.0-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/265376b981cca3cbf9a56bfb0e9cbd72/untitled267.ipynb).Thanks!", "@agchitu I do not see this issue with 2.2.0-rc2. here is a [colab gist](https://colab.research.google.com/gist/goldiegadde/b7d420eac7eb255b0867dc01ef242710/github-issue-33210.ipynb) of the same, can you please take a look and close if this is resolved ?", "@agchitu This was also resolved in `TF1.15.2`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/9e5b51ae2ce340597321dedb4e8913e0/untitled95.ipynb). \r\n\r\nPlease verify once and close the issue. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33210\">No</a>\n"]}, {"number": 33209, "title": "KMP_AFFINITY problem when doing import from keras (backend: TF) and using sklearn", "body": "Have a problem when doing import from keras (backend: TensorFlow) and using sklearn.preprocessing.StandardScaler\r\ndetails:\r\nWindows10\r\nTensorFlow 1.14 (working with CPU)\r\nkeras 2.2.4\r\npycharm 2019.2.2 (community edition)\r\n\r\n\r\nTo reproduce:\r\nRun(python)-\r\n`from sklearn.preprocessing import StandardScaler`\r\n`import numpy as np`\r\n`from keras.models import Sequential`\r\n`A = np.random.rand(4001,2)`\r\n`scaler = StandardScaler()`\r\n`scaler.fit(X=A)`\r\n`B = scaler.transform(A)`\r\n\r\nResuls:\r\n1. if `from keras.models import Sequential` removed works fine.\r\n2. if the sized of `A` reduce (for 4000 x 2 as example) works fine.\r\n3. else the last step `B = scaler.transform(A)` resulted with-\r\n> Using TensorFlow backend.\r\n> OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\r\n> OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\r\n> OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\r\n> OMP: Info #156: KMP_AFFINITY: 8 available OS procs\r\n> OMP: Info #157: KMP_AFFINITY: Uniform topology\r\n> OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\r\n> OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\r\n> OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 0 thread 1 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 1 thread 0 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 2 thread 0 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 2 thread 1 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 3 thread 0 \r\n> OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \r\n> OMP: Info #250: KMP_AFFINITY: pid 17364 tid 16076 thread 0 bound to OS proc set 0\r\n", "comments": ["I ran code in python Jupyter Notebook in Anaconda Environment and it works fine for me. Can you be more specific about where is the problem coming?\r\n", "These Info messages arose when running the last command `B = scaler.transform(A)` \r\ndetails:\r\nWindows10\r\nTensorFlow 1.14 (working with CPU)\r\nkeras 2.2.4\r\npycharm 2019.2.2 (community edition)\r\nAnaconda 2018.12\r\nPython 3.6\r\nscipy 1.2.1\r\nsklearn 0.21.2\r\n\r\nWhat other information would be useful?", "@idohi ,\r\nWhen tried executing the code in colab for latest version TF-1.15rc3 and TF-1.14, it worked fine without any issues. Take a look at [gist](https://colab.sandbox.google.com/gist/oanush/6289916ffe824317e0295ec57f774524/33209.ipynb) of colab.Thanks!", "@oanush ,\r\nRunning on colab works fine for me, but the issue is occur on the environment of my computer.", "@idohi I think this is not related to Tensorflow.\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33208, "title": "implementation of VariableOp", "body": "I have question of implementation of VariableOp.  I see it find op_kernel's name when every Compute.\r\nWhy do not save var as member variable in object?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 33207, "title": "compile tensorflow r1.14 with tensorrt error", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos 7.3\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:1.14\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):6.5\r\n- CUDA/cuDNN version:10.0/7.6.1\r\n- GPU model and memory:tesla V100\r\n\r\n\r\n\r\n**Describe the problem**\r\nTensorrt 5.1.5\r\nnccl 2.4.8\r\nwhen i compile tensorflow use  ./configure ,the log is bellow:\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]:\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:\r\n\r\n\r\nPlease specify the TensorRT version you want to use. [Leave empty to  default to TensorRT 5\r\n\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Leave empty to use http\r\n\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and header\r\n\r\n\r\nCould not find any NvInferVersion.h matching version '5' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\nof:\r\n        '/lib64'\r\n        '/usr'\r\n        '/usr/lib64/dyninst'\r\n        '/usr/local/cuda'\r\n        '/usr/local/cuda-10.0/targets/x86_64-linux/lib'\r\nAsking for detailed CUDA configuration...\r\n\r\n\r\n\r\nare some versions wrong\uff1f \r\n", "comments": ["@ltm920716, Just to verify, Did you set the path of TensorRT and NCCL during ./configure. Thanks!", "> @ltm920716, Just to verify, Did you set the path of TensorRT and NCCL during ./configure. Thanks!\r\n\r\nThanks", "I met same issue ! how did you solve it? @ltm920716 ", "> I met same issue ! how did you solve it? @ltm920716\r\nI alose met the same issue, have you solved the problem?\r\n", "I was having the same issue. The crux of my problem was that the error message says the configuration was looking for `NvInferVersion.h`, which I couldn't find anywhere (using `locate NvInferVersion.h`). I looked into the configuration and it seems it tries to find `NvInferVersion.h` *after failing to find* `NvInfer.h`.\r\n```python\r\n\r\n  try:\r\n    header_path, header_version = _find_header(base_paths, \"NvInfer.h\",\r\n                                               required_version,\r\n                                               get_header_version)\r\n  except ConfigError:\r\n    # TensorRT 6 moved the version information to NvInferVersion.h.\r\n    header_path, header_version = _find_header(base_paths, \"NvInferVersion.h\",\r\n                                               required_version,\r\n                                               get_header_version)\r\n```\r\n\r\nThus, all I needed to do was pass the correct path to `NvInfer,h`, which can be found using `locate NvInfer.h`. I thought I had done this already, but alas, I had not...\r\n\r\nFWIW, Building for TensorRT 5, cuDNN 7, and CUDA 10.0 on Ubuntu 16.04, this is my full list of paths: \r\n```\r\n/usr/local/cuda-10.0/targets/x86_64-linux/include/,/usr/local/cuda-10.0/targets/x86_64-linux/lib/,/usr/local/cuda-10.0/bin/,/usr/local/cuda-10.0/,/usr/include/,/usr/lib/x86_64-linux-gnu/,/usr/include/x86_64-linux-gnu/\r\n```\r\n\r\n"]}, {"number": 33206, "title": "Importerror when installing costum tf whl in conda environment", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip & conda\r\n- Bazel version (if compiling from source): 0.26.0\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.8)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nI cannot import tensorflow module in a conda virtual environment (Python 3.7) after installing a costum whl-package with pip of tensorflow 2.0.0.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFollowed the building from source steps [here](https://www.tensorflow.org/install/source):\r\n1. Created a new conda python 3.7 environment and installed: pip six numpy wheel setuptools mock 'future>=0.17.1' keras_applications keras_preprocessing\r\n2. Ran configure and set python paths to my new conda env\r\n3. Build pip-package with some CPU flags found [here](https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide):\r\n```shell \r\nbazel --output_user_root=/Codes/bazel/TensorFlow_2.0.0_pip_package build --jobs=8 --config=mkl -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512er --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n4. Create whl-package\r\n```shell\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package .\r\n```\r\n\r\n5. Installed package in conda environment using pip:\r\n```\r\nconda activate TensorFlow_2.0.0\r\npip install --upgrade Codes/tensorflow/tensorflow-2.0.0-cp37-cp37m-macosx_10_9_x86_64.whl\r\n```\r\n6. Ran simple import command to test installation:\r\n```\r\npython -c \"import tensorflow as tf\"\r\n```\r\nAnd here occurs the error, that it cannot find a module named tensorflow", "comments": ["Sorry, but we don't provide support for issues with the conda environment.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33206\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33206\">No</a>\n", "I found some to time to recreate the issue with \"virtualenv\":\r\n\r\n```bash\r\npip3 install virtualenv\r\nvirtualenv TensorFlow_2.0\r\nsource TensorFlow_2.0/bin/activate\r\npip install tensorflow_2.whl\r\npython -c \"import tensorflow\"\r\n```\r\n\r\nRunning the last command simply results in an error message: \"Illegal instruction:4\"\r\nEven installing it in my default python3 directory results in the same issue. Therefore this must be an issue on the tensorflow side and this issue should be reopened!", "@jbissantz, Does your CPU supports AVX instruction set or not. ", "> @jbissantz, Does your CPU supports AVX instruction set or not.\r\n\r\nApparently yes, because every time I run a tf application in python (conda installed pkg) or C++ (build from source with no FLAGS) I get the following line printed to my console:\r\n![image](https://user-images.githubusercontent.com/56394934/68287854-b2e09580-0083-11ea-8cf8-66d80ec1c117.png)\r\n"]}, {"number": 33205, "title": "tf.GradientTape() can't train custom subclassing model.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0, 7.6\r\n- GPU model and memory: 8G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI tried to make my custom model inherited from tf.keras.Model and I want to training this model by using tf.GradienTape(). \r\n\r\nBut it can't train my model. Loss keeps same values for training and isn't reduced.\r\nHowever, model.complie() and model.fit() with same criterion and optimizer work well for my custom model.\r\nI don't understand why does this situation happen. Which part is problem?\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ncfg_imagenet = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\r\ncfg_cifar = [64, 128, 128, 256, 256, 512, 512, 512, 512, 512, 512, 1024, 1024]\r\n\r\nclass MobileNet(tf.keras.Model):\r\n    def __init__(self, data_format='channels_last'):\r\n        super(MobileNet, self).__init__()\r\n        self.channel_axis = 1 if data_format == 'channels_last' else -1\r\n        self.initializer = tf.keras.initializers.he_normal()\r\n\r\n        self.features = self._make_layers()\r\n        self.classifier = tf.keras.layers.Dense(10, kernel_initializer='he_normal')\r\n\r\n    def _make_layers(self):\r\n        layers = []\r\n        layers.append(tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, padding='same', name='conv1',\r\n                      kernel_initializer=self.initializer))\r\n        layers.append(tf.keras.layers.BatchNormalization(axis=self.channel_axis, name='conv1_bn'))\r\n        layers.append(tf.keras.layers.ReLU(name='conv1_relu'))\r\n        for idx, x in enumerate(cfg_imagenet):\r\n            i = idx + 1\r\n            filters = x if isinstance(x, int) else x[0]\r\n            strides = 1 if isinstance(x, int) else x[1]\r\n            layers.append(tf.keras.layers.DepthwiseConv2D((3, 3), strides, padding='same', kernel_initializer=self.initializer, name='block{}_dw'.format(i)))\r\n            layers.append(tf.keras.layers.BatchNormalization(axis=self.channel_axis, name='block{}_bn1'.format(i)))\r\n            layers.append((tf.keras.layers.ReLU(name='block{}_relu1'.format(i))))\r\n            layers.append(tf.keras.layers.Conv2D(filters, 1, padding='same', activation='relu', kernel_initializer=self.initializer, name='block{}_pw'.format(i)))\r\n            layers.append(tf.keras.layers.BatchNormalization(axis=self.channel_axis, name='block{}_bn2'.format(i)))\r\n            layers.append((tf.keras.layers.ReLU(name='block{}_relu2'.format(i))))\r\n        layers.append(tf.keras.layers.GlobalAveragePooling2D())\r\n        return layers\r\n\r\n    def call(self, input_tensor):\r\n        x = input_tensor\r\n        for layer in self.features:\r\n            x = layer(x)\r\n        x = self.classifier(x)\r\n        return x\r\n\r\ncriterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n\r\ndef loss_func(model, x, y):\r\n    y_ = model(x)\r\n    return criterion(y, y_)\r\n\r\ndef grad(model, inputs, targets):\r\n    with tf.GradientTape() as tape:\r\n        loss_value = loss_func(model, inputs, targets)\r\n    return loss_value, tape.gradient(loss_value, model.trainable_variables)\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\r\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\r\nfor epoch in range(10):\r\n    train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\r\n    for x, y in train_dataset:\r\n        loss_value, grads = grad(model, x, y)\r\n        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\r\n        train_acc(y, model(x))\r\n        print(loss_value)\r\n        print(train_acc.result())\r\n    print(epoch, \"complete\")\r\n```\r\n\r\n\r\n", "comments": ["@jyh2378 ,\r\nWhen i tried running the given code, i got the output , kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/46ccc51b036859ff3fc97cb5d120380f/33205.ipynb) of colab. Can you provide complete code to reproduce the issue mentioned here?Thanks!", "@oanush \r\nI've got the answer of this problem. I didn't give the parameter \"training=True\" to BatchNorm layers.\r\nSo the model was trained except parameters of BatchNorm layers. When I fixed this part, the model was trained well."]}, {"number": 33204, "title": "TypeError: can't pickle _thread.RLock objects", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: Python 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version 10.1 \r\n- GPU model and memory: GeForce GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nI'm using GridSearchCV from sklearn\r\nWhen I start the training process finishes with `TypeError: can't pickle _thread.RLock objects`\r\n\r\n**Describe the expected behavior**\r\nNo error, working `grid.fit(train_X, train_Y)`\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow\r\nfrom tensorflow.compat.v2.keras.layers import *\r\nfrom tensorflow.compat.v2.keras.models import Model\r\nfrom tensorflow.compat.v2.keras.optimizers import *\r\nfrom tensorflow.compat.v2.keras.preprocessing import image\r\nfrom tensorflow.compat.v2.keras.wrappers.scikit_learn import KerasClassifier\r\nimport numpy as np\r\nfrom sklearn.model_selection import GridSearchCV\r\n\r\ndef loadImages(path):\r\n    data = []\r\n    for img_name in os.listdir(path):\r\n        img = image.load_img(path + img_name, target_size=(512, 512, 1))\r\n        img = image.img_to_array(img)\r\n        img = img / 255\r\n        data.append(img)\r\n    return np.array(data)\r\n\r\nif __name__ == \"__main__\":\r\n    batch_size = 4\r\n    train_frame_path = '/data/segmentation/train_frames/'\r\n    train_mask_path = '/data/segmentation/train_masks/'\r\n[segmentation_training.txt]\r\n\r\n    train_X = loadImages(train_frame_path)\r\n    train_Y = loadImages(train_mask_path)\r\n\r\n    m = unet()\r\n    model = KerasClassifier(build_fn=m, epochs=25, batch_size=batch_size, verbose=0)\r\n\r\n    optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n    param_grid = dict(optimizer=optimizer)\r\n    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\r\n    grid_result = grid.fit(train_X, train_Y)\r\n```\r\n\r\nHere there is the full code [segmentation_training.txt](https://github.com/tensorflow/tensorflow/files/3712133/segmentation_training.txt)\r\n\r\n**Other info / logs**\r\n```\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/vlongoba/singularity/testForRadio/jackzen.py\", line 120, in gridSearch\r\n    grid_result = grid.fit(train_X, train_Y)\r\n  File \"/home/vlongoba/singularity/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 633, in fit\r\n    base_estimator = clone(self.estimator)\r\n  File \"/home/vlongoba/singularity/.local/lib/python3.6/site-packages/sklearn/base.py\", line 64, in clone\r\n    new_object_params[name] = clone(param, safe=False)\r\n  File \"/home/vlongoba/singularity/.local/lib/python3.6/site-packages/sklearn/base.py\", line 55, in clone\r\n    return copy.deepcopy(estimator)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.RLock objects\r\n\r\n```", "comments": ["Do you know what the model architecture is defined in unet()?\r\n\r\nI'm not 100% sure about sklearn's gridsearch algorithm, but usually this kind of algorithm involves saving temporary best model to disk. However, tensorflow does't support saving Keras' Lambda Layer at the moment. So if unet() includes a Lambda layer, the error will be raised.", "@alexshade15, Please provide the necessary supporting files to reproduce the reported issue.  Thanks!", "> Do you know what the model architecture is defined in unet()?\r\n> \r\n> I'm not 100% sure about sklearn's gridsearch algorithm, but usually this kind of algorithm involves saving temporary best model to disk. However, tensorflow does't support saving Keras' Lambda Layer at the moment. So if unet() includes a Lambda layer, the error will be raised.\r\n\r\nThis is the unet() model, there are no Lambda Layers:\r\n```\r\ndef unet(pretrained_weights=None, input_size=(512, 512, 1)):\r\n    inputs = Input(input_size)\r\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\r\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\r\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\r\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\r\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\r\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\r\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\r\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\r\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\r\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\r\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\r\n    drop4 = Dropout(0.5)(conv4)\r\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\r\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\r\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\r\n    drop5 = Dropout(0.5)(conv5)\r\n    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal' (UpSampling2D(size=(2, 2))(drop5))\r\n    merge6 = concatenate([drop4, up6], axis=3)\r\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\r\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\r\n    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\r\n    merge7 = concatenate([conv3, up7], axis=3)\r\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\r\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\r\n    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\r\n    merge8 = concatenate([conv2, up8], axis=3)\r\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\r\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\r\n    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\r\n    merge9 = concatenate([conv1, up9], axis=3)\r\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\r\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\r\n    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\r\n    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\r\n    m = Model(inputs=inputs, outputs=conv10)\r\n    m.compile(optimizer=SGD(lr=0.015), loss='binary_crossentropy', metrics=['accuracy'])\r\n    return m\r\n```", "> @alexshade15, Please provide the necessary supporting files to reproduce the reported issue. Thanks!\r\n\r\nHere there is the dataset that I've used \r\nhttps://drive.google.com/file/d/1rGOUBJIvNp03x7qJP_PtsLNXtMLWYo6X/view?usp=sharing\r\n\r\n", "@alexshade15, Thanks for the complete code. I could replicate the issue on Colab. Please see the [gist](https://colab.sandbox.google.com/gist/gadagashwini/0c02bf54f77e41d7833ec5c563e9447d/untitled196.ipynb). Looks like issue is more related to scikit learn gridsearch. Can you confirm. Thanks!", "Yes, the issue is the same and it seems to be related to scikit learn gridsearch. Thank you.", "@alexshade15, Can you post this issue in relevant repo for better and faster resolution. We can close this issue. Thanks! ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I am having the same issue with\r\n```\r\ndef build_model():\r\n    model = keras.Sequential([\r\n        layers.Dense(24, activation='relu', input_shape=[len(features)]),\r\n        layers.Dense(12, activation='relu'),\r\n        layers.Dense(1)\r\n    ])\r\n    optimizer = tf.keras.optimizers.RMSprop(0.001)\r\n    model.compile(loss='mse',\r\n                    optimizer=optimizer,\r\n                    metrics=['mae', 'mse'])\r\n    return model\r\n\r\nmodel = KerasRegressor(build_model())\r\n\r\npipeline = Pipeline(steps=[ ('nn', model)])\r\n\r\ngs = GridSearchCV(estimator=pipeline, param_grid=params,\r\n                  n_jobs=1, return_train_score=True, scoring='r2');\r\n```", "@iegorval, Can you open new issue and provide the information asked in template. Thanks!", "It's crazy this is still an issue, still cannot perform any kind of gridsearchcv on AWS ubuntu.\r\n\r\nNot even with n_jobs=1", "I can\u00b4t believe there is no fix for this anywhere... I\u00b4m almost doing my own implementation of grid search... I can\u00b4t believe how much time I already wasted trying to fix it", "I just figured it out, the build_fn can\u00b4t be a method from an instance, but I don\u00b4t know why, probably a pickle serialization issue", "> I just figured it out, the build_fn can\u00b4t be a method from an instance, but I don\u00b4t know why, probably a pickle serialization issue\r\n\r\nI am having the same issue. Can you please elaborate how you fix it?", "The method that creates the model that I was passing to the gridsearch was inside a class, it cannot be ( apparently ) so I made a method outside the class and it worked... But I have no idea why this happened, I just figured I should try a method outside of a class and it worked \ud83e\udd37", "@badjano \r\nI am having the same issue. Can you please elaborate on how you fix it?\r\non this collab notebook :\r\nhttps://colab.research.google.com/drive/11s0YWZrhP9s6pL1w4uTSvvDFGAQMNfTy?usp=sharing\r\n", "> @badjano\r\n> I am having the same issue. Can you please elaborate on how you fix it?\r\n> on this collab notebook :\r\n> https://colab.research.google.com/gist/gadagashwini/0c02bf54f77e41d7833ec5c563e9447d/untitled196.ipynb\r\n\r\nThank you!! I got that work too!", "@shakewingo  thank you so much.\r\nif you can fix it on this collab notebook, please\r\n\r\nhttps://colab.research.google.com/drive/11s0YWZrhP9s6pL1w4uTSvvDFGAQMNfTy?usp=sharing", "I had the same question\uff0cmaybe you can try to You can try to replace \r\nmodel = KerasClassifier(build_fn=m, epochs=25, batch_size=batch_size, verbose=0)\r\nwith\r\nmodel = KerasClassifier(build_fn=unet, epochs=25, batch_size=batch_size, verbose=0)\uff0c\r\nthis work for me", "@wangxiaoshuai223  thanks so much  you are right\r\n", "I encountered the same error while using `from multiprocessing.dummy import Pool as ThreadPool`\r\n\r\nThis can be reproduced using:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\n\r\nfrom multiprocessing import Pool\r\nfrom multiprocessing.dummy import Pool as ThreadPool\r\nfrom functools import partial\r\n\r\ndef simple_model():\r\n    model = keras.models.Sequential([\r\n        keras.layers.Dense(units = 10, input_shape = [1]),\r\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\r\n    ])\r\n    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\r\n    return model\r\n\r\ndef clone_model(model):\r\n    model_clone = tf.keras.models.clone_model(model)\r\n    model_clone.set_weights(model.get_weights())\r\n    return model_clone\r\n\r\ndef work(model, seq):\r\n    return model.predict(seq)\r\n\r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,100).reshape(n, -1)\r\n    pool = Pool()\r\n    # model_list = [clone_model(model) for _ in range(n)]\r\n    # results = pool.map(work, zip(model_list,seqences))\r\n    partial_work = partial(work, model=model)\r\n    results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n    \r\n    return np.reshape(results, (-1, ))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = simple_model()\r\n    out = worker(model, n=4)\r\n    print(out)\r\n```", "@wangxiaoshuai223 I meet a same issue. Thank you so much!! u are right."]}, {"number": 33203, "title": "Memory leak", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version:3.7\r\n- CUDA/cuDNN version: 10.0/7.4\r\n- GPU model and memory: 1060 6GB\r\n\r\nTell me how to run the code on TF 2.0?\r\nThe problem arises only in the second era, as if the memory of the GPU is not cleared.\r\nThe first version helps\r\n`tf.keras.backend.get_session().run(tf.global_variables_initializer())`\r\nCode\r\nhttps://github.com/sgenza/keras_crnn\r\n", "comments": ["@sonfiree, Please provide the minimal standalone code to reproduce the issue reported here. Indeed, it will help us to investigate the root cause. Thanks! ", "> @sonfiree, Please provide the minimal standalone code to reproduce the issue reported here. Indeed, it will help us to investigate the root cause. Thanks!\r\n\r\nhttps://github.com/sgenza/keras_crnn", "https://github.com/tensorflow/tensorflow/issues/33178", "@sonfiree, Please provide more information on reproducing the issue. I cloned your repo but there is no description for how to use the repo. Thanks!", "Duplicate of #33178 (in lack of reproducer being provided here, OP pointed to duplicate)"]}, {"number": 33202, "title": "[TF-1.0] RecursionError: maximum recursion depth exceeded", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.2 LTS (Docker)\r\n- **TensorFlow installed from (source or binary)**: Binary, conda\r\n- **TensorFlow version (use command below)**: unknown 1.14.0\r\n- **Python version**: Python 3.7.3\r\n- **CUDA/cuDNN version**: CUDA=10.0, CUDNN=7.4.1.5-1\r\n- **GPU model and memory**: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.77\r\n\r\n### Describe the problem\r\nThe code below produces a `RecursionError` in TF-1.0 presumably because of the large Dataset. The error does not occur for much smaller values in the `n_files` variable. The error does also not occur in TF-2.0!\r\n\r\n**Describe the expected behavior**\r\nNo error, working `model.fit()`\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# TF-2.0\r\n# gpus = tf.config.experimental.list_physical_devices('GPU')\r\n# for gpu in gpus:\r\n#     tf.config.experimental.set_memory_growth(gpu, True)\r\n# #tf.debugging.set_log_device_placement(True)\r\n\r\n# TF-1.0\r\ntf.compat.v1.enable_eager_execution()\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\n#config.log_device_placement = True\r\nsess = tf.compat.v1.Session(config=config)\r\ntf.compat.v1.keras.backend.set_session(sess)\r\n\r\nassert tf.executing_eagerly()\r\n\r\nbatch_size = 256\r\nnum_tsteps = 144\r\nnum_features = 130\r\nnum_units = 88\r\n\r\nn_files = 3320\r\n#n_files = 10\r\nnum_epochs = 1000\r\n\r\nseq_len_max_trunc = batch_size * num_tsteps\r\nflen = 3728\r\n\r\nX = np.random.rand(flen + 1, num_features + 2)\r\nn_label0 = int((flen + 1) * 0.2)\r\nY = np.concatenate((\r\n    np.zeros((n_label0, 1)), # label 0\r\n    np.ones((flen - n_label0 + 1, 1)), # label 1\r\n), axis=0)\r\nds_out = tf.data.Dataset.from_tensor_slices((X, Y))\r\nds_ser = ds_out.map(lambda *x: \r\n   tf.reshape(tf.py_function(lambda *v: \r\n       tf.train.Example(features=tf.train.Features(feature={\r\n           \"features\": tf.train.Feature(float_list=tf.train.FloatList(value=v[0].numpy())),\r\n           \"label\": tf.train.Feature(float_list=tf.train.FloatList(value=v[1].numpy())),\r\n       })).SerializeToString(), x, tf.string\r\n   ), ()), num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n)\r\nwriter = tf.data.experimental.TFRecordWriter(\"temp.tfrecord\")\r\nwriter.write(ds_ser)\r\n\r\nfiles = [\"temp.tfrecord\"] * n_files\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.InputLayer(input_shape=(num_tsteps, num_features), batch_size=batch_size),\r\n    #tf.keras.layers.Masking(mask_value=0.0, input_shape=(num_tsteps, num_features)),\r\n    tf.keras.layers.LSTM(num_units,  batch_input_shape=(batch_size, num_tsteps, num_features), return_sequences=True, stateful=False),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)),\r\n    tf.keras.layers.Activation('sigmoid'),\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\n\r\ndef _prep_ds_file(file):\r\n    _ds = tf.data.TFRecordDataset(file)\r\n    _ds = _ds.map(lambda x: tf.io.parse_single_example(x, {\r\n        \"features\": tf.io.FixedLenFeature([132], tf.float32),\r\n        \"label\": tf.io.FixedLenFeature([1], tf.float32),\r\n    }), num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        \r\n    _ds = _ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])))\r\n\r\n    _trunc = min(seq_len_max_trunc, ((flen + 1) // num_tsteps) * num_tsteps)\r\n    _ds = _ds.take(_trunc)\r\n\r\n    _c_pad = (batch_size - ((flen + 1) // num_tsteps)) * num_tsteps\r\n    if _c_pad >= 0:\r\n        assert _c_pad + ((flen + 1) // num_tsteps * num_tsteps) == seq_len_max_trunc\r\n        _ds_pad = tf.data.Dataset.from_tensors((\r\n            tf.constant(0.0, shape=[num_features,]),\r\n            tf.constant(0.0, shape=[1,])))\r\n        _ds_pad = _ds_pad.repeat(_c_pad)\r\n        _ds = _ds.concatenate(_ds_pad) # pad to correct size\r\n\r\n    _ds = _ds.window(size=num_tsteps, shift=None, stride=1, drop_remainder=True)\r\n    _ds = _ds.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(num_tsteps), y.batch(num_tsteps))))\r\n\r\n    _ds = _ds.batch(batch_size, drop_remainder=True)\r\n    \r\n    return _ds\r\n\r\n\r\nds_fs = tf.data.Dataset.list_files(files, shuffle=True, seed=1)\r\nfs_train = ds_fs.take(int(n_files * 0.7))\r\nfs_val = ds_fs.skip(int(n_files * 0.7)).take(int(n_files * 0.1))\r\n\r\nds_train = [_prep_ds_file(f) for f in fs_train.take(1)][0]\r\nfor f in fs_train.skip(1):\r\n    ds_train = ds_train.concatenate(_prep_ds_file(f))\r\nds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\nds_val = [_prep_ds_file(f) for f in fs_val.take(1)][0]\r\nfor f in fs_val.skip(1):\r\n    ds_val = ds_val.concatenate(_prep_ds_file(f))\r\nds_val = ds_val.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\ncbs = [\r\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\r\n]\r\nmodel.fit(ds_train, epochs=num_epochs, verbose=1, shuffle=False,\r\n          validation_data=ds_val, validation_steps=None, callbacks=cbs)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW1010 10:35:45.397222 140253093480256 deprecation.py:323] From /ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n\r\n\r\nRecursionErrorTraceback (most recent call last)\r\n<ipython-input-1-c18884a831b5> in <module>\r\n    109 ]\r\n    110 model.fit(ds_train, epochs=num_epochs, verbose=1, shuffle=False,\r\n--> 111           validation_data=ds_val, validation_steps=None, callbacks=cbs)\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    692           workers=0,\r\n    693           shuffle=shuffle,\r\n--> 694           initial_epoch=initial_epoch)\r\n    695 \r\n    696     # Case 3: Symbolic tensors or Numpy array-like.\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1431         shuffle=shuffle,\r\n   1432         initial_epoch=initial_epoch,\r\n-> 1433         steps_name='steps_per_epoch')\r\n   1434 \r\n   1435   def evaluate_generator(self,\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\r\n    142       batch_size=batch_size,\r\n    143       epochs=epochs - initial_epoch,\r\n--> 144       shuffle=shuffle)\r\n    145 \r\n    146   do_validation = validation_data is not None\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py in convert_to_generator_like(data, batch_size, steps_per_epoch, epochs, shuffle)\r\n    475     return data, steps_per_epoch\r\n    476   if isinstance(data, dataset_ops.DatasetV2):\r\n--> 477     return dataset_ops.make_one_shot_iterator(data), steps_per_epoch\r\n    478 \r\n    479   # Create generator from NumPy or EagerTensor Input.\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in make_one_shot_iterator(dataset)\r\n   1940     # Call the defined `_make_one_shot_iterator()` if there is one, because some\r\n   1941     # datasets (e.g. for prefetching) override its behavior.\r\n-> 1942     return dataset._make_one_shot_iterator()  # pylint: disable=protected-access\r\n   1943   except AttributeError:\r\n   1944     return DatasetV1Adapter(dataset)._make_one_shot_iterator()  # pylint: disable=protected-access\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _make_one_shot_iterator(self)\r\n   1525   def _make_one_shot_iterator(self):  # pylint: disable=missing-docstring\r\n   1526     if context.executing_eagerly():\r\n-> 1527       return iterator_ops.IteratorV2(self)\r\n   1528 \r\n   1529     _ensure_same_dataset_graph(self)\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __init__(self, dataset)\r\n    562     with ops.device(\"/cpu:0\"):\r\n    563       # pylint: disable=protected-access\r\n--> 564       dataset = dataset._apply_options()\r\n    565       ds_variant = dataset._variant_tensor\r\n    566       self._structure = dataset._element_structure\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _apply_options(self)\r\n    230 \r\n    231     dataset = self\r\n--> 232     options = self.options()\r\n    233     if options.experimental_threading is not None:\r\n    234       t_options = options.experimental_threading\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n   1888 \r\n   1889   def options(self):\r\n-> 1890     return self._dataset.options()\r\n   1891 \r\n   1892   @property\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n    221     options = Options()\r\n    222     for input_dataset in self._inputs():\r\n--> 223       input_options = input_dataset.options()\r\n    224       if input_options is not None:\r\n    225         options = options.merge(input_options)\r\n\r\n... last 2 frames repeated, from the frame below ...\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n   1888 \r\n   1889   def options(self):\r\n-> 1890     return self._dataset.options()\r\n   1891 \r\n   1892   @property\r\n\r\nRecursionError: maximum recursion depth exceeded\r\n```", "comments": ["Issue replicating for TF-1.14, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/6e7a780b53967f33cd9bb97f16442e44/33202.ipynb) of colab.Thanks!", "@mimxrt I think this is something related to size of validation dataset that is not enough for validating the loss. Please check these resources [1](https://stackoverflow.com/questions/49035200/keras-early-stopping-callback-error-val-loss-metric-not-available) and [2](https://github.com/keras-team/keras/issues/3657). \r\n\r\nPlease check your data pipeline to find the root-cause. Thanks!\r\n\r\n", "@jvishnuvardhan Thank you for your comment. I provided a demonstration example in my initial comment that includes the data pipeline for your reference. As you can see the example contains 3320 time series files of length 3728 and the batch size is 256. The training dataset is a split of 70% and the validation dataset a split of 10%.\r\n\r\nBe that as is may, you can try to remove the last line of the example and see that the same error occurs even without the validation data and early stopping:\r\n\r\nReplace\r\n```\r\nmodel.fit(ds_train, epochs=num_epochs, verbose=1, shuffle=False,\r\n          validation_data=ds_val, validation_steps=None, callbacks=cbs)\r\n```\r\nwith\r\n```\r\nmodel.fit(ds_train, epochs=num_epochs, verbose=1, shuffle=False,\r\n          validation_data=None, validation_steps=None, callbacks=None)\r\n```\r\n\r\nIn addition to the validation dataset not having any impact, it seems the training itself is entirely unrelated to the error. I created a more condensed example that illustrates that this error is caused by the data pipeline itself as there is no training happening---the dataset is merely iterated:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.enable_eager_execution()\r\n\r\nassert tf.executing_eagerly()\r\n\r\nbatch_size = 256\r\nnum_tsteps = 144\r\nnum_features = 130\r\n\r\nn_files = 3320\r\nflen = 3728\r\n\r\ndef generate_data():\r\n    X = np.random.rand(flen + 1, num_features + 2)\r\n    n_label0 = int((flen + 1) * 0.2)\r\n    Y = np.concatenate((\r\n        np.zeros((n_label0, 1)), # label 0\r\n        np.ones((flen - n_label0 + 1, 1)), # label 1\r\n    ), axis=0)\r\n    ds_out = tf.data.Dataset.from_tensor_slices((X, Y))\r\n    ds_ser = ds_out.map(lambda *x: \r\n       tf.reshape(tf.py_function(lambda *v: \r\n           tf.train.Example(features=tf.train.Features(feature={\r\n               \"features\": tf.train.Feature(float_list=tf.train.FloatList(value=v[0].numpy())),\r\n               \"label\": tf.train.Feature(float_list=tf.train.FloatList(value=v[1].numpy())),\r\n           })).SerializeToString(), x, tf.string\r\n       ), ()), num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n    )\r\n\r\n    writer = tf.data.experimental.TFRecordWriter(\"temp.tfrecord\")\r\n    writer.write(ds_ser)\r\n\r\n\r\ngenerate_data()\r\nfiles = [\"temp.tfrecord\"] * n_files\r\n\r\n\r\ndef _prep_ds_file(file):\r\n    _ds = tf.data.TFRecordDataset(file)\r\n    _ds = _ds.map(lambda x: tf.io.parse_single_example(x, {\r\n        \"features\": tf.io.FixedLenFeature([132], tf.float32),\r\n        \"label\": tf.io.FixedLenFeature([1], tf.float32),\r\n    }), num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        \r\n    _ds = _ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])))\r\n    \r\n    return _ds\r\n\r\n\r\nds_fs = tf.data.Dataset.list_files(files, shuffle=True, seed=1)\r\nfs_train = ds_fs.take(int(n_files * 0.7))\r\n\r\nds_train = [_prep_ds_file(f) for f in fs_train.take(1)][0]\r\nfor f in fs_train.skip(1):\r\n    ds_train = ds_train.concatenate(_prep_ds_file(f))\r\nds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nfor e in ds_train.take(batch_size):\r\n    print(\"The training dataset contains at least {} elements.\".format(batch_size))\r\n\r\nfor i, e in enumerate(ds_train):\r\n    print(i)\r\n    if e > batch_size:\r\n        break\r\n```\r\n\r\nResult:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW1021 08:13:08.382446 140048215897920 deprecation.py:323] From /ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n\r\n\r\nRecursionErrorTraceback (most recent call last)\r\n<ipython-input-1-1fba291fe9fa> in <module>\r\n     59 \r\n     60 \r\n---> 61 for e in ds_train.take(batch_size):\r\n     62     print(\"The training dataset contains at least {} elements.\".format(batch_size))\r\n     63 \r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __iter__(self)\r\n   1895 \r\n   1896   def __iter__(self):\r\n-> 1897     return iter(self._dataset)\r\n   1898 \r\n   1899 \r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __iter__(self)\r\n    285       RuntimeError: If eager execution is not enabled.\r\n    286     \"\"\"\r\n--> 287     return iterator_ops.IteratorV2(self)\r\n    288 \r\n    289   @abc.abstractproperty\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __init__(self, dataset)\r\n    562     with ops.device(\"/cpu:0\"):\r\n    563       # pylint: disable=protected-access\r\n--> 564       dataset = dataset._apply_options()\r\n    565       ds_variant = dataset._variant_tensor\r\n    566       self._structure = dataset._element_structure\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _apply_options(self)\r\n    230 \r\n    231     dataset = self\r\n--> 232     options = self.options()\r\n    233     if options.experimental_threading is not None:\r\n    234       t_options = options.experimental_threading\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n    221     options = Options()\r\n    222     for input_dataset in self._inputs():\r\n--> 223       input_options = input_dataset.options()\r\n    224       if input_options is not None:\r\n    225         options = options.merge(input_options)\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n   1888 \r\n   1889   def options(self):\r\n-> 1890     return self._dataset.options()\r\n   1891 \r\n   1892   @property\r\n\r\n... last 2 frames repeated, from the frame below ...\r\n\r\n/ws/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in options(self)\r\n    221     options = Options()\r\n    222     for input_dataset in self._inputs():\r\n--> 223       input_options = input_dataset.options()\r\n    224       if input_options is not None:\r\n    225         options = options.merge(input_options)\r\n\r\nRecursionError: maximum recursion depth exceeded while calling a Python object\r\n```\r\nCan you confirm this result?", "Please, can anyone confirm this finding? What can I do to help resolve this? Thanks!", "I suspect the issue is that your input pipeline graph is too large which results in Python recusion depth exception. This issue is not unique to tf.data graphs and applies generally to TensorFlow graphs.\r\n\r\nI believe you should be able to overcome your issue by avoiding reliance on `concatenate` and instead of:\r\n\r\n```\r\nds_train = [_prep_ds_file(f) for f in fs_train.take(1)][0]\r\nfor f in fs_train.skip(1):\r\n    ds_train = ds_train.concatenate(_prep_ds_file(f))\r\nds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n```\r\n\r\ndo:\r\n\r\n```\r\nds_train = fs_train.flat_map(_prep_ds_file)\r\nds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n```\r\n", "Thank you @jsimsa, I can confirm the error is resolved by this change. So, can I assume the implementation in TF-2.0 is fundamentally different? Because running the exact same code snippet in TF-2.0 does work just fine. Anyway, closing this issue as the error is fixed by your solution. Thanks again!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33202\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33202\">No</a>\n"]}, {"number": 33201, "title": "Tensorflow 2.0 SavedModel format with GPU acceleration slowdown", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): tensorflow==2.0.0-rc1 (2.0.0rc0-gpu-py3 docker image)\r\n- Python version: 3.5.0\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: TeslaV100 \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI have a SavedModel trained with Tensorflow 2.0 which I use to make an inference as follows: \r\n\r\n```\r\n model= tf.saved_model.load(export_dir = 'path/to/savedmodel/1')\r\n infer = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n outputs = infer(img_tensor)\r\n\r\n```\r\nThe model predicts fast on a CPU but when using a GPU device, it scales linearly and GPU does not offer any advantage. When logging the device placement, I see that GPU is used.\r\n\r\nTo compare, I have the same model trained in Tensorflow 1.13 saved in frozen graph format. I use the model as follows:\r\n```\r\n\r\n   graph = load_graph('path/to/graph.pb')\r\n   labels = load_labels('path/to/labels.txt')\r\n\r\n    input_name = 'import/Placeholder'\r\n    output_name = 'import/final_result'\r\n\r\n    input_operation = graph.get_operation_by_name(input_name)\r\n    output_operation = graph.get_operation_by_name(output_name)\r\n\r\n    # initialize a tensorflow session\r\n    with tf.compat.v1.Session(graph=graph) as sess:\r\n        results = sess.run(\r\n            output_operation.outputs[0],\r\n            {input_operation.outputs[0]: img_array})\r\n\r\n        sess.close()\r\n\r\ndef load_graph(model_file):\r\n    graph = tf.Graph()\r\n    graph_def = tf.compat.v1.GraphDef()\r\n\r\n    with open(model_file, \"rb\") as file:\r\n        graph_def.ParseFromString(file.read())\r\n\r\n    with graph.as_default():\r\n        tf.import_graph_def(graph_def)\r\n\r\n    return graph\r\n\r\n```\r\n\r\nThe timing of this model on GPU in the same environment is much faster than SavedModel format. I think this is a performance issue.\r\n\r\nHere are the timing details:\r\nTF2.0 SavedModel\r\nBatch of 64 images CPU: 23 seconds\r\nBatch of 64 images GPU: 14 seconds\r\n\r\nTF13.0 Frozen Graph:\r\nBatch of 64 images CPU: 25 seconds\r\nBatch of 64 images GPU: 5 seconds\r\n\r\n**Describe the expected behavior**\r\nMy expected behaviour is that Tensorflow 2.0 version with SavedModel would use GPU acceleration. Maybe I am missing on how to import the SavedModel in python. Please let me know what could be the route cause of it.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a minimal standalone code and necessary files to reproduce the issue reported here in our environment.", "@SlavaKeshkov \r\n\r\nAny updates on this issue please.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@SlavaKeshkov \uff0c\r\nHas your problem been solved? Do you know how to use GPU to speed up savedmodel(TF2.0) inference\uff1f"]}, {"number": 33200, "title": "CancelledError: RecvAsync is cancelled during \"fit\" (module 'gast' has no attribute 'Num')", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0 (gpu)\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: v10.1\r\n- GPU model and memory: GTX 970 4GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nDuring \"fit\" of the first batch it gives a CancelledError\r\n\r\n**Describe the expected behavior**\r\nTo \"fit\" without errors\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\ndata: English: (4549, 15)x5687; Afrikaans: (4549, 15)x5982 --- (vsize, timesteps)xsamples\r\nz_train = OneHotEncoder(sparse=False, n_values=af_vsize).fit_transform(y_train[:,1:]).reshape(-1, af_timesteps-1, af_vsize)\r\n\r\nmodel:\r\nencoder_inputs = Input(batch_size=32, shape=(en_timesteps,), name='encoder_inputs')\r\nencoder_embeddings = Embedding(en_vsize, 128)(encoder_inputs)\r\ndecoder_inputs = Input(batch_size=32, shape=(af_timesteps-1,), name='decoder_inputs')\r\ndecoder_embeddings = Embedding(af_vsize, 128, mask_zero=True)(decoder_inputs)\r\nencoder_out, encoder_state = GRU(128, return_sequences=True, return_state=True, name='encoder_gru')(encoder_embeddings)\r\ndecoder_out, decoder_state = GRU(128, return_sequences=True, return_state=True, name='decoder_gru')(decoder_embeddings, initial_state=encoder_state)\r\nattn_out = Attention(name='attention_layer')([decoder_out, encoder_out])\r\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\r\ndense = Dense(af_vsize, activation='softmax', name='softmax_layer')\r\ndense_time = TimeDistributed(dense, name='time_distributed_layer')\r\ndecoder_pred = dense_time(decoder_concat_input)\r\nmodel = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\r\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\nThe error occurs when i run:\r\nh = model.fit([X_train, y_train[:,:-1]], z_train, validation_data=([X_test, y_test[:,:-1]], z_test), epochs=1)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTrain on 4094 samples, validate on 455 samples\r\nWARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002112B520B70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002112B520B70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\n  32/4094 [..............................] - ETA: 9:06\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-17-592a9f974384> in <module>\r\n      1 for i in range(50):\r\n----> 2     h = model.fit([X_train, y_train[:,:-1]], z_train, validation_data=([X_test, y_test[:,:-1]], z_test), epochs=1)\r\n      3     history.append(h.history)\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    518         # Lifting succeeded, so variables are initialized and we can run the\r\n    519         # stateless function.\r\n--> 520         return self._stateless_fn(*args, **kwds)\r\n    521     else:\r\n    522       canon_args, canon_kwds = \\\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node metrics/accuracy/broadcast_weights/assert_broadcastable/AssertGuard/else/_36/Assert/data_4/_92}}]]\r\n\t [[loss/time_distributed_layer_loss/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_1/has_valid_nonscalar_shape/then/_106/has_invalid_dims/concat/_58]] [Op:__inference_distributed_function_13318]\r\n\r\nFunction call stack:\r\ndistributed_function", "comments": ["@Bennie-higuru \r\n\r\nLooks like code is incomplete. In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "I am having the similar issue. I run the same code on my local machine with CPU and Tensorflow 1.14.0. It works fine.  However, when I run it on GPU with Tensorflow 2.0, I get \r\n\r\n```\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_65}}]]\r\n\t [[Reshape_13/_62]] [Op:__inference_distributed_function_3722]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```\r\n\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nprint(tf.__version__)\r\n\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\nbatch_size = 32\r\nnum_obs = 100\r\nnum_cats = 1 # number of categorical features\r\nn_steps = 10 # number of timesteps in each sample\r\nn_numerical_feats = 18 # number of numerical features in each sample\r\ncat_size = 12 # number of unique categories in each categorical feature\r\nembedding_size = 1 # embedding dimension for each categorical feature\r\n\r\nlabels =  np.random.random(size=(num_obs*n_steps,1)).reshape(-1,n_steps,1)\r\nprint(labels.shape)\r\n#(100, 10, 1)\r\n\r\n#3 numerical variable\r\nnum_data = np.random.random(size=(num_obs*n_steps,n_numerical_feats))\r\nprint(num_data.shape)\r\n#(1000, 3)\r\n#Reshaping numeric features to fit into an LSTM network\r\nfeatures = num_data.reshape(-1,n_steps, n_numerical_feats)\r\nprint(features.shape)\r\n#(100, 10, 3)\r\n\r\n#one categorical variables with 4 levels\r\ncat_data = np.random.randint(0,cat_size,num_obs*n_steps)\r\nprint(cat_data.shape)\r\n#(1000,)\r\nidx = cat_data.reshape(-1, n_steps)\r\nprint(idx.shape)\r\n#(100, 10)\r\n\r\nnumerical_inputs = keras.layers.Input(shape=(n_steps, n_numerical_feats), name='numerical_inputs', dtype='float32')\r\n#<tf.Tensor 'numerical_inputs:0' shape=(?, 10, 36) dtype=float32>\r\n\r\ncat_input = keras.layers.Input(shape=(n_steps,), name='cat_input')\r\n#<tf.Tensor 'cat_input:0' shape=(None, 10) dtype=float32>\r\n\r\ncat_embedded = keras.layers.Embedding(cat_size, embedding_size, embeddings_initializer='uniform')(cat_input)\r\n#<tf.Tensor 'embedding_1/Identity:0' shape=(None, 10, 1) dtype=float32>\r\n\r\nmerged = keras.layers.concatenate([numerical_inputs, cat_embedded])\r\n#<tf.Tensor 'concatenate_1/Identity:0' shape=(None, 10, 37) dtype=float32>\r\n\r\nlstm_out = keras.layers.LSTM(64, return_sequences=True)(merged)\r\n#<tf.Tensor 'lstm_2/Identity:0' shape=(None, 10, 64) dtype=float32>\r\n\r\nDense_layer1 = keras.layers.Dense(32, activation='relu', use_bias=True)(lstm_out)\r\n#<tf.Tensor 'dense_4/Identity:0' shape=(None, 10, 32) dtype=float32>\r\nDense_layer2 = keras.layers.Dense(1, activation='linear', use_bias=True)(Dense_layer1 )\r\n#<tf.Tensor 'dense_5/Identity:0' shape=(None, 10, 1) dtype=float32>\r\n\r\nmodel = keras.models.Model(inputs=[numerical_inputs, cat_input], outputs=Dense_layer2)\r\n\r\n#compile model\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\nmodel.compile(loss='mse',\r\n              optimizer=optimizer,\r\n              metrics=['mae', 'mse'])\r\nEPOCHS =5\r\n\r\n#fit the model\r\n#you can use input layer names instead\r\nhistory = model.fit([features, idx], \r\n                    y = labels,\r\n                    epochs=EPOCHS,\r\n                    batch_size=batch_size)\r\n```\r\n", "What is the version of `gast` on your system?\r\n\r\nYou will have to manually `pip install gast==0.2.2`, due to `gast` releasing a backwards incompatible release. See #32383\r\n\r\nThis also duplicates #32949, so closing", "Same error here. It appeared AFTER I had to revert to gast=0.2.2", "Yes, I did it but still having the same issue!\r\n"]}, {"number": 33199, "title": "use tf.saved_model.simple_save get {ValueError}At least two variables have the same name: InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta/ExponentialMovingAverage", "body": "use tf.saved_model.simple_save get {ValueError}At least two variables have the same name: InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta/ExponentialMovingAverage;\r\ntf.saved_model.simple_save(sess,\r\n                                          './models/test_pd3',\r\n                                        inputs={\"input\": x},\r\n                                          outputs={\"output\": output})\r\n\r\n\r\nWhat I don't understand is use graph_util.convert_variables_to_constants saved Success", "comments": ["  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/simple_save.py\", line 90, in simple_save\r\n    clear_devices=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/builder_impl.py\", line 585, in add_meta_graph_and_variables\r\n    saver = self._maybe_create_saver(saver)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/builder_impl.py\", line 223, in _maybe_create_saver\r\n    allow_empty=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 825, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 837, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 875, in _build\r\n    build_restore=build_restore)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 482, in _build_internal\r\n    names_to_saveables)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 335, in validate_and_slice_inputs\r\n    names_to_saveables = op_list_to_dict(names_to_saveables)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 292, in op_list_to_dict\r\n    name)\r\nValueError: At least two variables have the same name: InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta/ExponentialMovingAverage\r\n", "@L-lei ,\r\nCan you share a simple and standalone code to reproduce the issue ? also mention the TF version being used.", "@L-lei ,\r\nAny update on the issue ?Thanks!", " @oanush ,\r\nThank you very much. This does not affect my use\r\n"]}, {"number": 33198, "title": "Tensorflow 2.0, feature_column and input_layer", "body": "Documentation for tf.feature_column like for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file\r\n\r\nuses input_layer, which is not available in v2\r\n```\r\ncolumns = [embedding_column(states, 3),...]\r\nfeatures = tf.io.parse_example(..., features=make_parse_example_spec(columns))\r\ndense_tensor = input_layer(features, columns)\r\n```\r\n", "comments": ["@aszalucha, \r\nThe document which you are referring is related to Tf 2.0. `input_layer` is available in v2. \r\nLet us know if I misunderstood your issue. Thanks!  ", "It is available as a `tf.compat.v1.feature_column.input_layer` so as I understand it is not \"native\" to TF 2.0. Or I misunderstood sth? ", "@aszalucha, `tf.compat.v1.feature_column.input_layer` is available in Tf 2.0. The tf_upgrade_v2 script includes the compat.v1 module. This module replaces Tf 1.x symbols to tf.compat.v1 compatibility module in Tf 2.0. Please refer [this link](https://www.tensorflow.org/guide/upgrade#compatibility_modules) for more info. Thanks!  ", "So that link exactly proves my point \"While the compatibility module is nice, we recommend that you manually proofread replacements and migrate them to new APIs in the tf.* namespace instead of tf.compat.v1 namespace as quickly as possible.\"\r\n\r\nIf documentation recommends to replace` tf.compat.v1.*`, why documentation for TF 2.0 uses those symbols? ", "@aszalucha It is suggested for users who have used TF1.x and are trying to use TF2.x. Once the user get familiarize with TF2.x style, they can use the log generated while conversion to update the codes by replacing `tf.compat.v1.*` with correct symbols. Please read the [migration guide](https://www.tensorflow.org/guide/migrate) for more details. If you face any issues, please post them here. Thanks!\r\n\r\nI am closing the issue. Please open a new issue if you face any conversion related problems.  Thanks!"]}, {"number": 33197, "title": "About a function \uff1a tf.train.slice_input_producer()", "body": "when I use the function \uff1ainput_queue = tf.train.slice_input_producer([image, label]).\r\nA error come to me:AttributeError: module 'tensorflow_core._api.v2.train' has no attribute 'slice_input_producer'\r\n\r\nI want to know how can I solve the problem.\r\n\r\nis there anyone who can help me. \r\n", "comments": ["@Libaididi ,\r\nCan you try using` input_queue = tf.data.Dataset.from_tensor_slices([image, label])` as `tf.train.slice_input_producer` is depreciated in the Latest version? Thanks!", "@Libaididi ,\r\nHi, Any update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "tf.compat.v1.train.slice_input_producer works for me. "]}]