[{"number": 12825, "title": "Update relaxed_onehot_categorical.py", "body": "Fixed: default dtype in class documentation", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks for the fix @lhlmgr!"]}, {"number": 12824, "title": "Apparent Segmentation Violation with Go API", "body": "Hi, I am trying to build a project that will take multiple URLs, download their images, and then use TensorFlow and the InceptionV3 pre-trained model to perform image recognition. For this, I am using the Go API. Most of the time, this process occurs without an issue, but every now and again an error occurs. I think this may be caused by a bug in TensorFlow as it appears to being thrown from the c code.\r\n\r\nA sample of the code that I am using is below. In case it is relevant, I run ProcessImage from different workers concurrently. This obviously means that the tfSession variable is shared between different threads. However, I don't think this is the problem as I have tried having each worker create and use its own session, and the error still occurs.\r\n\r\n```go\r\nvar tfSession *tf.Session\r\nvar modelGraph, normaliseGraph *tf.Graph\r\nvar normaliseInput, normaliseOutput tf.Output\r\n\r\n/*\r\n * Sets up resources that can be shared by each request.\r\n */\r\nfunc init() {\r\n  model, _ := ioutil.ReadFile(\"inception3/inception_v3_2016_08_28_frozen.pb\")\r\n  modelGraph = tf.NewGraph()\r\n  modelGraph.Import(model, \"\")\r\n  tfSession, _ = tf.NewSession(modelGraph, nil)\r\n  normaliseGraph, normaliseInput, normaliseOutput = ConstructNormaliseGraph()\r\n}\r\n\r\n/*\r\n * Processes the image and returns the probabilities of each label.\r\n */\r\nfunc ProcessImage(url string) []float32 {\r\n  tensor, okay := MakeTensorFromImage(url)\r\n  if !okay {\r\n    return nil\r\n  }\r\n\r\n  output, err := tfSession.Run(\r\n    map[tf.Output]*tf.Tensor{\r\n      modelGraph.Operation(\"input\").Output(0): tensor,\r\n    },\r\n    []tf.Output{\r\n      modelGraph.Operation(\"InceptionV3/Predictions/Reshape_1\").Output(0),\r\n    },\r\n    nil)\r\n  if err != nil {\r\n    return nil\r\n  }\r\n\r\n  return output[0].Value().([][]float32)[0]\r\n}\r\n\r\n/*\r\n * Constructs graph used to normalise image to required dimensions.\r\n */\r\nfunc ConstructNormaliseGraph() (graph *tf.Graph, input, output tf.Output) {\r\n  s := op.NewScope()\r\n  input = op.Placeholder(s, tf.String)\r\n  output = op.Div(s,\r\n\t\top.Sub(s,\r\n\t\t\top.ResizeBilinear(s,\r\n\t\t\t\top.ExpandDims(s,\r\n\t\t\t\t\top.Cast(s,\r\n\t\t\t\t\t\top.DecodeJpeg(s, input, op.DecodeJpegChannels(3)), tf.Float),\r\n\t\t\t\t\top.Const(s.SubScope(\"make_batch\"), int32(0))),\r\n\t\t\t\top.Const(s.SubScope(\"size\"), []int32{299, 299})),\r\n\t\t\top.Const(s.SubScope(\"mean\"), float32(0))),\r\n\t\top.Const(s.SubScope(\"scale\"), float32(255)))\r\n\tgraph, _ = s.Finalize()\r\n  return\r\n}\r\n\r\n/*\r\n * Creates a Tensor from the given image url.\r\n */\r\nfunc MakeTensorFromImage(url string) (*tf.Tensor, bool) {\r\n  r, err := client.Get(url)\r\n  if err != nil {\r\n    return nil, false\r\n  }\r\n  bytes, _ := ioutil.ReadAll(r.Body)\r\n  r.Body.Close()\r\n\r\n  stringBytes := string(bytes)\r\n  if stringBytes == \"Content not found\" {\r\n    return nil, false\r\n  }\r\n  tensor, _ := tf.NewTensor(stringBytes)\r\n\r\n  session, _ := tf.NewSession(normaliseGraph, nil)\r\n  defer session.Close()\r\n\r\n  normalized, err := session.Run(\r\n    map[tf.Output]*tf.Tensor{normaliseInput: tensor},\r\n    []tf.Output{normaliseOutput},\r\n    nil)\r\n  if err != nil {\r\n    return nil, false\r\n  }\r\n  return normalized[0], true\r\n}\r\n```\r\n\r\nI'm using macOS Sierra, but this error also exists when I compile the project for Linux. I have included both of these Go environments below. On Sierra, I installed TensorFlow using Homebrew, and on Linux, I installed it using the instructions [here](https://www.tensorflow.org/install/install_go).\r\n\r\n```\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOEXE=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"darwin\"\r\nGOOS=\"darwin\"\r\nGOPATH=\"/Users/Jamie/Documents/Go\"\r\nGORACE=\"\"\r\nGOROOT=\"/usr/local/Cellar/go/1.9/libexec\"\r\nGOTOOLDIR=\"/usr/local/Cellar/go/1.9/libexec/pkg/tool/darwin_amd64\"\r\nGCCGO=\"gccgo\"\r\nCC=\"clang\"\r\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/qq/c31qf27j2mng1xxhvk0b6b6c0000gn/T/go-build437606594=/tmp/go-build -gno-record-gcc-switches -fno-common\"\r\nCXX=\"clang++\"\r\nCGO_ENABLED=\"1\"\r\nCGO_CFLAGS=\"-g -O2\"\r\nCGO_CPPFLAGS=\"\"\r\nCGO_CXXFLAGS=\"-g -O2\"\r\nCGO_FFLAGS=\"-g -O2\"\r\nCGO_LDFLAGS=\"-g -O2\"\r\nPKG_CONFIG=\"pkg-config\"\r\n```\r\n\r\n```\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOEXE=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"linux\"\r\nGOOS=\"linux\"\r\nGOPATH=\"/home/ec2-user/go\"\r\nGORACE=\"\"\r\nGOROOT=\"/usr/local/go\"\r\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\r\nGCCGO=\"gccgo\"\r\nCC=\"gcc\"\r\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build126220137=/tmp/go-build -gno-record-gcc-switches\"\r\nCXX=\"g++\"\r\nCGO_ENABLED=\"1\"\r\nPKG_CONFIG=\"pkg-config\"\r\nCGO_CFLAGS=\"-g -O2\"\r\nCGO_CPPFLAGS=\"\"\r\nCGO_CXXFLAGS=\"-g -O2\"\r\nCGO_FFLAGS=\"-g -O2\"\r\nCGO_LDFLAGS=\"-g -O2\"\r\n```\r\n\r\nThe error I am getting is below. For your information, image.go line 99 is the line that contains `output, err := tfSession.Run(` in the ProcessImage function above.\r\n\r\n```\r\nfatal error: unexpected signal during runtime execution\r\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x0]\r\n\r\nruntime stack:\r\nruntime.throw(0x436cbee, 0x2a)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/panic.go:605 +0x95\r\nruntime.sigpanic()\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/signal_unix.go:351 +0x2b8\r\n\r\ngoroutine 12 [syscall, locked to thread]:\r\nruntime.cgocall(0x42aedc0, 0xc425d31cd8, 0x4310100)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/cgocall.go:132 +0xe4 fp=0xc425d31c90 sp=0xc425d31c50 pc=0x40044d4\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69550, 0xc4200fe0e0, 0x1, 0xc425d69540, 0xc4200fe0d8, 0xc400000001, 0x0, 0x0, ...)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45 fp=0xc425d31cd8 sp=0xc425d31c90 pc=0x419af45\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69550, 0xc4200fe0e0, 0x1, 0xc425d69540, 0xc4200fe0d8, 0xc400000001, 0x0, 0xc400000000, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a fp=0xc425d31d48 sp=0xc425d31cd8 pc=0x41a56ca\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd770, 0xc425d31e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f fp=0xc425d31de0 sp=0xc425d31d48 pc=0x419efff\r\ngithub.com/jamiebaggott/vision.ProcessImage(0xc4202f2b60, 0x6d, 0xc420080301, 0x0, 0x0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214 fp=0xc425d31ea8 sp=0xc425d31de0 pc=0x42a8f94\r\ngithub.com/jamiebaggott/vision.ImageWorker()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c fp=0xc425d31fe0 sp=0xc425d31ea8 pc=0x42a9a3c\r\nruntime.goexit()\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc425d31fe8 sp=0xc425d31fe0 pc=0x4059781\r\ncreated by github.com/jamiebaggott/vision.init.1\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c\r\n\r\ngoroutine 1 [IO wait, 2 minutes]:\r\ninternal/poll.runtime_pollWait(0x46adeb0, 0x72, 0xffffffffffffffff)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc420108118, 0x72, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc420108118, 0xffffffffffffff00, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Accept(0xc420108100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:334 +0x1e2\r\nnet.(*netFD).accept(0xc420108100, 0x4376820, 0xc425ce1d98, 0x400439b)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:238 +0x42\r\nnet.(*TCPListener).accept(0xc4201440b0, 0x42f7d80, 0xc425ce1dc8, 0x4003137)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/tcpsock_posix.go:136 +0x2e\r\nnet.(*TCPListener).AcceptTCP(0xc4201440b0, 0xc425ce1e10, 0xc425ce1e18, 0xc425ce1e08)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/tcpsock.go:234 +0x49\r\nnet/http.tcpKeepAliveListener.Accept(0xc4201440b0, 0x43761e8, 0xc42019c000, 0x44dfda0, 0xc4201365d0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:3120 +0x2f\r\nnet/http.(*Server).Serve(0xc420160270, 0x44df960, 0xc4201440b0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2695 +0x1b2\r\nnet/http.(*Server).ListenAndServe(0xc420160270, 0xc420160270, 0x7)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2636 +0xa9\r\nnet/http.ListenAndServe(0x43608c9, 0x5, 0x0, 0x0, 0xc42004df70, 0x42ae572)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2882 +0x7f\r\nmain.main()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:18 +0x96\r\n\r\ngoroutine 5 [sleep]:\r\ntime.Sleep(0x1dcd6500)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngopkg.in/mgo%2ev2.(*mongoCluster).syncServersLoop(0xc4200f6000)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/cluster.go:368 +0x424\r\ncreated by gopkg.in/mgo%2ev2.newCluster\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/cluster.go:78 +0x181\r\n\r\ngoroutine 24 [sleep, 1 minutes]:\r\ntime.Sleep(0x37e11d600)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngopkg.in/mgo%2ev2.(*mongoServer).pinger(0xc420146000, 0xc420039e01)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/server.go:301 +0x4fd\r\ncreated by gopkg.in/mgo%2ev2.newServer\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/server.go:89 +0x13c\r\n\r\ngoroutine 6 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46adf70, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc420108218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc420108218, 0xc420154000, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc420108200, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc420108200, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc42000e038, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc42000e038, 0xc420154000, 0x24, 0x24, 0x0, 0x18)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4200f80e0)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 10 [syscall, locked to thread]:\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc420188120, 0xc4200fe058, 0x1, 0xc420188110, 0xc4200fe050, 0xc400000001, 0x0, 0x0, ...)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc420188120, 0xc4200fe058, 0x1, 0xc420188110, 0xc4200fe050, 0xc400000001, 0x0, 0xc400000000, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc42038a0f0, 0xc420385e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f\r\ngithub.com/jamiebaggott/vision.ProcessImage(0xc4202f2770, 0x6d, 0xc420080101, 0x0, 0x0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214\r\ngithub.com/jamiebaggott/vision.ImageWorker()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c\r\ncreated by github.com/jamiebaggott/vision.init.1\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c\r\n\r\ngoroutine 11 [syscall, locked to thread]:\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc420188260, 0xc4200fe0b8, 0x1, 0xc420188240, 0xc4200fe0b0, 0xc400000001, 0x0, 0x0, ...)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc420188260, 0xc4200fe0b8, 0x1, 0xc420188240, 0xc4200fe0b0, 0xc400000001, 0x0, 0xc400000000, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc42038a270, 0xc420389e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f\r\ngithub.com/jamiebaggott/vision.ProcessImage(0xc4202f25b0, 0x6d, 0xc42016e101, 0x417abd5, 0xc4200f6000)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214\r\ngithub.com/jamiebaggott/vision.ImageWorker()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c\r\ncreated by github.com/jamiebaggott/vision.init.1\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c\r\n\r\ngoroutine 13 [syscall, locked to thread]:\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69680, 0xc4200fe130, 0x1, 0xc425d69670, 0xc4200fe128, 0xc400000001, 0x0, 0x0, ...)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69680, 0xc4200fe130, 0x1, 0xc425d69670, 0xc4200fe128, 0xc400000001, 0x0, 0xc400000000, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd950, 0xc425cdfe78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f\r\ngithub.com/jamiebaggott/vision.ProcessImage(0xc4202f2d20, 0x6e, 0xc420080601, 0x0, 0x0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214\r\ngithub.com/jamiebaggott/vision.ImageWorker()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c\r\ncreated by github.com/jamiebaggott/vision.init.1\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c\r\n\r\ngoroutine 14 [syscall, locked to thread]:\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69700, 0xc4200fe180, 0x1, 0xc425d696f0, 0xc4200fe178, 0xc400000001, 0x0, 0x0, ...)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69700, 0xc4200fe180, 0x1, 0xc425d696f0, 0xc4200fe178, 0xc400000001, 0x0, 0xc400000000, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd9e0, 0xc425d35e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f\r\ngithub.com/jamiebaggott/vision.ProcessImage(0xc4202f2930, 0x6c, 0xc42016e301, 0x0, 0x0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214\r\ngithub.com/jamiebaggott/vision.ImageWorker()\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c\r\ncreated by github.com/jamiebaggott/vision.init.1\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c\r\n\r\ngoroutine 43 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46addf0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc425cfc218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc425cfc218, 0xc420154000, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc425cfc200, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc425cfc200, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc4200fe010, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe010, 0xc420154090, 0x24, 0x24, 0x0, 0x18)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4200f8ee0)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 66 [sleep]:\r\ntime.Sleep(0x2aea5400)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngithub.com/jamiebaggott/vision.GetRequest(0xc42005a000, 0x6b, 0x1, 0x2, 0x42d6a20, 0xc425ceebe0, 0xe, 0xc420154e40)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e\r\ngithub.com/jamiebaggott/vision.GetUsers(0xc420154e40, 0x30, 0xc42013c720, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce\r\ngithub.com/jamiebaggott/vision.Run(0xc42013c720, 0x1b, 0xc420084aa0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b\r\ncreated by main.handler\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1\r\n\r\ngoroutine 405 [chan receive, 1 minutes]:\r\ngithub.com/jamiebaggott/vision.ProcessImages(0xc42013c720, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b\r\ncreated by github.com/jamiebaggott/vision.Run\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc\r\n\r\ngoroutine 29 [sleep]:\r\ntime.Sleep(0x2aea5400)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngithub.com/jamiebaggott/vision.GetRequest(0xc42005bd50, 0x6c, 0x1, 0x2, 0x42d6a20, 0xc425d9aa20, 0xe, 0xc4200181c0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e\r\ngithub.com/jamiebaggott/vision.GetUsers(0xc4200181c0, 0x32, 0xc420158860, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce\r\ngithub.com/jamiebaggott/vision.Run(0xc420158860, 0x1b, 0xc4200846e0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b\r\ncreated by main.handler\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1\r\n\r\ngoroutine 69 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ada30, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc42025a118, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc42025a118, 0xc420244b00, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc42025a100, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc42025a100, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420286018, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286018, 0xc420244ba0, 0x24, 0x24, 0x0, 0x18)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4b420)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 33 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46adbb0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc425e1c218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc425e1c218, 0xc420244a00, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc425e1c200, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc425e1c200, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420144078, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144078, 0xc420244ae0, 0x24, 0x24, 0x0, 0x339cc)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420146620)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 439 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ad670, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc42025a298, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc42025a298, 0xc42008b000, 0x1000, 0x1000)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc42025a280, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc42025a280, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x8, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420286078, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ncrypto/tls.(*block).readFromUntil(0xc42038b710, 0xb4640e8, 0xc420286078, 0x5, 0xc420286078, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:488 +0x95\r\ncrypto/tls.(*Conn).readRecord(0xc420120380, 0x4376817, 0xc4201204a0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:590 +0xe0\r\ncrypto/tls.(*Conn).Read(0xc420120380, 0xc420342000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:1134 +0x110\r\nbufio.(*Reader).Read(0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0xc425d2bc70, 0x402b956, 0x4376820)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/bufio/bufio.go:213 +0x30b\r\nio.ReadAtLeast(0x44daa60, 0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0x9, 0xc425d2bcd0, 0xc425d2bcd0, 0x4007d52)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/io/io.go:309 +0x86\r\nio.ReadFull(0x44daa60, 0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0xc420113b00, 0xc425d2bd08, 0xc400000001)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/io/io.go:327 +0x58\r\nnet/http.http2readFrameHeader(0xc4201e8e38, 0x9, 0x9, 0x44daa60, 0xc420328b40, 0x0, 0xc400000000, 0xc425d2bdf0, 0x4266459)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1516 +0x7b\r\nnet/http.(*http2Framer).ReadFrame(0xc4201e8e00, 0xc4200fc180, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1774 +0xa4\r\nnet/http.(*http2clientConnReadLoop).run(0xc425d2bfb0, 0x4376220, 0xc42033cfb0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7862 +0x92\r\nnet/http.(*http2ClientConn).readLoop(0xc42016eb60)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7788 +0x9d\r\ncreated by net/http.(*http2Transport).newClientConn\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7053 +0x6b9\r\n\r\ngoroutine 67 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46adaf0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc420108798, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc420108798, 0xc420155200, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc420108780, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc420108780, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420286008, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286008, 0xc420155200, 0x24, 0x24, 0x0, 0x18)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4a1c0)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 56 [sleep]:\r\ntime.Sleep(0x2aea5400)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngithub.com/jamiebaggott/vision.GetRequest(0xc420345ab0, 0x6c, 0x1, 0x2, 0x42d6a20, 0xc4200e1ae0, 0xe, 0xc425e04200)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e\r\ngithub.com/jamiebaggott/vision.GetUsers(0xc425e04200, 0x32, 0xc4201589a0, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce\r\ngithub.com/jamiebaggott/vision.Run(0xc4201589a0, 0x1b, 0xc425dc08c0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b\r\ncreated by main.handler\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1\r\n\r\ngoroutine 85 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ad970, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc42025a598, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc42025a598, 0xc420155500, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc42025a580, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc42025a580, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420144098, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144098, 0xc420155530, 0x24, 0x24, 0x0, 0x339cc)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420147960)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 59 [sleep]:\r\ntime.Sleep(0x2aea5400)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130\r\ngithub.com/jamiebaggott/vision.GetRequest(0xc425cf4000, 0x6d, 0x1, 0x2, 0x42d6a20, 0xc425d8a800, 0xe, 0xc4200185c0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e\r\ngithub.com/jamiebaggott/vision.GetUsers(0xc4200185c0, 0x33, 0xc42013cb40, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce\r\ngithub.com/jamiebaggott/vision.Run(0xc42013cb40, 0x1b, 0xc425e205a0)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b\r\ncreated by main.handler\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1\r\n\r\ngoroutine 446 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46add30, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc425e1c498, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc425e1c498, 0xc4200ae800, 0x400, 0x400)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc425e1c480, 0xc4200ae800, 0x400, 0x400, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc425e1c480, 0xc4200ae800, 0x400, 0x400, 0xc420420a00, 0x158f2dd4a2167001, 0xc42003f870)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc42000e048, 0xc4200ae800, 0x400, 0x400, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ncrypto/tls.(*block).readFromUntil(0xc42024a090, 0xb4640e8, 0xc42000e048, 0x5, 0xc42000e048, 0xc42051c2c5)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:488 +0x95\r\ncrypto/tls.(*Conn).readRecord(0xc420130000, 0x4376817, 0xc420130120, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:590 +0xe0\r\ncrypto/tls.(*Conn).Read(0xc420130000, 0xc425d7d000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:1134 +0x110\r\nbufio.(*Reader).Read(0xc420328360, 0xc425decc78, 0x9, 0x9, 0xc42003fc70, 0x402b956, 0x4376820)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/bufio/bufio.go:213 +0x30b\r\nio.ReadAtLeast(0x44daa60, 0xc420328360, 0xc425decc78, 0x9, 0x9, 0x9, 0xc42003fcd0, 0xc42003fcd0, 0x4007d52)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/io/io.go:309 +0x86\r\nio.ReadFull(0x44daa60, 0xc420328360, 0xc425decc78, 0x9, 0x9, 0xc4203283c0, 0xc42003fd08, 0xc400000001)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/io/io.go:327 +0x58\r\nnet/http.http2readFrameHeader(0xc425decc78, 0x9, 0x9, 0x44daa60, 0xc420328360, 0x0, 0xc400000000, 0xc42003fdf0, 0x4266459)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1516 +0x7b\r\nnet/http.(*http2Framer).ReadFrame(0xc425decc40, 0xc42024ac00, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1774 +0xa4\r\nnet/http.(*http2clientConnReadLoop).run(0xc42003ffb0, 0x4376220, 0xc4203397b0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7862 +0x92\r\nnet/http.(*http2ClientConn).readLoop(0xc420080b60)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7788 +0x9d\r\ncreated by net/http.(*http2Transport).newClientConn\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7053 +0x6b9\r\n\r\ngoroutine 482 [chan receive]:\r\ngithub.com/jamiebaggott/vision.ProcessImages(0xc42013cb40, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b\r\ncreated by github.com/jamiebaggott/vision.Run\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc\r\n\r\ngoroutine 449 [chan receive]:\r\ngithub.com/jamiebaggott/vision.ProcessImages(0xc420158860, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b\r\ncreated by github.com/jamiebaggott/vision.Run\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc\r\n\r\ngoroutine 392 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ad8b0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc42025a198, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc42025a198, 0xc425d8ce00, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc42025a180, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc42025a180, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420144008, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144008, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x339cc)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420246e00)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 462 [chan receive]:\r\ngithub.com/jamiebaggott/vision.ProcessImages(0xc4201589a0, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b\r\ncreated by github.com/jamiebaggott/vision.Run\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc\r\n\r\ngoroutine 364 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ad7f0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc425e1c118, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc425e1c118, 0xc42001c700, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc425e1c100, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc425e1c100, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc420286000, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286000, 0xc42001c7b0, 0x24, 0x24, 0x0, 0xa9)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4a2a0)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 483 [chan send]:\r\ngithub.com/jamiebaggott/vision.ProcessImages.func1(0xc425d02960, 0xc4204f20c0, 0xc4200e1ba0, 0xc420345b20, 0xc42013cb40, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3\r\ncreated by github.com/jamiebaggott/vision.ProcessImages\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327\r\n\r\ngoroutine 394 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46adc70, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc425cfd218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc425cfd218, 0xc420245800, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc425cfd200, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc425cfd200, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc4200fe028, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe028, 0xc420245800, 0x24, 0x24, 0x0, 0x339cc)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425dec000)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 385 [chan send]:\r\ngithub.com/jamiebaggott/vision.ProcessImages.func1(0xc425d020f0, 0xc420119b00, 0xc425d049c0, 0xc4202f3ea0, 0xc42013c720, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3\r\ncreated by github.com/jamiebaggott/vision.ProcessImages\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327\r\n\r\ngoroutine 461 [IO wait]:\r\ninternal/poll.runtime_pollWait(0x46ad4f0, 0x72, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57\r\ninternal/poll.(*pollDesc).wait(0xc420108d98, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae\r\ninternal/poll.(*pollDesc).waitRead(0xc420108d98, 0xc420244e00, 0x24, 0x24)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\r\ninternal/poll.(*FD).Read(0xc420108d80, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a\r\nnet.(*netFD).Read(0xc420108d80, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52\r\nnet.(*conn).Read(0xc4200fe1a0, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)\r\n\t/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d\r\ngopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe1a0, 0xc420244e70, 0x24, 0x24, 0x0, 0x1e7)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53\r\ngopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4201e8540)\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658\r\ncreated by gopkg.in/mgo%2ev2.newSocket\r\n\t/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f\r\n\r\ngoroutine 463 [chan send]:\r\ngithub.com/jamiebaggott/vision.ProcessImages.func1(0xc425d6c2d0, 0xc42038ad80, 0xc425d83820, 0xc42005a150, 0xc4201589a0, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3\r\ncreated by github.com/jamiebaggott/vision.ProcessImages\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327\r\n\r\ngoroutine 464 [chan send]:\r\ngithub.com/jamiebaggott/vision.ProcessImages.func1(0xc425d6c3c0, 0xc42038ae40, 0xc425d83960, 0xc42005a1c0, 0xc420158860, 0x1b)\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3\r\ncreated by github.com/jamiebaggott/vision.ProcessImages\r\n\t/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327\r\n```", "comments": ["@asimshankar, do you have any hints to offer about how to figure this out?", "That is troubling, and from a cursory look at the stacktrace this seems like a NULL pointer dereference somewhere inside the C code, but I can't tell. \r\n\r\nIs there any way you can reduce this to a smaller sample of code that reproduces the problem?", "This may not be a smaller sample of code, but they are individual files that can be run, although you may need to run them a number of times as the errors aren't produced every time.\r\n\r\nIn the below gist, there is a file named `image.go` and `image2.go`; these files are the same apart from the fact that `image` shares `tfSession` between 10 workers, whereas `image2` creates a new session for each worker. Due to that, the memory used when running `image` is ~750MB, whereas for `image2` it is ~5GB.\r\n\r\nTo run these files, they need to be in a directory where there is an image named `image.png`, and where the pre-trained InceptionV3 model is in a directory named `inception3`. This can be found gzipped here: https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\r\n\r\nThe log files with 2 in their name correspond to `image2`, and those that do not correspond to `image`. `tf_error.log` and `tf_error2.log` are errors that are caused by running `tfSession` in the `ImageWorker` function, whereas `tf_error_alt.log` and `tf_error2_alt.log` are errors that are caused by creating or running the session in the `MakeTensorFromImage` function.\r\n\r\nhttps://gist.github.com/jamiebaggott/f540c2fbeadd89219127a8e0669bd462\r\n\r\nIf you require any more information, please let me know.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Is that still happening for you? If so, could you build with ASAN to see if you get more information?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 12823, "title": "bazel error ", "body": "ERROR: /Users/dile/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):\r\n\tFile \"/Users/dile/tensorflow/third_party/py/python_configure.bzl\", line 310\r\n\t\t_create_local_python_repository(repository_ctx)\r\n\tFile \"/Users/dile/tensorflow/third_party/py/python_configure.bzl\", line 268, in _create_local_python_repository\r\n\t\t_get_python_bin(repository_ctx)\r\n\tFile \"/Users/dile/tensorflow/third_party/py/python_configure.bzl\", line 166, in _get_python_bin\r\n\t\t_get_env_var(repository_ctx, _PYTHON_BIN_PATH, No..., ...)\r\n\tFile \"/Users/dile/tensorflow/third_party/py/python_configure.bzl\", line 49, in _get_env_var\r\n\t\t_python_configure_fail((\"'%s' environment variable is n...))\r\n\tFile \"/Users/dile/tensorflow/third_party/py/python_configure.bzl\", line 37, in _python_configure_fail\r\n\t\tfail((\"%sPython Configuration Error:%...)))\r\nPython Configuration Error: 'PYTHON_BIN_PATH' environment variable is not set\r\n and referenced by '//third_party/py/numpy:headers'.\r\nERROR: Analysis of target '//tensorflow/examples/image_retraining:retrain' failed; build aborted.", "comments": ["Can you put the rest of the information? (OS, etc) Did you run configure?", "maybe forgot to run configure?\r\n\r\nI apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 12822, "title": "TensorFlow import ", "body": "Tensor flow report issue:\r\n\r\nI am getting the following error  when importing tensorflow.\r\n\r\nimport tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>\r\n", "comments": ["(1) Please review tensorflow guidelines [here](https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md) before raising an issue.\r\n(2) Please go to [stackoverflow](https://stackoverflow.com/search?q=install+tensorflow+on+windows) for more help.\r\n(3) If you are trying to install tensorflow-gpu then have to follow specific guidelines [here](https://stackoverflow.com/questions/42011070/on-windows-running-import-tensorflow-generates-no-module-named-pywrap-tenso).\r\n(4) If you are trying to install tensorflow without gpu support then read and follow installation guidelines [here](https://www.tensorflow.org/install/install_windows).", "It seems module named '_pywrap_tensorflow_internal' is missing or cannot found.\r\nTherefore, your TensorFlow runtime failed to load.\r\nTry to fix it by going to your C:\\Users\\Deena Awny\\AppData\\Local\\Programs\\Python\\Python36\\lib directory and locate the missing file. ", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 12821, "title": "Wrong error message during compiling", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Amazon Linux 2017.03\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: release v1.3.0\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**: CUDA 7.5/cuDNN 5.1.10\r\n- **GPU model and memory**: Tesla K80\r\n- **Exact command to reproduce**: remove _patch_ command and try to compile\r\n\r\n### Describe the problem\r\nThere's a wrong error message when you try to compile TensorFlow without `patch` command installed. It's not a big deal but could take a couple of hours to figure it out.\r\n\r\n### Source code / logs\r\n`\r\nERROR: /home/ec2-user/workplace/tensorflow/tensorflow/tools/pip_package/BUILD:100:1: no such package '@boringssl//': Traceback (most recent call last):\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 116\r\n\t\t_apply_patch(repo_ctx, repo_ctx.attr.patch_file)\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 107, in _apply_patch\r\n\t\t_execute_and_check_ret_code(repo_ctx, cmd)\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 91, in _execute_and_check_ret_code\r\n\t\tfail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(256) when executing 'patch -p1 -d /home/ec2-user/.cache/bazel/_bazel_ec2-user/4ee13f1db5bfc278f4537815cf99cd27/external/boringssl -i /home/ec2-user/workplace/tensorflow/third_party/boringssl/add_boringssl_s390x.patch':\r\nStdout:\r\nStderr: java.io.IOException: Cannot run program \"patch\" (in directory \"/home/ec2-user/.cache/bazel/_bazel_ec2-user/4ee13f1db5bfc278f4537815cf99cd27/external/boringssl\"): error=2, No such file or directory and referenced by '//tensorflow/tools/pip_package:licenses'.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\n`", "comments": ["@MarkDaoust we should update the pre-requisites.\r\n\r\nThank for reporting this, @eaperz! If you want to send a PR, that's also great.", "Is it good to check whether `patch` is installed before it is invoked [here](https://github.com/tensorflow/tensorflow/blob/12a628a623a5dae81b8fc699792eaf414e6ace41/tensorflow/workspace.bzl#L110)?", "I think it should be checked in a pre-requisite stage, along with all other pre-requisites to build. Unfortunately it's my first contact with tensorflow and I have no idea where in the code is this verification done.", "@eaperz  I agree with you. Since I'm not familiar with bazel, I don't know how to do pre-check yet.", "Best place would probably be in the `configure`(https://github.com/tensorflow/tensorflow/blob/master/configure.py) script."]}, {"number": 12820, "title": "Install name fix for libtensorflow.so", "body": "There exists a problem with the built shared library for Mac. If ones creates a shared library that depends on libtensorflow.so and distributes it in a folder, along with libtensorflow.so, then the Mac linker will failed to load the library, unless libtensorflow.so is in `DYLD_LIBRARY_PATH`. This is problematic when libraries are distributed together as a package (e.g., in the context of JNI). From what I read online, this can be fixed using `@rpath`. This is what this patch is about and it seems to work in my experiments.", "comments": ["Can one of the admins verify this patch?", "@allenlavoie : Mind taking a look?", "@eaplatanios : Could you elaborate a bit - in the context of JNI libraries, the Java API explicitly loads the `.so` using [`System.loadLibrary`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java#L83), and I don't think the `rpath` issue has troubled usage on OS X there. So, I'd like to understand the details of the problem you're running into a bit more.", "Oh, I see, you probably have another shared library that depends on `libtensorflow.so`, whereas in the Java API right now we package a single `.so`. \r\n\r\nLooks good then. Thanks.", "Jenkins, test this please", "@asimshankar Yes, that's right. What I've done is that I package my cross-compiled JNI bindings along with the main Scala API in one package distributed through Sonatype. Then, for the TensorFlow binaries, I package each pre-compiled binary in its own package. Thus, when you load my API, you don't have to download the pre-compiled binaries. Also, when you do download them via depending on one of my wrapping packages, you only get to download the one corresponding to your platform (done so that the JARs are not very big).\r\n\r\nThis way, when I load the libraries through the JVM, I extract the JNI bindings library into a temporary directory. If you have also provided one of my wrapping packages for the main native library in your classpath, then I also extract that in the same directory. I then load the libraries from that directory, but in this case, `dlopen` would fail to load the JNI bindings dependency on the main native library due to the absolute path in the dependency name.\r\n\r\nI hope this makes sense."]}, {"number": 12819, "title": "Fix typo & Clarify comment", "body": "- Fix typo in comment : `Profiler` -> `Profile` \r\n- `uint64` can be misunderstood as `np.uint64`. So I propose to change it to `int`\r\n\r\nThis edit is to avoid misusage of tf.Profile by a developer using it for the first time. See the scenario below:\r\n\r\n0. He or she follow this [instruction](https://github.com/tensorflow/tensorflow/blob/084d29e67a72e369958c18ae6abfe2752fcddcbf/tensorflow/python/profiler/model_analyzer.py#L120) from comment\r\n1. He or she may want to pass evaluated [global_step](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/train/global_step) (which type is `np.int32`) to `profiler.add_step` \r\n```\r\nglobal_step = tf.Variable(0, name=\"global_step\", trainable=False)\r\nstep = session.run(global_step, ...)\r\nprofiler.add_step(step, run_meta)\r\n```\r\n2. `profiler.add_step` raise `TypeError: in method 'AddStep', argument 1 of type 'int64'`\r\n3. So he or she may mistakenly try again to convert `np.uint32` `step` to `np.uint64` `step`. *Because comment said use `uint64` type for `step`*\r\n\r\n```profiler.add_step(step.astype(np.uint64), run_meta) ```\r\n\r\n4.  **BUT!** `TypeError: in method 'AddStep', argument 1 of type 'int64'` raise again! \r\n5. ... correct answer is to try to convert `step` as `int(step)`.\r\n", "comments": ["Can one of the admins verify this patch?", "@caisq LGTM"]}, {"number": 12818, "title": "[feature request] Any way to control the order of send/recv (host to device data transfer) explicitly?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.2\r\n- **Python version**:\r\n3.5\r\n- **Bazel version (if compiling from source)**:\r\n0.5.2\r\n- **CUDA/cuDNN version**:\r\n8.0\r\n- **GPU model and memory**:\r\nGTX 1070\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nOverlapping the host to device data transfer with GPU calculation is an important method to improve the performance of inference workload. But I found it very difficult to control the order of data transfers explicitly at this moment. I understand the send/recv operations are added implicitly when the original graph is split/optimized into sub-graphs. I tried to use control dependency + identity/assign operation (as suggested [here](https://github.com/tensorflow/tensorflow/issues/2848)) to hand control send/recv order. But it seems impossible to achieve this goal. \r\n\r\nFor example, \r\nIn the following code, we'd like to overlap the H2D memcpy of B->B_GPU with the matmul calculation.\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.python.client import session\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import variables\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\r\n\r\nwith ops.Graph().as_default():\r\n  with tf.device('/cpu:0'):\r\n    A = tf.placeholder(tf.float32, shape=(1000, 100), name=\"A\")\r\n    B = tf.placeholder(tf.float32, shape=(1000, 1000), name=\"B\")\r\n  with tf.device('/gpu:0'):\r\n    C = variables.Variable(tf.random_normal([100,1000],stddev=0.1), name=\"C\")\r\n    A_GPU = tf.identity(A)\r\n    with tf.control_dependencies([A_GPU]):\r\n      B_GPU = tf.identity(B)\r\n      D = tf.add(tf.matmul(A_GPU, C), B_GPU, name=\"D\")\r\n\r\n  random_A=np.random.rand(1000,100).astype(np.float32)\r\n  random_B=np.random.rand(1000,1000).astype(np.float32)\r\n\r\n  sess = session.Session()\r\n  init = tf.global_variables_initializer()\r\n  sess.run(init)\r\n\r\n  for x in range(1,50):\r\n    output = sess.run(D,feed_dict={A:random_A,B:random_B})\r\n```\r\n\r\nBut it turned out that H2D memcpy A->A_GPU is not ensured to launch first. Actually among the 50 iterations, I noticed the order of transferring A->A_GPU and transferring B->B_GPU is randomly performed if we use multiple threads (because the two transfers are handled in different threads, and no-dependency could be built between them). \r\nIf A->A_GPU launches first, the matmul op could be overlapped with B->B-GPU\r\n![image](https://user-images.githubusercontent.com/8175586/30090954-3f28ef90-92a6-11e7-98ee-2a05e6a7463d.png)\r\notherwise, the matmul op has to wait until all H2D memcpys finished.\r\n![image](https://user-images.githubusercontent.com/8175586/30091033-c6b2f988-92a6-11e7-8abb-f41feac3bbf1.png)\r\n\r\nOnly if we can control the order of send node explicitly, the overlap can be ensured.\r\n\r\nPlease let me know if I didn't use the identity operation correctly.\r\n\r\nThanks.", "comments": ["@poxvoculi can you offer any hints for this use case?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "First, I apologize for not noticing this issue earlier.  In case it's still of interest, here's some analysis.\r\n\r\nShort summary: It's complicated. I'll give a longer answer than strictly necessary, to address cases more general than you describe.\r\n\r\nControl edges introduce a dependency where if there is such an edge from node i to node j, node j will not be scheduled for execution until node i has 'finished' execution.  I put the scare quotes around finished because while it's true in the way you probably expect for CPU operations, it's not really true in the case of GPU operations.  \r\n\r\nCPU operations are scheduled by immediately executing them or by queuing them on a threadpool, and their completion is detected synchronously or via callback.  \r\n\r\nGPU operations are scheduled by making a request to the StreamExecutor (an abstract wrapper around the CUDA driver).  TF pre-establishes a small number of execution streams on each GPU, for dedicated purposes.  All compute kernels are executed on a single compute stream.  Since that is the case, if nodes i and j in the example are both to execute on the same GPU, we can schedule j immediately after scheduling i, without waiting for i to finish, because j won't actually begin execution until i completes.   (In general we don't know or care exactly when a stream operation completes, just that the proper stream event ordering dependencies are introduced to guarantee safe execution.)  H2D copy operations are scheduled on their own dedicated stream, D2H copy operations on another, and D2D copy operations on yet another.  So it's possible to have up to 4 concurrent operations involving one GPU: one compute and three copies.  At least from the TF point of view; at the NVIDIA device level there may be a more detailed description with a different character.\r\n\r\nWhen a TF graph is executed, it is first partitioned into a subgraph of only nodes assigned to a single device, and value copy operations between those graphs are introduced in the form of (internal only) Send and Recv nodes.  Unless there's an optional control input a Recv node is eligible for immediate execution, but the data transfer doesn't start until it meets the corresponding Send in the Rendezvous table associated with the process of the source device.\r\n\r\nWith these considerations, let's examine your program.  After the first run C is fully initialized and the only operations that execute in each run are \r\n   1. feeding A  \r\n   2. feeding B\r\n   3. copying A to A_GPU\r\n   4. copying B to B_GPU\r\n   5. doing the matmul\r\n   6. doing the add\r\nOnly operations 1 & 2 execute on the CPU, all the rest are GPU stream operations.  I don't really know how the feeding works; if it's multi-threaded I suppose it may be non-deterministic whether A or B is completely populated first.\r\n\r\nYour program adds control edges from the tf.identity that establishes A_GPU to the tf.identity that establishes B_GPU and also the matmul and the add.  Strictly speaking, the first tf.identity executes on the GPU so it's eligible to schedule as soon as the Recv of A is 'finished'.  The second tf.identity is also a GPU operation and is eligible to schedule as soon as the Recv of B is finished *and* the first tf.identity is 'finished'.  Note one tricky point however; the data copy is triggered by the corresponding Send and Recv meeting in the process Rendezvous table, and your control edge is between two tf.identity operations, both of which are actually downstream (in terms of the dataflow graph) from the Recv operations.  From the point-of-view of the GPU executor, both of those Recv nodes are eligible for immediate scheduling, and in your multi-threaded environment it appears to be non-deterministic which copy gets into the H2D stream first.  Once it's in there, it will run to completion before the other copy starts.\r\n\r\nThe semantics of tf.identity are potentially confusing where the input tensor is non-local and the purpose of the operation is to introduce a copy.  In general, identity creates a new immutable tensor which shares type, shape and the same backing memory buffer with its input tensor.  Where the given input is non-local, the execution environment introduces an upstream Recv which actually allocates the memory buffer and populates it, and that Recv op is technically the input to the identity op.   If this is happening on a GPU then the Recv-triggered copy is scheduled on the H2D stream and the identity is scheduled on the compute stream. To ensure that the identity doesn't execute too soon, we could insert a dependency on the H2D stream in the compute stream immediately before enqueuing the identity op.  However, instead we treat Recv specially as the only async GPU operation and actually wait for it to terminate before considering it to be finished and enqueuing the identity op.\r\n\r\nIn the case of your program, the main problem is that you've introduced the control dependencies downstream of the actual data copies, but it's tricky to realize your intended behavior because of the strange semantics of GPU operations.  I would try rewriting your program as follows:\r\n\r\n      with tf.device('/gpu:0'):\r\n        A_GPU = tf.identity(A)\r\n      with tf.device('/cpu:0'):\r\n        with tf.control_dependencies([A_GPU]):\r\n          B_staged = tf.identity(B)\r\n      with tf.device('gpu:0'):\r\n        M = tf.matmul(A_GPU, C)\r\n        B_GPU = tf.identity(B_staged)\r\n        D = tf.add(M, B_GPU, name=\"D\")\r\n\r\nI find that with this definition the A copy consistently happens before the B copy, and the matmul may overlap with the B copy, BUT: overall execution is slower.  That's because starting the B copy stalls on waiting for a stream event to be harvested out of the CUDA driver and handled by the CPU, and in this particular program the matmul is relatively fast compared to copy times.  Also, maybe the B populate finishes first a lot of the time, but now we stall waiting for the B populate to finish before doing anything. \r\n But, maybe you can now find a way to improve your real problem.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "closing for lack of activity", "@poxvoculi  You suggestion is great and it works! I have one more question related to the same topic. Do you have any idea about how to control the dependency of ops in the auto-grad(backpropagation)?"]}, {"number": 12817, "title": "LMDB reader Error in Reading Data of multi-thread, queue based input pipeline", "body": "Hi,\r\n\r\nI am now using LMDB reader to read and decode my custom data into tensorflow training pipeline, based on the example:\r\n```\r\ndef read_my_file_format(filename_queue):\r\n  reader = tf.SomeReader()\r\n  key, record_string = reader.read(filename_queue)\r\n  example, label = tf.some_decoder(record_string)\r\n  processed_example = some_processing(example)\r\n  return processed_example, label\r\n\r\ndef input_pipeline(filenames, batch_size, num_epochs=None):\r\n  filename_queue = tf.train.string_input_producer(\r\n      filenames, num_epochs=num_epochs, shuffle=True)\r\n  example, label = read_my_file_format(filename_queue)\r\n  min_after_dequeue = 10000\r\n  capacity = min_after_dequeue + 3 * batch_size\r\n  example_batch, label_batch = tf.train.shuffle_batch(\r\n      [example, label], batch_size=batch_size, capacity=capacity,\r\n      min_after_dequeue=min_after_dequeue)\r\n  return example_batch, label_batch\r\n````\r\nHere, I designed my own decoder and used LMDB reader here. But the problem is that, when the `num_epochs` is not 1, there will be ERROR:\r\n\r\n```\r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n```\r\n\r\nCould you help check this?\r\n\r\nThanks\r\n", "comments": ["The detailed code is like:\r\n\r\n```\r\n# set data directory\r\nCURRENT = os.path.abspath(os.path.dirname(__file__))\r\nDATA_DIR = os.path.join(CURRENT, 'gt')\r\nDB_DIR = os.path.join(DATA_DIR, 'toy_db', 'data.mdb')\r\nOUT_DIR = os.path.join(DATA_DIR, 'out')\r\n\r\ndef tf_lmdb_reader():\r\n    test_queue = tf.train.string_input_producer([DB_DIR], num_epochs=2)\r\n    reader = io_ops.LMDBReader()\r\n    key, value = reader.read(test_queue)\r\n    npr_line, mask, train_input, depth, normal = decode_block(value, [380, 380, 12])\r\n\r\n    queue_buf = 1000\r\n    cap_shuffle = queue_buf + 3 * 1\r\n\r\n    batch_data = tf.train.shuffle_batch(tensors=[npr_line, mask, train_input, depth, normal],\r\n                                        batch_size=9,\r\n                                        num_threads=5,\r\n                                        capacity=cap_shuffle,\r\n                                        min_after_dequeue=queue_buf)\r\n\r\n    with tf.Session() as sess:\r\n\r\n        init_op = tf.group(tf.global_variables_initializer(),\r\n                           tf.local_variables_initializer())\r\n        sess.run(init_op)\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        try:\r\n            step = 0\r\n            while not coord.should_stop():\r\n                cur_batch = sess.run([batch_data])\r\n                step += 1\r\n                print(step)\r\n        except tf.errors.OutOfRangeError:\r\n            print('Done')\r\n        finally:\r\n            coord.request_stop()\r\n\r\n        coord.request_stop()\r\n        coord.join(threads)\r\n\r\nif __name__ == '__main__':\r\n    tf_lmdb_reader()\r\n```", "There should never be a SEGV.  I'm guessing the problem is on the LMDB reader. Do you have a stack trace?", "I guess the reason is that there is lock file when we open the LMDB database, this will prevent us to read it again when one epoch is finished. I got some explanation from other questions, like:\r\n\r\nWhen opening a database file, LMDB creates a lock file\u00a0lock.mdb\u00a0in the same folder to prevent that database being opened more than once. This unfortunately prevents us to enqueue the database file multiple times.\r\n\r\nBut how can solve this? I mean how to use LMDB reader to read database file more than one epoch in the above pipeline?\r\n\r\n", "Have you considered whether using DataFlow from tensorpack (though independent of tensorpack dependency-wise) would address this?\r\n\r\nThere's [an LMDB example here](http://tensorpack.readthedocs.io/en/latest/tutorial/efficient-dataflow.html#sequential-read)\r\n", "@quaeler sorry, I did not try. I already convert my data to TFRecords, which is bug free and can use the pipeline I used for LMDB. And I am waiting bug fixation for LMDB.\r\n\r\nThanks", "You mean the LMDB reader lacks a `close`?", "I don't know what's causing the problem, but just want to mention that lmdb database can be opened without a lock when the transaction is read-only.", "We [do currently open it in read-only mode](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/lmdb_reader_op.cc#L39), but [the documentation for the LMDB API](http://www.lmdb.tech/doc/group__mdb.html#ga32a193c6bf4d7d5c5d579e71f22e9340) states WRT read-only mode:\r\n```\r\nMDB_RDONLY Open the environment in read-only mode. No write operations\r\nwill be allowed. LMDB will still modify the lock file - except on\r\nread-only filesystems, where LMDB does not use locks.\r\n```\r\n\r\nIf we also specified the `MDB_NOLOCK` flag on the open (@drpngx,) perhaps this problem would go away; i'm unaware of other ramifications of not locking on the read-only read.", "Thanks for reporting the bug. I just saw this issue today. This PR #13396 should fix it. Sorry for the bug.", "Hi all,\r\n\r\nI was looking use my data which is present in LMDB form but i am unable to find any sample code or more usage documentation on using LMDB dataset in Tensorflow.\r\nIf someone has tried LMDB could share the usage experience .it would be very helpful.\r\nA simple example to read a LMDB file and print the key value pair would be helpful.\r\n\r\nThanks ", "@vishalghor It's pretty much the same as other readers like TFRecordReader.\r\nFor sample code, you may take a look at the test case.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/reader_ops_test.py#L998\r\n", "@bowang thank you for fast reply.I was able to read an LMDB file and print the values by assigning the tensor key and value to normal variables.\r\n\r\nHowever, Is there any sample implementation of LMDB dataset for any opensource models such as inception v3 or an implementation of LMDB dataset for the retraining inception v3 tutorial by tensorflow.\r\nIt would be very helpful if a sample of usage in training a models is provided.\r\n\r\nThanks and Regards", "Hi all,\r\n\r\nI was able to read LMDB database using the following code:\r\n\r\n```\r\nfrom __future__ import print_function\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import data_flow_ops\r\nfrom tensorflow.python.ops import io_ops\r\nfrom tensorflow.python.ops import variables\r\n\r\nprefix_path = \"tensorflow\"\r\n\r\ndef read_lmdb():\r\n    with tf.Session() as sess:\r\n        path = os.path.join(prefix_path, \"testLMDB\", \"data.mdb\")\r\n        #print(path)\r\n        reader=io_ops.LMDBReader()\r\n        queue = data_flow_ops.FIFOQueue(200, [dtypes.string], shapes=())\r\n        key, value = reader.read(queue)\r\n        queue.enqueue([path]).run()\r\n        queue.close().run()\r\n       for i in range(1,no_of_key_value_pair)\r\n            k,v = sess.run([key,value])\r\n            print(k)\r\n\r\nif __name__ == '__main__':\r\n    read_lmdb()\r\n```\r\n\r\nBut while researching more on LMDBReader,i found tf.LMDBReader also.\r\nSo what is the difference between io_ps.LMDBReader() and tf.LMDBReader().\r\n\r\nThe Tensorflow documentation speaks very minimal about various other forms of dataset format such as LMDB,HDF5 compared to TFRecord.\r\n\r\nHow such datasets be included in existing code?\r\n\r\nPlease help me in clearing the doubt due to lack of adequate documentation.\r\n\r\nThanks and Regards\r\n", "@vishalghor io_ps.LMDBReader() and tf.LMDBReader() are the same. But the former is for internal use only. Thus I'd recommend to use tf.LMDBReader.\r\nLMDBReader shares the same interface as TFRecordsReader. So you may follow the documentation of the latter. Once you get both key, value out of LMDB, it's up to you (and the LMDB you are using) to determine how to decode it. For example, if it's an image, you can pass the value to tf.image.decode_jpeg()", "@bowang So you fixed the error of loading LMDB multi-epoch Segment Error?", "@Enigma-li Yes. But it hasn't been merged yet. It'd be great if you can bring it to the notice of TensorFlow maintainers by commenting on it. #13396", "@bowang Sure, already commented", "Closing as the PR is merged."]}, {"number": 12816, "title": "The efficiency of sess.run", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["use Tensorflow for Image detection and classification;\r\nFor a single image ,However small is it , the sess.run() method cost  above 10ms\r\nBut a batch(batch num = 100) input, the sess.run() cost less than 200ms,  2ms per image\r\nWhy? Can I improve the efficiency for single Image input?? \r\n  ", "This is better suited for stackoverflow.\r\n\r\nSmall batches have worse performance because of how modern hardware architecture is structured. IE, single image batches on CPU, it will have to load neural net parameters into cache for each image. For 200-batch, it can load those parameters into cache once, and reuse them for all 200 images.\r\n\r\nThere are sometimes tricks to speed up small batches, ie, by using libxsmm which has some integration with TensorFlow.", "As you said\uff0c single image batches on CPU, it will have to load neural net parameters into cache for each image\uff0c so the loading process consume too much time ?\r\nBut  in Machine Learning project we  usually load the neural net parameters(or trained model) at the very beginning for only once,  than we process each vali sample.\r\nCan tensorflow load the weights Once? Cause sometimes our model can be small and won't take much cache \r\n", "@juventi this is a general issue not specific to TensorFlow -- you get better utilization when dealing with large batches. For instance large matrix multiply can be 10x more efficient, in terms of ops/sec than small matrix multiplies. It has to do with underlying hardware organizing computation more efficiently, ie, by using SRAM cache, this is not something you can directly control from TensorFlow client side. "]}, {"number": 12815, "title": "image classifier error", "body": "Source : [tensorflow for poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#4)\r\n\r\n```\r\nAnujs-iMac:tensorflow-for-poets-2 anujchampjain$ python -m scripts.label_image     --graph=tf_files/retrained_graph.pb      --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg\r\n2017-09-05 12:48:36.936100: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-05 12:48:36.936140: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-05 12:48:36.936144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-05 12:48:36.936148: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nTraceback (most recent call last):\r\n  File \"/Users/anujchampjain/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/Users/anujchampjain/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/Users/anujchampjain/Desktop/Workspace/Tensorflow/tensorflow-for-poets-2/scripts/label_image.py\", line 120, in <module>\r\n    input_operation = graph.get_operation_by_name(input_name);\r\n  File \"/Users/anujchampjain/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2836, in get_operation_by_name\r\n    return self.as_graph_element(name, allow_tensor=False, allow_operation=True)\r\n  File \"/Users/anujchampjain/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2708, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/Users/anujchampjain/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2768, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'import/input' refers to an Operation not in the graph.\"\r\n```", "comments": ["Is there no solution for this issue I am getting the same error and I am stuck, \r\nknock knock anybody there? need help!!!", "@petewarden any clue?", "I found the solution it is this, \r\n\r\nchange height to 299 as shown below and input layer to Mul and it will work........:)\r\n  input_height = 299\r\n  input_width = 299\r\ninput_layer = \"Mul\"", "Seems like a duplicate of https://github.com/tensorflow/tensorflow/issues/12736", "Closing in favor of other bug. Thanks @quaeler !", "Thanks for the solution @prashanthsun9 !\r\n"]}, {"number": 12814, "title": "Fix a typo", "body": "Fix a typo in comments", "comments": ["@Meinwerk, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @vrv and @jart to be potential reviewers.", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "This is not a typo. This doc string contains special characters (e.g., backslashes). So adding r before the doc string is required by our linter."]}, {"number": 12813, "title": "How to add a user_ops to android .so file ?", "body": "### Discription\r\nI want to add a custom op for tensorflow and use it in android app. But I find it only tell us how to add an op in python . I put my own .cc file witch contains register code into the user_ops folder and bazel build again to generate a new .so file . But when I test this .so in android code, It says the custom op is not registered and crashed. How can I succeed to register a new op and build it into the android .so file? \r\n\r\nAnd I found that there are two folder named \"user_ops\" : tensorflow/tensorflow/user_ops ; and tensorflow/tensorflow/core/user_ops;  witch folder should I put my ops in ?  \r\n\r\nHope for your answer. Thank you so much!\r\n\r\n------------------------\r\n\r\n### System information\r\nTensorflow r1.2\r\n\r\n### Source code / logs\r\n![image](https://user-images.githubusercontent.com/10495849/30049205-4bb48d28-924c-11e7-828e-62e14ba2e9a6.png)\r\n\r\n![image](https://user-images.githubusercontent.com/10495849/30049227-658ed708-924c-11e7-8a77-0fa3cb4a1105.png)\r\n\r\n![image](https://user-images.githubusercontent.com/10495849/30049236-6cfa6b06-924c-11e7-8384-6de337db0807.png)\r\n\r\n\r\n\r\n\r\n", "comments": ["@andrewharp this seems to be somewhat of a recurring question, is there a canonical page to refer to or should we create one?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Hi scucheri,\r\nDid you find an answer to this question?\r\n\r\nBest", "finally I add my own ops to tensorflow as  kernel  ops do.  you can add the op file and register it to the bazel build file"]}, {"number": 12812, "title": "tensorflow/tensorflow/examples/ios/benchmark/ .   Calculate % in Images.", "body": "In this example How we can calculate the % of Prediction.\r\nWe are getting 1.0.978 water bottle \r\n1.0.988 bottle\r\n1.0.078 mug\r\n type of result.\r\n\r\nHow we can convert in % value", "comments": ["I'm sorry, I don't quite understand what you're asking. It looks like you might be saying\r\np(water bottle) = 0.978\r\np(bottle) = 0.988\r\np(mug) = 0.078\r\nand you'd like to convert these probabilities into percentages? Can you' just multiply by 100?\r\n\r\nIn any case, this issues section is more usually used for bugs and feature requests; perhaps Stack Overflow would be a better venue for this kind of question. \r\n"]}, {"number": 12811, "title": "The predict results using java and python is different", "body": "My graph contains the following statements:\r\n`tf.contrib.layers.batch_norm(incoming, is_training=is_training, scale=True, decay=0.99)`\r\n` tf.contrib.layers.dropout(incoming, keep_prob=keep_prob, is_training=is_training)`\r\n\r\nWhen the variable **is_training** is set to **True**, the saved model give the same result using Java and Python. The result is right.\r\n\r\nBut, when the variable **is_training** is set to **False**, the saved model give different result using Java and Python. Python give a right result. Java give a wrong result.\r\n\r\nWhy does this happen?\r\nTensorflow:1.2.0\r\nOS: centos7\r\nJava:Sun jdk 1.8.0.144\r\nPython:3.4.5\r\n", "comments": ["That's interesting. Do you happen to have a full repro case?", "@Kitter : Is there any more information you can provide?  A more complete example to help reproduce the problem will help. Can you share the saved model and the code you're using to load and execute it in Java and/or Python?", "@asimshankar :\r\n\r\npython code:\r\n\r\n    encoder_size = 64\r\n    decoder_size = 17\r\n    model_file='/test/model.pb'\r\n    with tf.gfile.FastGFile(model_file, 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n        _ = tf.import_graph_def(graph_def, name='')\r\n   \r\n    with tf.Session() as sess:\r\n        input_feed={}\r\n        file_name = \"/test/test.png\"\r\n        img = Image.open(file_name)\r\n        im = img.convert('L')\r\n        im = np.asarray(im, dtype=np.uint8)\r\n        imdata = np.array([[im]], dtype=int)\r\n        input_feed['img_data:0']= imdata\r\n        input_feed['zero_paddings:0']= np.zeros(shape=[1, 1, 512], dtype=float)\r\n        for l in range(int(encoder_size) - 1):\r\n            input_feed['encoder_mask'+str(l)+':0'] = np.array([[1]], dtype=float)\r\n        input_feed['encoder_mask'+str(int(encoder_size) - 1)+':0'] = np.array([[0]], dtype=float)\r\n        input_feed['decoder0:0'] = np.array([1], dtype=int)\r\n        outputs= []\r\n        decoders = []\r\n        for l in range(int(decoder_size)):\r\n            if l == 0:\r\n                decoder = sess.graph.get_tensor_by_name('model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection/AttnOutputProjection/BiasAdd:0')\r\n            else:\r\n                decoder = sess.graph.get_tensor_by_name('model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection_' + str(l) + '/AttnOutputProjection/BiasAdd:0')\r\n            decoders.append(decoder)\r\n        decoders=sess.run(decoders,input_feed)\r\n        decoders=np.argmax(decoders, 2)\r\n        for output in decoders:\r\n            outputs.append(output[0])\r\n        print(outputs)\r\n\r\nJava code:\r\n\r\n       private static final int DECODER_SIZE = 17;\r\n       private static float[][][][] convertImageToArray(BufferedImage bf) {\r\n            int width = bf.getWidth();\r\n            int height = bf.getHeight();\r\n            int[] data = new int[width * height];\r\n            bf.getRGB(0, 0, width, height, data, 0, width);\r\n            float[][][][] rgbArray = new float[1][1][height][width];\r\n            for (int i = 0; i < height; i++) {\r\n                for (int j = 0; j < width; j++) {\r\n                    rgbArray[0][0][i][j] = data[i * width + j];\r\n                }\r\n            }\r\n            return rgbArray;\r\n       }\r\n\r\n       String imageFilePath = \"/test/test.png\";\r\n       String modelDir=\"/test/model.pb\";\r\n       byte[] graphDef = Files.readAllBytes(Paths.get(modelDir));\r\n       File imageFile = new File(imageFilePath);\r\n       BufferedImage im = ImageIO.read(imageFile);\r\n       float[][][][] imgData = convertImageToArray(im);\r\n       Graph g = new Graph();\r\n       g.importGraphDef(graphDef);\r\n       Session s = new Session(g);\r\n       String imageData = \"img_data\";\r\n       String decodeName = \"decoder0\";\r\n       int encoderSize = 64;\r\n       String zeroPaddingName = \"zero_paddings\";\r\n       Runner runner = s.runner().feed(imageData, Tensor.create(imgData));\r\n       runner = runner.feed(decodeName, Tensor.create(new int[]{1}));\r\n       runner = runner.feed(zeroPaddingName,  Tensor.create(new float[1][1][512]));\r\n       for(int index = 0; index < encoderSize; index++){\r\n            float[][] encoderMask = new float[1][1];\r\n            encoderMask[0][0] = 1;\r\n            if(index == encoderSize - 1) encoderMask[0][0] = 0;\r\n            String encoderMaskName = \"encoder_mask\" + index;\r\n            runner = runner.feed(encoderMaskName, Tensor.create(encoderMask));\r\n        }\r\n       String outputName;\r\n       int[] encodes = new int[DECODER_SIZE];\r\n       String prefix = \"model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection\";\r\n       for(int index = 0; index < DECODER_SIZE; index++){\r\n           if(index == 0){\r\n               outputName = prefix + \"/AttnOutputProjection/BiasAdd\";\r\n           } else {\r\n               outputName = prefix + \"_\" + index + \"/AttnOutputProjection/BiasAdd\";\r\n           }\r\n           runner.fetch(outputName);\r\n        }\r\n       List<Tensor> tensorList = runner.runAndFetchMetadata().outputs;\r\n       s.close();\r\n       for(Tensor result : tensorList){\r\n          final long[] rshape = result.shape();\r\n          if (result.numDimensions() != 2 || rshape[0] != 1) {\r\n              throw new RuntimeException(String.format(\r\n                  \"Expected model to produce a [1 N] shaped tensor where N is the number of labels, instead it produced one with shape %s\",\r\n                  Arrays.toString(rshape)));\r\n          }\r\n          int charNum = (int) rshape[1];\r\n          float[] outputs = result.copyTo(new float[1][charNum])[0];\r\n          int bestLabelIdx = maxIndex(outputs);\r\n          int index = tensorList.indexOf(result);\r\n          encodes[index] = bestLabelIdx;\r\n       }\r\n\r\n\r\nsaved model: [model.pb](http://61.136.1.102:9001/model.pb)\r\n", "@Kitter still working on my first coffee, so forgive me if this first blush is wrong, but it looks like your Python code is converting the image data to grayscale (`im = img.convert('L')`) whereas i don't see any color space affectation in the Java code.\r\n\r\nIf that blush is wrong, does everything look equal if you dump the Python generated pixel array data and compare it to a dump of the Java generated pixel array data?\r\n\r\nAlso, purely out of curiosity, why choose PIL operations instead of the [TF image operations](https://www.tensorflow.org/api_guides/python/image)?", "@quaeler  I add converting of image grayscale  in Java code, the result is the same as before. There is no improvement.\r\n", "@Kitter can you put your `test.png` some place from where it can be downloaded; also, could you post the code with which you did the Java BI grayscale conversion? Also, also, did you do a pixel array dump from each Python and Java and compare the values?", "@quaeler  \r\nJava BI grayscale conversion code:\r\n\r\n\t\tBufferedImage grayImage = new BufferedImage(width, height, BufferedImage.TYPE_BYTE_GRAY);\r\n\t\tfor (int i = 0; i < width; i++) {\r\n\t\t\tfor (int j = 0; j < height; j++) {\r\n\t\t\t\tint rgb = bf.getRGB(i, j);\r\n\t\t\t\tgrayImage.setRGB(i, j, rgb);\r\n\t\t\t}\r\n\t\t}\r\n\r\nimage file [:test.png](http://61.136.1.102:9001/test.png)\r\n\r\nIt is strange that Java and Python use  the [model_true.pb](http://61.136.1.102:9001/model_true.pb) (is_training is set to True),  the result is same.", "Thanks for the assets.\r\n\r\nI'm sorry to be hung up on this, but we're on board with the pixel values being used in Python and Java being wholly different - ya? (The values in the Python ndarray are nicely in the 0-255 range however the Java values being returned from BI are bitwise'd 8-bit R, G, B (and probably A since this is a PNG) resulting in the 'float' values being in the general region of -1.4E7 range.)\r\n\r\n(I'm spinning down for the day - will try to look at the saved models tomorrow.)\r\n\r\n", "@quaeler \r\nThanks for your help. \r\nThis is my fault.I tried using tensorflow\u2018s API to read the picture file. I got the right result.", "@Kitter \r\nCould you please tell me which tensorflow's API you use to read the picture file in java? Thank you! ", "@q657198385 \r\nI use java.nio.file.Files to read image file data, then use tensorflow API to did the grayscale conversion. I get the correct result.\r\n\r\nsource code:\r\n\r\n    private static Tensor constructAndExecuteGraphToNormalizeImage(byte[] imageBytes) {\r\n        Graph g = new Graph();\r\n        GraphBuilder b = new GraphBuilder(g);\r\n        final Output input = b.constant(\"img_data\", imageBytes);\r\n        final float mean = 117f;\r\n        final float scale = 1f;\r\n        Output output = b.binaryOp(\"Reshape\",b.div(b.sub(b.cast(b.decodeJpeg(input, 1), DataType.FLOAT), \r\n        b.constant(\"mean\", mean)), b.constant(\"scale\", scale)), b.constant(\"make_batch\", new int[]{1,1,32,256}));\r\n        Session s = new Session(g);\r\n        Tensor tensor = s.runner().fetch(output.op().name()).run().get(0);\r\n        s.close();\r\n        return tensor;\r\n    }\r\n    byte[] imageBytes = Files.readAllBytes(Paths.get(\"src/test/resources/test.png\"));\r\n    Tensor image = constructAndExecuteGraphToNormalizeImage(imageBytes);"]}, {"number": 12810, "title": "build libtensorflow-core.a error  ", "body": "buf -lpthread -lm -lz\r\nUndefined symbols for architecture x86_64:\r\n\"nsync::nsync_mu_init(nsync::nsync_mu_s_)\", referenced from:\r\ntensorflow::mutex::mutex() in env.o\r\ntensorflow::mutex::mutex() in random.o\r\n\"nsync::nsync_mu_lock(nsync::nsync_mu_s_)\", referenced from:\r\ntensorflow::mutex::lock() in env.o\r\ntensorflow::mutex::lock() in random.o\r\ntensorflow::mutex::lock() in histogram.o\r\n\"nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\", referenced from:\r\ntensorflow::mutex::unlock() in env.o\r\ntensorflow::mutex::unlock() in random.o\r\ntensorflow::mutex::unlock() in histogram.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [/Users/9kacha/Desktop/TFFF/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1\r\n\r\n    '[' 2 -ne 0 ']'\r\n    echo 'armv7 compilation failed.'\r\n    armv7 compilation failed.\r\n    exit 1\r\n\r\nhow to fix this error ? ", "comments": ["rename ./tensorflow/contrib/makefile/downloads/nsync/builds/default.linux.c++11/nsync.a to libnsync.a  and then modify makefile  -L$(DOWNLOADSDIR)/nsync/builds/default.linux.c++11/   -lnsync", "@chinaluffy did that fix your problem?", "@liyungithub I'm having the same issue. I can't figure out what you mean by \"makefile -L$(DOWNLOADSDIR)/nsync/builds/default.linux.c++11/ -lnsync\"", "I saw this and did the following:\r\n./tensorflow/contrib/makefile/compile_nsync.sh\r\nThen added: HOST_NSYNC_LIB=`pwd`/tensorflow/contrib/makefile/downloads/nsync/builds/default.linux.c++11/nsync.a at the end of my make command.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Also having this problem I cannot build the nsync lib with compile_nsync.sh via build_all_android.sh. compile_android_protobuf.sh fails also.\r\n\r\nMy current error is just failing to find basic headers like string.h and stdlib.h. I believe it has something to do with using the r16 NDK, have the header paths changed? I started trying to add paths to the build scripts but am unsure if this will lead to a solution.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 66 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "\r\n\r\n\r\n\r\n> rename ./tensorflow/contrib/makefile/downloads/nsync/builds/default.linux.c++11/nsync.a to libnsync.a and then modify makefile -L$(DOWNLOADSDIR)/nsync/builds/default.linux.c++11/ -lnsync\r\n\r\nI got the similar linking error when building label_image example for Raspberry Pi, but fixed it by following @liyungithub 's tips, thanks\r\n\r\n"]}, {"number": 12809, "title": "Fix compile_nsync.sh", "body": "compile_nsync.sh is not workable with android x86 arch, here is the fix by replacing arm specific arch option.", "comments": ["Can one of the admins verify this patch?", "@m3bm3b mind taking a look? Thanks!", "@tensorflow-jenkins test this please"]}, {"number": 12808, "title": "tensorflow performance issue for map_fn and gather", "body": "I am trying to understand more about certain surprising results i see in implementing a tf graph .\r\nThe graph i am working with is just a forest (bunch of trees). This is just a plain forward inference graph , and nothing related to training. I am sharing the snippets for 2 implementation\r\n\r\ncode snippet 1: \r\n\r\n    with tf.name_scope(\"main\"):\r\n       \r\n        def get_tree_output(offset):\r\n            loop_vars = (offset,)\r\n            leaf_indice = tf.while_loop(cond,\r\n                                        body,\r\n                                        loop_vars,\r\n                                        back_prop=False,\r\n                                        parallel_iterations=1,\r\n                                        name=\"while_loop\")\r\n            tree_score = tf.gather(score_tensor, leaf_indice, name=\"tree-scores\")\r\n            output = tf.add(tree_score, output)\r\n\r\n        leaf_indices = tf.map_fn(get_tree_output,\r\n                                 tree_offsets_tensor,\r\n                                 dtype=INT_TYPE,\r\n                                 parallel_iterations=n_trees,\r\n                                 back_prop=False,\r\n                                 name=\"tree-scores\")\r\n\r\n        tree_scores = tf.gather(score_tensor, leaf_indices, name=\"tree-scores\")\r\n\r\n        output = tf.reduce_sum(tree_scores, name=\"sum-output\")\r\n        output = tf.sigmoid(output, name=\"sigmoid-output\")\r\n\r\n\r\ncode snippet 2:\r\n\r\n    with tf.name_scope(\"main\"):\r\n        tree_offsets_tensor = tf.constant(tree_offsets, dtype=INT_TYPE, name=\"tree_offsets_tensor\")\r\n        loop_vars = (tree_offsets_tensor,)\r\n        leaf_indices = tf.while_loop(cond,\r\n                                     body,\r\n                                     loop_vars,\r\n                                     back_prop=False,\r\n                                     parallel_iterations=n_trees,\r\n                                     name=\"while_loop\")\r\n\r\n        tree_scores = tf.gather(score_tensor, leaf_indices, name=\"tree-scores\")\r\n\r\n        output = tf.reduce_sum(tree_scores, name=\"sum-output\")\r\n        output = tf.sigmoid(output, name=\"sigmoid-output\")\r\n\r\n\r\n\r\nThe rest of the code is exactly the same  : the constant tensors , variables, condition and body for the while loop. thread and parallelism was also the same in both case\r\ncode snippet2 :  takes about 500 micro sec to do inference \r\ncode snippet 1 : take about  12 milli sec to do inference \r\n\r\nThe difference is that in snippet 1 , I use `map_fn` to operate on `tree_offset_tensor`, where as in snippet 2 , I get rid of that `map_fn`, and just directly use that tensor, so as I understand in snippet1 `get_tree_output` method gets called with one element from `tree_offset_tensor`, we are  having multiple `while_loop` for each individual offset value, whereas in snippet 2 we just have one `while_loop` that just takes multiple offset values (basically the offset_tensor). \r\n\r\nI also tried another variation for snippet , instead of using the map_fn  I write a hand written for loop\r\n\r\ncode snippet 1 (variation for loop) :\r\n\r\n    output = 0\r\n    with tf.name_scope(\"main\"):\r\n        for offset in tree_offsets:\r\n            loop_vars = (offset,)  # offset here is a scalar \r\n            leaf_indice = tf.while_loop(cond,\r\n                                        body,\r\n                                        loop_vars,\r\n                                        back_prop=False,\r\n                                        parallel_iterations=1,\r\n                                        name=\"while_loop\")\r\n            tree_score = tf.gather(score_tensor, leaf_indice, name=\"tree-scores\")\r\n            output = tf.add(tree_score, output)\r\n\r\n        #leaf_indices = tf.map_fn(get_tree_output,\r\n        #    tree_offsets_tensor, dtype=INT_TYPE,\r\n        #    parallel_iterations=n_trees, back_prop=False,\r\n        #    name=\"tree-scores\")\r\n\r\n        #tree_scores = tf.gather(score_tensor, leaf_indices, name=\"tree-scores\")\r\n\r\n        #output = tf.reduce_sum(tree_scores, name=\"sum-output\")\r\n        output = tf.sigmoid(output, name=\"sigmoid-output\")\r\n\r\nThis gives minor improvement :  9 millisec\r\nThe while condition does a bunch of gather operation , so if i use map_fn or the \"for loop\" the gather operates on a bunch of scalars instead of tensor of offset . Why is the code 20-40x slower , is the usage wrong or are there any caveats here ? Any help in understanding or optimizing this is appreciated", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12807, "title": "Speech-Recognitin issue", "body": "Hi,\r\n\r\nWhile running  \"python tensorflow/examples/speech_commands/train.py\"\r\n\r\nI am getting following issue.::\r\n\"ImportError: cannot import name audio_ops\"\r\n\r\nPlease help. \r\n", "comments": ["This is a known issue, we haven't released the drivers.\r\n\r\nhttps://stackoverflow.com/questions/45952387/anaconda-install-of-tensorflow-missing-audio-ops-from-contrib-framework"]}, {"number": 12806, "title": "Support more Android arch in Makefile build", "body": "Adds support for various Android arch in Makefile build.\r\n\r\nThis resolves #11996", "comments": ["Can one of the admins verify this patch?", "@resec, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @andrewharp to be potential reviewers.", "This pr is ready for review", "Jenkins, test this please.\r\n\r\n@andrewharp any opinion on this?", "@andrewharp ping?", "@andrewharp, already changed ANDROID_OS_ARCH to ANDROID_HOST_OS_ARCH, thanks.", "@lihanchen FYI", "Jenkins, test this please.", "@benoitsteiner can this be merged? I don't know why the checks don't seem to finish.", "Jenkins, test this please.", "@gunan Any idea why Ubuntu CC never reports back in?", "Those are the new tests, we need to trigger them using \"kokoro:force-run\" tag", "Jenkins, test this please.", "```\r\nERROR: Skipping '//tensorflow/contrib/eager/python:datasets_test': no such target '//tensorflow/contrib/eager/python:datasets_test': target 'datasets_test' not declared in package 'tensorflow/contrib/eager/python' defined by /tmpfs/src/github/tensorflow/tensorflow/contrib/eager/python/BUILD\r\n```\r\n\r\nNot sure. Re-trying."]}, {"number": 12805, "title": "\"High-Performance Models\" documentation page unclear on StagingArea not being a FIFOQueue", "body": "I feel that it would be good to modify the [High-Performance Models page](https://www.tensorflow.org/performance/performance_models ) to make it clear that the StagingArea class does not guarantee ordered delivery. \r\nThis would mean changing the line:\r\n\r\n> ... StagingArea is a queue-like operator similar to tf.FIFOQueue. The difference is that StagingArea offers simpler functionality and can be executed on both CPU and GPU in parallel with other stages.\r\n\r\nto something like this:\r\n\r\n> ... StagingArea is a queue-like operator similar to tf.FIFOQueue. The difference is that StagingArea does not guarantee FIFO ordering, but offers simpler functionality and can be executed on both CPU and GPU in parallel with other stages.\r\n\r\n\r\nI just spent longer than I'd care to admit bug-hunting, when FIFO ordering was critical.", "comments": ["BTW this is [mentioned](https://github.com/tensorflow/tensorflow/blob/b5214cab6151fc9c0471829a05bab4872e2e3bc4/tensorflow/python/ops/data_flow_ops.py#L1596) in documentation for StagingArea\r\n\r\n```\r\nclass StagingArea(BaseStagingArea):\r\n  \"\"\"Class for staging inputs. No ordering guarantees.\r\n\r\n```", "Yeah I did miss that originally. I just think it would be nice to amend the high performance models page too, as it currently seems like it has a complete list of the differences. ", "@ashwhall would you like to send a pull request on the documentation page to prevent this sort of confusion in the future? I think it's this file --\r\n tensorflow/tensorflow/docs_src/performance/performance_models.md", "Pull request https://github.com/tensorflow/tensorflow/pull/12833 created\r\n\r\nThanks!", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "PR has been merged a while back. Closing this. Thanks @ashwhall!"]}, {"number": 12804, "title": "Feature request - non-scalar Multinomial draws", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.12.6 \r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nFor Multinomial distribution the _sample_n method does not support total_count to be a vector and throws a \r\n```\r\nNotImplementedError(\"Sample only supported for scalar number of draws.\") \r\n```\r\n[https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/distributions/multinomial.py#L236](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/distributions/multinomial.py#L236)\r\nIt would be a really useful feature to add. \r\n\r\n\r\n### Source code / logs\r\nNA", "comments": ["Closing as this is resolved"]}, {"number": 12803, "title": "tensorflow create myOwn_op.dll on windows", "body": "Hi tf developers, I have one request regarding tensorflow's windows version. \r\n\r\nI have tensorflow+gpu successfully built on windows 10 with visual studio 2015, from the source code.\r\nas a result, I get tensorflow.dll and tensorflow.lib.\r\nI have CUDA8.0 and cudnn 5.0; with a gtx 1080 gpu equipped. \r\n\r\nhowever, my question is not about building and compiling tensorflow.\r\nit is about creating tensorflow plugins. \r\nI followed the tutorial https://www.tensorflow.org/extend/adding_an_op to construct my own \"plug-in\".\r\nand then I tried to compile a windows .dll; so windows would not export symbols automatically for me .\r\nthen I compile a static lib first and used your tools \r\n /tensorflow/contrib/cmake/tools/create_def_file.py\r\nto create a .def file for me and eventually used that to compile the .dll.\r\n\r\nhowever, in my python code, when I tried to __correlation__ =  tf.load_op_library(correlation.dll) and I called      __correlation__.correlation()\r\nwith Correlation registered using REGISTER_OP(\"Correlation\");\r\nit still tells me\r\n AttributeError: module '7b088d8b906b36d3e50721b0adbaaa6a' has no attribute 'correlation'\r\n\r\nI think this is just  a windows (or cl compiler) issue, maybe what REGISTER_OP(\"Correlation\") did is just not picked up by the compiler,\r\n\r\nso is there any thing I can do to make this happen on windows??\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Hi I think \"making the tensorflow integration with windows more smooth\"\nshould in general be a feature request,\nconsider it will benefit a large community such as real-time computer\ngraphics and video games etc.\n\nOn Mon, Sep 4, 2017 at 4:15 PM, Justine Tunney <notifications@github.com>\nwrote:\n\n> This question is better asked on StackOverflow\n> <http://stackoverflow.com/questions/tagged/tensorflow> since it is not a\n> bug or feature request. There is also a larger community that reads\n> questions there. Thanks!\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12803#issuecomment-327037745>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALqEy5uwtjHskkObeR-RVXxdsvd4V7SPks5sfISRgaJpZM4PMQgl>\n> .\n>\n"]}, {"number": 12802, "title": "Cleanup work", "body": "Updated summary_op_util.py, head.py,  estimator.py, lookup_ops.py", "comments": ["Can one of the admins verify this patch?", "@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ysuematsu, @tensorflower-gardener and @ispirmustafa to be potential reviewers.", "Jenkins, test this please.", "GPU timeout.\r\n\r\nJenkins, test this please.", "@martinwicke @drpngx do these changes look good now?"]}, {"number": 12801, "title": "Change `dim` to `axis` for cosine_distance", "body": "This fix changes  `dim` to `axis` for cosine_distance so that the args are consistent with other methods in TensorFlow.\r\n\r\nThe backward-compatibility has been maintained in the fix.\r\n\r\nThis fix fixes #8205.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@martinwicke for api change approval.", "The PR has been rebased and pushed to address the merge conflict.", "Jenkins, test this please.\r\n\r\n@martinwicke good to go?", "The Jenkins failure is related to `//tensorflow/tools/api/tests:api_compatibility_test`. Will update the PR once api changes are approved.", "@martinwicke ping?", "Otherwise looks good, please run the compatibility golden update.", "Thanks @martinwicke for the review and sorry for the late reply (was out of town until this week). The PR has been updated with API goldens rerun. Please take a look.", "Jenkins, test this please.", "Unrelated failure. @rmlarsen is the lingalg test known to be flaky? ", "Jenkins, test this please.\r\n\r\nFor reference,\r\n```\r\n//tensorflow/python/kernel_tests:linalg_ops_test                        TIMEOUT in 105.5s\r\n```"]}, {"number": 12800, "title": "Fix incorrect error message in TensorArray.scatter", "body": "This fix tries to fix the issue raised in #12403 where the error message in TensorArray.scatter is incorrect. Specifically, in\r\n```\r\n      OP_REQUIRES(\r\n          ctx, max_index < array_size,\r\n          errors::InvalidArgument(\"Max scatter index must be <= array size (\",\r\n                                  max_index, \" vs. \", array_size, \")\"));\r\n```\r\n\r\nThe `<= array size` in error message should be `< array size` as the maximum value of index (0-based) should always be smaller than array size.\r\n\r\nThis fix fixes #12403.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "cmake failure is due to a flaky timeout. This is ready to be merged."]}, {"number": 12799, "title": "problem with optimize_for_inference", "body": "hi,\r\nI'm using tensorflow 1.3.0 installed via pip with python 2.7.12 (Ubuntu 16.04, cuda 8, nvidia 1060)\r\n\r\nwhen i try to optimize a custom model trained with tensorflow 1.3.0 with \r\n\r\n`python -m tensorflow.python.tools.optimize_for_inference --input saved_model.pb --output opt_model.pb --input_names=in --output_names=out`\r\n\r\ni get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/**********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\r\n    input_graph_def.ParseFromString(data)\r\n  File \"/home/***********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/message.py\", line 185, in ParseFromString\r\n    self.MergeFromString(serialized)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1069, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 633, in DecodeField\r\n    if value._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 612, in DecodeRepeatedField\r\n    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 743, in DecodeMap\r\n    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1095, in InternalParse\r\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 799, in _SkipGroup\r\n    new_pos = SkipField(buffer, pos, end, tag_bytes)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 814, in _SkipFixed32\r\n    raise _DecodeError('Truncated message.')\r\ngoogle.protobuf.message.DecodeError: Truncated message.\r\n```\r\n\r\n\r\ni already did a ' export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python'\r\nwithout doing it i got\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\r\n    input_graph_def.ParseFromString(data)\r\ngoogle.protobuf.message.DecodeError: Error parsing message\r\n```\r\n\r\nI'm saving the model like:\r\n\r\n```\r\nbuilder = saved_model_builder.SavedModelBuilder(\"model\"))\r\nbuilder.add_meta_graph_and_variables(sess,['serve'],signature_def_map= {\"model\": tf.saved_model.signature_def_utils.predict_signature_def(inputs= {\"in\" : X }, outputs= {\"out\": pred_Y })})\r\nbuilder.save()\r\n```\r\n\r\ni had the same issue with 1.2.1, after this i did the upgrade to 1.3.0 via pip install --upgrade and a retrain.\r\n\r\ni have no issues loading and using the model with tensorflow-rust in my test application, but to add some context i got the error\r\n\r\n```\r\nCaused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef \r\nat  org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392) at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)\r\n```\r\n\r\nwhen trying to load the model with tensorflow on android. first i thought this would be because of some unsupported ops, so i went the optimize_for_inference way. but i guess it looks like a protobuf issue\r\n \r\ni would appreciate any hint to solve this issue.\r\nwith best regards\r\n\r\n", "comments": ["Did you close this because you found the solution or went another way? I'm having the same message using the SavedModel exported by the Estimator API. Not sure here if the input/output nodes were correctly chosen.", "I'm having the same problem. Do you have the solution @kollapsderwellenfunktion ? ", "I am having the same problem, is there a solution for this?\r\n", "any solution?\r\n"]}, {"number": 12798, "title": "Revert \"Add vmodule support to TF OSS logging.\"", "body": "This reverts commit 072b0c9c552837a97c967963628b3c30951388f9.\r\n\r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/1508/console\r\nThis is to fix https://github.com/tensorflow/tensorflow/issues/12117 again, because https://github.com/tensorflow/tensorflow/pull/12151 got rollbacked.\r\n\r\n@learyg Sorry, I have to roll back this to fix the Windows build.\r\n\r\n@gunan ", "comments": ["Sounds good, today was a vacation day in the US so I was AFK. Will look at rolling forward a proper fix sometime this week. @gunan do we believe we have some target that'll fail if I introduce a dependency like this again? Didn't seem at submit time like anything was exploding in the CMake build, but I totally may have missed something. Happy to take any advice on making sure I do a properly tested fix, will try my darndest. :-)", "@gunan I remember you tried to set up a Kokoro presubmit job for just building TensorFlow on Windows, is it already working now?", "not yet, I have been sidetracked by other issues.\nI will try to make some time tomorrow.\n\nOn Wed, Sep 6, 2017 at 4:37 AM, Yun Peng <notifications@github.com> wrote:\n\n> @gunan <https://github.com/gunan> I remember you tried to set up a Kokoro\n> presubmit job for just building TensorFlow on Windows, is it already\n> working now?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12798#issuecomment-327456443>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOcEQj9ZagU3I0SWh15XT5955HZOmks5sfoPggaJpZM4PME13>\n> .\n>\n", "@learyg, would it be as simple as changing all `StringPiece` to `std::string` and then using\r\n\r\n```c++\r\n#include <string>\r\n#include <functional>\r\n\r\n  struct Hasher {\r\n    std::hash<std::string> hash_fn_;\r\n    size_t operator()(std::string arg) const {\r\n      return hash_fn_(arg);\r\n    }\r\n  };\r\n  using VmoduleMap = std::unordered_map<std::string, int, Hasher>;    \r\n```\r\n\r\nAs far as i can tell, the key constructors used for `StringPiece` and `std::string` are compatible (`const char*` with `size_t`)\r\n\r\n", "@apark263 There was some concern about the allocations that might be created by the std::strings, since VLOGging is so prevalent. Probably we could just define a custom hasher for the const char\\*s as keys, VLOG macro should always result in a stable const char* pointer to hash via the \\_\\_FILE\\_\\_ preprocessing token. +@hawkinsp who originally voiced the concern.", "@learyg @hawkinsp any plans to add vmodule support back? It greatly helps when debugging TensorFlow."]}, {"number": 12797, "title": "UINT8 is used but only partly supported in the Java API.", "body": "The datatype uint8 exists in the Java API (see DataType.UINT8) and is used by the LabelImage program. However, it does not seem to be fully supported. In particular, elemByteSize() in tensor_jni.cc does not have a case for TF_UINT8, which prevents uint8 tensors from being created or extracted from TensorFlow.", "comments": ["/CC: @asimshankar \r\n\r\nIt looks like you have a pending PR to fix this, LMK if you expect some action on our part.", "@andrewcmyers : Thanks for pointing this out. Do you want to package the commit in your repository as an independent PR?", "It's a bit entangled with the generics stuff. I could create a separate commit that fixes this problem, I guess. That would create some conflicts to iron out later.", "The genesis of the fix is due to [a merge down for the generics stuff,](https://github.com/tensorflow/tensorflow/pull/11535/commits/46981fb61c393a1b32b6e4569ac2e3e5c47b240f) so it makes more sense (imo) to include it in the PR for the generics stuff and not as a postscript to it."]}, {"number": 12796, "title": "About Cyclic Graph?", "body": "Here is the code that confuses me:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(0)\r\nupdate_a = tf.assign(a, a * 2 + 1)\r\nupdate_b = tf.assign(a, a * 3 + 3)\r\n\r\ns = tf.Session()\r\ns.run(tf.global_variables_initializer())\r\n\r\n_, _, x = s.run([update_b, update_a, a])\r\nprint(x)\r\n```\r\n\r\nIt outputs different results (1, 3, 6 and 7, 7 is the most) at different runs.\r\n\r\nI think it is caused by the cyclic graph. I don't know if tf has the constriction that the above graph is not allowed. But I have another more common example:\r\n\r\na = convnet_with_bn(img_a)\r\nb = convnet_with_bn(img_b)\r\n\r\nwhen the convnet is share, the bn' moving average operations is like the above code.\r\n\r\nCan anybody tells me how I can deal with the above problem?\r\n", "comments": ["This may be more appropriate for stack overflow. TensorFlow will run your `update_a` and `update_b` ops in random order", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}]