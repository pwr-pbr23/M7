[{"number": 11178, "title": "Inconsistent losses for Keras", "body": "TF 1.2.0, Python 3.5.\r\n\r\n## TF Official Keras\r\n```\r\ntf.contrib.keras.backend.sparse_categorical_crossentropy (output, target)\r\ntf.contrib.keras.losses.sparse_categorical_crossentropy  (target, output)\r\ntf.contrib.keras.metrics.sparse_categorical_crossentropy (target, output)\r\ntf.losses.sparse_softmax_cross_entropy (target, output)  - no sentinel\r\ntf.nn.sparse_softmax_cross_entropy_with_logits (target, output)\r\n'sparse_softmax_cross_entropy'\r\n```\r\n\r\n## Pure Keras\r\n```\r\nkeras.losses.sparse_categorical_crossentropy(target, output)\r\n```\r\n\r\nThere are many `sparse_softmax_cross_entropy` but they all have different APIs. Some are compatible with `tf.contrib.keras.models.Model.compile()` and  the others are not because of `_sentinel` and different order of `output` and `target`.\r\n\r\nInterestingly both the original TF and Keras use (target, output) and only `tf.contrib.keras.backend` version uses (output, target). tf-keras needs to use (output, target) otherwise the model is not trained.\r\n\r\nCan we unify the interface and document when to use each version?\r\n", "comments": ["Thanks for reaching out!\r\n\r\ncc: @martinwicke ", "Yes. We can remove the sentinel. We put it in as a safety since the those losses were not symmetric and we switched the argument order.\r\n\r\nHopefully, then, all losses will use (target, output), and can all be used with compile.", "> tf.contrib.keras.backend version uses (output, target)\r\n\r\nThat was modeled after the initial TF version. It was an oversight and we can change it. `backend.sparse_categorical_crossentropy` is meant as a cross-backend layer, it's not for public consumption; the official API is in `keras.losses`.", "I also found that the input arguments order of keras.backend.categorical_crossentropy() and keras.backend.tensorflow_backend.categorical_crossentropy() are not consistent with keras.losses.categorical_crossentropy(). I found this when I try to use the loss function from keras to check the numpy implementation of cross entropy loss function:\r\n```\r\nimport numpy as np\r\nimport keras\r\nimport keras.backend as K\r\n\r\nnp.random.seed(666)\r\ndef categorical_crossentropy_np(y_true, y_pred):\r\n    _EPSILON = K.epsilon()\r\n    y_pred = y_pred / np.expand_dims(np.sum(y_pred, axis=-1), axis=-1)\r\n    y_pred = np.clip(y_pred, _EPSILON, 1.0-_EPSILON)\r\n    return -np.sum(y_true * np.log(y_pred), axis=-1)\r\n\r\ndef check_loss():\r\n    shape = (6, 8)\r\n\r\n    y_a = np.random.random(shape).astype(np.float32)\r\n    y_b = np.random.random(shape).astype(np.float32)\r\n\r\n    # case 1\r\n    out1 = K.eval(K.categorical_crossentropy(K.variable(y_a), K.variable(y_b)))\r\n    # case 2\r\n    # out1 = K.eval(K.categorical_crossentropy(K.variable(y_b), K.variable(y_a))) \r\n    # case 3\r\n    # out1 = K.eval(keras.backend.tensorflow_backend.categorical_crossentropy(K.variable(y_a), K.variable(y_b))) \r\n    # case 4\r\n    # out1 = K.eval(keras.backend.tensorflow_backend.categorical_crossentropy(K.variable(y_b), K.variable(y_a))) \r\n    # case 5\r\n    # out1 = K.eval(keras.losses.categorical_crossentropy(K.variable(y_a), K.variable(y_b))) \r\n    # case 6\r\n    out2 = categorical_crossentropy_np(y_a, y_b)\r\n\r\n    assert out1.shape == out2.shape\r\n    assert out1.shape == shape[:-1]\r\n\r\n    print out1\r\n    print out2\r\n\r\nif __name__ == '__main__':\r\n    check_loss()\r\n\r\n```\r\nThe results are:\r\n(case 2 = case 4 = case 5 = case 6) \u2260 (case 1 = case 3)\r\n\r\n\r\n\r\n", "The backend functions are internal only and fixable. PRs welcome.", "This specific issue has been fixed in Keras 2.0.7. The version included in\ncontrib as of TF 1.3 is Keras 2.0.6, though.\n\nOn 25 September 2017 at 09:12, Martin Wicke <notifications@github.com>\nwrote:\n\n> The backend functions are internal only and fixable. PRs welcome.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11178#issuecomment-331930840>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AArWb3stv4yHDeqTMwyVzdRIPQCYN4ufks5sl9EJgaJpZM4OKuWG>\n> .\n>\n", "Got it. Thanks for your reply!", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "We updated past 2.0.9, so this should be fixed."]}, {"number": 11177, "title": "[OpenCL] Fixes warning caused by half type", "body": "  - half requires opencl extension that might not be avaiable on all platforms\r\n  - extends cast operation to cover int8, int16, uint8, uint16", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11176, "title": "[OpenCL] Fixes transpose operation", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11175, "title": "TensorFlow", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Also, I'm not sure what this does. Could you rebase, push again?"]}, {"number": 11174, "title": "Only use weakref.finalize from backports in Python < 3.4", "body": "The `backports` module should not be forced as a dependency for Python >= 3.4 as `weakref.finalize` has been introduced in Python 3.4. This solves #11082 and an [Arch Linux bug](https://bugs.archlinux.org/task/54606).", "comments": ["Can one of the admins verify this patch?", "LGTM but do we need to disable the third_party build rules for python3 to fix the arch Linux issue?  Either way this PR should go in if all tests pass.", "I don't know what you mean by \"the third_party build rules for python3\" but this change fixes the Arch Linux issue (which uses Python 3.6). The problem is that the `python-tensorflow` package depends on the `backports-weakref` package which is not listed in the requirements. BTW shall we declare `backports-weakref` as a requirement for Python < 3.4 somewhere?", "Jenkins, test this please.", "I thought it's in the pip setup.py as a requirement?\n\nOn Jun 30, 2017 10:39 AM, \"drpngx\" <notifications@github.com> wrote:\n\n> Jenkins, test this please.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-312329158>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim6dThDk13U0AMPxYG2CFt-DmKN3dks5sJTLEgaJpZM4OKnup>\n> .\n>\n", "@ebrevdo, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L38\r\n\r\nSomething like [this](https://github.com/sphinx-doc/sphinx/pull/3789#issuecomment-303943521) should work.\r\n\r\nEdit: Otherwise [this](https://github.com/ross/requests-futures/blob/master/setup.py#L25-L26).", "In [arch linux PKGBUILD](https://git.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/tensorflow#n104) the `pip install` command will be executed with `--no-dependencies` option. All the dependencies will be packaged separately and handled/installed by the systems package manager pacman. \r\n\r\nNevertheless, it makes sense to restrict the `backports.weakref` requirement to Python < 3.4 in the setup.py file, to avoid unneccessary installation of this package also on other platforms. ", "Feel free to add it to this PR.\n\nOn Jun 30, 2017 2:14 PM, \"spinnau\" <notifications@github.com> wrote:\n\n> In arch linux PKGBUILD\n> <https://git.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/tensorflow#n104>\n> the pip install command will be executed with --no-dependencies option.\n> All the dependencies will be packaged separately and handled/installed by\n> the systems package manager pacman.\n>\n> Nevertheless, it makes sense to restrict the backports.weakref\n> requirement to Python < 3.4 in the setup.py file, to avoid unneccessary\n> installation of this package also on other platforms.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-312374301>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxEqz-TU308wBiKVWyh9pqb_ZmM2ks5sJWUigaJpZM4OKnup>\n> .\n>\n", "Indeed most package managers store the dependencies on their own. Let's conditionally depend on `backports.weakref` in the `setup.py` (avoiding clutter for `pip` users). I'll update the PR. Thanks for your comments!", "I've updated `setup.py` to only depend on `backports.weakref` for Python < 3.4.\r\n\r\nShould we do something about 4ac7cc54c81984e38da7a17992a56f62560e2870? I don't know how Bazel works.", "There's only one version of `backports.weakref` so yes. I think it's less restrictive for the users in case they release an update.", "The versioning on that package is funny.  pip won't find it if you don't\nput the version number after the package name. That is why I was asking.\n\nOn Jul 3, 2017 2:08 PM, \"Micha\u00ebl Defferrard\" <notifications@github.com>\nwrote:\n\n> There's only one version of backports.weakref so yes. I think it's less\n> restrictive for the users in case they release an update.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-312733987>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8_byC9uWScQ9qFUwGpo63XqLcxXks5sKVhlgaJpZM4OKnup>\n> .\n>\n", "@ebrevdo: For me pip finds and installs backports.weakref (version 1.0rc1) just fine without giving any version number:\r\n \r\n```bash\r\n$ pip --version\r\npip 9.0.1 from /usr/lib/python3.6/site-packages (python 3.6)\r\n\r\n$ pip install --user backports.weakref\r\nCollecting backports.weakref\r\n  Using cached backports.weakref-1.0rc1-py3-none-any.whl\r\nInstalling collected packages: backports.weakref\r\nSuccessfully installed backports.weakref-1.0rc1\r\n```\r\n\r\nThe `>=1.0rc` version check from the setup.py creates the entry `Requires-Dist: backports.weakref (>=1.0rc1)` inside the wheels METADATA file. Installing the package and pulling the dependency also works fine for me with this using pip.\r\n\r\nAccording to this section in [PEP440](https://www.python.org/dev/peps/pep-0440/#inclusive-ordered-comparison) the inclusive ordered comparison `>=` can be used with the standard [version scheme](https://www.python.org/dev/peps/pep-0440/#version-scheme) and thus, also includes pre-release specifiers like `rc`.", "Interesting. That command did not work for me on a standard Ubuntu install\nwith python2.7.\n\nOn Jul 3, 2017 3:04 PM, \"spinnau\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo>: For me pip finds and installs\n> backports.weakref (version 1.0rc1) just fine without giving any version\n> number:\n>\n> $ pip --version\n> pip 9.0.1 from /usr/lib/python3.6/site-packages (python 3.6)\n>\n> $ pip install --user backports.weakref\n> Collecting backports.weakref\n>   Using cached backports.weakref-1.0rc1-py3-none-any.whl\n> Installing collected packages: backports.weakref\n> Successfully installed backports.weakref-1.0rc1\n>\n> The >=1.0rc version check from the setup.py creates the entry Requires-Dist:\n> backports.weakref (>=1.0rc1) inside the wheels METADATA file. Installing\n> the package and pulling the dependency also works fine for me with this\n> using pip.\n>\n> According to this section in PEP440\n> <https://www.python.org/dev/peps/pep-0440/#inclusive-ordered-comparison>\n> the inclusive ordered comparison >= can be used with the standard version\n> scheme <https://www.python.org/dev/peps/pep-0440/#version-scheme> and\n> thus, also includes pre-release specifiers like rc.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-312741039>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzjP_NVAGK-roZkgQgum1UUoXxoBks5sKWVigaJpZM4OKnup>\n> .\n>\n", "I just checked on Ubuntu 16.04 with Python 2.7 and it worked fine without giving any version number either:\r\n\r\n```\r\n$ pip --version\r\npip 8.1.1 from /usr/lib/python2.7/dist-packages (python 2.7)\r\n\r\n$ pip install --user backports.weakref\r\nCollecting backports.weakref\r\n  Downloading backports.weakref-1.0rc1-py2-none-any.whl\r\nInstalling collected packages: backports.weakref\r\nSuccessfully installed backports.weakref\r\n```\r\n\r\nShall we get rid of the version number altogether?", "$ cat /etc/lsb-release\nDISTRIB_CODENAME=trusty\nDISTRIB_DESCRIPTION=\"Ubuntu 14.04 LTS\"\n\n$ pip --version\npip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)\n\n$ pip install backports.weakref\nDownloading/unpacking backports.weakref\n  Could not find a version that satisfies the requirement backports.weakref\n(from versions: 1.0rc1, 1.0rc1)\n\n$ pip install backports.weakref>=1.0rc1\n(does NOTHING - just exits)\n\n$ pip install backports.weakref==1.0rc1\n(works!)\n\nso, please keep the string \"backports.weakref==1.0rc1\", not\n\"backports.weakref>=1.0rc1\" and do not remove the version number.\n\nOn Tue, Jul 4, 2017 at 2:06 AM, Micha\u00ebl Defferrard <notifications@github.com\n> wrote:\n\n> I just checked on Ubuntu 16.04 with Python 2.7 and it worked fine without\n> giving any version number either:\n>\n> $ pip --version\n> pip 8.1.1 from /usr/lib/python2.7/dist-packages (python 2.7)\n>\n> $ pip install --user backports.weakref\n> Collecting backports.weakref\n>   Downloading backports.weakref-1.0rc1-py2-none-any.whl\n> Installing collected packages: backports.weakref\n> Successfully installed backports.weakref\n>\n> Shall we get rid of the version number altogether?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-312824051>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim_nq_MRZO4_Zz6N70KhN0tech_f4ks5sKgB9gaJpZM4OKnup>\n> .\n>\n", "Okay. Maybe it's due to the old pip 1.5.4... I updated the PR.", "> $ pip install backports.weakref>=1.0rc1\r\n(does NOTHING - just exits)\r\n\r\n@ebrevdo: The package name and the version should be covered in quotation marks here, as otherwise in the shell the `>` sign redirects the output to file named `=1.0rc1`.\r\n\r\n```\r\n$ pip --version\r\npip 1.5.4 from /usr/local/lib/python2.7/dist-packages (python 2.7)\r\n\r\n$ pip install --user \"backports.weakref>=1.0rc1\"\r\nDownloading/unpacking backports.weakref>=1.0rc1\r\n  Downloading backports.weakref-1.0rc1-py2-none-any.whl\r\nInstalling collected packages: backports.weakref\r\nSuccessfully installed backports.weakref\r\nCleaning up...\r\n```\r\n\r\nAs I mentioned before, installing the tensorflow wheel package works fine for me if I change the version specifier inside the wheel from `==1.0rc1` to `>=1.0rc1` (unzip wheel file; edit METADATA file in dist-info folder; zip changed package again).\r\n\r\nI have also tested this on Ubuntu 14.04.05 LTS with pip 1.5.4, which works fine and downloads the rc1 package as expected:\r\n\r\n```\r\n$ uname -a\r\nLinux ubuntu 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n$ pip --version\r\npip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)\r\n\r\n$ aptitude show python-setuptools\r\nPackage: python-setuptools                   \r\nState: installed\r\nAutomatically installed: yes\r\nVersion: 3.3-1ubuntu2\r\n\r\n$ pip install tensorflow-1.2.1-cp27-none-linux_x86_64.whl \r\nUnpacking ./tensorflow-1.2.1-cp27-none-linux_x86_64.whl\r\nDownloading/unpacking mock>=2.0.0 (from tensorflow==1.2.1)\r\n  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB): 56kB downloaded\r\nDownloading/unpacking bleach==1.5.0 (from tensorflow==1.2.1)\r\n  Downloading bleach-1.5.0-py2.py3-none-any.whl\r\nDownloading/unpacking numpy>=1.11.0 (from tensorflow==1.2.1)\r\n  Downloading numpy-1.13.0.zip (5.0MB): 5.0MB downloaded\r\n  Running setup.py (path:/tmp/pip_build_ubuntu/numpy/setup.py) egg_info for package numpy\r\n    Running from numpy source directory.\r\n    /usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'python_requires'\r\n      warnings.warn(msg)    \r\n    warning: no previously-included files matching '*.pyc' found anywhere in distribution\r\n    warning: no previously-included files matching '*.pyo' found anywhere in distribution\r\n    warning: no previously-included files matching '*.pyd' found anywhere in distribution\r\nDownloading/unpacking backports.weakref>=1.0rc1 (from tensorflow==1.2.1)\r\n  Downloading backports.weakref-1.0rc1-py2-none-any.whl\r\nDownloading/unpacking markdown>=2.6.8 (from tensorflow==1.2.1)\r\n[...]\r\n```\r\n\r\nYour suggested change that was already implemented by @mdeff should be ok, but according to PEP440 *\"The use of == (without at least the wildcard suffix) when defining dependencies for published distributions is strongly discouraged as it greatly complicates the deployment of security fixes.\"*\r\n\r\nEdit: In the tensorflow installation instructions it is also strongly recommended to update pip to version 8.1 or higher.\r\n\r\nEdit2: Added version infos for test on Ubuntu 14.04 LTS\r\n", "I agree about PEP404: that is why I changed `==` to `>=` in the first place.\r\n\r\n@spinnau do you know why `pip install backports.weakref` does not work with pip 1.5.4?", "@mdeff: According to [this section of PEP404](https://www.python.org/dev/peps/pep-0440/#handling-of-pre-releases) *\"Pre-releases of any kind, including developmental releases, are implicitly excluded from all version specifiers, unless they are already present on the system, explicitly requested by the user, or if the only available version that satisfies the version specifier is a pre-release.\"* \r\n\r\nMaybe the functionality regarding the last part of that sentence was implemented after pip-1.5.4. You can also get this behavior by explicitly adding the `--pre` option to the pip install command.\r\n\r\nBut as the `>=` comparison combined with pre-release version specifiers already works in pip-1.5.4, this should not be a problem here.\r\n\r\n\r\n ", "Thanks @spinnau for your explanations. Back to `>=` then. I hope we can merge now. :)", "@ebrevdo, @spinnau does this look good to you now?\r\n\r\n@tensorflow-jenkins test this please", "LGTM\r\n\r\n* bazel build of pip-package (wheel) for Python-3.6 works fine on archlinux\r\n* the created Python-3.6 wheel installs and works fine on archlinux\r\n* verified that Python-2.7 wheel with changed dependency in METADATA file (`backports.weakref >= 1.0rc1` instead of `backports.weakref == 1.0rc1`) finds and downloads the backports.weakref package just fine on Ubuntu 14.04 LTS", "LGTM\n\nOn Jul 6, 2017 2:57 PM, \"spinnau\" <notifications@github.com> wrote:\n\n> LGTM\n>\n>    - bazel build of pip-package (wheel) for Python-3.6 works fine on\n>    archlinux\n>    - the created Python-3.6 wheel installs and works fine on archlinux\n>    - verified that Python-2.7 wheel with changed dependency in METADATA\n>    file (backports.weakref >= 1.0rc1 instead of backports.weakref ==\n>    1.0rc1) finds and downloads the backports.weakref package just fine on\n>    Ubuntu 14.04 LTS\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11174#issuecomment-313530509>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim-koJ2jGJjI-oQkjSbIBgAylQ51nks5sLVgxgaJpZM4OKnup>\n> .\n>\n", "@tensorflow-jenkins test this please"]}, {"number": 11173, "title": "Fixed 404 page in the docs (install_c.md)", "body": "When following the current link to `c_api.h` the link will results in a 404 page, see: https://github.com/tensorflow/tensorflow/tree/master/c/c_api.h", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "/CC: @MarkDaoust ", "@tensorflow-jenkins test this please"]}, {"number": 11172, "title": "[XLA] Ensure that the 2 data types chosen by the test are both valid for the device", "body": "Simple change.  The test previously assumed that all devices support float64, which isn't true for our device.\r\n\r\nNow the test will find 2 different floating point types and use those.  Doesn't execute if there are not 2 floating point types to choose from.\r\n", "comments": ["Can one of the admins verify this patch?", "hi.  Is this one ok now?\r\n", "Jenkins, test this please.", "Jenkins, test this please.", "thanks\r\n", "Ah, there is a problem.\r\n\r\n```\r\nInvalidArgumentError (see above for traceback): TensorArray dtype is float but op has dtype double.\r\n```", "@DavidNorman, any thoughts on how to fix the test failure that @drpngx pointed out?", "thinking about it now...  shouldn't be too hard.", "hmm... that error is what it is meant to do.  it is checking to see if that exception is thrown when the types don't match.   perhaps the regular expression for matching the types isn't quite right.  it is ok on my Mac - but it could be down to different python versions.  i'll check on a linux machine.\r\n", "ok - it really is that the exception regexp match doesn't match on the test machine, but does on my two machines.  am thinking of using [a-z] instead of the character class.  or maybe just match:\r\n\r\n\"TensorArray dtype is \"\r\n\r\n", "@drpngx  ok - lets try testing that again.  I've tried all 3 of our various machines and none of them fail.  it must be some sort of python weirdness.\r\n", "@tensorflow-jenkins test this please", "hmm..  still failing.  It doesn't really make sense.   I think I will have to do a clean build from a fresh checkout to make sure I am not missing something.\r\n\r\nI'll get back to you once I have found something", "@caisq \r\n\r\noops - i just noticed that my last change didn't actually merge the RE change that I was hoping for.   Can we try once again please?\r\n\r\nhopefully the problem is that the CI system python doesn't like '\\c' as a regexp thing.\r\n\r\n", "Jenkins, test this please.", "phew - at least this time it was a completely different build problem.   presumably it has gone away by now...\r\n", "and thankfully the XLA test passed.   It must have been something about regexp support in python (perhaps not accepting \\c as a character class) - or maybe a failure in my escaping (?)\r\n\r\nanyway - hope that the GPU tests go through on the next try.\r\n", "Jenkins, test this please.\n\nOn Jul 10, 2017 1:55 AM, \"David Norman\" <notifications@github.com> wrote:\n\n> and thankfully the XLA test passed. It must have been something about\n> regexp support in python (perhaps not accepting \\c as a character class) -\n> or maybe a failure in my escaping (?)\n>\n> anyway - hope that the GPU tests go through on the next try.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11172#issuecomment-314045880>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbSLyM-yFHW0zTjQ1iB4ZwdAU71ORks5sMecJgaJpZM4OKjK6>\n> .\n>\n", "@drpngx hooray - thanks goodness - they all passed :)\r\n", "Yay!"]}, {"number": 11170, "title": "Adding support for s390x for boringssl ", "body": "Adding support for s390x for boringssl through patched_http_archive rule. ", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@Nayana-ibm did you try to push this upstream?", "We tried, but boringssl was not willing to maintain this.\r\nWe discussed this with @martinwicke and we decided it is OK to patch boringssl here as long as s390x support is maintained by ibm, which @Nayana-ibm \r\n\r\nDoes this capture the whole story, Nayana?", "Thank you @gunan for the context!", "@gunan Yes..correct. Boringssl was not willing to maintain this s390x support.\r\n@drpngx  Hence this PR.", "Please note that while it's correct that BoringSSL declined to carry this patch, that's because we don't support big-endian systems and _will produce the wrong results on big-endian systems_. The unittests will catch this all over the place and that's why it's not possible to compile BoringSSL on big-endian systems.\r\n\r\nIn keeping with most Google software, we have no plans to support big-endian systems and recommend that this patch be reverted. It'll just mislead people.", "So basically, anything that uses boringssl will likely be broken on s390x. \r\n\r\nIn fact, the only part of TensorFlow that uses boringssl is the core/platform/cloud:oauth_client target. \r\n\r\n@Nayana-ibm since that target is not going to work anyway, could you look into removing this patch, and simply disabling the oauth support on big endian instead?", "@martinwicke I will prepare one more PR to remove the patch added for s390x support in boringssl.\r\nHowever I'm not sure how to disable the oauth support. Could you please let me know. ", "Could you try disabling GCP support whenever we are on a big endian system?\r\nI think that should do the trick. You can then disable the tests under `tensorflow/core/platform/cloud` with a tag like `no_big_endian`, then we need to edit the s390x testing bazel command with `--test_tag_filters=-no_big_endian`\r\n", "Hi @gunan Sorry for late reply on this. \r\nI could see that the PR changes made for s390x are now reverted in Tensorflow master.\r\n\r\nAbout disabling GCP support on a big-endian systems,  I followed following steps:\r\n~/tensorflow# ./configure\r\n\r\n> You have bazel 0.6.1- (@non-git) installed.\r\n> Please specify the location of python. [Default is /usr/bin/python]:\r\n> Found possible Python library paths:\r\n>   /usr/local/lib/python2.7/dist-packages\r\n>   /usr/lib/python2.7/dist-packages\r\n> Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n> \r\n> Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\r\n> jemalloc as malloc support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\n> No Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\n~/tensorflow# bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nEven after disabling GCP support, build fails with an error:\r\n```\r\nERROR: /root/.cache/bazel/_bazel_root/30b0ed2738c25ecefa4b108f71649fc1/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1).\r\nIn file included from external/boringssl/src/include/openssl/bio.h:60:0,\r\n                 from external/boringssl/src/crypto/bio/printf.c:57:\r\nexternal/boringssl/src/include/openssl/base.h:114:2: error: #error \"Unknown target CPU\"\r\n #error \"Unknown target CPU\"\r\n  ^\r\n\r\n```\r\nNeed more changes here?\r\n\r\nOn test cases part, I have added `tags = [\"no_big_endian\"] ` in `tensorflow/core/platform/cloud/BUILD `file. \r\nYet to verify this changes. \r\n\r\n\r\n"]}, {"number": 11169, "title": "How to run the program coding by python in the Android phone?", "body": "I already wrote a pretrain vgg16 on my computer(python, Linux), now I want to run this program using my android phone`s CPU/GPU, the outcome could show in terminal. However, I cannot find any hint in this situation, so I want some hint and hope you can update the Readme.", "comments": ["_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nYou'll want to use the android libraries to then use the JAVA API.\r\nAndroid Libraries: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android\r\nJava API Info: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md\r\n\r\nYou can also see the demo Android Application here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android", "@jubjamie sorry about that and thank you!", "I've spotted your issue on Stack Overflow. Hopefully you'll get more help there and can go from the above links. Good luck in your project!"]}, {"number": 11168, "title": "LSTMBlockCell variable names changed - old checkpoints cannot be restored", "body": "In TF 1.1 and earlier, bias and weights had the variable names `\"biases\"` and `\"weights\"` in the `LSTMBlockCell`.\r\n\r\nSince TF 1.2, they have the variable names `\"bias\"` and `\"kernel\"`.\r\n\r\nWhy was that changed? It makes all checkpoint files incompatible, but for no real reason.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@ali01  No, you misunderstood. This is a bug in TensorFlow. I did not asked any question. The \"why\" is a rhetorical question. Of course it should not have been changed. There is no reason to just change the variable names to make checkpoint files incompatible.\r\n", "Note: I checked the commit logs, and there have been several breaking changes. First for TF 1.0 it was changed to what I was expecting in commit 92da8abfd35b93488ed7a55308b8f589ee23b622. Then the breaking change I was talking about here was introduced in 157370e5916b85c65958ed8383ae31d727228ed7. My argument in this GitHub issue was that this should not have been done. There is really no point in posting this to StackOverflow."]}, {"number": 11167, "title": "Improve docstrings involving package structure", "body": "This PR improves docstrings involving `tf.learn`. In the case of `tensorflow_dataframe.py`, I think it is better to put just `DataFrame` in order to keep consistency within one file. Except for the case, all the `tf.learn`s are replaced by `tf.contrib.learn`s.", "comments": ["Can one of the admins verify this patch?", "Thank you for putting this together. I think that the original intent was to have \"tf.learn\" as a project name, not reflecting the actual package name. In that case we would want to leave it as is.\r\n\r\n@martinwicke WDYT?", "The tf.learn name is confusing and we want to basically remove it completely. Using the package name is fine, but there's usually no need to. Ideally, we'd just get rid of the qualifier and talk about e.g., Estimator directly, or if clarification is required, tf.estimators.Estimator.", "I agree with the feedback, thank you @drpngx and @martinwicke! This PR has been revised as follows:\r\n- `tf.learn` -> `Estimator` under `learn.estimators` and `layers.feature_column`.\r\n- `tf.learn.DataFrame` -> `DataFrame` under `learn.dataframe`.\r\n- `tf.learn/inflow` -> `inflow` under installation shell scripts.\r\nI would like you to review again this version.", "ping for @drpngx (or @martinwicke )", "Sorry I'm out this week. Martin, feel free to reply if you get to it sooner\n\nOn Jul 24, 2017 10:09 PM, \"Vijay Vasudevan\" <notifications@github.com>\nwrote:\n\n> ping for @drpngx <https://github.com/drpngx> (or @martinwicke\n> <https://github.com/martinwicke> )\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11167#issuecomment-317539209>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbXrVX_Dar8zu9_rldGCK6OA1KP9Eks5sRPoKgaJpZM4OKQ8C>\n> .\n>\n", "Jenkins, test this please."]}, {"number": 11166, "title": "Fix typos", "body": "This PR fixes some typos: `the the`, `Dont`, `Initalized`, `Dimenson`, and `resuts`.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 11165, "title": "[feature-request] Multi-arity elems in fold{l,r}", "body": "The functions ```fold{l,r}``` that are part of ```tensorflow.python.ops.functional_ops``` currently only allow single-arity arguments for ```elems```. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use ```tf.map_fn``` for accomplishing this task).\r\n\r\nThis scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (```tensorflow-models:object_detection/core/post_processing.py```) gets around this by fixing the batch size and using ```tf.split``` during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making ```tf.dynamic_partition``` ..erm, more dynamic (without introducing a List into Tensorflow's semantics).\r\n\r\nI currently resort to something like the following,\r\n``` python\r\nzeroq = tf.constant(0) - tf.constant(0)\r\nnkeeps_0 = tf.zeros([zeroq], dtype=tf.int32); keeps_0 = tf.zeros([zeroq], dtype=tf.int32)  \r\ndef _compute(ii, nkeeps_r, keeps_r):\r\n  keep_ii = <function that spits a varying tensor of shape [M_ii]>\r\n  return (ii + 1, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[0]])], axis=0), tf.concat([keeps_r, keep_ii], axis=0))\r\n_, *ret = control_flow_ops.while_loop(lambda ii, *_: ii < bsize, _compute, [tf.constant(0), nkeeps_0, keeps_0], back_prop=False)\r\n```\r\nI'm not sure how this will play with ```back_prop=True```, or as to how this would fit in with the larger goals for the project.", "comments": ["FYI @mrry"]}, {"number": 11164, "title": "Expose reader.read_up_to in slim parallel reader", "body": "When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to \r\n\r\n```python\r\ndef ReadTFRecord(filename_queue):\r\n  num_tfrecords_at_once = 1024 \r\n  reader = tf.TFRecordReader()\r\n  _, queue_batch = reader.read_up_to(filename_queue, num_tfrecords_at_once)\r\n  return [queue_batch]\r\n```\r\nthe returned value is then fed to `tf.train.shuffle_batch` with enqueue_many set to true. \r\n\r\nAs far as I understand, this behavior is currently not exposed in slim.ParallelReader, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132. Are there any plans for adding it?", "comments": ["I am looking into this.", "@frreiss I'm sorry, I've done it by now, just make some preparations for commit. How far did you go?", "I've sent the pull request to show my path. If you have it already done I will skip my PR.", "No problem @AKindyakov, plenty of other stuff to work on :)", "Thank's a lot, @frreiss !", "Closing as this is resolved"]}, {"number": 11163, "title": "Expected one attr with name u'T' in name: \"swap_out_d_0\"", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.2\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: CUDA8.0\r\n- **GPU model and memory**:  Tesla P100, 16GB\r\n\r\n### Describe the problem\r\nI used OptimizeGraph API in Grappler for inserting \"swap_to_host\" nodes in my graph. When I import the new graph_def generated from this API, I got error mesage: \"Expected one attr with name u'T' in swap_out_d_0.\" I think the new graph_def misses some attribute information.\r\nI am following this bug and handing on fixing it.\r\n\r\n### Source code / logs\r\nsource code:\r\n\r\n```python\r\nd.op.node_def.attr['_swap_to_host'].i = 0\r\nmg = meta_graph.create_meta_graph_def(graph=ops.get_default_graph())\r\ngraph = tf_optimizer.OptimizeGraph(rewriter_config, mg)\r\ntf.import_graph_def(graph)\r\n```\r\nlog:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"memory_optimizer_test.py\", line 62, in testSimpleSwap\r\n    tf.import_graph_def(graph)\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 307, in import_graph_def\r\n    output_types = _OutputTypes(node, op_dict)\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 83, in _OutputTypes\r\n    return _ArgsToTypes(node_def, op_def.output_arg)\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 72, in _ArgsToTypes\r\n    types.extend(_SingleArgToTypes(node_def, arg_def))\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 63, in _SingleArgToTypes\r\n    types = _ArgToTypesNoRef(node_def, arg_def)\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 54, in _ArgToTypesNoRef\r\n    return [_GetNodeAttr(node_def, arg_def.type_attr).type]\r\n  File \"/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 40, in _GetNodeAttr\r\n    % (attr_name, str(node_def)))\r\nValueError: Expected one attr with name u'T' in name: \"swap_out_d_0\"\r\nop: \"Identity\"\r\ninput: \"b\"\r\ndevice: \"/CPU\"\r\n.\r\n```\r\n\r\n\r\n", "comments": ["I have encountered the same problem. Any solution? ", "@benoitsteiner can you look at the bug fix #11283?", "@benoitsteiner can you please take a look at this fix? We have made this fix and waited for code review for about one week.\r\n\r\nThanks.", "Sorry for the delay, I have been away on vacation. The fix looks good, we should be able to merge it soon.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Closing this out since #11283 was merged long ago."]}, {"number": 11162, "title": "Rank mismatch error when using contrib.seq2seq.AttentionWrapper in a dynamic_rnn with sequence_length", "body": "### System information\r\nLinux Ubuntu 16.04\r\nTensorFlow installed from pip binary\r\nTensorFlow version 1.2.0 (v1.2.0-rc2-21-g12f033d)\r\nPython 3.6.1 Anaconda 4.4.0\r\nCUDA 8.0 / cuDNN 5.1\r\nTITAN X (Pascal) 11.9GB\r\n\r\n### Describe the problem\r\n\r\nError: `Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].` when using `tf.contrib.seq2seq.AttentionWrapper` in a `dynamic_rnn` with `seqence_length` provided.\r\n\r\nCode to reproduce:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import LSTMCell, MultiRNNCell\r\nimport numpy as np\r\n\r\nencoder_outputs = tf.constant(np.random.rand(10,20,512).astype(np.float32))\r\ndecoder_inputs = tf.constant(np.random.rand(10,20,512).astype(np.float32))\r\nlengths = tf.constant(np.random.randint(5,20,(10,),dtype=np.int32))\r\n\r\ncell = LSTMCell(512)\r\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(512, encoder_outputs)\r\nattn_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n          cell, attention_mechanism, attention_layer_size=256)\r\n\r\no, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, lengths, dtype=tf.float32)\r\n# this works: o, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, dtype=tf.float32)\r\n# this works: o, s = tf.nn.dynamic_rnn(cell, decoder_inputs, lengths, dtype=tf.float32)\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    sess.run(o)\r\n```\r\n\r\n### Traceback\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\r\n    input_tensors_as_shapes, status)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 14, in <module>\r\n    o, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, lengths, dtype=tf.float32)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 210, in _rnn_step\r\n    final_output_and_state = _copy_some_through(new_output, new_state)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 182, in _copy_some_through\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 182, in <listcomp>\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 171, in _copy_one_through\r\n    return array_ops.where(copy_cond, output, new_output)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\r\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\r\n    name=name)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. If this does turn out to be a bug, please re-open this issue. Thanks!"]}, {"number": 11161, "title": "Fix an error", "body": "Fix an error or the if statement will never be true.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Build timeout.\r\n\r\nJenkins, test this please.", "@fchollet, gentle ping.", "Thanks, @Kongsea and @fchollet "]}, {"number": 11160, "title": "High variance in training convergence between keras (with tf backend) and tf.contrib.keras", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.2\r\n- **Python version**: \r\n3.6\r\n\r\n\r\n### Describe the problem\r\nI started to move my keras (Keras 2.0.4) scripts to tf.contrib.keras  (tf version 1.2) but I am achieving worse performance though the porting was seamless. Not sure why there is such huge discrepancy. in training performance\r\n\r\n### Source code / logs\r\nOriginal (Keras 2.0.4 code)\r\n```\r\nimport tensorflow as tf\r\nimport keras\r\n\r\nresnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')\r\ninput_ = resnet.input\r\nfinal_layer = resnet.layers[-1]\r\noutput_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)\r\nmodel = keras.models.Model(input_, output_)\r\nnum_layers=len(model.layers)\r\nfor i,layer in enumerate(model.layers):\r\n    if i == num_layers -1 :\r\n        layer.trainable=True\r\n    else:\r\n        layer.trainable = False\r\n\r\nig=keras.preprocessing.image.ImageDataGenerator(\r\n    preprocessing_function=preprocess_function)\r\ntraining_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)\r\nvalidation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)\r\n\r\nmodel.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])\r\nmodel.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)\r\n```\r\n\r\n___This model achieved 96% accuracy in 1 epoch___ (which is expected)\r\n\r\nSame code (tf.contrib.keras)\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.keras as keras\r\n\r\nresnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')\r\ninput_ = resnet.input\r\nfinal_layer = resnet.layers[-1]\r\noutput_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)\r\nmodel = keras.models.Model(input_, output_)\r\nnum_layers=len(model.layers)\r\nfor i,layer in enumerate(model.layers):\r\n    if i == num_layers -1 :\r\n        layer.trainable=True\r\n    else:\r\n        layer.trainable = False\r\n\r\nig=keras.preprocessing.image.ImageDataGenerator(\r\n    preprocessing_function=preprocess_function)\r\ntraining_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)\r\nvalidation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)\r\n\r\nmodel.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])\r\nmodel.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)\r\n\r\n```\r\n\r\n___This model struggles to achieve 58% accuracy after 1 epoch and 61% after 2 epochs__\r\n\r\nIs there something different in terms of hyper-parameter settings that is required when switching between the 2 versions. \r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11159, "title": "Update head.py", "body": "Switching to tf.summary.scalar", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "```\r\n==================== Test output for //bazel_pip/tensorflow/contrib/learn:head_test:\r\n2017-07-01 17:37:31.975956: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-01 17:37:31.976063: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-01 17:37:31.976098: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-01 17:37:31.976113: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-01 17:37:31.976119: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nWARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\r\nWARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\r\n/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/bin/bazel_pip/tensorflow/contrib/learn/head_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/learn/python/learn/estimators/head_test.py:717: DeprecationWarning: Please use assertEqual instead.\r\n  k: v[0] for k, v in six.iteritems(model_fn_ops.output_alternatives)\r\nF..--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.4/logging/__init__.py\", line 978, in emit\r\n    msg = self.format(record)\r\n  File \"/usr/lib/python3.4/logging/__init__.py\", line 828, in format\r\n    return fmt.format(record)\r\n  File \"/usr/lib/python3.4/logging/__init__.py\", line 565, in format\r\n    record.message = record.getMessage()\r\n  File \"/usr/lib/python3.4/logging/__init__.py\", line 328, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\n```", "@drpngx  I compiled and ran successfully head_test.py with a minor fix in `JetBrains PyCharm 2017.1.4` with `Python 3.6` and showed status `All 83 tests passed`. I am wondering how can I verify with Jenkins from my end so that I don't waste resources here.Please share me possible ways to verify changes for all OS.", "Jenkins, test this please.", "@printdhruv thank you for being thoughtful! Jenkins tests different platforms, and it's good to check on your end as you do. For other platforms, if you want to go the extra mile, you can try docker.  The docker platforms are [checked in](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker). But it's fine for us to test the build as long as you tested your main platform.", "On line 1483, you are still using logging_ops.scalar_summary.", "Jenkins, test this please.", "`//tensorflow/contrib/learn:head_test` is failing. Sample logs:\r\n\r\n```FAIL: testMultiClassWithLabelKeysEvalAccuracy1 (__main__.MultiClassHeadTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/contrib/learn/head_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head_test.py\", line 1444, in testMultiClassWithLabelKeysEvalAccuracy1\r\n    _assert_summary_tags(self, [\"loss\"])\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/contrib/learn/head_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head_test.py\", line 90, in _assert_summary_tags\r\n    test_case.assertItemsEqual(expected_tags or [], actual_tags)\r\nAssertionError: Element counts were not equal:\r\nFirst has 1, Second has 0:  'loss'\r\nFirst has 0, Second has 1:  u'multi_class_head/loss'```", "@frankchn @alanyee @drpngx \r\nI replaced `logging_ops.scalar(\r\n          _summary_key(head_name, mkey.LOSS), weighted_average_loss)\t\t          _summary_key(head_name, mkey.LOSS), weighted_average_loss)`\r\n \r\nwith the following statement.\r\n\r\n `tensorflow.summary.scalar(\r\n        name=_summary_key(head_name, mkey.LOSS), tensor=weighted_average_loss,collections=None)`\r\n\r\nWhat I think the` AssertionError: Element counts were not equal:` is generated is due to the eval and loss is in the different graph according to author's comment on line `623-624`.\r\n```\r\n\r\n# Uses the deprecated API to set the tag explicitly.\r\n# Without it, training and eval losses will show up in different graphs.\r\n\r\n```\r\nIf I am wrong then please give your suggestions. ", "@printdhruv, can you make @alanyee's change first and rebase to master? `logging_ops` is still used on line 1483.", "Jenkins, test this please.", "@printdhruv I haven't fixed the deprecated tf.summary yet."]}, {"number": 11158, "title": "Added assertion error in reset_default_graph()", "body": "See #11121 ", "comments": ["Can one of the admins verify this patch?", "That might trigger an API change.\r\n\r\nJenkins, test this please.", "Tests should pass now unless I did something very wrong on my end.", "Jenkins, test this please.", "@Thenerdstation @drpngx  FYI, it seems that the PR is causing a test failure. The failure seems to be specific to Mac , for reasons I don't fully understand. See example log from Jenkins nightly Mac build:\r\nhttp://ci.tensorflow.org/view/Tensorflow%20Jenkins%20Monitored%20builds/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=NO_PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/537/consoleFull\r\n\r\nIf you have thoughts, please let me know.", "That is very odd. It passed when I merged.\r\n\r\nThe `exporter_test` looks like a genuine error, except that it's Mac only, and the `session_test` points to some other part of the code where `self.stack` is used. The `generate_lib_test` is probably some other error :(\r\n\r\nChecking the submit logs, it looks like `exporter_test` did not exist on Mac at the time, but `session_test` passed. `session_test` has been there for a while and it's not clear what changed.\r\n\r\nGiven the risk that the extra strict check would blow up when merging into google code, we might want to revert this CL and push it from the inside with more internal test coverage.", "Yeah, I don't own a mac so I wasn't able to test for that, sorry."]}, {"number": 11157, "title": "TypeError: can't pickle _thread.lock objects", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, using stock examples\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.6.1 (Anaconda 4.4.0 64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: I'm running the seq2seq example in models/tutorials/rnn/translate, verbatim.\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nCollecting system information...\r\n2017-06-29 18:35:16.672194: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:35:16.672242: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:35:16.672250: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda:/usr/local/cuda/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nThu Jun 29 18:35:19 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K40m          Off  | 0000:27:00.0     Off |                    0 |\r\n| N/A   27C    P8    21W / 235W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI get exception: TypeError: can't pickle _thread.lock objects. It happens on different machines with the same python version. Just running your example code verbatim. \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nTraceback (most recent call last):\r\n  File \"translate.py\", line 322, in <module>\r\n    tf.app.run()\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"translate.py\", line 319, in main\r\n    train()\r\n  File \"translate.py\", line 178, in train\r\n    model = create_model(sess, False)\r\n  File \"translate.py\", line 136, in create_model\r\n    dtype=dtype)\r\n  File \"/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py\", line 179, in __init__\r\n    softmax_loss_function=softmax_loss_function)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1206, in model_with_buckets\r\n    decoder_inputs[:bucket[1]])\r\n  File \"/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py\", line 178, in <lambda>\r\n    lambda x, y: seq2seq_f(x, y, False),\r\n  File \"/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py\", line 142, in seq2seq_f\r\n    dtype=dtype)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 848, in embedding_attention_seq2seq\r\n    encoder_cell = copy.deepcopy(cell)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 476, in __deepcopy__\r\n    setattr(result, k, copy.deepcopy(v, memo))\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 215, in _deepcopy_list\r\n    append(deepcopy(a, memo))\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/t-mabruc/anaconda3/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.lock objects", "comments": ["Hi,\r\n        As website sates \"NOTE: The conda package is community supported, not officially supported. That is, the TensorFlow team neither tests nor maintains this conda package. Use that package at your own risk.\"\r\n        I think that you should try it with native `Python environment.` I tested and seems running successfully.", "I also tried it with native Python, and the error persists. The error disappears only when downgrading to tensorflow version 1.0.0", "Can you list the exact steps,source code which you are executing?", "I'm running the code found here https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate\r\n\r\nI run it with:\r\n`python translate.py --data_dir <path-to-data-dir> --train_dir <path-to-train-dir> --from_train_data  <path-to-from-train-data> --to_train_data <path-to-to-train-data>`\r\n\r\nI'm running this code as-is. Python is native (no Anacoda, no virtualenv, etc.)\r\n\r\nAlso, the same error happens on both Linux and Windows. And it is fixed on both systems only by using tensorflow 1.0.0.", "@nealwu ", "That's very odd that the error disappears with TensorFlow 1.0. @lukaszkaiser do you know what might be happening here?", "There were a lot of changes to RNNCell since 1.0, must ask @ebrevdo  to take a look.", "Do you get this error in earlier versions of python (i.e., python 3.4)?  I'm trying to replicate locally with python2.7.", "Scratch that; i'll test it with python3.4.", "I totally reproduced this error on py3.6.0 and py2.7.10 on Mac, but the error are different:\r\n\r\nfor python3.6.0:\r\nseq2seq.py\", line 910, in embedding_attention_seq2seq\r\n    encoder_cell = copy.deepcopy(cell)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 476, in __deepcopy__\r\n    setattr(result, k, copy.deepcopy(v, memo))\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 215, in _deepcopy_list\r\n    append(deepcopy(a, memo))\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.lock objects\r\n\r\n\r\n\r\n\r\n\r\n\r\nfor python2.7.10:\r\n    encoder_cell = copy.deepcopy(cell)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 174, in deepcopy\r\n    y = copier(memo)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/layers/base.py\", line 476, in __deepcopy__\r\n    setattr(result, k, copy.deepcopy(v, memo))\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 230, in _deepcopy_list\r\n    y.append(deepcopy(a, memo))\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 230, in _deepcopy_list\r\n    y.append(deepcopy(a, memo))\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 230, in _deepcopy_list\r\n    y.append(deepcopy(a, memo))\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 237, in _deepcopy_tuple\r\n    y.append(deepcopy(a, memo))\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 334, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 163, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy.py\", line 329, in _reconstruct\r\n    y = callable(*args)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/copy_reg.py\", line 93, in __newobj__\r\n    return cls.__new__(cls, *args)\r\nTypeError: object.__new__(NotImplementedType) is not safe, use NotImplementedType.__new__()", "@mattfeel Can you tell the log when you execute `python translate.py`? It will download WMT data from internet thus make sure that you have at least 20GB of disk space.\r\n", "I get this same error with __Keras+TensorFlow__ on `fit_generator`.\r\nAnd the same code with __Keras+Theano works fine__.\r\n\r\nFollow the command gets the error:\r\n```\r\nmodel.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n                    validation_data=test_input_sequence, validation_steps=steps_test,\r\n                    max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n                    workers=self.train_inputs.workers, use_multiprocessing=True,\r\n                    callbacks = callbacks)\r\n```\r\nThe error:\r\n```\r\nEpoch 1/1\r\nTraceback (most recent call last):\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\r\n    inputs = self.queue.get(block=True).get()\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\r\n    raise self._value\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\r\n    put(task)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\r\n    cls(buf, protocol).dump(obj)\r\nTypeError: can't pickle _thread.lock objects\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./myfolder/mycode.py\", line 473, in <module>\r\n    main()\r\n  File \"./myfolder/mycode.py\", line 459, in main\r\n    autonem.train_autonem(args.embedding_file, args.tune_embedding)\r\n  File \"./myfolder/mycode.py\", line 182, in train_autonem\r\n    callbacks = callbacks)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\r\n    generator_output = next(output_generator)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\r\n    raise StopIteration(e)\r\nStopIteration: can't pickle _thread.lock objects\r\n```\r\n\r\n__System information:__\r\n\r\n__Have I written custom code:__ Yes\r\n__OS Platform and Distribution:__ Linux GnomeUbuntu 16.04, but with new kernel\r\n__TensorFlow installed from:_ pip\r\n__TensorFlow version:__ 1.2.1\r\n__Python version:__ 3.6.1 (Miniconda3 4.3.11-64bit)\r\n__Bazel version (if compiling from source):__ I don't know.\r\n__CUDA/cuDNN version:__ I don't use because my graphic card is AMD-Radeon\r\n__GPU model and memory:__ AMD Radeon R7 M260/M265\r\n__CPU model:__ Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\r\n__RAM Memory:__ 16GiB (2x8Gib dual-channel)\r\n__Exact command to reproduce:__\r\n```\r\nhistory = CumulativeHistory()\r\ncallbacks = [history]\r\nfrom keras import backend as K\r\nif K.backend() == 'tensorflow':\r\n  board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\r\n                                    histogram_freq=1, write_graph=True, write_images=True)\r\n  callbacks.append(board)\r\nmetric_to_compare = 'val_euclidean_distance'\r\nprint(\"Begin of training model...\")\r\nfor i in range(MAX_NUM_EPOCHS):\r\n  model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n                      validation_data=test_input_sequence, validation_steps=steps_test,\r\n                      max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n                      workers=self.train_inputs.workers, use_multiprocessing=True,\r\n                      callbacks = callbacks)\r\n  try:\r\n    metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\r\n  except:\r\n    metrics_diff = -1\r\n  if metrics_diff < 0:\r\n    self._save_models(i)\r\n    self.data_processor = None  # Empty memory\r\n    best_epoch = i\r\n    num_worse_epochs = 0\r\n  elif metrics_diff > 0:\r\n    num_worse_epochs += 1\r\n    if num_worse_epochs >= PATIENCE:\r\n      print(\"Ran out of patience. Stopping training.\")\r\n      break\r\nprint(\"End of training model.\")\r\n```\r\n\r\n__Collected information__:\r\n```\r\n(myenv) myuser@mymachine:~$ ./tf_env_collect.sh \r\nCollecting system information...\r\n2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\n(myenv) myuser@mymachine:~$ cat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"14.04.5 LTS, Trusty Tahr\"\r\nVERSION_ID=\"14.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\r\n\r\n== cuda libs  ===================================================\r\n```", "Try using the tf 1.3 rc\n\nOn Jul 28, 2017 2:35 PM, \"Fabr\u00edcio Raphael Silva Pereira\" <\nnotifications@github.com> wrote:\n\n> I get this same error with Keras+TensorFlow on fit_generator.\n> And the same code with Keras+Theano works fine.\n>\n> Follow the command gets the error:\n>\n> model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n>                     validation_data=test_input_sequence, validation_steps=steps_test,\n>                     max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n>                     workers=self.train_inputs.workers, use_multiprocessing=True,\n>                     callbacks = callbacks)\n>\n> The error:\n>\n> Epoch 1/1\n> Traceback (most recent call last):\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n>     inputs = self.queue.get(block=True).get()\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n>     raise self._value\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n>     put(task)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n>     self._send_bytes(_ForkingPickler.dumps(obj))\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n>     cls(buf, protocol).dump(obj)\n> TypeError: can't pickle _thread.lock objects\n>\n> During handling of the above exception, another exception occurred:\n>\n> Traceback (most recent call last):\n>   File \"./myfolder/mycode.py\", line 473, in <module>\n>     main()\n>   File \"./myfolder/mycode.py\", line 459, in main\n>     autonem.train_autonem(args.embedding_file, args.tune_embedding)\n>   File \"./myfolder/mycode.py\", line 182, in train_autonem\n>     callbacks = callbacks)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n>     return func(*args, **kwargs)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n>     generator_output = next(output_generator)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n>     raise StopIteration(e)\n> StopIteration: can't pickle _thread.lock objects\n>\n> *System information:*\n>\n> *Have I written custom code:* Yes\n> *OS Platform and Distribution:* Linux GnomeUbuntu 16.04, but with new\n> kernel\n> _*TensorFlow installed from:* pip\n> *TensorFlow version:* 1.2.1\n> Python version: 3.6.1 (Miniconda3 4.3.11-64bit)\n> *Bazel version (if compiling from source):* I don't know.\n> *CUDA/cuDNN version:* I don't use because my graphic card is AMD-Radeon\n> *GPU model and memory:* AMD Radeon R7 M260/M265\n> *CPU model:* Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\n> *RAM Memory:* 16GiB (2x8Gib dual-channel)\n> Exact command to reproduce:\n>\n> history = CumulativeHistory()\n> callbacks = [history]\n> from keras import backend as K\n> if K.backend() == 'tensorflow':\n>   board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n>                                     histogram_freq=1, write_graph=True, write_images=True)\n>   callbacks.append(board)\n> metric_to_compare = 'val_euclidean_distance'\n> print(\"Begin of training model...\")\n> for i in range(MAX_NUM_EPOCHS):\n>   model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n>                       validation_data=test_input_sequence, validation_steps=steps_test,\n>                       max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n>                       workers=self.train_inputs.workers, use_multiprocessing=True,\n>                       callbacks = callbacks)\n>   try:\n>     metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n>   except:\n>     metrics_diff = -1\n>   if metrics_diff < 0:\n>     self._save_models(i)\n>     self.data_processor = None  # Empty memory\n>     best_epoch = i\n>     num_worse_epochs = 0\n>   elif metrics_diff > 0:\n>     num_worse_epochs += 1\n>     if num_worse_epochs >= PATIENCE:\n>       print(\"Ran out of patience. Stopping training.\")\n>       break\n> print(\"End of training model.\")\n>\n> *Collected information*:\n>\n> (myenv) myuser@mymachine:~$ ./tf_env_collect.sh\n> Collecting system information...\n> 2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n> Wrote environment to tf_env.txt. You can review the contents of that file.\n> and use it to populate the fields in the github issue template.\n>\n> cat tf_env.txt\n>\n> (myenv) myuser@mymachine:~$ cat tf_env.txt\n>\n> == cat /etc/issue ===============================================\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n> VERSION=\"14.04.5 LTS, Trusty Tahr\"\n> VERSION_ID=\"14.04\"\n>\n> == are we in docker =============================================\n> No\n>\n> == compiler =====================================================\n> c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n> Copyright (C) 2013 Free Software Foundation, Inc.\n> This is free software; see the source for copying conditions.  There is NO\n> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n>\n>\n> == uname -a =====================================================\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n>\n> == check pips ===================================================\n> numpy (1.13.1)\n> protobuf (3.3.0)\n> tensorflow (1.2.1)\n>\n> == check for virtualenv =========================================\n> False\n>\n> == tensorflow import ============================================\n> tf.VERSION = 1.2.1\n> tf.GIT_VERSION = v1.2.0-5-g435cdfc\n> tf.COMPILER_VERSION = v1.2.0-5-g435cdfc\n> Sanity check: array([1], dtype=int32)\n>\n> == env ==========================================================\n> LD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\n> DYLD_LIBRARY_PATH is unset\n>\n> == nvidia-smi ===================================================\n> ./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n>\n> == cuda libs  ===================================================\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-318790632>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim_x0X7z4fwR27nf-QB5eI0azF46Pks5sSn5qgaJpZM4OKDmJ>\n> .\n>\n", "@ebigelow \r\nit doesn't work!", "It is a real disaster!\r\n\r\nany workaround?", "@loveJasmine I was able to work around it by replacing the `.deepcopy` call with `.copy`. This probably breaks other things in subtle ways, but for my purpose it allowed me to get on with training.\r\n\r\nThe line I changed was\r\n```\r\npackages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 848, in embedding_attention_seq2seq\r\nencoder_cell = copy.deepcopy(cell)\r\n```\r\n\r\n@ebrevdo this was after trying the RC and compiling master myself to no avail.", "Interesting, I thought we had fixed this in master.  I'll dig some more\nafter vacation.\n\nOn Aug 1, 2017 10:46 AM, \"pwfff\" <notifications@github.com> wrote:\n\n> @loveJasmine <https://github.com/lovejasmine> I was able to work around\n> it by replacing the .deepcopy call with .copy. This probably breaks other\n> things in subtle ways, but for my purpose it allowed me to get on with\n> training.\n>\n> The line I changed was\n>\n> packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 848, in embedding_attention_seq2seq\n> encoder_cell = copy.deepcopy(cell)\n>\n> @ebrevdo <https://github.com/ebrevdo> this was after trying the RC and\n> compiling master myself to no avail.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-319491715>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim0XaIbwB8YeFQx62kznZgx2nejtOks5sT466gaJpZM4OKDmJ>\n> .\n>\n", "@pwfff \r\nin my project,change from deepcopy to copy will move on, but it doesn't make any sense on the logic", "@mattfeel ,\r\n\r\nI suffered exactly the same problem.\r\nI just passed the error by modifying 2 lines of the following seq2seq.py file from Tensorflow.\r\n\r\nfile: Anaconda3\\Lib\\site-packages\\tensorflow\\contrib\\legacy_seq2seq\\python\\ops\\seq2seq.py\r\n848     #encoder_cell = copy.deepcopy(cell)\r\n849     encoder_cell = core_rnn_cell.EmbeddingWrapper(\r\n850         cell, #encoder_cell,\r\n\r\nNow, my seq2seq model is being trained.\r\nGood luck!", "@Chesao \r\n\r\nwhat is core_rnn_cell", "@loveJasmine \r\n\r\nit is tf.nn.rnn_cell.GRUCell()", "Same issue here, when using a Keras + Tensorflow  and creating an sklearn wrapper. Still couldn't find a workaround.", "@dshahrokhian \r\n\r\nHave you tried my workaround? Why don't you dump up your full error log here?", "@dshahrokhian \r\nyour workaround works on my case, thanks", "@Chesao AFAIK I cannot use your method in my case. Here's my error log, but I already decided to put some extra code so I don't need to use the sklearn wrapper that was giving me the error.\r\n```\r\nTraceback (most recent call last):\r\n  File \"experiments/openface_ck+.py\", line 77, in <module>\r\n    main()\r\n  File \"experiments/openface_ck+.py\", line 74, in main\r\n    io_utils.kfold_report_metrics(get_temporal_model, optimal['max_params'], features, labels)\r\n  File \"/home/dani/Git/EmotionRecognition/experiments/io_utils.py\", line 140, in kfold_report_metrics\r\n    print(\"Test loss and Confidence Interval: %.2f (+/- %.2f)\" % (np.mean(losses), np.std(losses)))\r\n  File \"/home/dani/Git/EmotionRecognition/experiments/io_utils.py\", line 225, in plot_learning_curve\r\n    \r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 772, in learning_curve\r\n    for train, test in cv_iter\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 758, in __call__\r\n    while self.dispatch_one_batch(iterator):\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 603, in dispatch_one_batch\r\n    tasks = BatchedCalls(itertools.islice(iterator, batch_size))\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 127, in __init__\r\n    self.items = list(iterator_slice)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 773, in <genexpr>\r\n    for n_train_samples in train_sizes_abs)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 69, in clone\r\n    new_object_params[name] = clone(param, safe=False)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 60, in clone\r\n    return copy.deepcopy(estimator)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 215, in _deepcopy_list\r\n    append(deepcopy(a, memo))\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/dani/Software/anaconda3/lib/python3.6/copy.py\", line 169, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: can't pickle _thread.lock objects\r\n```\r\n\r\nThanks,\r\nDani", "Can someone provide a minimal reproducible code snippet?  Ideally ~ 10 lines with tf.constant() inputs?", "@ebrevdo \r\n\r\n```\r\nimport pickle\r\nfrom keras.layers import Dense\r\nfrom keras.layers import LSTM\r\nfrom keras.models import Sequential\r\nfrom keras.metrics import categorical_accuracy\r\n\r\nmodel = Sequential()\r\nmodel.add(LSTM(20, return_sequences=True, stateful=False, batch_input_shape=(10, 20, 4)))\r\nmodel.add(Dense(3, activation='softmax'))\r\n\r\nmodel.compile(loss=\"categorical_crossentropy\",\r\n              optimizer='adam',\r\n              metrics=[categorical_accuracy],\r\n              sample_weight_mode='temporal')\r\n\r\ndata_path = '/home/ubuntu/invoice/data/'     #any path to store pickle dump\r\noutput_file_path = data_path + 'model.dat'\r\nwith open(output_file_path, 'wb') as f:\r\n    pickle.dump(model, f)\r\n```\r\n\r\nError Msg:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 19, in <module>\r\nTypeError: can't pickle _thread.lock objects\r\n```", "same problem... keras1.2.0, tf0.12.1", "I found the solution. Instead of dumping a keras model object, save it using `keras.save`\r\n[See here](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)", "hi guys\r\ni want to train my model but it has errors like below...anybody knows whats that????   and i have to tell u   i have updated my keras to 2.0.9 and after that i got this error\r\n\r\n\r\n\r\nFile \"train.py\", line 57, in train\r\n    history=model.fit_generator(datagen_train, steps_per_epoch=train_samples_per_epoch, epochs = 10, verbose = 1, validation_data                          = datagen_valid, validation_steps =val_samples_per_epoch, initial_epoch = 0)\r\n  File \"/home/nscl/anaconda2/envs/fn/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/nscl/anaconda2/envs/fn/lib/python2.7/site-packages/keras/engine/training.py\", line 2047, in fit_generator\r\n    generator_output = next(output_generator)\r\n  File \"/home/nscl/anaconda2/envs/fn/lib/python2.7/site-packages/keras/utils/data_utils.py\", line 553, in get\r\n    raise StopIteration(e)\r\nStopIteration\r\n", "I have similar problems when trying to reproduce [esim](https://arxiv.org/abs/1609.06038). However, when I use simpler neural network architecture, such as [bilstm](https://arxiv.org/abs/1508.01991), everything works correctly.\r\n\r\nChanging saving to keras.save did not help.\r\n\r\n  \r\n    Traceback (most recent call last):\r\n      File \"src/scripts/train_model.py\", line 69, in <module>                                                                                         \r\n        plugins=[MetaSaver(), AutomaticNamer(namer=\"timestamp_namer\")])                                                                               \r\n      File \"/home/kchledowski/subspace-word-embeddings/src/vegab.py\", line 403, in main                                                               \r\n        call_training_func)()                                                                                                                         \r\n      File \"/home/kchledowski/subspace-word-embeddings/src/vegab.py\", line 265, in func_wrapper                                                       \r\n        func(*args, **kwargs)                                                                                                                         \r\n      File \"/home/kchledowski/subspace-word-embeddings/src/vegab.py\", line 388, in call_training_func                                                 \r\n        func(config, args.save_path, **training_func_kwargs)                                                                                          \r\n      File \"src/scripts/train_model.py\", line 56, in train_model                                                                                      \r\n        n_epochs=config[\"n_epochs\"], batch_size=config[\"batch_size\"])                                                                                 \r\n      File \"/home/kchledowski/subspace-word-embeddings/src/training_loop.py\", line 125, in baseline_training_loop                                     \r\n        callbacks=callbacks)                                                                                                                          \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper                      \r\n        return func(*args, **kwargs)                                                                                                                  \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/engine/training.py\", line 2082, in fit_generator                \r\n        callbacks.on_epoch_end(epoch, epoch_logs)                                                                                                     \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/callbacks.py\", line 77, in on_epoch_end                         \r\n        callback.on_epoch_end(epoch, logs)                                                                                                            \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/callbacks.py\", line 428, in on_epoch_end                        \r\n        self.model.save(filepath, overwrite=True)                                                                                                     \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/engine/topology.py\", line 2553, in save                         \r\n        save_model(self, filepath, overwrite, include_optimizer)                                                                                      \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/models.py\", line 107, in save_model                             \r\n        'config': model.get_config()                                                                                                                  \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/site-packages/keras/engine/topology.py\", line 2394, in get_config                   \r\n        return copy.deepcopy(config)                                                                                                                  \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)   \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 240, in _deepcopy_dict                                               \r\n        y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)                                                                                                                           \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 220, in _deepcopy_tuple                                              \r\n        y = [deepcopy(a, memo) for a in x]                                                                                                            \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 220, in <listcomp>                                                   \r\n        y = [deepcopy(a, memo) for a in x]                                                                                                            \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)                                                                                                                           \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 220, in _deepcopy_tuple                                              \r\n        y = [deepcopy(a, memo) for a in x]                                                                                                            \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 220, in <listcomp>                                                   \r\n        y = [deepcopy(a, memo) for a in x]                                                                                                            \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 180, in deepcopy                                                     \r\n        y = _reconstruct(x, memo, *rv)                                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 280, in _reconstruct                                                 \r\n        state = deepcopy(state, memo)                                                                                                                 \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)                                                                                                                           \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 240, in _deepcopy_dict                                               \r\n        y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 180, in deepcopy                                                     \r\n        y = _reconstruct(x, memo, *rv)                                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 280, in _reconstruct                                                 \r\n        state = deepcopy(state, memo)                                                                                                                 \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)                                                                                                                           \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 240, in _deepcopy_dict                                               \r\n        y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 180, in deepcopy                                                     \r\n        y = _reconstruct(x, memo, *rv)                                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 280, in _reconstruct                                                 \r\n        state = deepcopy(state, memo)                                                                                                                 \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 150, in deepcopy                                                     \r\n        y = copier(x, memo)                                                                                                                           \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 240, in _deepcopy_dict                                               \r\n        y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                                                \r\n      File \"/home/kchledowski/anaconda2/envs/tf3gpu/lib/python3.6/copy.py\", line 169, in deepcopy                                                     \r\n        rv = reductor(4)                                                                                                                              \r\n    TypeError: can't pickle _thread.lock objects \r\n\r\nAny ideas, what might be the cause? The first epoch works ok, then I get this error during callbacks.", "same problem, tf 1.4.1, py 3.6 in Anaconda3", "my problem was a lambda layer in my training loop. Please check if you have any and try to substitute it.", "Here's what you can do in **your code** to pass this (without modifying tensorflow's `seq2seq.py`):\r\n```python\r\nsetattr(tf.contrib.rnn.GRUCell, '__deepcopy__', lambda self, _: self)\r\nsetattr(tf.contrib.rnn.BasicLSTMCell, '__deepcopy__', lambda self, _: self)\r\nsetattr(tf.contrib.rnn.MultiRNNCell, '__deepcopy__', lambda self, _: self)\r\n```\r\n\r\nIf you're using core RNN API, you can change to `tf.nn.rnn_cell.GRUCell` (both variants work, actually).\r\n\r\nThis is a workaround. The proper fix is either make cells deep-copeable or get rid of the `copy.deepcopy` call. See also [this StackOverflow discussion](https://stackoverflow.com/q/44855603/712995).", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@ebrevdo any updates on reproducing or fixing this issue?", "I am facing similar error. Keras.save didn't help.\r\n  \r\nFile \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 218, in _deepcopy_list\r\n    y.append(deepcopy(a, memo))\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 223, in _deepcopy_tuple\r\n    y = [deepcopy(a, memo) for a in x]\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 223, in <listcomp>\r\n    y = [deepcopy(a, memo) for a in x]\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 243, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 182, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 297, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 243, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 182, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 297, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 243, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 182, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 297, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 155, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 243, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 182, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\ENV_tensorflow\\lib\\copy.py\", line 306, in _reconstruct\r\n    y.__dict__.update(state)\r\nAttributeError: 'NoneType' object has no attribute 'update'", "@AmnaKhan1 the cause of this stacktrace is the same, my previous https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-353725791 solves it too.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A couple of solutions have been proposed. E.g. using keras.save. Closing.", "Does anyone know of any other solutions? I am having the same problem, and none of the above solutions seem to work.", "@ebrevdo unfortunately, `keras.save` doesn't not seem to be a universal solution, because that's what has brought me here in the first place. I've checked all major tensorflow releases from 1.4 to 1.7 \u2013\u00a0the issue is persistent. ", "It seems to be an issue caused when using embedding_attention_seq2seq several times while training with buckets.", "One alternative might be only fit one bucket at a time", "@maxim5\r\nyour solution does not work for me.\r\n@Chesao 's solution works.\r\nBut I am not sure if there's any other influence.", "Seeing same issue with tf 1.5.0:\r\npk.dumps(obj)\r\nTypeError: can't pickle _thread.lock objects", "Saved final_models/thor_model.pkl\r\nTraceback (most recent call last):\r\n  File \"train_expert/train_thor.py\", line 46, in <module>\r\n    main()\r\n  File \"train_expert/train_thor.py\", line 42, in main\r\n    act.save(\"final_models/thor_model.pkl\")\r\n  File \"/home/sdc/github/baselines-rudder/baselines/deepq/simple.py\", line 62, in save\r\n    cloudpickle.dump((model_data, self._act_params), f)\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 879, in dump\r\n    CloudPickler(file, protocol=protocol).dump(obj)\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 268, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 408, in dump\r\n    self.save(obj)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 725, in save_tuple\r\n    save(element)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 413, in save_function\r\n    self.save_function_tuple(obj)\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 559, in save_function_tuple\r\n    save(state)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 770, in save_list\r\n    self._batch_appends(obj)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 797, in _batch_appends\r\n    save(tmp[0])\r\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\r\n    save(state)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\r\n    save(state)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\r\n    save(state)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\r\n    save(state)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\r\n    save(v)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 630, in save_builtin_function\r\n    return self.save_function(obj)\r\n  File \"/home/sdc/github/baselines-rudder/baseline/lib/python3.5/site-packages/cloudpickle/cloudpickle.py\", line 400, in save_function\r\n    return self.save_reduce(obj=obj, *rv)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 599, in save_reduce\r\n    save(args)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/usr/lib/python3.5/pickle.py\", line 725, in save_tuple\r\n    save(element)\r\n  File \"/usr/lib/python3.5/pickle.py\", line 495, in save\r\n    rv = reduce(self.proto)\r\nTypeError: can't pickle _thread.lock objects\r\n\r\ntf 1.8", "I'm getting a similar error with keras 2.0.9 and tensorflow 1.3.0. Note, however, that this happens only when I wrap a model using the **keras.utils.training_utils.multi_gpu_model** class, as below:\r\n\r\n```\r\nmodel = multi_gpu_model(model, gpus=8) # I was trying to utilize 8 GPUs\r\n..\r\n..\r\ncheckpointer = ModelCheckpoint(filepath='results/model.hd5', verbose=0)\r\n..\r\nhist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\r\n        epochs=epochs, validation_data=audio_gen.next_valid(), validation_steps=validation_steps,\r\n        callbacks=[checkpointer], verbose=verbose)  <<<<<<<<<<< # ON THIS LINE #\r\n\r\n```\r\n\r\nIn the absence of multi_gpu_model, this code above runs without a problem.\r\n\r\n===================== OUTPUT ======================\r\nEpoch 1/20\r\n 24/106 [================>.] - ETA: 35 - loss: 194.7247\r\n\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n     74     hist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\r\n     75         epochs=epochs, validation_data=audio_gen.next_valid(), validation_steps=validation_steps,\r\n---> 76         callbacks=[checkpointer], verbose=verbose)\r\n     77 \r\n     78     # save model loss\r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)\r\n     85                 warnings.warn('Update your `' + object_name +\r\n     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\r\n---> 87             return func(*args, **kwargs)\r\n     88         wrapper._original_function = func\r\n     89         return wrapper\r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   2115                         break\r\n   2116 \r\n-> 2117                 callbacks.on_epoch_end(epoch, epoch_logs)\r\n   2118                 epoch += 1\r\n   2119                 if callback_model.stop_training:\r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/callbacks.py in on_epoch_end(self, epoch, logs)\r\n     71         logs = logs or {}\r\n     72         for callback in self.callbacks:\r\n---> 73             callback.on_epoch_end(epoch, logs)\r\n     74 \r\n     75     def on_batch_begin(self, batch, logs=None):\r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/callbacks.py in on_epoch_end(self, epoch, logs)\r\n    423                     self.model.save_weights(filepath, overwrite=True)\r\n    424                 else:\r\n--> 425                     self.model.save(filepath, overwrite=True)\r\n    426 \r\n    427 \r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py in save(self, filepath, overwrite, include_optimizer)\r\n   2554         \"\"\"\r\n   2555         from ..models import save_model\r\n-> 2556         save_model(self, filepath, overwrite, include_optimizer)\r\n   2557 \r\n   2558     def save_weights(self, filepath, overwrite=True):\r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/models.py in save_model(model, filepath, overwrite, include_optimizer)\r\n    105         f.attrs['model_config'] = json.dumps({\r\n    106             'class_name': model.__class__.__name__,\r\n--> 107             'config': model.get_config()\r\n    108         }, default=get_json_type).encode('utf8')\r\n    109 \r\n\r\n/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py in get_config(self)\r\n   2395             model_outputs.append([layer.name, new_node_index, tensor_index])\r\n   2396         config['output_layers'] = model_outputs\r\n-> 2397         return copy.deepcopy(config)\r\n   2398 \r\n   2399     @classmethod\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_list(x, memo)\r\n    216     memo[id(x)] = y\r\n    217     for a in x:\r\n--> 218         y.append(deepcopy(a, memo))\r\n    219     return y\r\n    220 d[list] = _deepcopy_list\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_tuple(x, memo)\r\n    221 \r\n    222 def _deepcopy_tuple(x, memo):\r\n--> 223     y = [deepcopy(a, memo) for a in x]\r\n    224     # We're not going to put the tuple in the memo, but it's still important we\r\n    225     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n/usr/lib/python3.5/copy.py in <listcomp>(.0)\r\n    221 \r\n    222 def _deepcopy_tuple(x, memo):\r\n--> 223     y = [deepcopy(a, memo) for a in x]\r\n    224     # We're not going to put the tuple in the memo, but it's still important we\r\n    225     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_tuple(x, memo)\r\n    221 \r\n    222 def _deepcopy_tuple(x, memo):\r\n--> 223     y = [deepcopy(a, memo) for a in x]\r\n    224     # We're not going to put the tuple in the memo, but it's still important we\r\n    225     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n/usr/lib/python3.5/copy.py in <listcomp>(.0)\r\n    221 \r\n    222 def _deepcopy_tuple(x, memo):\r\n--> 223     y = [deepcopy(a, memo) for a in x]\r\n    224     # We're not going to put the tuple in the memo, but it's still important we\r\n    225     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_method(x, memo)\r\n    248 \r\n    249 def _deepcopy_method(x, memo): # Copy instance methods\r\n--> 250     return type(x)(x.__func__, deepcopy(x.__self__, memo))\r\n    251 _deepcopy_dispatch[types.MethodType] = _deepcopy_method\r\n    252 \r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    180                             raise Error(\r\n    181                                 \"un(deep)copyable object of type %s\" % cls)\r\n--> 182                 y = _reconstruct(x, rv, 1, memo)\r\n    183 \r\n    184     # If is its own copy, don't memoize.\r\n\r\n/usr/lib/python3.5/copy.py in _reconstruct(x, info, deep, memo)\r\n    295     if state is not None:\r\n    296         if deep:\r\n--> 297             state = deepcopy(state, memo)\r\n    298         if hasattr(y, '__setstate__'):\r\n    299             y.__setstate__(state)\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    153     copier = _deepcopy_dispatch.get(cls)\r\n    154     if copier:\r\n--> 155         y = copier(x, memo)\r\n    156     else:\r\n    157         try:\r\n\r\n/usr/lib/python3.5/copy.py in _deepcopy_dict(x, memo)\r\n    241     memo[id(x)] = y\r\n    242     for key, value in x.items():\r\n--> 243         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    244     return y\r\n    245 d[dict] = _deepcopy_dict\r\n\r\n/usr/lib/python3.5/copy.py in deepcopy(x, memo, _nil)\r\n    172                     reductor = getattr(x, \"__reduce_ex__\", None)\r\n    173                     if reductor:\r\n--> 174                         rv = reductor(4)\r\n    175                     else:\r\n    176                         reductor = getattr(x, \"__reduce__\", None)\r\n\r\nTypeError: can't pickle _thread.lock objects\r\n```", "Safdar, that's an unrelated error. Can you open a new issue for it?\n\nOn Wed, Jul 25, 2018, 7:14 AM Skye Wanderman-Milne <notifications@github.com>\nwrote:\n\n> Assigned #11157 <https://github.com/tensorflow/tensorflow/issues/11157>\n> to @ebrevdo <https://github.com/ebrevdo>.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157#event-1752713343>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1FGeIlfOtW0GcgBbzkc0r-qEPdYks5uKH1dgaJpZM4OKDmJ>\n> .\n>\n", "> 848\r\n\r\ndid not work for me.maybe I did not type it correct,can u please write it properly", "> I get this same error with **Keras+TensorFlow** on `fit_generator`.\r\n> And the same code with **Keras+Theano works fine**.\r\n> \r\n> Follow the command gets the error:\r\n> \r\n> ```\r\n> model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n>                     validation_data=test_input_sequence, validation_steps=steps_test,\r\n>                     max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n>                     workers=self.train_inputs.workers, use_multiprocessing=True,\r\n>                     callbacks = callbacks)\r\n> ```\r\n> The error:\r\n> \r\n> ```\r\n> Epoch 1/1\r\n> Traceback (most recent call last):\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\r\n>     inputs = self.queue.get(block=True).get()\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\r\n>     raise self._value\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\r\n>     put(task)\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\r\n>     self._send_bytes(_ForkingPickler.dumps(obj))\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\r\n>     cls(buf, protocol).dump(obj)\r\n> TypeError: can't pickle _thread.lock objects\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"./myfolder/mycode.py\", line 473, in <module>\r\n>     main()\r\n>   File \"./myfolder/mycode.py\", line 459, in main\r\n>     autonem.train_autonem(args.embedding_file, args.tune_embedding)\r\n>   File \"./myfolder/mycode.py\", line 182, in train_autonem\r\n>     callbacks = callbacks)\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\r\n>     return func(*args, **kwargs)\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\r\n>     generator_output = next(output_generator)\r\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\r\n>     raise StopIteration(e)\r\n> StopIteration: can't pickle _thread.lock objects\r\n> ```\r\n> **System information:**\r\n> \r\n> **Have I written custom code:** Yes\r\n> **OS Platform and Distribution:** Linux GnomeUbuntu 16.04, but with new kernel\r\n> __TensorFlow installed from:_ pip\r\n> **TensorFlow version:** 1.2.1\r\n> **Python version:** 3.6.1 (Miniconda3 4.3.11-64bit)\r\n> **Bazel version (if compiling from source):** I don't know.\r\n> **CUDA/cuDNN version:** I don't use because my graphic card is AMD-Radeon\r\n> **GPU model and memory:** AMD Radeon R7 M260/M265\r\n> **CPU model:** Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\r\n> **RAM Memory:** 16GiB (2x8Gib dual-channel)\r\n> **Exact command to reproduce:**\r\n> \r\n> ```\r\n> history = CumulativeHistory()\r\n> callbacks = [history]\r\n> from keras import backend as K\r\n> if K.backend() == 'tensorflow':\r\n>   board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\r\n>                                     histogram_freq=1, write_graph=True, write_images=True)\r\n>   callbacks.append(board)\r\n> metric_to_compare = 'val_euclidean_distance'\r\n> print(\"Begin of training model...\")\r\n> for i in range(MAX_NUM_EPOCHS):\r\n>   model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n>                       validation_data=test_input_sequence, validation_steps=steps_test,\r\n>                       max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n>                       workers=self.train_inputs.workers, use_multiprocessing=True,\r\n>                       callbacks = callbacks)\r\n>   try:\r\n>     metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\r\n>   except:\r\n>     metrics_diff = -1\r\n>   if metrics_diff < 0:\r\n>     self._save_models(i)\r\n>     self.data_processor = None  # Empty memory\r\n>     best_epoch = i\r\n>     num_worse_epochs = 0\r\n>   elif metrics_diff > 0:\r\n>     num_worse_epochs += 1\r\n>     if num_worse_epochs >= PATIENCE:\r\n>       print(\"Ran out of patience. Stopping training.\")\r\n>       break\r\n> print(\"End of training model.\")\r\n> ```\r\n> **Collected information**:\r\n> \r\n> ```\r\n> (myenv) myuser@mymachine:~$ ./tf_env_collect.sh \r\n> Collecting system information...\r\n> 2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n> Wrote environment to tf_env.txt. You can review the contents of that file.\r\n> and use it to populate the fields in the github issue template.\r\n> \r\n> cat tf_env.txt\r\n> \r\n> (myenv) myuser@mymachine:~$ cat tf_env.txt\r\n> \r\n> == cat /etc/issue ===============================================\r\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n> VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n> VERSION_ID=\"14.04\"\r\n> \r\n> == are we in docker =============================================\r\n> No\r\n> \r\n> == compiler =====================================================\r\n> c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n> Copyright (C) 2013 Free Software Foundation, Inc.\r\n> This is free software; see the source for copying conditions.  There is NO\r\n> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n> \r\n> \r\n> == uname -a =====================================================\r\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n> \r\n> == check pips ===================================================\r\n> numpy (1.13.1)\r\n> protobuf (3.3.0)\r\n> tensorflow (1.2.1)\r\n> \r\n> == check for virtualenv =========================================\r\n> False\r\n> \r\n> == tensorflow import ============================================\r\n> tf.VERSION = 1.2.1\r\n> tf.GIT_VERSION = v1.2.0-5-g435cdfc\r\n> tf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\n> Sanity check: array([1], dtype=int32)\r\n> \r\n> == env ==========================================================\r\n> LD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\r\n> DYLD_LIBRARY_PATH is unset\r\n> \r\n> == nvidia-smi ===================================================\r\n> ./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\r\n> \r\n> == cuda libs  ===================================================\r\n> ```\r\n\r\nwhen I use fit_generator() meet the same error with tf 1.8.0 and keras 2.2.4.", "> Hi,\r\n> As website sates \"NOTE: The conda package is community supported, not officially supported. That is, the TensorFlow team neither tests nor maintains this conda package. Use that package at your own risk.\"\r\n> I think that you should try it with native `Python environment.` I tested and seems running successfully.\r\n\r\nI think there is no connection with \"Python environment\", because I try it in Colaboratory, same error.", "> my problem was a lambda layer in my training loop. Please check if you have any and try to substitute it.\r\n\r\nBut I need this lambda layer!! Do you know another solution?", "@minda163 I've resorted to saving weigths alone and using a constructor function to build the model itself. It seems like there is no other way around this, because `pickle` can't handle closures. The devs might want to consider `dill` as a more robust alternative to `pickle`.", ">     172                     reductor = getattr(x, \"__reduce_ex__\", None)\r\n>     173                     if reductor:\r\n> --> 174                         rv = reductor(4)\r\n>     175                     else:\r\n>     176                         reductor = getattr(x, \"__reduce__\", None)\r\n> \r\n> TypeError: can't pickle _thread.lock objects\r\n> ```\r\n\r\nDid you fix it. I have the same error?", "Although that the issues discussed in this thread are somewhat diverse in their origin, [this answer on Stackoverflow](https://stackoverflow.com/questions/47066635/checkpointing-keras-model-typeerror-cant-pickle-thread-lock-objects/55229794#55229794) might help some in looking for a solution to their problem.", "> @ebrevdo\r\n> \r\n> ```\r\n> import pickle\r\n> from keras.layers import Dense\r\n> from keras.layers import LSTM\r\n> from keras.models import Sequential\r\n> from keras.metrics import categorical_accuracy\r\n> \r\n> model = Sequential()\r\n> model.add(LSTM(20, return_sequences=True, stateful=False, batch_input_shape=(10, 20, 4)))\r\n> model.add(Dense(3, activation='softmax'))\r\n> \r\n> model.compile(loss=\"categorical_crossentropy\",\r\n>               optimizer='adam',\r\n>               metrics=[categorical_accuracy],\r\n>               sample_weight_mode='temporal')\r\n> \r\n> data_path = '/home/ubuntu/invoice/data/'     #any path to store pickle dump\r\n> output_file_path = data_path + 'model.dat'\r\n> with open(output_file_path, 'wb') as f:\r\n>     pickle.dump(model, f)\r\n> ```\r\n> \r\n> Error Msg:\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"<input>\", line 19, in <module>\r\n> TypeError: can't pickle _thread.lock objects\r\n> ```\r\nDo you solve this issue ? If you solve please suggest me to modifications please", "One way is to use the model saving functionality in TensorFlow:\ntf.keras.models.save_model\n<https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model> or\ncalling model.save\n<https://www.tensorflow.org/guide/keras/save_and_serialize>.  Don't use\npickle.\n\nOn Mon, Oct 7, 2019 at 7:19 AM SumitNikam <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo>\n>\n> import pickle\n> from keras.layers import Dense\n> from keras.layers import LSTM\n> from keras.models import Sequential\n> from keras.metrics import categorical_accuracy\n>\n> model = Sequential()\n> model.add(LSTM(20, return_sequences=True, stateful=False, batch_input_shape=(10, 20, 4)))\n> model.add(Dense(3, activation='softmax'))\n>\n> model.compile(loss=\"categorical_crossentropy\",\n>               optimizer='adam',\n>               metrics=[categorical_accuracy],\n>               sample_weight_mode='temporal')\n>\n> data_path = '/home/ubuntu/invoice/data/'     #any path to store pickle dump\n> output_file_path = data_path + 'model.dat'\n> with open(output_file_path, 'wb') as f:\n>     pickle.dump(model, f)\n>\n> Error Msg:\n>\n> Traceback (most recent call last):\n>   File \"<input>\", line 19, in <module>\n> TypeError: can't pickle _thread.lock objects\n>\n> Do you solve this issue ? If you solve please suggest me to modifications\n> please\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157?email_source=notifications&email_token=AANWFGYP3ZQWRMDTSASYNE3QNNAPXA5CNFSM4DRIHGE2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAQQGCA#issuecomment-539034376>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AANWFG4B6FWNJ4EPBETPMKTQNNAPXANCNFSM4DRIHGEQ>\n> .\n>\n", "@ebrevdo Well, still huge amount of non-tf packages I want to use with my tf model depend on a pickle. I encountered the issue 3 times:\r\n1: Trying to save my model with pickle after saving and loading it with custom objects did not work\r\n2: Wrapping it in Keras Wrapper so it is usable in Scikit-Like APIs for Sampling, Interpretation and more\r\n3: Trying to train my model in parallel as I can only use around 30% of the 40 CPUs the server has.  (", "What happened to this issue? \r\nI am running into it as well with this code\r\n```\r\ndef nn_model3(in_shape,out_shape): \r\n    model=tf.keras.models.Sequential()\r\n    model.add(tf.keras.layers.Conv1D(filters=256,kernel_size=3,activation='relu',input_shape=[256,1,]))\r\n    model.add( tf.keras.layers.Conv1D(filters=64, kernel_size=6, activation='relu'))\r\n    model.add(tf.keras.layers.Dropout(0.2))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add(tf.keras.layers.Dense(256, activation = \"relu\"))\r\n    model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\r\n    model.add(CuDNNLSTM(100,  return_sequences=True))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add( tf.keras.layers.Dense(189, kernel_initializer='normal'))#, activation='sigmoid'))\r\n    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\r\n    return model\r\n    ```\r\n\r\nnn_model3.save('filename.h5') now throws the error\r\n\r\nThing is I need that  \r\n```    model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))```\r\n\r\nFor the LSTM to work. \r\n\r\nThe workarounds of declaring statics does not work for me since I need that model.output to be evaluated dynamically", "@GGDRriedel this error can happen for many reasons; so your instance may differ a bit from the previous instances in this thread.  I suggest opening a new issue on github and answering some of the questions in the template (version of TF, etc) and someone from the keras team can likely help you.", "It's still the inability to pickle dynamic model structures from\r\n\r\n> \r\n> \r\n> > my problem was a lambda layer in my training loop. Please check if you have any and try to substitute it.\r\n> \r\n> But I need this lambda layer!! Do you know another solution?\r\n\r\nso it's basically the same problem.\r\nAnyway I resorted to saving just the weights as  a workaround but obviously this won't work in deployment/production and so on", "It depends on what your Lambda layer does.  If it doesn't call to\ntensorflow, then it's possible your thread/lock object is completely\nunrelated to the one in the bug - aka you would want to push a new bug or\ndebug why you have locks in your code.  If your code is accessing variables\n- don't.  Lambda is not meant for code that accesses tf.Variables. If\nyou're in tf1 legacy mode,then the issues are very different and you should\nfile a separate bug (though I guess the suggestion will be to move to TF2\nand eager mode/tf.functions completely).  Without knowing more we can't\nhelp you.  For example; we can't see your stack trace.  And for that you'd\nfile a new bug anyway.\n\nOn Thu, Feb 25, 2021 at 4:39 AM GGDRriedel <notifications@github.com> wrote:\n\n> It's still the inability to pickle dynamic model structures from\n>\n> my problem was a lambda layer in my training loop. Please check if you\n> have any and try to substitute it.\n>\n> But I need this lambda layer!! Do you know another solution?\n>\n> so it's basically the same problem.\n> Anyway I resorted to saving just the weights as a workaround but obviously\n> this won't work in deployment/production and so on\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-785866104>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFG6ZCGV45CBDTT65TBLTAZAJTANCNFSM4DRIHGEQ>\n> .\n>\n"]}, {"number": 11156, "title": "Updating release.md.", "body": "", "comments": []}, {"number": 11155, "title": "head.py still uses scalar_summary", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.5\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nhead.py still uses `logging_ops.scalar_summary` despite the method being a depreciated, leading to warnings. The problem seems to start from `estimator.fit` and `estimator.evaluate`\r\n\r\n### Source code\r\n```\r\nimport tensorflow as tf\r\n# NumPy is often used to load, manipulate and preprocess data.\r\nimport numpy as np\r\n\r\n# Declare list of features. We only have one real-valued feature. There are many\r\n# other types of columns that are more complicated and useful.\r\nfeatures = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\r\n\r\n# An estimator is the front end to invoke training (fitting) and evaluation\r\n# (inference). There are many predefined types like linear regression,\r\n# logistic regression, linear classification, logistic classification, and\r\n# many neural network classifiers and regressors. The following code\r\n# provides an estimator that does linear regression.\r\nestimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\r\n\r\n# TensorFlow provides many helper methods to read and set up data sets.\r\n# Here we use two data sets: one for training and one for evaluation\r\n# We have to tell the function how many batches\r\n# of data (num_epochs) we want and how big each batch should be.\r\nx_train = np.array([1., 2., 3., 4.])\r\ny_train = np.array([0., -1., -2., -3.])\r\nx_eval = np.array([2., 5., 8., 1.])\r\ny_eval = np.array([-1.01, -4.1, -7, 0.])\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_train}, y_train,\r\n                                              batch_size=4,\r\n                                              num_epochs=1000)\r\neval_input_fn = tf.contrib.learn.io.numpy_input_fn(\r\n    {\"x\":x_eval}, y_eval, batch_size=4, num_epochs=1000)\r\n\r\n# We can invoke 1000 training steps by invoking the  method and passing the\r\n# training data set.\r\nestimator.fit(input_fn=input_fn, steps=1000)\r\n# Here we evaluate how well our model did.\r\ntrain_loss = estimator.evaluate(input_fn=input_fn)\r\n\r\neval_loss = estimator.evaluate(input_fn=eval_input_fn)\r\n\r\nprint \"train loss: %r\"% train_loss\r\nprint \"eval loss: %r\"% eval_loss\r\n```\r\n\r\n### Logs\r\n```\r\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/1l/v82bx7_s5zvf7z8wlgjz4j_06gd09g/T/tmpQRR2VF\r\nWARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\n2017-06-29 16:53:02.952908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 16:53:02.952925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 16:53:02.952930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 16:53:02.952934: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nWARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\ntrain metrics: {'loss': 9.803332e-07, 'global_step': 1000}\r\neval metrics: {'loss': 0.0026192721, 'global_step': 1000}\r\n```\r\n", "comments": ["Hi,\r\n         You are right! I have created a pull request in order to use `tf.summary.scalar`  which you can modify locally if you want to get rid of the error. Have a look to proposed file changes in `File changed tab` [https://github.com/tensorflow/tensorflow/pull/11159](https://github.com/tensorflow/tensorflow/pull/11159)"]}, {"number": 11154, "title": "Fixes to the getting started documentation", "body": "Removed some unneeded code, streamlined the code, fixed a broken example, corrected output for example code, minor grammar fix", "comments": ["Can one of the admins verify this patch?", "I noticed this file referred to `tf.estimator` instead of `tf.contrib.learn`, but the current version of TensorFlow (1.2.0) seems not to `tf.estimator.LinearRegressor` yet. I am unsure how to approach this discrepancy from https://www.tensorflow.org/get_started/get_started.", "@alanyee about the `DNNRegressor`, the current documentation is the way we want it. This is a bit out of sync right now until 1.2.0 is released.\r\n\r\n@MarkDaoust Could you take a look at this PR? It looks like some numbers changed.", "Jenkins, test this please.", "@drpngx `DNNRegressor`? I think I was talking about `LinearRegressor`.\r\n\r\nAlso I updated another part of the webpage again. Could you run the Jenkins again?", "Jenkins, test this please.\r\n\r\nThe core version is what we want people to use moving forward, except that it's not here yet.", "@gunan before I investigate, just making sure that nothing changed on the Mac side that would cause these failures right?", "Looks like another one of the xcode issues we keep seeing on mac1\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-mac/5552/console\r\n@caisq, could you take a look?\r\n\r\nThe build failure is definitely unrelated, PR ok to merge.", "Hmmm. Let me try removing the old version of xcode tomorrow.", "Jenkins, test this please.", "Thank you @gunan and @caisq ! It passed.\r\n\r\n@MarkDaoust what do you think of the changes?", "Jenkins, test this please."]}, {"number": 11153, "title": "Fix sparse_placeholder error when int is passed in shape argument", "body": "This fix tries to address the issue raised in #6749 where and error\r\n```\r\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: 'Tensor(\"Const:0\", shape=(2,), dtype=int32)'\r\n```\r\nis thrown out in case int is passed in the shape argument.\r\n\r\nThis fix fixes the issue and adds test cases for it.\r\n\r\nThis fix fixes #6749.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Hi @mrry can you take a look at this and see whether it is reasonable? Thanks!"]}, {"number": 11152, "title": "Threading example at programmers_guide/threading_and_queues broken", "body": "Dear TF folks,\r\n\r\nI am trying to reproduce the example listed at [1], \r\n\r\n```\r\n# Thread body: loop until the coordinator indicates a stop was requested.\r\n# If some condition becomes true, ask the coordinator to stop.\r\ndef MyLoop(coord):\r\n  while not coord.should_stop():\r\n    ...do something...\r\n    if ...some condition...:\r\n      coord.request_stop()\r\n\r\n# Main thread: create a coordinator.\r\ncoord = tf.train.Coordinator()\r\n\r\n# Create 10 threads that run 'MyLoop()'\r\nthreads = [threading.Thread(target=MyLoop, args=(coord,)) for i in xrange(10)]\r\n\r\n# Start the threads and wait for all of them to stop.\r\nfor t in threads:\r\n  t.start()\r\ncoord.join(threads)\r\n```\r\nWhen running this example, I cannot find the `threading.Thread` class (e.g. by searching for \"Thread\" in the API docs or `tf.threading.Thread`).\r\n\r\nAm I missing something where? Is the example maybe broken?\r\n\r\nThanks!\r\n\r\n\\jv\r\n\r\n## Setup\r\n\r\n```bash\r\n$ python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n```\r\n\r\n[1]: https://www.tensorflow.org/programmers_guide/threading_and_queues\r\n", "comments": ["This is actually Python's threading library:\r\n\r\n    import threading"]}, {"number": 11151, "title": "Train a classifier error tensorflow.python.framework.errors_impl.NotFoundError:", "body": "I train my classifier, but when I'm going to rate an image this error appears:\r\n\r\nroot@e7bfbff82a10:/tf_files# python label_image.py new/maca/2Q==.jpg\r\nTraceback (most recent call last):\r\n  File \"label_image.py\", line 11, in <module>\r\n    image_data = tf.gfile.FastGFile(image_path, 'rb').read()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 115, in read\r\n    self._preread_check()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 75, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: new/maca/2Q==.jpg\r\n\r\nI follow all steps of code lab TensorFlow for poets, but I still have this problem. ", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11150, "title": "Printdhruv patch 2", "body": "Update ISSUE_TEMPLATE.md", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.\r\n"]}, {"number": 11149, "title": "Self-contained source code package of tensorflow", "body": "Dear TensorFlow development team,\r\n    Government regularization on medical software requires software to be compiled from fully controllable source code. Downloading from outside of the manufacture is not permitted. This literally implies that medical software should be able to compile without Internet connection. Currently, the bazel compilation procedure download from Internet. We post this request for a self-contained package of tensorflow.\r\n\r\n", "comments": ["+1 for me. There are many reasonable situations when it is not desired and/or feasible to download additional packages at compile time.", "There are several third-party open source source code are download  when build, maybe you can download manually and store on local machine and modify the url of the source repository so that you can build without download again.", "@datainfer \r\nIs this still an issue, could you please check in the latest version as many issues have been fixed in the latest version", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/11149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/11149\">No</a>\n"]}, {"number": 11148, "title": "TFDBG Crashing on Windows 10; 'Causality Violated in Timing Relations of Debug Dumps'", "body": "I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd. \r\n\r\nBut when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'\r\n\r\n------------------------\r\n\r\n-Windows 10, up to date\r\n-Python 3.5\r\n-TensorFlow 1.2.0, compiled in CPU-only mode\r\n\r\nSource Code:\r\nI have one script to define the network and one to run the actual test. I will include both.\r\n\r\nsameDiffNet:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass SameDiffNet:\r\n\t# class is a siamese FC network for classifying vectors as same/different\r\n\t\r\n\tdef __init__(self,inputLen):\r\n\t\t# settings\r\n\t\tself.NUM_BRANCHES = 2\r\n\t\tself.LAYER_SIZES = [100,100]\r\n\t\tself.DATA_TYPE = tf.float32\r\n\t\t\r\n\t\t# input\r\n\t\tself.inputs = []\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\r\n\r\n\t\t# network branches\r\n\t\tself.branches = []\r\n\t\tself.branchWeights = self.branch_weights(inputLen)\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.branches.append(self.network_branch(branch))\r\n\t\t\t\t\r\n\t\t# combination layer and loss\r\n\t\tself.out = self.distance_layer_euclidean()\r\n\t\tself.target = tf.placeholder(self.DATA_TYPE,None)\r\n\t\tself.loss = self.cross_entropy_loss()\r\n\t\t\r\n\tdef branch_weights(self,inputLen):\r\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\r\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\r\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\r\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=\"weights\"))\r\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias\"))\r\n\t\t\r\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\r\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=\"weights\"))\r\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=\"bias\"))\r\n\t\t\r\n\t\treturn netWeights\r\n\t\t\r\n\tdef network_branch(self,branch):\r\n\t\tfc = self.inputs[branch]\r\n\t\tfor layer in range(len(self.LAYER_SIZES)):\r\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\r\n\t\treturn fc\r\n\t\t\t\r\n\tdef distance_layer_euclidean(self):\r\n\t\tassert self.NUM_BRANCHES == 2\r\n\t\tdist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))\r\n\t\treturn dist\r\n\t\t\r\n\tdef cross_entropy_loss(self):\r\n\t\tloss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))\r\n\t\treturn loss`\r\n```\r\n\r\ntoyTestTraining:\r\n```\r\n''' A simple test where we train our siamese network on toy examples\r\nOur training data consists of a pair of 0's and 1's, and our truth output will\r\nsimply be the XOR of these two values'''\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import debug as tf_debug\r\nfrom sameDiffNet import SameDiffNet\r\n\r\nnumTraining = 1000\r\nnumIter = 1000\r\n\r\nsess = tf.InteractiveSession()\r\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\r\nsess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\r\nnetwork = SameDiffNet(2)\r\noptimizer = tf.train.AdamOptimizer().minimize(network.loss)\r\n\r\ndata = np.random.randint(0,2,(numTraining,2))\r\ntruth = data[:,0] == data[:,1]\r\ntruth = [float(not truth[b]) for b in range(numTraining)]\r\ndata = data.astype(float)\r\n\r\ninit = tf.global_variables_initializer().run()\r\nfor iter in range(numIter):\r\n\tpermutationL = np.random.permutation(numTraining)\r\n\tpermutationR = np.random.permutation(numTraining)\r\n\ttarget = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]\r\n\r\n\ttotalLoss = 0.0\r\n\tfor v in range(numTraining):\r\n\t\t_, loss = sess.run([optimizer,network.loss], feed_dict={\r\n\t\t\t\t\t\tnetwork.inputs[0]:[data[permutationL[v],:]],\r\n\t\t\t\t\t\tnetwork.inputs[1]:[data[permutationR[v],:]],\r\n\t\t\t\t\t\tnetwork.target: target[v]})\r\n\t\ttotalLoss += loss\r\n\t\t\r\n\tif np.isnan(totalLoss):\r\n\t\tprint('Model diverged with loss = NaN')\r\n\t\tquit()\r\n\r\n\tif iter % 10 == 0:\r\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\r\n```\r\n\r\n\r\nimport toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Computer Vision\\Siamese Same-Different Network\\toyTestTraining.py\", line 35, in <module>\r\n    network.target: target[v]})\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 495, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 312, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 551, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 809, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 985, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]\r\n\r\n\r\nThis error happens 100% of the time I run these commands.\r\nI apologize in advance if I'm overlooking something obvious. Thank you.", "comments": ["check this [official code for tfdebug](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/examples/debug_mnist.py).\r\nYou should use `sess = tf_debug.LocalCLIDebugWrapperSession(sess)` after you have initialized all the variables.", "Nagging Assignee @caisq: It has been 290 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}]