[{"number": 9276, "title": "Implement atan2", "body": "This addresses #6095.\r\n\r\nSince `atan2` is not implemented in Eigen, this is loosely based on the `rint` implementation. Suggestions are welcome.", "comments": ["That will require and API review.", "I've addressed your code comments (although I won't get a chance to test the GPU code myself until tomorrow).", "Jenkins, test this please.", "Could we add a test that checks random values, and also all special values listed here?\r\nhttps://docs.scipy.org/doc/numpy/reference/generated/numpy.arctan2.html\r\n\r\nThanks", "Done. Gradients for random arguments are rather flaky, unless I clip the inputs to be well away from zero. Perhaps this is because the gradients blow up near the origin. Curiously, I have to clip them more severely for float64 inputs, due to the stricter tolerance on the check.", "Jenkins, test this please.", "Apparently `math.inf` doesn't exist in python 2. I've fixed that, but it doesn't explain the python 3 failure. How can I see the detailed log of the failure? I can't find it on the CI web interface.", "FWIW, running bazel test --config=opt //tensorflow/python/kernel_tests:cwise_ops_test passes now (with my previous commit) for both python 2 and 3 on my local machine. Perhaps you could test it again?", "You'll need to add an entry [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/api/golden/tensorflow.pbtxt#L635) to extend the public API.\r\n\r\nJenkins, test this please.", "Done.", "Jenkins, test this please.", "@martinwicke this is an API change, WDYT?", "This is good from an API perspective after reverting to the `(y, x)` signature.", "Done.", "Jenkins, test this please.", "Jenkins, test this please.", "Fetch errors.\r\n\r\nJenkins, test this please."]}, {"number": 9275, "title": "incorrect datasets path in tutorial: tf.contrib.learn.datasets.base.load_csv_with_header", "body": "The path for loading the iris dataset \" tf.contrib.learn.datasets.base.load_csv_with_header\" in the tutorial is incorrect:\r\n\r\n`# Load datasets.\r\n  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n      filename=IRIS_TRAINING,\r\n      target_dtype=np.int,\r\n      features_dtype=np.float32)\r\n  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n      filename=IRIS_TEST,\r\n      target_dtype=np.int,\r\n      features_dtype=np.float32)\r\n`\r\n\r\nI believe it should be something closer to the README here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/README.md\r\n\r\n`import tensorflow.contrib.learn.python.learn as learn\r\nfrom sklearn import datasets, metrics\r\n\r\niris = datasets.load_iris()`", "comments": ["What do you mean by path? You mean the variable? The documentation links to another page where it's defined. https://www.tensorflow.org/get_started/tflearn", "\r\nI get an \"ImportError\": there is no path tf.contrib.learn.datasets and no \"tf.contrib.learn.datasets.base.load_csv_with_header\". These are specified in the documentation referenced [https://www.tensorflow.org/get_started/tflearn](https://www.tensorflow.org/get_started/tflearn).\r\n"]}, {"number": 9274, "title": "Merging rc2 commits back into master.", "body": "Note: went with master versions of keras, cmake differences, and 1.1 version of configure.", "comments": ["Jenkins, test this please."]}, {"number": 9273, "title": "[Docs] Update wheels URLs to match latest TensorFlow release (1.1.0)", "body": "The wheels available on the website are from the previous release (1.0.1) which still contain OpKernels errors that are solved at head (as well as on 1.1.0) and can be ignored but are confusing users prompting repeated reports of this issue.", "comments": ["What errors are you thinking of? Which release points?\r\n\r\n@av8ramit @yifeif for cherry-picking.", "@drpngx It's fixed has been a long time but for some reason it didn't make it to 1.0.1. (updated description above to mention 1.1.0)\r\n\r\n#8500 #8724 #8525 #7859 #8644 are some reports of the same problem as other mentions that eventually come up in closed issues. The issue itself is harmless but confusing users. ", "Oh yes, I was on some of those threads. Thanks for making the connection! We should definitely think about some remediation action, either cherry pick or add some kind of informative unsupported message, or add some docs.", "Thanks for reporting this @Carmezim! We usually do not update the binary [urls](https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package) for RCs. But official 1.1.0 should be out very soon.", "@yifeif so action is to wait for `1.1`?", "Got it. Do you think would be interesting to add a temporary note to common issues for instance, or point users to the PYPI packages that are already compliant with the latest version?\r\n\r\nNow is closer to the official release than when most of these issues were reported so I don't know if it makes sense for you guys to change the docs.", "Went through the issues @Carmezim linked to again and it looks like most people saw this issue were using \"pip install tensorflow\", which by default, does not install release candidates. We can add an entry under [\"Common Installation Problem\"](https://www.tensorflow.org/install/install_windows#common_installation_problems) to comment on the issue on 1.0.1 binary for future references. I'll send a PR.", "At the time those issues did arise also 1.0.1 was on PYPI (before March 24) which now contains 1.1rc2 so it will probably only affect those following the Anaconda and virtualenv instructions that point to install with the official 1.0.1 binary. That may help narrow down the possible affected users", "PR merged. Website will be updated with the 1.1.0 release(cc @av8ramit). Closing this issue. Thanks!"]}, {"number": 9272, "title": "[idea] new Op: Conv2DWithBiasActivation for Backends that Support Higher Level Op", "body": "This is a [repost of the comment here](https://github.com/tensorflow/tensorflow/pull/8673#issuecomment-290722014):\r\n\r\nAlong the lines of [`MklConv2DWithBias`](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645), I suggest defining a new primitive Op, `Conv2DWithBiasActivation` that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.\r\n\r\nAs far as the (new) fused `Conv2D` Op that I am using for my BNNS implementation, I used the [MKL Conv2D Op](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645) as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.\r\n\r\nI understand that the primitive `Conv2D` op in TF does not currently handle activations or bias addition, but this op may be \"too primitive\". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: https://github.com/tensorflow/tensorflow/issues/8828). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a `fused` version of the Op to reduce the number of primitive Ops used.\r\n\r\nAddendum\r\nThere are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:\r\n* Metal Performance Shaders (https://github.com/tensorflow/tensorflow/issues/7958). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned `MPSTemporary\u200bImage` and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.\r\n* MKL (as linked above, perhaps the MKL specific Op (`MklConv2DWithBias`) can be unified with this new Op.\r\n* [cuDNN v6](https://github.com/tensorflow/tensorflow/issues/8828)\r\n\r\n/CC @drpngx @petewarden @flx42 @gunan ", "comments": ["Assigning @petewarden but feel free to bounce.", "We're going to be working on fusing ops like this as part of TF Lite, so I don't think this change will make it into the main code base. Closing, but please reopen if you strongly feel the fused ops should exist at this level.", "I don't know what TF Lite is, but I guess I do think this would be valuable for TF main."]}, {"number": 9271, "title": "Remove extra space in sample code", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 9270, "title": "SVM output layer in tensor flow", "body": "The SVM output layer has been shown to accelerate model training in [https://arxiv.org/pdf/1306.0239.pdf](https://arxiv.org/pdf/1306.0239.pdf).  Is the SVM output layer available as an alternative for `tf.nn.softmax` in tensorflow at this moment?", "comments": ["I'm not aware of an effort here, but that's probably a good candidate for `tf.contrib`. We could put it in learn @sguada , layers @fchollet or `nn` @ebrevdo .", "@agarwal-ashish might also know of any existing efforts", "There is no such a layer currently. We have the following that are related but not sufficient for what you want to do here:\r\n- a binary svm head (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/head.py) which is the head for standard hinge loss\r\n- a linear SVM classifier (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/svm.py). This is for binary classification only and also uses SDCA for the underlying optimization problem but SDCA is not gradient based so it won't play well when composing with SGD and NNs.\r\n\r\nHowever, I was planning to add multi-class hinge loss (Cramer & Singer maybe) at some point.", "Thanks! Sounds good.", "@petrosmol @drpngx  there is already an implementation of [SVM output layer](https://github.com/dmlc/mxnet/pull/2708/commits/7a651fd2867e56ffcbf539aaaf4218e11cf61b0d) in MxNet. It may be useful for similar implementation in tensorflow. ", "If you can write the SVM layer as a composition of simple ops, inputs, and\nVariables, i suggest putting it in tf.contrib.layers.  How much C++ code\ndoes it require?\n\nOn Tue, Apr 18, 2017 at 9:32 AM, Xiangchun Li <notifications@github.com>\nwrote:\n\n> @petrosmol <https://github.com/petrosmol> @drpngx\n> <https://github.com/drpngx> there is already an implementation of SVM\n> output layer\n> <https://github.com/dmlc/mxnet/pull/2708/commits/7a651fd2867e56ffcbf539aaaf4218e11cf61b0d>\n> in MxNet. It may be useful for similar implementation in tensorflow.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9270#issuecomment-294902033>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim5Y0v7TyBvIANSaMClzm7VEU26dPks5rxOWMgaJpZM4M_RXV>\n> .\n>\n", "Has there been any progress about this implementation? I'd be also interested in an option to use one-class SVM. I'm currently considering implementing that myself but it might take a while if I have to do it from scratch... ", "FYI, I have checked in sparse_multiclass_hinge_loss which can be used (almost) as a drop-in replacement in place of sparse_softmax_cross_entropy_with_logits. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/kernel_methods/python/losses.py\r\nfor more details. The only difference is that logits passed to sparse_multiclass_hinge_loss should have rank 2 ([batch_size, num_classes]). And I ran some experiments that confirm that, in some cases, accuracy-related metrics can be improved by replacing softmax_cross_entropy with multiclass_hinge_loss", "+1", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Is there any further update that supports directly make SVM, especially non-linear svm with custom regularization (at least common ones like l2-regularization) as one layer in a neural network?", "Are there any updates on this topic?", "Is this a separate feature request? In response to the initial request I checked in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/kernel_methods/python/losses.py some time ago. \r\n\r\n@atomextranova: Can you elaborate on your request? also shall we open a separate issue for this?", "Thanks!"]}, {"number": 9269, "title": "Merge pull request #1 from tensorflow/master", "body": "sync", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "No files seem to be changed and no CLA signed. Please reopen if necessary."]}, {"number": 9268, "title": "Fix code annotation", "body": "Fix code annotation", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 9267, "title": "Including the grpc++/create_channel.h only when gRPC support is enabled", "body": "Trying to build TF without the support of gRPC should not include the create_channel header.", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed the CLA agreement.", "CLAs look good, thanks!\n\n<!-- ok -->", "@tensorflow-jenkins test this please", "Linux CPU Makefile build flaked out. Testing again.\r\n\r\n@tensorflow-jenkins test this please"]}, {"number": 9266, "title": "Update batch_norm_benchmark.py", "body": "Fix typo", "comments": []}, {"number": 9265, "title": "fix style_guide.md my_op-example", "body": "2 Typos causes errors:\n\n-tf.add_to_collections -> tf.add_to_collection\n-adding missing indentation (0 -> 2 spaces)\n\nResulting my_op-chunk tested with tf. version 1.0.1\n\nSee:\nhttps://www.tensorflow.org/community/style_guide\nFor the erronous version.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 9264, "title": "Install on Windows 10 not working on power shell, but cmd", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Pro Version 1607 amd64 \r\n- **TensorFlow installed from (source or binary)**:\r\nInstall via native pip or anaconda via:\r\n```\r\nconda create -n tensorflow python=3.5\r\n```\r\n- **TensorFlow version (use command below)**:\r\nAs described in the get started page:\r\n```\r\npip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl\r\n```\r\n- **Bazel version (if compiling from source)**: - \r\n- **CUDA/cuDNN version**: - \r\n- **GPU model and memory**: - \r\n- **Exact command to reproduce**: - \r\nFollow the install instructions [1] on windows using the **power shell** or **git bash** (with or without admin rights)\r\n1: https://www.tensorflow.org/install/install_windows\r\n\r\nYou can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow'\r\n```\r\n### Describe the problem\r\n\r\n### Source code / logs\r\nOn running the pip install command, the classic \"... wheel is not supported\" error comes up:\r\n```\r\nPS C:\\Users\\user> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl\r\ntensorflow-1.0.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\r\n```\r\n\r\nUsing the cmd, everything works just fine and i think, that a lot of people are having this problem out there right now, imho the install doc page must be updated to contain some warnings about this.\r\n\r\nOh and by the way: tensorflow is fucking amazing!\r\n", "comments": ["It looks like the powershell environment might be using a different platform.\r\nFollow the command [here](http://stackoverflow.com/questions/28107123/cannot-install-numpy-from-wheel-format) to figure out what version you need.", "Just a question, are you installing outside the conda env and importing TF inside it? \r\n\r\nIt is working as expected on PowerShell.\r\n```\r\nPS C:\\Users\\AppData\\Local\\Programs\\Python\\Python35\\Scripts> python .\\pip3.5.exe install --ignore-installed --upg\r\nrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl\r\nCollecting tensorflow==1.0.1 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_\r\namd64.whl\r\n  Downloading https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl (14.7MB)\r\n    100% |################################| 14.7MB 71kB/s\r\nCollecting numpy>=1.11.0 (from tensorflow==1.0.1)\r\n  Using cached numpy-1.12.1-cp35-none-win_amd64.whl\r\nCollecting wheel>=0.26 (from tensorflow==1.0.1)\r\n  Using cached wheel-0.29.0-py2.py3-none-any.whl\r\nCollecting protobuf>=3.1.0 (from tensorflow==1.0.1)\r\n  Using cached protobuf-3.2.0-py2.py3-none-any.whl\r\nCollecting six>=1.10.0 (from tensorflow==1.0.1)\r\n  Using cached six-1.10.0-py2.py3-none-any.whl\r\nCollecting setuptools (from protobuf>=3.1.0->tensorflow==1.0.1)\r\n  Downloading setuptools-35.0.0-py2.py3-none-any.whl (390kB)\r\n    100% |################################| 399kB 193kB/s\r\nCollecting appdirs>=1.4.0 (from setuptools->protobuf>=3.1.0->tensorflow==1.0.1)\r\n  Using cached appdirs-1.4.3-py2.py3-none-any.whl\r\nCollecting packaging>=16.8 (from setuptools->protobuf>=3.1.0->tensorflow==1.0.1)\r\n  Using cached packaging-16.8-py2.py3-none-any.whl\r\nCollecting pyparsing (from packaging>=16.8->setuptools->protobuf>=3.1.0->tensorflow==1.0.1)\r\n  Using cached pyparsing-2.2.0-py2.py3-none-any.whl\r\nInstalling collected packages: numpy, wheel, six, appdirs, pyparsing, packaging, setuptools, protobuf, tensorflow\r\nSuccessfully installed appdirs-1.4.3 numpy-1.12.1 packaging-16.8 protobuf-3.2.0 pyparsing-2.2.0 setuptools-35.0.0 six-1.\r\n10.0 tensorflow-1.1.0rc1 wheel-0.29.0\r\nPS C:\\Users\\Adriano\\AppData\\Local\\Programs\\Python\\Python35\\Scripts> python\r\nPython 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('\r\nop: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\nb'Hello, TensorFlow!'\r\n```", "@Carmezim I am not saying that it is not possible somehow like you're installing it, the point is, what you're doing does not match the install guide and standard case.\r\n\r\nAs described above I did follow the install guide for windows via both ways, via native pip and via anaconda _as_ described in the install guide.\r\n\r\n@drpngx the environment has been for each install completely been set new and according to strict python:3.5 (version). Many folks out there say, that the only way is to install python:3.6 and go from there but I took the tensorflow dependency very strict and refused to use something not supported, recommended, documented, etc. So the dependencies are right.\r\n\r\n@all what's with the unknown op? This is also something 1:1 copy and pasted from the getting started guide which is has an different output.", "@Carmezim thx for your https://github.com/tensorflow/tensorflow/issues/7778#issuecomment-281678077 regarding the warnings and unknow op. This should somehow match the install guide for ident input (guide examples) and output.", "@4F2E4A2E It does match the standard case as in it was installed satisfying all requirements in the Docs and with the code you provided that generated error for you on PowerShell. \r\nIf you're referring calling pip globally or using the script it won't make any difference whatsoever. \r\n\r\nSo the unsupported wheel error you received is due something wrong on your side and not a TensorFlow bug neither related to PowerShell. \r\nOne case for instance is if you have more than one Python installation besides 3.5 64-bit generating conflicts with `pip` as it may be linked not to 3.5 but to other version, therefore requiring to use `pip3`. I am not sure if this is your situation.\r\n\r\nThe only thing I didn't test was to use a conda environment on PowerShell.", "Thanks, I guess you're referring to https://github.com/tensorflow/tensorflow/issues/9273 right? :)", "@4F2E4A2E I am referring to the unsupported wheel error you've got trying to install TensorFlow through Powershell, which is not a TensorFlow bug neither Powshell's but derived from a misconfiguration on your side. Then I mentioned one possible and common cause of this error which is multiple python installations and `pip` linking to an unsupported one (e.g. 2.7, 3.6 etc in this case).\r\n\r\nThe issue 9273 is a different situation non related to the problems you reported.\r\n\r\nThe only case to be addressed now is if there is any conflict using TensorFlow in a conda environment on PowerShell as you mentioned.", "Hi @4F2E4A2E, did you make any progress? Let us know if you need help with anything else. If you happened to have solved, this issue can be closed now.", "I had tensorflow working from the beginning, the only thing I wanted to point out is that if one follows the guide it won't work in some cases. I am glad you found the cause of this problem, you also sure did test it in a clean environment and can to 100% exclude any problems with the install procedure. Great job! \ud83d\udc4d \r\n> which is not a TensorFlow bug neither Powershell's but derived from a misconfiguration on your side.\r\n"]}, {"number": 9263, "title": "import tensorflow Segmentation fault", "body": "I get 'Segmentation fault' everytime when import tensorflow.\r\nNo matter which tf's version, or which numpy's version i try. Or even 'import numpy' at first.\r\nMy computer is CentOS6.5 with python 2.7.3.\r\nCurrent tensorflow's version is 'https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl'.\r\nBTW: it happends after i try to update my glibc. cause i met \"version `GLIBC_2.14' not found\" and \"version `GLIBC_2.16' not found\" before.", "comments": ["And GDB shows me this:\r\n\r\n[Thread debugging using libthread_db enabled]\r\nMissing separate debuginfo for /home/tools/Python/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0\r\n[New Thread 0x7ffff3244700 (LWP 29968)]\r\n[New Thread 0x7ffff2843700 (LWP 29969)]\r\n[New Thread 0x7fffefe42700 (LWP 29970)]\r\n[New Thread 0x7fffed441700 (LWP 29971)]\r\n[New Thread 0x7fffeaa40700 (LWP 29972)]\r\n[New Thread 0x7fffe803f700 (LWP 29973)]\r\n[New Thread 0x7fffe563e700 (LWP 29974)]\r\n\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n0x00007ffff7bc678b in init_one_static_tls (map=0x0) at allocatestack.c:1171\r\n1171\t  void *dest = (char *) curp - map->l_tls_offset;\r\nMissing separate debuginfos, use: debuginfo-install glibc-2.12-1.192.el6.x86_64 keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-57.el6.x86_64 libcom_err-1.41.12-22.el6.x86_64 libselinux-2.0.94-7.el6.x86_64 openssl-1.0.1e-48.el6_8.4.x86_64 zlib-1.2.3-29.el6.x86_64", "Sorry, we don't support CentOS below 7. It looks like there is the wrong glibc. I would suggest installing from source in that case.", "I install it from source and it work. Thanks a lot!", "Great, thanks for reporting back!"]}, {"number": 9262, "title": "Estimator numpy_input_fn doesn't work when reading input with pytables", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Relatively straightforward attempt at using estimator flow with `input_fn`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Gentoo Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: b'v1.0.0-2171-gbaa85cb' 1.0.1\r\n- **Bazel version (if compiling from source)**: 0.4.4-\r\n- **CUDA/cuDNN version**: 8.0.61\r\n- **GPU model and memory**: GTX 970 4GB\r\n- **Exact command to reproduce**: \r\n\r\nOther stuff: Python 3.4, pytables 3.3.0, numpy 1.12.1, hdf5-1.8.18\r\n\r\n### Describe the problem\r\n\r\nI have an issue when reading multidimensional arrays from hdf5 file using pytables. I can fix the issue for myself locally by changing `_OrderedDictNumpyFeedFn` class (line 173 in my version) from \r\n\r\n```python\r\n column[integer_indexes]\r\n```\r\n\r\nto\r\n\r\n```python\r\nnp.take(column, integer_indexes, axis=0)\r\n```\r\n\r\n### Source code / logs\r\n\r\nRelevant bit of code:\r\n\r\n```python\r\ndef make_input_fn(data, batch_size):\r\n    input_features = {node.name: node for node in data.get_node('/x')}\r\n    ys = data.get_node('/y')\r\n    return numpy_input_fn(input_features, ys, batch_size=batch_size, num_epochs=5, shuffle=False, num_threads=1)\r\n\r\ndef main(unused_argv):\r\n    model_fn = make_train_model(feat)\r\n    config = learn.RunConfig(save_checkpoints_secs=60)\r\n    est = learn.Estimator(\r\n        model_fn=model_fn, model_dir=\"data/tf/try1\", config=config\r\n    )\r\n    training_data = tables.open_file('data/hdf5/training.h5')\r\n    train_in = make_input_fn(training_data, 256)\r\n    est.fit(\r\n        input_fn=train_in,\r\n        steps=100\r\n    )\r\n    training_data.close()\r\n```\r\n\r\nError I get:\r\n\r\n```\r\nINFO:tensorflow:Using config: {'_is_chief': True, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 60, '_environment': 'local', '_num_ps_replicas': 0, '_master': '', '_task_type': None, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1.0\r\n}\r\n, '_num_worker_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff377eaf550>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_evaluation_master': '', '_model_dir': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_task_id': 0}\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2017-04-17 10:05:38.231511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-04-17 10:05:38.231863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: GeForce GTX 970\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.4305\r\npciBusID 0000:01:00.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.45GiB\r\n2017-04-17 10:05:38.232016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-04-17 10:05:38.232048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-04-17 10:05:38.232081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)\r\nINFO:tensorflow:Restoring parameters from data/tf/try1/model.ckpt-4\r\nINFO:tensorflow:Error reported to Coordinator: <class 'ValueError'>, operands could not be broadcast together with shapes (256,) (4,) \r\nINFO:tensorflow:Saving checkpoints for 4 into data/tf/try1/model.ckpt.\r\nTraceback (most recent call last):\r\n  File \".../venv/lib/python3.4/site-packages/tables/array.py\", line 651, in __getitem__\r\n    startl, stopl, stepl, shape = self._interpret_indexing(key)\r\n  File \".../venv/lib/python3.4/site-packages/tables/array.py\", line 408, in _interpret_indexing\r\n    raise TypeError(\"Non-valid index or slice: %s\" % key)\r\nTypeError: Non-valid index or slice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python3.4/runpy.py\", line 170, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib64/python3.4/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/zfs_data/Sources/betahex/betahex/training/supervised.py\", line 106, in <module>\r\n    tf.app.run()\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/zfs_data/Sources/betahex/betahex/training/supervised.py\", line 99, in main\r\n    steps=50\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \".../venvs/default/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 429, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 977, in _train_model\r\n    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\r\n  File .../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 500, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 535, in _close_internal\r\n    self._sess.close()\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 769, in close\r\n    self._sess.close()\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 866, in close\r\n    ignore_live_threads=True)\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/lib/python3.4/site-packages/six.py\", line 686, in reraise\r\n    raise value\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py\", line 93, in _run\r\n    feed_dict = None if feed_fn is None else feed_fn()\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\", line 175, in __call__\r\n    for column in self._ordered_dict_of_arrays.values()\r\n  File \".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\", line 175, in <listcomp>\r\n    for column in self._ordered_dict_of_arrays.values()\r\n  File \".../venv/lib/python3.4/site-packages/tables/array.py\", line 656, in __getitem__\r\n    coords = self._point_selection(key)\r\n  File \".../venv/lib/python3.4/site-packages/tables/leaf.py\", line 561, in _point_selection\r\n    coords[idx] = (coords + self.shape)[idx]\r\nValueError: operands could not be broadcast together with shapes (256,) (4,) \r\nClosing remaining open files:data/hdf5/training.h5...done\r\n```", "comments": ["@sguada is that a scenario that is supposed to work?", "Not sure better ask @martinwicke ", "Interesting, your `np.take` expression ought to be equivalent to the fancy indexing, but maybe pytables doesn't fully support the fancy expression. Do you want to send a PR? Looks like yours is strictly more robust.", "`np.take` converts its input to a numpy array, so of course it works. So would `np.asarray(column)[integer_indexes]`.\r\n\r\nInstead, it would probably make sense for `numpy_input_fn` to either coerce each value to a numpy array with `np.asarray`, or raise an error if any inputs aren't numpy arrays.", "Ah, right. coercing each input to be actual numpy arrays makes most sense.", "Thank you all for your comments, they made me explore this issue a bit further, and get to the following conclusions:\r\n\r\n- As @shoyer observed, `np.take()` works because numpy does `np.asaray()`, but that means that entire array is loaded into memory.\r\n- pytables does support \"fancy\" indexing, but arity must still match with array's dimensions\r\n- but they do support ellipsis, so `data[list,...]` actually works.\r\n\r\nAt this point I feel this should be treated as an issue with pytables. Doing `np.asarray(column)` would actually be a regression in my case, because it would slow things down due to copying (things *are* slow with the fix I mentioned in the issue, and I now have an idea why). Changing tensorflow code to add ellipsis when reading a batch from column is what I'll do locally, to see if thing are gonna speed up, but I feel it's too specific workaround to be merged upstream.", "Thanks @StarvingMarvin. I will close this issue. If you determine that the ellipsis works without negative side effects, feel free to send a PR."]}, {"number": 9261, "title": "a python implmentation of label_image", "body": "A quick implementation of tensorflow/examples/label_image/main.cc\r\nin python.\r\n\r\nWith data file described in [1], we can we get reasonable results\r\n\r\n$ python3 ./tensorflow/examples/label_image/label_image.py\r\nmilitary uniform 0.834306\r\nmortarboard 0.0218692\r\nacademic gown 0.0103579\r\npickelhaube 0.00800814\r\nbulletproof vest 0.00535088\r\n\r\n[1] https://www.tensorflow.org/tutorials/image_recognition", "comments": ["Can one of the admins verify this patch?", "@petewarden ping?", "Can one of the admins verify this patch?", "@petewarden is this good to go?", "Jenkins, test this please.", "Can you fix this error? That should also clear the other problems.\r\n\r\n```\r\ntensorflow/examples/label_image/label_image.py:128: [W0311(bad-indentation), ] Bad indentation. Found 5 spaces, expected 4\r\n```", "Thanks. Fixed and pushed it.", "@tensorflow-jenkins test this please", "Jenkins, test this please.", "Looks like some transient failure.\r\n\r\nJenkins, test this please.", "Jenkins, test this please.", "hi,there is a ';' at the end of the line 54,and why I can not find the function of tf.image.decode_bmp in a python3 interpreter.\r\n     \r\n    dims_expander = tf.expand_dims(float_caster, 0);\r\n\r\n", "1. yes, I am a C programmer :-)\r\n2. please update your TensorFlow package for python3"]}, {"number": 9259, "title": "TensorFlow on ARMv7 seems to be slower", "body": "I have installed tensorflow on our custom board which is based on i.mx6 (ARMv7) processor. I have compiled the C++ module alone without python support and was able to run the \"tensorflow/pi_examples/label_image\"\r\n\r\nCommand used:  **make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI**\r\n\r\nThe problem is that the application seems to be very slow compared to Laptop (Intel i5). The inference takes close to 60-70s while it takes only 0.6 - 0.7s in my Laptop. \r\n\r\nAfter that, I figured out that I missed to use compiler optimization flag to use Neon. I compiled with Neon support and now it takes around 10-17s for same example.\r\n\r\nCommand used: **make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI  OPTFLAGS=\"-Os -mfpu=neon -funsafe-math-optimizations -ftree-vectorize\"**\r\n\r\nIs there anything I am missing?\r\n\r\n### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Yocto debian flavour\r\n- **TensorFlow installed from**:  source (27a9808)\r\n- **TensorFlow version**: NA\r\n- **Bazel version (if compiling from source)**: Not used\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n", "comments": ["@petewarden do these number look reasonable? 20x?", "It's good to see that NEON helps. It's hard to say exactly what performance you should be getting without knowing more about your model, and exactly which i.mx6 chip you're using, but a 10x slowdown on a low-power chip versus a laptop doesn't seem too crazy.", "@gunasekaran7, closing since it looks like you are getting reasonable performance. If you have a more specific issue, let us know.", "@petewarden, I am using i.mx6 QuadCore from NXP.", "@gunasekaran7 Hi, could you please tell me how to cross-compile tensorflow c++ module on i.mx6? Thank you so much!", "@Air000 , I used this [link](https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md)", "@gunasekaran7 Thanks! I successfully ported tensorflow to i.MX6! \r\nBut I meet another issue, when I run the benchmark or label_image, it comes out with messages like \"E tensorflow/core/framework/op_kernel.cc:1142]\", but it also says \"Running model succeeded!\" at the end. I don't know what it means by \"E tensorflow/core/framework/op_kernel.cc:1142\".", "@Air000, Were you able to see the class label output on the terminal?", "@gunasekaran7, Yes, output as following:\r\n```\r\n2017-06-28 09:53:25.282150: I tensorflow/contrib/pi_examples/label_image/label_image.cc:379] Running model succeeded!\r\n2017-06-28 09:53:25.296182: I tensorflow/contrib/pi_examples/label_image/label_image.cc:273] military uniform (866): 0.647334\r\n2017-06-28 09:53:25.296287: I tensorflow/contrib/pi_examples/label_image/label_image.cc:273] suit (794): 0.0477206\r\n2017-06-28 09:53:25.296338: I tensorflow/contrib/pi_examples/label_image/label_image.cc:273] academic gown (896): 0.0232351\r\n2017-06-28 09:53:25.296390: I tensorflow/contrib/pi_examples/label_image/label_image.cc:273] bow tie (817): 0.0157328\r\n2017-06-28 09:53:25.296439: I tensorflow/contrib/pi_examples/label_image/label_image.cc:273] bolo tie (940): 0.0144991\r\n```", "@Air000. then you are good to go.its working fine.."]}, {"number": 9257, "title": "InvalidArgumentError when running word2vec_basic.py", "body": "### System information\r\n- Just running the word2vec_basic.py\r\n- Windows 10 64bir\r\n- b'unknown' 0.12.head (I installed 0.12 first then uninstalled old version and install new version to 1.0)\r\n- GTX 760 4GB\r\n\r\n\r\n### Describe the problem\r\n\r\n```\r\nInvalid argument: indices[0] = 4575361316406883040 is not in [0, 50000)\r\n         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\nW c:\\tensorflow\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:975] Invalid argument: indices[0] = 4575361316406883040 is not in [0, 50000)\r\n         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1021, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1003, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\Anaconda3\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 4575361316406883040 is not in [0, 50000)\r\n         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \".\\word2vec_basic.py\", line 232, in <module>\r\n    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 4575361316406883040 is not in [0, 50000)\r\n         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\n\r\nCaused by op 'nce_loss/embedding_lookup', defined at:\r\n  File \".\\word2vec_basic.py\", line 199, in <module>\r\n    num_classes=vocabulary_size))\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 1044, in nce_loss\r\n    name=name)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 891, in _compute_sampled_logits\r\n    weights, all_ids, partition_strategy=partition_strategy)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 111, in embedding_lookup\r\n    validate_indices=validate_indices)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1293, in gather\r\n    validate_indices=validate_indices, name=name)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2371, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1258, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): indices[0] = 4575361316406883040 is not in [0, 50000)\r\n         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\n```\r\nIt seems that somehow indices[num] point to a very large number that not in the vocabulary vector?\r\n\r\nI found there are also two cases in https://github.com/dennybritz/cnn-text-classification-tf/issues/17 but cannot find the solution\r\n", "comments": ["It seems due to the version conflict, solved", "@Strideradu  what did you mean by \"It seems due to the version conflict\"?, I faced with this problem too, how did you solve it? thanks!\r\n\r\nerror:\r\npywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[16,422] = 53410 is not in [0, 53410)", "@zhangwbnn you may want to check the version of Tensorflow. That time I thought I updated my 0.12 to 1.0 but later I found seems not and I uninstalled old tensorflow and reinstalled again", "word2vec_basic.py works on 1.0.0-rc2 but not 1.2.0-rc1:\r\n\r\n> Caused by op u'nce_loss/embedding_lookup', defined at:\r\n  File \"/home/hadi/Projects/NLP/word2vec.py\", line 171, in <module>\r\n    num_classes=vocabulary_size))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py\", line 1151, in nce_loss\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py\", line 970, in _compute_sampled_logits\r\n    weights, all_ids, partition_strategy=partition_strategy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 122, in embedding_lookup\r\n    return maybe_normalize(_do_gather(params[0], ids, name=name))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 42, in _do_gather\r\n    return array_ops.gather(params, ids, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\r\n    validate_indices=validate_indices, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2511, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1267, in __init__\r\n    self._traceback = _extract_stack()\r\nInvalidArgumentError (see above for traceback): indices[0] = -1 is not in [0, 50000)\r\n\t [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Variable_1\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, nce_loss/concat)]]\r\n\r\n", "I get the following error too after running an embedding layer as;\r\n\r\n`Embedding(23624, 50, input_length=5, trainable=False)`\r\n\r\n> InvalidArgumentError (see above for traceback): **indices[6,4]** = 23624 is not in [0, 23624)\r\n> \t [[Node: embedding_1/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\r\n\r\nEach datapoint here is a number(index). Upon checking indices[6,4] I found the following\r\n\r\n```\r\nprint(ar_train_data[6,4])\r\n5088\r\n```\r\nThe training stops towards the end of the first epoch with this error.\r\nam amazed! 5088 is no where out of range for [0, 23624).  Can anyone suggest what could be the issue here?\r\nPlease suggest if additional code snippets are required for clarity.\r\n\r\nKeras version - 2.2.4\r\ntensorflow version: 1.5.0\r\n\r\nRegards"]}, {"number": 9256, "title": "tf.contrib.learn example couldn't run correctly in tensforflow official website", "body": "Hi, \r\nI'm testing the tf.contrib.learn example in the \r\nhttps://www.tensorflow.org/get_started/tflearn\r\nBut when I executing the statement:\r\nclassifier.fit(input_fn=get_train_inputs, steps=2000)\r\nI get the following error logs:\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 960M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.176\r\npciBusID 0000:01:00.0\r\nTotal memory: 3.95GiB\r\nFree memory: 3.24GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 3.95G (4240965632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 3.55G (3816868864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 984, in _train_model\r\n    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 462, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 786, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 891, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\n\r\nCaused by op u'dnn/hiddenlayer_0/MatMul', defined at:\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 934, in _train_model\r\n    model_fn_ops = self._call_legacy_get_train_ops(features, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1003, in _call_legacy_get_train_ops\r\n    train_ops = self._get_train_ops(features, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1162, in _get_train_ops\r\n    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1133, in _call_model_fn\r\n    model_fn_results = self._model_fn(features, labels, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 143, in _dnn_model_fn\r\n    scope=scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1409, in fully_connected\r\n    outputs = layer.apply(inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 303, in apply\r\n    return self.__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 273, in __call__\r\n    outputs = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/core.py\", line 145, in call\r\n    outputs = standard_ops.matmul(inputs, self.kernel)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1855, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\r\n    transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\n\r\n>>> \r\n>>> # Define the test inputs\r\n... def get_test_inputs():\r\n...     x = tf.constant(test_set.data)\r\n...     y = tf.constant(test_set.target)\r\n...     return x, y\r\n... \r\n>>> classifier.fit(input_fn=get_train_inputs, steps=2000)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)\r\nINFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:loss = 1.21915, step = 1\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:472] failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_EXECUTION_FAILED\r\nW tensorflow/core/framework/op_kernel.cc:993] Internal: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\nW tensorflow/core/framework/op_kernel.cc:993] Internal: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 984, in _train_model\r\n    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 462, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 786, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 891, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\n\t [[Node: train_op/dnn/train/update/_198 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_175_train_op/dnn/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'dnn/hiddenlayer_0/MatMul', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 934, in _train_model\r\n    model_fn_ops = self._call_legacy_get_train_ops(features, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1003, in _call_legacy_get_train_ops\r\n    train_ops = self._get_train_ops(features, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1162, in _get_train_ops\r\n    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1133, in _call_model_fn\r\n    model_fn_results = self._model_fn(features, labels, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 143, in _dnn_model_fn\r\n    scope=scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1409, in fully_connected\r\n    outputs = layer.apply(inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 303, in apply\r\n    return self.__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 273, in __call__\r\n    outputs = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/core.py\", line 145, in call\r\n    outputs = standard_ops.matmul(inputs, self.kernel)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1855, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\r\n    transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4\r\n\t [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]\r\n\t [[Node: train_op/dnn/train/update/_198 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_175_train_op/dnn/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n\r\nIt seems some APIs are obsolete, can you update some new tf.contrib.learn examples in the website and make it workable with the latest version tensorflow?\r\nAnd where can I get the new examples for tf.contrib.learn? \r\n\r\nThanks!", "comments": ["I've checked the guide,\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier\r\nI got the following description\r\n.............\r\nProperties\r\nbias_\r\nDEPRECATED FUNCTION\r\nTHIS FUNCTION IS DEPRECATED. It will be removed after 2016-10-30. Instructions for updating: This method will be removed after the deprecation date. To inspect variables, use get_variable_names() and get_variable_value().\r\n.......................\r\nI'm confused with the description since the \"bias_\" should be a property, instead of a function, so why it said \"THIS FUNCTION IS DEPRECATED\"? Does it mean the whole DNNClassifier class \"DEPRECATED\"? If YES, then this is the root cause of this issue, we are using an obsolete class in tensflow. If NOT, then this description is another problem in tensorflow website, it's better to say \"DEPRECATED PROPERTY, This property will be removed after deprecation date.......\"\r\n\r\nThe same description also happens on the property: weights_\r\n\r\nThanks!", "After I upgrade my tensorflow to latest version by:\r\nsudo pip install --upgrade tensorflow-gpu\r\nThe tf.contrib.learn example could run on my machine. Then we could close this issue."]}, {"number": 9255, "title": "stack_bidirectional_dynamic_rnn input incorrect documentation", "body": "Hi, this is really a documentation problem rather than problem with the actual code.\r\nThe [doc](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/stack_bidirectional_dynamic_rnn) states that inputs should be of shape number of numSequences x batchSize x inputSize, but in reality it's batchSize x numSequences x inputSize.", "comments": ["@ebrevdo is that right?", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 9254, "title": "Reading each filter response from a 4-D Tensor", "body": "```\r\n`class MyLayer(Layer):\r\n    def __init__(self, output_dim, **kwargs):\r\n        self.output_dim = output_dim\r\n        super(MyLayer, self).__init__(**kwargs)\r\n\r\n def build(self, input_shape):\r\n        # Create a trainable weight variable for this layer.\r\n        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),\r\n                                      initializer='uniform',\r\n                                      trainable=True)\r\n        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\r\n\r\n    def call(self, x):\r\n        s = x.get_shape()\r\n        r = K.eval(x)\r\n        print(r)\r\n       # Convert to 64 (25 * 25) tensors.\r\n       # Need to flatten each of these 64 tensors.\r\n       # write some functions on these 64 tensors.\r\n       return <tensor [?,64]>`\r\n```\r\n\r\nx is of shape [?,25,25,64]\r\n\r\nI need 64 tensors of [?,25,25]\r\n\r\nWill `keras.layers.Flatten()` work in the second step.\r\n\r\nCan a Tensor be converted to an numpy array?\r\n\r\nPlease help me on this.\r\n\r\nNote: I am using Functional APIs for Keras.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9253, "title": "no tensorflow/cc/ops/array_ops.h found", "body": "in file tensorflow/cc/ops/standard_ops.h\r\ninclude tensorflow/cc/ops/array_ops.h\r\nbut it seem that array_ops.h disappeared\r\nI found array_ops.cc at ./core/ops/array_ops.cc\r\ndoes it a bug?\r\n\r\nI use youcompleteme to complete my c++ code, found this problem.", "comments": ["`array_ops.h` is a generated file which you will find in `bazel-genfiles/tensorflow/cc/ops/array_ops.h` when building bazel targets that depend on it."]}, {"number": 9252, "title": "fix package description", "body": "fix package description", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 9251, "title": "why there are not file \"decoder_fn.py\"", "body": "why there are not file \"decoder_fn.py\",which mention in the tensorflow website(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference).\r\n", "comments": ["Apologies, the website generator is incorrectly linking to the master branch when in this case it should be linking to the latest release: https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/seq2seq/python/ops/decoder_fn.py\r\n\r\n@wolffg is in the process of fixing the website generator so that it links to code in the appropriate release branch."]}, {"number": 9250, "title": "undefined reference", "body": "Please go to Stack Overflow for help and support: http://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 9249, "title": "Why are there not dbn and rbm in tensorflow model zoo?", "body": "Can anyone add them to tensorflow to make it better?", "comments": ["@jmchen-g @nealwu for model zoo. Model zoos tend to be applied examples, for instance image recognition network training on a corpus such as MNIST, rather than a network building block, like an RNN cell.\r\n\r\nRBMs can be implemented in contrib. Effectively we have DBNs if you care to stack layers.", "If there are models you would like to see in https://github.com/tensorflow/models, feel free to submit a pull request for them."]}, {"number": 9248, "title": "Old python version", "body": "I have python 3.6.0 but tensorflow only supports 3.5", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case.   We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!\r\n\r\n(Closing this issue out due to lack of information and I suspect that this is a duplicate of #6999. If that is not the case, please feel free to file a new issue with all requested details)"]}, {"number": 9247, "title": "Exceptions for nest._recursive_assert_same_structure", "body": "I see [`nest._recursive_assert_same_structure`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/nest.py#L102) is used as a validator that makes sure that two nested sequences have same structure. However, due to its direct use of `zip(nest1, nest2)`, it doesn't make any error in this simple case.\r\n`_recursive_assert_same_structure([[1,2,3], [2,3,[4]]], [[1,2,3,3,4,5]], False)`\r\n\r\nIt can give ValueError when the second argument is changed as  below.\r\n`_recursive_assert_same_structure([[1,2,3], [2,3,[4]]], [1,2,3,3,4,5], False)`\r\n=> ValueError: The two structures don't have the same nested structure. First structure: [1, 2, 3], second structure: 1.", "comments": ["I'm now bit confused.\r\nIs it intended not to raise ValueError for this case (same type with different length)?\r\n`_recursive_assert_same_structure([1,2,3], [1,2,3,4], False)` doesn't give error.", "I found I was using the wrong API. I should've used `assert_same_structure instead`.\r\nClosing this issue."]}, {"number": 9246, "title": "Issue with OpenCL Supported Bazel Compilation of Tensorflow 1.1 (From Source) on UBUNTU 14.04.3", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: UBUNTU 14.04.3-->Trusty\r\n- **TensorFlow installed from (source or binary)**:Source\r\n- **TensorFlow version (use command below)**:1.1.0 (Used git to clone repo)\r\n- **Bazel version (if compiling from source)**:0.4.5\r\n- **CUDA/cuDNN version**:NA\r\n- **OPENCL Version**:\r\n\t\t\t  Platform Version:\t\t\t\t OpenCL 2.0 AMD-APP (1800.11)\r\n\t\t\t  Platform Name:\t\t\t\t AMD Accelerated Parallel Processing\r\n\t\t\t  Platform Vendor:\t\t\t\t Advanced Micro Devices, Inc.\r\n\t\t\t  Platform Extensions:\t\t\t\t cl_khr_icd cl_amd_event_callback cl_amd_offline_devices \r\n- **GPU model and memory**:\r\n\t\t\t  Platform Name:\t\t\t\t AMD Accelerated Parallel Processing\r\n\t\t\tNumber of devices:\t\t\t\t 2\r\n\t\t\t  Device Type:\t\t\t\t\t CL_DEVICE_TYPE_GPU\r\n\t\t\t  Board name:\t\t\t\t\t AMD Radeon (TM) R5 M335\r\n                          Memory: 4096 MB \r\n\r\n- **Exact command to reproduce**:\r\n\t\tbazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package\r\n\r\n- ** G++/GCC version**:\r\n\tg++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n\r\nI have compiled CPP programs, they work fine.\r\n\r\n-- ** Python**: I am using Anaconda distribution Python for 2.7.2. (Anaconda - 2.4.3)\r\n### Describe the problem\r\n\r\nI am trying to compile Tensorflow with OPENCL support (experimental) on UBUNTU 14.04.3. I have an AMD GPU. I have followed the instructions from this site: https://github.com/benoitsteiner/tensorflow-opencl/blob/master/tensorflow/g3doc/get_started/os_setup.md#installing-from-sources\r\nEverything works ok till the bazel compile step. When I try to compile with the following command: bazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package\r\nI get the following error:\r\n#################################################\r\n..............................\r\nWARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/sayantan/tensorflow/tensorflow/core/BUILD:1292:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: computecpp failed: error executing command external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG -g0 '-std=c++11' -MD -MF ... (remaining 27 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n/usr/share/bash-completion/completions/g++: 41: /usr/share/bash-completion/completions/g++: Syntax error: \"(\" unexpected (expecting \"fi\")\r\nTraceback (most recent call last):\r\n  File \"external/local_config_sycl/crosstool/computecpp\", line 88, in <module>\r\n    sys.exit(main())\r\n  File \"external/local_config_sycl/crosstool/computecpp\", line 59, in main\r\n    return subprocess.call([CPU_CXX_COMPILER] + compiler_flags)\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 168, in call\r\n    return Popen(*popenargs, **kwargs).wait()\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 390, in __init__\r\n    errread, errwrite)\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 1024, in _execute_child\r\n    raise child_exception\r\nOSError: [Errno 8] Exec format error\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 146.513s, Critical Path: 3.91s\r\n#################################################\r\n\r\nWhen I execute with more verbosity, I get teh following error:(bazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package --verbose_failures)\r\n#################################################\r\nWARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/sayantan/.cache/bazel/_bazel_sayantan/6f05f78a1e215999d72e42c1e87a8c1d/external/protobuf/BUILD:241:1: C++ compilation of rule '@protobuf//:js_embed' failed: computecpp failed: error executing command \r\n  (cd /home/sayantan/.cache/bazel/_bazel_sayantan/6f05f78a1e215999d72e42c1e87a8c1d/execroot/tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/lib32:/usr/local/computecpp/lib \\\r\n    PATH=/home/sayantan/bin:/home/sayantan/anaconda2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/sayantan/bin \\\r\n  external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG -g0 '-std=c++11' -MD -MF bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.d '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/protobuf/src/google/protobuf/compiler/js/embed.cc -o bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n/usr/share/bash-completion/completions/g++: 41: /usr/share/bash-completion/completions/g++: Syntax error: \"(\" unexpected (expecting \"fi\")\r\nTraceback (most recent call last):\r\n  File \"external/local_config_sycl/crosstool/computecpp\", line 88, in <module>\r\n    sys.exit(main())\r\n  File \"external/local_config_sycl/crosstool/computecpp\", line 59, in main\r\n    return subprocess.call([CPU_CXX_COMPILER] + compiler_flags)\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 168, in call\r\n    return Popen(*popenargs, **kwargs).wait()\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 390, in __init__\r\n    errread, errwrite)\r\n  File \"/home/sayantan/anaconda2/lib/python2.7/subprocess.py\", line 1024, in _execute_child\r\n    raise child_exception\r\nOSError: [Errno 8] Exec format error\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 10.148s, Critical Path: 8.76s\r\n\r\n################################################\r\n\r\nPlease let me know if there are any fixes or if I can do something to get round this issue.\r\nThanks and regards\r\nSayantan", "comments": ["Solved issue by upgrading g++ to 4.9"]}, {"number": 9245, "title": "AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'rnn_decoder'", "body": "### System information\r\n- **OS and Env**: Windows 7, Python 3.5.1\r\n- **TensorFlow installed from**: binary, pip install tensorflow\r\n- **TensorFlow version**: 1.0.1\r\n\r\n\r\n### Describe the problem\r\nAfter upgrading from TF 0.9 to TF 1.0.1, am unable to find `seq2seq.rnn_decoder()`. Updated the `imports` to include seq2seq module (TF 0.9: `tensorflow.python.ops`, TF 1.0: `tensorflow.contrib`). \r\n\r\nOn exploring the new API, I noticed a _similar_ function: `dynamic_rnn_decoder`. Unfortunately, `dynamic_rnn_decoder` has different signature than `rnn_decoder`, and a simple function name change fails.\r\n\r\n**The Ask**\r\nWhat's the equivalent of `seq2seq.rnn_decoder()` in TF 1.0+?\r\n\r\n### Source code (TF 0.9)\r\n`seq2seq.rnn_decoder(inputs_split,              self.initial_state,\r\n                                                                  self.cell,\r\n                                                                  loop_function=loop if test else None,\r\n                                                                  scope='lstm_vars')`\r\n", "comments": ["0.9 to 1.0.1 is a big jump. A lot changed. https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md The good news is now that we're past 1.0, the core Python API is guaranteed to be stable forevermore. Also please note that most of contrib hasn't been made available on Windows yet.", "Tensorflow 0.9 to 1.0.1 is a big jump. A lot changed.\r\nDetails: https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md\r\n\r\nIn tf 1.0.0, the API has been changed such as:\r\n\r\ntf.nn.seq2seq.sequence_loss_by_example(\r\nto\r\ntf.contrib.legacy_seq2seq.sequence_loss_by_example(\r\n\r\ntf.nn.rnn_cell.\r\nto\r\ntf.contrib.rnn.\r\n\r\ntf.nn.rnn_cell.MultiRNNCell(\r\nto\r\ntf.contrib.rnn.MultiRNNCell(\r\n\r\n..."]}]