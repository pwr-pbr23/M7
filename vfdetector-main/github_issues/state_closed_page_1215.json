[{"number": 16716, "title": "Linker Tools Error encountered when use StepStats", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10.0.16299\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.5 release\r\n- **Python version**: \r\n3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n\r\n\r\n\r\n### Describe the problem\r\n\r\nEncounter link error when build the program (source code attached). Build went through well with TF 1.4 release \r\n\r\nError\tLNK2001\tunresolved external symbol \"class tensorflow::StepStatsDefaultTypeInternal tensorflow::_StepStats_default_instance_\" (?_StepStats_default_instance_@tensorflow@@3VStepStatsDefaultTypeInternal@1@A)\tReprBug\tc:\\Users\\xx\\documents\\visual studio 2015\\Projects\\ReprBug\\ReprBug\\Source.obj\r\n\r\n\r\n### Source code / logs\r\n\r\n```cpp \r\n#include \"tensorflow/cc/saved_model/tag_constants.h\"\r\n#include \"tensorflow/core/public/session_options.h\"\r\n#include \"tensorflow/core/util/stat_summarizer.h\"\r\n#include \"tensorflow/contrib/session_bundle/bundle_shim.h\"\r\n\r\nclass SynchronizedStatSummarizer\r\n{\r\npublic:\r\n\tSynchronizedStatSummarizer(const tensorflow::StatSummarizerOptions& options)\r\n\t\t: m_statSummarizer{ options }, m_mutex{}\r\n\t{\r\n\t}\r\n\r\n\tvoid AddStepStats(const tensorflow::StepStats& stepStats)\r\n\t{\r\n\t\tstd::lock_guard<std::mutex> guard{ m_mutex };\r\n\t\tm_statSummarizer.ProcessStepStats(stepStats);\r\n\t}\r\n\r\nprivate:\r\n\t// The TF stat summarizer.\r\n\ttensorflow::StatSummarizer m_statSummarizer;\r\n\r\n\t// Synchronizes access to m_statSummarizer.\r\n\tmutable std::mutex m_mutex;\r\n};\r\n\r\nint main() {\r\n\r\n\ttensorflow::SessionOptions sessionOptions;\r\n\ttensorflow::RunOptions runOptions{};\r\n\ttensorflow::ConfigProto& config = sessionOptions.config;\r\n\t\r\n\tstd::unique_ptr<tensorflow::SavedModelBundle> m_bundle (new tensorflow::SavedModelBundle());\r\n\r\n\tconst std::string path = \"somepath\";\r\n\ttensorflow::Status status = tensorflow::serving::LoadSessionBundleOrSavedModelBundle(\r\n\t\tsessionOptions, runOptions, path, { tensorflow::kSavedModelTagServe }, m_bundle.get());\r\n\r\n\tstd::vector<std::pair<std::string, tensorflow::Tensor>> modifiedInputs;\r\n\tstd::vector<std::string> modifiedOutputNames;\r\n\tstd::vector<tensorflow::Tensor> tensorOutputs;\r\n\ttensorflow::RunMetadata runMetadata{};\r\n\r\n\ttensorflow::Status run_status = m_bundle->session->Run(\r\n\t\trunOptions, modifiedInputs, modifiedOutputNames, {}, &tensorOutputs, &runMetadata);\r\n\r\n\tstd::unique_ptr<SynchronizedStatSummarizer> m_runTracingStats;\r\n\r\n\tif (run_status.ok())\r\n\t{\r\n\t\tm_runTracingStats->AddStepStats(runMetadata.step_stats());\r\n\t}\r\n\r\n}\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 16715, "title": "Branch 184352399", "body": "", "comments": []}, {"number": 16714, "title": "Propagate the name on resource variable assign", "body": "", "comments": []}, {"number": 16713, "title": "Add k8 to detection for when to use neon_tensor_utils.", "body": "", "comments": []}, {"number": 16712, "title": "Fix spelling: change \"invaild\" to \"invalid\"", "body": "", "comments": []}, {"number": 16711, "title": "Fixed a typo in `group_by_window` documentation", "body": "Nothing else to add :)", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 16710, "title": "Removing the typo line.", "body": "", "comments": []}, {"number": 16709, "title": "Revert \"Update external protobuf codebase version for Windows cmake b\u2026", "body": "\u2026uild\"\r\n\r\nThis reverts commit 07bec47ba5db4c2f2e33ecb49f23253a371bfbbe.", "comments": []}, {"number": 16708, "title": "Fix sanity", "body": "", "comments": []}, {"number": 16707, "title": "Can't initialize an all zero SparseTensor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Kind of?\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac 10.12.6 (not relevant)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.5.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nIt doesn't seem possible to initialize a `tf.SparseTensor` with all zero entries. \r\n\r\nA call doing this would look something like:\r\n\r\n    tf.SparseTensor(indices=[], values=[], dense_shape=(10, 10))\r\n\r\nHowever, attempting this initialization produces the error:\r\n\r\n     ValueError: Shape (0,) must have rank 2\r\n\r\n\r\n### Source code / logs\r\nCurrent relevant section from `SparseTensor.__init__`:\r\n\r\n    indices_shape = indices.get_shape().with_rank(2) # <--- .with_rank(2) is what causes the problem\r\n    values_shape = values.get_shape().with_rank(1)\r\n    dense_shape_shape = dense_shape.get_shape().with_rank(1)\r\n\r\n    # Assert number of rows in indices match the number of elements in values.\r\n    indices_shape[0].merge_with(values_shape[0])\r\n    # Assert number of columns in indices matches the number of elements in\r\n    # dense_shape.\r\n    indices_shape[1].merge_with(dense_shape_shape[0])\r\n\r\nExample solution:\r\n\r\n    tf.cond(tf.equal(indices.get_shape()[0], 0),\r\n            true_fn=lambda: None,\r\n            false_fn=self._validate_input)\r\n\r\n    def _validate_input(self):\r\n        indices_shape = self._indices.get_shape().with_rank(2)\r\n        values_shape = self._values.get_shape().with_rank(1)\r\n        dense_shape_shape = self._dense_shape.get_shape().with_rank(1)\r\n\r\n        # Assert number of rows in indices match the number of elements in values.\r\n        indices_shape[0].merge_with(values_shape[0])\r\n        # Assert number of columns in indices matches the number of elements in\r\n        # dense_shape.\r\n        indices_shape[1].merge_with(dense_shape_shape[0])\r\n\r\nMy only worry with the example solution is that `tf.cond` is too high level a function and there's some alternative that would be better. Is that the case? ", "comments": ["/CC @ebrevdo", "indices must be a zero-row matrix:\r\n\r\n```python\r\ntf.SparseTensor(indices=np.empty((0, 2), dtype=np.int64), values=[], dense_shape=(10, 10))\r\n```", "(you can also use `tf.zeros((0,2), tf.int64)`)"]}, {"number": 16706, "title": "Absl fix", "body": "", "comments": []}, {"number": 16705, "title": "Update Eigen library to 2355b229ea4c and fixes conv2d padding issue", "body": "This fix updates Eigen to 2355b229ea4c, so that the issue raised in #14601 could be fixed.\r\n\r\nThis fix fixes #14601.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["My tensorflow was installed with Anaconda, not from source, then how can i change my tensorflow to fix this bug? Thanks! @yongtang @gunan ", "@Zealoe If you update to the latest version of tensorflow in your system I think the issue will be resolved."]}, {"number": 16704, "title": "Remove all_files rule from com_google_absl.BUILD", "body": "", "comments": []}, {"number": 16703, "title": "tf.contrib.rnn.GLSTMCell is hilariously broken", "body": "In 3f579020bab8f00e4621e9c7c740cbf13136a809 an \"if\" was added that caches linear transformation weights:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L2316\r\n\r\nThe problem is that this _linear is inside a loop. And so the change tied weights of all these linear transformations.\r\n\r\nCC @okuchaiev \r\n", "comments": ["/CC @panyx0718, can you take a look?", "Right. this is a bug introduced during a refactoring. Perhaps we should cache one Linear for each group_id.", "/CC @asimshankar, can you fix this?", "Doh! Thanks for pointing this out @akhti - will send out a fix.\r\n(Though, not sure if this will result in an update to the 1.5 release since APIs in `tf.contrib` are experimental and bugs there aren't treated with the same urgency as the stable APIs).", "No worries - the bug was here since October and nobody noticed :)\r\nThough it's a very nasty bug - nothing fails, but model quality is suboptimal. Is it possible to add some simple test, like for a number of parameters to avoid this in the future?", "Please have a look at this PR https://github.com/tensorflow/tensorflow/pull/16788 "]}, {"number": 16702, "title": "Fixing the cuda and cudnn versions in 1.5 docs.", "body": "", "comments": ["We should also make sure to CP this into master and 1.6"]}, {"number": 16701, "title": "Update version to 1.6.0-rc0.", "body": "", "comments": []}, {"number": 16700, "title": "Revert \"Updating the version to 1.6.0-rc0.\"", "body": "Accidentally pushed this to master.", "comments": []}, {"number": 16699, "title": "Branch 184236409", "body": "", "comments": []}, {"number": 16698, "title": "We must also trim everything after TAB, in order to correctly parse version from TensorRT-3.0.2", "body": "Note TABS after version numbers:\r\n\r\n```\r\ndmikushin@tesla-cmc:/opt/TensorRT-3.0.2/include$ cat NvInfer.h | grep SONAME\r\n#define NV_TENSORRT_SONAME_MAJOR 4\t\t//!< shared object library major version number\r\n#define NV_TENSORRT_SONAME_MINOR 0\t\t//!< shared object library minor version number\r\n#define NV_TENSORRT_SONAME_PATCH 2\t\t//!< shared object library patch version number\r\n```\r\n\r\nI'm not a Python expert, please feel free to rework this in a better way.\r\n\r\nThis pull requests fixes the following build error:\r\n\r\n```\r\nCuda Configuration Error: TensorRT library version detected from /opt/TensorRT-3.0.2/include/NvInfer.h (4\t\t//!<.0\t\t//!<.2\t//!<) does not match TF_TENSORRT_VERSION (4.0.2). To fix this rerun configure again.\r\nWARNING: Target pattern parsing failed.\r\n```", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks @dmikushin for the fix. I think there is also a fix in [PR #16253](https://github.com/tensorflow/tensorflow/pull/16253/files#diff-27368da6eb4c2514a27a4d9733bc9b57), does it fix your problem?", "@aaroey Yes, that patch works for me, `strip()` does the job:\r\n\r\n`version = version.replace(define, \"\").strip()`", "@dmikushin Thanks. Since we're going to merge that PR shortly, I'm closing this PR."]}, {"number": 16697, "title": "gcc: error: unrecognized command line option '--config=opt'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: \r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: release 0.9.0- (@non-git) \r\n- **GCC/Compiler version (if compiling from source)**: Using built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/local/stow/gcc-4.9.2/libexec/gcc/x86_64-unknown-linux-gnu/4.9.2/lto-wrapper\r\nTarget: x86_64-unknown-linux-gnu\r\nConfigured with: /usr/src/nfs/gcc-4.9.2/configure --prefix=/usr/local/stow/gcc-4.9.2\r\nThread model: posix\r\ngcc version 4.9.2 (GCC)\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: x86_64 GNU/Linux\r\n- **Exact command to reproduce**:  bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\ngcc: error: unrecognized command line option '--config=opt'\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n'''\r\nERROR: /usa/haoxu/.cache/bazel/_bazel_haoxu/95196ed5087168c723729aeb7fc160d9/external/flatbuffers/BUILD:22:1: C++ compilation of rule '@flatb\r\nuffers//:flatbuffers' failed (Exit 1)\r\ngcc: error: unrecognized command line option '--config=opt'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 57.329s, Critical Path: 13.22s\r\nFAILED: Build did NOT complete successfully\r\n'''", "comments": ["Finally installed the tensorflow:\r\n#1970\r\n#15129\r\n#13413\r\n#7268\r\n#121\r\nhttps://docs.bazel.build/versions/master/output_directories.html\r\nhttps://www.jianshu.com/p/908c88260b08\r\n```\r\nbazel build  --linkopt='-lrt' -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```"]}, {"number": 16696, "title": "Add stream selection support for `tf.contrib.ffmpeg.decode_video`", "body": "This fix is a follow up to #16101. In #16101, stream selection support has been added for `tf.contrib.ffmpeg.decode_audio`.\r\nHowever, it was still not possible to selectively decode a perticular stream with `tf.contrib.ffmpeg.decode_vidio`.\r\n\r\nThis fix adds an additional attribute `stream` which could be used to specify the stream of the video to decode. By default `stream=''` which leaves the decision to ffmpeg.\r\n\r\nThis fix is related to comment https://github.com/tensorflow/tensorflow/pull/16101#issuecomment-357448137\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Nagging Reviewer @fredbertsch: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 304 days with no activity and the `awaiting review` label has been applied.", "@yongtang Thanks for your contribution and apologies for the delay in reverting. Can you please sync with latest TensorFlow:Master? @fredbertsch Can you please take a look? Thanks!\r\n", "As ffmpeg is being removed from contrib soon, I think we could close this PR."]}, {"number": 16695, "title": "Padding algo is not working as doc says", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linus centos 7\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**: 0\r\n- **GCC/Compiler version (if compiling from source)**:0\r\n- **CUDA/cuDNN version**:0\r\n- **GPU model and memory**:0\r\n- **Exact command to reproduce**:\r\n\r\nIn the following situation, TF [doc](https://www.tensorflow.org/api_guides/python/nn#Convolution) is not correct.\r\n- Input tensor shape : [1, 5, 2, 1]\r\n- Kernel shape:           [1, 3, 1, 1]\r\n- Stride :                      [1, 5, 5, 1]\r\n- Padding =                  \"SAME\"\r\n\r\nAccording to the formula we can compute : \r\nout_h = 1\r\nout_w = 1\r\n\r\n```\r\nif (in_height % strides[1] == 0):\r\n  pad_along_height = max(filter_height - strides[1], 0)\r\nelse:\r\n  pad_along_height = max(filter_height - (in_height % strides[1]), 0)\r\nif (in_width % strides[2] == 0):\r\n  pad_along_width = max(filter_width - strides[2], 0)\r\nelse:\r\n  pad_along_width = max(filter_width - (in_width % strides[2]), 0)\r\n```\r\ngives :\r\npad_along_height = 0\r\npad_along_width = 1\r\n\r\nthen \r\n```\r\npad_top = pad_along_height // 2\r\npad_bottom = pad_along_height - pad_top\r\npad_left = pad_along_width // 2\r\npad_right = pad_along_width - pad_left\r\n```\r\n\r\ngives:\r\n\r\npad_top = 0\r\npad_bottom = 0\r\npad_left = 0\r\npad_right = 1\r\n\r\nHow tensorflow do a convolution with a kernel of height 1 on a image of height 5 and which gives output of height 1 (stride = 5) ??? How TF do this ? The doc can't explain the method used ... \r\n\r\nDoing retro engineering, I saw that TF apply the filter on the middle of the input tensor (pad_top = -2 and pad_bottom=-2).\r\nI agree with this method, but the formulas of the Convolution doc is doing max(.., 0) so padding could never be negative (according to the doc).\r\n\r\nCould someone explain me clearly what is the formula used in tensorflow ?\r\nCould someone update the doc ?", "comments": ["Closing since this looks like a duplicate of #14601."]}, {"number": 16694, "title": "Tensorflow 1.5.0 doesn't compile from source, linking issue with tf.contrib.lite.toco", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nN/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.5.0\r\n- **Python version**:\r\n3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n0.9.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc 5.4.0 20160609\r\n- **CUDA/cuDNN version**:\r\nTried 9.0 and 9.1 with cuDNN 7.0.5\r\n- **GPU model and memory**:\r\nGeForce GTX 1080Ti\r\n- **Exact command to reproduce**:\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\ngit checkout v1.5.0\r\n./configure  # selected yes for CUDA, no for other optional things\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n### Describe the problem\r\nAs described in #14573, this is the error I get from Bazel. It is quite long, but it starts with:\r\n```\r\nERROR: ~/tensorflow/tensorflow/contrib/lite/toco/BUILD:326:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1)\r\n/usr/bin/ld: warning: libcublas.so.9.1, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcudnn.so.7, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcufft.so.9.1, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcurand.so.9.1, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyr2k_v2@libcublas.so.9.1'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgerc_v2@libcublas.so.9.1'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemv_v2@libcublas.so.9.1'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemm_v2@libcublas.so.9.1'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftCreate@libcufft.so.9.1'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate@libcudnn.so.7'\r\nbazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor@libcudnn.so.7'\r\n(and so on for other symbols)\r\n```\r\n\r\nAs suggested in #14573, adding the following option to Bazel fixes the issue:\r\n```\r\n--action_env=LD_LIBRARY_PATH=/path/to/cuda/lib64/stubs:${LD_LIBRARY_PATH}\r\n```\r\n\r\nNote that CUDA is properly installed and all necessary environment variables are set (CUDA_HOME, LD_LIBRARY_PATH). Installing e.g. Tensorflow 1.4.1 (and earlier versions) with exactly the same set up is no problem. Tried with both CUDA 9.0 and CUDA 9.1, both show the same issue.\r\n\r\nCC: @kmhofmann @gunan \r\n", "comments": ["@gunan What should we do to handle this? Wait until 1.6.0?", "I suspect this will still exist in 1.6\r\nMaybe we can update our bazelrc with `--action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}`\r\n\r\n@aselle any idea why we need these libraries when linking toco?", "toco doesn't really need those libraries. libtensorflow_framework.so, which is used by toco, needs them when `--config cuda` is used.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "No updates seen so far from TF developers. Just tried to compile 1.7.0 and the issue is still there!", "bazelrc update was merged long ago.\r\nCould you file a new issue with full details?\r\nIncluding your setup, command to reproduce, and the exact error message?", "Sorry, that was a mistake on my side. It works, I'll close this issue, it is indeed no longer necessary in 1.7.0.", "tensorflow  version 1.5 does not contain lite error during keras model to tensorflowlite model conversion"]}, {"number": 16693, "title": "Separate constant file for tpu to make reusable", "body": "Using constants is more a way of defensive programming, also it improves performance optimization. Most importantly, it is for human reader.\r\n\r\nSince I have made a nice cleanup to make a separate constant file for making global variable reusable for tpu that can be use anywhere.", "comments": ["@drpngx  @caisq ", "@jhseu ", "Thanks for the contribution! We chatted about this change internally, and we prefer the existing style."]}, {"number": 16692, "title": "Bug: using pandas_input_fn with tensorflow.contrib.tensor_forest.client.random_forest.TensorForestEstimator", "body": "### System information\r\n- **Have I written custom code:  YES\r\n- **OS Platform and Distribution : Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from : pip\r\n- **TensorFlow version (use command below): 1.4.1\r\n- **Python version: 2.7.12 \r\n\r\n### Describe the problem\r\n\r\n\r\n### Source code / logs\r\n\r\nI am working on a simple Tensorflow programme, and build input pipeline with pandas.My code is below:\r\n\r\n```\r\ndef train_rf(X,Y):\r\n  print(X.shape) #output is  (53443, 131)\r\n  print(Y.shape) #output is  (53443,)\r\n\r\n  #features is the list of names of features\r\n  params = tensor_forest.ForestHParams(\r\n      num_classes=2,\r\n      num_features=len(features),\r\n      num_trees=config['rf']['num_trees'])\r\n\r\n  est = random_forest.TensorForestEstimator(params, model_dir=config['rf']['model_dir'])\r\n\r\n  train_input_fn = tf.estimator.inputs.pandas_input_fn(\r\n      X,\r\n      y=Y,\r\n      batch_size=config['rf']['train_batch_size'],\r\n      num_epochs=1,\r\n      shuffle=True)\r\n\r\n  est.fit(input_fn=train_input_fn, steps=100)\r\n```\r\n\r\nHowever, when I run this function, I got error like this:\r\n```\r\n    Traceback (most recent call last):\r\n      File \"random_forest.py\", line 118, in <module>\r\n        train_rf(train_ohd[features].iloc[X_1],l(y_1),train_ohd[features].iloc[X_2])\r\n      File \"random_forest.py\", line 44, in train_rf\r\n        est.fit(input_fn=train_input_fn, steps=100)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 316, in new_func\r\n        return func(*args, **kwargs)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 480, in fit\r\n        loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 986, in _train_model\r\n        model_fn_ops = self._get_train_ops(features, labels)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1202, in _get_train_ops\r\n        return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1166, in _call_model_fn\r\n        model_fn_results = self._model_fn(features, labels, **kwargs)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/client/random_forest.py\", line 171, in _model_fn\r\n        features)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py\", line 489, in inference_graph\r\n        data_ops.ParseDataTensorOrDict(input_data))\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/ops/data_ops.py\", line 159, in ParseDataTensorOrDict\r\n        processed_dense_features = array_ops.concat(dense_features, 1)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\r\n        return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\r\n        \"ConcatV2\", values=values, axis=axis, name=name)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2958, in create_op\r\n        set_shapes_for_outputs(ret)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2209, in set_shapes_for_outputs\r\n        shapes = shape_func(op)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2159, in call_with_requiring\r\n        return call_cpp_shape_fn(op, require_shape_fn=True)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 627, in call_cpp_shape_fn\r\n        require_shape_fn)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 691, in _call_cpp_shape_fn_impl\r\n        raise ValueError(err.message)\r\n    ValueError: Shape must be at least rank 2 but is rank 1 for 'concat' (op: 'ConcatV2') with input shapes: [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [] and with computed input tensors: input[131] = <1>.\r\n```\r\n\r\nThe output of `print(X.shape)` and `print(Y.shape)` is `(53443, 131)`, `(53443,)` respectively. So I got confused why there will be 132 dimensions in input and why I got this `ValueError`?\r\n\r\nWhat's more, when I used `tf.contrib.learn.LinearRegressor` to replace `TensorForestEstimator`, I can train and eval model with no error. So there's no problems in my `train_input_fn` and I assume this is a bug of Tensorflow.\r\n", "comments": ["@gilberthendry @thomascolthurst any idea?", "@nataliaponomareva ", "It probably complains because the rank of the label is 1 whereas it expects it to be of rank 2. Can you try \r\nY=numpy.expand_dims(Y, axis=1) before you feed it into input fn", "@nataliaponomareva According to https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn, Y should be pandas Series object. And I guess I call the method in a proper way.\r\n\r\nBesides, if I change the code in your way, I will get the error below:\r\n\r\nTraceback (most recent call last):\r\nFile \"random_forest.py\", line 119, in \r\ntrain_rf(train_ohd[features].iloc[X_1],l(y_1))\r\nFile \"random_forest.py\", line 44, in train_rf\r\nshuffle=True)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/pandas_io.py\", line 85, in pandas_input_fn\r\nif not np.array_equal(x.index, y.index):\r\nAttributeError: 'numpy.ndarray' object has no attribute 'index'\r\n\r\nAnd I change the code like this: Y= pd.Series(np.expand_dims(Y.values, axis=1).tolist())\r\n\r\nStill, I get the error:\r\n\r\nValueError: Shape must be at least rank 2 but is rank 1 for 'concat' (op: 'ConcatV2') with input shapes: [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [?], [] and with computed input tensors: input[131] = <1>.", "And as I said before, there's no error when I use LinearRegressor, so I think the rank of label is fine.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It is actually the features that are of wrong shape. You can wrap the pandas input fn inside of a custom input fn and get the features expanded. Like this\r\n```python\r\ndef train_rf():\r\n  input_dimension = 1\r\n  batch_size = 10\r\n  # I am creating dummy data just to test, remove it.\r\n  x1 = np.array([1., 2., 3., 4.], dtype=np.float32)\r\n  x2 = np.array([4., 8., 3., 4.], dtype=np.float32)\r\n  target = np.array([1, 0, 1, 0], dtype=np.int32)\r\n  X = pd.DataFrame({'x1': x1, 'x2':x2})\r\n  Y = pd.Series(target)\r\n  \r\n  params = tensor_forest.ForestHParams(\r\n      num_classes=2,\r\n      num_features=2,\r\n      num_trees=10)\r\n\r\n  est = random_forest.TensorForestEstimator(params)\r\n\r\n  # The wrapper.  \r\n  def new_input_fn(X, Y, batch_size, num_epochs, shuffle):\r\n    \r\n    def internal_input_fn():\r\n      features, labels =  tf.estimator.inputs.pandas_input_fn(\r\n         X,\r\n         y=Y,\r\n         batch_size=batch_size,\r\n         num_epochs=num_epochs,\r\n         shuffle=shuffle,\r\n      target_column='y')()\r\n      \r\n      for name in features:\r\n        tensor = features[name]\r\n        # Expand dims of features\r\n        tensor = tf.expand_dims(tensor, axis=1)\r\n        features[name] =tensor\r\n      \r\n      return features, labels\r\n  \r\n    return internal_input_fn\r\n  \r\n  new_input_fn = new_input_fn(X,Y, batch_size, 10, True)\r\n\r\n  est.fit(input_fn=new_input_fn, steps=1000)\r\n\r\ntrain_rf()", "I understand that the pandas_input_fn results in feature values of incorrect shape, but why doesn't the built in function account for this automatically? Is there a fix coming out for this function?", "It is better to throw an error so the user can adjust their input fn accordingly, then to silently convert and potentially be wrong about this conversion..."]}, {"number": 16691, "title": "docs error in triplet_semihard_loss()", "body": "Since ||AP|| + alpha < ||AN||, I think the docs in the following\r\n\r\ndef triplet_semihard_loss(labels, embeddings, margin=1.0):\r\n  \"\"\"Computes the triplet loss with semi-hard negative mining.\r\n  The loss encourages the positive distances (between a pair of embeddings with\r\n  the same labels) to be smaller than the minimum negative distance among\r\n  which are at least greater than the positive distance **plus** the margin constant\r\n  (called semi-hard negative) in the mini-batch. If no such negative exists,\r\n  uses the largest negative distance instead.\r\n\r\nshould be\r\n\r\ndef triplet_semihard_loss(labels, embeddings, margin=1.0):\r\n  \"\"\"Computes the triplet loss with semi-hard negative mining.\r\n  The loss encourages the positive distances (between a pair of embeddings with\r\n  the same labels) to be smaller than the minimum negative distance among\r\n  which are at least greater than the positive distance **minus** the margin constant\r\n  (called semi-hard negative) in the mini-batch. If no such negative exists,\r\n  uses the largest negative distance instead.\r\n", "comments": ["since Since ||AP|| + alpha < ||AN||, it should be plus.", "/CC @coreylynch", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I just came back and re-read that again, I think it should be a 'plus', no problem. Don't remember why I thought it should be a 'minus'. Maybe that sentence is too long for a non-English speaker lol", "Is there an alternative for that loss function now that tf contrib is about to be deprecated?"]}, {"number": 16690, "title": "change to anchor link", "body": "Fixing markdown typo", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@andrewharp "]}, {"number": 16688, "title": "how to assign the GPU device using C++?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["You probably want to use `set_requested_device` that is to implement [`tf.device`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/c/python_api.cc#L45).\r\n\r\nThis question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 16687, "title": "[DO NOT MERGE] Testing", "body": "", "comments": []}, {"number": 16686, "title": "Is there still a math_ops.h", "body": "I followed the C++ API tutorial (https://www.tensorflow.org/api_guides/cc/guide). But I can't make it because I don't find \"tensorflow/cc/ops/math_ops.h\" (and many other header files). Then I go to the repo on master branch, didn't find them too. \r\n### System information\r\n- **my code is very simple**\r\n`   using namespace tensorflow; `\r\n  `using namespace tensorflow::ops;`\r\n ` Scope root = Scope::NewRootScope();`\r\n  `// Matrix A = [3 2; -1 0]`\r\n ` auto A = Const(root, { {3.f, 2.f}, {-1.f, 0.f} });`\r\n ` // Vector b = [3 5]`\r\n ` auto b = Const(root, { {3.f, 5.f} });`\r\n ` // v = Ab^T`\r\n`  auto v = MatMul(root) ` \r\n**And the function MatMul can't be recognized.**\r\n\r\n- **OS Platform and Distribution:** Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: source\r\n", "comments": ["it's under bazel-genfiles..."]}]