[{"number": 3558, "title": "Docker build script: Fix logic re TF_BUILD_APPEND_CI_DOCKER_EXTRA_PARAMS", "body": "", "comments": []}, {"number": 3557, "title": "What would be required to submit an implementation of the Hungarian algorithm to tf.contrib", "body": "@Russell91 and I have an interest in contributing an implementation of the Hungarian algorithm, perhaps based off of the implementation he has [here](https://github.com/Russell91/TensorBox/tree/master/utils/hungarian).\n\nWhat do we need to do to make this happen? Is there a document covering this somewhere (besides the one that says we need to sign the CLA). \n", "comments": ["I don't have experience with this but I think submitting a PR to add a new Op under contrib/hungarian would be welcome. @martinwicke is that the right process?\n", "Yes, please submit a PR. \n\nTry to stick to the style as you see it in other parts of the code (for contrib, for instance, stick to the directory structure you see in other contrib directories). For documentation, this is covered specifically in https://www.tensorflow.org/versions/r0.10/how_tos/documentation/index.html, but that's not all.\n\nThe code review we will do should surface other things.\n", "No activity or contributions made to this issue for a long time. Closing due to inactivity. Please reopen if somebody is working on this."]}, {"number": 3556, "title": "R0.10: Update Session documentation.", "body": "Updates core/public/README.md and Session API doc to address issue #3195.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3555, "title": "Branch 128756911", "body": "", "comments": []}, {"number": 3554, "title": "Different outputs using tensorflow.contrib.learn.Estimator.predict()", "body": "I trained a tensorflow model using skflow, but when I tried to predict some new value of my data, things didn't work. This is what is happening.\n\nI have X, the matrix containing the observations.\n\nWhen I run\n\n`y_predicted = classifier.predict(X, batch_size=128)`\n\nI'm interested in the output of indexes 855, 15035, 49536, 856, 857\n\nso\n\n`y_predicted['class'][(855, 15035, 49536, 856, 857), ]`\n\nthe results are exactly what I have expected\n\n`array([0, 0, 0, 3, 3])`\n\nEverything is fine up to here, but if I pass to predict function just the indexes of interest, the results are different. Here is an example:\n\n`y_predicted = classifier.predict(X[(855, 15035, 49536, 856, 857), :], batch_size=128)`\n\nThen, the output is wrong\n\n`y_predicted['class']``\n\ngives\n\n`array([0, 0, 0, 2, 0])`\n\nI tried several ways to do this, and I always get the wrong results.\n\nThank you.\n", "comments": ["This type of usage question is better suited to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow). Please reopen if it turns out this is a TensorFlow bug.\n"]}, {"number": 3553, "title": "Fix typos in print statements in Wide & Deep Tutorial", "body": "", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3552, "title": "Add release note to 0.10.0", "body": "", "comments": []}, {"number": 3551, "title": "Correct tf.Gradient... to tf.train.Gradient...", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thank you @JohnAllen! train.md is auto-generated, could you remove the change from PR?\n", "Happy to contribute!  Train.md removed from the PR.\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3550, "title": "Error during building tensorflow ? ", "body": "Operating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN:  Cuda 8.0 RC , cuDNN 5 for 8.0RC\n\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n`-rw-r--r-- 1 root root   560184 \u099c\u09c1\u09b2    28 20:29 libcudadevrt.a\nlrwxrwxrwx 1 root root       16 \u099c\u09c1\u09b2    28 20:29 libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 \u099c\u09c1\u09b2    28 20:29 libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 \u099c\u09c1\u09b2    28 20:29 libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 \u099c\u09c1\u09b2    28 20:29 libcudart_static.a\n-rwxr-xr-x 1 root root 78065952 \u099c\u09c1\u09b2    28 20:45 libcudnn.so\n-rwxr-xr-x 1 root root 78065952 \u099c\u09c1\u09b2    28 20:45 libcudnn.so.5\n-rwxr-xr-x 1 root root 78065952 \u099c\u09c1\u09b2    28 20:45 libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 68709594 \u099c\u09c1\u09b2    28 20:45 libcudnn_static.a\n`\n\nRan the command with `bazel build -c opt  --verbose_failures --config=cuda //tensorflow/cc:tutorials_example_trainer`\n### What have you tried?\n1. Tried adding /usr/lib/gcc/x86_64-linux-gnu/4.9 to the path. Then it fails `/usr/include/stdlib.h:32:20: fatal error: stddef.h: No such file or directory` .\n\nError Message : \nERROR: /home/tamim/.cache/bazel/_bazel_tamim/2f3c0cf2059f53bbcd160daf720cb6e9/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/tamim/.cache/bazel/_bazel_tamim/2f3c0cf2059f53bbcd160daf720cb6e9/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/home/tamim/bin:/usr/local/cuda/bin:/home/tamim/anaconda3/bin:/home/tamim/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o' -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/highwayhash -isystem bazel-out/host/genfiles/external/highwayhash -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.d -c external/highwayhash/highwayhash/sip_hash.cc -o bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n\nFeature Request: A prebuilt wheel for cuda8 release candidate.\n", "comments": ["Solution of the same problem for me: sudo apt-get install g++-4.8\n", "Yes, looks like it cannot run gcc -- does @pkonovalov-softheme's solution work for you?\n", "Closing this for inactivity. Please comment with new information to reopen.\n", "@martinwicke Same problem, but the posted solution doesn't work for me.\n", "What is the error you get and what system are you on (OS, gcc version, etc.)? \n", "It's been a while, and I'm now using the binary (yay!) for Cuda 8 so it doesn't affect me anymore. Thanks for checking, though.\n", "Upgrading to g++-4.8 solves this.\n", "use g++-4.8 and set the absolute path when setting config,using symbolic link will be  occurred this error"]}, {"number": 3549, "title": "Android: NoOpKernel was registered to support Op 'TensorflowArray' DynamicRNN", "body": "I'm trying to load a graph I trained in python, which includes only using dynamicRNN, and the most basic RNN cell. \n\nWhen I try execute the graph on the Android, I get the following error message:\n\n```\nInvalid argument: No OpKernel was registered to support Op 'TensorArray' with these attrs\n     [[Node: c96ce52cccd5408aad2fb356a8246023/RNN/TensorArray_1 = TensorArray[clear_after_read=true, dtype=DT_FLOAT, dynamic_size=false, tensor_array_name=\"c96ce52cccd5408aad2fb356a8246023/RNN/dynamic_rnn/input\"](c96ce52cccd5408aad2fb356a8246023/RNN/unpack)]]\n```\n### Environment info\n\nOperating System:\nUbuntu x64 14.04\nAndroid 6.0\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   tag v0.9.0\n2. The output of `bazel version`\n   0.3.0\n### Steps to reproduce\n1. Create RNN model in python\n2. Compile it with tensorflow_android_lib targeting armv7\n3. Try run the model on android\n### What have you tried?\n1. \n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["It seems it that the RNN ops are default not included in the `android_extended_ops_group` under /tensorflow/cc/kernel/BUILD.\n\na hack is adding the operations manually but the more correct way seems to use selective_registration.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/selective_registration.h\n\nEDIT: Easy regex to automatically list all operations in your graph, as long as you have it dumped in text format:\n\n`grep \"op: \"  PATH/TO/mygraph.txt  | sort | uniq | sed -E 's/^.+\"(.+)\".?$/\\1/g'`\n", "And on the same note, is there an example of how to use selective_registration, in particular how to differentiate between `SHOULD_REGISTER_OP_KERNEL` `SHOULD_REGISTER_OP` and `SHOULD_REGISTER_OP_GRADIENT`\n", "So long as the op builds and runs correctly, it's fine to add it to the default ops file group (we've just been adding them on an as-needed basis now that we have a way to manage binary size).\n\nYou don't need to use selective registration yourself unless you are prioritizing binary-size -- it will cut the final .so size essentially in half to result in < 1mb compressed for a typical graph.\n\n@cwhipkey do you know if there is a public example of this yet?\n", "Okay, but it would be nice to be able to do selective registration eventually, so I can get the minimal size for my own graph right.\n\nI tried to do it on my own, and replaced the android_cc_library, to depend on `android_all_ops` instead. Like this:\n\n```\ncc_library(\n    name = \"android_tensorflow_kernels\",\n    srcs = select({\n        \"//tensorflow:android\": [\n            \"//tensorflow/core/kernels:android_all_ops\",\n        ],\n        \"//conditions:default\": [],\n    }),\n    copts = tf_copts(),\n    tags = [\n        \"manual\",\n        \"notap\",\n    ],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"//tensorflow/core:android_tensorflow_lib_lite\",\n        \"//tensorflow/core:protos_cc\",\n        \"//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n```\n\nBut then I got the following error during compilation:\n\n```\nexternal/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/StaticAssert.h:32:40: error: static assertion failed: THIS_TYPE_IS_NOT_SUPPORTED\n     #define EIGEN_STATIC_ASSERT(X,MSG) static_assert(X,#MSG);\n                                        ^\nexternal/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/SpecialFunctions.h:976:9: note: in expansion of macro 'EIGEN_STATIC_ASSERT'\n         EIGEN_STATIC_ASSERT((internal::is_same<Scalar, Scalar>::value == false),\n```\n\nThis is my main build file:\n\n```\ncc_binary(\n    name = \"myapp\",\n    srcs = [\n        \"main.cc\",\n        \"ops_to_register.h\"\n    ],\n    copts = [\n        \"-fno-exceptions\",\n        \"-DEIGEN_AVOID_STL_ARRAY\",\n        \"-DSELECTIVE_REGISTRATION\",\n        \"-mfpu=neon\", # This one for ARM only\n        \"-std=c++11\",\n        \"-DMIN_LOG_LEVEL=0\",\n        \"-DTF_LEAN_BINARY\",\n        \"-O2\",\n        \"-fPIE\",\n    ],\n    linkopts = [\n        \"-landroid\",\n        \"-llog\",\n        \"-lm\",\n        \"-z defs\",\n        \"-s\",\n        \"-Wl,--icf=all\",  # Identical Code Folding\n        \"-Wl,--exclude-libs,ALL\",  # Exclude syms in all libs from auto export\n        \"-pie\",\n    ],\n    deps = [\n        \"@org_tensorflow//tensorflow/core:android_tensorflow_lib\",\n    ],\n)\n```\n\nAnd finally my `ops_to_register.h` looks like this:\n\n```\n#ifndef METALANG_OPS_TO_REGISTER\n#define METALANG_OPS_TO_REGISTER\n\n#include \"tensorflow/core/framework/selective_registration.h\"\n\nSHOULD_REGISTER_OP(\"Add\")\nSHOULD_REGISTER_OP(\"AddN\")\nSHOULD_REGISTER_OP(\"All\")\nSHOULD_REGISTER_OP(\"ApplyAdam\")\nSHOULD_REGISTER_OP(\"ArgMax\")\n....\n....\n\n#endif\n```\n\nAny ideas as to why it might be failing to compile with EIGEN?\n", "In my case op 'Div' is already included in tensorflow/contrib/makefiletf_op_files.txt but I getting error [https://github.com/tensorflow/tensorflow/issues/3546](3546). I think it is probably depending on context.\n", "Adding links to #3543 and #3546 in case they all have a related root cause.\n", "Regarding the question: \"@cwhipkey do you know if there is a public example of this yet?\", no there is no public example yet of creating a selective-registration header.\n", "Re: @lingz :  I was able to compile with selective registration, but it didn't help reduce the file size for me.  Instead, I ended up using the makefile from tensorflow/contrib/makefile, removing all the unused ops classes from [tf_op_files.txt.](https://github.com/tensorflow/tensorflow/blob/f71cc62282bf2e066f9ebd08cf3f605fc98c6e41/tensorflow/contrib/makefile/tf_op_files.txt)  \n\nFor what it's worth, this is what I had in my `ops_to_register.h`:\n\n``` C++\nconst bool kRequiresSymbolicGradients = false;\nconst char* kNecessaryOpKernelClasses = \n    \",Add,\"\n    \",Const,\"\n    ...\n    \",Softmax,\";\n\n\nconstexpr bool ShouldRegisterOp(const char* name) {\n    return strcmp(name,\"Add\") ? true :\n        strcmp(name,\"Const\") ? true :\n        ...\n        strcmp(name,\"Softmax\") ? true :\n        false;\n}\n```\n\nThe `SHOULD_REGISTER_OP` macro from [tensorflow/core/framework/selective_registration.h](https://github.com/tensorflow/tensorflow/blob/f71cc62282bf2e066f9ebd08cf3f605fc98c6e41/tensorflow/core/framework/selective_registration.h) calls ShouldRegisterOp, which returns true if the op should be registered.\nThe `SHOULD_REGISTER_OP_KERNEL` macro does a string search in `kNecessaryOpKernelClasses`\n", "For why the header didn't make the size smaller, I think there are a few\npossibilities to check:\n1. selective registration can only make code deleted if the expressions can\n   be evaluated as constexprs.  Using const char\\* instead of const char[] on\n   the definition of kNecessaryOpKernelClasses may be enough to prevent this.\n   But even with that,  I would have expected some drop by the const bool\n   kRequiresSymbolicGradients = false;  line.  Was it no change at all in\n   size, or a small change?\n2. doublecheck that SELECTIVE_REGISTRATION macro is defined for calls to\n   compile the ops and kernels.\n3. what compiler are you using?  Maybe compiler differences could explain\n   it as well.\n\nHere's an example ops_to_register.h that gets generated by the tool that\nwill be opensourced soon:\n\n#ifndef OPS_TO_REGISTER\n#define OPS_TO_REGISTER\nconstexpr inline bool ShouldRegisterOp(const char op[]) {\n  return false\n     || (strcmp(op, \"AvgPool\") == 0)\n     || (strcmp(op, \"BiasAdd\") == 0)\n     || (strcmp(op, \"Concat\") == 0)\n     || (strcmp(op, \"Const\") == 0)\n     || (strcmp(op, \"Conv2D\") == 0)\n     || (strcmp(op, \"Identity\") == 0)\n     || (strcmp(op, \"LRN\") == 0)\n     || (strcmp(op, \"MatMul\") == 0)\n     || (strcmp(op, \"MaxPool\") == 0)\n     || (strcmp(op, \"NoOp\") == 0)\n     || (strcmp(op, \"Placeholder\") == 0)\n     || (strcmp(op, \"Relu\") == 0)\n     || (strcmp(op, \"Reshape\") == 0)\n     || (strcmp(op, \"Softmax\") == 0)\n     || (strcmp(op, \"_Recv\") == 0)\n     || (strcmp(op, \"_Send\") == 0)\n  ;\n}\nconst char kNecessaryOpKernelClasses[] = \",\"\n\"AvgPoolingOp<CPUDevice, float>,\"\n\"BiasOp<CPUDevice, float>,\"\n\"ConcatOp<CPUDevice, float>,\"\n\"ConstantOp,\"\n\"Conv2DOp<CPUDevice, float>,\"\n\"IdentityOp,\"\n\"LRNOp<CPUDevice, float>,\"\n\"MatMulOp<CPUDevice, float, false >,\"\n\"MaxPoolingOp<CPUDevice, float>,\"\n\"NoOp,\"\n\"PlaceholderOp,\"\n\"ReluOp<CPUDevice, float>,\"\n\"ReshapeOp,\"\n\"SoftmaxOp<CPUDevice, float>,\"\n\"RecvOp,\"\n\"SendOp,\"\n;\nconst bool kRequiresSymbolicGradients = false;\n#endif\n\n## \n\nOn Thu, Sep 29, 2016 at 11:39 AM, Sam notifications@github.com wrote:\n\n> Re: @lingz https://github.com/lingz : I was able to compile with\n> selective registration, but it didn't help reduce the file size for me.\n> Instead, I ended up using the makefile from tensorflow/contrib/makefile,\n> removing all the unused ops classes from tf_op_files.txt.\n> https://github.com/tensorflow/tensorflow/blob/f71cc62282bf2e066f9ebd08cf3f605fc98c6e41/tensorflow/contrib/makefile/tf_op_files.txt\n> \n> For what it's worth, this is what I had in my ops_to_register.h:\n> \n> const bool kRequiresSymbolicGradients = false;const char\\* kNecessaryOpKernelClasses =\n>     \",Add,\"\n>     \",Const,\"\n>     ...\n>     \",Softmax,\";\n> \n> constexpr bool ShouldRegisterOp(const char\\* name) {\n>     return strcmp(name,\"Add\") ? true :\n>         strcmp(name,\"Const\") ? true :\n>         ...\n>         strcmp(name,\"Softmax\") ? true :\n>         false;\n> }\n> \n> The SHOULD_REGISTER_OP macro from tensorflow/core/framework/\n> selective_registration.h\n> https://github.com/tensorflow/tensorflow/blob/f71cc62282bf2e066f9ebd08cf3f605fc98c6e41/tensorflow/core/framework/selective_registration.h\n> calls ShouldRegisterOp, which returns true if the op should be registered.\n> The SHOULD_REGISTER_OP_KERNEL macro does a string search in\n> kNecessaryOpKernelClasses\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3549#issuecomment-250553879,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AQw4wQ7SVEzQUTsU3512180ZgGITJBZTks5qvAXugaJpZM4JXOz-\n> .\n", "The tool for generating ops_to_register.h that @cwhipkey mentioned is now commited: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py\n", "hi @andrewharp \r\n\r\nI tried to use print_selective_registration_header.py to write ops to ops_to_register.h. I follow instructions and run:\r\n\r\n`bazel build tensorflow/python/tools:print_selective_registration_header && bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=path/to/graph.pb > ops_to_register.h`\r\n\r\nThen \r\n\r\n```\r\nbazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" \\\r\n    --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" \\\r\n    //tensorflow/contrib/android:libtensorflow_inference.so \\\r\n    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n    --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a\r\n```\r\n\r\nEverything went well, so I use the libtensorflow_inference.so in my Android project. Still when I run the model resnet_101_coco from the model zoo, I get the error:\r\n`\r\njava.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Round' with these attrs.  Registered devices: [CPU], Registered kernels:  <no registered kernels>`\r\n\r\nHow to overcome this? Thanks.", "@bobeo: What does your ops_to_register.h look like?", "hi @andrewharp \r\n\r\nI attached the ops_to_register.h. I can see it has 'Round\" ops ( || isequal(op, \"Round\") ) . The final libtensorflow_inference.so is 4MB. \r\n\r\nThe model I use is faster_rcnn_resnet101_coco from \r\n http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz\r\n\r\nThanks.\r\n\r\n\r\n\r\n[ops_to_register.h.zip](https://github.com/tensorflow/tensorflow/files/1364323/ops_to_register.h.zip)\r\n", "@andrewharp Have you had time to check on this? Thanks", "There are at least couple reasons this could happen:\r\n1. the kernel for round isn't being compiled on android.  you could add a compilation error in tensorflow/core/kernels/cwise_op_round.cc and then run the android build again, to see if it actually compiles that file.\r\n\r\n2. the kernel is being compiled, but for some reason the ops_to_register.h is causing it to not use the Round op.  ops_to_register.h works by comparing the string name of the class to the string in the ops_to_register.h.  It's possible the compiler for the device is using a different name than the compiler for the host (used to make ops_to_register.h).  It can be tricky to get the names out of the device compilation -- one way could be to change the cwise_op_round.cc kernel file and\r\n\r\nAdd:\r\n#define CLAZ_NAME(x) #x\r\nstatic_assert(false, CLAZ_NAME(UnaryOp<float>)); \r\n\r\nthen build and look for the class name printed by the assertion failure.", "thanks @bobeo ,\r\nI did this process with a few pb graphs including the ones from the example app\r\nand in in time I'm the print_selective_registration_header process i see that the ops_to_register.h file is updated according to the graph but the resulting libtensorflow_inference.so is always in the same size.\r\ni tried all the bazel clean / bazel dump options that i have found, but nothing helped\r\nso it is either a bazel caching issue. or that the build from ops_to_register.h does not work properly.", "OK,\r\njust realized that i had 2 ops_to_register.h files ...\r\none in the /core/framework folder\r\nand one in the project root folder where i ran the print_selective_registration_header build\r\ni think that this is worth clearing in the print_selective_registration_header.h comments...\r\nor changing it in a way that the ops_to_register.h file will be created only in one place no matter where the process is called from", "@eli99999 any luck? Can you try this [model](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz)?\r\nI'm trying all over again, if success I will let you know. Cheers!", "@cwhipkey @andrewharp hi guys, do you know if I should compile **libtensorflow_inference.so** with GPU enabled? Or it doesnt make any difference? Currently I compiled it without GPU because else I got this [error](https://github.com/tensorflow/tensorflow/issues/12468)\r\n\r\nWhen I run it an Android, it takes like 1 minute to process each frame. Is that normal?"]}, {"number": 3548, "title": "Display the graph on tensorboard horizontally from left to right, or vertically from top to bottom", "body": "Dear community, \n\nMay I ask is there any option that enables us to change the orientation of the current layout of graphs in tensorboard? \nBy default it is vertically from bottom to top in the current form. \n\nBest,\n", "comments": ["There is no such option, and no plans for one at this time. \n"]}, {"number": 3547, "title": "Fixed typo:", "body": "Variables must be initialized by running an `init` Op\n\"before\" having launched the graph, not \"after\".\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3546, "title": "iOS: No OpKernel was registered to support Op 'Div' with these attrs", "body": "I'm trying to build graph in iOS but i have following error:\n\n```\nInvalid argument: No OpKernel was registered to support Op 'Div' with these attrs\n     [[Node: conv1/conv/moments/sufficient_statistics/truediv = Div[T=DT_DOUBLE](conv1/conv/moments/sufficient_statistics/truediv/Cast, conv1/conv/moments/sufficient_statistics/truediv/Cast_1)]]\n```\n\nIn Python if I run this code: \n`batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], keep_dims=True)`\nI'm getting the error above, otherwise works fine.\nI'm trying to find ops (core/ops, core/kernels).\n", "comments": ["This could be related to #3543 so I will update once we hear a response there.\n", "I am having the same issue on iOS. Spent the entire day trying to fix it with no progress.\n", "Any ideas?\n", "I'm experiencing same issue on Linux. Looks like in my case it only happens with int tensors.\n", "You could try casting the quantities to float and see if that is supported? Otherwise, please provide the minimal and complete reproducible test case.. Here are some tests to try.\n\n``` python\nimport tensorflow as tf.\na=tf.constant(3)\nb=tf.constant(6)\nsess=tf.Session()\nsess.run(tf.truediv(a,b))\nsess.run(tf.div(a,b))\nsess.run(tf.truediv(af,bf))\nsess.run(tf.div(af,bf))\n```\n", "Closing automatically due to lack of recent activity. Please reopen when further information becomes available. Thank you.\n", "For me, casting the input tensor to tf.float32 / tf.float64 before calling tf.nn.moments()  solved the issue\n", "@cedricsimar Your problem solved?I met a similar problem,and consult.Thank you!!\r\n\r\n> No OpKernel was registered to support Op 'Maximum' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n\t [[Node: gradients/Mean_grad/Maximum = Maximum[T=DT_INT32, _output_shapes=[[]], _device=\"/device:CPU:0\"](gradients/Mean_grad/Prod_1, gradients/Mean_grad/Maximum/y)]]"]}, {"number": 3545, "title": "Tensorflow unable to detect no. of CPU cores", "body": "### Environment info\n\n**Operating System:**\nUbuntu 14.04 Linux ppc64le\n\n**Installed version of CUDA and cuDNN: 7.5**\nls -l /usr/local/cuda-7.5/lib64/libcud*\n-rw-r--r-- 1 root root   326744 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.23\n-rwxr-xr-x 1 root root   445192 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.23\n-rw-r--r-- 1 root root   902750 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Apr 24 20:17 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.5\n-rwxr-xr-x 1 root root 60068392 Apr 22 19:18 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 59436124 Apr 22 19:30 /usr/local/cuda-7.5/lib64/libcudnn_static.a\n**\n\n**Tensorflow 0.8 built and installed from source. (v0.8.0 tag)**\n1. The commit hash (`git rev-parse HEAD`) : 4b7bc3174ed67b4a0eb1803537c9d00f132e9ae7\n2. The output of `bazel version`: 0.2.0\nNote: Same issue also exists with tensorflow 0.9\n\n**Steps to reproduce:**\nOn python prompt, \n1. import tensorflow as tf\n2. tf.Session()\n\nIn a large output of above statement, there is a line that says \"can't determine no. of CPU cores, assuming 4\".\n\nAfter looking into the tensorflow code, I found that __linux macro in tensorflow/core/platform/posix/port.cc is found to be not defined and hence sched_getaffinity is not called, and returns 4 as default value. I checked that usually on linux, __linux is defined but if we compile using -std=c++11, then this macro gets undefined. \nAnyway, even if sched_getaffinity is called, it returns logical no. of CPU cores i.e. maximum threads possible. On POWER, usually this count is pretty higher and having so many threads degrades the performance. Ideally, we should have physical core size as the max possible thread count in thread pool for optimum performance. I tried looking for a built-in function that gives me physical core size, but unfortunately, all of the functions I found gives me logical core size. Then I found another library \"[libhwloc](https://www.open-mpi.org/projects/hwloc/)\" that gives C API to get this information. This library in general is very useful with nice documentation. It is also available on canonical and one can install it using \"apt-get install libhwloc-dev\" on Ubuntu system or on RHEL using \"yum install hwloc-devel\". \nSo, I wanted to know if Tensorflow can accept this additional dependency on hwloc library.  \n", "comments": ["@martinwicke can you comment on dependency questions?\n", "Hi, \nCould you please let me know if hwloc can be added in the dependency list of tensorflow?\n", "We can add it as a source dependency. @michaelisard what's your take on how useful this is, as opposed to fixing the `sched_getaffinity` issue directly? I'd lean toward the latter to fix this bug.\n", "@cwhipkey you have been looking at threadpools recently. What do you think?\n", "@cwhipkey could you please let us know your thoughts?\n", "I think it would be good to figure out the issue with __linux not being set properly.\n\nCan you try:\n`touch /tmp/foo.cc`\n`cpp -dM -std=c++11 /tmp/foo.cc`\n\nvs\n`cpp -dM /tmp/foo.cc`\n\nSave the output of each separately and attach both files?  It will be good to see which macros are actually defined in both cases.\n", "Here are the files with both outputs. The one with std=c++11 doesn't have **linux defined (it has __linux** defined though) while the other one without it, has **linux and __linux** defined.\n\nEven if __linux is defined, sched_getaffinity does not give us expected output. It gives us logical no. of cores, i.e. max possible threads (no. of sockets \\* core per socket \\* threads per core) which is pretty high on Power and it degrades the performance adversely. We also tested that using physical core size gives the best performance. All the existing relevant APIs like std::thread::hardware_concurrency(), omp_get_max_threads(), omp_get_num_procs(), get_nprocs(), etc. give the logical core size. We could not find any API giving us required size. \nHwloc library is the one that provides the required API. We would anyway call this API only for power architectures, for non-power arch, sched_getaffinity will still be functional.\n[WithOUTStdc++11.txt](https://github.com/tensorflow/tensorflow/files/412613/WithOUTStdc.11.txt)\n[WithStdc++11.txt](https://github.com/tensorflow/tensorflow/files/412614/WithStdc.11.txt)\n", "Thanks for posting that info.  We'll make a change to use **linux** instead of __linux, so that would fix the issue with using the hardcoded value instead of sched_getaffinity.\n\nFor logical vs physical, it does seem useful to be able to detect physical and use on PPC (unless there is some other change that can be made to use the logical cores in a more useful way).  I don't have experience with powerpc, so I don't know why using the logical cores makes it worse - is there a particular kind of computation that gets much worse in that case?\n", "What I've observed on most of our development machines that no. of threads per core is usually 8. So, sched_getaffinity returns values like 160 or 128. This value is (no. of threads per core \\* no. of cores per socket \\* no. of sockets). We did perform various tests with different thread count, and with 160 threads, we got degraded performance, and with even 4, the performance was no good. So, trying out further values, we settled at 32 or 40 which gave us the best performance. This means threads equal to actual physical no. of cores will work the best. On x86, we usually have less no. of threads per core (probably 1 or 2) which will give thread count approximately 20 or 32 that must be the best bet. \n\nI'm not sure about exact computation that suffered the performance hit on Power. We tested Googlenet-tensorflow Inception v3 models for training some images. I'll get back to you on this.\n", "We actually tested Googlenet-tensorflow Inception V3 models, wherein we tried training a very small set of imagenet dataset (around 20 images) for just 10 steps with 1,2 and 4 GPUs. And, we ran this for different core sizes.\n", "Hello,\n\nCould you please let me know if I can go ahead with hwloc library for retrieving physical core size?\n", "I think it's okay to include that library for this purpose.\n\nI am still uncertain why it would have so much impact on a benchmark that\nuses GPUs for the core computation - the main CPU work would be just the\nscheduling of GPU kernels.\n\nNote that this recent commit would affect any GPU benchmark as well:\nhttps://github.com/tensorflow/tensorflow/commit/f1acb3bd828a73b15670fc8019f06a5cd51bd564\n.  It's possible that that change, which would reduce the amount of thread\nswitching when running a GPU benchmark, will also help your case.\n\nOn Mon, Aug 22, 2016 at 6:22 AM, Nishidha notifications@github.com wrote:\n\n> Hello,\n> \n> Could you please let me know if I can go ahead with hwloc library for\n> retrieving physical core size?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3545#issuecomment-241409943,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AQw4wR4cMFLje1CNvWGHTmJtH_yKg_0Aks5qiaJ4gaJpZM4JW_kK\n> .\n", "Thank you @cwhipkey . We'll test with this commit and let you know the status of whether we need to address core size problem using hwloc library.\n", "@cwhipkey , we tested the recent commit referred by you. With macro change from **linux to __linux**, that recent commit worked well. We see better performance with this commit which is equally comparable with what we got using physical core size. Hence, for power, what we need is \n1. Changing **linux to __linux** in port.cc where we call get_schedaffinity so that the function is called even on power\n2. This recent commit that reduces the amount of thread switching in GPU mode.\n\nThanks for making the 1st change in the repo and fixing the 2nd one. We can close the issue now.\n", "Thanks for testing out the changes!  Closing this now.\n"]}, {"number": 3544, "title": "Should *.pb.h files be generated in cross-compile cases?", "body": "A few days ago, I have tried to import the tensorflow project directly into Android Studio on Windows and use Gradle to build the project. Header files with suffix \".pb.h\" are not generated. Google says bazel should be used to build the project. Now I use bazel on Linux to build it again with CPU=arm64-v8a using the following command\n\nbazel build //tensorflow/examples/android:tensorflow_native_libs --crosstool_top=//external:android/crosstool --cpu=$CPU --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\n\nas in the issue #3444 .\n\nHowever header files with suffix \".pb.h\" are still not generated. Android Studio cannot find the include file and hence the build procedure cannot be continued. Is there any method to use tensorflow C++ library in Android Studio?\n", "comments": ["Did the bazel build appear to succeed? For completeness, would you build CPU=armabi-v7a as in #3444 and see if the headers are generated for that target?\n", "For both cases(arm64-v8a and armeabi-v7a), there were only warnings like the following:\n\n(1) WARNING: /home/alan/.cache/bazel/_bazel_alan/16525490ccae1ec04acb6f1b1a5f7367/external/protobuf/WORKSPACE:1: Workspace name in /home/alan/.cache/bazel/_bazel_alan/16525490ccae1ec04acb6f1b1a5f7367/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\n(2) WARNING: /home/alan/Desktop/Tensorflow_On_Android_Playground/tensorflow/tensorflow/core/BUILD:640:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n\nwithout any error. I think bazel build succeeded. In addition, libtensorflow_demo.so were generated successfully. \n\nUnfortunately, even if CPU=armeabi-v7a, the *.pb.h headers are still not generated. (For example, I have only tensorflow/core/framework/graph.proto instead of tensorflow/core/framework/graph.pb.h)\n\nI wonder the bazel generates *.pb.h only when it is used to generate the whole apk using the following command\n\nbazel build //tensorflow/examples/android:tensorflow_demo\n\non the official website\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android \n, but I cannot try it now because I have no sdk on my ubuntu. Should I install sdk on my ubuntu and try the whole apk version again? Because my whole project is on Windows Android Studio, I hope I can use tensorflow on Windows.\n\nUmm.. After all I think I should guarantee the answer to the following question is YES first, or I don't have to build the \"whole\" headers on Linux.\n\nIf libtensorflow_demo.so and the *.pb.h headers are generated successfully on \"Linux\" eventually, can I just migrate libtensorflow_demo.so to Windows as a jni library and the whole tensorflow project as jni include header files and guarantee that tensorflow functions can work successfully on \"Windows?\" (i.e. regardless of OS difference)\n\nThanks for your help !\n", "@andrewharp could you comment on the intended behavior before OP embarks on the next experiment?\n", "The generated header files should not be necessary unless you are planning on modifying the Tensorflow C++ code in Android Studio. Merely copying the built libtensorflow_demo.so to the appropriate libs/ directory is sufficient, and then you can build it as a regular Android application in Android Studio.\n\nYou also don't need the SDK on your Ubuntu machine unless you desire to build the entire project with Bazel.\n\nHow are you attempting to make Gradle build the project, such that it is even looking for these pb.h files?\n", "I have thought originally that .so libraries must be accompanied with source codes to satisfy JNI structure. Thanks for correcting my thoughts!\n\nIn fact, I have written some codes to preprocess some captcha last summer for my practice(low recognition rate). On this summer vacation, I plan to migrate it from my Ubuntu virtual machine to android cell phone for convenience. Thanks to the project https://github.com/niektemme/tensorflow-mnist-predict , I can use the classifier model to recognize digits. It includes two kinds of python script. Create_model.py is used to generate model (*.ckpt) and predict.py is used to predict the value from digit image using the model built by create_model.py. \n\nMy final final purpose is to execute predict_2.py on my android. It includes tensorflow module. I originally want to rewrite the python script in C++ language and migrate the generated .so library on my android studio project. Should I still need to move the whole source code to Windows Android Studio? The answer is NO according to your answer, am I right? Additionally, if I want to write my own C++ codes with tensorflow, should the bazel build file also be modified?\n\nThank you again for solving my problem!\n", "@alan23273850 \nIf you don't need to modify the native C++ code, then no you can just copy the built .so file into your Android studio project as described. However, if you plan to modify them, you'll need to rebuild, which at this point will be hard to do in Windows due to the lack of Bazel support.\n"]}, {"number": 3543, "title": "boolean_mask failed in iOS: Running model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs", "body": "### Environment info\n\nOperating System:\nBuilding on Mac OS X\nRunning on iOS 9.2.1\n1. The commit hash (`git rev-parse HEAD`)\n   71f6bb336e5e11d6da2cedac6ba1c992ad9992bd\n2. The output of `bazel version`\n\n```\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue Jul 12 11:11:47 2016 (1468321907)\nBuild timestamp: 1468321907\nBuild timestamp as int: 1468321907\n```\n### Steps to reproduce\n1. I compile tf for iOS with the makefile\n2. I frozen a model with last step as  a boolean_mask (that prozen pb file runs perfectly with TF 0.9.0 python api )\n3. I run it in iOS, log report \n\n```\nRunning model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs\n     [[Node: classes_num_filtered/Gather = Gather[Tindices=DT_INT64, Tparams=DT_INT64, validate_indices=true](classes_num_filtered/Reshape, classes_num_filtered/Squeeze)]]\n```\n\nso it happens with the gather op inside the boolean_mask, when I removed this operation, it runs without problem in iOS.\nIs that means gather op is not currently support in iOS? \nDo I have a work around for now? I need to filter the data with porbs > threhold.\n\n``` python\n        mask = self.classes_prob > self.threshold\n        self.classes_prob_filtered = tf.boolean_mask(self.classes_prob, mask, name=\"probs_filtered\") \n        self.classes_arg_filtered = tf.boolean_mask(self.classes_arg, mask, name=\"classes_num_filtered\") \n        self.boxes_filtered = tf.boolean_mask(self.boxes, mask, name=\"boxes_filtered\") \n```\n\nI checked the  tf_cc_files.txt, tensorflow/core/kernels/gather_op.cc do exist.\n", "comments": ["I update to last reversion 98d63de3bb2bab7c9a81f83c8ca864741399300c and recompiled everything, problem still exist\n", "@petewarden could you take a look?\n", "Sorry for the long delay on this one. We only support a limited number of ops by default on iOS, to keep the binary size small, but you can add your own to the list by including them locally in this file:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/tf_op_files.txt\n\nIn this case you'll want to add `tensorflow/core/kernels/gather_op.cc`. Can you let me know if that helps?\n", "@petewarden 's solution should work. Feel free to open a new issue if the problem persists."]}, {"number": 3542, "title": "Fix go build errors", "body": "Two minor changes:\n- enum declaration should use C++ syntax\n- swig can't port `int64_t` to Go's type system. `long long` used instead.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "Adding @josh11b to review. \n\nThe files had all been moved to tensorflow/c\n", "- We really want a 64-bit int type, not whatever long long happens to be\n- The whole point of this file is to use C not C++ so the enum change is counter productive.\n", "@josh11b fair point, but I was not able to use the Go API bindings until I made these changes. I should probably take a different approach and try to modify the swig helpers rather than the C API itself.\n", "@damienstanton should we keep this PR open for you to try a different approach, or close and wait for a fresh PR?\n", "@danmane since I don't want my branch to get too stale, let's close this and I will open a new PR down the line. Thanks!\n", "OK, looking forward to the new one :)\n"]}, {"number": 3541, "title": "Constant folding seems to cause error with ImmutableConst ops", "body": "Using memory-mapped ImmutableConst ops seems to cause the initial constant folding process to fail.\n## Reproduction steps:\n- Load a graph containing ImmutableConst ops.\n- Create a memory-mapped environment and session like this:\n\n``` c++\n // Create and initialize MemmappedEnv from the converted file.\n  MemmappedEnv memmapped_env(Env::Default());\n  TF_ASSERT_OK(memmapped_env.InitializeFromFile(filename_mmap));\n\n  // Load the graph and run calculations.\n  SessionOptions session_options;\n  session_options.env = &memmapped_env;\n  std::unique_ptr<Session> session(NewSession(session_options));\n```\n- Run the graph using session->Run().\n## Expected results:\n\nThe graph should execute successfully with no error messages.\n## Actual results:\n\nThe graph seems to execute correctly, but the following is printed to the console:\n\n```\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Unimplemented: File system scheme memmapped_package not implemented\n     [[Node: W_conv23 = ImmutableConst[dtype=DT_FLOAT, memory_region_name=\"memmapped_package://W_conv23\", shape=[9,9,32,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n```\n## Notes\n\nFrom investigation, it seems like the constant folding code creates a new device with empty session options, which means a default Env is used instead of the memory-map-aware one the client passes in:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/constant_folding.cc#L166\n", "comments": ["a short-term fix:\n // Create and initialize MemmappedEnv from the converted file.\n  MemmappedEnv memmapped_env(Env::Default());\n  TF_ASSERT_OK(memmapped_env.InitializeFromFile(filename_mmap));\n\n  // Load the graph and run calculations.\n  SessionOptions session_options;\n  options.config.mutable_graph_options()\n        ->mutable_optimizer_options()\n        ->set_opt_level(::tensorflow::OptimizerOptions::L0);\n  session_options.env = &memmapped_env;\n  std::unique_ptr<Session> session(NewSession(session_options));\n", "Please open a new issue if the short-term fix is still required in recent versions of tensorflow."]}, {"number": 3540, "title": "Variable.assign throws expection randomly", "body": "I'm trying to copy weights between two graphs which are running in two different processes simply by fetching the values from one, sending them to the second process and assigning the values there.\n\nThe code I have is pretty simple and straight forward:\n\n```\ndef get_all_variable_values(self):\n    vars = list(self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n    names = [v.name for v in vars]\n    values = self.sess.run(vars)\n    return dict(zip(names, values))\n\ndef set_all_variable_values(self, update_dict):\n    for var in self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n        self.sess.run(var.assign(update_dict[var.name]))\n```\n\nBut time to time (seems to be completely random), the following exception happens.\nI also tried replacing `Variable.assign` with `tf.assign` and the same problem happens.\n\nAny idea why?\n\n```\nTraceback (most recent call last):\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 715, in _do_call\n    return fn(*args)\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 697, in _run_fn\n    status, run_metadata)\n  File \"/home/mbz/anaconda3/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.NotFoundError: FetchOutputs node Assign_404:0: not found\n\nDuring handling of the above exception, another exception occurred.\n\nTraceback (most recent call last):\n  File \"/home/mbz/anaconda3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n    self.run()\n  File \"/home/mbz/anaconda3/lib/python3.5/threading.py\", line 862, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mbz/projects/pacman_multi_gpu/ProcessServer.py\", line 50, in update_model\n    self.model.set_all_variable_values(update_dict)\n  File \"/home/mbz/projects/pacman_multi_gpu/NetworkVP.py\", line 258, in set_all_variable_values\n    self.sess.run(var.assign(update_dict[var.name]))\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 636, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 708, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 728, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.NotFoundError: FetchOutputs node Assign_404:0: not found\n\n```\n", "comments": ["This is probably better discussed on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). Have you tried creating the graph before the call to run? It looks as if you are modifying the graph inside the loop in set_all_variable_values.\n", "The graph has been created beforehand, but I'm not modifying it (at least not deliberately!).\nI'm not sure which line in `set_all_variable_values` you are talking about:\n\n```\nfor var in self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n```\n\nThis one is to just go through all the variables, and this \n\n```\nself.sess.run(var.assign(update_dict[var.name]))\n```\n\njust replaces their value.\n", "TensorFlow works by first building a graph of Ops, and then running that graph once it is assembled. tf.assign adds a new assign node to the graph, which is typically run later as a side-effect of calling tf.run on some node. In your case you are adding the new node and then calling run on the newly-added node. As I said, this kind of discussion is better suited to the StackOverflow forum which is a good place for discussing TensorFlow usage.\n", "Thanks, that makes sense. However that still doesn't explain the random behaviour of TensorFlow, does it? With your explanation, the rational is that `Graph` object is not thread safe and if changes while being processed the code may break? \n", "Well, I'm not sure because you didn't provide a larger code snippet but you did say that there are multiple processes and it's unclear how you are calling it. It certainly isn't the common use case to have multiple threads mutating the graph concurrently. @mrry could you comment on what if any guarantees there are for thread safety?\n", "Which version of TensorFlow are you running? The thread safety of the `tf.Graph` has been improved somewhat recently, so it'd be great if you could confirm this is still a problem with the latest version.\n\nIn general though, if you're modifying the graph in response to an unbounded number of server requests, there's a memory leak that will bite you in the future. I'd suggest creating one assign op per variable ahead of time, which would take a placeholder that you could feed each time you get a new value. That would address the leak (and sidestep the potential thread safety issue).\n", "Thanks for the reply. I'm switching to your design. Just out of curiosity, can I pull the same thing off using a `Saver`? It seems what `Saver` essentially does is the same as what you described.\n\nI'm using Version: 0.9.0rc0. Can update to a newer version if it is available. \n", "Yes, you could do this using a `Saver`, but it should be slightly faster (fewer copies etc.) to go through the feed mechanism. Either way, creating the saver or the placeholders once would be the way to go.\n\nIt looks like the thread-safety fix missed 0.9, but it should be in the nightlies and 0.10rc0.\n", "cool, I ended up writing the following functions:\n\n```\n    def _create_restore_point(self):\n        self.restore_dict = {}\n        self.restore_ops = []\n        for var in self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n            place_holder = tf.placeholder(tf.float32, var.get_shape(), 'ph%s' % var.name.split(':')[0])\n            self.restore_dict[var.name] = place_holder\n            self.restore_ops.append(tf.assign(var, place_holder))\n\n    def set_all_variable_values(self, update_dict):\n        feed_dict = {}\n        for name, value in update_dict.items():\n            feed_dict[self.restore_dict[name]] = value\n        self.sess.run(self.restore_ops, feed_dict=feed_dict)\n```\n\nIt seems that it is working, but may not be optimal.\n", "That looks good to me. I'll close this issue for now, since it doesn't seem like there's any (unfixed) bug, but feel free to reopen if that doesn't work.\n"]}, {"number": 3539, "title": "parallelize OneVsRestClassifier", "body": "Hi,\n\nI have implemented a CNN model in a TensorFlowEstimator and I use it with a OneVsRestClassifier.\nIt works good.\nWhen I am trying to parallelize it by putting n_jobs=2 in the OneVsRestClassifier, I got a strange error that I don't understand : \n\nMaybeEncodingError: Error sending result: '[TensorFlowEstimator(batch_size=32, class_weight=None, clip_gradients=5.0,\n          config=None, continue_training=True, learning_rate=0.001,\n          model_fn=<function cnn_model at 0x11f22d500>, n_classes=16,\n          optimizer='Adam', steps=200, verbose=1)]'. Reason: 'PicklingError(\"Can't pickle <type 'module'>: it's not found as **builtin**.module\",)'\n\nDo you have an idea of what does it mean ?\n\nThanks\n", "comments": ["@poxvoculi would you take a look?\n", "In short, no I don't know just what's going on, but here's what I can deduce, not having much experience with python or the python layer of tensorflow.\n\nThis is a python error trickling up, evidently from the python pickle operation which serializes an in-memory object for storage or i/o with another process.  It appears something is unsuccessfully trying to serialize TensorFlowEstimator, which is in contrib.learn.TensorFlowEstimator.  (Maybe this is a result of parallelizing, so now the entire program is being pickled before being transferred to some child processes.)  The python pickling rules described [here](https://docs.python.org/2/library/pickle.html#what-can-be-pickled-and-unpickled) suggest that TensorFlowEstimator should be pickleable, since it's a class at the top level of a module.  Could it be that somehow the way you're running the program, access to that full definition has been lost by the compilation/execution unit that is trying to do the pickle at runtime?\n", "Sorry I misdirected but thanks @poxvoculi. @ilblackdragon could you have a quick look?\n", "I'm only running it in the command shell by writing : \npython program.py\n\nSo I don't know how to handle the access\n", "?\n", "The error means that some component inside the object can't be picklable (serializable).\nProbably this means the `model_fn` didn't serialize. (I'm not sure because your error doesn't have info about object like this `Can't pickle <function _model_fn at 0x108802140>:`).\n\nTwo things:\n1) Try using `Estimator`, because `TensorFlowEstimator` is deprecated.\n2) You can try to move whatever you passing to `model_fn` into separate module and import it. This may allow to serialize the pointer to function.\n\nIf pickling of the `model_fn` function doesn't work, you can always make a wrapper that will do the work of constructing new estimator and returning.\n", "Thanks\nIn which library can I find : Estimator ?\n", "@rubenstern `tf.contrib.learn.estimator`\n", "1) and 2) doesn't work : I got the same error.\n\nHow can I make a wrapper that will do the work of constructing new estimator and returning ?\n", "You can serialize params / arguments you pass to `Estimator` and then just re-create object by passing arguments again.\n", "Marking as fixed. Thanks @ilblackdragon !"]}, {"number": 3538, "title": "Branch 128624829", "body": "", "comments": []}, {"number": 3537, "title": "Cannot build a simple C++ TensorFlow example for Android x86", "body": "Operating System: Ubuntu 14.04 LTS 64bit\n\nInstalled:\nAndroid NDK (r12b), \nAndroid SDK (Latest), \nTensorflow (0.9) (configured for CPU only),  \nBazel (0.3.0)\n\nI faced the same problem of the issue #2753, then I changed to use \"//tensorflow/core:android_tensorflow_lib\", now the error is:\n\n```\nexternal/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/TypeCasting.h: In function 'TgtPacket Eigen::internal::pcast(const SrcPacket&) [with SrcPacket = Eigen::internal::Packet4h; TgtPacket = __vector(4) float]':\nexternal/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/TypeCasting.h:143:38: error: '_mm_cvtm64_si64' was not declared in this scope\n   __int64_t a64 = _mm_cvtm64_si64(a.x);\n                                      ^\nTarget //tensorflow/mydemo:mydemo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 174.487s, Critical Path: 168.61s\n```\n\nI'm building with the following command:\n\n`bazel build :mydemo --crosstool_top=//external:android/crosstool --cpu=x86 --host_crosstool_top=@bazel_tools//tools/cpp:toolchain`\n\nAnd with the following BUILD file:\n\n```\ncc_binary(\n    name = \"mydemo\",\n    srcs = [\"mydemo.cc\"],\n    deps = [\n        \"//tensorflow/core:android_tensorflow_lib\",\n    ]\n)\n```\n\nMy WORKSPACE configuration:\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 22,\n    build_tools_version = \"24.0.1\",\n    path = \"/myandroid/sdk\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/myandroid/android-ndk-r12b\",\n    api_level=22)\n```\n\nI'm just trying to build a very simple C++ TensorFlow example for Android x86.\n", "comments": ["I also tried with NDK r11c, and it throws the same error. I believe it is something related with host platform of the cross-compilation which is x86_64 and the target Android compilation for x86 (32-bits).\n\nIt seems that Eigen is trying to use x86_64 instructions even if it is compiled for x86 (32-bits).\n\nUsing `--cpu=armeabi-v7a` it works fine.\n", "I had this same problem when building Tensorflow 0.9.0. The Eigen dependency that 0.9.0 uses includes this issue. It's fixed just three commits later: https://bitbucket.org/eigen/eigen/commits/e934860fa7bc\r\n\r\n Updating bazel to use the newer version of Eigen above worked for me. This problem also may be solved when building a more recent version of Tensorflow, but I wanted to save a couple hours of time for anyone else in my position.", "Thanks @jacob-meacham for your comment! Marking as fixed. If the problem still persists with `0.12.x` and/or `master`, feel free to open an issue."]}, {"number": 3536, "title": "Bazel target to create C++ library headers", "body": "Thanks to the `//tensorflow:libtensorflow.so` target, I can now build a shared library that I can use in my C++ programs.  I want to install that library in `/usr/local/lib` and put the headers for it in `/usr/local/include`, but there is no target to build and install those headers.  In particular, building the library doesn't build the headers from the proto files, so I have `error_codes.proto`, but not `error_codes.pb.h`, so I can't even use the source directory for the headers.\n", "comments": ["@martinwicke is this addressed in any planned build system changes?\n", "No\n", "Is the target `//tensorflow/core:framework_headers_lib` not sufficient?\n", "The .proto files are not compiled to .pb.h files when I build the `//tensorflow/core:framework_headers_lib` target\n\n```\n$ **bazel build //tensorflow/core:framework_headers_lib**\n..\nWARNING: /private/var/tmp/_bazel_aaron/cd1b...c/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_aaron/cd1b...c/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /private/var/tmp/_bazel_aaron/cd1b...c/external/re2/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_aaron/cd1b...c/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /private/var/tmp/_bazel_aaron/cd1b...c/external/highwayhash/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_aaron/cd1b...c/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nINFO: Found 1 target...\nTarget //tensorflow/core:framework_headers_lib up-to-date (nothing to build)\nINFO: Elapsed time: 5.460s, Critical Path: 0.01s\n```\n", "@hillegass Sorry, I misunderstood your requirement. `//tensorflow/core:framework_headers_lib` is meant for use within a `BUILD` file, when building with `bazel`. If you want to use `libtensorflow.so` in a different build system, and just want the header files, we package them up in the pip packages. For example, [here](https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl) is the python2 pip package. The header files go in `<install path>/tensorflow/include`m where `<install path>` is platform dependent. It usually is something like `/usr/local/lib/python2.7/site-packages`. Feel free to close the issue once you verify that it works for you.\n", "My fault.  The headers were, indeed, in the python directory.  (For other lost people, on a Mac the include directory is `/Library/Python/2.7/site-packages/tensorflow/include/` . Thank you!\n", "Quick follow up note for others: A couple of the important headers (especially those related to sessions) are not in that include directory, so you will need to copy them from the source tree: \n\n```\n$ cd tensorflow/tensorflow/core/public\n$ sudo cp session.h session_options.h tensor_c_api.h /Library/Python/2.7/site-packages/tensorflow/include/tensorflow/core/public/\n```\n", "Heads-up: there is a dedicated `//tensorflow:install_headers` target now  "]}, {"number": 3535, "title": "SGD only? What about other algorithms like L-BFGS?", "body": "This is simply a question, not an issue, as this seemed like the best place to ask:\n\nI was looking at the video an model on the site, and it appeared to only have SGD as an algorithm for machine learning.  I was wondering if other algorithms are also included in tensorflow.\n\nAn interested student,\nWilliam\n", "comments": ["It's better to ask this kind of question on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow), thanks!\n"]}, {"number": 3534, "title": "Document exceptions to broadcasting semantics ", "body": "## Environment info\n\nOperating System: Ubuntu 14.04, OSX 10.11\n\nInstalled from `1b7b7703c8449769ba1cfb7553494c9b472925d7`\n\nOutput of `bazel version`:\n\n```\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n```\n### Steps to reproduce\n\nRunning this script:\n\n```\nimport tensorflow as tf\n\nshape_1 = (50, 1, 20, 10)\nshape_2 = (50, 30, 20, 1)\n\nA = tf.Variable(tf.random_normal(shape_1))\nB = tf.Variable(tf.random_normal(shape_2))\n\nwith tf.Session() as S:\n    S.run(tf.initialize_all_variables())\n    C = S.run(A+B)\n```\n\nproduces\n\n`UnimplementedError: Broadcast between [50,1,20,10] and [50,30,20,1] is not supported yet.`\n### What did you try?\n\nMoving the broadcast dimensions to the results in success\n\n```\nshape_1 = (50, 20, 10, 1)\nshape_2 = (50, 30, 1, 20)\n```\n\nThe following also works\n\n```\nshape_1 = (1, 1, 20, 10)\nshape_2 = (1, 30, 20, 1)\n```\n\nas does\n\n```\nshape_1 = (1, 20, 10)\nshape_2 = (30, 20, 1)\n```\n### Discussion\n\nI am aware of #508 and #1519 however this does not appear to be covered by #1519. It would be very nice if the exceptions to normal numpy broadcasting rules were documented somewhere. \n\nA tentative list would include\n- number of broadcasting dimensions limited to 2\n- broadcasting dimensions must (sometimes??) be relegated to the last dimensions\n", "comments": ["@vrv, @girving it does seem as if this should be documented. I could add it to #508 but this seems like a more targeted fix to the general 'how we do broadcasting for elementwise ops' doc, since we don't really do numpy broadcasting only a weird subset of it. Shall I keep this as a separate issue?\n", "#508 should definitely cover the documentation part of this, but maybe we keep this bug open to track the completion of the 'numpy broadcasting semantics' ?\n", "My concern about #508 is that it has degenerated into the nice-to-have 'go add a line to every op' with 'contributions welcome' and I'm not sure anyone is going to do it, whereas 'the doc that we already have is actively wrong and generates NotImplemented exceptions' seems a bit more urgent. I'd be happy to update #508 with the info from here if you can suggest someone to assign it to so it gets done.\n", "I think #1519 is actually fine for the underlying bug if I link this to it with a comment.\n", "SGTM.  Maybe assign to ZF\n", "OK closing and moving to #508.\n"]}, {"number": 3533, "title": "Problems with quantization. Op type not registered 'Dequantize' and other problems", "body": "Hi Everyone,\n\nI did quantization with tensorflow following this manual: https://www.tensorflow.org/versions/master/how_tos/quantization/index.html\n\nHere detailed description of my current problem: \nhttp://stackoverflow.com/questions/38615558/bug-in-tensorflow-tuttorial-about-quantization\n\nAnd here parent problem: \nhttp://stackoverflow.com/questions/38595600/notfounderror-op-type-not-registered-dequantize\n\nI use pip install tensorflow. Python2.7, tensorflow=0.9.0\nAlso I have git-master repository and use bazel-build for other tools like freezing and so on. \nbazel version=0.3.0\nOS: Ubuntu 16.04 LTS\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1) \n\n@petewarden \n\nI am ready to give you any additional information \n\nThanks, \n Artem \n", "comments": ["Same problems. Can't load the quantization library anyway!\nSolved by updating to tf 0.10.rc\n", "i found a solution, rebuilt the `label_image` by adding two lines below \n\n```\n\"//tensorflow/contrib/quantization:cc_ops\",\n\"//tensorflow/contrib/quantization/kernels:quantized_ops\"\n```\n\ninto `tensorflow/examples/label_image/BUILD` . It works for me (ubuntu 1404LTS, tf0.9-gpu ).\n", "I'm facing the same issue, however in my case adding the dependencies doesn't work because they don't compile for Android.\n", "@perone same problem as you, did your android project work now? @petewarden can you give a tutorial about how android project use the quantize neural networks ? \n", "@chenbiaolong not yet, I tried to add the required dependencies (the quantized operations) but they do not compile for Android, it seems that quantization isn't ready yet for Android compilation.\n", "I am facing the same issues when trying to use a quantized network on Android (tried both with TF r0.8 and r0.10). Any news, solutions or advices? :)\n", "Please upgrade to a newer version, `0.12.1` or master. Feel free to open a new issue if the problem persists."]}, {"number": 3532, "title": "Dask Integration with tf.learn", "body": "Current `DaskDataFeeder` is no longer working due to recent refactoring. It will be switched to use `tf.DataFrame`. \n\n@davidsoergel what's the status on replacing data feeders with `tf.DataFrame` in estimators? Do you want to take a look at dask as well?\n\ncc: @jcrist @mrocklin @ogrisel @shoyer \n", "comments": ["A few thoughts from looking through [the code of DaskDataFeeder](https://github.com/tensorflow/tensorflow/blob/5df4c71c86b28c2a4dd746bd67f00fc0281bd24f/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py#L507):\n- It looks like DaskDataFeeder currently does random sampling for input. This is nice in some cases, but in general could be very expensive. I would prefer something simpler that simply iterates through in rows in order, which would also fit better with the chunking design of dask.\n- The current design calls `.compute()` twice in `_feed_dict_fn`. This could be trivially improved by calling `dask.compute` once, but the bigger issue is that the non-distributed version of dask is not really designed for incremental computation -- calling `compute()` evaluates the entire graph from scratch. For example, if you center a column by subtracting the mean, the mean would be recalculated each time you call compute! This is potentially a pretty big gotcha. So we should either integrate with dask-distributed's executor or consider extending the non-distributed engine (which uses threads) to handle incremental computation.\n- There are also potential for integration with `dask.array`, which would make it quite straightforward to map `xarray.Dataset` objects backed by dask into a `learn.DataFrame` (with multi-dimensional arrays in each column). This could be quite useful for multi-dimensional scientific data.\n", "Between the following two choices:\n1.  Explicitly depend on the distributed scheduler\n2.  Extend the single-machine scheduler to support iterative workloads\n\nI recommend the first \n", "Replacing data feeders is high on our DataFrame todo list, and should be straightforward in principle because we already have various feeding functionality working-- so it's just a matter of hooking that up in the right places.  It could easily be a month before it's done, though, both because we're juggling a lot and because I'll be on vacation for a few weeks.\n\nHowever: we had decided specifically to deprioritize the Dask functionality, based on feedback that it is less used than the rest of data feeders etc.  I'm happy to hear arguments to the contrary, but the baseline is that we won't be supporting it in the short term.\n", "@davidsoergel I agree, dask is less important than other data feeders (NumPy/pandas/iterators). Most data is small data, and flexibility is more important than supporting any particular engine.\n\nI do think it would be interesting to support, though, because it offers similar (but more mature) out of core and distributed dataframe/array functionality to that envisioned with learn.DataFrame.\n", "Closing due to inactivity. Feel free to open a new bug if you want to track additional issues.", "Interestingly I was just looking at what the status of all this was.  The last DaskDataFeeder was made without any collaboration with Dask devs.  I am not particularly surprised that it flopped.\r\n\r\nI (a Dask dev) have some time for this coming up if anyone on the tensorflow side wants to work together to try things out.", "I think Dask integration would be pretty sweet as an in-between to tf.train.Example protocol buffers and NumPy feed_dict.", "`enqueue_data`, which already turns numpy arrays and pandas DataFrames into TensorFlow queues, is possibly a good entry point for this functionality: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/dataframe/queues/feeding_functions.py\r\n\r\n(It's already serves some use uses in-between `feed_dict` and `tf.train.Example` protos)", "Yes, that should be a good place to start. @mrocklin The original DaskDataFeeder was actually created by me with your help understanding dask but it will be removed soon. Feel free to create another one that's similar to that and incorporates enqueue_data", "At first glance this appears to be a single machine solution.  Correct?  Any thoughts on handing data from a distributed dask cluster over to tensorflow workers?  \r\n\r\nAdditionally, any thoughts on spinning up tensorflow workers from dask workers?  It might be convenient to use dask as a launching platform if it is possible to start distributed tensorflow by calling python functions.\r\n\r\nAlso, let me know if I should move this over to a new issue.", "Here is a brief experiment launching tensorflow from dask and then using dask.array to feed distributed tensorflow data: http://matthewrocklin.com/blog/work/2017/02/11/dask-tensorflow", "From a deep learning perspective, the experiment is hacky at best.  Hopefully the notes around setup and data movement are of use to someone though."]}, {"number": 3531, "title": "Fix debian build; Bring debian build into ci_parameterized_build", "body": "", "comments": ["@tensorflow-jenkins test this please\n", "Ready to be reviewed/merged.\n"]}, {"number": 3530, "title": "Update go branch", "body": "This is a merge of the latest changes from `master` onto the `go` branch.\nBuild and local tests of TensorFlow 0.9 using the Python and Go APIs is successful.\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "Can one of the admins verify this patch?\n", "Having git issues. Please ignore this PR\n"]}, {"number": 3529, "title": "Fixed typo:", "body": "There is no Mechanics tab, practical aspects of usage is inside TUTORIALS\nand HOW TO tab.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks @wang-yang !\n"]}]