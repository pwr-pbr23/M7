[{"number": 908, "title": "Visualizing CNNs with TensorBoard", "body": "I am a huge fan of Tensorboard visualization however in my opinion it may lack good documentation when the user wants to implement non trivial visualization for example visualizing weights for a CNNs (or even features) (and also on how everything is stored and processed but that is another question).  \nI am runing a CNN on a set of color images the structure and the code of my cnn is almost entirely based on Deep MNIST tutorial/MNIST+tensorboard tutorial.\nI have several problems :\nI want to run tf.image_summary(W_conv1) every 100 steps/epochs of the training with W_conv1 being of shape (3,5,5,32) (first conv layer after an RGB image)\nHowever the desired shape is (32,5,5,3) so I reshape using `tf.reshape(W_conv1;shape=(32,5,5,3))`\nI am only using reshape because I could not find a numpy swapaxes equivalent in tf (and from the definition of reshape in numpy doc I am not sure wether or not it does exactly what I wanted but I agree it is my problem...).\nI call a `merge_all_summaries()` that I feed every 100 steps.\nI run 1000 epochs so I should get 320 images, instead I get 2 or 3 actually displayed !!!\nOn stackoverflow I found out that even if all the images are loaded into the memory (where?!) it does not display them all and that I should do something like initialize an empty tf.summary() and call `.MergefromString(image_summary)` but I am confused on exactly where in the code I should do that and at what time ?\nMy second issue is I also want to see the weights for the second conv layer which is of shape (32,5,5,64) so I would like to split it into (32x64) 5x5 images does that seem reasonnable ?\nHow would I go about displaying them ?\nSame for features obtained at different layers of the CNN ?\nI understand my questions are trivial but I think a lot of people would benefit (I would certainly) from an example of a clean and efficient code in tensorflow of a CNN on whatever image dataset WITH tensorboard visualization of the weights/features.\nThanks for the work TF is amazing !\n", "comments": ["This issue is related to #842\n", "I agree with you it is related, however I am not asking for the creation of a toolbox, more for a small example script somewhere, which let you use TensorBoard as it was planned !\nBut I would be in favour of such a tool of course if the team is motivated !\n", "I asked something similar not too long ago [on stackoverflow](http://stackoverflow.com/questions/33802336/visualizing-output-of-convolutional-layer-in-tensorflow). The solution there was to pack the activations into a grid of little images. Would that solve your problem?\n", "Damn it I saw it on stack but did not really read through ! That is certainly a great start ! Thanks ! However I stand by my demand of a clean and safe tutorial made by google team to transform this very intelligent hack into something classier.\n", "I did the trick to get a grid of weights, and convolutions of one image (thanks @panmari ) Nonetheless I still want to hear a clean and good solution for exemple the grid trick is not super great because the size of the entire grid seems to be limited to very short values (even using `tf.image.resize_images`).\nI am sure there are better ideas out there on how to do these visualizations !\nHere is what I used (based almost entirely on the answer @MarkDaoust gave to @panmari on stackoverflow):\n\n```\nwith tf.name_scope(\"First_image_after_conv_i\") as scope:\n    I1=stf.slice(h_conv,(0,0,0,0),(1,-1,-1,-1))\n    I1=tf.reshape(I1,(1,size,size,width_grid,height_grid))\n    I1=tf.transpose(I1,(3,1,4,2,0))\n    I1=tf.reshape(I1,(1,width_grid*size,height_grid*size,1))\n    images_after_conv_i=image_summary(\"images_after_conv\",I1)\nwith tf.name_scope(\"W_conv_i\") as scope:\n    I2=tf.reshape(W_conv_i,(size_mask,size_mask,nb_features_map_i,nb_feature_maps_o))\n    I2=tf.transpose(I2,(2,0,3,1))\n    I2=tf.reshape(I2,(1,nb_feature_maps_i*size_mask,nb_feature_maps_o*size_mask,1))\n    weights_conv_i=image_summary(\"weights_conv_i\",I2)\n```\n\nFeeding the summary at each step : the only ones displayed seem to be related to the last image of the last batch not sure though. I am still quite disatisfied with this solution for the problem mentionned above and because it looks hacky.\n", "No comment/improvement/other ideas on how to visualize CNN in a tensorflow way ?\n", "Hi jeandut\n\nHere is a snippet of code fo visualising convolutional layer, in my case it's of shape [5, 5, 1, 24] so you will have to adapt it to your case. I reformatted the 5x5 24-deep convolution kernel as a square grid of 25 5x5 images, the last one being just padding:\n\n```\nW1_a = W1                            # [5, 5, 1, 24]\nW1pad= tf.zeros([5, 5, 1, 1])        # [5, 5, 1, 1]\nW1_b = tf.concat(3, [W1_a, W1pad])   # [5, 5, 1, 25]\nW1_c = tf.split(3, 25, W1_b)         # 25 x [5, 5, 1, 1]\nW1_row0 = tf.concat(0, W1_c[0:5])    # [25, 5, 1, 1]\nW1_row1 = tf.concat(0, W1_c[5:10])   # [25, 5, 1, 1]\nW1_row2 = tf.concat(0, W1_c[10:15])  # [25, 5, 1, 1]\nW1_row3 = tf.concat(0, W1_c[15:20])  # [25, 5, 1, 1]\nW1_row4 = tf.concat(0, W1_c[20:25])  # [25, 5, 1, 1]\nW1_d = tf.concat(1, [W1_row0, W1_row1, W1_row2, W1_row3, W1_row4]) # [25, 25, 1, 1]\nW1_e = tf.reshape(W1_d, [1, 25, 25, 1])\nWtag = tf.placeholder(tf.string, None)\ntf.image_summary(Wtag, W1_e)\n```\n", "Hi martin-gorner thanks for making this thread live on !!! By reading your code hastily I am kind of curious about what you are doing but will try it tomorrow for sure. However what intrigues me the most is the last line, where does Wtag come from ? Is it a way to make it evolve through time ? (like any othe summary except images that seem to be stuck)  Because in mark daoust's trick you already had a kind of reshaping into a grid of weights. Could you explain the advantages of your method ?\n", "Sorry, Wtag is just a string placeholder. It's the tring tensorboard will display in ints output as a caption for the image. I modified the code to make it explicit. I feed it in the training loop with something like W1_iteration_####\n", "For your case, I would try something like this (I have not tested it):\nYou have 32 color (3-deep) kernels of size 5x5. The shape of your W1 is [5, 5, 3, 32].\nSo I would try to display the 32 kernels in a 6x6 grid. That's 36 slots so you will have to add 4 zero kernels for padding.\n\n```\nW1_a = W1                            # [5, 5, 3, 32]\nW1pad= tf.zeros([5, 5, 3, 1])        # [5, 5, 3, 4]  - four zero kernels for padding\nW1_b = tf.concat(3, [W1_a, W1pad])   # [5, 5, 3, 36]\nW1_c = tf.split(3, 36, W1_b)         # 36 x [5, 5, 3, 1]\nW1_row0 = tf.concat(0, W1_c[0:6])    # [30, 5, 3, 1]\nW1_row1 = tf.concat(0, W1_c[6:12])   # [30, 5, 3, 1]\nW1_row2 = tf.concat(0, W1_c[12:18])  # [30, 5, 3, 1]\nW1_row3 = tf.concat(0, W1_c[18:24])  # [30, 5, 3, 1]\nW1_row4 = tf.concat(0, W1_c[24:30])  # [30, 5, 3, 1]\nW1_row5 = tf.concat(0, W1_c[30:36])  # [30, 5, 3, 1]\nW1_d = tf.concat(1, [W1_row0, W1_row1, W1_row2, W1_row3, W1_row4, W1_row5]) # [30, 30, 3, 1]\nW1_e = tf.reshape(W1_d, [1, 30, 30, 3])\nWtag = tf.placeholder(tf.string, None)\ntf.image_summary(Wtag, W1_e)\n```\n", "Oh in this case I would have an update of the look of the weights throughout the training! Thanks @martin-gorner ! Good answer probably the one closest to what I have been asking for however I am not closing this issue though as I still feel a bit unsatisfied of the look of the results in terms of display Tensorboard should be able to do better.\n", "And here is a sample output (first convolutional layer of a neural network training on the MNIST handwritten character recognition problem). The grid was photoshopped in and individual kernel visualisations assembled as an animated GIF. On this specific run, the network ended up recognising 9935 out of the 10000 test images (which is good).\n![mnist7convsimplified_w1_best](https://cloud.githubusercontent.com/assets/959847/13878781/dec1a482-ed13-11e5-921a-37edf9f68f51.gif)\n", "@jeandut \nJeandut, I can understand your answer is not satisfactorily answered. I join you on the quest for nice tutorials. \nIn the meantime, I got some code running that uses TensorBoard for a nice graph, plots some histograms and the visualization of the 32 filters. You can find it on\nhttp://robromijnders.github.io/tensorflow_basic/\n\nHope that helps:)\n", "Yeah thanks to you guys my plots are beginning to feel right ! @RobRomijnders this webpage is really nicely done ! I am hesitating to close this issue because it seems like the longer it lasts the more cool answers I am getting. However I can honestly say that my original question has been answered !\n", "@RobRomijnders @jeandut If you are on a quest for nice tutorials, I encourage you to help improve the TensorFlow tutorials. It's an open source project - you can modify everything yourself! For example, @RobRomijnders you could modify our tutorial code for CNNs to use TensorBoard like in the page you posted.\n\n@martin-gorner nice job with the convolution filter visualization. If you want to submit a proposal for how the API should look for adding that to TensorBoard, that would be quite welcome.\n\nClosing this issue since @jeandut says his question was answered (:\n", "Many thanks to @martin-gorner for the code examples above. It was very helpful to me.\r\nNow here is my derived code for an 8x8x32x64 conv2d layer that works with TensorFlow 1.1 (order of parameters shifted for some methods). Maybe this helps someone else.\r\n\r\n```\r\n  f2=32\r\n  f3=64\r\n\r\n  W3 = weight_variable([8, 8, f2, f3]) # hidden layer 3 has f2 input channels and f3 output channels\r\n  b3 = bias_variable([f3])\r\n  l3 = tf.nn.relu(conv2d(a2, W3) + b3) # a2 is downsampled activations from layer_2\r\n  a3 = max_pool_2x2(l3)\r\n\r\n  # visualize 32 x 64 learned feature filters as 32 (input channel) images \r\n  # each input channel is seen as an 8x8 (64 output channels) grid of 8x8x1 (grayscale) filters\r\n  with tf.name_scope('layer_3'):\r\n    W3_a = W3                                           # [8, 8, 32, 64]\r\n    #W3pad= tf.zeros([8, 8, 32, n])             # [8, 8, 32, n]  - n zero kernels for padding\r\n    #W3_b = tf.concat([W3_a, W3pad], 3)  # [8, 8, 32, 64]\r\n    # in my case I have exactly 64 output channels so I assign W3_b to W3_a\r\n    # comment the assignment below and uncomment the tf.zeros and tf.concat statements above to pad\r\n    # fewer than 64 output channels to exactly 64. You have to change \"n\" of course!\r\n    W3_b = W3_a\r\n    W3_c = tf.split(W3_b, 64, 3)                  # 64 x [8, 8, 32, 1]\r\n    W3_row0 = tf.concat(W3_c[0:8], 0)       # [64, 8, 32, 1]\r\n    W3_row1 = tf.concat(W3_c[8:16], 0)     # [64, 8, 32, 1]\r\n    W3_row2 = tf.concat(W3_c[16:24], 0)    # [64, 8, 32, 1]\r\n    W3_row3 = tf.concat(W3_c[24:32], 0)    # [64, 8, 32, 1]\r\n    W3_row4 = tf.concat(W3_c[32:40], 0)    # [64, 8, 32, 1]\r\n    W3_row5 = tf.concat(W3_c[40:48], 0)    # [64, 8, 32, 1]\r\n    W3_row6 = tf.concat(W3_c[48:56], 0)    # [64, 8, 32, 1]\r\n    W3_row7 = tf.concat(W3_c[56:64], 0)    # [64, 8, 32, 1]\r\n    W3_d = tf.concat([W3_row0, W3_row1, W3_row2, W3_row3, W3_row4, W3_row5, W3_row6, W3_row7], 1) # [64, 64, 32, 1]\r\n    W3_e = tf.reshape(W3_d, [1, 64, 64, 32])\r\n    W3_f = tf.split(W3_e, 32, 3)                    # 32 x [1, 64, 64, 1]\r\n    W3_g = tf.concat(W3_f[0:32], 0)             # [32, 64, 64, 1]\r\n    tf.summary.image(\"filter\", W3_g, 32)\r\n\r\n```", "When i try to run the above code for the first conv layer i get the following error:\r\nTypeError: Expected int32, got <tf.Variable 'W_conv1:0' shape=(5, 5, 1, 32) dtype=float32_ref> of type 'Variable' instead.\r\n\r\nHelp is appreciated! Thanks!", "@martin-gorner, @edubergeek, and @jeandut I'm almost in a similar situation but in case of convolution layer, I'm trying to visualize a deconvolution layer. The shape of the layer is (5, 100, 100, 3) in NHWC format. Basically, I need 100 x 300 grids but when I'm implementing the above concept I'm getting an error \"ValueError: Cannot reshape a tensor\". Any idea how can I solve this issue?\r\n", "Issue solved. Thanks", "Hello. Can someone explain me the logic behind @martin-gorner code? I want to visualize some filters but I really don't understand what he did there. Thanks a lot, Alex", "@vesaalexandru95 The explanations:\r\n\r\nI was trying to visualize the weights of a convolutional layer of shape [5,5,1,24]. That'a a 5x5 convolution working on an image with 1 channel (B&W). The convolution is repeated 24 times with different weights. So we have 24 different convolution \"kernels\" to visualize. It will be a nice fit in a 5x5=25 grid with a single grid cell unoccupied.\r\n\r\n\r\n```\r\n# All the weights are in this tensor\r\nW1_a = W1                            # [5, 5, 1, 24]\r\n# We add zeros for the weights of a 25th \"kernel\", so as to have 25 kernels to visualize\r\nW1pad= tf.zeros([5, 5, 1, 1])        # [5, 5, 1, 1]\r\n# This now looks like we have 25 \"kernels\"\r\nW1_b = tf.concat(3, [W1_a, W1pad])   # [5, 5, 1, 25]\r\n# We split into a list of 25 individual \"kernels\"\r\nW1_c = tf.split(3, 25, W1_b)         # 25 x [5, 5, 1, 1]\r\n# This could be in a for loop, easier to understand with rows spelled out one by one\r\n# Concatenate five 5x5 \"kernels\" into a row of 25x5 weights\r\nW1_row0 = tf.concat(0, W1_c[0:5])    # [25, 5, 1, 1]\r\n# Concatenate another five 5x5 \"kernels\" into a row of 25x5 weights\r\nW1_row1 = tf.concat(0, W1_c[5:10])   # [25, 5, 1, 1]\r\n# Concatenate another five 5x5 \"kernels\" into a row of 25x5 weights\r\nW1_row2 = tf.concat(0, W1_c[10:15])  # [25, 5, 1, 1]\r\n# Concatenate another five 5x5 \"kernels\" into a row of 25x5 weights\r\nW1_row3 = tf.concat(0, W1_c[15:20])  # [25, 5, 1, 1]\r\n# Concatenate another five 5x5 \"kernels\" into a row of 25x5 weights\r\nW1_row4 = tf.concat(0, W1_c[20:25])  # [25, 5, 1, 1]\r\n# Concatenate the five 25x5 rows into a 25x25 grid. In this grid, each \"kernel\" is now a 5x5 square.\r\nW1_d = tf.concat(1, [W1_row0, W1_row1, W1_row2, W1_row3, W1_row4]) # [25, 25, 1, 1]\r\n# Reshape as a batch of N images (with N=1). Each image is 5x5 pixels and 1 color channel (b&w)\r\nW1_e = tf.reshape(W1_d, [1, 25, 25, 1])\r\n# name this visulaization\r\nWtag = tf.placeholder(tf.string, None)\r\n# output as a \"summary\" visible in Tensorboard.\r\ntf.image_summary(Wtag, W1_e)\r\n```"]}, {"number": 907, "title": "Remove unused import", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for the fix, but it turns out this is actually required in our codebase for platform-specific reasons. \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/__init__.py#L16\n\nWe'll try to better document this somewhere.\n", "@vrv Thanks for the feedback!\n"]}, {"number": 906, "title": "Update CROSSTOOL with Toolchain for ARM", "body": "Update CROSSTOOL that it uses the local_linux toolchain for arm as some people managed to build tensor flow on raspberrypi2 and jetson. Otherwise it would fail with:\n\n```\nERROR: No toolchain found for cpu 'arm'. Valid cpus are: [\n  k8,\n  piii,\n  darwin,\n].\n```\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for the contribution!  I'm a bit confused though -- you've made the change to the crosstool when compiling with GPUs.  Did you intend to want it to work without --config=cuda too?\n", "Hmm, I never tried to compile without --config=cuda. Probably its a non issue for systems without cuda...\n", "Assigning to @andrewharp, who has more experience with arm builds :)\n", "Seems sensible, but it looks like you need to merge master into your branch.\n", "Removed post as my concerns were wrong\n", "Can one of the admins verify this patch?\n", "By the way, building without cuda on aarch64 works perfectly.\n", "@tensorflow-jenkins: test this please\n\n(sorry for the huge delay)\n", "every time you merge, it invalidates the tests, so it would be good to avoid merging after i've kicked off tests :)\n", "@tensorflow-jenkins: test this please\n", "Hi @jmtatsch \nI was trying to build it on my arm64 boards with aarch64:\n\nroot@linaro-alip:~# gcc -v\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/aarch64-linux-gnu/4.8/lto-wrapper\nTarget: aarch64-linux-gnu\nConfigured with: ../src/configure -v --with-pkgversion='Debian/Linaro 4.8.4-1' --with-bugurl=file:///usr/share/doc/gcc-4.8/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.8 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.8 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-libmudflap --disable-libsanitizer --disable-libquadmath --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.8-arm64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.8-arm64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.8-arm64 --with-arch-directory=arm64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-multiarch --enable-checking=release --build=aarch64-linux-gnu --host=aarch64-linux-gnu --target=aarch64-linux-gnu\nThread model: posix\ngcc version 4.8.4 (Debian/Linaro 4.8.4-1)\n\nroot@linaro-alip:~# bazel build -c opt --local_resources 1024,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package\n......\n\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/farmhash_archive/BUILD:5:1: Executing genrule @farmhash_archive//:configure failed: bash failed: error executing command \n  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/tensorflow && \\\n  exec env - \\\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; pushd external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260; workdir=$(mktemp -d -t tmp.XXXXXXXXXX); cp -a \\* $workdir; pushd $workdir; ./configure; popd; popd; cp $workdir/config.h bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260; rm -rf $workdir;'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/tensorflow/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/tensorflow\n/tmp/tmp.5EXVBY1p2Z /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/tensorflow/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/tensorflow\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking build system type... /tmp/tmp.5EXVBY1p2Z/missing: Unknown `--is-lightweight' option\nTry`/tmp/tmp.5EXVBY1p2Z/missing --help' for more information\nconfigure: WARNING: 'missing' script is too old or missing\n./config.guess: unable to guess system type\n\nIf the version you run (./config.guess) is already up to date, please\nsend the following data and any information you think might be\npertinent to config-patches@gnu.org in order to provide the needed\ninformation to handle your system.\n\nconfig.guess timestamp = 2010-08-21\n\nuname -m = aarch64\nuname -r = 3.10.52-linaro-bubblegum\nuname -s = Linux\nuname -v = #22 SMP PREEMPT Fri Apr 15 11:21:43 CST 2016\n\n/usr/bin/uname -p = \n/bin/uname -X     = \n\nhostinfo               = \n/bin/universe          = \n/usr/bin/arch -k       = \n/bin/arch              = \n/usr/bin/oslevel       = \n/usr/convex/getsysinfo = \n\nUNAME_MACHINE = aarch64\nUNAME_RELEASE = 3.10.52-linaro-bubblegum\nUNAME_SYSTEM  = Linux\nUNAME_VERSION = #22 SMP PREEMPT Fri Apr 15 11:21:43 CST 2016\nconfigure: error: cannot guess build type; you must specify one\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 29.680s, Critical Path: 27.59s\n"]}, {"number": 905, "title": "ValueError: All shapes must be fully defined.", "body": "Hi,\nI am trying to create a TFRecord file where each picture is saved by its dimensions, label and image content. \nSince every picture has different dimensions, so it is necessary to read the info from the file and reshape them. When I did something as the following:\n\nfeatures = tf.parse_single_example(\n      serialized_example,\n      dense_keys=['image_raw', 'label', 'height', 'width', 'depth'],\n      # Defaults are not specified since both keys are required.\n      dense_types=[tf.string, tf.int64, tf.int64, tf.int64, tf.int64])\n\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\n  height = tf.cast(features['height'], tf.int32)\n  width = tf.cast(features['width'], tf.int32)\n  depth = tf.cast(features['depth'], tf.int32)\n\n  im_shape = tf.pack([height, width, depth])\n  new_image = tf.reshape(image, im_shape)\n\nI got the error \"ValueError: All shapes must be fully defined.\" Is this because I used the tensors representing dimensions instead of specific numbers? I have searched through the internet, all the tutorials and discussions are about reading fixed sized images. I do think reading various sized images is important. Any solutions to this issue? I would really appreciate it. \n", "comments": ["Here's a recent discussion of how to read variable sized images: http://stackoverflow.com/questions/35028173/how-to-read-images-with-different-size-in-a-tfrecord-file\n", "That is my post. Because it did not solve the problem, so I came here for help.\n"]}, {"number": 904, "title": "Fixed Momentum Optimization Equation", "body": "", "comments": ["Can one of the admins verify this patch?\n", "If I remember correctly, the existing code is actually a correct reparameterization of momentum, even though it looks subtly different.\n\nThe momentum vector stores the unscaled gradients, and we multiply the entire momentum vector by the learning rate when applying the update.\n\n(This has come up several times internally -- we should add documentation to the ApplyMomentum op: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/training_ops.cc#L98  Feel free to do so there if you think it would help others).\n"]}, {"number": 903, "title": "Wrong Momentum Equation in Tensorflow's Kernel", "body": "I believe I found a slight error in the multiplication of the learning rate\n\nMomentum Optimization has the form:\n![brahms_cpmc_columbia_edu_publications_momentum_pdf](https://cloud.githubusercontent.com/assets/5315899/12606885/98bc9276-c496-11e5-8bfc-0b887bfaef71.png)\nWhere epsilon is the learning rate and p is the momentum.\nReference: Ning Qian's Momentum Paper (1999) http://brahms.cpmc.columbia.edu/publications/momentum.pdf\n\nIn tensorflow/core/kernel/training_ops.cc, lines 68 and 69 (ApplyMomentum) we find:\n\n``` c++\naccum = accum * momentum() + grad;\nvar -= accum * lr();\n```\n\nExpanding this, we get:\n\n``` c++\nvar -= (accum*momentum() + grad) * lr();\n// =>\nvar -= accum*momentum()*lr() + grad*lr();\n```\n\nNotice how the momentum variable is being multiplied by the learning rate, but this should not be the case. The correct form is:\n\n``` c++\naccum = accum * momentum() + grad * lr();\nvar -= accum;\n```\n\nHere's my pull request fixing this: #904 \n", "comments": ["Two forms produce equivalent descent path. Note that you can factor out lr() out of momentum in your formulation, and then write accum = lr()_(unscaled_accum); var-=lr()_unscaled_accum. So in our case the difference between our accum and your accum is an extra factor of lr(), but it doesn't affect the update. There are several slightly different variations of momentum equation out there which are equivalent for practical purposes. For instance, Polyak's original paper on momentum wrote update as x_{k+1}=x_k - \\alpha_g grad + beta_k(x_k-x_{k-1})\n", "Closing this. Reopen if the scaling of the stored value is important.\n", "@yaroslavvb, thanks for your explanation! I was not entirely sure if scaling would eventually affect the results, but that cleared it up! \n"]}, {"number": 902, "title": "Use the same types in `for` statements.", "body": "This removes lots of simple compiler warnings on 'signed' and 'unsigned'\ncomparisons (reported in #128). Please note that there are two types of\nchanges. It is because this does not change any function signatures.\n- In most cases: `int` --> `size_t`.\n- In `lookup_table_op.cc`, `string_to_number_op.cc`, and\n  `sparse_tensor.h`: `size_t` --> int.\n", "comments": ["Can one of the admins verify this patch?\n", "FYI, the number of lines of output: 32552 --> 17670 (As of today).\nThis is not enough to close #128 . This is just a sub PR for #128 .\n", "@tensorflow-jenkins: test this please\n", "Merged\n", "Thank you for merging, @vrv .\n"]}, {"number": 901, "title": "Added missing PY2AND3 build annotation", "body": "As @martinwicke [commented](https://github.com/tensorflow/tensorflow/issues/791#issuecomment-173009071), building for python 3 was failing due to missing `srcs_version=\"PY2AND3\"` annotations. This single addition of the annotation allowed the build to complete successfully for me using python 3.5.1 on OS X 10.11.2.\n\nFixes #791 \n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, go test this please.\n", "Thanks. This looks good. Running tests for completeness.\n", "You're welcome. Glad I could help!\n"]}, {"number": 900, "title": "Note that master is installed with plain git clone", "body": "Since the docs are versioned, and the latest stable version is the default visible docset on the website, we should point out that the installation instructions actually install master, and also give instructions on how to install a specific branch. This change doesn't mention which branch it is on because we don't want to have to change this text in each release. \n\nThis PR supercedes #891.\n", "comments": ["squash commits? :)\n", "The merge script now has a --squash! :)\n", "Neat, LGTM.\n", "Merged.\n"]}, {"number": 899, "title": "MatMul \"flops\" statistic looks incorrect", "body": "I think the flops estimate for MatMul is incorrect. In a vanilla matrix multiply AB=C with dimensions `shape_A=(i,j)`, `shape_B=(j,k)`, and `shape_C=(i,k)`, we should get ~ `2*i*j*k`. It appears `_calc_mat_mul_flops` is giving `shape_A[0] * prod(shape_C)`, or `2*i*i*k` for an un-transposed multiply, ignoring the internal dimensions. I believe you meant `shape_A[0] * prod(shape_B)`. Or if it helps,\n\n```\nweights_shape = graph_util.tensor_shape_from_node_def_name(graph,node.input[1])\nweights_shape.assert_is_fully_defined()\nweight_count = np.prod(weight_shape.as_list())\nreturn ops.OpStats(\"flops\", (k * weight_count * 2))\n```\n\nAlso, here's a minimum working example that demonstrates the problem.\n\n```\nimport tensorflow as tf\nimport tensorflow.python.framework.ops as ops \ng = tf.Graph()\nwith g.as_default():\n  A = tf.Variable(tf.random_normal( [25,16] ))\n  B = tf.Variable(tf.random_normal( [16,9] ))\n  C = tf.matmul(A,B) # shape=[25,9]\nfor op in g.get_operations():\n  flops = ops.get_stats_for_node_def(g, op.node_def, 'flops').value\n  if flops is not None:\n    print 'Flops should be ~',2*25*16*9\n    print '25 x 25 x 9 would be',2*25*25*9 # ignores internal dim, repeats first\n    print 'TF stats gives',flops\n```\n\nAnd it's output:\n\n```\nFlops should be ~ 7200\n25 x 25 x 9 would be 11250\nTF stats gives 11250\n```\n", "comments": ["Looks like a transpose gone wrong here: tensorflow/python/ops/math_ops.py:967\n", "Thanks for the catch Bob! I've just submitted a fix, and adapted versions of your tests, hopefully it should show up in the public repo soon. I had a braino when I was coding up the FLOPs calculations, because I forgot that the y dimension in the shape [x, y] would be at index 1, not 0 in TF's conventions.\n\nAnyway, I appreciate the well-documented bug and test code, thank you!\n", "@petewarden @ragulpr \r\nThe FLOPS returned is always None. Is there a way to concretely measure FLOPS?", "I am getting the following output:\r\n\r\nFlops should be ~ 7200\r\n25 x 25 x 9 would be 11250\r\nTF stats gives 8288"]}, {"number": 898, "title": "HEAD does not load the inception-v3 graph def", "body": "The code:\n\n```\ngraph_def = tf.GraphDef()\ngraph_def.ParseFromString(open(PB_PATH).read())\n```\n\nThe error:\n\n```\ngoogle.protobuf.message.DecodeError: Error parsing message\n```\n\nThe SHA: `f2a42d48a885ce8956c3ea69ef900cf484a6e873`\n\nThanks.\n", "comments": ["duplicate of #582 \n"]}, {"number": 897, "title": "gradient of tf.floor", "body": "``` python\nimport numpy as np\nimport tensorflow as tf\nf = np.array([3.8], dtype='float32')\nvif = tf.placeholder(tf.float32, shape=[1])\n\n#out = vif + tf.cast(tf.cast(vif, tf.int32), tf.float32)\nout = vif + tf.floor(vif)\ngrad = tf.gradients(tf.reduce_sum(out), vif)\n\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\nprint sess.run(grad, feed_dict={vif: f})  # print 2\n\nimport theano\nimport theano.tensor as T\nvif = T.fvector()\nout = vif + T.floor(vif)\ngrad = T.grad(out.sum(), vif)\nfunc = theano.function([vif], grad)\nprint func(f) # print 1\n```\n\nIt looks like the gradient of `tf.floor(x)` w.r.t `x` is 1. But I'm expecting it to be 0, as in theano.\nRight now I could use a double casting as a work around, but why is it different?\n", "comments": ["Yes, the gradient of floor is always zero.\n", "Well, almost always.\n", "Should it be as simple as changing:\n\n``` python\n@ops.RegisterGradient(\"Floor\")\ndef _FloorGrad(_, grad):\n  return grad  # return 0\n```\n\nin `python/ops/math_grad.py`? \n", "Yes, changing it to return `[None]` would be the fix.\n", "Thanks. Could you explain why `None` is preferred over 0 ?\nI observed that the gradient of `tf.cast(tf.cast(vif, tf.int32), tf.float32)` is also `None`, that's why I added   vif in the example code.\n", "`None` will be treated by the gradient code as \"no connection\", which is mathematically equivalent to zero but faster since it will never construct large zero matrices.  There's some related discussion here: #783.\n"]}, {"number": 896, "title": "Missing --recurse-submodules flag in ci_build instructions", "body": "In the file https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/README.md, the git clone command is missing the --recurse-submodules option flag, which will cause Bazel builds to fail on users' machines.\n", "comments": ["Want to send us a PR?\n", "Please see PR: https://github.com/tensorflow/tensorflow/pull/934\n"]}, {"number": 895, "title": "Udacity example 1: import urllib for download", "body": "Really minor, import urllib so the dataset download below just works the first time.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "I think this may be superceded by a change @vincentvanhoucke recently made ...\n", "Do you mean this one? https://github.com/tensorflow/tensorflow/commit/6e5a7d9af85d67ec1dd499b472472b68a56d51a2\n\nHow recently? I cloned around half an hour ago.\n", "Oh, I see. Updated to use urlretrieve from six as intended.\n", "@vincentvanhoucke already fixed this internally (we'll be pushing it out soon).\n"]}, {"number": 894, "title": "added //tensorflow/cc:cc_ops to //tensorflow:libtensorflow.so", "body": "Hey, I've wrapped tensorflow into openframeworks (http://openframeworks.cc/ ) was a massive PITA but more on that later :)\n\nI needed the c++ ops so I added that to the libtensorflow.so target. I believe this is the right way to do it?\n(I can confirm that it does work, I can create graphs in openframeworks. I'll make it all public once i've ironed out a few other things)\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@keveman @josh11b for more thoughts.\n\nAt a first glance, it might be better to create a separate target for this.  libtensorflow.so is, I think, meant to hold the core TF library.  cc_ops are just an API for defining the graph, which isn't really part of the core, so I'd be worried about conflating the two.  \n", "ah ok, fair enough. initially I did have it separate, but wasn't sure what to call it. I thought libtensorflow would be the lib of all of tensorflow, and the core would perhaps be libtensorflowcore? alternatively libtensorflow could stay as just core, and libtensorflowcc could be core+cc? either way works for me. \n", "The library for the graph building C++ API should be distinct and separate from libtensorflow.so, IMO. Perhaps make a separate libtensorflow_cc.so target for it?\n", "ok i've separated into a new target. libtensorflow.so is as it was before, libtensorflow_cc.so is core+cc. (i've also merged from upstream so it's up to date)\n", "ping for @keveman \n", "I was recommending separate library for building C++ ops, i.e., libtensorflow_cc.so containing only cc (not core + cc). But that's my opinion. Perhaps @josh11b can chime in?\n", "Hi @keveman I actually tried that but was getting errors when running. I can't remember the error exactly but something like \"could not start DEFAULT_SESSION\". Not sure if that's a bug of an error on my side?\n", "My recollection is that the library for building C++ ops depends on things like core/graph/graph_def_builder, which has other dependencies in core.  Were you thinking that libtensorflow_cc.so would have a dependency on the core so?\n", "Yes, libtensorflow_cc.so will have a dependency on libtensorflow.so.\n", "Can one of the admins verify this patch?\n", "Hi @memo: is this still being worked on / ready to look at?\n", "it's just a tiny change to the build file to add a lib with core+cc. I last used this build target 4 days ago to build 0.7 libs for linux and osx. ( https://github.com/memo/ofxMSATensorFlow ) . Just now updated my branch. \n", "Okay, sorry for the delay (our test machines were down).  can you re-merge one more time and squash the commits for one last look?\n", "ok up to date and commits cleaned up\n", "@tensorflow-jenkins: test this please\n", "Merged\n"]}, {"number": 893, "title": "While doing the assignment, I noticed that my train_dataset was getting trampled", "body": "My laptop loads the original data very slowly\n", "comments": ["Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 892, "title": "Corrected bug in Python code, wrong variable being used.", "body": "Corrected variable usage.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "LGTM @vrv \n", "@tensorflow-jenkins: test this please\n", "Merged. Thanks!\n"]}, {"number": 891, "title": "Clone 0.6.0 branch to use 0.6 branch", "body": "Master head is not bazel 0.1.1-compatible any more.\n", "comments": ["Can one of the admins verify this patch?\n", "Ha. You found a real problem here. You are correct that this is the right thing. I think I will change the installation instructions to say you'll be installing master, and fix the bazel version issue you noticed in 0.6.\n", "Take a look at #900. I change it to make clear that the installation instructions given will install the current master branch, and added what to do to install a specific release. I'll make another PR to make the same change in 0.6.0. It's not perfect, but if we add a bazel version number, it will get stale. I also don't want to encourage people to install the latest stable release from source -- I'd much prefer people installing from source work off master.\n", "My point is about how to compile TF 0.6 version, specifically. The documentation should specify clearly that master branch is NOT 0.6, and they should use latest bazel for latest TF. On the other hand, for TF 0.6, they should checkout 0.6 branch, and they MUST use bazel 0.1.1. That's it.\n"]}, {"number": 890, "title": "\"ImportError: No module named protobuf\" on El Capitan with VirtualEnv", "body": "Hello, \nWhen I try importing tensorflow in Python I get \"ImportError: No module named protobuf\".\n\nI followed instructions from here https://www.tensorflow.org/versions/0.6.0/get_started/os_setup.html#virtualenv_install and also updated protobuf:\n\nbrew reinstall --devel protobuf\n\nThe version I have is 3.0.0a3\n\nI looked at the issues here and all remedies don't seem to work. \n\nAny clue?\n\nThx\n", "comments": ["There is not nearly enough information for anybody to help.  If you add more information about your setup, what you've tried, etc., we might be able to offer help, and I'll reopen the issue.\n", "I apologize, I am new to this and wasn't sure what level of details is needed.\n\nHost: El Capitan 10.11.3\n\nRepro steps:\n$ sudo easy_install pip\n$ sudo pip install --upgrade virtualenv\n$ virtualenv --system-site-packages ~/tensorflow\n$ source ~/tensorflow/bin/activate\n(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n\nThen I tried to test\n\n$ python\n\n> > > import tensorflow as tf\n\nI got this:\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/xxx/tensorflow/lib/python2.7/site-packages/tensorflow/**init**.py\", line 4, in <module>\n    from tensorflow.python import *\n  File \"/Users/xxx/tensorflow/lib/python2.7/site-packages/tensorflow/python/**init**.py\", line 13, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/Users/xxx/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\nImportError: No module named protobuf\n\nthen I quit python and executed this:\n\n$ brew reinstall --devel protobuf\n\nthis command :\n$ pip freeze\n\nshows:\nprotobuf==3.0.0a3\n\nI then try again with python, same commands as above, and get the exact same error as above. \n\nPlease let me know if you need other kind of details. I will send them.\n\nThanks,\nPierre\n", "Exactly same question here. \n", "I had the same error and those steps worked for me (although I did not use any virtual environments):\n\n```\npip uninstall protobuf\npip install protobuf\npip install --upgrade protobuf==3.0.0a3\n```\n", "tried Grzego's approach. Got a new error though...\n\n`import tensorflow as tf\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 69, in <module>\n    from tensorflow.python.training import training as train\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/training.py\", line 149, in <module>\n    from tensorflow.python.training.saver import generate_checkpoint_state_proto\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 29, in <module>\n    from google.protobuf.any_pb2 import Any\nImportError: No module named any_pb2`\n", "ended up creating a new virtualenv and now it's working. noticed a new protobuf was installed \n'Successfully installed protobuf-3.0.0b2 tensorflow-0.7.1'\n", "I had the same problem on my Mac. Like @FiniteElementries, I ran into the error `No module named any_pb2`. Solution:\n\n```\npip uninstall protobuf\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl\n```\n\nAfter that, tensorflow works fine for me.\n", "Try this. Will likely solve the problem \nsudo pip install --upgrade protobuf==3.0.0b2\n", "I ran into the same problems, which are likely due to conflict with old versions.\nGot it run with:\nsudo pip uninstall protobuf\nsudo pip uninstall tensorflow\nand then install again tensorflow as said in the TF install page.\n", "as markusdr  said, it worked!  thanks!\npip uninstall protobuf\npip install /tmp/tensorflow_pkg/tensorflow*.whl\n", "On El Capitan 10.11.6 and within Virtualenv environment, I've got:\nImportError: No module named protobuf\nSo I did:\n(tensorflow) $ sudo -H pip install protobuf\n(tensorflow) $ sudo easy_install -U six\nThen,\n(tensorflow) $ python\n\n> > > import tensorflow as tf\n> > > hello = tf.constant('Hello, TensorFlow!')\n> > > sess = tf.Session()\n> > > print(sess.run(hello))\n> > > Hello, TensorFlow!\n> > > a = tf.constant(10)\n> > > b = tf.constant(32)\n> > > print(sess.run(a + b))\n> > > 42\n> > > So, it worked :)\n", "May want to look at this issue: https://github.com/tensorflow/tensorflow/issues/1415\nThere are workarounds mentioned there.\n", "I got the same problem. \n\nIt could be fixed by\n\nsudo pip install --upgrade protobuf\n\nand then protobuf-3.0.0 will be replaced by protobuf-3.1.0. Nailed it.\n", "I keep getting the following even after using the protobuf upgrade mentioned above. Any ideas?\r\n\r\nI'm on El Capitan 10.12.1 using Python 2.7.12\r\n\r\n```\r\n$ python\r\nPython 2.7.12 (default, Oct 11 2016, 05:20:59) \r\n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.38)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/node_def_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 22, in <module>\r\n    serialized_pb=_b('\\n/tensorflow/core/framework/resource_handle.proto\\x12\\ntensorflow\\\"m\\n\\x0eResourceHandle\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tB4\\n\\x18org.tensorflow.frameworkB\\x13ResourceHandleProtoP\\x01\\xf8\\x01\\x01\\x62\\x06proto3')\r\nTypeError: __init__() got an unexpected keyword argument 'syntax'\r\n>>> \r\n\r\n```", "This is a very annoying problem. I fixed the problem by following @markusdr.\r\nNote that the latest protobuf to date is 3.4.0, so I changed the command as this:\r\n\r\npip install --upgrade protobuf==3.4.0\r\n\r\nHope this helps!\r\n", "On Mac OS - Installing tensorflow 1.3 - it will automatically remove other protobuf installs and install protobuf 3.4. However, this does not work and neither does installing or downgrading to any other protobuf version.\r\n\r\nHowever I found a solution.\r\nNot sure why this works - but on Mac OS this solved it.\r\n\r\n    pip install google", "meet same problems.\r\npip uninstall tensorflow\r\npip install tensorflow\r\nit works for me"]}, {"number": 889, "title": "Large Strides for 1x1 Convolutions", "body": "When a conv2d operator has a stride greater than the kernel size, the following error is thrown:\n`ValueError: ('stride must be less than or equal to filter size', 'stride: [2x2] filter: [Dimension(1)xDimension(1)]')`\nThis makes implementing the 1x1 convolutions used to reduce spatial resolution in several papers (MSRA 2015 among others) awkward. Also, a convolution with stride greater than kernel size may be unusual but is it still well defined. Fixing this may be as simple as removing this assertion.\nThanks to everyone who developed TensorFlow, it's a fascinating tool.\n", "comments": ["I think this has been called 'atrous convolution', at least in the Eigen code.  Does anybody know whether cudnn supports this?  @zheng-xq ?  \n", "I don't think Cudnn supports convolutions for stride larger than 1. Not\nsure the FFT algorithm they were using would still be correct.\n\nOn Tue, Jan 26, 2016 at 10:56 AM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> I think this has been called 'atrous convolution', at least in the Eigen\n> code. Does anybody know whether cudnn supports this? @zheng-xq\n> https://github.com/zheng-xq ?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/889#issuecomment-175176178\n> .\n", "I stand corrected. The stride larger than 1 should be supported by Cudnn. I was looking at upscalex instead. \n", "it's not just stride > 1, it's stride > the input patch.  E.g., skipping regions of the input.\n\n@vincentvanhoucke just corrected me: atrous is introducing holes in the input patch, so the input has 'holes'.  So it's different.\n\nI don't know if our eigen (CPU) implementation supports stride > input_patch.  If it does, and cudnn does too, we can remove this assertion.\n", "FYI last week I did try to look at this and cudnn appeared to give different results than I expected (eigen was correct for both CPU and GPU).  Not yet sure whether this is a bug in cudnn or how we were calling it.\n", "The same error is thrown when calling `tf.nn.max_pool` or `tf.nn.avg_pool` with stride greater than filter size.\n", "I hit this bug while trying implement ResNet. I'm working around it by using a 2x2 kernel with all but the top-left zeroed out.\nhttps://github.com/ry/tensorflow-resnet/blob/2775805c4c4af3a3a082100c36a2b2f77791df4d/convert.py#L119-L122\n", "@ry I used resize_nearest_neighbour to circumvent that problem: https://github.com/cesarsalgado/tensorflowed/blob/master/models/residual_nets.py#L46 \n\nOr you could also use average pooling for sub-sampling, although it will not be exactly what the paper proposes. \n", "I'm marking this a bug since it really should work. Also contributions welcome. See also the recent duplicate #1815.\n", "@martinwicke I'd like to take a look at fixing it because I'm hitting this still. But I've never hacked on TF before, if you could give a rough outline of what's involved it'd help!\n", "@ry: I wish I could still find my code.  I remember Eigen doing something consistent across GPU and CPU and expected and cudnn doing something different (and seemingly wrong), but I might have introduced a bug.\n\nThe best thing to start with is via a test: add a simple test to conv_ops_test.py that exercises say, a 1x1 convolution with input depth 1 and output depth 1 for a 1x3x3x1 input with stride 2 (so you get four values: the corners multiplied by a filter).  \n\nIf you try to run that, you'll first run into a problem doing conv2d shape inference in python (because it checks for stride < filter) -- remove that and make sure that the shape calculation is correct.\n\nThen you'll probably have to make the same fix in the C++ code (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ops_util.cc#L41) to remove that check.\n\nOther than that, I don't think there was anything else I had to do to get the calls to run, but that's when I started seeing different output and didn't have time to debug.  It's possible it has something to do with padding or the shape inference difference between us and cudnn.  Happy to help how I can.\n"]}, {"number": 888, "title": "multiple GPU training out of memory ", "body": "When I run the cifar10_mutil_gpu_train.py example with 2 gpus, I got error message like the below, does this mean there is out of memory problem? How to solve or work around this?\nMy GPU is K80 so there are two K40 actually. \n\nPoolAllocator: After 2573 get requests, put_count=2268 evicted_count=1000 eviction_rate=0.440917 and unsatisfied allocation rate=0.546055\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\n", "comments": ["That message is not an \"out of memory\" error: it's just information about the status of the host-pinned memory allocator (e.g., it's useful for diagnosing poor performance) and is printed (hopefully) infrequently.\n\nIn general, messages that start with \"I\" are info logs.  Errors start with \"E\".\n"]}, {"number": 887, "title": "Use portable code in stringpiece.cc", "body": "A new pull request. It only has new commit.\n\nstd::min is defined in <algorithm>[1]. It should be included.\nmemmem is a GNU extension, std::search is standard.\n\n[1] http://en.cppreference.com/w/cpp/algorithm/minmax\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "test failure is due to flakiness, so this is probably fine.  assigning to @zheng-xq in case he knows of any performance implications of switching to std::search over memmem\n", "ping for @zheng-xq \n", "@tensorflow-jenkins: test this please\n\nFor the common case of simple short matches, std::search should be faster than memmem -- for the more pathlogical cases, memmem can be faster, but for most cases where the substrings don't overlap much, std::search should be preferred, so we'll take this change.\n", "Merged\n"]}, {"number": 886, "title": "Some error checking and user output notes", "body": "Hi,\n\nWhile running this it seems like the notebook hung but what really is happening is that notMNIST_large.tar.gz is taking a long time to extract. Also, since I looked at the contents of the directory a .DS_Store file was created. Re-sending pull request because of a mistake on earlier pull request.\n", "comments": ["Can one of the admins verify this patch?\n", "Merged\n"]}, {"number": 885, "title": "Keeps optional question format consisten", "body": "Added a newline to keep separation of optional questions from required tasks consistent and easier to read.\n", "comments": ["Can one of the admins verify this patch?\n", "LGTM @vrv \n"]}, {"number": 884, "title": "Some error checking and user output notes", "body": "Hi,\n\nWhile running this it seems like the notebook hung but what really is happening is that notMNIST_large.tar.gz is taking a long time to extract. Also, since I looked at the contents of the directory a .DS_Store file was created.\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "I signed it! ( the CLA) \n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "LGTM @vrv \n", "LG, squash the commits into one and we'll merge!\n", "Not sure how to do that with the GH interface. I made the changes in the web UI, not on git repo I checked out. None of the changes show up in my forked branch.\n"]}, {"number": 883, "title": "Build fails on Mac OSX 10.11.3 with `no type  named 'Scalar' in...`", "body": "Using the most recent commit \"a27d844e05447e65aa279ae5269a2d75590f46f6\" on Jan 25, 2016, the build fails with \n\n```\n./external/eigen_archive/eigen-eigen-\nc8e5d094f3a9/unsupported/Eigen/CXX11/src/Tensor/TensorContractionBlocking.h:29:31: error: no type\n named 'Scalar' in 'Eigen::internal::TensorContractionInputMapper<float, long, 0,\n Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 2>, const \nEigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long>, \n16> > >, Eigen::ThreadPoolDevice>, Eigen::array<long, 1>, Eigen::array<long, 1>, 4, true, true, 0>'\n  typedef typename RhsMapper::Scalar RhsScalar;\n```\n\nusing an older commit from Jan 21, 2016  \"e14090d217fc4e7e49ac04ccbc50acdba8b9f120\" completes normally.\n", "comments": ["FWIW, our builds on Jenkins are still working...\n", "same error as rizzomichaelg.\n", "I'm getting this same error on OS X as well.  Running OS X 10.10 + Xcode 7.2\n", "This error came with the commit \"19b3606\".\n", "It's not working on mac... \n", "I might revert 19b3606: can anyone confirm that reverting just that CL fixes the problem for them?\n", "Reverted the change that updated Eigen.  Let us know if this was not enough and we'll investigate further.\n", "Compiles!  Thanks for the help.\n"]}, {"number": 882, "title": "Fix training of decoder embeddings.", "body": "When `loop_function` is provided, `rnn_decoder` and `attention_decoder` do not propagate gradients over the loop function. However,  when `feed_previous` for `embedding_rnn_decoder`, `embedding_tied_rnn_seq2seq` and `embedding_attention_decoder` is `True`, the output symbols are embedded by the loop function `extract_argmax_and_embed`. The embedding for output symbols will learning nothing if there is no gradient propagating over the loop function.\n\nI think it will be better if the propagation of gradients is specified within the loop function itself instead of `rnn_decoder` and `attention_decoder`.\n", "comments": ["Can one of the admins verify this patch?\n", "ping for @ebrevdo \n", "Lukasz knows this code better.\n", "I'm not sure it's always better to propagate down to the embeddings, but indeed - it would be great to at least have the option. Before accepting the code I think it's necessary to correct the embedding_seq2seq models that define loop functions extract_argmax_and_embed -- these functions will not work at all without stop_gradients (as there is no gradient for argmax). I hope our tests will catch this.\n", "If the gradients don't propagate down to the embeddings, the input of the decoder RNN will be the random _initial values_ throughout the training. This might be weird, for example, when the embeddings for all words have the same initial values (word 'ils' corresponds to `[1, 0, 0, 0, 0]`, word 'personnes' corresponds to `[1, 0, 0, 0, 0]` too, ...).\nMaybe it will be better if the embeddings could learn something during the training. And if it is not the case, maybe we could replace the return value of `extract_argmax_and_embed`, which is now `return embedding_ops.embedding_lookup(embedding, prev_symbol)`, with `return array_ops.stop_gradient(embedding_ops.embedding_lookup(embedding, prev_symbol))`.\n\nI am not sure, but I think that gradients don't propagate down to the second parameter of `embedding_ops.embedding_lookup`. Could we replace `prev_symbol = array_ops.stop_gradient(math_ops.argmax(prev, 1))` in `extract_argmax_and_embed` with `prev_symbol = math_ops.argmax(prev, 1)` and add a comment on this?\n\n---\n\n(Edit)\n\n> these functions will not work at all without stop_gradients (as there is no gradient for argmax).\n\nIf we don't want to propagate gradients through the sampling decisions, why the absence of the gradient for `argmax` makes these functions fail?\n", "Can one of the admins verify this patch?\n", "In all cases, this patch needs a unit test.\n", "I'll try to come up with a test.\n", "When `feed_previous` is a boolean tensor, `embedding_rnn_seq2seq` will construct two `embedding_rnn_decoder` with `feed_previous=True` and `feed_previous=False`. During the course of training, gradients will propagate through the embeddings within the decoders when `feed_previous` is evaluated as false. \n\nHowever, when an user create `embedding_rnn_seq2seq` with `feed_previous=True`, there will be only one `embedding_rnn_decoder` with `feed_previous=True` in the model. It might be confusing that the embeddings within `embedding_rnn_decoder` learn nothing and remain as random initial values after training.\n\nTo control whether embeddings for symbols generated by the decoder itself will be updated during the course of training, a new parameter `update_embedding_for_previous` is added to `embedding_rnn_decoder` and `embedding_attention_decoder`. For example, the following two cases have the same effect:\n- Train `embedding_rnn_seq2seq` with `feed_previous=True`, which contains a `embedding_rnn_decoder` with `feed_previous=True` and `update_embedding_for_previous=True`. The decoder is fed with \"<Go>\" and outputs \"A, B, C\".\n- Train `embedding_rnn_seq2seq` with `feed_previous=False`. The decoder is fed with \"<Go>, A, B\".\n\nA test unit is added to check this.\n", "This change looks very good to me, let's merge and submit. Thanks for correcting this error!\n", "Jenkins, test this please.\n", "I see a conflict in this PRs future. A modified seq2seq is already on staging. I'd like to wait until we push this, and then resolve that conflict before we merge.\n", "Hi @martinwicke, \nI've resolved some conflicts.\n", "@tensorflow-jenkins: test this please\n", "Hi @vrv ,\nI added an empty line before the \"main\" line.\n", "@tensorflow-jenkins: test this please\n", "@tensorflow-jenkins: test this please\n", "Merged\n"]}, {"number": 881, "title": "Git branch 0.6.0 not showing", "body": "Hi,\nI've cloned the tensorflow repository (git clone https://github.com/tensorflow/tensorflow.git)\nand when I do \ngit branch -a \nit only appears master branch (\\* master) instead of \n*master\n0.6.0 \nas i though it should appear \nCan someone please help me?\nThanks\n", "comments": ["``````\n$ git branch -a -v\n* master                a27d844 Merge commit for internal changes\n  remotes/origin/0.6.0  8242b4d TensorFlow: some more python3 compatibility test fixes\n  remotes/origin/HEAD   -> origin/master\n  remotes/origin/master a27d844 Merge commit for internal changes```\n\n$ git checkout 0.6.0 -b 0.6.0\n\n$ git log -n 1\ncommit 8242b4dd1b36440e191fef8a07b6f37d8bcee60d\nAuthor: Vijay Vasudevan <vrv@google.com>\nDate:   Wed Dec 9 17:00:29 2015 -0800\n\n    TensorFlow: some more python3 compatibility test fixes\n\n    Change-Id: I5678cbdfb45757e2218494f542c9b0a0d5cc16a4\n``````\n\nSeems to works for me...\n", "Thanks a lot, missed the -v\n", "Again, only master branch showing:  \ngit init\nInitialized empty Git repository in /home/users/mcarbonell/tensorflow/.git/\nmcarbonell@asterix:~/tensorflow$ git pull https://github.com/tensorflow/tensorflow.git\nremote: Counting objects: 18687, done.\nremote: Total 18687 (delta 0), reused 0 (delta 0), pack-reused 18687\nReceiving objects: 100% (18687/18687), 24.33 MiB | 1.34 MiB/s, done.\nResolving deltas: 100% (13252/13252), done.\nFrom https://github.com/tensorflow/tensorflow\n- branch            HEAD       -> FETCH_HEAD\n  Checking out files: 100% (1853/1853), done.\n  mcarbonell@asterix:~/tensorflow$ git branch -a -v\n  - master 3e89c75 Merge pull request #1087 from tensorflow/fix-android-build.\n\ncan someone tell me why please?\n", "```\n$ git clone https://github.com/tensorflow/tensorflow.git  --recurse-submodules \n$ cd tensorflow\n$ git branch -r\n  origin/0.6.0\n  origin/HEAD -> origin/master\n  origin/master\n  origin/r0.7\n  origin/release-notes\n$ git branch 0.6.0\n$ git checkout 0.6.0\n```\n", "Thanks\n"]}, {"number": 880, "title": "Unable to run example convolutional.py", "body": "Hello,\nI did the three differents installations\nbased on pip\nbased on virtualenv \nbased on docker.\ni am on Virtual Machine (VM Virtual Box) with Ubuntu.\n\nand i have these errors when trying to run :\n\nroot@b6782358bd01:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist# python -m tensorflow.models.image.mnist.convolutional\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 290, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 121, in main\n    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 59, in maybe_download\n    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n  File \"/usr/lib/python2.7/urllib.py\", line 94, in urlretrieve\n    return _urlopener.retrieve(url, filename, reporthook, data)\n  File \"/usr/lib/python2.7/urllib.py\", line 240, in retrieve\n    fp = self.open(url, data)\n  File \"/usr/lib/python2.7/urllib.py\", line 208, in open\n    return getattr(self, name)(url)\n  File \"/usr/lib/python2.7/urllib.py\", line 352, in open_http\n    'got a bad status line', None)\nIOError: ('http protocol error', 0, 'got a bad status line', None)\n\ni did not suceed with the three methods. can anyone who has found these issues help me. Thanks in advance. Best Regards.\n", "comments": ["The server hosting MNIST is currently down.\n", "The source of the dataset http://yann.lecun.com/exdb/mnist/ is down since at least this past Sunday.  Anyone know of alternate URL?\n", "https://www.reddit.com/r/MachineLearning/comments/42ic2y/does_anyone_know_where_to_download_the_mnist/\nmight help.\n", "Great tip.  Thanks!!!\n\n@waoudi I got my\n\n```\npython -m tensorflow.models.image.mnist.convolutional\n```\n\nto work by modifying the line 37 of `/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py` to:\n\n```\nSOURCE_URL = 'https://github.com/HIPS/hypergrad/raw/master/data/mnist/'\n```\n\nHopefully http://yann.lecun.com/ will come back online soon.\n", "http://yann.lecun.com/exdb/mnist/ it is back again\n"]}, {"number": 879, "title": "Fix typo in Problem 1", "body": "Simple typo in the description.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "LGTM, awaiting CLA. Thanks!\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@seanpavlov looks like you need to rebase, I'm getting conflicts.\n", "Fix a-coming from upstream.\n"]}]