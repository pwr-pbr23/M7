[{"number": 33808, "title": "An implementation of eigendecomposition gradients", "body": "As for now, some tests yet failing, but I thought may be someone can help me by pointing out what my mistake is.", "comments": ["cc: @rmlarsen\r\nMaybe you can help?", "cc: @refraction-ray you've done a great job for SVD, can you take a look please? I'm clueless", "> cc: @refraction-ray you've done a great job for SVD, can you take a look please? I'm clueless\r\n\r\nI am not sure about the current status of this PR since all CI are still in queue. What nature are these failing tests? If it has something to do with the math underneath, i.e. there is already difference in numerical values of gradients between numerical differentiation and backprop formula, then I may have a look at the backprop formula for general complex eigen decompositions. If the failing cases are something due to tf inner test apis or setups, I am afraid that I cannot help much since I know very little in terms of these.", "@refraction-ray yeah, that's a bit inconvenient. The problem is the difference in numerical values of gradients between numerical differentiation and backprop formula, that's why I thought you might help. ", "> @refraction-ray yeah, that's a bit inconvenient. The problem is the difference in numerical values of gradients between numerical differentiation and backprop formula, that's why I thought you might help.\r\n\r\nI have numerically tested and read roughly about ad for general eigen decom in https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf. I believe there indeed might be some issues with diagonal elements of $U^{-1}dU$ which is taken as zero in the above paper. I will definitely look into this. ", "Thanks!", "I think I have found the answer, please check the reference https://arxiv.org/pdf/1701.00392.pdf, the correct formula for general eigen decomposition is 4.77 in this paper. \r\nNote the one in M. Giles. \u201cAn Extended Collection of Matrix Derivative Results for Forward and Reverse Mode Automatic Differentiation\u201d has one term missing somehow.\r\nBetter comment relevant references and especially their missing parts clearly in the comments of source code.", "Have you tested the corrected formula? The current version seems to still have inconsistencies with numeric gradients.", "> Have you tested the corrected formula? The current version seems to still have inconsistencies with numeric gradients.\r\n\r\nI am currently implementing backprop of general eigen in autograd based on the formula in 1701.00392. And I believe the formula is correct based on some numerical test. Could you share the loss function(objectives) in the failed case? It is worth noting that the order of eigenvalues returned by eig might be different even after slight change of parameters which should be taken care of.\r\n\r\nAlso, the loss function must be gauge invariant, i.e. f(E, U) = f(E, U\\Lambda) where \\Lambda is a diagonal matrix with phase elements e^{i\\theta}\r\n\r\n**Update**: if transformation matrix U is complex, there seems indeed some issue, I am looking at it now", "The gradient checking  the Jacobian, differentiating each entry of EV matrix by each entry of input (diagonalized matrix) -- https://github.com/tensorflow/tensorflow/pull/33808/files#diff-c4d84030401d2d3584cae9620c5c077bR240\r\nAs for gauge invariance, the eigenvectors are normalized so that first element is real which I think fixes the gauge", "It seems that the formula is correct when you add `tf.real` to the final results when the input matrix of eig is real. See https://github.com/HIPS/autograd/pull/543", "I do the casting for real types and still have failed tests for complex types too. I'll go through the code again. Thanks again", "I couldn't find any difference between our code, but the test are still failing. If I won't be able to pinpoint it, I'll probably will need to start comparing intermediate steps outputs for the same input...", "Practically, I am now pretty confident that the formula in 1701.00392 is correct since we now have another independent but more rigorous proof on that. \r\nTheoretically, I believe AD for general eig is a very good and deep problem, and thank you for bringing me to this point. The core of the problem still lies at the gauge freedom and how can we deal with such gauge freedom. By this problem, we have realized there is a bug in the original proof in AD for complex SVD case we have done two months ago (it doesn't affect the final ad formula, though).\r\nWe improved the proof for complex SVD case and built a similar proof on general eig case. Both of the proofs require some arts on gauge. \r\nHopefully, I will write up a post on gauge problem in AD soon.", "> I couldn't find any difference between our code, but the test are still failing. If I won't be able to pinpoint it, I'll probably will need to start comparing intermediate steps outputs for the same input...\r\n\r\nHave you conjugated `f`? Note `f=1/(Ei-Ej)` in this case is not necessarily real. And for gradient backprop formula which is the case for tensorflow, one should use conjugate of f. Note how tensorflow and autograd are different, one backprops gradient while the other backprops derivatives, which are different in complex number context. 4.77 is exactly suitable for tensorflow, so it should be `tf.conj(f)`.", "@refraction-ray Thank you, that was exactly the problem I missed.\r\n\r\n@gbaned @rmlarsen As for now the PR passes local tests, can you review it please?\r\n\r\nIn addition, it seems there is a problem with numeric calculation of gradient of `eig` if the input is real. I get the outputs of order of 1e6, which is the reason I turned off real inputs in tests. Possibly it has to do with the fact it has complex outputs. ", "@Randl I will review this, thanks.", "ping", "@rmlarsen is anything expected from me at this stage?", "@rmlarsen can you please review this PR ?", "ping @rmlarsen @gbaned", "@Randl  Can you please resolve conflicts? Thanks!", "@gbaned done. Anything else I can do to speed up the merge?", "I am not familiar enough with the code to review it.", "For anyone who would like to review this PR in the future, you can read this post: https://re-ra.xyz/Gauge-Problem-in-Automatic-Differentiation for reference on the problem setup and its solution. It is actually not an easy problem.", "ping @rmlarsen @gbaned", "I guess I'll keep pinging every month or so...  @rmlarsen @gbaned", "We don't have one, but it should be possible to make one for the\neigendecomposition only, which is numerically stable, just for this test?\n\nI am worried that this might regress for the most used dtypes if we don't\nhave a test.\n\nOn Mon, Apr 13, 2020 at 8:57 AM Evgeniy Zheltonozhskiy <\nnotifications@github.com> wrote:\n\n> *@Randl* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/kernel_tests/eig_op_test.py\n> <https://github.com/tensorflow/tensorflow/pull/33808#discussion_r407554178>\n> :\n>\n> > @@ -194,5 +262,10 @@ def Test(self):\n>            shape = batch_dims + (size, size)\n>            name = \"%s_%s_%s\" % (dtype.name, \"_\".join(map(str, shape)), compute_v)\n>            _AddTest(EigTest, \"Eig\", name, _GetEigTest(dtype, shape, compute_v))\n> -          # No gradient yet\n> +\n> +          # TODO: gradient_check gets wrong numeric output for real inputs\n> +          # (might be connected with the fact that outputs are complex)\n>\n> Is there alternative implementation? I though to try investigate the bug\n> in gradient_check after this get merged\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33808#discussion_r407554178>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMTAPQDWIGZMPRWDUTRMMY75ANCNFSM4JGEDJPA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp I fixed tests. It was a problem with sorting of the eigenvalues: eigen switched conjugate eigenvalues which resulted in strange gradients.", "@alextp can you run once again, please?", "@alextp Sorry, I think this time I managed to get code style right.", "Is there any problem? ", "@Randl I believe there is a mistake in your gradient test. You have:\r\n`v = array_ops.gather(v, idx, batch_dims=b_dims)`\r\nbut this sorts the rows of `v`, while the columns of `v` are the eigenvectors you want to sort. So it should be:\r\n`v = array_ops.matrix_transpose(array_ops.gather(array_ops.matrix_transpose(v), idx, batch_dims=b_dims))`"]}, {"number": 33807, "title": "TensorFlow pre-built package not available for download", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version: 2.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip using wheel\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nWe are not able to download the wheels given on page -> https://www.tensorflow.org/install/pip. We are getting the following error when we try to get the *.whl in a browser:\r\n\r\n<Error>\r\n<Code>NoSuchKey</Code>\r\n<Message>The specified key does not exist.</Message>\r\n<Details>\r\nNo such object: tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl\r\n</Details>\r\n</Error>\r\n\r\nThe issue occurs with all the links. We tried wget command on linux and get 404 error.\r\n \r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nwget https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33807\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33807\">No</a>\n", "Oops, I've accidentally closed this issue. (Don't know why exactly yet...) Sorry for the inconvenience.", "Strange! I meant to auto close it with  tensorflow/docs@89c6bbf56262. I'm not sure why github only noticed the copy in your fork... I do think this is fixed now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33807\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33807\">No</a>\n"]}, {"number": 33806, "title": " [ROCm] Fix for the broken ROCm CSB. ", "body": "This PR addresses to separate breaks in ROCm CSB\r\n\r\n### 1\r\n\r\nThe following commit breaks the `--config=rocm` build\r\n\r\nab65243\r\n\r\nThe commit above introduces the test \"test_opt_einsum_cached\" in //tensorflow/python:special_math_ops_test_gpu\r\n\r\nThe order of execution of other tests within that file can dictate whether or not the newly added test will pass or fail.\r\nThe failure (caught byt he ROCm Nighty CSB run) does not seem specific to the ROCm platform.\r\n\r\nThe \"fix\" is to explicitly clear the lru_cache of the routine \"special_math_ops._get_opt_einsum_contract_path\" (before running the test) to gurantee that the test will pass, irrespective of the order in which it is run relative to the other tests.\r\n\r\n-------\r\n\r\n### 2\r\n\r\nThe following commit breaks the `--config=rocm` build\r\n\r\nc8b0100\r\n\r\nThe commit above introduces the test \"testFusedBatchNormGradsInference\" in //tensorflow/python/eager:forwardprop_test_gpu\r\n\r\nWe are still working towards analysing the cause of the failure and potentially coming up with the fix. In meantime, the change in this commit is to skip the failing subtest on the ROCm platform. This is so that we can get he ROCm Nightly CSB build passing again.\r\n\r\n--------\r\n\r\n@whchung @chsigg ", "comments": ["@chsigg , please re-approve. I pushed out a new commit to fix the py_lint error. thanks", "@chsigg, gentle ping", "@gbaned gentle ping"]}, {"number": 33805, "title": "InTopKV2 cannot use k as a tensor", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n   Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\n    binary\r\n- TensorFlow version (use command below):\r\n   TF 1.0\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n   I try to use k as a tensor in InTopKV2 however, it tells me the k must be a scalar.\r\n   This is my code\r\n`input = tf.constant([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])\r\n k = tf.constant([2, 3])\r\n output = gen_nn_ops.in_top_kv2(input,[2,2],k)\r\n`\r\n![image](https://user-images.githubusercontent.com/22829190/67732568-c31ac400-fa36-11e9-91af-b7084f915877.png)\r\n   \r\n**Describe the expected behavior**\r\n   K can be used as 1-D tensor\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n![image](https://user-images.githubusercontent.com/22829190/67732046-24419800-fa35-11e9-8b40-e72d436ea757.png)\r\n", "comments": ["@593618638 \r\nLooks like code is incomplete.Please, provide simple standalone code, then it is easy for localizing the issue faster. Thanks !", "@593618638 \r\nPlease, let us know any update on this issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 33804, "title": "Does Tensorflowlite model support GPU boost on PC?", "body": "\r\nDoes Tensorflowlite model support GPU boost on PC? I can't find an example for supporting  GPU boost on PC, there're all examples for the mobile GPU boost or mobile CPU.", "comments": ["@huangshaoguang \r\nCan you go through the [link ](https://www.tensorflow.org/lite/performance/gpu)and see if it helps you.Thanks!", "@huangshaoguang \r\n\r\nCan you please let us know any update on this issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 33803, "title": "Enable tf.nn.bias_add python op tests to work in eager mode (as well as graph mode)", "body": "This current PR is a follow-on from [PR 31465](https://github.com/tensorflow/tensorflow/pull/31465) (Add GPU-deterministic tf.nn.bias_add). This current PR enhances the testing of the tf.nn.bias_add op to include eager as well as graph mode.", "comments": ["@duncanriach  Can you please resolve conflicts? Thanks!", "@gbaned, that was a pretty hairy rebase involving manual resolution of conflicts with changes made by @sanjoy yesterday, in which he added a `parameterized` decorator from `absl.testing`.\r\n\r\nI'm pretty sure I haven't broken anything (and I ran tests locally). The only issue I have now is that @sanjoy's changes prevented a work-around I was using in `tensorflow/python/kernel_tests/bias_op_deterministic_test.py` where it's not possible (currently) to use a `cached_session` with `force_gpu=True` for testing in both eager and graph mode. In the original pull request, before the `parameterized` decorator was added, I worked-around this by setting a non-cached session context, with `force_gpu=True`, outside the nested loops that provided the parameter combinations. With the `parameterized` decorator, I can no longer set the session context at that level.\r\n\r\n@sanjoy, please will you have a look at this for me and see if it's easy for you to suggest a better way of doing it? Go to post-merge line 79 in the diff for `tensorflow/python/kernel_tests/bias_op_deterministic_test.py`.", "> where it's not possible (currently) to use a `cached_session` with `force_gpu=True` for testing in both eager and graph mode.\r\n\r\nWhy do you need to use the cached session?  If that's only to make the test run faster then I'd say we can leave the change as is.", "@sanjoy: That's right. Just to make the test run faster. If you're happy with how this is, then so am I.\r\n@chsigg: Please will you re-review this?", "Looks like this is waiting on @chsigg \r\n\r\n(Gaurav, sorry for the notification spam.)", "History of this PR:\r\n* Nov 21, 2019: approved by @chsigg\r\n* Nov 21, 2019: CI revealed a tiny pylint error, which I resolved the same day. Re-review then pended.\r\n* Dec 10, 2019: I was informed of a conflict with another merge, which I resolved on the same day. Re-review then pended.\r\n* Dec 26, 2019: @sanjoy removed @chsigg re-review request, and seems to have left it without and requested review.\r\n\r\n@gbaned, please will you help me to get this reviewed and merged? Should it, or can it, be assigned to another, or an additional, reviewer?\r\n\r\nPS: I have come to understand that it's not actually helpful for me to rebase pull-request-branches after making small changes, when there are no conflicts (i.e. when an auto-rebase at merge is possible), because I imagine that it makes it much harder for reviewers to confidently recognize that I've only made a tiny incremental change on top of their prior review of my more extensive original changes. I apologize for any previous naivet\u00e9. It looks like I did do a force-push (possibly because of an unnecessary rebase) after fixing the tiny pylint error. I did, however, legitimately have to do a rebase to resolve the later conflict.", "I'll ping @chsigg internally to see if he can do another review or I'll find another reviewer.", "@duncanriach Could you please address Ubuntu Sanity errors? Thanks!", "Fixed Ubuntu Sanity error, then ran sanity locally. @chsigg, please will you re-approve following [this change](https://github.com/tensorflow/tensorflow/pull/33803/commits/4ea10c4bcc1ca3d98e34c6742220c2c8fe9df946).", "Hi @sanjoy, this PR has been `ready to pull` since January 10 (a month ago). Is there any way it can be moved closer to merge?", "@mihaimaruseac can you please help pull this PR manually. ", "Done"]}, {"number": 33800, "title": "Pull Requests: Trusted committers should be able to approve", "body": "@jenselofsson is a trusted external committer from Arm, but at least some of the PRs that he has approved have required an additional Google review on GitHub. I would expect that he would be able to review and approve pull requests. For an example, see PR https://github.com/tensorflow/tensorflow/pull/33420", "comments": ["/cc @jenselofsson @freddan80", "@petewarden \r\nIs this still an issue, could you please verify if all review access is provided as requested for so we may move this to closed status.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33800\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33800\">No</a>\n"]}, {"number": 33799, "title": "TF 2.0.0 Python 3.8 TypeError: _logger_find_caller() takes from 0 to 1 positional arguments but 2 were given", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  See script from Tensorflow training session and uploaded file below.  Nb: There is no error with TF2.0.0 and python 3.6 or 3.7.  The error occurs with TF2.0.0 and python 3.8.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: CUDA 10/cuDNN 7.6.4\r\n- GPU model and memory: NVidia RTX 2080 TI and 2080 MaxQ\r\n\r\n**Describe the current behavior**\r\n\r\nAfter running the code below (with the attached file), you get the following error:\r\n\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)\r\n    525         options=options, autograph_module=tf_inspect.getmodule(converted_call))\r\n--> 526     converted_f = conversion.convert(target_entity, program_ctx)\r\n    527 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert(entity, program_ctx)\r\n    324 \r\n--> 325   converted_entity_info = _convert_with_cache(entity, program_ctx,\r\n    326                                               free_nonglobal_var_names)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in _convert_with_cache(entity, program_ctx, free_nonglobal_var_names)\r\n    238 \r\n--> 239     nodes, converted_name, entity_info = convert_entity_to_ast(\r\n    240         entity, program_ctx)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_entity_to_ast(o, program_ctx)\r\n    474   elif tf_inspect.ismethod(o):\r\n--> 475     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n    476   elif hasattr(o, '__class__'):\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_func_to_ast(f, program_ctx, do_rename)\r\n    672   context = converter.EntityContext(namer, entity_info, program_ctx, new_name)\r\n--> 673   node = node_to_graph(node, context)\r\n    674 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in node_to_graph(node, context)\r\n    702   node = converter.standard_analysis(node, context, is_initial=True)\r\n--> 703   node = converter.apply_(node, context, function_scopes)\r\n    704   node = converter.apply_(node, context, arg_defaults)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py in apply_(node, context, converter_module)\r\n    408   node = standard_analysis(node, context)\r\n--> 409   node = converter_module.transform(node, context)\r\n    410   return node\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py in transform(node, ctx)\r\n    119 def transform(node, ctx):\r\n--> 120   return FunctionBodyTransformer(ctx).visit(node)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py in visit(self, node)\r\n    345     try:\r\n--> 346       return super(Base, self).visit(node)\r\n    347     finally:\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)\r\n    479     if not anno.hasanno(node, anno.Basic.SKIP_PROCESSING):\r\n--> 480       result = super(Base, self).visit(node)\r\n    481     self.ctx.current_origin = parent_origin\r\n\r\n/usr/local/lib/python3.8/ast.py in visit(self, node)\r\n    359         visitor = getattr(self, method, self.generic_visit)\r\n--> 360         return visitor(node)\r\n    361 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py in visit_FunctionDef(self, node)\r\n    101     \"\"\"\r\n--> 102     wrapped_body = templates.replace(\r\n    103         template,\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in replace(template, **replacements)\r\n    268   for node in nodes:\r\n--> 269     node = ReplaceTransformer(replacements).visit(node)\r\n    270     if isinstance(node, (list, tuple)):\r\n\r\n/usr/local/lib/python3.8/ast.py in visit(self, node)\r\n    359         visitor = getattr(self, method, self.generic_visit)\r\n--> 360         return visitor(node)\r\n    361 \r\n\r\n/usr/local/lib/python3.8/ast.py in generic_visit(self, node)\r\n    435                     if isinstance(value, AST):\r\n--> 436                         value = self.visit(value)\r\n    437                         if value is None:\r\n\r\n/usr/local/lib/python3.8/ast.py in visit(self, node)\r\n    359         visitor = getattr(self, method, self.generic_visit)\r\n--> 360         return visitor(node)\r\n    361 \r\n\r\n/usr/local/lib/python3.8/ast.py in generic_visit(self, node)\r\n    444             elif isinstance(old_value, AST):\r\n--> 445                 new_node = self.visit(old_value)\r\n    446                 if new_node is None:\r\n\r\n/usr/local/lib/python3.8/ast.py in visit(self, node)\r\n    359         visitor = getattr(self, method, self.generic_visit)\r\n--> 360         return visitor(node)\r\n    361 \r\n\r\n/usr/local/lib/python3.8/ast.py in generic_visit(self, node)\r\n    435                     if isinstance(value, AST):\r\n--> 436                         value = self.visit(value)\r\n    437                         if value is None:\r\n\r\n/usr/local/lib/python3.8/ast.py in visit(self, node)\r\n    359         visitor = getattr(self, method, self.generic_visit)\r\n--> 360         return visitor(node)\r\n    361 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in visit_Name(self, node)\r\n    199 \r\n--> 200     new_nodes = self._prepare_replacement(node, node.id)\r\n    201 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in _prepare_replacement(self, replaced, key)\r\n    138 \r\n--> 139     new_nodes = ast_util.copy_clean(repl, preserve_annos=self.preserved_annos)\r\n    140     if isinstance(new_nodes, gast.AST):\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy_clean(node, preserve_annos)\r\n     75   \"\"\"\r\n---> 76   return CleanCopier(preserve_annos).copy(node)\r\n     77 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)\r\n     53       if not f.startswith('__') and hasattr(node, f):\r\n---> 54         new_fields[f] = self.copy(getattr(node, f))\r\n     55     new_node = type(node)(**new_fields)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)\r\n     40     if isinstance(node, list):\r\n---> 41       return [self.copy(n) for n in node]\r\n     42     elif isinstance(node, tuple):\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in <listcomp>(.0)\r\n     40     if isinstance(node, list):\r\n---> 41       return [self.copy(n) for n in node]\r\n     42     elif isinstance(node, tuple):\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)\r\n     54         new_fields[f] = self.copy(getattr(node, f))\r\n---> 55     new_node = type(node)(**new_fields)\r\n     56 \r\n\r\n~/tf38/lib/python3.8/site-packages/gast/gast.py in create_node(self, *args, **kwargs)\r\n      9         nbparam = len(args) + len(kwargs)\r\n---> 10         assert nbparam in (0, len(Fields)), \\\r\n     11             \"Bad argument number for {}: {}, expecting {}\".\\\r\n\r\nAssertionError: Bad argument number for keyword: 1, expecting 2\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-10-8b26b7af23a7> in <module>\r\n----> 1 tf_model.fit(Xs_train[:, 0:1], y_train.reshape(-1, 1));\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    613       # This is the first call of __call__, so we have to initialize.\r\n    614       initializers = []\r\n--> 615       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    616     finally:\r\n    617       # At this point we know that the initialization is complete (or less\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    494     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)\r\n    495     self._concrete_stateful_fn = (\r\n--> 496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n    497             *args, **kwds))\r\n    498 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2363       args, kwargs = None, None\r\n   2364     with self._lock:\r\n-> 2365       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2366     return graph_function\r\n   2367 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2671 \r\n   2672       self._function_cache.missed.add(call_context_key)\r\n-> 2673       graph_function = self._create_graph_function(args, kwargs)\r\n   2674       self._function_cache.primary[cache_key] = graph_function\r\n   2675       return graph_function, args, kwargs\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2551     arg_names = base_arg_names + missing_arg_names\r\n   2552     graph_function = ConcreteFunction(\r\n-> 2553         func_graph_module.func_graph_from_py_func(\r\n   2554             self._name,\r\n   2555             self._python_function,\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    956                                           converted_func)\r\n    957 \r\n--> 958       func_outputs = python_func(*func_args, **func_kwargs)\r\n    959 \r\n    960       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    438         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    440     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    441 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in bound_method_wrapper(*args, **kwargs)\r\n   3179     # However, the replacer is still responsible for attaching self properly.\r\n   3180     # TODO(mdan): Is it possible to do it here instead?\r\n-> 3181     return wrapped_fn(*args, **kwargs)\r\n   3182   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)\r\n   3183 \r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    935           # TODO(mdan): Push this block higher in tf.function's call stack.\r\n    936           try:\r\n--> 937             return autograph.converted_call(\r\n    938                 original_func,\r\n    939                 args,\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)\r\n    552           'Cause: %s', target_entity, e)\r\n    553     else:\r\n--> 554       logging.warn(\r\n    555           'AutoGraph could not transform %s and will run it as-is.\\n'\r\n    556           'Please report this to the TensorFlow team. When filing the bug, set'\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/utils/ag_logging.py in warn(msg, *args, **kwargs)\r\n    144 \r\n    145 def warn(msg, *args, **kwargs):\r\n--> 146   logging.warn(msg, *args, **kwargs)\r\n    147   if echo_log_to_stdout:\r\n    148     _output_to_stdout('WARNING: ' + msg, *args, **kwargs)\r\n\r\n~/tf38/lib/python3.8/site-packages/tensorflow_core/python/platform/tf_logging.py in warn(msg, *args, **kwargs)\r\n    159 @tf_export(v1=['logging.warn'])\r\n    160 def warn(msg, *args, **kwargs):\r\n--> 161   get_logger().warning(msg, *args, **kwargs)\r\n    162 \r\n    163 \r\n\r\n/usr/local/lib/python3.8/logging/__init__.py in warning(self, msg, *args, **kwargs)\r\n   1444         \"\"\"\r\n   1445         if self.isEnabledFor(WARNING):\r\n-> 1446             self._log(WARNING, msg, args, **kwargs)\r\n   1447 \r\n   1448     def warn(self, msg, *args, **kwargs):\r\n\r\n/usr/local/lib/python3.8/logging/__init__.py in _log(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\r\n   1563             #IronPython can use logging.\r\n   1564             try:\r\n-> 1565                 fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\r\n   1566             except ValueError: # pragma: no cover\r\n   1567                 fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\r\n\r\nTypeError: _logger_find_caller() takes from 0 to 1 positional arguments but 2 were given\r\n\r\n**Describe the expected behavior**\r\n\r\nThere should be no error.  It works fine with TF2.0.0 and Python 3.6 or Python 3.7.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport gzip\r\nimport json\r\nfrom sklearn.model_selection import ShuffleSplit\r\n\r\nwith gzip.open(\"small_data/cal_house.json.gz\", \"r\") as fin:\r\n    housing = json.load(fin)\r\n    \r\nfor train, test in ShuffleSplit(1, 0.2, random_state=42).split(housing['data']):\r\n    X_train = np.array(housing['data'])[train].astype(np.float32)\r\n    y_train = np.array(housing['target'])[train].astype(np.float32)\r\n    X_test = np.array(housing['data'])[test].astype(np.float32)\r\n    y_test = np.array(housing['target'])[test].astype(np.float32)\r\n\r\nX_mean = X_train.mean(axis=0)\r\nX_std = X_train.std(axis=0)\r\n\r\nXs_train = (X_train - X_mean) / X_std\r\nXs_test = (X_test - X_mean) / X_std\r\n\r\nclass LinearRegressionTF():\r\n    def __init__(self, eta=.1):\r\n        self.W = tf.Variable(0.)\r\n        self.b = tf.Variable(0.)\r\n        self.opt = tf.keras.optimizers.SGD(learning_rate=eta)\r\n    \r\n    def loss(self, X, y, return_func=False):\r\n        def loss_():\r\n            return tf.reduce_mean(tf.square(X * self.W + self.b - y))\r\n        \r\n        if not return_func:\r\n            return loss_()\r\n        \r\n        return loss_\r\n\r\n    @tf.function\r\n    def fit(self, X, y, steps=1):\r\n        for _ in range(steps):\r\n            self.opt.minimize(self.loss(X, y, return_func=True), [self.W, self.b])\r\n\r\ntf_model = LinearRegressionTF()\r\n\r\ntf_model.fit(Xs_train[:, 0:1], y_train.reshape(-1, 1));\r\n\r\n[cal_house.json.gz](https://github.com/tensorflow/tensorflow/files/3780890/cal_house.json.gz)\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nNil", "comments": ["@dbonner \r\n\r\nI tried to reproduce the issue. However i am seeing the different error.`AttributeError: 'LinearRegressionTF' object has no attribute 'fit'` .Please, help me with the reproducible code . It helps in localizing the issue faster.", "@ravikyram \r\nI'm sorry the code is not properly indented in a number of places when it appears in github.  I can't seem to edit it to get it to show properly.  Please find an attached file (moved to next post)  with the properly indented code that reproduces this error on my system when running in one cell in Jupyter Notebook.\r\nApologies .... See the next post for the correct file.", "@ravikyram \r\nI've finally got this right.  Sorry to mess you around with this.  Github markdown removed the underscores on the init part of the LinearRegressionTF() class when I pasted it in.  This got transferred through to the code file.  The correct code is attached.  It runs fine in Python 3.7 but errors in Python 3.8.  I have also removed the reference to the subdirectory \"small_data\" so you can run the code with the file \"cal_house.json.gz\" in the current working directory.\r\n[code_py38_tf2_error.txt](https://github.com/tensorflow/tensorflow/files/3786825/code_py38_tf2_error.txt)\r\n[cal_house.json.gz](https://github.com/tensorflow/tensorflow/files/3786826/cal_house.json.gz)\r\n\r\n", "Hi @ymodak,\r\nHave you had a chance to test the python 3.8 error I reported (Issue: #33799).\r\nAll the best,\r\nDan", "I am able to reproduce the issue with the following command on python 3.8 (master build):\r\n```\r\nbazel test -s --verbose_failures --disk_cache=/home/ubuntu/bazel \\\r\n        //tensorflow/python:image_ops_test\r\n```\r\n\r\nHaven't figure out the reason yet.", "@dbonner @ymodak Added a PR #33953 for the fix. Please take a look.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33799\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33799\">No</a>\n", "I recieved this error also when using tensorflow 1.13.2 + python 3.8 I am considering opening a separate issue. "]}, {"number": 33798, "title": "Pull Requests: Ubuntu CC test is flakey", "body": "When testing pull requests the \"Ubuntu CC\" test seems to never(?) complete. See two examples here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/33492\r\nhttps://github.com/tensorflow/tensorflow/pull/32168\r\n\r\nThis makes it hard to for contributors to tell if their changes have broken the project, or if it's an unrelated flake (as it seems to be in these cases). This is the most obvious example of the problem, but we see many unrelated failures on the CI tests for PRs.", "comments": ["/cc @jenselofsson", "/cc @freddan80", "BTW, I think CI should run automatically after each commit.  ", "Unfortunately, running CI automatically for each commit is not something we can do at the moment, due to the restrictions put on us by the service we are using.\r\n", "Main issue right now is that the test seems to hang. It never finishes. Many PR's have been in this limbo for weeks. There's no link or status indication for us to see what actually is going on, all we see is this:\r\n\r\n![image](https://user-images.githubusercontent.com/15377492/68010677-81338d00-fc85-11e9-8570-bf3d9656bd05.png)\r\n\r\nThe same goes for most PR's here:\r\nhttps://github.com/tensorflow/tensorflow/labels/comp%3Amicro\r\n\r\nWhat exactly does this test do? ", "This one is also failing.  How can we fix this?  #33553 ", "@gunan removed \"Ubuntu CC\" from the GitHub setting."]}, {"number": 33797, "title": "Which ssd model to use to generate the smallest tflite for a lite>experimental>micro project?", "body": "Hi, I have asked [this](https://stackoverflow.com/questions/58595004/how-to-obtain-a-small-tflite-file) question on stack overflow and I am going to ask the same thing here; Furthermore I would like to know if the lite>experimental>micro project is still under developing; In particular:\r\n\r\n- I cannot execute the MUL operation, will it be ever available for the micro sub-project?\r\n- If not, can I rely on previous ssd mobilenets (v1 or v2)  in order to execute an object-detection?\r\n- Which ssd model do you suggest to generate the smallest object detection model?\r\n- And more important, I would ask you if there is something that I have missed on the documentation/process that I have done (more details on the posted question) in order to generate the .cc file to be run on the microcontroller.\r\n\r\nThank you for your attention.", "comments": ["The micro project is still under development and ops are still being added.  The MUL op hasn't been added yet, but it is on the todo list.  Maybe @MeghnaNatraj can offer some advice with respect to SSD models.", "> The micro project is still under development and ops are still being added. The MUL op hasn't been added yet, but it is on the todo list. Maybe @MeghnaNatraj can offer some advice with respect to SSD models.\r\n\r\nThank you for your reply.", "The [TensorFlow Object detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) has many pre-trained models and is the best resource to get started with SSD models. Most users pick a pre-trained model and use transfer learning to customize it (similar to your use-case). Unfortunately, even the smallest ones (mobilenet V1/V2/V3 models) target mobile devices (few MBs) and not embedded. So currently, there are 3 options:\r\n\r\n1. Experimenting with the smallest pre-trained mobilenet models - (eg: ssd_mobilenet_v1_0.75_depth_quantized_coco, ssd_mobilenet_v1_ppn_coco, ssd_mobilenet_v2_quantized_coco, ssdlite_mobilenet_v2_coco, ssd_mobilenet_v3_small_coco)\r\nHave you tried using the v1 and v2 models and do any of them fit your memory constraints? (Will discuss v3 in the next section)\r\n2. [Training your own model ](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/defining_your_own_model.md) or using [embedded mobilenet config](https://github.com/tensorflow/models/blob/master/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py). Unfortunately, this would require a lot of effort.\r\n\r\nFor ssd_mobilenet_v3_small_coco, I [visualized the model.tflite file ](https://www.tensorflow.org/lite/guide/faq#how_do_i_inspect_a_tflite_file) to check all the ops which are required. They are listed below:\r\n```\r\nindex\tbuiltin_code\t  custom_code\tversion\r\n0\tADD\t          None\t        1\r\n1\tAVERAGE_POOL_2D\t  None\t        1\r\n2\tCONCATENATION     None\t        1\r\n3\tCONV_2D\t          None\t        1\r\n4\tDEPTHWISE_CONV_2D None\t        1\r\n5\tDEQUANTIZE\t  None\t        1\r\n6\tMUL\t          None\t        1\r\n7\tRESHAPE\t          None\t        1\r\n8\tHARD_SWISH\t  None\t        1\r\n```\r\nWhen we [compare this to the list of currently supported ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/kernels/all_ops_resolver.cc), we can see that the unsupported ops are: CONCATENATION (work in progress), MUL (work in progress) and HARD_SWISH (will be prioritized).\r\n\r\nNow back to your questions:\r\n1. I cannot execute the MUL operation, will it be ever available for the micro sub-project? \r\n> It's a work in progress, we'll update this thread once it's complete. #TODO\r\n2. If not, can I rely on previous ssd mobilenets (v1 or v2) in order to execute an object-detection? \r\n> Yes!\r\n3. Which ssd model do you suggest to generate the smallest object detection model? \r\n> Answered above in 1) Experimenting with the smallest .....\r\n4. And more important, I would ask you if there is something that I have missed on the documentation/process that I have done (more details on the posted question) in order to generate the .cc file to be run on the micro controller. \r\n> There are no issues in your process, however, you can try visualizing/inspecting the tflite model to check what ops are required and ensure they are all supported before converting them. This can save your time as you can ensure all ops are supported at once vs trying to convert it to a cc file and finding a new unsupported op error every time. eg: Here, the conversion failed for one op (eg: MUL), and you would've missed that the model also requires 2 additional unsupported ops. \r\n\r\n\r\n", "CONCATENATION and MUL have been implemented. Could you confirm if you're still blocked on this issue and require the HARD_SWISH op. It's a high priority, but currently we cannot provide an estimated completion date. If you could use another activation function until this is implemented, it could solve the issue temporarily.\r\n", "Received no response; Marking issue as closed.", "Hi, MeghnaNatraj, I have a question related to this issue. I am working on object detection using TFLite micro + SSD model. For ssd_mobilenet_v3_small_coco, the last operator is TFLite_Detection_PostProcess. I couldn't find the support for this operator in TFLite micro. Could you give me some guide?", "Hi @alisonwh! We do have support for this operation in TFLite Micro:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/detection_postprocess.cc\r\n\r\nWe haven't yet created an example, documentation, or end to end test cases for it yet though, but hopefully you should be able to use it by just exporting your model and loading it into the interpreter. Drop us an email at micro@tensorflow.org if you do hit problems.", "@petewarden Thank you very much for your reply. I will try to use this operator and send you an email if I meet problems.", "@petewarden I tried to send an email to micro@tensorflow.org, but it failed with the information that \"We're writing to let you know that the group you tried to contact (micro) may not exist, or you may not have permission to post messages to the group. \"", "@petewarden My question is as below:\r\n\r\nI am working on object detection based on Arm Cortex-M7 + TFLite Micro. The model I used is SSD mobilenet v1 quantized.\r\n\r\nUsing https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/detection_postprocess.cc, the previous issue about operator DETECTION_POSTPROCESS is not registered has been fixed. Thanks for your help.\r\n\r\nNow the application runs to interpreter invoke function. It fails at operator LOGISTIC invoke function. The reason is the input tensor type is UINT8. It is not supported yet as below.\r\n\r\n// TODO(b/141211002): Also support other data types once we have supported\r\n    // temporary tensors in TFLM.\r\n    TF_LITE_KERNEL_LOG(context, \"Input %s, output %s not supported.\",\r\n                       TfLiteTypeGetName(input->type),\r\n                       TfLiteTypeGetName(output->type));\r\n\r\nMay I ask when will you add this support? Or do you have some suggestions for this problem? ", "> @petewarden My question is as below:\r\n> \r\n> I am working on object detection based on Arm Cortex-M7 + TFLite Micro. The model I used is SSD mobilenet v1 quantized.\r\n> \r\n> Using https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/detection_postprocess.cc, the previous issue about operator DETECTION_POSTPROCESS is not registered has been fixed. Thanks for your help.\r\n> \r\n> Now the application runs to interpreter invoke function. It fails at operator LOGISTIC invoke function. The reason is the input tensor type is UINT8. It is not supported yet as below.\r\n> \r\n> // TODO(b/141211002): Also support other data types once we have supported\r\n> // temporary tensors in TFLM.\r\n> TF_LITE_KERNEL_LOG(context, \"Input %s, output %s not supported.\",\r\n> TfLiteTypeGetName(input->type),\r\n> TfLiteTypeGetName(output->type));\r\n> \r\n> May I ask when will you add this support? Or do you have some suggestions for this problem?\r\n\r\nHello. I am also working on ssd with stm32. Have you solve the problem ? ", "@furknclk I have solved the problem. This is my patch https://github.com/tensorflow/tensorflow/pull/46873/commits. It has not been merged yet. Anyway, you can try it.", "@alisonwh I really dont understand and find  a source about that how should  be the mcu code arcitecht . Ssd seems totaly different from other examples. where did you find source. And what is your main code look like. Thanks  lots."]}, {"number": 33796, "title": "tf.data.Dataset.from_generator triggers a SIGBUS signal when operating with numpy arrays", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nOSX Mojave 10.14.6 \r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n\r\n- TensorFlow installed from (source or binary):\r\nBinray\r\n- TensorFlow version (use command below):\r\nGIT v2.0.0-rc2-26-g64c3d382ca \r\nTensorflow 2.0.0\r\n\r\n- Python version: \r\nPython 3.6.8\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nOn cpu\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nClean virtualenv with tensorflow==2.0.0 installed \r\ntf.data.Dataset.from_generator raises a SIGBUS when operating on large enough Numpy arrays \r\n\r\nUsing \r\ntf_dataset = tf.data.Dataset.from_generator(gen_callable,\r\n                                                output_types=(tf.float32),\r\n                                                output_shapes=(None, 3))\r\nwith a function that generates and operates on medium sized numpy arrays triggers a SIGBUS signal.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo SIGUS should be raised\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### NOT A CONTRIBUTION\r\n```\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef foo(x, R):\r\n    return np.matmul(x, R)\r\n\r\n\r\ndef baz(x, R):\r\n    return foo(x, R)\r\n\r\n\r\ndef bar(x, R):\r\n    registered_x = baz(\r\n        x, R\r\n    )\r\n    return registered_x\r\n\r\n\r\ndef gen_callable():\r\n    for i in range(1):\r\n        R = np.eye(3).astype(np.float32)\r\n        x = np.random.randn(40000, 3).astype(np.float32)\r\n        prod = bar(\r\n            x, R\r\n        )\r\n        yield prod\r\n\r\n\r\ndef make_tf_generator():\r\n    tf_dataset = tf.data.Dataset.from_generator(gen_callable,\r\n                                                output_types=(tf.float32),\r\n                                                output_shapes=(None, 3))\r\n\r\n    for d in tf_dataset:\r\n        print(d)\r\n\r\nif __name__ == '__main__':\r\n    make_tf_generator()\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\noutput of pip freeze \r\n\r\nabsl-py==0.8.1\r\nastor==0.8.0\r\ngast==0.2.2\r\ngoogle-pasta==0.1.7\r\ngrpcio==1.24.1\r\nh5py==2.10.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nMarkdown==3.1.1\r\nnumpy==1.17.2\r\nopt-einsum==3.1.0\r\nprotobuf==3.10.0\r\nsix==1.12.0\r\ntensorboard==2.0.0\r\ntensorflow==2.0.0\r\ntensorflow-estimator==2.0.0\r\ntermcolor==1.1.0\r\nWerkzeug==0.16.0\r\nwrapt==1.11.2\r\n", "comments": ["Apologies for the delay in response. I was able to execute your script successfully using TF 2.1.0-rc1.\r\n```python\r\ntf.Tensor(\r\n[[-0.31721887  1.0121828   0.18239886]\r\n [-0.23083398 -1.3029127  -1.4065455 ]\r\n [-0.05021447  0.17920735  0.6323469 ]\r\n ...\r\n [ 0.8527863  -0.31213287  0.14148703]\r\n [ 1.2265248  -1.2042834  -0.91572493]\r\n [-2.5031376  -1.3834713   1.367332  ]], shape=(40000, 3), dtype=float32)\r\n```"]}, {"number": 33795, "title": "Anaconda tensorflow-gpu faulty package?", "body": "Using [`conda install -c anaconda tensorflow-gpu`](https://anaconda.org/anaconda/tensorflow-gpu) yields the pre-installation message below, showing that cuDNN 7.6.0 will be installed _against_ the TensorFlow GPU [compatibility table](https://www.tensorflow.org/install/source_windows#gpu). `pip` install does _not_ include cuDNN. Further, I already have cuDNN 7.4.2 installed per [official instructions](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows) with paths [set up](https://www.tensorflow.org/install/gpu#windows_setup).\r\n\r\nEither the compatibility table is outdated, or the Anaconda package is faulty - which is it?\r\n\r\n<hr>\r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/67711092-ae104780-f9da-11e9-8651-dad5ff602319.png\" width=\"550\">\r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/67711269-13fccf00-f9db-11e9-9f13-53e5fab60bfc.png\" width=\"650\">", "comments": ["**UPDATE**: proceeded w/ Conda install, it worked - but only after installing `keras_applications` and `keras_preprocessing` via `pip`. Thus, the compatibility table appears outdated. \r\n\r\nI remain unsure how Conda's 7.6 install doesn't conflict with my manual 7.4 install, however.", "The compatibility table tells us about the configurations which are tested and were able to build TF successfully. However it does not cover all successful build configurations but only a subset of it.\r\nSo the [tested build configurations table](https://www.tensorflow.org/install/source_windows#tested_build_configurations) is not outdated.\r\nI will close this issue now since you are able to install TF. Thanks!", "@ymodak While I've made an install, I now face a compatibility issue w/ Keras 2.3.1 - latter aside, my question on cuDNN compatibility remains: can cuDNN 7.4.2 installed from source, manually, run with cuDNN 7.6.0 installed by Anaconda (into a conda environment w/ TF2 install)? I can open a separate issue on this if needed.", "We do not build anaconda packages ourselves.\r\nTherefore, I am not sure.\r\nAnaconda or the community may be building TF with different cuda/cudnn versions than we are doing, so that table there does not apply to what you download from anaconda.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33795\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33795\">No</a>\n"]}, {"number": 33794, "title": "[TF 2.0 API Docs] tf.keras.layers.simpleRNN", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/SimpleRNN\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe document mentions nothing about call argument `inputs` when it takes \r\n`[[batch, timesteps, feature], [batch, state]]`. In case of `inputs` is a list, the elements of `inputs[1:]` work as initial_state in each batch.\r\n\r\nExample)\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\n\r\n\r\nclass foo(tf.keras.Model):\r\n    def __init__(self, rnn_units, dense_units, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.r1 = SimpleRNN(rnn_units)\r\n        self.r2 = SimpleRNN(rnn_units)\r\n        self.flat = tf.keras.layers.Flatten()\r\n        self.d1 = Dense(rnn_units)\r\n        self.d2 = Dense(dense_units)\r\n\r\n    def call(self, inputs, **kwargs):\r\n\r\n        x = self.r1(inputs)\r\n        state = self.d1(self.flat(x))\r\n        x = self.r2([inputs, state])\r\n        x = self.d2(x)\r\n\r\n        return x\r\n\r\n\r\ntrain_input = tf.random.normal(shape=(6, 5, 10))\r\ntrain_target = tf.random.normal(shape=(6, 8))\r\n\r\na = foo(10, 8)\r\na.compile(tf.keras.optimizers.SGD(0.01), loss=tf.keras.losses.MeanSquaredError())\r\na.fit(train_input, train_target)\r\n\r\n\r\nb = SimpleRNN(10)(train_input)\r\nstate = Dense(10)(tf.reshape(b, (tf.shape(b)[0], -1)))\r\nb = SimpleRNN(10)([train_input, state])\r\n```\r\n\r\nIt also should be noted that `initial_state` argument should be `None` when `inputs` has states.\r\nOther recurrent layers have same issue.\r\n\r\n### Submit a pull request?\r\nIf this issue was not intended or a bug,\r\nI'm planning to submit a pull request to fix the doc issue in a week. May i?", "comments": ["@brorro Are you interested in submitting a PR to update the docs? Please feel free to send PR and add a note here so that we can track. Thanks!", "@jvishnuvardhan I will. Thank you", "I am willing to take up this issue", "@SumanSudhir Happy to hear that. I tried this but cannot find any documents to create my edited api docs.. it only creates unmodified one.", "@brorro \r\nIs this still an issue.", "This is updated in recent TF version. Please check the page https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if this is still an issue. Thanks!"]}, {"number": 33793, "title": "DenseFeatures always returns float32", "body": "(https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, a call to `tf.keras.layers.DenseFeatures` returns `float32` no matter what.\r\nIt doesn't respect its own `dtype` (e.g., `DenseFeatures(..., dtype=tf.float64)`\r\nis not working). Using `tf.keras.backend.set_floatx('float64')` does not change\r\nthe behavior, either. It will be nice if a user can choose to return `float64`.\r\nOr at least respect the setting of `tf.keras.backend.set_floatx(...)`.\r\n\r\nThis behavior is not mentioned in the API documentation:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures\r\n\r\nBut it is mentioned in the docstring of `DenseFeatures.call`:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/feature_column/dense_features.py#L119-L122\r\n\r\nHere's a simple sample code:\r\n```\r\nimport numpy\r\nimport tensorflow as tf\r\n\r\nnumpy.set_printoptions(15)\r\n\r\ncolumns = [\r\n    tf.feature_column.numeric_column(\"a\", dtype=tf.float64),\r\n    tf.feature_column.numeric_column(\"b\", dtype=tf.float64)\r\n]\r\n\r\nlayer = tf.keras.layers.DenseFeatures(columns, dtype=tf.float64)\r\n\r\ndata = {\r\n    \"a\": tf.constant([1./3.], dtype=tf.float64),\r\n    \"b\": tf.constant([numpy.pi], dtype=tf.float64)\r\n}\r\n\r\nprint(\"\\n\"+\"-\"*80)\r\nprint(\"data[\\\"a\\\"]:\", data[\"a\"])\r\nprint(\"data[\\\"b\\\"]:\", data[\"b\"])\r\nprint(\"layer(data):\", layer(data))\r\nprint(\"-\"*80)\r\n```\r\n\r\nAnd the output:\r\n```\r\n--------------------------------------------------------------------------------\r\ndata[\"a\"]: tf.Tensor([0.333333333333333], shape=(1,), dtype=float64)\r\ndata[\"b\"]: tf.Tensor([3.141592653589793], shape=(1,), dtype=float64)\r\nlayer(data): tf.Tensor([[0.33333334 3.1415927 ]], shape=(1, 2), dtype=float32)\r\n--------------------------------------------------------------------------------\r\n```\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nNot sure. But who ever uses `tf.keras.backend.set_floatx('float64')` will\r\nprobably be happy.\r\n\r\n**Any Other info.**\r\n\r\nN/A", "comments": ["@piyueh Can you be clear about how setting float32 to float64 helps the community. Thanks!", "@gowthamkpr To back up this issue: depending on the application context, a user may want to use float64 to enable handling larger or more precise values than with float32. Alternatively, one may want to use float16 to limit the memory cost of their model.\r\n\r\nAt any rate, the keras API is built to support the specification of an alternative dtype for float layers. The fact that the `DenseFeatures` layer exposes this API trait but does not actually implement it is indeed an issue, since it is basically a violation of the `tf.keras.layers.Layer` common specification (thus notably enfringing the Liskov substitution principle).", "To fix this, one needs to alter source code in [this folder](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/feature_column) to ensure proper dtypes are passed to variable constructors (whose methods seem to be doted with the necessary parameters; so the API probably does not need to change, some arguments just need to be explicitly passed instead of assuming that the layer's dtype is always float32).\r\n\r\nIf nobody else does it in the upcoming days, I will try to submit a PR this week-end.", "Makes sense @pandrey-fr. Thanks for detailed explanation.", "My pleasure :)\r\nI have not had time to start working on a fix yet but hopefully I will submit something this week (unless somebody else does it first!).", "Assigning to @tanzhenyu who owns this area.", "I think the bottleneck here is that EmbeddingColumn is always with float32, which seems to be a legacy feature column issue, and we don't want feature column rely on keras backend. Moving forward, we're deprecating DenseFeatures or any other feature column related things and it's better to use [preprocessing layers](https://github.com/tensorflow/community/pull/188)\r\nClosing this issue for now. If PR is desired, please open one and I can help review it."]}, {"number": 33792, "title": "Several issues with saving model by averaging multiple models", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: 2080 ti\r\n\r\nI try to average two models weights to form one final model. The two original models are initialized following the same setting up. The only difference is they are trained with different data. After train them, I load them and average them using the code below:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nsess1 = tf.Session()\r\nsess2 = tf.Session()\r\n# toy example, so load the same model twice and do averaging\r\nsaver1 = tf.train.import_meta_graph('model.meta')\r\nsaver2 = tf.train.import_meta_graph('model.meta')  \r\nsaver1.restore(sess1, 'model')\r\nsaver2.restore(sess2, 'model')\r\nwith tf.Session() as sess3:\r\n    sess3.run(init_op)\r\n    all_vars = tf.trainable_variables()\r\n    values1 = sess1.run(all_vars)\r\n    values2 = sess2.run(all_vars)\r\n    all_assign = []\r\n    for var, val1, val2 in zip(all_vars, values1, values2):\r\n        all_assign.append(tf.assign(var, (val1 + val2)/ 2))\r\n    sess3.run(all_assign)\r\n    saver3 = tf.train.Saver()\r\n    save_path = saver3.save(sess3, os.path.join('./debug/', 'model'))\r\n```\r\nThen it shows the error:\r\nAt least two variables have the same name: beta1_power\r\n\r\nI have two questions:\r\n1). is this way I do averaging right?\r\n2). why I have the error?\r\n\r\nThank you very much!\r\n", "comments": ["@sun-peach \r\nPlease, let us know what error you are getting.Can you share the simple standalone code along with supporting files to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "@ravikyram hi, I have solved the second question. But for the first question, I still don't know how to average two models. I tried a little bit, but result is not right.\r\n\r\nI split the data to 2 partition and train as 2 jobs, resulting in 2 models. Eventually, I average the 2 models. But, the resulting model has validation accuracy 0.0. Previously, when I train the model with all data and without partitioning and averaging, the accuracy can approach 98%. ", "The current code is below:\r\n```\r\nwith tf.Graph().as_default():\r\n        # define the main net\r\n        nnets_to_average = nnets_list.split(\" \")  # list of nnets to be averaged in a string delimited by space \r\n        main_net_dir = nnets_to_average[0]\r\n        # meta file from main net (assuming all nets have exactly same architecture)\r\n        saver = tf.train.import_meta_graph(os.path.join(main_net_dir,'model.meta'))\r\n        all_vars = tf.trainable_variables()\r\n        # read all model params\r\n        model_params = []\r\n        for net_dir in nnets_to_average:\r\n            temp_sess = tf.Session()\r\n            saver.restore(temp_sess, os.path.join(net_dir,'model'))\r\n            temp_param = temp_sess.run(all_vars)\r\n            model_params.append(temp_param)\r\n            temp_sess.close()\r\n        # do averaging\r\n        #init_op = tf.global_variables_initializer()\r\n        sess_final = tf.Session()\r\n        saver.restore(sess_final, os.path.join(main_net_dir,'model'))       # main net as a template\r\n        all_assign = []\r\n        sum_count = 1\r\n        for var_list in zip(all_vars, *model_params):\r\n            var_list = list(var_list)\r\n            var = var_list[0]\r\n            temp_sum = var_list[1]\r\n            if len(var_list)>=3:\r\n                for sub_var in var_list[2:]:\r\n                    temp_sum += sub_var\r\n                    sum_count += 1\r\n            all_assign.append(tf.assign(var, temp_sum/sum_count))\r\n        sess_final.run(all_assign)\r\n        # save averaged model and copy remaining file\r\n        out_dir = '{0}/model_{1}'.format(dir, iter+1)\r\n        if not os.path.exists(out_dir):\r\n            os.makedirs(out_dir)\r\n        saver.save(sess_final, os.path.join(out_dir,'model'))\r\n        sess_final.close()\r\n```", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks"]}, {"number": 33791, "title": "tflite operators support dependent on tf.shape", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): docker images\r\n- TensorFlow version (use command below): 1.15.0-rc2 / 2.10.-dev20191027\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI am trying to convert an variational autoencoder into a tflite model. During the process, I stumbled across a weird bug. When explicitly specifying the shape of the sampling layer like this: `tf.random.normal(shape=(10,))`, the model is convertible without any errors.\r\n\r\nBut in case of not hard-coding the shape into my model, e.g. by inferencing it from the input vector(s) like so:\r\n\r\n```\r\ndimension = tf.shape(z_mu)[1] #index 0 is batch size\r\neps = tf.random.normal(shape=(dim,))\r\n```\r\nI get the error that tf.random.normal is not supported by the TF Lite runtime:\r\n\r\n> Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, EXP, FULLY_CONNECTED, LEAKY_RELU, LOG, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt doesn't make sense to me that the possibly buggy inference of a shape influences whether an OP is supported or not. Also, I am not sure if the hard-coded model can be trusted or not.\r\n\r\n**Code to reproduce the issue**\r\nJust set the EXPLICIT flag to False to get the error.\r\n```\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom tensorflow import keras\r\n\r\nprint(tf.__version__)\r\n\r\nEXPLICIT = True\r\n\r\n### DATA\r\ntraining_data = np.random.rand(1000, 90)\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((training_data, training_data))\r\ntrain_dataset = train_dataset.shuffle(1000).batch(100)\r\n\r\n### MODEL\r\nx = keras.layers.Input(shape=(90,))\r\nh = keras.layers.Dense(40, activation=tf.nn.relu)(x)\r\nz_mu = keras.layers.Dense(10)(h)\r\nz_sigma = keras.layers.Dense(10, activation=tf.nn.sigmoid)(h)\r\n\r\n#########################################################################################\r\nif EXPLICIT:\r\n    eps = tf.random.normal(shape=(10,)) # this works\r\n\r\nelse:\r\n    batch_size = tf.shape(z_mu)[0]\r\n    dimension = tf.shape(z_mu)[1]\r\n    eps = tf.random.normal(shape=(batch_size, dimension)) # this does NOT work, also tried using shape=(dimension,)\r\n\r\n#########################################################################################\r\nz = z_mu + eps * z_sigma\r\n\r\nh_decoded = keras.layers.Dense(40, activation=tf.nn.relu)(z)\r\nx_decoded = keras.layers.Dense(90)(h_decoded)\r\n\r\nmodel = keras.models.Model(x, x_decoded)\r\n\r\n### LOSS\r\nrecon_err = tf.reduce_sum(tf.abs(x - x_decoded), axis=1)\r\nkl_div = -.5 * tf.reduce_sum(1 + 2 * tf.math.log(z_sigma) - tf.square(z_mu) - tf.square(z_sigma), axis=1)\r\ntotal_loss = tf.reduce_mean(recon_err + kl_div)\r\nmodel.add_loss(total_loss)\r\n\r\n### TRAINING\r\nmodel.compile(optimizer='adam')\r\nprint(model.summary())\r\nmodel.fit(train_dataset, epochs=5)\r\n\r\n### SAVE\r\nkeras_file = 'vae_test.h5'\r\nkeras.models.save_model(model, keras_file)\r\n\r\n### CONVERSION\r\ntest_dataset = np.random.rand(100, 90).astype(np.float32)\r\n\r\ndef representative_dataset_gen():\r\n    for i in range(100):\r\n        yield [test_dataset[i:i+1]]\r\n\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_file_name = 'vae.tflite'\r\ntflite_model = converter.convert()\r\nopen(tflite_file_name, 'wb').write(tflite_model)\r\n\r\n```\r\nCan you confirm the strange behavior and whether tf.random.normal is implemented or not?", "comments": ["After further testing, I think that the tflite model is not working as intended. Although it can be loaded and seems to produce somewhat plausible results, it seems to be a completely deterministic model. If it was working correctly, this would not be the case.\r\n\r\nThis leads me to believe that a non-implemented error for the random function goes unnoticed by the converter. Maybe this proves helpful for further investigations.", "Perhaps using `SELECT_TF_OPS` can help in this case.\r\n```python\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\nSee [gist](https://colab.research.google.com/gist/ymodak/66f0d0164296121ece4bfe79df65c11c/github_33791.ipynb) for your reference. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33791\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33791\">No</a>\n"]}, {"number": 33790, "title": "\"Beginner Hello World\" Warning: WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> could not be transformed and will be executed as-is. ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 7:\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 2.0.0 v2.0.0-rc2-26-g64c3d382ca'\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nGetting a warning after executing the \"Hello World\" example for beginners from https://www.tensorflow.org/overview/?hl=es. Code:\r\n```\r\nimport tensorflow as tf\r\ntf.autograph.set_verbosity(10)\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\n\r\nThe initial message (without verbosity set to 10):\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002D042158>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002D042158>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x0000000005166F28>\r\n    args: (<tf.Tensor 'args_0:0' shape=(60000,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x0000000005166F28>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55730>\r\n    args: (<tf.Tensor 'args_0:0' shape=(32,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(60000, 28, 28) dtype=float64>, <tf.Tensor 'args_2:0' shape=(60000, 1) dtype=uint8>))\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55730>: DoNotConvert rule for tensorflow\r\nTrain on 60000 samples\r\nINFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28>\r\n    args: ()\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> key <code object initialize_variables at 0x00000000096CE6F0, file \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000000002D4C2978>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmpupjy58ms)\r\nINFO:tensorflow:Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 506, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 324, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 266, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 92, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\nWARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \r\n60000/60000 [==============================] - 3s 52us/sample - loss: 0.2937 - accuracy: 0.9152\r\n<tensorflow.python.keras.callbacks.History object at 0x000000002C5A0A20>\r\n\r\n\r\nThe console output with verbosity set to 10 looks as follows:\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002CD55510>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002CD55510>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x000000002CD55950>\r\n    args: (<tf.Tensor 'args_0:0' shape=(60000,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x000000002CD55950>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55B70>\r\n    args: (<tf.Tensor 'args_0:0' shape=(32,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(60000, 28, 28) dtype=float64>, <tf.Tensor 'args_2:0' shape=(60000, 1) dtype=uint8>))\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55B70>: DoNotConvert rule for tensorflow\r\nTrain on 60000 samples\r\nINFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>\r\n    args: ()\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8> is not cached for key <code object initialize_variables at 0x00000000096CE6F0, file \"C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000000002D866FD0>, frozenset({'initializer_map'}))\r\nINFO:tensorflow:Converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>\r\nINFO:tensorflow:Source code of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n@function_lib.defun\r\ndef initialize_variables():\r\n  op_map = object_identity.ObjectIdentityDictionary()\r\n  for v, init in initializer_map.items():\r\n    with ops.init_scope():\r\n      if resource_variable_ops.var_is_initialized_op(v.handle):\r\n        # Ignore variables which are already initialized at trace time.\r\n        continue\r\n    op_map = lift_to_graph.lift_to_graph(\r\n        [init], ops.get_default_graph(), op_map=op_map)\r\n    v.assign(op_map[init])\r\n\r\n\r\nINFO:tensorflow:Compiled output of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:\r\n\r\n# coding=utf-8\r\ndef tf__initialize_variables():\r\n  with ag__.FunctionScope('initialize_variables', 'initialize_variables_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as initialize_variables_scope:\r\n    op_map = ag__.converted_call(object_identity.ObjectIdentityDictionary, initialize_variables_scope.callopts, (), None, initialize_variables_scope)\r\n\r\n    def get_state_2():\r\n      return ()\r\n\r\n    def set_state_2(_):\r\n      pass\r\n\r\n    def loop_body(iterates, op_map):\r\n      v, init = iterates\r\n      continue_ = False\r\n      with ops.init_scope():\r\n\r\n        def get_state():\r\n          return ()\r\n\r\n        def set_state(_):\r\n          pass\r\n\r\n        def if_true():\r\n          continue_ = True\r\n          return continue_\r\n\r\n        def if_false():\r\n          return continue_\r\n        cond = ag__.converted_call(resource_variable_ops.var_is_initialized_op, initialize_variables_scope.callopts, (v.handle,), None, initialize_variables_scope)\r\n        continue_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('continue_',), ())\r\n\r\n      def get_state_1():\r\n        return ()\r\n\r\n      def set_state_1(_):\r\n        pass\r\n\r\n      def if_true_1():\r\n        op_map_1, = op_map,\r\n        op_map_1 = ag__.converted_call(lift_to_graph.lift_to_graph, initialize_variables_scope.callopts, ([init], ag__.converted_call(ops.get_default_graph, initialize_variables_scope.callopts, (), None, initialize_variables_scope)), {'op_map': op_map_1}, initialize_variables_scope)\r\n        ag__.converted_call(v.assign, initialize_variables_scope.callopts, (op_map_1[init],), None, initialize_variables_scope)\r\n        return op_map_1\r\n\r\n      def if_false_1():\r\n        return op_map\r\n      cond_1 = ag__.not_(continue_)\r\n      op_map = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('op_map',), ())\r\n      return op_map,\r\n    op_map, = ag__.for_stmt(ag__.converted_call(initializer_map.items, initialize_variables_scope.callopts, (), None, initialize_variables_scope), None, loop_body, get_state_2, set_state_2, (op_map,), ('op_map',), ())\r\n\r\n\r\nINFO:tensorflow:Compiled AST of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:\r\n\r\nFunctionDef:\r\n| name=u\"tf__initialize_variables\"\r\n| args=arguments:\r\n| | args=[]\r\n| | vararg=None\r\n| | kwonlyargs=[]\r\n| | kw_defaults=[]\r\n| | kwarg=None\r\n| | defaults=[]\r\n| | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| body=[\r\n| | With:\r\n| | | items=[\r\n| | | | withitem:\r\n| | | | | context_expr=Call:\r\n| | | | | | func=Attribute:\r\n| | | | | | | value=Name:\r\n| | | | | | | | id=u\"ag__\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: (), 'static_value': <module 'tensorflow.python.autograph.operators' from 'C:\\\\Users\\\\cenic\\\\Anaconda3\\\\envs\\\\tensorflow2env\\\\lib\\\\site-packages\\\\tensorflow_core\\\\python\\\\autograph\\\\operators\\\\__init__.py'>}\r\n| | | | | | | attr=u\"FunctionScope\"\r\n| | | | | | | ctx=Load()\r\n| | | | | | | ___pyct_anno={QN: ag__.FunctionScope, 'static_value': <class 'tensorflow.python.autograph.core.function_wrappers.FunctionScope'>}\r\n| | | | | | args=[\r\n| | | | | | | Str:\r\n| | | | | | | | s=u\"initialize_variables\"\r\n| | | | | | | Str:\r\n| | | | | | | | s=u\"initialize_variables_scope\"\r\n| | | | | | | Call:\r\n| | | | | | | | func=Attribute:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: (), 'static_value': <module 'tensorflow.python.autograph.operators' from 'C:\\\\Users\\\\cenic\\\\Anaconda3\\\\envs\\\\tensorflow2env\\\\lib\\\\site-packages\\\\tensorflow_core\\\\python\\\\autograph\\\\operators\\\\__init__.py'>}\r\n| | | | | | | | | attr=u\"ConversionOptions\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={QN: ag__.ConversionOptions, 'static_value': <class 'tensorflow.python.autograph.core.converter.ConversionOptions'>}\r\n| | | | | | | | args=[]\r\n| | | | | | | | keywords=[\r\n| | | | | | | | | keyword:\r\n| | | | | | | | | | arg=u\"recursive\"\r\n| | | | | | | | | | value=NameConstant:\r\n| | | | | | | | | | | value=True\r\n| | | | | | | | | keyword:\r\n| | | | | | | | | | arg=u\"user_requested\"\r\n| | | | | | | | | | value=NameConstant:\r\n| | | | | | | | | | | value=True\r\n| | | | | | | | | keyword:\r\n| | | | | | | | | | arg=u\"optional_features\"\r\n| | | | | | | | | | value=Tuple:\r\n| | | | | | | | | | | elts=[]\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | keyword:\r\n| | | | | | | | | | arg=u\"internal_convert_user_code\"\r\n| | | | | | | | | | value=NameConstant:\r\n| | | | | | | | | | | value=True\r\n| | | | | | | | ]\r\n| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(), w=()}}\r\n| | | | | | ]\r\n| | | | | | keywords=[]\r\n| | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(ag__, ag__.ConversionOptions), w=()}}\r\n| | | | | optional_vars=Name:\r\n| | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | ctx=Store()\r\n| | | | | | annotation=None\r\n| | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | ___pyct_anno={SCOPE: Scope{r=(ag__, ag__.FunctionScope, ag__.ConversionOptions), w=(initialize_variables_scope,)}}\r\n| | | ]\r\n| | | body=[\r\n| | | | Assign:\r\n| | | | | targets=[\r\n| | | | | | Name:\r\n| | | | | | | id=u\"op_map\"\r\n| | | | | | | ctx=Store()\r\n| | | | | | | annotation=None\r\n| | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323152],), ORIGIN: def_function.py:605:6, QN: op_map, DEFINITIONS: (AnnotatedDef[766997112],)}\r\n| | | | | ]\r\n| | | | | value=Call:\r\n| | | | | | func=Attribute:\r\n| | | | | | | value=Name:\r\n| | | | | | | | id=u\"ag__\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | attr=u\"converted_call\"\r\n| | | | | | | ctx=Load()\r\n| | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | args=[\r\n| | | | | | | Attribute:\r\n| | | | | | | | value=Name:\r\n| | | | | | | | | id=u\"object_identity\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:605:15, QN: object_identity, DEFINITIONS: ()}\r\n| | | | | | | | attr=u\"ObjectIdentityDictionary\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | ___pyct_anno={ORIGIN: def_function.py:605:15, QN: object_identity.ObjectIdentityDictionary}\r\n| | | | | | | Attribute:\r\n| | | | | | | | value=Name:\r\n| | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | Tuple:\r\n| | | | | | | | elts=[]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | NameConstant:\r\n| | | | | | | | value=None\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | ]\r\n| | | | | | keywords=[]\r\n| | | | | | ___pyct_anno={ORIGIN: def_function.py:605:15, ARGS_SCOPE: Scope{r=(initialize_variables_scope.callopts, object_identity, object_identity.ObjectIdentityDictionary, initialize_variables_scope), w=()}}\r\n| | | | | ___pyct_anno={ORIGIN: def_function.py:605:6, SCOPE: Scope{r=(object_identity.ObjectIdentityDictionary, ag__, object_identity, initialize_variables_scope, ag__.converted_call, initialize_variables_scope.callopts), w=(op_map,)}, LIVE_VARS_IN: frozenset({ops, object_identity.ObjectIdentityDictionary, object_identity, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, ag__.converted_call, v.handle, v.assign})}\r\n| | | | FunctionDef:\r\n| | | | | name=u\"get_state_2\"\r\n| | | | | args=arguments:\r\n| | | | | | args=[]\r\n| | | | | | vararg=None\r\n| | | | | | kwonlyargs=[]\r\n| | | | | | kw_defaults=[]\r\n| | | | | | kwarg=None\r\n| | | | | | defaults=[]\r\n| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | body=[\r\n| | | | | | Return:\r\n| | | | | | | value=Tuple:\r\n| | | | | | | | elts=[]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}\r\n| | | | | ]\r\n| | | | | decorator_list=[]\r\n| | | | | returns=None\r\n| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(get_state_2,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}\r\n| | | | FunctionDef:\r\n| | | | | name=u\"set_state_2\"\r\n| | | | | args=arguments:\r\n| | | | | | args=[\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"_\"\r\n| | | | | | | | ctx=Param()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[767224408],)}\r\n| | | | | | ]\r\n| | | | | | vararg=None\r\n| | | | | | kwonlyargs=[]\r\n| | | | | | kw_defaults=[]\r\n| | | | | | kwarg=None\r\n| | | | | | defaults=[]\r\n| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}\r\n| | | | | body=[\r\n| | | | | | Pass:\r\n| | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}\r\n| | | | | ]\r\n| | | | | decorator_list=[]\r\n| | | | | returns=None\r\n| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(set_state_2,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, ag__, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, lift_to_graph, v.handle, v.assign})}\r\n| | | | FunctionDef:\r\n| | | | | name=u\"loop_body\"\r\n| | | | | args=arguments:\r\n| | | | | | args=[\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"iterates\"\r\n| | | | | | | | ctx=Param()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: iterates, DEFINITIONS: (AnnotatedDef[764742904],)}\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"op_map\"\r\n| | | | | | | | ctx=Param()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}\r\n| | | | | | ]\r\n| | | | | | vararg=None\r\n| | | | | | kwonlyargs=[]\r\n| | | | | | kw_defaults=[]\r\n| | | | | | kwarg=None\r\n| | | | | | defaults=[]\r\n| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(op_map, iterates)}}\r\n| | | | | body=[\r\n| | | | | | Assign:\r\n| | | | | | | targets=[\r\n| | | | | | | | Tuple:\r\n| | | | | | | | | elts=[\r\n| | | | | | | | | | Name:\r\n| | | | | | | | | | | id=u\"v\"\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:606:10, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}\r\n| | | | | | | | | | Name:\r\n| | | | | | | | | | | id=u\"init\"\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:606:13, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}\r\n| | | | | | | | | ]\r\n| | | | | | | | | ctx=Store()\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:10}\r\n| | | | | | | ]\r\n| | | | | | | value=Name:\r\n| | | | | | | | id=u\"iterates\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: iterates, DEFINITIONS: (AnnotatedDef[764742904],)}\r\n| | | | | | | ___pyct_anno={SCOPE: Scope{r=(iterates,), w=(init, v)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, resource_variable_ops.var_is_initialized_op, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, lift_to_graph, v.handle, v.assign, iterates})}\r\n| | | | | | Assign:\r\n| | | | | | | targets=[\r\n| | | | | | | | Name:\r\n| | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | ctx=Store()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[767225360],)}\r\n| | | | | | | ]\r\n| | | | | | | value=NameConstant:\r\n| | | | | | | | value=False\r\n| | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}\r\n| | | | | | With:\r\n| | | | | | | items=[\r\n| | | | | | | | withitem:\r\n| | | | | | | | | context_expr=Call:\r\n| | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"ops\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:607:13, QN: ops, DEFINITIONS: ()}\r\n| | | | | | | | | | | attr=u\"init_scope\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:13, QN: ops.init_scope}\r\n| | | | | | | | | | args=[]\r\n| | | | | | | | | | keywords=[]\r\n| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:13, ARGS_SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | | | optional_vars=None\r\n| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(ops, ops.init_scope), w=()}}\r\n| | | | | | | ]\r\n| | | | | | | body=[\r\n| | | | | | | | FunctionDef:\r\n| | | | | | | | | name=u\"get_state\"\r\n| | | | | | | | | args=arguments:\r\n| | | | | | | | | | args=[]\r\n| | | | | | | | | | vararg=None\r\n| | | | | | | | | | kwonlyargs=[]\r\n| | | | | | | | | | kw_defaults=[]\r\n| | | | | | | | | | kwarg=None\r\n| | | | | | | | | | defaults=[]\r\n| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | | | body=[\r\n| | | | | | | | | | Return:\r\n| | | | | | | | | | | value=Tuple:\r\n| | | | | | | | | | | | elts=[]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}\r\n| | | | | | | | | ]\r\n| | | | | | | | | decorator_list=[]\r\n| | | | | | | | | returns=None\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(get_state,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, continue_, v.handle, v.assign})}\r\n| | | | | | | | FunctionDef:\r\n| | | | | | | | | name=u\"set_state\"\r\n| | | | | | | | | args=arguments:\r\n| | | | | | | | | | args=[\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"_\"\r\n| | | | | | | | | | | | ctx=Param()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[764743464],)}\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | vararg=None\r\n| | | | | | | | | | kwonlyargs=[]\r\n| | | | | | | | | | kw_defaults=[]\r\n| | | | | | | | | | kwarg=None\r\n| | | | | | | | | | defaults=[]\r\n| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}\r\n| | | | | | | | | body=[\r\n| | | | | | | | | | Pass:\r\n| | | | | | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}\r\n| | | | | | | | | ]\r\n| | | | | | | | | decorator_list=[]\r\n| | | | | | | | | returns=None\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(set_state,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, get_state, v.handle, v.assign})}\r\n| | | | | | | | FunctionDef:\r\n| | | | | | | | | name=u\"if_true\"\r\n| | | | | | | | | args=arguments:\r\n| | | | | | | | | | args=[]\r\n| | | | | | | | | | vararg=None\r\n| | | | | | | | | | kwonlyargs=[]\r\n| | | | | | | | | | kw_defaults=[]\r\n| | | | | | | | | | kwarg=None\r\n| | | | | | | | | | defaults=[]\r\n| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | | | body=[\r\n| | | | | | | | | | Assign:\r\n| | | | | | | | | | | targets=[\r\n| | | | | | | | | | | | Name:\r\n| | | | | | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764740216],)}\r\n| | | | | | | | | | | ]\r\n| | | | | | | | | | | value=NameConstant:\r\n| | | | | | | | | | | | value=True\r\n| | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:610:12, SCOPE: Scope{r=(), w=(continue_,)}, LIVE_VARS_IN: frozenset()}\r\n| | | | | | | | | | Return:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764740216],)}\r\n| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({continue_})}\r\n| | | | | | | | | ]\r\n| | | | | | | | | decorator_list=[]\r\n| | | | | | | | | returns=None\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(if_true,)}, BODY_SCOPE: Scope{r=(continue_,), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, continue_, set_state, v.handle, v.assign, get_state})}\r\n| | | | | | | | FunctionDef:\r\n| | | | | | | | | name=u\"if_false\"\r\n| | | | | | | | | args=arguments:\r\n| | | | | | | | | | args=[]\r\n| | | | | | | | | | vararg=None\r\n| | | | | | | | | | kwonlyargs=[]\r\n| | | | | | | | | | kw_defaults=[]\r\n| | | | | | | | | | kwarg=None\r\n| | | | | | | | | | defaults=[]\r\n| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | | | body=[\r\n| | | | | | | | | | Return:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[767225360],)}\r\n| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({continue_})}\r\n| | | | | | | | | ]\r\n| | | | | | | | | decorator_list=[]\r\n| | | | | | | | | returns=None\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(if_false,)}, BODY_SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, set_state, v.handle, v.assign, get_state})}\r\n| | | | | | | | Assign:\r\n| | | | | | | | | targets=[\r\n| | | | | | | | | | Name:\r\n| | | | | | | | | | | id=u\"cond\"\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={QN: cond, DEFINITIONS: (AnnotatedDef[767225416],)}\r\n| | | | | | | | | ]\r\n| | | | | | | | | value=Call:\r\n| | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | | | attr=u\"converted_call\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | | | | | args=[\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"resource_variable_ops\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:608:13, QN: resource_variable_ops, DEFINITIONS: ()}\r\n| | | | | | | | | | | | attr=u\"var_is_initialized_op\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:13, QN: resource_variable_ops.var_is_initialized_op}\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | id=u\"v\"\r\n| | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:608:57, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}\r\n| | | | | | | | | | | | | | attr=u\"handle\"\r\n| | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:57, QN: v.handle}\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | NameConstant:\r\n| | | | | | | | | | | | value=None\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | keywords=[]\r\n| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:13, ARGS_SCOPE: Scope{r=(resource_variable_ops, v, initialize_variables_scope, resource_variable_ops.var_is_initialized_op, v.handle, initialize_variables_scope.callopts), w=()}}\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(ag__.converted_call, ag__, resource_variable_ops, v, initialize_variables_scope, resource_variable_ops.var_is_initialized_op, v.handle, initialize_variables_scope.callopts), w=(cond,)}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, if_false, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, set_state, v.handle, v.assign, get_state})}\r\n| | | | | | | | Assign:\r\n| | | | | | | | | targets=[\r\n| | | | | | | | | | Name:\r\n| | | | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764785776],)}\r\n| | | | | | | | | ]\r\n| | | | | | | | | value=Call:\r\n| | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | | | attr=u\"if_stmt\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={QN: ag__.if_stmt}\r\n| | | | | | | | | | args=[\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"cond\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: cond, DEFINITIONS: (AnnotatedDef[767225416],)}\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"if_true\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: if_true, DEFINITIONS: (AnnotatedDef[767223904],)}\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"if_false\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: if_false, DEFINITIONS: (AnnotatedDef[767223176],)}\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"get_state\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: get_state, DEFINITIONS: (AnnotatedDef[764560608],)}\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"set_state\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: set_state, DEFINITIONS: (AnnotatedDef[767225472],)}\r\n| | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | | Str:\r\n| | | | | | | | | | | | | | s=u\"continue_\"\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | elts=[]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | keywords=[]\r\n| | | | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(if_true, cond, set_state, get_state, if_false), w=()}}\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(if_true, cond, ag__, set_state, ag__.if_stmt, get_state, if_false), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, cond, init, initialize_variables_scope.callopts, if_false, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, ag__.if_stmt, initialize_variables_scope, v, op_map, ag__.converted_call, set_state, v.assign, get_state})}\r\n| | | | | | | ]\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:8, BODY_SCOPE: Scope{r=(if_true, ops, ag__.converted_call, ag__, cond, resource_variable_ops, set_state, ag__.if_stmt, ops.init_scope, initialize_variables_scope, v, resource_variable_ops.var_is_initialized_op, continue_, get_state, v.handle, initialize_variables_scope.callopts, if_false), w=(if_true, cond, set_state, continue_, get_state, if_false)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, v.handle, v.assign})}\r\n| | | | | | FunctionDef:\r\n| | | | | | | name=u\"get_state_1\"\r\n| | | | | | | args=arguments:\r\n| | | | | | | | args=[]\r\n| | | | | | | | vararg=None\r\n| | | | | | | | kwonlyargs=[]\r\n| | | | | | | | kw_defaults=[]\r\n| | | | | | | | kwarg=None\r\n| | | | | | | | defaults=[]\r\n| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | body=[\r\n| | | | | | | | Return:\r\n| | | | | | | | | value=Tuple:\r\n| | | | | | | | | | elts=[]\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}\r\n| | | | | | | ]\r\n| | | | | | | decorator_list=[]\r\n| | | | | | | returns=None\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(get_state_1,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, lift_to_graph, continue_, v.assign})}\r\n| | | | | | FunctionDef:\r\n| | | | | | | name=u\"set_state_1\"\r\n| | | | | | | args=arguments:\r\n| | | | | | | | args=[\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"_\"\r\n| | | | | | | | | | ctx=Param()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[767302736],)}\r\n| | | | | | | | ]\r\n| | | | | | | | vararg=None\r\n| | | | | | | | kwonlyargs=[]\r\n| | | | | | | | kw_defaults=[]\r\n| | | | | | | | kwarg=None\r\n| | | | | | | | defaults=[]\r\n| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}\r\n| | | | | | | body=[\r\n| | | | | | | | Pass:\r\n| | | | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}\r\n| | | | | | | ]\r\n| | | | | | | decorator_list=[]\r\n| | | | | | | returns=None\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(set_state_1,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, ag__.converted_call, continue_, v.assign})}\r\n| | | | | | FunctionDef:\r\n| | | | | | | name=u\"if_true_1\"\r\n| | | | | | | args=arguments:\r\n| | | | | | | | args=[]\r\n| | | | | | | | vararg=None\r\n| | | | | | | | kwonlyargs=[]\r\n| | | | | | | | kw_defaults=[]\r\n| | | | | | | | kwarg=None\r\n| | | | | | | | defaults=[]\r\n| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | body=[\r\n| | | | | | | | Assign:\r\n| | | | | | | | | targets=[\r\n| | | | | | | | | | Tuple:\r\n| | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | Name:\r\n| | | | | | | | | | | | | id=u\"op_map_1\"\r\n| | | | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={QN: op_map_1, DEFINITIONS: (AnnotatedDef[764640168],)}\r\n| | | | | | | | | | | ]\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | ]\r\n| | | | | | | | | value=Tuple:\r\n| | | | | | | | | | elts=[\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({lift_to_graph.lift_to_graph, ops, ag__, lift_to_graph, initialize_variables_scope, v, op_map, initialize_variables_scope.callopts, ag__.converted_call, init, op_map_1[init], v.assign, ops.get_default_graph})}\r\n| | | | | | | | Assign:\r\n| | | | | | | | | targets=[\r\n| | | | | | | | | | Name:\r\n| | | | | | | | | | | id=u\"op_map_1\"\r\n| | | | | | | | | | | ctx=Store()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152],), ORIGIN: def_function.py:611:8, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}\r\n| | | | | | | | | ]\r\n| | | | | | | | | value=Call:\r\n| | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | | | attr=u\"converted_call\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | | | | | args=[\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"lift_to_graph\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:611:17, QN: lift_to_graph, DEFINITIONS: ()}\r\n| | | | | | | | | | | | attr=u\"lift_to_graph\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:17, QN: lift_to_graph.lift_to_graph}\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | | List:\r\n| | | | | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | | | | Name:\r\n| | | | | | | | | | | | | | | | id=u\"init\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:612:13, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}\r\n| | | | | | | | | | | | | | ]\r\n| | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:12}\r\n| | | | | | | | | | | | | Call:\r\n| | | | | | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | | | | | | | attr=u\"converted_call\"\r\n| | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | | | | | | | | | args=[\r\n| | | | | | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | | | id=u\"ops\"\r\n| | | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:612:20, QN: ops, DEFINITIONS: ()}\r\n| | | | | | | | | | | | | | | | attr=u\"get_default_graph\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:20, QN: ops.get_default_graph}\r\n| | | | | | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | | | | | elts=[]\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | NameConstant:\r\n| | | | | | | | | | | | | | | | value=None\r\n| | | | | | | | | | | | | | | Name:\r\n| | | | | | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | | | | | ]\r\n| | | | | | | | | | | | | | keywords=[]\r\n| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:20, ARGS_SCOPE: Scope{r=(ops, initialize_variables_scope.callopts, ops.get_default_graph, initialize_variables_scope), w=()}}\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | Dict:\r\n| | | | | | | | | | | | keys=[\r\n| | | | | | | | | | | | | Str:\r\n| | | | | | | | | | | | | | s=u\"op_map\"\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | | values=[\r\n| | | | | | | | | | | | | Name:\r\n| | | | | | | | | | | | | | id=u\"op_map_1\"\r\n| | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152], AnnotatedDef[764323152]), ORIGIN: def_function.py:612:52, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764640168],)}\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | keywords=[]\r\n| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:17, ARGS_SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1, initialize_variables_scope, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=()}}\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:8, SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1, initialize_variables_scope, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1[init], v.assign, op_map_1, initialize_variables_scope, v, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph})}\r\n| | | | | | | | Expr:\r\n| | | | | | | | | value=Call:\r\n| | | | | | | | | | func=Attribute:\r\n| | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | | | attr=u\"converted_call\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | | | | | args=[\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"v\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:613:8, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}\r\n| | | | | | | | | | | | attr=u\"assign\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, QN: v.assign}\r\n| | | | | | | | | | | Attribute:\r\n| | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | | | | | Tuple:\r\n| | | | | | | | | | | | elts=[\r\n| | | | | | | | | | | | | Subscript:\r\n| | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | id=u\"op_map_1\"\r\n| | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152],), ORIGIN: def_function.py:613:17, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}\r\n| | | | | | | | | | | | | | slice=Index:\r\n| | | | | | | | | | | | | | | value=Name:\r\n| | | | | | | | | | | | | | | | id=u\"init\"\r\n| | | | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:613:24, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}\r\n| | | | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:17, QN: op_map_1[init]}\r\n| | | | | | | | | | | | ]\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | NameConstant:\r\n| | | | | | | | | | | | value=None\r\n| | | | | | | | | | | Name:\r\n| | | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | keywords=[]\r\n| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, ARGS_SCOPE: Scope{r=(op_map_1[init], op_map_1, initialize_variables_scope, v, init, initialize_variables_scope.callopts, v.assign), w=()}}\r\n| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, SCOPE: Scope{r=(ag__, op_map_1[init], op_map_1, initialize_variables_scope, v, ag__.converted_call, init, initialize_variables_scope.callopts, v.assign), w=()}, LIVE_VARS_OUT: frozenset({op_map_1}), LIVE_VARS_IN: frozenset({ag__, op_map_1[init], op_map_1, initialize_variables_scope, v, ag__.converted_call, init, initialize_variables_scope.callopts, v.assign})}\r\n| | | | | | | | Return:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"op_map_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}\r\n| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map_1,), w=()}, LIVE_VARS_IN: frozenset({op_map_1})}\r\n| | | | | | | ]\r\n| | | | | | | decorator_list=[]\r\n| | | | | | | returns=None\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(if_true_1,)}, BODY_SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, v.assign, op_map_1[init], op_map_1, initialize_variables_scope, v, op_map, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, set_state_1, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, continue_, v.assign})}\r\n| | | | | | FunctionDef:\r\n| | | | | | | name=u\"if_false_1\"\r\n| | | | | | | args=arguments:\r\n| | | | | | | | args=[]\r\n| | | | | | | | vararg=None\r\n| | | | | | | | kwonlyargs=[]\r\n| | | | | | | | kw_defaults=[]\r\n| | | | | | | | kwarg=None\r\n| | | | | | | | defaults=[]\r\n| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}\r\n| | | | | | | body=[\r\n| | | | | | | | Return:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}\r\n| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({op_map})}\r\n| | | | | | | ]\r\n| | | | | | | decorator_list=[]\r\n| | | | | | | returns=None\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(if_false_1,)}, BODY_SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({ag__.not_, if_true_1, ag__, set_state_1, ag__.if_stmt, get_state_1, op_map, continue_})}\r\n| | | | | | Assign:\r\n| | | | | | | targets=[\r\n| | | | | | | | Name:\r\n| | | | | | | | | id=u\"cond_1\"\r\n| | | | | | | | | ctx=Store()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={QN: cond_1, DEFINITIONS: (AnnotatedDef[764788296],)}\r\n| | | | | | | ]\r\n| | | | | | | value=Call:\r\n| | | | | | | | func=Attribute:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | attr=u\"not_\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={QN: ag__.not_}\r\n| | | | | | | | args=[\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"continue_\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764785776],)}\r\n| | | | | | | | ]\r\n| | | | | | | | keywords=[]\r\n| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(continue_,), w=()}}\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(ag__, continue_, ag__.not_), w=(cond_1,)}, LIVE_VARS_IN: frozenset({ag__.not_, if_true_1, ag__, set_state_1, ag__.if_stmt, get_state_1, if_false_1, continue_})}\r\n| | | | | | Assign:\r\n| | | | | | | targets=[\r\n| | | | | | | | Name:\r\n| | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | ctx=Store()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764562848],)}\r\n| | | | | | | ]\r\n| | | | | | | value=Call:\r\n| | | | | | | | func=Attribute:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | attr=u\"if_stmt\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={QN: ag__.if_stmt}\r\n| | | | | | | | args=[\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"cond_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: cond_1, DEFINITIONS: (AnnotatedDef[764788296],)}\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"if_true_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: if_true_1, DEFINITIONS: (AnnotatedDef[764786224],)}\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"if_false_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: if_false_1, DEFINITIONS: (AnnotatedDef[764788576],)}\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"get_state_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: get_state_1, DEFINITIONS: (AnnotatedDef[764787344],)}\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"set_state_1\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: set_state_1, DEFINITIONS: (AnnotatedDef[764787960],)}\r\n| | | | | | | | | Tuple:\r\n| | | | | | | | | | elts=[\r\n| | | | | | | | | | | Str:\r\n| | | | | | | | | | | | s=u\"op_map\"\r\n| | | | | | | | | | ]\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | Tuple:\r\n| | | | | | | | | | elts=[]\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | ]\r\n| | | | | | | | keywords=[]\r\n| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(if_true_1, set_state_1, get_state_1, if_false_1, cond_1), w=()}}\r\n| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(if_true_1, set_state_1, ag__, ag__.if_stmt, get_state_1, if_false_1, cond_1), w=(op_map,)}, LIVE_VARS_IN: frozenset({cond_1, if_true_1, if_false_1, set_state_1, ag__, ag__.if_stmt, get_state_1})}\r\n| | | | | | Return:\r\n| | | | | | | value=Tuple:\r\n| | | | | | | | elts=[\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764562848],)}\r\n| | | | | | | | ]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({op_map})}\r\n| | | | | ]\r\n| | | | | decorator_list=[]\r\n| | | | | returns=None\r\n| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(loop_body,)}, BODY_SCOPE: Scope{r=(ops, if_true_1, cond, op_map_1, ops.init_scope, init, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, resource_variable_ops, ag__.converted_call, continue_, get_state, v.handle), w=(if_true, continue_, if_true_1, cond, set_state_1, set_state, v, get_state_1, op_map, if_false_1, cond_1, init, get_state, if_false)}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, set_state_2, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}\r\n| | | | Assign:\r\n| | | | | targets=[\r\n| | | | | | Tuple:\r\n| | | | | | | elts=[\r\n| | | | | | | | Name:\r\n| | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | ctx=Store()\r\n| | | | | | | | | annotation=None\r\n| | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[767039808],)}\r\n| | | | | | | ]\r\n| | | | | | | ctx=Store()\r\n| | | | | ]\r\n| | | | | value=Call:\r\n| | | | | | func=Attribute:\r\n| | | | | | | value=Name:\r\n| | | | | | | | id=u\"ag__\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | attr=u\"for_stmt\"\r\n| | | | | | | ctx=Load()\r\n| | | | | | | ___pyct_anno={QN: ag__.for_stmt}\r\n| | | | | | args=[\r\n| | | | | | | Call:\r\n| | | | | | | | func=Attribute:\r\n| | | | | | | | | value=Name:\r\n| | | | | | | | | | id=u\"ag__\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}\r\n| | | | | | | | | attr=u\"converted_call\"\r\n| | | | | | | | | ctx=Load()\r\n| | | | | | | | | ___pyct_anno={QN: ag__.converted_call}\r\n| | | | | | | | args=[\r\n| | | | | | | | | Attribute:\r\n| | | | | | | | | | value=Name:\r\n| | | | | | | | | | | id=u\"initializer_map\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:606:21, QN: initializer_map, DEFINITIONS: ()}\r\n| | | | | | | | | | attr=u\"items\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:21, QN: initializer_map.items}\r\n| | | | | | | | | Attribute:\r\n| | | | | | | | | | value=Name:\r\n| | | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | | annotation=None\r\n| | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | | | attr=u\"callopts\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}\r\n| | | | | | | | | Tuple:\r\n| | | | | | | | | | elts=[]\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | NameConstant:\r\n| | | | | | | | | | value=None\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"initialize_variables_scope\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}\r\n| | | | | | | | ]\r\n| | | | | | | | keywords=[]\r\n| | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:21, ARGS_SCOPE: Scope{r=(initializer_map.items, initialize_variables_scope.callopts, initializer_map, initialize_variables_scope), w=()}}\r\n| | | | | | | NameConstant:\r\n| | | | | | | | value=None\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"loop_body\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: loop_body, DEFINITIONS: (AnnotatedDef[766998064],)}\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"get_state_2\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: get_state_2, DEFINITIONS: (AnnotatedDef[766999576],)}\r\n| | | | | | | Name:\r\n| | | | | | | | id=u\"set_state_2\"\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | | annotation=None\r\n| | | | | | | | ___pyct_anno={QN: set_state_2, DEFINITIONS: (AnnotatedDef[767000416],)}\r\n| | | | | | | Tuple:\r\n| | | | | | | | elts=[\r\n| | | | | | | | | Name:\r\n| | | | | | | | | | id=u\"op_map\"\r\n| | | | | | | | | | ctx=Load()\r\n| | | | | | | | | | annotation=None\r\n| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[766997112],)}\r\n| | | | | | | | ]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | Tuple:\r\n| | | | | | | | elts=[\r\n| | | | | | | | | Str:\r\n| | | | | | | | | | s=u\"op_map\"\r\n| | | | | | | | ]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | | Tuple:\r\n| | | | | | | | elts=[]\r\n| | | | | | | | ctx=Load()\r\n| | | | | | ]\r\n| | | | | | keywords=[]\r\n| | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts), w=()}}\r\n| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, ag__.for_stmt, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts), w=(op_map,)}, LIVE_VARS_IN: frozenset({get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, ag__.for_stmt, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts})}\r\n| | | ]\r\n| | | ___pyct_anno={BODY_SCOPE: Scope{r=(ops, object_identity.ObjectIdentityDictionary, if_true_1, cond, op_map_1, ops.init_scope, set_state_2, initializer_map, init, initializer_map.items, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, object_identity, loop_body, ag__.for_stmt, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, resource_variable_ops, ag__.ConversionOptions, ag__.converted_call, continue_, ag__.FunctionScope, get_state, v.handle), w=(get_state_2, set_state_2, loop_body, op_map, initialize_variables_scope)}, LIVE_VARS_IN: frozenset({ops, object_identity.ObjectIdentityDictionary, ag__.converted_call, object_identity, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, ag__.ConversionOptions, lift_to_graph, ag__.FunctionScope, v.handle, v.assign})}\r\n| ]\r\n| decorator_list=[]\r\n| returns=None\r\n| ___pyct_anno={'lineno': 4, ORIGIN: def_function.py:603:4, SCOPE: Scope{r=(), w=(initialize_variables,)}, BODY_SCOPE: Scope{r=(ops, object_identity.ObjectIdentityDictionary, if_true_1, cond, op_map_1, ops.init_scope, set_state_2, initializer_map, init, initializer_map.items, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, object_identity, loop_body, ag__.for_stmt, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, resource_variable_ops, ag__.ConversionOptions, ag__.converted_call, continue_, ag__.FunctionScope, get_state, v.handle), w=(get_state_2, set_state_2, loop_body, op_map, initialize_variables_scope)}, 'function_context_name': 'initialize_variables_scope'}\r\n\r\n\r\n\r\nINFO:tensorflow:Defaults of <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> : None\r\nINFO:tensorflow:KW defaults of <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> : None\r\nINFO:tensorflow:Calling <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> with\r\n\r\n\r\nINFO:tensorflow:Converted call: <class 'tensorflow.python.util.object_identity.ObjectIdentityDictionary'>\r\n    args: ()\r\n    kwargs: None\r\n\r\nINFO:tensorflow:Permanently whitelisted: <class 'tensorflow.python.util.object_identity.ObjectIdentityDictionary'>: constructor\r\nINFO:tensorflow:Converted call: <bound method Mapping.items of ObjectIdentityDictionary({})>\r\n    args: ()\r\n    kwargs: None\r\n\r\nINFO:tensorflow:Whitelisted: <bound method Mapping.items of ObjectIdentityDictionary({})>: DoNotConvert rule for collections\r\n60000/60000 [==============================] - 4s 59us/sample - loss: 0.2964 - accuracy: 0.9143\r\n<tensorflow.python.keras.callbacks.History object at 0x000000002D05D1D0>\r\n", "comments": ["@jramirezpr \r\n\r\nI have tried on colab with TF version 2.0  and i am not able to see any warning message. Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/2f99e63572566049c81a2298760f0616/untitled307.ipynb)Thanks!  ", "@ravikyram Do you think  this has to do with my install? I get the warning when printing the model.fit command.\r\n________________________________\r\nDe: ravikyram <notifications@github.com>\r\nEnviado: lunes, 28 de octubre de 2019 11:38 p. m.\r\nPara: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCC: Juan Carlos Ramirez <the_passenger89@hotmail.com>; Mention <mention@noreply.github.com>\r\nAsunto: Re: [tensorflow/tensorflow] \"Beginner Hello World\" Warning: WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> could not be transformed and will be executed as-is. (#33...\r\n\r\n\r\n@jramirezpr<https://github.com/jramirezpr>\r\n\r\nI have tried on colab with TF version 2.0 and i am not able to see any warning message. Please, find the gist here.<https://colab.sandbox.google.com/gist/ravikyram/2f99e63572566049c81a2298760f0616/untitled307.ipynb> .Thanks!\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/33790?email_source=notifications&email_token=AGDJUUQ27TOZ5OZSHKOQHRTQQ7K6FA5CNFSM4JF4KRTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECPMRRY#issuecomment-547276999>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGDJUUSGIPZYAMTXE5YQKWLQQ7K6FANCNFSM4JF4KRTA>.\r\n", "I got the message on the Spyder IDE for Anaconda (Windows 7).", "@jramirezpr,\r\nCould you please try updating TensorFlow to the latest stable version i.e. v2.1 and the check if it works?\r\n\r\nI was able to reproduce the issue with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/3cd7a001755622118f9da0d180e24dcb/tf-nightly.ipynb). But did not face any issues while running the code with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/e040dc47c8b27325fdd3c0706a2f29de/2-1-template.ipynb). Please find the attached gist. Thanks!", "> I was able to reproduce the issue with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/3cd7a001755622118f9da0d180e24dcb/tf-nightly.ipynb). But did not face any issues while running the code with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/e040dc47c8b27325fdd3c0706a2f29de/2-1-template.ipynb). Please find the attached gist. Thanks!\r\n\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Getting the same error. categorical cross entropy is bloating only one category\r\n", "@vikrantsingh209 As this is an old issue, can you please open a new issue with a simple standalone code to reproduce the issue? Please provided as many details as possible to resolve the issue faster. Thanks!"]}, {"number": 33789, "title": " Model created by tf.keras.models.Model does not have attribute 'metrics_tensors'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14 and 2.0 (GPU)\r\n- Python version: 3.6.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/6.7.4\r\n- GPU model and memory: RTX 2060\r\n\r\nAfter switching to tf.keras from Keras I cannot append to metrics_tensors.\r\nCode from https://github.com/matterport/Mask_RCNN\r\n```\r\n# Add metrics for losses\r\n        for name in loss_names:\r\n            if name in self.keras_model.metrics_names:\r\n                continue\r\n            layer = self.keras_model.get_layer(name)\r\n            self.keras_model.metrics_names.append(name)\r\n            loss = (\r\n                tf.reduce_mean(layer.output, keepdims=True)\r\n                * self.config.LOSS_WEIGHTS.get(name, 1.))\r\n            self.keras_model.metrics_tensors.append(loss)\r\n```\r\nresult:\r\n```\r\n  File \"C:\\Project\\mrcnn\\model.py\", line 35, in build_mrcnn_network\r\n    maskRcnn = MaskRCNN(mode, config, common_services, depth, service_version)\r\n  File \"C:\\Project\\mrcnn\\model.py\", line 52, in __init__\r\n    self.compile()\r\n  File \"C:\\Project\\mrcnn\\model.py\", line 270, in compile\r\n    self.keras_model.metrics_tensors.append(loss)\r\nAttributeError: 'Model' object has no attribute 'metrics_tensors'\r\n```", "comments": ["Documents relating to this matter:\r\nhttps://github.com/keras-team/keras/issues/13497\r\nhttps://github.com/matterport/Mask_RCNN/issues/1820", "@kiflowb777 \r\nCan you please share simple standalone code to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "```\r\nuse_tf_keras = False\r\n\r\nimport numpy as np\r\nimport mnist\r\nimport tensorflow as tf\r\n\r\nif use_tf_keras:\r\n    from tensorflow.keras.models import Sequential\r\n    from tensorflow.keras.layers import Dense\r\n    from tensorflow.keras.utils import to_categorical\r\nelse:\r\n    from keras.models import Sequential\r\n    from keras.layers import Dense\r\n    from keras.utils import to_categorical\r\n\r\ntrain_images = mnist.train_images()\r\ntrain_labels = mnist.train_labels()\r\ntest_images = mnist.test_images()\r\ntest_labels = mnist.test_labels()\r\n\r\n# Normalize the images.\r\ntrain_images = (train_images / 255) - 0.5\r\ntest_images = (test_images / 255) - 0.5\r\n\r\n# Flatten the images.\r\ntrain_images = train_images.reshape((-1, 784))\r\ntest_images = test_images.reshape((-1, 784))\r\n\r\n# Build the model.\r\nmodel = Sequential([\r\n  Dense(64, activation='relu', input_shape=(784,)),\r\n  Dense(64, activation='relu'),\r\n  Dense(10, activation='softmax'),\r\n])\r\n\r\nloss_name = 'categorical_crossentropy'\r\n\r\n# Compile the model.\r\nmodel.compile(\r\n  optimizer='adam',\r\n  loss=loss_name,\r\n  metrics=['accuracy'],\r\n)\r\n\r\n# This causes an error after switching to the tf.keras\r\nfor layer in model.layers:\r\n    loss = tf.reduce_mean(layer.output, keepdims=True)\r\n    model.metrics_tensors.append(loss)  # if tf.keras: AttributeError: 'Sequential' object has no attribute 'metrics_tensors'\r\n\r\n# Train the model.\r\nmodel.fit(\r\n  train_images,\r\n  to_categorical(train_labels),\r\n  epochs=5,\r\n  batch_size=32,\r\n)\r\n```\r\n\r\nuse_tf_keras= False (use Keras), \r\nuse_tf_keras = True (then use tf.keras)", "if I use the Keras everything is ok, but when I use the tf.keras I get an error:\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-c6ee62f59e7b> in <module>\r\n     46 for layer in model.layers:\r\n     47     loss = tf.reduce_mean(layer.output, keepdims=True)\r\n---> 48     model.metrics_tensors.append(loss)\r\n     49 \r\n     50 # Train the model.\r\n\r\nAttributeError: 'Sequential' object has no attribute 'metrics_tensors'\r\n```", "@kiflowb777 The error is correctly displaying the attribute error as there is no attribute named \"metric_tensors\". When i changed one line from \r\n`model.metrics_tensors.append(loss)`\r\nto\r\n`model.metrics.append(loss)`\r\nthere was no error. I changed your code to work with `tf.keras` and the updated code is [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/6305f3b797a7ca9059b9d766e71a53f1/untitled605.ipynb). Thanks!\r\n\r\nI will close this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!\r\n", "Related topics: https://github.com/tensorflow/tensorflow/issues/34443", "Should use\r\n```model.metrics.append(loss)```\r\n or \r\n```model.add_metric(loss)```\r\n?"]}, {"number": 33788, "title": "TFLiteConverter from_keras_model TypeError: call() got an unexpected keyword argument 'training'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Custom code\r\n- Arch Linux Kernel 5.3.7\r\n- TensorFlow installed via pip\r\n- TensorFlow version v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen trying to convert a Keras CNN to TFlite file I get an error at the following line: `converter = tf.lite.TFLiteConverter.from_keras_model(model)`\r\n\r\n**Describe the expected behavior**\r\nA TFlite file is expected to be created and written to the local directory.\r\n\r\n**Code to reproduce the issue**\r\n```\r\n# Importing the Keras libraries and packages\r\nfrom keras.models import Sequential, save_model\r\nfrom keras.layers.core import Dense, Dropout, Flatten\r\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\r\nfrom keras.preprocessing import image\r\nfrom sklearn.metrics import classification_report, confusion_matrix\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nimageResX, imageResY = 256, 256\r\n\r\ndef CNNmodel():\r\n\tclassifier = Sequential()\r\n\tclassifier.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(imageResX, imageResY, 3)))\r\n\tclassifier.add(MaxPooling2D(pool_size=(3,3)))\r\n\tclassifier.add(Flatten())\r\n\tclassifier.add(Dense(units=128, activation='relu'))\r\n\tclassifier.add(Dropout(rate=0.5))\r\n\tclassifier.add(Dense(units=4, activation='softmax'))\r\n\tclassifier.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n\treturn classifier\r\n\r\n# create a data generators\r\ntrain_datagen = image.ImageDataGenerator(rescale=1./255)\r\ntest_datagen = image.ImageDataGenerator(rescale=1./255) \r\n\r\ntraining_set = train_datagen.flow_from_directory('MY DATA/Training', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical')\r\nevaluate_set = train_datagen.flow_from_directory('MY DATA/Evaluation', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical')\r\ntest_set = test_datagen.flow_from_directory('MY DATA/Testing', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical', shuffle=False)\r\n\r\nstep_size_train=training_set.n//training_set.batch_size\r\nstep_size_evaluate=evaluate_set.n//evaluate_set.batch_size\r\nstep_size_test=test_set.n//test_set.batch_size\r\n\r\nmodel = CNNmodel()\r\nhistory = model.fit_generator(generator=training_set, steps_per_epoch=step_size_train, epochs=1, validation_data=evaluate_set, validation_steps=step_size_evaluate)\r\n\r\nlabels = (training_set.class_indices)\r\nlabels = dict((v,k) for k,v in labels.items())\r\n\r\n# Save KERAS model\r\nmodelName = \"ST-AI-Model\"\r\nsave_model(model, str(modelName+\".h5\"))\r\n\r\n# Convert KERAS model\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(str(modelName+\".tflite\"), \"wb\").write(tflite_model)\r\n\r\nprediction = model.predict_generator(generator=test_set, verbose=1)\r\nclasses = test_set.classes[test_set.index_array]\r\npredicted_class_indices = np.argmax(prediction, axis=1)\r\ntarget_names = [labels[k] for k in range(len(training_set.class_indices))]\r\n\r\n\r\nprint('Confusion Matrix')\r\nprint(confusion_matrix(test_set.classes[test_set.index_array], predicted_class_indices))\r\nprint('Classification Report')\r\nprint(sum(predicted_class_indices==classes)/len(test_set.classes))\r\nprint(classification_report(test_set.classes[test_set.index_array], predicted_class_indices, target_names=target_names))\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> Traceback (most recent call last):\r\n  File \"/home/user/code/classifier.py\", line 98, in <module>\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 383, in from_keras_model\r\n    concrete_func = func.get_concrete_function()\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 776, in get_concrete_function\r\n    self._initialize(args, kwargs, add_initializers_to=initializer_map)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\", line 143, in _wrapped_model\r\n    outputs_list = nest.flatten(model(inputs=inputs, training=False))\r\n  File \"/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 75, in symbolic_fn_wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 489, in __call__\r\n    output = self.call(inputs, **kwargs)\r\nTypeError: call() got an unexpected keyword argument 'training'\r\n[Finished in 666.7s with exit code 1]", "comments": ["Could you try something like this:\r\n\r\nBefore you actually create the tflite converter:\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(str(modelName+\".tflite\"), \"wb\").write(tflite_model)\r\n\r\nTry load a new instance of the keras model you just saved, rather than using the one created before training. I just create the same keras model 'CNNmodel' as yours, and convert it directly to tflite (without the fit step) and it works without any issue.", "I tried that. Still gives the same error. I've even simplified the code to a much more simple case that produces the same error.\r\n\r\n```\r\n# Importing the Keras libraries and packages\r\nfrom keras.models import Sequential, save_model\r\nfrom keras.layers.core import Dense, Dropout, Flatten\r\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\r\nimport tensorflow as tf\r\n\r\nimageResX, imageResY = 256, 256\r\n\r\ndef CNNmodel():\r\n\tclassifier = Sequential()\r\n\tclassifier.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(imageResX, imageResY, 3)))\r\n\tclassifier.add(MaxPooling2D(pool_size=(3,3)))\r\n\tclassifier.add(Flatten())\r\n\tclassifier.add(Dense(units=128, activation='relu'))\r\n\tclassifier.add(Dropout(rate=0.5))\r\n\tclassifier.add(Dense(units=4, activation='softmax'))\r\n\tclassifier.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n\treturn classifier\r\n\r\nmodel = CNNmodel()\r\n\r\n# Convert KERAS model\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(\"test.tflite\", \"wb\").write(tflite_model)\r\n```", "I'm getting the same error trying to do the same thing, was the resolved?", "I've fixed this issue (and am on to the next bug). I was also using the keras lib, however if you switch over to tf.keras the problem goes away.", "Forgot to mention that I was also using the `tf.keras` API rather than the pure `keras` version. Could you try switching to `tf.keras` API and convert?", "I just switched over, now it's working!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33788\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33788\">No</a>\n", "> Forgot to mention that I was also using the `tf.keras` API rather than the pure `keras` version. Could you try switching to `tf.keras` API and convert?\r\n\r\nI am getting this error, I am using pure keras, what needs to be done to switch to tf.keras\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\nshould this line be changed to something else, please advise with a code snippet\r\n\r\n\r\n", "> > Forgot to mention that I was also using the `tf.keras` API rather than the pure `keras` version. Could you try switching to `tf.keras` API and convert?\r\n> \r\n> I am getting this error, I am using pure keras, what needs to be done to switch to tf.keras\r\n> \r\n> converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n> \r\n> should this line be changed to something else, please advise with a code snippet\r\n\r\nI mean when you build your keras model, use the `tf.keras.xxx` layer API instead of the one without the `tf` prefix. I believe there are some minor differences between the two set of APIs. Cheers.", "I am unable to create a new model using tf.keras API, but when using keras it works (but I can't convert keras model to TFLite model.).\r\nPython 3.6.8\r\nTf: 2.1.0\r\nkeras-transformer: 0.32\r\n\r\ncode :\r\n`dict_size = 7000\r\nmodel = get_model(\r\ntoken_num=dict_size,\r\nembed_dim=32,\r\nencoder_num=3,\r\ndecoder_num=2,\r\nhead_num=4,\r\nhidden_dim=128,\r\nattention_activation='relu',\r\nfeed_forward_activation='relu',\r\ndropout_rate=0.5,\r\nembed_weights=np.random.random((dict_size, 32))\r\n)`\r\n`model.compile(\r\noptimizer='adam',\r\nloss='sparse_categorical_crossentropy',\r\nmetrics=['accuracy']\r\n)`\r\n`model.summary()`\r\n\r\n> AttributeError                            \r\nTraceback (most recent call last)in module\r\n     11     feed_forward_activation='relu',\r\n     12     dropout_rate=0.5,\r\n------ 13     embed_weights=np.random.random((dict_size, 32))\r\n     14 )\r\n     15 model.compile(\r\n\r\nD:\\projects\\GEC\\tflite\\keras_transformer\\transformer.py in get_model(token_num, embed_dim, encoder_num, decoder_num, head_num, hidden_dim, attention_activation, feed_forward_activation, dropout_rate, use_same_embed, embed_weights, embed_trainable, trainable, use_adapter, adapter_units, adapter_activation)\r\n    443         mode=TrigPosEmbedding.MODE_ADD,\r\n    444         name='Encoder-Embedding',\r\n-- 445     )(encoder_embed_layer(encoder_input)[0])\r\n    446     encoded_layer = get_encoders(\r\n    447         encoder_num=encoder_num,\r\n\r\nd:\\projects\\gec\\tf2.1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)\r\n     73         if _SYMBOLIC_SCOPE.value:\r\n     74             with get_graph().as_default():\r\n--- 75                 return func(*args, **kwargs)\r\n     76         else:\r\n     77             return func(*args, **kwargs)\r\n\r\nd:\\projects\\gec\\tf2.1\\lib\\site-packages\\keras\\engine\\base_layer.py in __call__(self, inputs, **kwargs)\r\n    473 \r\n    474             # Handle mask propagation.\r\n-- 475             previous_mask = _collect_previous_mask(inputs)\r\n    476             user_kwargs = kwargs.copy()\r\n    477             if not is_all_none(previous_mask):\r\n\r\nd:\\projects\\gec\\tf2.1\\lib\\site-packages\\keras\\engine\\base_layer.py in _collect_previous_mask(input_tensors)\r\n   1439             inbound_layer, node_index, tensor_index = x._keras_history\r\n   1440             node = inbound_layer._inbound_nodes[node_index]\r\n- 1441             mask = node.output_masks[tensor_index]\r\n   1442             masks.append(mask)\r\n   1443         else:\r\n\r\nAttributeError: 'Node' object has no attribute 'output_masks'", "> > Forgot to mention that I was also using the `tf.keras` API rather than the pure `keras` version. Could you try switching to `tf.keras` API and convert?\r\n> \r\n> I am getting this error, I am using pure keras, what needs to be done to switch to tf.keras\r\n> \r\n> converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n> \r\n> should this line be changed to something else, please advise with a code snippet\r\n\r\nHere is how the import statements should look. Notice that it is not straight forwards \"Find&Replace\" as a number of paths have changed.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential, save_model\r\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n```\r\n", "@mritunjai-chandra to your problem\uff0c try to update your tensorflow at least 2.3", "`import tensorflow as tf\r\nassert float(tf.__version__[:3]) >= 2.3\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = tf.compat.v1.InteractiveSession(config=config)\r\nimport tensorflow.keras as keras\r\nimport pathlib\r\nimport numpy as np\r\nimport tensorflow_model_optimization as tfmot\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\n\r\norigin_model = tf.keras.applications.MobileNetV3Small(\r\n    input_shape=(224, 224, 3), alpha=1.0, include_top=True, weights='imagenet',\r\n    input_tensor=None, pooling=None, classes=1000,\r\n    classifier_activation='softmax'\r\n)\r\n\r\n\r\nquant_aware_model = tfmot.quantization.keras.quantize_model(origin_model)\r\n\r\n\r\n\r\nquant_aware_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.00001),  # 0.045, momentum=0.9, decay=0.98),\r\n                              loss='sparse_categorical_crossentropy',\r\n                              metrics=['accuracy'])`\r\nWhen I do this it's very strange to report an error.\r\n![image](https://user-images.githubusercontent.com/32632952/120809866-13e09000-c57d-11eb-8469-6d0cff43b86b.png)\r\n@krishnak @haozha111 @Mohit-Ak @mritunjai-chandra @Machine-Hum,Can you help me find out the reason? It's been bothering me for a long time"]}, {"number": 33787, "title": "Using tf.keras.backend.zeros in while loops.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Arch Linux**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **Binary**\r\n- TensorFlow version (use command below): **2.0.0**\r\n- Python version: **3.7**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **N/A**\r\n\r\n**Describe the current behavior**\r\nThe effect of `tf.zeros` and `tf.keras.backend.zeros` is not the same and results in some inconsistent behaviour. This also holds for other functions such as `tf.keras.backend.ones` and others like it.\r\n\r\nSpecifically, using `tf.keras.backend.zeros` in a `tf.map_fn` function (or something similar) breaks because `tf.keras.backend.zeros` has a `tf.init_scope` which causes it to be created out of the context of the while loop.\r\n\r\n**Describe the expected behavior**\r\nExpected behaviour would be that `tf.zeros` and `tf.keras.backend.zeros` are identical and that they follow the usage of `tf.zeros`; meaning not changing the scope in which they are created.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.disable_v2_behavior()\r\n\r\n# Works because we don't change the scope.\r\ndef works(inputs):\r\n\treturn tf.zeros((tf.keras.backend.shape(inputs[0])[0],))\r\n\r\n# Works because both tf.zeros and its inputs are in the same scope.\r\n## This function helps explain the root of the issue.\r\ndef works2(inputs):\r\n\twith tf.init_scope():\r\n\t\treturn tf.zeros((tf.keras.backend.shape(inputs[0])[0],))\r\n\r\n# Breaks because tf.keras.backend.zeros is being created in a different scope from tf.keras.backend.shape.\r\ndef breaks(inputs):\r\n\treturn tf.keras.backend.zeros((tf.keras.backend.shape(inputs[0])[0],))\r\n\r\n# Breaks because the shape is created outside of the context of the tf.zeros.\r\n## This function helps explain the root of the issue.\r\n## This is an extract of how tf.keras.backend.zeros is implemented.\r\ndef breaks2(inputs):\r\n\tshape = (tf.keras.backend.shape(inputs[0])[0],)\r\n\twith tf.init_scope():\r\n\t\treturn tf.zeros(shape)\r\n\r\ninputs = [tf.keras.layers.Input(shape=(5, 5))]\r\n\r\n# This works when using tf.zeros because it doesn't change the scope.\r\ntf.map_fn(works, elems=inputs, dtype=tf.keras.backend.floatx())\r\n\r\n# This works when tf.zeros and its inputs are in the same scope (using tf.init_scope).\r\ntf.map_fn(works2, elems=inputs, dtype=tf.keras.backend.floatx())\r\n\r\n# This breaks when using tf.keras.backend.zeros because it creates the zeros in a new scope.\r\ntry:\r\n\ttf.map_fn(breaks, elems=inputs, dtype=tf.keras.backend.floatx())\r\nexcept ValueError as e:\r\n\tprint(\"Caught error: {}\".format(e))\r\n\r\n# This breaks when using tf.zeros when its inputs are defined in a different scope.\r\ntry:\r\n\ttf.map_fn(breaks2, elems=inputs, dtype=tf.keras.backend.floatx())\r\nexcept ValueError as e:\r\n\tprint(\"Caught error: {}\".format(e))\r\n```\r\n\r\n**Other info / logs**\r\nThis change was introduced in https://github.com/tensorflow/tensorflow/commit/1d91f3532ee4df36749dda1a39b8a2a78232dd74 by @rjpower . It would be great if I could get some feedback on why this `init_scope` got added there and if it should be changed.", "comments": ["Indeed, this was my change, but I've long forgotten the reasoning. I looked up a bit more context. Summarizing the conversation at the time:\r\n\r\nVariables initialized inside of a loop (as from a training loop) need to be in the init_scope to avoid an error.  For layers, this is handled by the make_variable helper, but optimizers can end up creating temporary variables and triggering this issue.\r\n\r\nI'm not sure what the contract is for tf.keras.backend (is it intended as public or not). But I support fixing this. We should remmove the scoping from backend.{zeros, ones} and explicitly add the init_scope when initializing optimizer variables. I'll defer to the keras-team for how to properly stage the fix.", "Thank you for the feedback @rjpower . I'm fairly certain `tf.keras.backend` is intended to be public, as it provides an easy migration from `keras` to `tf.keras`.\r\n\r\n> I'll defer to the keras-team for how to properly stage the fix.\r\n\r\nIs there a way I can follow this progress? Or will this issue be updated when the keras-team handles it?", "Sorry for the delay -- yes -- I'll ask someone on the Keras/DS team to look into this and update the status on this issue.", "Hey @rjpower , it has been a while, is there an update on this issue?", "@rjpower any update on this?", "@hgaiser apologies for the delay.\r\n\r\nSo: tf.keras.backend should be considered private to Keras. Unfortunately it looks like fixing the behavior will be somewhat challenging as it affects variable initialization. There's some long term work planned to try to make this more consistent, but I'm afraid it won't land soon.", "Note that tf.zeros and tf.keras.backend.zeros are different.\r\n\r\ntf.zeros is expected to return a constant tensor, whereas tf.keras.backend.zeros is expected to return a **variable** that filled with zeros. The keras one is more like a shortcut to create variable with a zero initializer.\r\n\r\nClosing this bug since the expectation of those two API are different.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33787\">No</a>\n", "@qlzh727 I understand that `tensorflow.zeros` creates a constant tensor and `tf.keras.backend.zeros` creates a variable, but shouldn't they both be useable in a while loop?\r\n\r\nCurrently, `tf.keras.backend.zeros` **can't** be used in while loops, while if you created a `tf.variable` containing zeros you **can** use it in while loops. Surely that's a bug right?", "Thanks for bring this up. I agree that forcing init_scope under the hood is not ideal, and its not clearly documented in the API docstring.\r\n\r\nI think the issue that @rjpower trying to walkaround is for the optimizer, which use backend.zeros to create varibles. I think we should remove the init_scope in backend.zeros, and add init_scope explicitly to the optimizer. ", "Checked with @fchollet offline for this issue. He think it is fine to create variables with zeros/ones under init scope, and we will keep this behavior. If you need non-variable zeros under while loop, you can use tf.zeros, otherwise, you can use tf.Variable(), but the initiali value of it need to be under init_scope as well.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33787\">No</a>\n", "I respectfully disagree with you @qlzh727 . What is the motivation for @fchollet to say it is fine? I can't think of any reason for a function as basic as a `zeros` or `ones` to not work in a different scope (like a loop). Specially since it used to work before https://github.com/tensorflow/tensorflow/commit/1d91f3532ee4df36749dda1a39b8a2a78232dd74 . \r\n\r\nI don't know what the motivation is for `zeros` and `ones` to be in `init_scope` for the optimizer, but it makes more sense to perform the scope change there instead of forcing it everywhere when it isn't necessary. This simply breaks expected (and previously working) functionality. What is the benefit, outside of the optimizer, to use `tf.init_scope`? \r\n\r\nYou suggest to use `tf.zeros` instead, which is a possible (yet in my opinion illogical) solution, but this same issue exists in Keras. In the case of Keras it makes no sense at all to use `tf.zeros` since the whole idea is to be backend independent. I was expecting this to be fixed in `tf.keras` so that it can possibly be fixed in Keras as well."]}, {"number": 33786, "title": "Cannot import tf.keras.engine", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14 and 2.0 (gpu)\r\n- Python version: 3.6.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/6.7.4\r\n- GPU model and memory: RTX 2060 6GB\r\n\r\nAfter switching my code to tf.keras I cannot import tf.keras.engine:\r\nwith Keras:\r\n```\r\nimport keras.layers as KL\r\nimport keras.models as KM\r\nimport keras.engine as KE\r\n```\r\n`>>>OK`\r\n\r\n\r\nwith tf.keras:\r\n```\r\nimport tensorflow.keras.layers as KL\r\nimport tensorflow.keras.models as KM\r\nimport tensorflow.keras.engine as KE\r\n```\r\n\r\n```\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-2-004966c96ded> in <module>\r\n      1 import tensorflow.keras.layers as KL\r\n      2 import tensorflow.keras.models as KM\r\n----> 3 import tensorflow.keras.engine as KE\r\n\r\nModuleNotFoundError: No module named 'tensorflow.keras.engine'\r\n```\r\n\r\n\r\n", "comments": ["Hi,\r\nYou are not able to import it because the is no module tensorflow.keras.engine.\r\n\r\nThis answer might help you:\r\nhttps://stackoverflow.com/questions/51337558/how-to-import-keras-engine-topology-in-tensorflow\r\n\r\nSimilar functionalities are provided by tf in other modules. ", "I have tried on colab with TF version 2.0 ,1.14, 1.15.0-rc3, 2.1.0-dev20191028 and was able to reproduce the issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/857ee7fdf5e48e7e54c913f8eaf91624/untitled308.ipynb) Thanks!", "@kiflowb777 As mentioned by @Sooryakiran there is no module named 'tensorflow.keras.engine'. All of the submodules unders the `keras.engine` are under different modules within `tf.keras`. I am sure you are trying to migrate from `keras` to `tf.keras`. In the process, if you notice any bugs, please file them as new issues.\r\n\r\nI am closing this issue as it is resolved. Please feel free to open a new issue when you notice any bug. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33786\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33786\">No</a>\n"]}, {"number": 33785, "title": "The inheriting keras.layers.Layer does not call a compute_output_shape after switching to tf.keras from keras", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14, 1.15 and 2.0 (gpu)\r\n- Keras version: 2.2.4 and 2.2.4-tf\r\n- Python version: 3.6.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/6.7.4\r\n- GPU model and memory: RTX 2060 6GB\r\n\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` unknown 1.14.0\r\n\r\nAfter switching to tf.keras from keras my project witch use Mask_RCNN does not work.\r\nI noticed that TimeDistributed returns a different tensor shape in keras (1.) and tf.keras (2.):\r\n1.` Tensor(\"mrcnn_class_bn1/Reshape_1:0\", shape=(?, 1000, 1, 1, 256), dtype=float32)`\r\n2. `Tensor(\"mrcnn_class_bn1/Reshape_1:0\", shape=(?, ?, 1, 1, 256), dtype=float32)`\r\n\r\n```\r\nx = PyramidROIAlign([pool_size, pool_size], feature_levels,\r\n                        name=\"roi_align_classifier\")([rois, image_meta] + feature_maps)\r\nx = KL.TimeDistributed(KL.Conv2D(fc_layers_size, (pool_size, pool_size), padding=\"valid\"),\r\n                           name=\"mrcnn_class_conv1\")(x)\r\n```\r\n\r\nwhere rois is generated by ProposalLayer from Mask_RCNN module (https://github.com/matterport/Mask_RCNN)\r\n\r\nProposalLayer inherits from the class keras.layers.Layer.\r\nIn Keras the overwritten function compute_output_shape is called, but not in the tf.keras.\r\n\r\nAdditionally, the rois created in the tf.keras does not have the parameter _keras_shape that is most likely needed in the function TimeDistributed to create a proper shape.\r\n", "comments": ["Related topics:\r\nhttps://github.com/matterport/Mask_RCNN/issues/1820\r\nhttps://github.com/keras-team/keras/issues/13497\r\nhttps://stackoverflow.com/questions/54613474/tensorflow-keras-input-layer-does-not-add-keras-shape\r\nhttps://github.com/matterport/Mask_RCNN/issues/1815\r\nhttps://github.com/matterport/Mask_RCNN/issues/1775", "@kiflowb777 \r\n\r\nCan you please share simple standalone code to reproduce the issue in our environment.It helps in localizing the issue faster. Thanks!", "```\r\nuse_tf_keras = False\r\n\r\nif use_tf_keras:\r\n    import tensorflow.keras\r\n    from tensorflow.keras.models import Sequential\r\n    from tensorflow.keras import layers\r\n    from tensorflow.keras.datasets import mnist\r\n    from tensorflow.keras import backend as K\r\nelse:\r\n    import keras\r\n    from keras.models import Sequential\r\n    from keras import layers\r\n    from keras.datasets import mnist\r\n    from keras import backend as K\r\n    \r\n\r\nclass Antirectifier(layers.Layer):\r\n    def compute_output_shape(self, input_shape):\r\n        print(\"compute_output_shape called\")\r\n        shape = list(input_shape)\r\n        assert len(shape) == 2  # only valid for 2D tensors\r\n        shape[-1] *= 2\r\n        return tuple(shape)\r\n\r\n    def call(self, inputs):\r\n        print(\"Antirectifier called\")\r\n        inputs -= K.mean(inputs, axis=1, keepdims=True)\r\n        inputs = K.l2_normalize(inputs, axis=1)\r\n        pos = K.relu(inputs)\r\n        neg = K.relu(-inputs)\r\n        return K.concatenate([pos, neg], axis=1)\r\n\r\n# global parameters\r\nbatch_size = 128\r\nnum_classes = 10\r\nepochs = 5\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nx_train = x_train.reshape(60000, 784)\r\nx_test = x_test.reshape(10000, 784)\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n\r\n# build the model\r\nmodel = Sequential()\r\nmodel.add(layers.Dense(256, input_shape=(784,)))\r\nmodel.add(Antirectifier())\r\nmodel.add(layers.Dropout(0.1))\r\nmodel.add(layers.Dense(256))\r\nmodel.add(Antirectifier())\r\nmodel.add(layers.Dropout(0.1))\r\nmodel.add(layers.Dense(num_classes))\r\nmodel.add(layers.Activation('softmax'))\r\n\r\n# compile the model\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy'])\r\n\r\n# train the model\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          verbose=1,\r\n          validation_data=(x_test, y_test))\r\n```\r\n\r\nIf you switch use_tf_keras to True you can notice that compute_output_shape in custom layer is not called.\r\n", "I have tried on colab with TF version 1.14 and was able to execute the code  successfully with `use_tf_keras to True ` and `use_tf_keras = False`. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/0c7d4ac2d3a4f820271eec36c8b6dbd7/untitled318.ipynb).I have tried on colab with TF 2.0 and i am seeing the below error.`runtimeError: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14.`. Is this is the expected output. Thanks!", "Thanks.\r\nI'm trying to migrate from keras to tf.keras. Most of my project works on the tf.keras. But one network uses Mask_RCNN (https://github.com/matterport/Mask_RCNN).\r\nI noticed that the layers shapes generated by Mask_RCNN are different if I use the keras and tf.keras.\r\n\r\nIt seems to me that if you use the tf.keras the compute_output_shape is not called. \r\nYou might notice that in this case that line `print(\"compute_output_shape called\")` is not printed if use tf.keras.\r\n", "You can try run this code in IDE (e.g. PyCharm) and add breakpoint inside `custom compute_output_shape()` during debug mode. \r\nYou may notice that the program will not stop only if you use the tf.keras.", "I wrote a simple code that shows that the shape differs depending on whether we use the keras or the tf.keras:\r\n\r\n```\r\nuse_tf_keras = False\r\n\r\nif use_tf_keras:\r\n    import tensorflow.keras\r\n    from tensorflow.keras.models import Sequential\r\n    from tensorflow.keras import layers\r\n    from tensorflow.keras import backend as K\r\nelse:\r\n    import keras\r\n    from keras.models import Sequential\r\n    from keras import layers\r\n    from keras import backend as K\r\n    \r\nclass Antirectifier(layers.Layer):\r\n    def compute_output_shape(self, input_shape):\r\n        print(\"custom compute_output_shape called\")\r\n        shape = list(input_shape)\r\n        shape[-1] *= 1\r\n        return tuple(shape)\r\n\r\n    def call(self, inputs):\r\n        inputs -= K.mean(inputs, axis=1, keepdims=True)\r\n        inputs = K.l2_normalize(inputs, axis=1)\r\n        pos = K.relu(inputs)\r\n        neg = K.relu(-inputs)\r\n        return K.concatenate([pos, neg], axis=1)\r\n\r\n# build the model\r\nmodel = Sequential()\r\nmodel.add(layers.Dense(256, input_shape=(784,)))\r\nmodel.add(Antirectifier())\r\nprint(model.output_shape)\r\n```\r\n\r\nkeras:   **(None, 256)**\r\ntf.keras:   **(None, 512)**", "I found similar problems:\r\nhttps://github.com/tensorflow/tensorflow/issues/34141\r\nhttps://github.com/tensorflow/tensorflow/issues/32029\r\nhttps://github.com/tensorflow/tensorflow/issues/19961\r\nhttps://github.com/matterport/Mask_RCNN/issues/1815\r\nhttps://stackoverflow.com/questions/51028861/tensorflow-compute-output-shape-not-working-for-custom-layer\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/34248", "I also checked on TF 1.15, but the problem also exists.", "I tried to manually correct the shape of the custom layer by using the tf.reshape() or set_shape function after each use, but the summary of the model created in tf.keras differs from the one created in keras.", "Sorry for the very late reply. \r\n\r\nI don't think compute_output_shape need to be called if we can already get the output tensor from the layer itself. It doesn't make sense to call compute_output_shape() when we have layer.output available. If the model's output doesn't carry the correct static shape information, I think we should fix the layer.call() body for that.\r\n\r\nCould u point me to the layer in your code that produce the unexpected output?", "Ping @kiflowb777 for updates.", "Closing this issue due to lack of feedback, feel free to reopen this issue with more information for further troubleshooting.", "Hi @qlzh727 , please reopen this issue and check the following `ResizeLayer` in tensorflow 1.15. It could run on `keras` even if the `compute_output_shape` function is commented out. But in `tf.keras` the code fails as:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/fanliwen/PycharmProjects/textual-relevance/layers_test.py\", line 58, in <module>\r\n    s = Dense(1)(Dense(20, activation='relu')(z))\r\n  File \"/Users/fanliwen/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/Users/fanliwen/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/Users/fanliwen/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\", line 1009, in build\r\n    raise ValueError('The last dimension of the inputs to `Dense` '\r\nValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\r\n```\r\n\r\n- use_tf_keras = True: fails\r\n- use_tf_keras = False: works, even `compute_output_shape` not implemented\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nuse_tf_keras = True\r\nif use_tf_keras:\r\n    from tensorflow.keras.layers import Flatten, Dense\r\n    from tensorflow.keras import Input, Model\r\n    from tensorflow.keras import layers\r\nelse:\r\n    from keras.layers import Flatten, Dense\r\n    from keras import Input, Model\r\n    from keras import layers\r\n\r\n\r\nclass ResizeLayer(layers.Layer):\r\n    \"\"\"\r\n    Inputs:\r\n        images:\r\n            4D tensor with shape `(batch_size, rows, cols, channels)`\r\n        rows:\r\n            1D tensor with shape `(batch_size,)`\r\n        cols:\r\n            1D tensor with shape `(batch_size,)`\r\n    Outputs:\r\n        4D tensor with shape `(batch_size, rows, cols, channels)`\r\n    \"\"\"\r\n\r\n    def __init__(self, **kwargs):\r\n        super(ResizeLayer, self).__init__(**kwargs)\r\n\r\n    def call(self, inputs, **kwargs):\r\n        images = inputs[0]\r\n        rows = inputs[1]\r\n        cols = inputs[2]\r\n\r\n        nhwc = tf.shape(images)\r\n        boxes = tf.stack([tf.zeros(shape=(nhwc[0],), dtype='float32'),\r\n                          tf.zeros(shape=(nhwc[0],), dtype='float32'),\r\n                          tf.cast(rows, 'float32') / tf.cast(nhwc[1], 'float32'),\r\n                          tf.cast(cols, 'float32') / tf.cast(nhwc[2], 'float32'), ], axis=-1)\r\n        box_ind = tf.range(0, limit=nhwc[0])\r\n        crop_size = (nhwc[1], nhwc[2])\r\n\r\n        resize = tf.image.crop_and_resize(images, boxes, box_ind, crop_size)\r\n\r\n        return resize\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        images_shape = input_shape[0]\r\n        return images_shape\r\n\r\n\r\nimg = Input(shape=(8, 4, 3), name='img')\r\nq_len = Input(batch_shape=(None,), name='q_len')\r\nd_len = Input(batch_shape=(None,), name='d_len')\r\n\r\nz2 = ResizeLayer()([img, q_len, d_len])\r\n\r\nz = Flatten()(z2)\r\ns = Dense(1)(Dense(20, activation='relu')(z))\r\nmodel = Model([img, q_len, d_len], s, name='resize')\r\nprint(model.summary())\r\n```", "@levyfan, the issue is caused by the line:\r\ncrop_size = (nhwc[1], nhwc[2])\r\n\r\nNote that nhwc is a tensor and its slice will not have the value when feed as crop_size, and it cause the resize shape to be [None, None, None, 3], rather than [None, 8, 4, 3].\r\n\r\nIf you replace the line with below, which use image's static size, then it will correctly propagate the static shape to the resize.\r\ncrop_size = images.shape[1:3]\r\n\r\nAlternatively, you can also just set the static shape of resize before u return:\r\nresize.shape = images.shape\r\nreturn resize\r\n", "Thanks, that works!", "@qlzh727  Hi,\r\nabove problems about matterport maskrcnn is stated below\r\n\r\n\r\nif we use keras - 2.2.4\r\nthe output produced by timedistributed layer is\r\nx - inputshape --> (1,None,7,7,256)\r\nx = keras.Timedistributed(conv2(1024 , (7,7))) (x)\r\nx - output shape --> (None , 200, 1,1,1024)\r\n\r\nfor tensorflow 2.0\r\nthe output produced by timedistributed layer is\r\nx - inputshape --> (1,None,7,7,256)\r\nx = tf.keras.Timedistributed(conv2(1024 , (7,7))) (x)\r\nx - output shape --> (None , None, 1,1,1024)\r\n\r\nso basically the output shape is wrong in new tf 2.0 /timesteps calculated wrongly\r\n\r\nany ideas how to solvethis\r\nthanks", "> I tried to manually correct the shape of the custom layer by using the tf.reshape() or set_shape function after each use, but the summary of the model created in tf.keras differs from the one created in keras.\r\n\r\nhi i have converted the matterport model to tf 2.x model\r\njust had few queries , will you help me\r\nThanks", "Do not help this person. When he finds the answer, he closes the question and does not respond to those who need help.", "I found a solution, try at the end of the self.call method:\r\n\r\n```\r\ndef call(self, input):\r\n   input_shape = input.shape  # you must find a way to retrieve this value on your own\r\n   ...\r\n   out_shape = self.compute_output_shape(input_shape)\r\n   output = output.set_shape(out_shape)\r\n   return output\r\n```"]}, {"number": 33784, "title": "tfp.sts.AutoregressiveStateSpaceModel noise mean should be settable", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nin tfp.sts.AutoregressiveStateSpaceModel you cant currently set the mean of the normally distributed noise. this would be nice to add as some auto-regressive models may add a constant term at each time step. the math would then be :\r\n\r\n```python\r\nlevel[t+1] = (sum(coefficients * levels[t:t-order:-1]) +\r\n              Normal(level_mean, level_scale))\r\n```\r\n\r\n**Will this change the current api? How?**\r\nthis would require an additional parameter\r\n\r\n**Who will benefit with this feature?**\r\npeople who want to do auto-regressive models with a constant term\r\n\r\n**Any Other info.**\r\n", "comments": ["@jrm346,\r\nSorry for the delayed response. Can you please let us know if [this is the functionality](https://www.tensorflow.org/probability/api_docs/python/tfp/sts/AutoregressiveStateSpaceModel#mean) that you are looking for? \r\n\r\nIf not, please feel free to submit a **`PR`** so that the respective Engineers will review it.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33783, "title": "fix quantization specification doc error", "body": "", "comments": []}, {"number": 33782, "title": "Executing genrule @nccl_archive//:device_code_sm_61 failed (Exit 1): bash failed: error executing command ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.13\r\n- **Python version**: 3.7\r\n- **Bazel version (if compiling from source)**: 0.193\r\n- **GCC/Compiler version (if compiling from source)**: 5.5\r\n- **CUDA/cuDNN version**: 10.0/7\r\n- **GPU model and memory**: GTX 1080Ti\r\n- **Exact command to reproduce**: bazel build --spawn_strategy=standalone --verbose_failures --config=cuda --copt=\"-fPIC\" --copt=\"-DNDEBUG\" --local_resources 11048,2.0,2.0 -c dbg --copt -g //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nWhen I ran the upper command, I got the error as follows: nvlink fatal   : No input files specified; use option --help for more information\r\nHope someone could help me.\r\n\r\n### Source code / logs\r\nERROR: /home/yunxiang/.cache/bazel/_bazel_yunxiang/6e00d14c3b41ff4ee29863f700329782/external/nccl_archive/BUILD.bazel:139:1: Executing genrule @nccl_archive//:device_code_sm_61 failed (Exit 1): bash failed: error executing command \r\n  (cd /home/yunxiang/.cache/bazel/_bazel_yunxiang/6e00d14c3b41ff4ee29863f700329782/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64: \\\r\n    PATH=/home/yunxiang/.local/bin:/usr/local/python3.7/bin:/usr/local/cuda-10.0/bin:/home/yunxiang/bin:/home/yunxiang/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/python3.7/lib/python3.7/site-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=10.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION='' \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; external/local_config_nccl/nvlink --cpu-arch=X86_64 --arch=sm_61  --register-link-binaries=bazel-out/k8-dbg/genfiles/external/nccl_archive/device_code_sm_61.h --output-file=bazel-out/k8-dbg/genfiles/external/nccl_archive/device_code_sm_61.cubin')\r\nnvlink fatal   : No input files specified; use option --help for more information\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6494.760s, Critical Path: 459.04s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 13376 processes: 13376 local.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33782\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33782\">No</a>\n", "I downgrade the CUDA, cuDNN, TensorFlow as follows, and able to build it finally.\r\n\r\nTensorFlow version (use command below): 1.4\r\nPython version: 3.5\r\nBazel version (if compiling from source): 0.5.4\r\nCUDA/cuDNN version: 8/6", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33782\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33782\">No</a>\n"]}, {"number": 33781, "title": "  print interpreter information of tensors and nodes as tflite.", "body": "@rthadur \r\nPlease help merge this pr. thanks\r\n", "comments": ["@wenshuai-xiaomi can you please check the build failures ?", "This has been submitted. Can we mark this obsolete?"]}, {"number": 33780, "title": "core dump when call SetShapeFn in custom op under 2.0", "body": "", "comments": ["@zh794390558 ,\r\nThank you for raising the issue, Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@oanush ,\r\n\r\n**System information**\r\n- OS Platform and Distribution : centOS 7.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): tf2.0.0\r\n-GCC version: gcc (GCC) 4.8.5\r\n-test env:  import tensorflow as tf\r\n                  from tensorflow.python.framework.ops import disable_eager_execution\r\n                   disable_eager_execution()\r\n\r\n**SetShapeFn Code**\r\n\r\nStatus AddRNAShapeFn(InferenceContext* c) {\r\n  ShapeHandle input_data;\r\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input_data));\r\n  int wav_len = c->Value(c->Dim(input_data, 0));\r\n  bool  if_add_rir;\r\n  TF_RETURN_IF_ERROR(c->GetAttr(\"if_add_rir\", &if_add_rir));\r\n  c->set_output(0, c->Vector(wav_len));\r\n  return Status::OK();\r\n}\r\n\r\n**Error log **\r\n\r\ntensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, long long, tensorflow::shape_inference::ShapeHandle*)\r\n\r\n\tstd::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*)\r\n\ttensorflow::shape_inference::InferenceContext::Run(std::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)> const&)\r\n\ttensorflow::ShapeRefiner::RunShapeFn(tensorflow::Node const*, tensorflow::OpRegistrationData const*, tensorflow::ExtendedInferenceContext*)\r\n\ttensorflow::ShapeRefiner::AddNode(tensorflow::Node const*)\r\n\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@zh794390558 \r\nCan you please provide data in the standard template ? also should the same description be considered posted by @aishinchi ? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33779, "title": "tf 1.15.0  retrained ssdlite_mobilenet_v2_coco+focal loss to quantization", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu18.04\r\n- TensorFlow installed from (source or binary):  source\r\n- TensorFlow version (or github SHA if from source): 1.15.0\r\n\r\n\r\nStep1:retrain ssdlite_mobilenet_v2_coco model using focal loss,get model.ckpt\r\nStep2:using export_inference_graph.py to get frozen_inference_graph.pb and saved_model\r\nStep3:using tflite \r\n\r\n```\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(path/to/saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\n```\r\n//error\r\narray.data_type==array.final_data_type Array \"image_tensor\" has mis-matching .....(data_type=uint8,final_data_type=float)\r\n```\r\n\r\nThen, using `saved_model_cli show --dir=./saved_model --all` \r\n\r\nouput is\r\n\r\n```\r\nsignature_def['serving_default']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['inputs'] tensor_info:\r\n        dtype: DT_UINT8\r\n        shape: (-1, -1, -1, 3)\r\n        name: image_tensor:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['detection_boxes'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 100, 4)\r\n        name: detection_boxes:0\r\n    outputs['detection_classes'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 100)\r\n        name: detection_classes:0\r\n    outputs['detection_scores'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 100)\r\n        name: detection_scores:0\r\n    outputs['num_detections'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1)\r\n        name: num_detections:0\r\n  Method name is: tensorflow/serving/predict\r\n```\r\n\r\n1.Just means , my saved_model input is unit8 and output is float32, could not using tf-lite to quantization?\r\n2. Could get ssd_mobilenet_v2 quantized model without config parameter,it means train again!!\r\n`graph_rewriter {quantization {....}}`\r\n\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33779\">No</a>\n"]}, {"number": 33778, "title": "Example of \"audio recognition\" trained in tf-1.15.0 isn't able to recognize sound \"Yes\" on SparkFun Edge development board.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.\r\n- TensorFlow installed from (source or binary):\r\nCreated a docker container from docker image: tensorflow/tensorflow:1.15.0-gpu-py3-jupyter.\r\nInside the container, got tensorflow source tree through the following steps:\r\n```\r\nmkdir tensorflow\r\ncd tensorflow\r\ngit init\r\ngit remote add origin https://github.com/tensorflow/tensorflow.git\r\ngit ls-remote --tags origin | grep 1.15.0\r\n38ea9bbfea423eb968fcc70bc454471277c9537c\trefs/tags/v1.15.0\r\ngit pull origin refs/tags/v1.15.0\r\n```\r\n- TensorFlow version (use command below): v1.15.0.\r\n- Python version: 3.6.8.\r\n- Bazel version (if compiling from source): neither installed nor used. \r\n- GCC/Compiler version (if compiling from source): gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1). \r\n- CUDA/cuDNN version:  compute capability: 5.2. \r\n- GPU model and memory: GeForce GTX 960. \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nv1.15.0-rc3-22-g590d6ee 1.15.0\r\n\r\n**Describe the current behavior**\r\nGoing through the following steps (for all the steps in details, please see **Code to reproduce the issue** ), SparkFun Edge board was be flashed successfully. But it wasn't able to recognize the sound \u201cYes\u201d :-(\r\n\r\n**Describe the expected behavior**\r\nIf flashing the board with [the binary tf model](tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/simple_features/tiny_conv_simple_features_model_data.cc) that tf source tree brings, the sound \u201cYes\u201d was recognized perfectly.\r\nCould you let us know the exact environment and procedure that your tiny_conv_simple_features_model_data.cc was generated in? \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n### 1, Training model (refer to [Training model on your local machine](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#use-your-local-machine)). \r\n#### 1.1, In the same container that we got in \u201c**System information**\u201d.\r\n#### 1.2, \r\n```\r\npython tensorflow/tensorflow/examples/speech_commands/train.py \\\r\n--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\r\n--wanted_words=\"yes,no\" --silence_percentage=25 --unknown_percentage=25 \\\r\n--quantize=1 --verbosity=INFO --how_many_training_steps=\"15000,3000\" \\\r\n--learning_rate=\"0.001,0.0001\" --summaries_dir=/tmp/retrain_logs \\\r\n--data_dir=/tmp/speech_dataset \u2013train_dir=/tmp/speech_commands_train\r\n```\r\nThe training reached ~90%  accuracy, see [191028.log](https://github.com/tensorflow/tensorflow/files/3778241/191028.log.tar.gz) as attached.\r\n\r\n#### 1.3, \r\n```\r\npython tensorflow/tensorflow/examples/speech_commands/freeze.py \\\r\n--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\r\n--wanted_words=\"yes,no\" --quantize=1 --output_file=/tmp/tiny_conv.pb \\\r\n--start_checkpoint=/tmp/speech_commands_train/tiny_conv.ckpt-18000\r\n```\r\n#### 1.4, \r\n```\r\ntoco \\\r\n--graph_def_file=/tmp/tiny_conv.pb --output_file=/tmp/tiny_conv.tflite \\\r\n--input_shapes=1,49,40,1 --input_arrays=Reshape_2 --output_arrays='labels_softmax' \\\r\n--inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077\r\n```\r\n#### 1.5,   \r\n```\r\nxxd -i /tmp/tiny_conv.tflite > /tmp/tiny_conv_micro_features_model_data.cc\r\n```\r\n#### 1.6,\r\nModified the binary model file to [tiny_conv_micro_features_model_data.new.cc](https://github.com/tensorflow/tensorflow/files/3778266/tiny_conv_micro_features_model_data.new.cc.gz) as attached, put it into tensorflow/lite/experimental/micro/examples/micro_speech/micro_features\r\n### 2, Flashed the model, (refer to [Deploy to SparkFun Edge](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#deploy-to-sparkfun-edge)).\r\n#### 2.1, \r\n```\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge TAGS=\"CMSIS\" micro_speech_bin\r\n```\r\n#### 2.2, \r\n```\r\ncp tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info0.py \\\r\ntensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info.py\r\n```\r\n#### 2.3,\r\n```\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \\\r\n--bin tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin \\\r\n--load-address 0xC000 \\\r\n--magic-num 0xCB \\\r\n-o main_nonsecure_ota \\\r\n--version 0x0\r\n```\r\n#### 2.4, \r\n```\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\r\n--load-address 0x20000 \\\r\n--bin main_nonsecure_ota.bin \\\r\n-i 6 \\\r\n-o main_nonsecure_wire \\\r\n--options 0x1\r\n```\r\n#### 2.5,\r\nWalked through [AI on a microcontroller with TensorFlow Lite and SparkFun Edge](https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0), flashed our program and bootloader into the board. \r\nTest it then. \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["### 3. More results that I have dug out until Oct 31, 2019. \r\n#### 3.1, \r\nAs reported at 1.2, we got a model whose accuracy reached ~ 90%. But, after freezing, its \u201cpredictions\u201d on many \u201cYes\u201d sample wavs are always 33% (see\r\n[191031v2.log](https://github.com/tensorflow/tensorflow/files/3797952/191031v2.log)).\r\n#### 3.2, \r\nIf I just ran [your example for Training](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#training) by \"copy/paste\", the accuracy is < 10%! (see \r\n[191031v3.log](https://github.com/tensorflow/tensorflow/files/3797992/191031v3.log). (Could you let me know why?)\r\n#### 3.3, \r\nAlso on your guidance [Use your local machine](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#use-your-local-machine), you wrote: \r\n#### \"You must currently use the TensorFlow Nightly pip package. This version is confirmed to work:\"\r\n```\r\ntf-nightly-gpu==1.15.0.dev20190729\r\n```\r\nHowever, train.py still was failed when I ran the commands as below.  \r\n```\r\npip3 list | grep tensorflow\r\ntensorflow-estimator 1.15.1             \r\ntensorflow-gpu       1.15.0\r\n```\r\n```\r\npip3 install tf-nightly-gpu==1.15.0.dev20190729\r\nCollecting tf-nightly-gpu==1.15.0.dev20190729\r\n  Using cached https://files.pythonhosted.org/packages/c6/ed/6cc1a8a764c046cd102ec58904c32eebaa1360efe858796c97645f63401e/tf_nightly_gpu-1.15.0.dev20190729-cp36-cp36m-manylinux1_x86_64.whl\r\n......\r\nSuccessfully installed tf-nightly-gpu-1.15.0.dev20190729\r\n```\r\n```\r\npython tensorflow/tensorflow/examples/speech_commands/train.py \\\r\n> --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\r\n> --wanted_words=\"yes,no\" --silence_percentage=25 --unknown_percentage=25 \\\r\n> --quantize=1 --verbosity=INFO --how_many_training_steps=\"15000,3000\" \\\r\n> --learning_rate=\"0.001,0.0001\" --summaries_dir=/tmp/retrain_logs \\\r\n> --data_dir=/tmp/speech_dataset \u2013train_dir=/tmp/speech_commands_train\r\nTraceback (most recent call last):\r\n  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 81, in <module>\r\n    import input_data\r\n......\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features'\r\n```\r\nCould you let us know the environments that you confirmed the train.py could work with? And we would continue to work for you on this issue if you need. ", "The key problem of this issue is here -- \r\nThe [doc of Simple Audio Recognition](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#simple-audio-recognition) guides: \r\n\"\r\nTo begin the training process, go to the TensorFlow source tree and run:\r\n...\r\npython tensorflow/examples/speech_commands/train.py\r\n...\r\nAfter a few hours of training (depending on your machine's speed) ... you should see an **accuracy** of **between 85% and 90%**.\r\n\"\r\nBut the **accuracy** that I got with my reproduction is **33% or < 10%**  (see my commits 3.1 and 3.2 as above). \r\nI believe that **the command got success some times ago**.\r\nIt will be very appreciated if you could let us know **the environment (or configuration) that you had made the command succeed in with**? You just need to let us know which commit needs to be **restored** from repository, then we could reproduce your success of the training.  \r\nMany thanks again.", "Sorry you're having trouble reproducing our results.  @dansitu can help with the details of the exact configuration we used in our tutorial.  I've also downloaded the model file you supplied and will see if I get any better results.  Maybe @dansitu can also comment on the accuracy that should be expected when running this code on a sparkfun board with our demo code.  The accuracy number quoted is the accuracy expected from the training code.", "### 4, A model was created. \r\n***Thanks*** for [@rockyrhodes](https://github.com/rockyrhodes) taking care of the issue and [@dansitu](https://github.com/dansitu) handling it.\r\n\r\nWith surfing internet and my trials, the example model of \"speech recognition\", \r\ntrained by tensorflow/examples/speech_commands/***train.py***, can reach ***accuracy ~ 90%***. \r\nBut, if running the model on ***on SparkFun Edge board*** (e.g., a word \"Yes\"), the confidence score is ***far lower*** than the score that the existing binary model, provided by the commit,  provides. \r\nWhat is ***key problem*** for us to ***train your own*** \"speech recognition\" ***model***? According to my experiences, the key problem is to find correct git repository commit. \r\nAt the end of this comment, you will learn how to ***create***/***train***/***flash*** a model based on 2 commits of Tensorflow repository. If \"detection_threshold\" is set as 150 (the commit provides a binary format model whose \"detection_threshold\" is 200), the model could recognize almost all \"Yes\" heard on SparkFun Edge board. \r\n\r\n#### 4.1, Setup environment.\r\n[How to Train New TensorFlow Lite Micro Speech Models](https://www.digikey.com/en/maker/projects/how-to-train-new-tensorflow-lite-micro-speech-models/e9480d4a38264604a2bf0336ce11aa9e) is a good reference. \r\n```\r\nsudo docker run --runtime=nvidia \u2013name speech-verify -it tensorflow/tensorflow:1.15.0-gpu-py3-jupyter bash\r\nsudo docker container start speech-verify\r\nsudo docker container exec -it speech-verify /bin/bash \r\n```\r\nWithin the container,\r\n```\r\napt-get install -y curl zip git xxd\r\n\r\npip3 list | grep tensorflow\r\ntensorflow-estimator 1.15.1             \r\ntensorflow-gpu       1.15.0\r\n\r\npip3 install tf-nightly-gpu==1.15.0.dev20190729\r\npip3 install -I tensorflow_estimator==1.13.0\r\n\r\ncurl -O -L\u00a0https://github.com/bazelbuild/bazel/releases/download/0.23.1/bazel-0.23.1-installer-linux-x86_64.sh\r\nchmod +x bazel-0.23.1-installer-linux-x86_64.sh\r\n./bazel-0.23.1-installer-linux-x86_64.sh \r\n```\r\nCheckout 2 commits from Git repository of Tensorflow:\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\n\r\ncp -rp  tensorflow  tensorflow-aa47072ff4e2b7735b0e0ef9ef52f68ffbf7ef54\r\ncd  tensorflow-aa47072ff4e2b7735b0e0ef9ef52f68ffbf7ef54\r\ngit checkout aa47072ff4e2b7735b0e0ef9ef52f68ffbf7ef54\r\n\r\ncd ..\r\nmv tensorflow tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045\r\ncd tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045\r\ngit checkout 4a464440b2e8f382f442b6e952d64a56701ab045\r\n\r\nyes \"\" | ./configure\r\n\r\n```\r\n#### 4.2, Training.\r\nStill in the container:\r\n```\r\nbazel run -c opt --copt=-mavx2 --copt=-mfma tensorflow/examples/speech_commands:train -- --model_architecture=tiny_conv --window_stride=20 --preprocess=micro --wanted_words=\"yes,no\" --silence_percentage=25 --unknown_percentage=25 \u2013quantize=1\r\n\r\nbazel run tensorflow/examples/speech_commands:freeze -- --model_architecture=tiny_conv --window_stride=20 --preprocess=micro --wanted_words=\"yes,no\" --quantize=1 --output_file=/tmp/tiny_conv.pb \u2013start_checkpoint=/tmp/speech_commands_train/tiny_conv.ckpt-18000\r\n\r\nbazel run tensorflow/lite/toco:toco -- --input_file=/tmp/tiny_conv.pb --output_file=/tmp/tiny_conv.tflite --input_shapes=1,49,40,1 --input_arrays=Reshapexxd -i /tmp/tiny_conv.tflite > /tmp/tiny_conv_micro_features_model_data.cc_1 --output_arrays='labels_softmax' --inference_type=QUANTIZED_UINT8 --mean_values=0 --std_values=9.8077\r\n\r\nxxd -i /tmp/tiny_conv.tflite > /tmp/tiny_conv_micro_features_model_data.cc\r\n```\r\n#### 4.3, Flash.\r\nContinue inside container:\r\n```\r\ncd ../tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045\r\n```\r\nActually the commit provides an existing model that was trained, which is located at: ***tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/tiny_conv_micro_features_model_data.cc***. Change its name and keep it in case we want to test it as comparison. \r\nChange value of \"detection_threshold\" to 150 (source file: tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/recognize_commands.h).\r\n```\r\nmv tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.cc \r\ntensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.ori.cc\r\ncp -p  /tmp/tiny_conv_micro_features_model_data.cc tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile clean\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge TAGS=\"CMSIS\" micro_speech_bin\r\n\r\ncp tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info0.py \\\r\ntensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info.py\r\n\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \\\r\n--bin tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin \\\r\n--load-address 0xC000 \\\r\n--magic-num 0xCB \\\r\n-o main_nonsecure_ota \\\r\n--version 0x0\r\n\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\r\n--load-address 0x20000 \\\r\n--bin main_nonsecure_ota.bin \\\r\n-i 6 \\detection_threshold\r\n-o main_nonsecure_wire \\\r\n--options 0x1\r\n```\r\nFollowing the [STEPs](https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#5), flash the board physically. \r\n#### 4.4, Comparison for 2 test results.\r\nIf [Reading debug output](https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#8),we could get 2 test results. \r\n![binary-model-provided-by-the-commit](https://user-images.githubusercontent.com/20430028/68668334-e723ec80-0582-11ea-80e8-649de08202ef.png) is the test result originating from running the existing binary model (see 4.3). The test recognizes all sound \"Yes\" with \"detection_threshold=200\".\r\n![model-trained-by-the-commit](https://user-images.githubusercontent.com/20430028/68669339-43880b80-0585-11ea-85c8-5c1918f934ea.png) shows the test based on the model we have just trained. The model recognizes almost all \"Yes\" but detection_threshold is tuned to a lower value: 150. \r\n#### 4.5, Remaining question.\r\nWe have just created a model that could manage to recognize words (e.g., \"Yes\") as expected. But It is sure that someone had created a working model that can get higher confidence accuracy. How could we reach the \"higher confidence accuracy\"? \r\n\r\n", "As for my ***\"Remaining question\"*** (see 4.5 above): ***\"How could we reach the 'higher confidence accuracy'?\"***, could you give us some guidance? Thanks!", "#### 4.3, Flash (the section needs to be fixed as below)\r\nPrepare the board image to flash, which the trained model is in.\r\nStill in the container, change directory --\r\n```\r\ncd ../tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045\r\n```\r\nActually the commit provides an existing trained model, which is: tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045/tensorflow/lite/experimental/micro/examples/micro_speech/tiny_conv_micro_features_model_data.cc. Change its name as tiny_conv_micro_features_model_data.ori.cc and keep it in case you may need to test it as comparison.\r\n\r\nRegarding to the current \"confidence score\" that can be reached with the 2 commits, I would suggest to change value of \"[detection_threshold](tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/recognize_commands.h)\" to 150.\r\n```\r\nmv tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.cc \r\ntensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.ori.cc\r\ncp -p  /tmp/tiny_conv_micro_features_model_data.cc tensorflow/lite/experimental/micro/examples/micro_speech/micro_features\r\n```\r\nFollowing \"[Convert to a C array](https://www.tensorflow.org/lite/microcontrollers/build_convert#convert_to_a_c_array)\", copy the head and tail of tensorflow-4a464440b2e8f382f442b6e952d64a56701ab045/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.ori.cc, paste them to tiny_conv_micro_featurestensorflow-4a464440b2e8f382f442b6e952d64a56701ab045/tensorflow/lite/experimental/micro/examples/micro_speech/micro_features/tiny_conv_micro_features_model_data.cc.\r\n\r\nBuild borad image including the model and all depedencies --\r\n```\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile clean\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge TAGS=\"CMSIS\" micro_speech_bin\r\n\r\ncp tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info0.py \\\r\ntensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info.py\r\n\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \\\r\n--bin tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin \\\r\n--load-address 0xC000 \\\r\n--magic-num 0xCB \\\r\n-o main_nonsecure_ota \\\r\n--version 0x0\r\n\r\npython3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\r\n--load-address 0x20000 \\\r\n--bin main_nonsecure_ota.bin \\\r\n-i 6 \\detection_threshold\r\n-o main_nonsecure_wire \\\r\n--options 0x1\r\n```\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33778\">No</a>\n"]}, {"number": 33777, "title": "Tensorflow Probability distributions HiddenMarkovModel not working with tf.function", "body": "using tensorflow 2.0 on cpu\r\n\r\nthe following function works with no errors when executing in eager mode, but if it is decorated with `@tf.function` i get the error at the bottom.\r\n\r\n```python\r\ndef generate_data(size, p_0, p_0_0, p_1_1, mu0, s0, mu1, s1):\r\n    states = tfd.Categorical(probs=[p_0, 1-p_0])\r\n\r\n    transition = tfd.Categorical(probs=[[p_0_0, 1 - p_0_0],\r\n                                        [1 - p_1_1, p_1_1]])\r\n\r\n    emission = tfd.Normal(loc=[mu0, mu1], scale=[s0, s1])\r\n\r\n    model = tfd.HiddenMarkovModel(states, transition, emission, size)\r\n\r\n    return model.sample()\r\n\r\ndata = generate_data(50, 0.01, 0.3, 0.7, -10, 2, 10, 3)\r\n\r\nprint(data)\r\n```\r\nand the error\r\n```\r\ntraceback (most recent call last):\r\n  File \"/home/abaka/Abaka.FIN.Apis/test.py\", line 21, in <module>\r\n    data = generate_data(50, 0.01, 0.3, 0.7, -10, 2, 10, 3)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 905, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n    relative to /home/abaka:\r\n\r\n    Abaka.FIN.Apis/test.py:19 generate_data  *\r\n        return model.sample()\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py:848 sample\r\n        return self._call_sample_n(sample_shape, seed, name, **kwargs)\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py:826 _call_sample_n\r\n        samples = self._sample_n(n, seed, **kwargs)\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:406 _sample_n\r\n        lambda: init_state[tf.newaxis, ...])\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/internal/prefer_static.py:176 cond\r\n        return true_fn()\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:397 _scan_multiple_steps\r\n        initializer=init_state)\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/functional_ops.py:508 scan\r\n        maximum_iterations=n)\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:2675 while_loop\r\n        back_prop=back_prop)\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:234 while_loop\r\n        len_orig_loop_vars], expand_composites=True))\r\n    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:1068 _check_shapes_compat\r\n        \"specify a less-specific shape.\" % (input_t.name, shape, t.shape))\r\n\r\n    ValueError: Input tensor 'HiddenMarkovModel_1/sample/Reshape:0' enters the loop with shape (1, 1), but has shape (1, None) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\r\n```\r\n", "comments": ["@jrm346 ,\r\nWhen tried executing the given code \r\n`AttributeError: module 'tensorflow_datasets' has no attribute 'Categorical'` was faced, can you provide complete standalone code to reproduce the issue ?Thanks! ", "sorry forgot to add my import statements.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\ntfd = tfp.distributions\r\n\r\n@tf.function  # <---- This is what causes the error (the function works fine in eager mode)\r\ndef generate_data(size, p_0, p_0_0, p_1_1, mu0, s0, mu1, s1):\r\n    states = tfd.Categorical(probs=[p_0, 1-p_0])\r\n\r\n    transition = tfd.Categorical(probs=[[p_0_0, 1 - p_0_0],\r\n                                        [1 - p_1_1, p_1_1]])\r\n\r\n    emission = tfd.Normal(loc=[mu0, mu1], scale=[s0, s1])\r\n\r\n    model = tfd.HiddenMarkovModel(states, transition, emission, size)\r\n\r\n    return model.sample()\r\n\r\ndata = generate_data(50, 0.01, 0.3, 0.7, -10, 2, 10, 3)\r\n\r\nprint(data)\r\n```", "Issue replicating for the given code, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/e46b968c3a12f9aef2efa7336cd2accb/33777.ipynb) of colab.Thanks!", "yup that's the error should work with the `@tf.function` line removed", "@brianwa84 is HiddenMarkovModel compatible with graph mode?", "I assume its supposed to be. The log_prob method of the class works in graph mode. Also, all the other tensorflow probability distributions i have tried seem to be compatible with graph mode.", "@jrm346 \r\n\r\nCan you please try with latest TF version TF 2.2.0-rc4 (`!pip install tensorflow==2.2-rc4`). I am not seeing any issue with TF 2.2.0-rc4.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/7d018d0493e23d1e690e3a2e96f33843/untitled858.ipynb).Please, verify once and close the issue.Thanks!", "@jrm346 \r\n\r\nI am closing this issue as it was resolved in TF 2.2.0-rc4 version.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33777\">No</a>\n"]}]