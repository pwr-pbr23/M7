[{"number": 47261, "title": "[Code provided] Weird tf.function behaviour with boolean inputs after trace", "body": "When passed a tensor (dtype = tf.bool) from an tf.function to another tf.function, its behaviour become weird after first time call (trace).\r\n\r\nhttps://colab.research.google.com/drive/1id1t9L8xypGbavcA2hqtNEDQ4VFwJ40I?usp=sharing", "comments": ["@edwardyehuang,\r\nI was able to reproduce the issue with TF v2.3 and [TF v2.4](https://colab.research.google.com/gist/amahendrakar/24e97b6032722f41d872a86ef4bfb535/47261.ipynb). However, the issue seems to be fixed with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/e9f37c18981bcdc2715461c28aeb267e/47261-tf-nightly.ipynb). \r\n\r\nPlease check the linked gist for reference. Thanks!", "Confirm it has been fixed in nightly.\r\nBut I wonder which commits fix it. Could you help me to find it if you have time @amahendrakar ? \r\n\r\nClose issue for now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47261\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47261\">No</a>\n"]}, {"number": 47260, "title": "EfficientnetB1 :ValueError: You are trying to load a weight file containing 185 layers into a model with 184 layers ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\nyes- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nColab - OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nSource- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n3.6- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nafter using your code efficientnet_weight_update_util.py to  converted pretrained weights model.ckpt to efficientnetb1_notop.h5\r\n\r\nplease help, im getting the mentioned error\r\nmodel = EfficientNetB1(weights=\"efficientnetb1_notop.h5\", include_top=False)\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@gunjan5489 \r\nPlease share simple indented stand alone code to replicate the issue faced along with error logs, or if possible share a colab gist with the same.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47260\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47260\">No</a>\n"]}, {"number": 47259, "title": "tflite building is taking hours", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): yocto\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 2.4 \r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.7\r\n- GCC/Compiler version (if compiling from source): 10.2\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to compile tensorflow-lite and benchmark_model from source using yocto. I already managed to do it using a yocto recipe based on the Makefile. But the Makefile support is limited, so I need to compile tensorflow-lite and benchmark_model using bazel. But bazel build takes several hours!  \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI started from http://git.yoctoproject.org/cgit/cgit.cgi/meta-tensorflow/ and slightly modified http://git.yoctoproject.org/cgit/cgit.cgi/meta-tensorflow/tree/recipes-framework/tensorflow/tensorflow_2.4.0.bb to compile tensorflow-lite instead of tensorflow. Basically I just modified the do_compile so now it is:\r\n```\r\ndo_compile () {\r\n    export CT_NAME=$(echo ${HOST_PREFIX} | rev | cut -c 2- | rev)\r\n    unset CC\r\n    ${BAZEL} build \\\r\n        --jobs=40 \\\r\n        ${TF_ARGS_EXTRA} \\\r\n        -c opt \\\r\n        --cpu=${BAZEL_TARGET_CPU} \\\r\n        --crosstool_top=@local_config_yocto_compiler//:toolchain \\\r\n        --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n        --copt -DTF_LITE_DISABLE_X86_NEON --copt -DCL_DELEGATE_NO_GL \\\r\n        //tensorflow/lite:libtensorflowlite.so \\\r\n        //tensorflow/lite/tools/benchmark:benchmark_model \\\r\n        //tensorflow/tools/pip_package:build_pip_package \\\r\n        ${TF_TARGET_EXTRA}\r\n}\r\n```\r\nI also updated the do_install function with the correct path (tensorflow --> tensorflow-lite)\r\n\r\nAnd the recipe works. I was able to install `benchmark_model` on the target and run it. \r\nThe issue here is that, the build takes literally 3 hours to complete while with the Makefile it tooks only few minutes. \r\nI am building on a very powerfull machine with 40 cores and 189G of RAM. When using `htop` to monitor cpu load, I see only a few processes although I added `--jobs=40` on the bazel build command. \r\n\r\nAm I missing something here? \r\nThank you for your help\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Did you also try using [instructions on TF Lite](https://www.tensorflow.org/lite/guide/build_arm64) webpage?\r\nhttps://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary", "The following lines are used to build TF not TFLite. You can remove them.\r\n```\r\n        //tensorflow/tools/pip_package:build_pip_package \\\r\n        ${TF_TARGET_EXTRA}\r\n```", "thank you @terryheo  this is much faster!! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47259\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47259\">No</a>\n"]}, {"number": 47258, "title": "[TFL] Remove unnecessary Reshape before FullyConnected.", "body": "Remove unnecessary Reshape before FullyConnected. TFLite support N-D input of shape [batch_size, ..., channels] for FullyConnected. When keep_num_dims is false, all dimensions except the last one are collapsed into a single dimension. Therefore, it's safe to remove Reshape when it does not alter the last dimension.\r\n\r\nThe pattern is found in the official [mobilebert](https://www.tensorflow.org/lite/models/bert_qa/overview). Reshape op is not expensive but will block the folding of two consecutive FullyConnected Op (unimplemented yet).\r\n\r\nI benchmark with simple model here, which is similar to the one found in provided tflite mobilebert model `bert/encoder/layer_0/bottleneck/attention/FakeLayerNorm/add`.\r\n\r\n```python\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(128, batch_input_shape=(1, 384, 128), use_bias=True),\r\n])\r\n```\r\n\r\nIt contains a pattern of Reshape-FullyConnected-Reshape. This PR remove the first Reshape so it becomes FullyConnected-Reshape. The performance on Pixel3a is in the following\r\n\r\n-----\r\nBefore\r\n```\r\ncount=1035 first=987 curr=923 min=913 max=1070 avg=939.102 std=27\r\n```\r\n-----\r\nAfter\r\n```\r\ncount=1049 first=991 curr=910 min=894 max=1069 avg=923.888 std=31\r\n```\r\n-----\r\n\r\nFor end2end testing, I download the savedmodel from [google-research/mobilebert](https://github.com/google-research/google-research/tree/master/mobilebert) (floating point) and convert to tflite.\r\n\r\n-----\r\nBefore\r\n```\r\ncount=94 first=1612190 curr=1611814 min=1601869 max=1623227 avg=1.61185e+06 std=4439\r\n```\r\n-----\r\nAfter\r\n```\r\ncount=94 first=1601583 curr=1600427 min=1590411 max=1614870 avg=1.60146e+06 std=5378\r\n```\r\n-----\r\n\r\nThere is no significant performance regression or improvement as FullyConnected ops dominate the running time.\r\n\r\nI have to reword that the Reshape that will block the folding of two consecutive FullyConnected disappears if I convert the model  manually with tf-nightly, but the pattern still happens very often in mobilebert as well as using `tf.keras.layers.Dense` with 3D or higher input. Also, I cannot really find the pattern stated in my previous response https://github.com/tensorflow/tensorflow/pull/47258#issuecomment-782819838 if I convert the model manually with tf-nightly.\r\n\r\nMoreover, even with the simple two consecutive dense layers with 3D input, for example,\r\n\r\n```python\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(2, batch_input_shape=(1, 384, 512)),\r\n  tf.keras.layers.Dense(3)\r\n])\r\n```\r\n\r\nthe Reshape ops between two dense layers are optimized out.", "comments": ["I think we can even remove reshape without the constraint of last dimension. In TFLite runtime, number of rows is determined by weights instead of input and there is no check about the dimensions of input, which means that there can be one or more inner dimensions that are considered as rows.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/0e6b3a307f6363a9ee9dc9e03a8a0350c7668799/tensorflow/lite/kernels/fully_connected.cc#L225-L227\r\n\r\nGiven reshape op does not modify the order of data, it should be safe enough to be removed.\r\n\r\nSome examples in mobilebert (`bert/encoder/layer_16/attention/self/MatMul_1`)\r\n\r\n![image](https://user-images.githubusercontent.com/11615393/108619597-b9129680-73da-11eb-9a75-27da262155f4.png)", "Generally, it looks good to me. However, I wonder that the new pattern performs really better or not since the fully connected op may be sensitive with the dimension information. Could you simply verify the performance in order not to make a performance regression on it?", "I benchmark with simple model here, which is similar to the one found in provided tflite mobilebert model `bert/encoder/layer_0/bottleneck/attention/FakeLayerNorm/add`.\r\n\r\n```python\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(128, batch_input_shape=(1, 384, 128), use_bias=True),\r\n])\r\n```\r\n\r\nIt contains a pattern of Reshape-FullyConnected-Reshape. This PR remove the first Reshape so it becomes FullyConnected-Reshape. The performance on Pixel3a is in the following\r\n\r\n-----\r\nBefore\r\n```\r\ncount=1035 first=987 curr=923 min=913 max=1070 avg=939.102 std=27\r\n```\r\n-----\r\nAfter\r\n```\r\ncount=1049 first=991 curr=910 min=894 max=1069 avg=923.888 std=31\r\n```\r\n-----\r\n\r\nFor end2end testing, I download the savedmodel from [google-research/mobilebert](https://github.com/google-research/google-research/tree/master/mobilebert) (floating point) and convert to tflite.\r\n\r\n-----\r\nBefore\r\n```\r\ncount=94 first=1612190 curr=1611814 min=1601869 max=1623227 avg=1.61185e+06 std=4439\r\n```\r\n-----\r\nAfter\r\n```\r\ncount=94 first=1601583 curr=1600427 min=1590411 max=1614870 avg=1.60146e+06 std=5378\r\n```\r\n-----\r\n\r\nThere is no significant performance regression or improvement as FullyConnected ops dominate the running time.\r\n\r\nI have to reword that the Reshape that will block the folding of two consecutive FullyConnected disappears if I convert the model  manually with tf-nightly, but the pattern still happens very often in mobilebert as well as using `tf.keras.layers.Dense` with 3D or higher input. Also, I cannot really find the pattern stated in my previous response https://github.com/tensorflow/tensorflow/pull/47258#issuecomment-782819838 if I convert the model manually with tf-nightly.\r\n\r\nMoreover, even with the simple two consecutive dense layers with 3D input, for example,\r\n\r\n```python\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(2, batch_input_shape=(1, 384, 512)),\r\n  tf.keras.layers.Dense(3)\r\n])\r\n```\r\n\r\nthe Reshape ops between two dense layers are optimized out.\r\n\r\nGiven that I cannot find a pattern that Reshape will block any fusing opportunities in nightly version and there is only limited improvement, I think this PR becomes meaningless. What do you think?", "I can see that there is a small improvement in both simple case and mobilebert case. Thank you @WindQAQ for conducting these tests! Could you also leave these information in the PR's description?", "Updated the descriptions \ud83d\ude03 BTW, it would be great if one can update the provided mobilebert tflite model on the official example. I see that it is from tfhub, and it seems to be converted with v1 converter. It should be okay to convert it with mlir converter given that google-research also provides saved model as well. Thank you!", "Thanks for the suggestion! To be clear, could you share the TOCO-generated mobilebert link to me? I will make a request to update the model file.", "Here is the model\r\n- TF hub: https://tfhub.dev/tensorflow/lite-model/mobilebert/1/metadata/1\r\n- From official website (same model with TF hub): https://www.tensorflow.org/lite/models/bert_qa/overview\r\n- Pretrained ckpt from google-research: https://github.com/google-research/google-research/tree/master/mobilebert#pre-trained-checkpoints\r\n\r\n"]}, {"number": 47257, "title": "MultiWorkerMirroredStrategy rendezvous Did not find key ", "body": "Hi, I want to use rendezvous to transfer tensor between two machines within the scope of MultiWorkerMirroredStrategy, but it complains an Internal error `Did not find key my_tensor_name`.\r\n\r\nWhat is the device name different machines used to identify each other in the cluster? Can two machines identify each other with such device name? \r\n```c++\r\nconst char* dst_device_name = \"/job:worker/replica:0/task:1/device:CPU:0\";\r\nconst char* src_device_name= \"/job:worker/replica:0/task:0/device:CPU:0\";\r\n```\r\n\r\nBTW, `typeid(*OpKernelContext->rendezvous()).name()` show `SimpleRendezvous` in one machine and `IntraProcessRendezvous` for another machine. Why not `*Remote*Rendezvous` is created? \r\n\r\nHere is my code snippet:\r\n1. my custom op\r\n```c++\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include <chrono>\r\n#include <thread>\r\n\r\nnamespace tensorflow {\r\n\r\nusing GPUDevice = Eigen::GpuDevice;\r\nusing CPUDevice = Eigen::ThreadPoolDevice; \r\n\r\nclass TestRendezvousMultiWorkerOp : public AsyncOpKernel {\r\npublic:\r\n    explicit TestRendezvousMultiWorkerOp(OpKernelConstruction* ctx) : AsyncOpKernel(ctx) {\r\n        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"task_id\", &task_id_));\r\n        OP_REQUIRES(ctx, task_id_ >= 0, \r\n            errors::Internal(\"task_id should be >= 0, but got \", task_id_));\r\n    }\r\n    void ComputeAsync(OpKernelContext* ctx, DoneCallback done) override {\r\n        OP_REQUIRES_ASYNC(ctx, ctx->rendezvous() != nullptr,\r\n            errors::Internal(\"Op kernel context needs to provide a rendezvous.\"), done);\r\n\r\n        const char* dst_device_name = \"/job:worker/replica:0/task:1/device:CPU:0\";\r\n        const char* src_device_name = \"/job:worker/replica:0/task:0/device:CPU:0\";\r\n\r\n        std::string send_key = Rendezvous::CreateKey(\r\n                            src_device_name /*src_device*/,\r\n                            123/*src_incarnation*/,\r\n                            dst_device_name /*dst_device*/,\r\n                            \"test_rendezvous_string\"/*name*/,\r\n                            FrameAndIter(0, 0)/*frame_and_iter*/);\r\n\r\n        Rendezvous::ParsedKey parsed_key;\r\n        OP_REQUIRES_OK_ASYNC(ctx, Rendezvous::ParseKey(send_key, &parsed_key), done);\r\n        \r\n        Rendezvous::Args args;\r\n\r\n        const Tensor* input_tensor = nullptr;\r\n        OP_REQUIRES_OK_ASYNC(ctx, ctx->input(\"value\", &input_tensor), done);\r\n        Tensor* out_tensor = nullptr;\r\n        OP_REQUIRES_OK_ASYNC(ctx, ctx->allocate_output(0, input_tensor->shape(), &out_tensor), done);\r\n\r\n        if (task_id_ == 0) {\r\n            OP_REQUIRES_OK_ASYNC(ctx, ctx->rendezvous()->Send(parsed_key, args, *input_tensor, ctx->is_input_dead()), done);\r\n            std::memcpy(out_tensor->data(), input_tensor->data(), input_tensor->TotalBytes());\r\n            std::this_thread::sleep_for(std::chrono::seconds(5));\r\n        } else {\r\n            bool is_dead = false;\r\n            OP_REQUIRES_OK_ASYNC(ctx, ctx->rendezvous()->Recv(parsed_key, args, out_tensor, &is_dead), done);\r\n        }\r\n\r\n        done();\r\n        \r\n    }\r\nprivate:\r\n    int task_id_;\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"TestRendezvousMultiWorker\").Device(DEVICE_CPU), \r\n                        TestRendezvousMultiWorkerOp);\r\n\r\n} // namespace tensorflow\r\n```\r\n\r\n2. my python script\r\n```python\r\nimport tensorflow as tf\r\nimport os, json\r\n\r\nos.environ['CUDA_VISIBLE_DEVICES'] = \"\"\r\n\r\nos.environ[\"TF_CONFIG\"] = json.dumps({\r\n    \"cluster\": {\"worker\": [\"host1:port\", \"host2:port\"]},\r\n    \"task\": {\"type\": \"worker\", \"index\": args.task_id}\r\n})\r\n\r\nresolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\r\nstrategy = tf.distribute.MultiWorkerMirroredStrategy(resolver)\r\n\r\nimport my_custom_lib\r\n\r\n@tf.function\r\ndef _test_step(task_id):\r\n    value = tf.constant([1.0, 2.0])\r\n    out = my_custom_lib.test_rendezvous_multi_worker(value, task_id=task_id)\r\n    return out\r\n\r\nout = strategy.run(_test_step, args=(args.task_id,))\r\nprint(out)\r\n```\r\n\r\n3. the python3 command\r\n```python\r\npython3 file.py --task_id=0 # on machine 1\r\npython3 file.py --task_id=1 # on machine 2\r\n```", "comments": ["This is not supported. With MultiWorkerMirroredStrategy, you only have access to your local devices. Normally people use collective operations like all-reduce and all-gather to communicate between devices.\r\n\r\n", "This seems to be a duplicate of #47277. There's no plan to support using rendezvous to communicate between workers with MultiWorkerMirroredStrategy. We can discuss in #47277 about your use case and alternatives.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47257\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47257\">No</a>\n"]}, {"number": 47256, "title": "[Grappler] Optimise branches with constant predicates. ", "body": "I am using tf 1.15. When I try to optimize a graph using grappler and get an optimized graph_def, I see that branches on constant predicates are not folded. Is this something that is not supported?\r\n", "comments": ["@bhatuzdaname \r\nYes there is no support for 1.x as well now, please upgrade to 2.x and let us know in case you face any issues.\r\n\r\nOr you will have to implement  a custom kernel to associate the mapping predicates, or you may us TensorRT or TFLite  for optimizing the graph .", "Hi, I tried it with 2.4 and face the same issue.", "@bhatuzdaname Can you please share a simple standalone code (with `TF2.x`) to reproduce the issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47256\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47256\">No</a>\n"]}, {"number": 47255, "title": "First Commit for issue #47216", "body": "I have made some changes to address issue #47216 - https://github.com/tensorflow/tensorflow/issues/47216\r\nThis is my first pull request to TensorFlow, so I would appreciate complete feedback including the coding style too.\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47255) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "Thanks for the PR!\r\n\r\nBut one thing to notice is that python is not a type language, so generally we discourage type checking in the code. ", "Thanks for the review @chenmoneygithub, I made changes to my pull request. I converted the weights to np.array, so even if we use get_weights() or .weights or send in the layer weights manually to the set_weights() function, it will not return a type error. Please check my pull request."]}, {"number": 47254, "title": "Why TF do not support strides = [1,0] or [0,1] for conv2d?", "body": "It will mean the kernel moves on only one direction. \r\nAre there alternative way to do it?\r\nThank you very much.", "comments": ["@guotong1988 \r\n\r\nPlease, share colab link or simple standalone code to reproduce the issue.It helps us in localizing the issue faster.Thanks!\r\n", "```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch_size = 2\r\nsequence_len = 5\r\nhidden_size = 16\r\nkernel_len = 2\r\nin_channel = 1\r\nout_channel = hidden_size\r\na1 = np.array(np.arange(1, 1 + sequence_len * hidden_size).reshape([sequence_len, hidden_size, in_channel]),\r\n              dtype=np.float32)\r\n\r\ninputX = np.stack([a1, a1], axis=0)\r\n\r\n\r\nkernel = np.array(np.arange(1, 1 + kernel_len * hidden_size * in_channel * out_channel), dtype=np.float32).reshape(\r\n    [kernel_len, hidden_size, in_channel, out_channel])\r\n\r\n\r\nconv2d = tf.nn.conv2d(inputX, kernel, strides=[1,0], padding='VALID')\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    print(sess.run(tf.shape(conv2d)))\r\n    print(sess.run(conv2d))\r\n\r\n```", "@guotong1988 \r\n\r\nWhich version of TF you are using?.\r\nI think you are using 1.x. Can you please check with recent stable version 2.4 or nightly version and see if the issue still persists?\r\nThanks!", "I think it is easy to edit the code to TF2.", "@guotong1988,\r\nPlease share the code in Tensorflow Version 2.x. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47254\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47254\">No</a>\n"]}, {"number": 47253, "title": "tensorflow is shown on listing packages using pip list or conda list but you can't import in Python", "body": "Same issue happened even with using pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-2.3.0-cp38-cp38-macosx_10_14_x86_64.whl\r\n\r\nas mentioned in https://www.tensorflow.org/install/pip#package-location\r\n\r\ntensorflow is shown on listing packages using pip list or conda list but you can't import in Python\r\n\r\nWhen I try to import TensorFlow the kernel restarting and then I have the message \r\n\r\n[SpyderKernelApp] WARNING | No such comm: 7843964a725e11eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: 81501ed4725e11eb900a1e29c0108246", "comments": ["@nayrr25,\r\nIn order to expedite the trouble-shooting process, could you please provide the following details\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nand the exact sequence of commands / steps that you executed before running into the problem. Thanks! ", "Also, looking at the messages it seems like the issue is with Spyder IDE. To confirm if TensorFlow is successfully installed please run the below code snippet. \r\n```\r\nimport tensorflow as tf\r\nprint(tf.reduce_sum(tf.random.normal([1000, 1000])))\r\n```\r\nThanks!", "When I run that code:\r\n\r\nimport tensorflow as tf\r\nprint(tf.reduce_sum(tf.random.normal([1000, 1000])))\r\n\r\nI receive that message:\r\n\r\n\r\nKernel died, restarting\r\nRestarting kernel... \r\n\r\n[SpyderKernelApp] WARNING | No such comm: 7843964a725e11eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: 81501ed4725e11eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: e012dd08725e11eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: b8bfbb76726411eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: f1fb85aa726411eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: 24454e6e726b11eb900a1e29c0108246\r\n[SpyderKernelApp] WARNING | No such comm: d8eaf940726b11eb900a1e29c0108246", "@nayrr25,\r\nPlease try importing TensorFlow in the macOS terminal i.e. outside the conda environment and check if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47253\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47253\">No</a>\n"]}, {"number": 47252, "title": "Same issue happened even with using  pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-2.3.0-cp38-cp38-macosx_10_14_x86_64.whl  as mentioned in https://www.tensorflow.org/install/pip#package-location  tensorflow is shown on listing packages using pip list or conda list but you can't import in Python", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@nayrr25 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47252\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47252\">No</a>\n"]}, {"number": 47251, "title": "Add GPU implementation of SparseReshape", "body": "This follows https://github.com/tensorflow/tensorflow/pull/46275.\r\n\r\ncc @nluehr ", "comments": []}, {"number": 47250, "title": "Please Do not merge. This is a dummy PR for checking my accesses.", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47250) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 47249, "title": "CUDA_ERROR_ILLEGAL_ADDRESS after upgrading form TF 2.3.1 to 2.3.2 on Windows 10", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: no\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: -\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: v2.3.1-38-g9edbe5075f7 2.3.2\r\n-   **Python version**: 3.7.5\r\n-   **Bazel version (if compiling from source)**: -\r\n-   **GCC/Compiler version (if compiling from source)**: -\r\n-   **CUDA/cuDNN version**: cuda_10.1.105_418.96_win10.exe / cudnn-10.1-windows10-x64-v7.6.5.32.zip\r\n-   **GPU model and memory**: Geforce RTX 2060, 6 GB RAM\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm running a CNN in TF.\r\nOn TF 2.3.1 it runs fine.\r\n(On TF 2.4 it runs out of memory - another filed bug.)\r\nNow I tried it on TF 2.3.2 (upgraded both tensorflow and tensorflow-gpu). At Epoch 740/800 it gives the bellow CUDA_ERROR_ILLEGAL_ADDRESS error.\r\nNothing changed, compared to the previous runs, only the TF version.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nEpoch 739/800\r\n61/61 [==============================] - 12s 200ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.2726 - val_accuracy: 0.9485\r\nEpoch 740/800\r\n50/61 [=======================>......] - ETA: 2s - loss: 0.0192 - accuracy: 0.99282021-02-18 20:55:36.002311: E tensorflow/stream_executor/cuda/cuda_driver.cc:951] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered :: 0x00007FFA1C753DA5\r\n        tensorflow::CurrentStackTrace\r\n0x00007FFA1C4A286E      tensorflow::CostGraphDef_Node::set_is_final\r\n0x00007FFA1C64AA1E      stream_executor::StreamExecutor::SetDeviceSharedMemoryConfig\r\n0x00007FFA1A1DB796      tensorflow::StepStats::internal_default_instance\r\n0x00007FFA1A1ECFC4      google::protobuf::RepeatedPtrField<tensorflow::InterconnectLink>::Add\r\n0x00007FFA020A0177      std::vector<tensorflow::DtypeAndPartialTensorShape,std::allocator<tensorflow::DtypeAndPartialTensorShape> >::operator=\r\n0x00007FFA0207B0BB      absl::lts_2020_02_25::Span<tensorflow::Tensor const >::end\r\n0x00007FFA01FF3ACF      TFE_TensorHandleResolve\r\n0x00007FFA01F90E83      TFE_Py_TensorShapeSlice\r\n0x00007FFA01F8E6FA      std::_Tree<std::_Tmap_traits<std::array<std::basic_string<char,std::char_traits<char>,std::allocator<char> >,0>,tensorflow::monitoring::CounterCell,std::less<std::array<std::basic_string<char,std::char_traits<char>,std::allocator<char>\r\n0x00007FFA529A2AB7      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A318C      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A32E3      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A32E3      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA5299FBEA      PyFunction_FastCallDict\r\n0x00007FFA529B4DCD      PyObject_IsAbstract\r\n0x00007FFA529A46D5      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3A0F      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3E12      PyEval_EvalFrameDefault\r\n0x00007FFA529A32E3      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3E12      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3A0F      PyEval_EvalFrameDefault\r\n0x00007FFA529A32E3      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A32E3      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A455A      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A3963      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA5299FBEA      PyFunction_FastCallDict\r\n0x00007FFA529B4DCD      PyObject_IsAbstract\r\n0x00007FFA529A46D5      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529A33FC      PyMethodDef_RawFastCallKeywords\r\n0x00007FFA529A455A      PyEval_EvalFrameDefault\r\n0x00007FFA529A0886      PyEval_EvalCodeWithName\r\n0x00007FFA529C0CFF      PyEval_EvalCodeEx\r\n0x00007FFA529C0C5D      PyEval_EvalCode\r\n0x00007FFA529C0C07      PyArena_Free\r\n0x00007FFA52B24A95      PyRun_FileExFlags\r\n0x00007FFA52B252BC      PyRun_SimpleFileExFlags\r\n0x00007FFA52B24963      PyRun_AnyFileExFlags\r\n0x00007FFA52A71113      Py_UnixMain\r\n0x00007FFA52A711BB      Py_UnixMain\r\n0x00007FFA529F8C00      PyErr_NoMemory\r\n0x00007FFA529A5AC3      Py_Main\r\n0x00007FFA529A5A9E      Py_Main\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 103, in <module>\r\n    epochs=EPOCHS, verbose=1)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1103, in fit\r\n    callbacks.on_train_batch_end(end_step, logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 440, in on_train_batch_end\r\n    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 289, in _call_batch_hook\r\n    self._call_batch_end_hook(mode, batch, logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 309, in _call_batch_end_hook\r\n    self._call_batch_hook_helper(hook_name, batch, logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 342, in _call_batch_hook_helper\r\n    hook(batch, logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 961, in on_train_batch_end\r\n    self._batch_update_progbar(batch, logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1016, in _batch_update_progbar\r\n    logs = tf_utils.to_numpy_or_python_type(logs)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 537, in to_numpy_or_python_type\r\n    return nest.map_structure(_to_single_numpy_or_python_type, tensors)\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 635, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 635, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 533, in _to_single_numpy_or_python_type\r\n    x = t.numpy()\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1063, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1031, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: GPU sync failed\r\n2021-02-18 20:55:36.255246: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n         [[{{node PyFunc}}]]\r\n\r\n", "comments": ["@lmocsi \r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#gpu).Can you please create a fresh environment and see if the issue still persists.Thanks!", "@ravikyram \r\nNeither configuration fits the above problem description.\r\nWith TF 2.4, I have another bug filed (#46111).\r\n", "@lmocsi,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet so that we can reproduce the issue on our end.\r\n\r\nAlso, try limiting GPU memory growth using any of the methods listed [here](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and check if it helps.\r\n\r\nThanks!\r\n\r\n", "I was using code from here:\r\n   https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/\r\n\r\nThe only difference was, that in class SmallerVGGNet, I added some extra layers (duplicating some existing ones).\r\n", "> The only difference was, that in class SmallerVGGNet, I added some extra layers (duplicating some existing ones).\r\n\r\nCould you please share the Python file/notebook you are running? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I run the code like this:\r\npython train.py -d dataset -m celeb.model -l lb.pickle\r\n(attached python files have been renamed to .txt, since this site does not support uploading python files: train.py -> train.txt, pyimagesearch/smallervggnet.py -> pyimagesearch/smallervggnet.txt)\r\nAnd you need images in the dataset directory in subdirectories, named like emma_watson or charlize_theron.\r\n(I have 731 MBs of them in 10069 files, so I won't upload them)\r\n\r\n[smallervggnet.txt](https://github.com/tensorflow/tensorflow/files/6223922/smallervggnet.txt)\r\n[train.txt](https://github.com/tensorflow/tensorflow/files/6223915/train.txt)\r\n\r\n", "@lmocsi,\r\nWhile trying to reproduce the issue, I am facing an error stating `cv2.error: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'`. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/419b5756f1746947c6b307fe0c1a3cb9/47249.ipynb). Thanks!", "Also, if possible could you please uninstall CUDA, cuDNN, TensorFlow and Python, restart your machine and check if a fresh installation works? Thanks!", "@amahendrakar,\r\n\r\nAll my images are sized n*n, where n >= 95 pixels.\r\nMaybe this causes the resize problem.\r\n", "@lmocsi,\r\nOn running the code with a dummy dataset, I am facing a different error stating `tcmalloc: large alloc 2211840000 bytes == 0x55c0cc56c000`, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/0d27c9e82948bcb6c3749e8f259748d7/47249.ipynb).\r\n\r\n\r\n> Also, try limiting GPU memory growth using any of the methods listed [here](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and check if it helps.\r\n\r\nCould you please confirm if you are facing the same issue even after limiting GPU memory growth. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47249\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47249\">No</a>\n"]}, {"number": 47248, "title": "ValueError: Expected `model` argument to be a functional `Model` instance, but got a subclass model instead.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Maybe, unless there's some way to achieve the same thing already\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI need to copy a keras model and there is no way that I know of which can be done unless the model **is not** a `tf.keras.models.Model()` subclass. \r\n\r\n**Note:** The use `copy.deepcopy()` will work without giving any errors however it will result in another error whenever the copy is used:\r\n\r\nResults in:\r\n\r\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:569 _run_internal_graph  **\r\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\r\n    \r\n    AssertionError: Could not compute output KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.int64, name=None), name='tf.math.argmax/ArgMax:0', description=\"created by layer 'tf.math.argmax'\")\r\n\r\nExample:\r\n\r\n    import tensorflow as tf\r\n    \r\n    class MyModel(tf.keras.Model):\r\n    \r\n      def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\r\n        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\r\n        self.dropout = tf.keras.layers.Dropout(0.5)\r\n    \r\n      def call(self, inputs, training=False):\r\n        x = self.dense1(inputs)\r\n        if training:\r\n          x = self.dropout(x, training=training)\r\n        return self.dense2(x)\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n        model1 = MyModel()\r\n        model2 = tf.keras.models.clone_model(model1)\r\n\r\nResults in:\r\n\r\n    Traceback (most recent call last):\r\n      File \"/Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py\", line 600, in <module>\r\n        model2 = tf.keras.models.clone_model(model1)\r\n      File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\", line 430, in clone_model\r\n        return _clone_functional_model(\r\n      File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\", line 171, in _clone_functional_model\r\n        raise ValueError('Expected `model` argument '\r\n    ValueError: Expected `model` argument to be a functional `Model` instance, but got a subclass model instead.\r\n\r\n**Will this change the current api? How?** I don't know\r\n\r\n**Who will benefit with this feature?** Whoever wants to create n copies of a custom model without writing n lines for achieving the same thing.\r\n\r\n**Any Other info.**\r\n", "comments": ["@emadboctorx,\r\nLooks like this is a duplicate of [#47048](https://github.com/tensorflow/tensorflow/issues/47048).\r\n\r\nCan we close this issue since it is already being tracked there. Thanks!", "@amahendrakar sure, thanks", "Is this issue addressed? I meet the same problem", "@Suesoso Looks like it was brought up previously in other issues but still I don't see a solution anywhere", "Any updates on this? Having the same issue on TF2.5.0."]}, {"number": 47247, "title": "Switch gcs to modular file system on tensorflow/io", "body": "This PR is part of the effort to switch to modular file system support.\r\n\r\nThis PR switches gcs file system and direct user to use modular file system\r\nfrom tensorflow-io instead. See PR #46955 for related changes.\r\n\r\nA TF_ENABLE_LEGACY_FILESYSTEM=1 will allow the usage of original gcs file\r\nsystem the same way as before (a warning will be displayed).\r\n\r\n/cc @mihaimaruseac @vnvo2409 @tensorflow/sig-io-maintainers @burgerkingeater\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["thanks for making this change!", "This seem to break TPUs on internal code, will have to look deeper into this. Sorry for the delay.", "@mihaimaruseac I think it might be because we haven't fully implemented the `gcs` plugin yet. When @yongtang sent the first PR to copy the code from `tensorflow` to `io`, we didn't have enough `c` headers. I've just exposed them recently. I will send a PR by the end of the week and I think we could retry this PR.\r\n\r\nDid you get signal abort when using TPUs ?", "I didn't look at the log in detail", "@mihaimaruseac @vnvo2409  I don't have a lot of context on TPU but just wondering if https://github.com/tensorflow/io/pull/919 is related? /cc @marioecd ", "Errors seem to be `F0225 15:29:50.816806    4040 grpc_tensorflow_server.cc:331] Non-OK-status: Env::Default()->GetFileSystemForFile(\"gs://dummy/file\", &fs) status: Unimplemented: File system scheme 'gs' not implemented (file: 'gs://dummy/file')`\r\n\r\nSo I'll try to see why this happens internally, probably next week when I get some more time.", "@mihaimaruseac Wondering if there is any update. Given the upcoming R2.5 branch cut on 3/25/2020, it would be great if this PR can be merged before 03/25.", "Sorry I didn't get to look into this.\r\n\r\nP0 is enabling all py39 on all platforms and testing. I'll try to get this PR in by the branch cut date but at the moment team is overswamped with breakages.", "Thanks @mihaimaruseac for the update \ud83d\udc4d . Let me know in case there is anything I can help.", "Sorry it took so long. I think now I managed to fix everything that was broken. Pending a few more tests, this should land today", "Thanks @mihaimaruseac for the great help! \ud83d\udc4d \ud83c\udf89 \ud83d\udd25 "]}, {"number": 47246, "title": "TensorFlow lite support for snapdragon 888/875 dsp", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Mobile device Snapdragon 875/888\r\n- TensorFlow version 2.4.0:\r\n\r\n\r\n\r\nProblem description:\r\n\r\nwhen running my tesorflow lite app that need to use the hexagon dsp delegate.\r\nI get the following error:\r\n\r\n\"WARNING: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\nINFO: Hexagon Delegate is not supported\"\r\n\r\nfrom https://www.tensorflow.org/lite/performance/hexagon_delegate I can't see that you support the snapdragon version I'm using 875/888 , is the Hexagon delegate doesn't support this new snapdragon device or am I'm missing something ?\r\nWhen will it be supported ?\r\n\r\n\r\nThanks\r\nShuki\r\n", "comments": ["Hi @shuki-k \r\nSadly this is not possible.\r\nThese new chips uses a newer version of HVX that is different than what Hexagon delegate supports.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47246\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47246\">No</a>\n", "when will that be the new snapdragon 888 be supported by TFlite ? is it in the roadmap", "Hi @shuki-k,\r\nSadly no plans, as this is not totally in our hands.\r\nThe new hardware is completely new and Qualcomm is not planning to update the API which is used by the Hexagon Delegate. \r\nWe are checking with Qualcomm for other options for this new hardware.\r\n\r\nThanks", "Facing same issue here with Xiaomi MI11. ", "But how come that #48081 says that its possible to run tflite model on the dsp ? ", "Hi @alexanderfrey \r\nAs mentioned earlier, QC new hardware is using new chip and API and it doesn't even use Hexagon NN, that's why the delegate doesn't work (Sorry, i wish i could do something to help here :( )\r\n\r\nFor NNAPI case, it's different than Hexagon delegate, and QC provides different drivers for android.", "Hey @karimnosseir , is there any update on this issue. Could we expect support for SD 888 DSP anytime soon?", "Hey @anandravi24 Sorry same reply, the new chip doesn't leverage Hexagon NN API. I wish i could help"]}, {"number": 47244, "title": "Cannot assign a device for operation using Google Cloud TPU", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nThe codebase can be found at https://github.com/google/compare_gan.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu on Google Cloud.\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNot applicable.\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\nTF v1.15\r\n- Python version:\r\n3.8\r\n- Bazel version (if compiling from source):\r\nNot applicable.\r\n- GCC/Compiler version (if compiling from source):\r\nNot applicable.\r\n- CUDA/cuDNN version:\r\nNot applicable.\r\n- GPU model and memory:\r\nTPU v3-8\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\nv1.15.0-rc3-22-g590d6ee 1.15.0\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nThe original issue can be found at [here](https://github.com/google/compare_gan/issues/53). I used the exact same software setup as stated in the CompareGAN repo, and ran it on V3-8 TPU with 4 vCPU VM. \r\n \r\nI had the following error: \r\n \r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation input_pipeline_task0/TensorSliceDataset: node input_pipeline_task0/TensorSliceDataset (defined at /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /job:worker/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\r\n\r\nIt looks to me that this error is caused by different naming conventions from older TF. The original repo uses TensorFlow 1.15, while the firmware of TPU/VM might have been updated over time, thus, it may not properly recognize the device name. I tried a workaround as suggested here (https://github.com/google/compare_gan/issues/53), but using a GPU instance can be very expensive and it goes against the reason of using TPUs. \r\n\r\nTherefore, I wonder if there is a way to rename the device from TensorFlow, or manually assign the device for input_pipeline handling?\r\n\r\n**Describe the expected behavior**\r\nI expect TF to recognize the device name properly. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nYou can use the following command if you have a TPU:\r\n```python3 compare_gan/main.py --use_tpu=True  --gin_config=/home/xxx/compare_gan/example_configs/resnet_cifar10.gin ```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 236, in download_and_prepare\r\n    self.info.compute_dynamic_properties()\r\n  File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_info.py\", line 245, in compute_dynamic_properties\r\n    self._compute_dynamic_properties(self._builder)\r\n  File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_info.py\", line 258, in _compute_dynamic_properties\r\n    builder, split_name)\r\n  File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_info.py\", line 447, in get_dataset_feature_statistics\r\n    for example in tqdm.tqdm(np_dataset, unit=\" examples\"):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tqdm/std.py\", line 1107, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/xxx/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_utils.py\", line 98, in _graph_dataset_iterator\r\n    yield sess.run(ds_item)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation input_pipeline_task0/TensorSliceDataset: node input_pipeline_task0/TensorSliceDataset (defined at /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /job:worker/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\r\n         [[input_pipeline_task0/TensorSliceDataset]]\r\n```", "comments": ["@StevenShi-23,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue. Thanks!", "Hi @amahendrakar , thanks for the prompt reply!\r\n\r\nI've tried to port the original repo to TF v2, but it requires much more changes than fixing this issue, and some code explicitly depends on TF v1. Therefore, I resort to finding a fix from TF v1. In my humble option, It should be easy, as we only need to mask the device name, but I don't know where to start. May you advise please?\r\n\r\nMany thanks in advance!", "A quick update: I ported the code to TF v2.4.1, but the same error occurs:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\r\n    return fn(*args)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1358, in _run_fn\r\n    self._extend_graph()\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1398, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation input_pipeline_task0/TensorSliceDataset: {{node input_pipeline_task0/TensorSliceDataset}} was explicitly assigned to /job:worker/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n         [[input_pipeline_task0/TensorSliceDataset]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"compare_gan/main.py\", line 135, in <module>\r\n    app.run(main)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"compare_gan/main.py\", line 129, in main\r\n    eval_every_steps=FLAGS.eval_every_steps)\r\n  File \"/home/xxx/xxx/compare_gan/runner_lib.py\", line 337, in run_with_schedule\r\n    hooks=train_hooks)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3130, in train\r\n    rendezvous.raise_errors()\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\", line 150, in raise_errors\r\n    six.reraise(typ, value, traceback)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3125, in train\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 349, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1175, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1204, in _train_model_default\r\n    self.config)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2962, in _call_model_fn\r\n    config)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1163, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3242, in _model_fn\r\n    input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1484, in generate_infeed_enqueue_ops_and_dequeue_fn\r\n    self._invoke_input_fn_and_record_structure())\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1591, in _invoke_input_fn_and_record_structure\r\n    host_device, host_id))\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 927, in generate_per_host_enqueue_ops_fn_for_host\r\n    inputs = _Inputs.from_input_fn(input_fn(user_context))\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3096, in _input_fn\r\n    return input_fn(**kwargs)\r\n  File \"/home/xxx/xxx/compare_gan/gans/modular_gan.py\", line 426, in input_fn\r\n    preprocess_fn=self._preprocess_fn)\r\n  File \"/home/xxx/xxx/compare_gan/datasets.py\", line 334, in input_fn\r\n    return self.train_input_fn(params=params, preprocess_fn=preprocess_fn)\r\n  File \"/home/xxx/xxx/compare_gan/datasets.py\", line 284, in train_input_fn\r\n    ds = self._load_dataset(split=self._train_split)\r\n  File \"/home/xxx/xxx/compare_gan/datasets.py\", line 245, in _load_dataset\r\n    as_dataset_kwargs={\"shuffle_files\": False})\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py\", line 253, in load\r\n    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 236, in download_and_prepare\r\n    self.info.compute_dynamic_properties()\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py\", line 245, in compute_dynamic_properties\r\n    self._compute_dynamic_properties(self._builder)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py\", line 258, in _compute_dynamic_properties\r\n    builder, split_name)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py\", line 447, in get_dataset_feature_statistics\r\n    for example in tqdm.tqdm(np_dataset, unit=\" examples\"):\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tqdm/std.py\", line 1170, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_utils.py\", line 98, in _graph_dataset_iterator\r\n    yield sess.run(ds_item)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 968, in run\r\n    run_metadata_ptr)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1191, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1369, in _do_run\r\n    run_metadata)\r\n  File \"/home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1394, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation input_pipeline_task0/TensorSliceDataset: node input_pipeline_task0/TensorSliceDataset (defined at /home/xxx/miniconda3/envs/tf2.4/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_utils.py:76)  was explicitly assigned to /job:worker/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n         [[input_pipeline_task0/TensorSliceDataset]]\r\n\r\n```", "> I ported the code to TF v2.4.1, but the same error occurs:\r\n\r\n@StevenShi-23,\r\nCould you please provide the ported code, so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47244\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47244\">No</a>\n"]}, {"number": 47243, "title": "TFL: Update detection_postprocess kernel", "body": "Changing std::partial_sort to std::stable_sort in the case where\r\nstd::partial_sort use the full range. This is the case preventing\r\nbit-exactness between TFL and TFLM. Problem with std::partial_sort\r\nis that the order of equal elements is not guaranteed to be\r\npreserved. Possibly std::partial_sort should be totally\r\nreplaced but leaving that for now.\r\nAlso adding a unit test for stable sort.\r\n\r\nThis progress towards: https://github.com/tensorflow/tensorflow/issues/47158\r\n\r\nNote that this was the first fix: https://github.com/tensorflow/tensorflow/pull/47159\r\nHowever that was merged before adding a unit test, and it was also reverted. So opening this new PR.", "comments": ["The original change was rolled back internally, due to unit test failures from one of our example apps. I am taking a look...", "So there is a test in the [Object Detection example app](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) which checks output from a detection model (in terms of bbox, confidence & class indices). \r\n\r\nBbox & scores seem fine, but we need a smaller threshold for the [bounding box](https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/androidTest/java/org/tensorflow/lite/examples/detection/DetectorTest.java#L124) overlap %age check in that test. Its currently at 95%, but looks like 90-93% also works. My hunch is that the new sorting scheme modifies the order of some of the results, which leads to a similar, but not exactly the same output.\r\n\r\nTo keep things easy, I can send an internal code change to get this in. @advaitjain & @mansnils WDYT?", "Thanks for taking a look at the test failure. An internal change sounds very good to me.", "I totally agree. Thanks for taking a look.", "This change was submitted by @srjoglekar246 with https://github.com/tensorflow/tensorflow/commit/0bb52df11094fefc21e245c9d0f3e7351fc158a3 and then rolled back because of failures (and an unexpected drop in mAP of SSD MobileNetV2as measured by an internal test) with https://github.com/tensorflow/tensorflow/commit/20f2d64adc985792bc78b6f23ae3579fc4813941.\r\n\r\nI am closing the current PR but we can certainly revisit the topic of stable_sort and determinism separate from this specific PR.\r\n\r\nFor completeness, here is a link to the internal bug: http://b/180647541"]}, {"number": 47242, "title": "Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array.", "body": "**System information**\r\n- OS Platform and Distribution: Arch Linux\r\n- TensorFlow installed from package: python-tensorflow\r\n- TensorFlow version: unknown 2.4.1\r\n- Python version: 3.9.1\r\n- CUDA/cuDNN version: No GPU\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nfrom tensorflow.keras.layers import Embedding, Input, GRU\r\n\r\nx = Input(shape=(None,))\r\nx = Embedding(input_dim=50, output_dim=16, mask_zero=True)(x)\r\nx = GRU(units=256)(x)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jnphilipp/Nextcloud/Code/jnphilipp/deep_learning/test3.py\", line 5, in <module>\r\n    x = GRU(units=256)(x)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 660, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 951, in __call__\r\n    return self._functional_construction_call(inputs, args, kwargs,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1090, in _functional_construction_call\r\n    outputs = self._keras_tensor_symbolic_call(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\r\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 863, in _infer_output_signature\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\", line 439, in call\r\n    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 859, in _process_inputs\r\n    initial_state = self.get_initial_state(inputs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 642, in get_initial_state\r\n    init_state = get_initial_state_fn(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 1948, in get_initial_state\r\n    return _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 2987, in _generate_zero_filled_state_for_cell\r\n    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 3005, in _generate_zero_filled_state\r\n    return create_zeros(state_size)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 3000, in create_zeros\r\n    return array_ops.zeros(init_state_size, dtype=dtype)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2819, in wrapped\r\n    tensor = fun(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2868, in zeros\r\n    output = _constant_if_small(zero, shape, dtype, name)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2804, in _constant_if_small\r\n    if np.prod(shape) < 1000:\r\n  File \"<__array_function__ internals>\", line 5, in prod\r\n  File \"/usr/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 3030, in prod\r\n    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n  File \"/usr/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 87, in _wrapreduction\r\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 852, in __array__\r\n    raise NotImplementedError(\r\nNotImplementedError: Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n", "comments": ["+1! I'm getting the same issue. ", "@jnphilipp \r\nI ran the code shared above it seems incomplete, please find the [gist here ](https://colab.research.google.com/gist/Saduf2019/883a41f4a5a9737bfb85138d5b476d09/untitled545.ipynb)[there is no error or output]\r\nmenwhile can you please refer to these resolved issues and let us know: [link](https://stackoverflow.com/questions/58479556/notimplementederror-cannot-convert-a-symbolic-tensor-2nd-target0-to-a-numpy), [link2](https://github.com/tensorflow/tensorflow/issues/36792)", "@Saduf2019  I know the code looks incomplete, but it is the minimum that I need to get the error message above.\r\nAs to the issues: I don't even import numpy.", "i too am having this issue just now\r\ni have been running the same scripts for months, and i just started having this issue today when i re-run them. Last time they worked was 7 days ago (i even have the git commit uploading the then freshly executed script)\r\n\r\nthe only thing that changed in between was an updated version of numpy\r\n\r\nin my case however, the issue arises when adding a data augmentation layer:\r\n\r\nAdding data augmentation\r\ndata_augmentation = tf.keras.Sequential([\r\ntf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\r\ntf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\r\n])\r\n\r\ninputs = tf.keras.Input(shape=(224, 398, 3))\r\nx = data_augmentation(inputs)\r\noutputs = inference_model(x, training=False)\r\ntraining_model = tf.keras.Model(inputs, outputs)\r\n\r\nthen i have an error, with a long traceback  (simplified here):\r\n\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-11-4e12e0617af3> in <module>\r\n      1 inputs = tf.keras.Input(shape=(224, 398, 3))\r\n----> 2 x = data_augmentation(inputs)\r\n      3 outputs = inference_model(x, training=False)\r\n      4 training_model = tf.keras.Model(inputs, outputs\r\n.\r\n.\r\n.\r\nNotImplementedError: Cannot convert a symbolic Tensor (sequential_1/random_rotation_1/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n\r\nagain, this exact code worked without a hitch a week ago", "Me too, after the last update.", "@jnphilipp I ran your code in `TF2.4.1` and I don't see any error as you described. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/9259875409e4f892b4db22fe11e12322/untitled545.ipynb). Am i missing something here?\r\n\r\n@ZeroOut @ghylander Can you please share a standalone code to reproduce the issue? Thanks!", "@jvishnuvardhan \r\nyes\r\n`numpy.__version__`\r\n`1.19.3`\r\nthis problem arises with numpy version 1.20 and 1.21", "> @jvishnuvardhan\r\n> yes\r\n> `numpy.__version__`\r\n> `1.19.3`\r\n> this problem arises with numpy version 1.20 and 1.21\r\n\r\nThanks! The same issue just started happening on my setup, and downgrading to 1.19.4 solved.", "@jvishnuvardhan no, you're not missing anything in the gist.", "> @jvishnuvardhan no, you're not missing anything in the gist.\r\n\r\nSo, the issue was resolved for you.? If the issue was not resolved for you, please change your numpy version as mentioned by others. `TF2.4.1` pip package was built with `'numpy ~= 1.19.2'`. The colab i shared was using `numpy = 1.19.5`. So I guess, if it is working well from numpy versions ` 1.19.2` to ` 1.19.5`. Thanks!", "@ZeroOut @ghylander As mentioned by you, looks like this was related to numpy version. I just checked that TF was built with `'numpy ~= 1.19.2'` . Please check [here](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/tools/pip_package/setup.py#L84) to know all the packages and their versions that were used when building TF `pip` package`2.4`. Thanks!\r\n\r\ncc @mihaimaruseac \r\n\r\nPlease close the issue if this was resolved for you all. Thanks!", "Similar issues that are due to numpy version 1.20.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/47263\r\nhttps://github.com/tensorflow/tensorflow/issues/47311", "I met a similar problem when I run the BERT model (repo: https://github.com/google-research/bert).\r\nI have downgrade Numpy from 1.20 to 1.19.2 and the problem solved.\r\nThanks!", "I am closing this issue as this is more related to numpy version as mentioned above and not related core Tensorflow. Loading correct numpy version resolves the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47242\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47242\">No</a>\n", "Moved to #47691", "Try making a new python environment and install tensorflow==2.4.0", "> @jvishnuvardhan yes `numpy.__version__` `1.19.3` this problem arises with numpy version 1.20 and 1.21\r\n\r\nSaved my day! Thanks!", "### [Solved]\r\nI have the same error when training the data, even also try to downgrade the NumPy version, but it not be fixed.\r\n**Finally, I solved that issue**. Try the below command:\r\n\r\n`!pip install numpy==1.17.4`\r\n`!pip install pycocotools==2.0.0`"]}, {"number": 47241, "title": "add tflite_micro with cmake files and zephyr modules", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source):\r\n- Tensorflow version (e85120faff5febebc6ac527b8cf977333a8dd6f4):\r\n- Target platform (Arm Mbed OS):\r\n\r\n**Describe the problem**\r\n\r\ntflite only have makefile support, so add cmake support will make tf easy to be integarted.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nI use Zephyr RTOS as example, \r\nhttps://github.com/hakehuang/zephyr/commits/tf_int\r\n\r\ncd samples/hello_world/\r\nwest build -b mimxrt1060_evk\r\n\r\n\r\n", "comments": ["PR is created\r\n#47240 ", "https://github.com/tensorflow/tensorflow/pull/47240#issuecomment-791160760 describes why will not be able to add cmake support at this time, and also gives some direction for how you might be able to integrate TFLM as part of a larger project.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47241\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47241\">No</a>\n", "> [#47240 (comment)](https://github.com/tensorflow/tensorflow/pull/47240#issuecomment-791160760) describes why will not be able to add cmake support at this time, and also gives some direction for how you might be able to integrate TFLM as part of a larger project.\r\n@advaitjain \r\nit is strange why TFLM does not want to have CMAKE support, as I see in the TFLite there is ready CMAKE solution, can you explain the reason?", "@hakehuang, very valid question.\r\n\r\nWe do see a lot of potential benefits to having cmake support. However, (at this time) we do not want to support more than two separate build systems simultaneously. So any additional build system support would have to be accompanied by a solid plan and justification to remove one of the existing ones (Make and Bazel).\r\n\r\nFor the time-being, we would like to make it easier to perform such integrations without needing to merge code in upstream Tensorflow.\r\n\r\nWe would also welcome further discussion on this topic at the [SIG-micro mailing list](https://groups.google.com/a/tensorflow.org/g/micro).\r\n\r\nSomewhat separate from the topic of cmake or not, we would also like to have any Zephyr or any other framework/IDE/OS integration to be outside of the TFLM repository."]}, {"number": 47240, "title": "add cmake build support for tflite_micro", "body": "also add zephyr config files so that it can be a module\r\nfor zephyr\r\n\r\nSigned-off-by: Hake Huang <hake.huang@oss.nxp.com>", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47240) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47240) for more info**.\n\n<!-- need_sender_cla -->", "@hakehuang This PR is in draft, any update on this? Please. Thanks!", "> @hakehuang This PR is in draft, any update on this? Please. Thanks!\r\n\r\n@gbaned , can I move it to a former PR? I create an issue  https://github.com/tensorflow/tensorflow/issues/47241", "Thanks for the PR. At this time we would like to avoid adding additional build systems and will not be able to accept this PR.\r\n\r\nAdditionally, we are also in the process of making it easier to have integrations such as this (but external to the TFLM codebase) which would give you more control over exactly how you use TFLM as part of a larger system.\r\n\r\nPlease see https://github.com/tensorflow/tensorflow/issues/47413 for more details.\r\n\r\nI am closing this PR but will be happy to answer questions on how to use this v2 project generation / external integration framework.\r\n"]}, {"number": 47238, "title": "TFLM: Support null pointer bias in CMSIS-NN fully_connected", "body": "Remove bias null pointer checks as arm_fully_connected_s8 now supports it.\r\n\r\nFix for: https://github.com/tensorflow/tensorflow/issues/47237", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47237, "title": "CMSIS-NN fully_connected kernel does not support null pointer bias", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\narm_fully_connected_s8 supports null pointer bias. Therefore should the null pointer checks be removed in CMSIS-NN kernel.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": []}, {"number": 47236, "title": "How do I profile layers in tensorflow instead of ops? Is there a way to profile only layers in tensorflow?", "body": "", "comments": ["@saisriker \r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47236\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47236\">No</a>\n", "Take a look at TensorFlow Profiler https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras"]}, {"number": 47235, "title": "Failed to convert QAT model to tflite when I use tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- TensorFlow installation (pip package or built from source):pip package\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):2.3.1\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\nWhen I use tf.lite.TFLiteConverter to convert keras ACTIVATIONS_INT16_WEIGHTS_INT8 QAT model to tflite file\u3002There are some bugs and the conversion is failed.\r\nThis is my convert code and Bugs.\r\n**quant_converter1 = tf.lite.TFLiteConverter.from_keras_model(model1_quant)\r\nquant_converter1.optimizations = [tf.lite.Optimize.DEFAULT]\r\nquant_converter1.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\r\nquant_tflite_model1 = quant_converter1.convert()\r\nwith open(model1_tflite_quant, 'wb') as f:\r\n  f.write(quant_tflite_model1)**\r\n\r\n\r\n![as](https://user-images.githubusercontent.com/12438262/108315281-17f5c700-71b3-11eb-9ec9-f0e0d1114f9f.png)\r\n**I updated the TensorFlow to the latest stable version v2.4.1 and also  face the same error**  @amahendrakar\r\n\r\n\r\n\r\n", "comments": ["@eliver8801,\r\nIn order to reproduce the issue reported here, could you please provide a minimal code snippet and all the files required to run the code.\r\n\r\nAlso, please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same error? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47235\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47235\">No</a>\n", "**I updated the TensorFlow to the latest stable version v2.4.1 and also face the same error** @amahendrakar", "@eliver8801,\r\nCould you please provide a minimal code snippet along with all the supporting files, so that we can reproduce the issue on our end. Thanks!", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47235\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47235\">No</a>\n"]}, {"number": 47234, "title": "Add GPU support for SparseToDense Op", "body": "This PR adds the GPU support for the SparseToDense Op.\r\n\r\nFYI. @nluehr @benbarsdell ", "comments": ["@sanjoy Changes are made according to your comments. PTAL.\r\n\r\n> How are you using Eigen here?\r\n\r\nWe need to use the `Eigen::GpuDevice` for CUDA kernel launching.", "Done. PTAL. @sanjoy ", "@sanjoy Just added the scope you mentioned in another thread. (By the way, what is this for? Why do we need that?)"]}, {"number": 47233, "title": "Add NFNets to keras.applications", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes, as much as possible but probably need help.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nDeepMind recently introduced their new \"Normalizer-Free\" [NFNets](https://arxiv.org/abs/2102.06171), matching the test accuracy of EfficientNet-B7 on ImageNet while being up to 8.7x faster to train, and their largest models attain a new state-of-the-art top-1 accuracy of 86.5%. It seems fitting that these would be available in keras since they surpass EfficientNets which are already available.\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis would introduce new APIs i.e., `tensorflow.keras.applications.NFNetF0` through to `tensorflow.keras.applications.NFNetF6`.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone doing image classification, including transfer learning and fine tuning; a large portion of the machine learning community!\r\n\r\n**Any Other info.**\r\n\r\nDeepMind's [implementation](https://github.com/deepmind/deepmind-research/tree/master/nfnets)", "comments": ["I would like to work on this issue. If contributors can guide me through the solution approach, it would be helpful", "I can provide implementation for WSConv and AGCModel by the way ", "what about this?\r\nhttps://github.com/ypeleg/nfnets-keras\r\nmaybe some code could be reused", "> what about this?\r\n> https://github.com/ypeleg/nfnets-keras\r\n> maybe some code could be reused\r\n\r\nI referred to this but it's not working out of box. it's converted from the original pytorch code without a careful transition to keras. Let me just copy paste my code here for whoever wanna work on this:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.engine import data_adapter\r\n\r\nfrom tensorflow.python.ops import array_ops, nn_ops, nn\r\nfrom tensorflow.keras.layers import *\r\nimport tensorflow.keras.backend as K\r\n\r\n\r\ndef _standardize_weight(weight, eps, dtype, gain=None):\r\n    mean = tf.math.reduce_mean(weight, axis=(0, 1, 2), keepdims=True)\r\n    var = tf.math.reduce_variance(weight, axis=(0, 1, 2), keepdims=True)\r\n    fan_in = tf.cast(tf.math.reduce_prod(weight.shape[:-1]), dtype)\r\n\r\n    updated_weight = (weight - mean) / tf.math.rsqrt((var * fan_in + tf.convert_to_tensor(eps, dtype=dtype)))\r\n    if gain is not None:\r\n        updated_weight = updated_weight * gain\r\n    return updated_weight\r\n\r\nclass WSConv2D(Conv2D):\r\n    def __init__(self, *args,\r\n                 eps=1e-4,\r\n                 enable_gain=False,\r\n                 **kwargs):\r\n        super(WSConv2D, self).__init__(*args, **kwargs)\r\n        self.eps = eps\r\n        self.enable_gain = enable_gain\r\n\r\n    def build(self, input_shape):\r\n        if self.enable_gain:\r\n            self.gain = self.add_weight(\r\n                name='gain',\r\n                shape=(1, 1, 1, self.filters),\r\n                initializer='ones',\r\n                trainable=True,\r\n                dtype=self.dtype\r\n            )\r\n        return super().build(input_shape)\r\n\r\n    def call(self, inputs):\r\n        weight = self.kernel\r\n        if self.enable_gain:\r\n            updated_kernel = _standardize_weight(weight, self.eps, self.dtype, self.gain)\r\n        else:\r\n            updated_kernel = _standardize_weight(weight, self.eps, self.dtype)\r\n\r\n        if self._is_causal:  # Apply causal padding to inputs for Conv1D.\r\n            inputs = array_ops.pad(inputs, self._compute_causal_padding(inputs))\r\n\r\n        outputs = self._convolution_op(inputs, updated_kernel)\r\n\r\n        if self.use_bias:\r\n            output_rank = outputs.shape.rank\r\n            if self.rank == 1 and self._channels_first:\r\n                # nn.bias_add does not accept a 1D input tensor.\r\n                bias = array_ops.reshape(self.bias, (1, self.filters, 1))\r\n                outputs += bias\r\n            else:\r\n                # Handle multiple batch dimensions.\r\n                if output_rank is not None and output_rank > 2 + self.rank:\r\n\r\n                    def _apply_fn(o):\r\n                        return nn.bias_add(o, self.bias, data_format=self._tf_data_format)\r\n\r\n                    outputs = nn_ops.squeeze_batch_dims(\r\n                        outputs, _apply_fn, inner_rank=self.rank + 1)\r\n                else:\r\n                    outputs = nn.bias_add(\r\n                        outputs, self.bias, data_format=self._tf_data_format)\r\n\r\n        if self.activation is not None:\r\n            return self.activation(outputs)\r\n        return outputs\r\n\r\n    def get_config(self):\r\n        orig_config = super().get_config()\r\n        orig_config['eps'] = self.eps\r\n        orig_config['enable_gain'] = self.enable_gain\r\n        return orig_config\r\n\r\nclass AGCModel(tf.keras.Model):\r\n    def __init__(self, *args, clip_factor=0.01, eps=1e-3, **kwargs):\r\n        super(AGCModel, self).__init__(*args, **kwargs)\r\n        self.clip_factor = clip_factor\r\n        self.eps = eps\r\n\r\n    @staticmethod\r\n    def compute_norm(x, axis, keepdims):\r\n        return tf.math.reduce_sum(x ** 2, axis=axis, keepdims=keepdims) ** 0.5\r\n\r\n    @staticmethod\r\n    def unitwise_norm(x):\r\n        if len(x.get_shape()) <= 1:  # Scalars and vectors\r\n            axis = None\r\n            keepdims = False\r\n        elif len(x.get_shape()) in [2, 3]:  # Linear layers of shape IO or multihead linear\r\n            axis = 0\r\n            keepdims = True\r\n        elif len(x.get_shape()) == 4:  # Conv kernels of shape HWIO\r\n            axis = [0, 1, 2, ]\r\n            keepdims = True\r\n        else:\r\n            raise ValueError(f\"Got a parameter with shape not in [1, 2, 4]! {x}\")\r\n        return AGCModel.compute_norm(x, axis, keepdims)\r\n\r\n    def adaptive_clip_grad(self, parameters, gradients):\r\n        new_grads = []\r\n        for (params, grads) in zip(parameters, gradients):\r\n            p_norm = self.unitwise_norm(params)\r\n            max_norm = tf.math.maximum(p_norm, self.eps) * self.clip_factor\r\n            grad_norm = self.unitwise_norm(grads)\r\n            clipped_grad = grads * (max_norm / tf.math.maximum(grad_norm, 1e-6))\r\n            new_grad = tf.where(grad_norm < max_norm, grads, clipped_grad)\r\n            new_grads.append(new_grad)\r\n        return new_grads\r\n\r\n    def train_step(self, data):\r\n        data = data_adapter.expand_1d(data)\r\n        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\r\n\r\n        with tf.GradientTape() as tape:\r\n            y_pred = self(x, training=True)\r\n            loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\r\n        trainable_params = self.trainable_variables\r\n        gradients = tape.gradient(loss, trainable_params)\r\n        agc_gradients = self.adaptive_clip_grad(trainable_params, gradients)\r\n        self.optimizer.apply_gradients(zip(agc_gradients, trainable_params))\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n        return {m.name: m.result() for m in self.metrics}\r\n\r\n```\r\n\r\nSome key points that differ from the original repo. \r\n\r\n1. the original repo uses variable assign which can't be supported by tensorrt or onnx etc. my work requires tensorrt so I modified it this way. \r\n2. The AGCModel  is updated by referencing the tf 2.4.0 code. \r\n\r\nThis is not optimal code cus I copy pasted a lot from the tf source code. but at least this can work.", "A PyTorch implementation for reference https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/nfnet.py", "Another PyTorch implementation for ref. https://github.com/vballoli/nfnets-pytorch\r\n\r\nAnyway, just curious to know, why don't we have the `SE-Net` model series in keras applications, i.e. `SE-ResNet`, `Se-ResNeXT`? or `ResNeSt`? ", "has there been any progress on this? I'd love to use on Tensorflow/Keras too!!", "Are there any news about it yet? I see the post from 12 days ago but is this discussed within? ", "Is it happening? ", "May I know the progress? Do you need manpower to help on this feature update?", "@marcusturewicz \r\n\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "I have transferred this to https://github.com/keras-team/keras/issues/15229, so closing this one. Please continue the discussions there."]}, {"number": 47232, "title": "Edited as it was spam", "body": "Edited as it was spam", "comments": ["@IanSMoyes  Please read [code of conduct ](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md) before posting any queries and be respectful as advised in the earlier issues authored by you. The issue tracker is for Tensorflow feature requests or bug reports. Please refrain from posting inappropriate comments. If any functionality or feature does not work to your satisfaction, please let us know, as each feedback is valuable to us. Tensorflow team will be happy to address them. Again, we can only help if you restrict your posts to product issues and not personal rants.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47232\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47232\">No</a>\n"]}, {"number": 47231, "title": "Fix the Xtensa Vision P6 build.", "body": "https://github.com/tensorflow/tensorflow/pull/47199 broke the Vision P6 build with the following error message:\r\n```\r\ntensorflow/lite/micro/kernels/xtensa/quantize.cc:144:5: error: static_assert failed \"Unsupported xtensa architecture.\"\r\n    static_assert(false, \"Unsupported xtensa architecture.\");\r\n```\r\n\r\nManually confirmed that with this change, the following command passes:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=vision_p6 XTENSA_CORE=P6_200528 test -j8\r\n```\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47230, "title": "Using TensorArray for storing large dataset of interactions", "body": "**Reading from TensorArray:**\r\n \r\n```python\r\ndef __init__(self, size):\r\n        self.obs_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.obs2_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.act_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.rew_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.done_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n\r\n def get_sample(self, batch_size):\r\n            idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n            tf.print(idxs)\r\n            return self.obs_buf.gather(indices=idxs),     \\     # HERE IS THE ISSUE\r\n                   self.act_buf.gather(indices=idxs),     \\\r\n                   self.rew_buf.gather(indices=idxs),     \\\r\n                   self.obs2_buf.gather(indices=idxs),    \\\r\n                   self.done_buf.gather(indices=idxs)\r\n```\r\n\r\n**Usage:**\r\n\r\n```python\r\n@tf.function\r\ndef train(self, rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(1, gradient_steps + 1):\r\n        obs, act, rew, next_obs, done = rpm.get_sample(batch_size)\r\n\r\n        with tf.GradientTape() as tape:\r\n            ...\r\n```\r\n**Issue:**\r\n\r\n> Traceback (most recent call last):\r\n>   File \".\\main.py\", line 130, in <module>\r\n>     rl_training.train()\r\n>   File \"C:\\Users\\user\\Documents\\Projects\\rl-toolkit\\rl_training.py\", line 129, in train\r\n>     self._rpm, self.batch_size, self.gradient_steps, logging_wandb=self.logging_wandb\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n>     result = self._call(*args, **kwds)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 871, in _call\r\n>     self._initialize(args, kwds, add_initializers_to=initializers)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 726, in _initialize\r\n>     *args, **kwds))\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\r\n>     graph_function, _ = self._maybe_define_function(args, kwargs)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3361, in _maybe_define_function\r\n>     graph_function = self._create_graph_function(args, kwargs)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3206, in _create_graph_function\r\n>     capture_by_value=self._capture_by_value),\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 990, in func_graph_from_py_func\r\n>     func_outputs = python_func(*func_args, **func_kwargs)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 634, in wrapped_fn\r\n>     out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3887, in bound_method_wrapper\r\n>     return wrapped_fn(*args, **kwargs)\r\n>   File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 977, in wrapper\r\n>     raise e.ag_error_metadata.to_exception(e)\r\n> tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in user code:\r\n> \r\n>     C:\\Users\\user\\Documents\\Projects\\rl-toolkit\\policy\\sac\\sac.py:183 update  *\r\n>         obs, act, rew, next_obs, done = rpm.get_sample(batch_size)\r\n>     C:\\Users\\user\\Documents\\Projects\\rl-toolkit\\utils\\replay_buffer.py:39 __call__  *\r\n>         return self.obs_buf.gather(indices=idxs),                    self.act_buf.gather(indices=idxs),                    self.rew_buf.gather(indices=idxs),                    self.obs2_buf.gather(indices=idxs),                   self.done_buf.gather(indices=idxs)\r\n>     C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:1190 gather  **\r\n>         return self._implementation.gather(indices, name=name)\r\n>     C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:861 gather\r\n>         return array_ops.stack([self._maybe_zero(i) for i in indices])\r\n>     C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:505 __iter__\r\n>         self._disallow_iteration()\r\n>     C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:498 _disallow_iteration\r\n>         self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\r\n>     C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:476 _disallow_when_autograph_enabled\r\n>         \" indicate you are trying to use an unsupported feature.\".format(task))\r\n> \r\n>     OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n\r\nWhy I cannot using TensorArray in this context? And what alternatives I have?\r\n\r\nTF version: 2.4.1\r\nPython version:  3.6.8", "comments": ["@markub3327,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here and also the dataset you are using. Thanks!", "```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass ReplayBuffer(tf.Module):\r\n    def __init__(self, size, name=\"replay_buffer\"):\r\n        super(ReplayBuffer, self).__init__(name=name)\r\n\r\n        self.obs_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.obs2_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.act_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.rew_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.done_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False)\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf = self.obs_buf.write(self.ptr, obs)\r\n        self.obs2_buf = self.obs2_buf.write(self.ptr, next_obs)\r\n        self.act_buf = self.act_buf.write(self.ptr, act)\r\n        self.rew_buf = self.rew_buf.write(self.ptr, rew)\r\n        self.done_buf = self.done_buf.write(self.ptr, done)\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    # Get batch\r\n    def __call__(self, batch_size):\r\n        idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n        tf.print(idxs)\r\n        return self.obs_buf.gather(indices=idxs),     \\\r\n               self.act_buf.gather(indices=idxs),     \\\r\n               self.rew_buf.gather(indices=idxs),     \\\r\n               self.obs2_buf.gather(indices=idxs),    \\\r\n               self.done_buf.gather(indices=idxs)\r\n\r\nrpm = ReplayBuffer(size=10)  \r\n\r\n# store \r\nfor i in range(10):\r\n    rpm.store(np.array([0, 1, 2, 3, 4, 5]), np.array([0, 1, 2, 3, 4, 5]), np.array([0, 1, 2, 3, 4, 5]), np.array([0, 1, 2, 3, 4, 5]), np.array([0, 1, 2, 3, 4, 5]))\r\n\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(1, gradient_steps + 1):\r\n        obs, act, rew, next_obs, done = rpm(batch_size)\r\n      \r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....\r\n     \r\ntrain(rpm, 64, 100)\r\n```\r\n\r\nHere is the reproduciable code. Thanks. The dataset is stored in ReplayBuffer class and I'm using OpenAI Gym games.", "@markub3327,\r\nI was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/92fbae9d2dd5af0f67b8ec853d627537/47230.ipynb#scrollTo=0lQejRoawvGo).\r\n\r\nCould you please take a look at [this guide](https://www.tensorflow.org/guide/function#loops) for using loops with tf.function and check if it helps. Thanks!", "```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.__version__\r\n\r\n\r\nclass ReplayBuffer(tf.Module):\r\n    def __init__(self, size, name=\"replay_buffer\"):\r\n        super(ReplayBuffer, self).__init__(name=name)\r\n\r\n        self.obs_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.obs2_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.act_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.rew_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.done_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf = self.obs_buf.write(self.ptr, obs)\r\n        self.obs2_buf = self.obs2_buf.write(self.ptr, next_obs)\r\n        self.act_buf = self.act_buf.write(self.ptr, act)\r\n        self.rew_buf = self.rew_buf.write(self.ptr, rew)\r\n        self.done_buf = self.done_buf.write(self.ptr, done)\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    # Get batch\r\n    def __call__(self, batch_size):\r\n        idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n        tf.print(idxs)\r\n\r\n        obs_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        obs2_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        act_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        rew_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        done_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n\r\n        for i in tf.range(batch_size):\r\n            obs_batch = obs_batch.write(i, self.obs_buf.stack()[i])\r\n            obs2_batch = obs2_batch.write(i, self.obs2_buf.stack()[i])\r\n            act_batch = act_batch.write(i, self.act_buf.stack()[i])\r\n            rew_batch = rew_batch.write(i, self.rew_buf.stack()[i])\r\n            done_batch = done_batch.write(i, self.done_buf.stack()[i])\r\n \r\n        return obs_batch, act_batch, rew_batch, obs2_batch, done_batch\r\n\r\n\r\nrpm = ReplayBuffer(size=1000000)  \r\n\r\n# store 1M of experiences from the game\r\nfor i in range(10):\r\n    rpm.store(\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([4]),\r\n        tf.random.uniform([1]),\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([1])\r\n    )\r\n\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(gradient_steps):\r\n        obs, act, rew, next_obs, done = rpm(batch_size)\r\n      \r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....\r\n\r\ntrain(rpm, 8, 10)\r\n```\r\n\r\nIs this a naive solution for a large memory that will contains about 1M experiences from the game? I try it with `.read(index)`, but I get an error too:\r\n\r\n> <ipython-input-1-6c7dad339eed>:66 train  *\r\n>     obs, act, rew, next_obs, done = rpm(batch_size)\r\n>     <ipython-input-7-fb7b628dd210>:41 __call__  *\r\n>     obs_batch = obs_batch.write(i, self.obs_buf.read(i))\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py:1141 read  **\r\n>    return self._implementation.read(index, name=name)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py:755 read\r\n>         if index < 0:\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:885 __bool__\r\n>         self._disallow_bool_casting()\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:489 _disallow_bool_casting\r\n>         \"using a `tf.Tensor` as a Python `bool`\")\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:476 _disallow_when_autograph_enabled\r\n>         \" indicate you are trying to use an unsupported feature.\".format(task))\r\n> \r\n>OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n\r\n**Should I figure it out with using the tf.Dataset?**", "@rmothukuru,\r\nColab session crashes on running the code with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/11780cdea6435d5c0b2bb2569e5d9356/47230.ipynb). Thanks!", "The issue here is a lot of data that I would store in ReplayBuffer. When you try it with \r\n```python\r\nrpm = ReplayBuffer(size=1000)  \r\n```\r\ninstead of \r\n```python\r\nrpm = ReplayBuffer(size=1000000)  \r\n```\r\nit runs correctly. But I need to store a lot of data (min. 1000000 interactions). Thanks.", "@markub3327,\r\nSome points from my side:\r\n\r\n1. As @amahendrakar mentioned, Session is crashing when trying to reproduce your issue in Google Colab\r\n2. As per [your comment](https://github.com/tensorflow/tensorflow/issues/47230#issuecomment-792772133), I've replaced `size=1000000` with `size=1000` but couldn't observe the Error. Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/bbe262ada06cb610ee6dae4a6eacc718/47230.ipynb).\r\n3. The documentation of [write function](https://www.tensorflow.org/api_docs/python/tf/TensorArray#write) states \r\n> Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its `.mark_used()` method.\r\n\r\nCan you please add `mark_used` and see if the issue still persists? Thanks!", "I try paste `.mark_used()` after every write function ...\r\n\r\nHere is code:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\n\r\nclass ReplayBuffer(tf.Module):\r\n    def __init__(self, size, name=\"replay_buffer\"):\r\n        super(ReplayBuffer, self).__init__(name=name)\r\n\r\n        self.obs_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.obs2_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.act_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.rew_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.done_buf = tf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf = self.obs_buf.write(self.ptr, obs)\r\n        self.obs2_buf = self.obs2_buf.write(self.ptr, next_obs)\r\n        self.act_buf = self.act_buf.write(self.ptr, act)\r\n        self.rew_buf = self.rew_buf.write(self.ptr, rew)\r\n        self.done_buf = self.done_buf.write(self.ptr, done)\r\n\r\n        self.obs_buf.mark_used()\r\n        self.obs2_buf.mark_used()\r\n        self.act_buf.mark_used()\r\n        self.rew_buf.mark_used()\r\n        self.done_buf.mark_used()\r\n\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    # Get batch\r\n    def __call__(self, batch_size):\r\n        idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n        tf.print(idxs)\r\n\r\n        obs_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        obs2_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        act_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        rew_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n        done_batch = tf.TensorArray(tf.float32, size=batch_size, clear_after_read=False, dynamic_size=False)\r\n\r\n        for i in idxs:\r\n            obs_batch = obs_batch.write(i, self.obs_buf.stack()[i])\r\n            obs2_batch = obs2_batch.write(i, self.obs2_buf.stack()[i])\r\n            act_batch = act_batch.write(i, self.act_buf.stack()[i])\r\n            rew_batch = rew_batch.write(i, self.rew_buf.stack()[i])\r\n            done_batch = done_batch.write(i, self.done_buf.stack()[i])\r\n \r\n            #obs_batch.mark_used()\r\n            #obs2_batch.mark_used()\r\n            #act_batch.mark_used()\r\n            #rew_batch.mark_used()\r\n            #done_batch.mark_used()\r\n\r\n        return obs_batch, act_batch, rew_batch, obs2_batch, done_batch\r\n\r\n\r\nrpm = ReplayBuffer(size=1000000)\r\n\r\n# store 1M of experiences from the game\r\nfor i in range(10):\r\n    rpm.store(\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([4]),\r\n        tf.random.uniform([1]),\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([1])\r\n    )\r\n\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(gradient_steps):\r\n        obs, act, rew, next_obs, done = rpm(batch_size)\r\n      \r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....      \r\n       # Q = rew + (1-done) * nextQ\r\n\r\ntrain(rpm, 8, 10)\r\n```\r\n\r\nStill, it's not working with size=1000000, but it's necessary. Before that, I solved this by numpy arrays where interactions were saved. Here is the code with using numpy that cannot be used in `tf.function` (`.sample()` function runs only once and all indexes are the same during updating steps):\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\n\r\nimport numpy as np\r\n\r\n\r\nclass ReplayBuffer:\r\n    \"\"\"\r\n    A simple FIFO experience replay buffer for DDPG agents.\r\n    Based on https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/ddpg/ddpg.py.\r\n    \"\"\"\r\n\r\n    def __init__(self, obs_dim, act_dim, size):\r\n        self.obs_buf = np.zeros((size,) + obs_dim, dtype=np.float32)\r\n        self.obs2_buf = np.zeros((size,) + obs_dim, dtype=np.float32)\r\n        self.act_buf = np.zeros((size,) + act_dim, dtype=np.float32)\r\n        self.rew_buf = np.zeros((size, 1), dtype=np.float32)\r\n        self.done_buf = np.zeros((size, 1), dtype=np.float32)\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf[self.ptr] = obs\r\n        self.obs2_buf[self.ptr] = next_obs\r\n        self.act_buf[self.ptr] = act\r\n        self.rew_buf[self.ptr] = rew\r\n        self.done_buf[self.ptr] = done\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    def sample(self, batch_size):\r\n        idxs = np.random.randint(0, self.size, size=batch_size)\r\n        tf.print(idxs)\r\n\r\n        return dict(\r\n            obs=self.obs_buf[idxs],\r\n            obs2=self.obs2_buf[idxs],\r\n            act=self.act_buf[idxs],\r\n            rew=self.rew_buf[idxs],\r\n            done=self.done_buf[idxs],\r\n        )\r\n\r\nrpm = ReplayBuffer((28,), (4,), int(1e6))\r\n\r\n# store 1M of experiences from the game\r\nfor i in range(10000):\r\n    rpm.store(\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([4]),\r\n        tf.random.uniform([1]),\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([1])\r\n    )\r\n\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(gradient_steps):\r\n        obs, act, rew, next_obs, done = rpm.sample(batch_size)\r\n\r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....\r\n\r\ntrain(rpm, 8, 10)\r\n```\r\n\r\n> Result from Colab:\r\n> 2.4.1\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n> array([2932, 3930, 5488, 7077, 7024, 4499, 5958, 7022])\r\n\r\nCan I rewrite it to tensors?\r\n\r\nThanks.", "Hi @markub3327, if I understand correctly from this thread, you're only seeing that `OperatorNotAllowedInGraphError` when `rpm = ReplayBuffer(size=1000000)` but there does not seem to be an issue if the size is smaller (say 10)?\r\n\r\nIs that correct?", "Yes, when I created too large `tf.TensorArray` for storing interactions of my agent, it's crashed. I do the same thing with NumPy arrays and it's working.\r\n\r\nWith Numpy:\r\n```python\r\nnp.zeros((size,) + obs_dim, dtype=np.float32)\r\n```\r\n\r\nWith TF:\r\n```python\r\ntf.TensorArray(tf.float32, size=size, clear_after_read=False, dynamic_size=False)\r\n```\r\n\r\nExist an effective way of implementing this? [Tensorflow Replay Buffers](https://www.tensorflow.org/agents/tutorials/5_replay_buffers_tutorial) is no the solution for me. Thanks.", "TensorArrays are a bit problematic here (its a known issue) [Details: We have [2 kinds of TensorArrays](https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/tensor_array_ops.py#L1055) - eager mode and graph mode; capturing eager mode tensor arrays in graph/tf.function mode isn't well supported and thats why you run into problems doing a .read() on self.obs_buf etc.]\r\n\r\nI'd recommend the approach you're gravitating towards in your last update i.e. using Tensors instead. The only nuance here is that Tensorflow Tensors are immutable and so you can't manipulate them like numpy arrays. As a result you need to use scatter/gather ops instead.\r\n\r\n```python\r\nclass ReplayBuffer:\r\n    \"\"\"\r\n    A simple FIFO experience replay buffer for DDPG agents.\r\n    Based on https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/ddpg/ddpg.py.\r\n    \"\"\"\r\n\r\n    def __init__(self, obs_dim, act_dim, size):\r\n        self.obs_buf = tf.zeros((size,) + obs_dim, dtype=tf.float32)\r\n        self.obs2_buf = tf.zeros((size,) + obs_dim, dtype=tf.float32)\r\n        self.act_buf = tf.zeros((size,) + act_dim, dtype=tf.float32)\r\n        self.rew_buf = tf.zeros((size, 1), dtype=tf.float32)\r\n        self.done_buf = tf.zeros((size, 1), dtype=tf.float32)\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf = tf.tensor_scatter_nd_update(self.obs_buf, [[self.ptr]], [obs])\r\n        self.obs2_buf = tf.tensor_scatter_nd_update(self.obs2_buf, [[self.ptr]], [next_obs])\r\n        self.act_buf = tf.tensor_scatter_nd_update(self.act_buf, [[self.ptr]], [act])\r\n        self.rew_buf = tf.tensor_scatter_nd_update(self.rew_buf, [[self.ptr]], [rew])\r\n        self.done_buf = tf.tensor_scatter_nd_update(self.done_buf, [[self.ptr]], [done])\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    def sample(self, batch_size):\r\n        idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n        tf.print(idxs)\r\n\r\n        return dict(\r\n            obs=tf.gather(self.obs_buf, idxs),\r\n            obs2=tf.gather(self.obs2_buf, idxs),\r\n            act=tf.gather(self.act_buf, idxs),\r\n            rew=tf.gather(self.rew_buf, idxs),\r\n            done=tf.gather(self.done_buf, idxs),\r\n        )\r\n\r\nrpm = ReplayBuffer((28,), (4,), int(1e6))\r\n\r\n# store 1M of experiences from the game\r\nfor i in range(10000):\r\n    rpm.store(\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([4]),\r\n        tf.random.uniform([1]),\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([1])\r\n    )\r\n\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(gradient_steps):\r\n        obs, act, rew, next_obs, done = rpm.sample(batch_size)\r\n\r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....\r\n\r\ntrain(rpm, 8, 10)\r\n```\r\n\r\nI've verified that this works. Please let me know what you think! ", "Yeah, It looks well, but I tested it in Colab and the run cell takes about 11 min 14 s. The NumPy array solution is faster, only 3 s.\r\n\r\nWith fewer elements than 10000 was the run shorter.", "The program that I provided in the last comment - I ran that on colab and it took around 35 seconds (I was using a GPU runtime). I tried with CPU runtime and that was really slow (didn't even get to finish).\r\n\r\nAnother option is to use tf.Variable here - the biggest slowdown is because of the tf.tensor_scatter_nd_update since that allocates and creates a new tensor each time. With tf.Variable, we just re-use the same underlying buffer and the CPU runtime comes down to 15 seconds.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport time\r\n\r\nclass ReplayBuffer:\r\n    \"\"\"\r\n    A simple FIFO experience replay buffer for DDPG agents.\r\n    Based on https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/ddpg/ddpg.py.\r\n    \"\"\"\r\n\r\n    def __init__(self, obs_dim, act_dim, size):\r\n        self.obs_buf = tf.Variable(tf.zeros((size,) + obs_dim, dtype=tf.float32))\r\n        self.obs2_buf = tf.Variable(tf.zeros((size,) + obs_dim, dtype=tf.float32))\r\n        self.act_buf = tf.Variable(tf.zeros((size,) + act_dim, dtype=tf.float32))\r\n        self.rew_buf = tf.Variable(tf.zeros((size, 1), dtype=tf.float32))\r\n        self.done_buf = tf.Variable(tf.zeros((size, 1), dtype=tf.float32))\r\n        self.ptr, self.size, self.max_size = 0, 0, size\r\n\r\n    def store(self, obs, act, rew, next_obs, done):\r\n        self.obs_buf.scatter_nd_update([[self.ptr]], [obs])\r\n        self.obs2_buf.scatter_nd_update([[self.ptr]], [next_obs])\r\n        self.act_buf.scatter_nd_update([[self.ptr]], [act])\r\n        self.rew_buf.scatter_nd_update([[self.ptr]], [rew])\r\n        self.done_buf.scatter_nd_update([[self.ptr]], [done])\r\n        self.ptr = (self.ptr + 1) % self.max_size\r\n        self.size = min(self.size + 1, self.max_size)\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    def sample(self, batch_size):\r\n        idxs = tf.random.uniform(shape=[batch_size], maxval=self.size, dtype=tf.int32)\r\n        # tf.print(idxs)\r\n\r\n        return dict(\r\n            obs=tf.gather(self.obs_buf, idxs),\r\n            obs2=tf.gather(self.obs2_buf, idxs),\r\n            act=tf.gather(self.act_buf, idxs),\r\n            rew=tf.gather(self.rew_buf, idxs),\r\n            done=tf.gather(self.done_buf, idxs),\r\n        )\r\n\r\nrpm = ReplayBuffer((28,), (4,), int(1e6))\r\n\r\n@tf.function\r\ndef train(rpm, batch_size, gradient_steps):\r\n    for gradient_step in tf.range(gradient_steps):\r\n        obs, act, rew, next_obs, done = rpm.sample(batch_size)\r\n\r\n       # HERE I RUN tf.GradientTape BUT IT IS NOT IMPORTANT FOR NOW ....\r\n\r\nstart_time = time.time()\r\n# store 1M of experiences from the game\r\nfor i in range(10000):\r\n    rpm.store(\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([4]),\r\n        tf.random.uniform([1]),\r\n        tf.random.uniform([28]),\r\n        tf.random.uniform([1])\r\n    )\r\n\r\n\r\n\r\ntrain(rpm, 8, 10)\r\nend_time = time.time()\r\n\r\nprint(end_time - start_time)\r\n```", "Was able to reproduce the issue in   TF 2.6.0-dev20210527,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/471b72ca3d82747ddeb45bba0d269419/untitled32.ipynb#scrollTo=pty7ZQoGKH34)..Thanks !", "Thanks @rohan100jain ! It's a solution for me. I tested it on CPU with time ~15 s, on GPU ~35 s and Numpy version has ~10 s.  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47230\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47230\">No</a>\n"]}]