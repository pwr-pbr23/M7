[{"number": 33743, "title": "Hyperlink in codelab redirects to a 404 page", "body": "#32417  URL(s) with the issue:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&utm_source=gdev&utm_medium=yt-desc#1\r\n\r\n## Description of issue (what needs changing):\r\nUpdate the link to redirect to the latest version of Tensorflow\r\n\r\n### Clear description\r\n\r\nAlways better to redirect to a page that helps out a user, rather than keep links to 404 pages.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Raises listed and defined\r\n\r\nServer raises a 404 Page, which is an error.\r\n\r\n### Usage example\r\n\r\nIt isn't exactly a use case. Just a QoL change.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n<img width=\"1440\" alt=\"Screenshot 2019-10-26 at 4 36 23 PM\" src=\"https://user-images.githubusercontent.com/41414202/67618592-17435f80-f80f-11e9-9cb1-2b4d9a44ab34.png\">\r\n<img width=\"1440\" alt=\"Screenshot 2019-10-26 at 4 36 31 PM\" src=\"https://user-images.githubusercontent.com/41414202/67618594-1a3e5000-f80f-11e9-92f4-6716b871496f.png\">\r\n\r\n\r\n\r\n### Submit a pull request?\r\n Yes. I love contributing in small ways, since I'm still a rather newbie developer. Errors even small should be dealt with I presume?\r\n\r\n", "comments": ["Could I receive some help regarding the repo? Please ping me at abhishek.sankar.in@ieee.org\r\n\r\nThanks!", "That Codelab has been deprecated ever since TF 2.0 was released. A 2.0 version of the colab can be found at [https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb](url)"]}, {"number": 33742, "title": "Cannot import tensorflow.math, tensorflow.linalg and much more", "body": "\r\n**System information**\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n2.0.0 behavior\r\n\r\n```python3\r\n>>> import tensorflow\r\n>>> tensorflow.__version__\r\n'2.0.0'\r\n>>> import tensorflow.linalg\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.linalg'\r\n```\r\n\r\nI am unable to import as above, but only `tensorflow.math.sin` works when I import tensorflow.\r\n\r\n**Describe the expected behavior**\r\n\r\n1.13 and 1.14 behavior\r\n```python3\r\n>>> import tensorflow\r\n>>> tensorflow.__version__\r\n'1.13.1'\r\n>>> import tensorflow.math\r\n>>> import tensorflow.linalg\r\n>>> from tensorflow.math import sin\r\n```\r\n```python3\r\n>>> import tensorflow\r\n>>> tensorflow.__version__\r\n'1.14.0'\r\n>>> import tensorflow.math\r\n>>> import tensorflow.linalg\r\n>>> from tensorflow.math import sin\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\n**Other info / logs**\r\n", "comments": ["I think changing the code to:\r\n```python\r\nfrom tensorflow import linalg, math\r\n```\r\nfixes the issue.\r\nBut you then need to use, math.sin() and so on...\r\n", "Duplicate to #33022."]}, {"number": 33741, "title": "Copy one graph to another", "body": "I want to copy a loaded graph to another one. Here, is what I'm trying to do\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\n\r\ninput_names = ['image_tensor']\r\npb_fname1 = \"/Users/vedanshu/frozen_graph/ssd_tomato_l1_frozen_graph.pb\"\r\n\r\ndef get_frozen_graph(graph_file):\r\n    \"\"\"Read Frozen Graph file from disk.\"\"\"\r\n    with tf.gfile.FastGFile(graph_file, \"rb\") as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n    return graph_def\r\n\r\ntrt_graph1 = get_frozen_graph(pb_fname1)\r\n\r\ndetection_graph1 = tf.Graph()\r\nwith detection_graph1.as_default():\r\n    tf.import_graph_def(trt_graph1, name='')\r\n    tf_sess1 = tf.Session(graph=detection_graph1)\r\n\r\ntf_input1 = tf_sess1.graph.get_tensor_by_name(input_names[0] + ':0')\r\ntf_scores1 = tf_sess1.graph.get_tensor_by_name('detection_scores:0')\r\ntf_boxes1 = tf_sess1.graph.get_tensor_by_name('detection_boxes:0')\r\ntf_classes1 = tf_sess1.graph.get_tensor_by_name('detection_classes:0')\r\ntf_num_detections1 = tf_sess1.graph.get_tensor_by_name('num_detections:0')\r\n```\r\n\r\nNow I want to copy `tf_input1`, `tf_scores1`, `tf_boxes1`, `tf_num_detections1` to another graph. Currently I'm trying to use `copy_op_to_graph` (depricated) as follows:\r\n\r\n```\r\nimport sys\r\n\r\ndetection_graph2 = tf.Graph()\r\n\r\nnamespace = \"Ved\"\r\ncopied_variables = []\r\nsys.setrecursionlimit(10000000)\r\n\r\ntf_num_detections1_copy = tf.contrib.copy_graph.copy_op_to_graph(tf_num_detections1, detection_graph2,copied_variables, namespace)\r\n```\r\n\r\nBut the python kernel is getting killed without any error. \r\n\r\nSystem informations:\r\nOS: Mac OS 10.13.6\r\nTf veriosn: 1.13.1\r\nRAM: 8GB\r\n", "comments": ["@anshkumar ,\r\nCan you please share `ssd_tomato_l1_frozen_graph.pb` so that we can try replicating the issue ?Thanks!", "@oanush Here is the [link](https://drive.google.com/open?id=1JC66YZEsdjtuGTF6ONJEfNibhJvSMvj5) to the model.", "Issue replicating for the given code both in TF version-1.13 and 1.15. Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/dd9fead0efb88c6947e2540896d6380c/untitled25.ipynb) of the colab.Thanks!", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33741\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33741\">No</a>\n"]}, {"number": 33740, "title": "Why Isn't TensorFlow Website Accessible from Iranian IP Addresses?", "body": "\r\n![Screenshot from 2019-10-26 10-34-20](https://user-images.githubusercontent.com/14098141/67616056-f9f79c80-f7e0-11e9-9499-fb4c3d008fee.png)\r\n\r\nI'm Iranian, from Iranian IP address, TensorFlow.org is not accessible?\r\n\r\nNow, I have the following questions:\r\n\r\n- If I use TensorFlow in my projects, is it illegal? \r\n- Can you address the article that base on that you have prohibited access to TensorFlow.org for Iranian?\r\n- Is it fair to prohibiting a project that the contributors all around the world are contributing to it?\r\n", "comments": ["Duplicate #18169\r\nSee https://github.com/tensorflow/tensorflow/issues/18169#issuecomment-378005528 to know more", "Closing as duplicate. Please consul #18169 for reasons.", "Firstly, my issue has three questions, are all questions of my issue duplicate?\r\n\r\nSecondly, can you confirm that the reason of inaccessibility is hosting on Google Cloud Platform and not because of the field of activity? in other world, can you address an official document that confirm that all websites hosted on Google Cloud Platform are inaccessible from Iranian IP addresses? or can you address an official document that confirm that the reason is not because [TensorFlow.org](https://www.tensorflow.org/) has been sanctioned because of only the field of activity (i.e. artificial intelligence) ?\r\n\r\nAbove all, if you can't answers my question, please introduce me a channel to contact to Google.", "Dear @mihaimaruseac, please open my issue again.", "Dear @mihaimaruseac, please open my issue again.", "Apologies for late response. However, I cannot further comment on your questions, beside marking this a duplicate of #18169.", "> Apologies for late response. However, I cannot further comment on your questions, beside marking this a duplicate of #18169.\r\n\r\nThank you very much."]}, {"number": 33739, "title": "add a new class for realizing Early Stopping", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0 but this is for keras.\r\n- Are you willing to contribute it (Yes/No): yes. I have already realized it and now I am using it.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI want to add a new class for realizing Early Stopping. \r\n\r\nThey are based on 3 metrics from paper \"Early Stopping - but when? Lutz Prechelt, University Karlsrhe\". \r\n\r\n1. **Generalization Loss**(GL). GL can be described as a metric that can measure how much current validation loss exceeds the lowest validation loss. Training will stop as soon as GL exceeds a certain threshold. \r\n\r\n2. **Progress Quotient**(PQ).  It considers training strip of length `k`. Progress means how much was the average training error during the strip larger than the minimum training error during the strip. Quotient means use the quotient of GL and Progress. Thus, training will stop as soon as the PQ exceeds a certain threshold. \r\n\r\n3. **UP**. This is simple. Training will stop when the generalization error increased in `s` successive strips.\r\n\r\nCombining these metrics, there are 5 modes for doing early stopping. 1, 2, 3, 1+3, 2+3.\r\n\r\nNow the EarlyStopping class of Keras can only stop training based on patience and delta, whereas there are advanced and useful early stopping methods.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo. Only a new class will be added.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nBasically all workers using Keras.\r\n\r\n**Any Other info.**\r\n\r\nThis idea comes from others paper, I just realized it. For further info, please refer to the paper.\r\n[early stopping - but when.pdf](https://github.com/tensorflow/tensorflow/files/3774558/early.stopping.-.but.when.pdf)\r\n\r\n", "comments": ["@wubowen416,\r\nSorry for the delayed response. In your comment you stated:\r\n\r\n> Are you willing to contribute it (Yes/No): yes. I have already realized it and now I am using it.\r\n\r\nSince you have already realized it and are using it, can you please submit a **`PR`** so that the respective Engineers can review it?\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33738, "title": "TypeError: expected str, bytes or os.PathLike object, not NoneType", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\npip install tensorflow-gpu\r\n- TensorFlow version:\r\n2\r\n- Python version:\r\n3.7\r\n- Installed using virtualenv? pip? conda?:\r\npip in a conda env\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\ncuda 10.0.1\r\n- GPU model and memory:\r\nGeForce GTX 1050 Ti with Max-Q Design/PCIe/SSE2\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 45, in <module>\r\n    from . _api.v2 import compat\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/__init__.py\", line 23, in <module>\r\n    from . import v1\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py\", line 666, in <module>\r\n    [_module_util.get_parent_dir(estimator)] + _current_module.__path__)\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tools/module_util.py\", line 24, in get_parent_dir\r\n    return os.path.abspath(os.path.join(os.path.dirname(module.__file__), \"..\"))\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/posixpath.py\", line 156, in dirname\r\n    p = os.fspath(p)\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType\r\n", "comments": ["duplicate #33730", "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\r\nUsing cache found in /home/glmr/.cache/torch/hub/pytorch_fairseq_master\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/glmr/anaconda3/envs/fairseq/lib/python3.6/site-packages/torch/hub.py\", line 363, in load\r\n    model = entry(*args, **kwargs)\r\n  File \"/home/glmr/.cache/torch/hub/pytorch_fairseq_master/fairseq/models/fairseq_model.py\", line 190, in from_pretrained\r\n    **kwargs,\r\n  File \"/home/glmr/.cache/torch/hub/pytorch_fairseq_master/fairseq/hub_utils.py\", line 56, in from_pretrained\r\n    kwargs['data'] = os.path.abspath(os.path.join(model_path, data_name_or_path))\r\n  File \"/home/glmr/anaconda3/envs/fairseq/lib/python3.6/posixpath.py\", line 80, in join\r\n    a = os.fspath(a)\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType\r\n", "Anyone pls help with this problem.\r\n"]}, {"number": 33737, "title": "AttributeError: module 'tensorflow' has no attribute 'matrix_band_part'", "body": "There is a past issue #30297, but no updates. The reproducible example is here.\r\n\r\nhttps://github.com/bojone/bert4keras/blob/eb4dcffd72b9ba08a7ccfb11aee8cdfaeed2d1df/bert4keras/bert.py#L292-L300\r\n\r\nI get this error `AttributeError: module 'tensorflow' has no attribute 'matrix_band_part'`, when I run sorta code in Jupyter notebook.\r\nSurely, I install 2.0.0 Tensorflow on Windows 7.  Here is my session information.\r\n\r\n<details>\r\n<summary>Session Info</summary>\r\n\r\n```bash\r\n# packages in environment at D:\\install\\miniconda:\r\n#\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   0.8.1                    pypi_0    pypi\r\nasn1crypto                0.24.0                   py37_0  \r\nastor                     0.8.0                    pypi_0    pypi\r\natomicwrites              1.3.0                    pypi_0    pypi\r\nattrs                     19.1.0                   py37_1  \r\nbackcall                  0.1.0                    py37_0  \r\nbert-tensorflow           1.0.1                    pypi_0    pypi\r\nblas                      1.0                         mkl    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\r\nbleach                    3.1.0                    py37_0  \r\nblis                      0.4.1                    pypi_0    pypi\r\nboto                      2.49.0                   pypi_0    pypi\r\nboto3                     1.9.252                  pypi_0    pypi\r\nbotocore                  1.12.252                 pypi_0    pypi\r\nbzip2                     1.0.8                he774522_0  \r\nca-certificates           2019.5.15                     0  \r\ncertifi                   2019.6.16                py37_1  \r\ncffi                      1.12.3           py37h7a1dbc1_0  \r\nchardet                   3.0.4                    py37_1  \r\ncolorama                  0.4.1                    py37_0  \r\nconda                     4.7.10                   py37_0  \r\nconda-package-handling    1.3.11                   py37_0  \r\nconsole_shortcut          0.1.1                         3  \r\ncryptography              2.7              py37h7a1dbc1_0  \r\ncycler                    0.10.0                   pypi_0    pypi\r\ncymem                     2.0.2                    pypi_0    pypi\r\ndecorator                 4.4.0                    py37_1  \r\ndefusedxml                0.6.0                      py_0  \r\ndocutils                  0.15.2                   pypi_0    pypi\r\nentrypoints               0.3                      py37_0  \r\nfastprogress              0.1.21                   pypi_0    pypi\r\nfreetype                  2.9.1                ha9979f8_1  \r\nfuncy                     1.13                     pypi_0    pypi\r\nfuture                    0.18.1                   pypi_0    pypi\r\ngast                      0.2.2                    pypi_0    pypi\r\ngensim                    3.8.1                    pypi_0    pypi\r\ngoogle-pasta              0.1.7                    pypi_0    pypi\r\ngrpcio                    1.24.1                   pypi_0    pypi\r\nh5py                      2.10.0                   pypi_0    pypi\r\nicc_rt                    2019.0.0             h0cc432a_1  \r\nicu                       58.2                 ha66f8fd_1  \r\nidna                      2.8                      py37_0  \r\nimportlib-metadata        0.23                     pypi_0    pypi\r\nintel-openmp              2019.4                      245  \r\nipykernel                 5.1.1            py37h39e3cac_0  \r\nipython                   7.7.0            py37h39e3cac_0  \r\nipython_genutils          0.2.0                    py37_0  \r\nipywidgets                7.5.0                      py_0  \r\njedi                      0.13.3                   py37_0  \r\njieba                     0.39                     pypi_0    pypi\r\njinja2                    2.10.1                   py37_0  \r\njmespath                  0.9.4                    pypi_0    pypi\r\njoblib                    0.14.0                   pypi_0    pypi\r\njpeg                      9b                   hb83a4c4_2  \r\njsonschema                3.0.1                    py37_0  \r\njupyter                   1.0.0                    py37_7  \r\njupyter_client            5.3.1                      py_0  \r\njupyter_console           6.0.0                    py37_0  \r\njupyter_core              4.5.0                      py_0  \r\nkeras                     2.3.1                    pypi_0    pypi\r\nkeras-applications        1.0.8                    pypi_0    pypi\r\nkeras-bert                0.80.0                   pypi_0    pypi\r\nkeras-embed-sim           0.7.0                    pypi_0    pypi\r\nkeras-layer-normalization 0.13.0                   pypi_0    pypi\r\nkeras-multi-head          0.22.0                   pypi_0    pypi\r\nkeras-pos-embd            0.11.0                   pypi_0    pypi\r\nkeras-position-wise-feed-forward 0.6.0                    pypi_0    pypi\r\nkeras-preprocessing       1.1.0                    pypi_0    pypi\r\nkeras-rectified-adam      0.17.0                   pypi_0    pypi\r\nkeras-self-attention      0.41.0                   pypi_0    pypi\r\nkeras-transformer         0.31.0                   pypi_0    pypi\r\nkiwisolver                1.1.0                    pypi_0    pypi\r\nlibarchive                3.3.3                h0643e63_5  \r\nlibiconv                  1.15                 h1df5818_7  \r\nlibpng                    1.6.37               h2a8f88b_0  \r\nlibsodium                 1.0.16               h9d3ae62_0  \r\nlibtiff                   4.0.10               hb898794_2  \r\nlibxml2                   2.9.9                h464c3ec_0  \r\nlightgbm                  2.3.0                    pypi_0    pypi\r\nlz4-c                     1.8.1.2              h2fa13f4_0  \r\nlzo                       2.10                 h6df0209_2  \r\nm2w64-gcc-libgfortran     5.3.0                         6  \r\nm2w64-gcc-libs            5.3.0                         7  \r\nm2w64-gcc-libs-core       5.3.0                         7  \r\nm2w64-gmp                 6.1.0                         2  \r\nm2w64-libwinpthread-git   5.0.0.4634.697f757               2  \r\nmarkdown                  3.1.1                    pypi_0    pypi\r\nmarkupsafe                1.1.1            py37he774522_0  \r\nmatplotlib                3.1.1                    pypi_0    pypi\r\nmenuinst                  1.4.16           py37he774522_0  \r\nmistune                   0.8.4            py37he774522_0  \r\nmkl                       2019.4                      245  \r\nmkl_fft                   1.0.12           py37h14836fe_0  \r\nmkl_random                1.0.2            py37h343c172_0  \r\nmore-itertools            7.2.0                    pypi_0    pypi\r\nmsys2-conda-epoch         20160418                      1  \r\nmurmurhash                1.0.2                    pypi_0    pypi\r\nnbconvert                 5.5.0                      py_0  \r\nnbformat                  4.4.0                    py37_0  \r\nninja                     1.7.2                         0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\r\nnotebook                  6.0.0                    py37_0  \r\nnumexpr                   2.7.0                    pypi_0    pypi\r\nnumpy                     1.16.4           py37h19fb1c0_0  \r\nnumpy-base                1.16.4           py37hc3f5095_0  \r\nolefile                   0.46                     py37_0  \r\nopencv-python             4.1.0.25                 pypi_0    pypi\r\nopenssl                   1.1.1c               he774522_1  \r\nopt-einsum                3.1.0                    pypi_0    pypi\r\npackaging                 19.2                     pypi_0    pypi\r\npandas                    0.25.0           py37ha925a31_0  \r\npandoc                    1.19.2.1                      1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\r\npandocfilters             1.4.2                    py37_1  \r\nparso                     0.5.0                      py_0  \r\npickleshare               0.7.5                    py37_0  \r\npillow                    6.1.0            py37hdc69c19_0  \r\npip                       19.1.1                   py37_0  \r\nplac                      0.9.6                    pypi_0    pypi\r\npluggy                    0.13.0                   pypi_0    pypi\r\npowershell_shortcut       0.0.1                         2  \r\npreshed                   3.0.2                    pypi_0    pypi\r\nprometheus_client         0.7.1                      py_0  \r\nprompt_toolkit            2.0.9                    py37_0  \r\nprotobuf                  3.10.0                   pypi_0    pypi\r\npy                        1.8.0                    pypi_0    pypi\r\npycosat                   0.6.3            py37hfa6e2cd_0  \r\npycparser                 2.19                     py37_0  \r\npygments                  2.4.2                      py_0  \r\npyks                      1.1.3                    pypi_0    pypi\r\npyldavis                  2.1.2                    pypi_0    pypi\r\npyopenssl                 19.0.0                   py37_0  \r\npyparsing                 2.4.2                    pypi_0    pypi\r\npyqt                      5.9.2            py37h6538335_2  \r\npyrsistent                0.14.11          py37he774522_0  \r\npysocks                   1.7.0                    py37_0  \r\npytest                    5.2.1                    pypi_0    pypi\r\npython                    3.7.3                h8c8aaf0_1  \r\npython-dateutil           2.8.0                    py37_0  \r\npython-libarchive-c       2.8                     py37_11  \r\npytorch-cpu               1.1.0               py3.7_cpu_1    pytorch\r\npytz                      2019.1                     py_0  \r\npywin32                   223              py37hfa6e2cd_1  \r\npywinpty                  0.5.5                 py37_1000  \r\npyyaml                    5.1.2                    pypi_0    pypi\r\npyzmq                     18.0.0           py37ha925a31_0  \r\nqt                        5.9.7            vc14h73c81de_0  \r\nqtconsole                 4.5.2                      py_0  \r\nrequests                  2.22.0                   py37_0  \r\nruamel_yaml               0.15.46          py37hfa6e2cd_0  \r\ns3transfer                0.2.1                    pypi_0    pypi\r\nscikit-learn              0.21.3                   pypi_0    pypi\r\nscipy                     1.3.1                    pypi_0    pypi\r\nseaborn                   0.9.0                    pypi_0    pypi\r\nsend2trash                1.5.0                    py37_0  \r\nsetuptools                41.0.1                   py37_0  \r\nsip                       4.19.8           py37h6538335_0  \r\nsix                       1.12.0                   py37_0  \r\nsmart-open                1.8.4                    pypi_0    pypi\r\nspacy                     2.2.1                    pypi_0    pypi\r\nsqlite                    3.29.0               he774522_0  \r\nsrsly                     0.1.0                    pypi_0    pypi\r\ntensorboard               2.0.0                    pypi_0    pypi\r\ntensorflow                2.0.0                    pypi_0    pypi\r\ntensorflow-estimator      2.0.1                    pypi_0    pypi\r\ntensorflow-hub            0.6.0                    pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nterminado                 0.8.2                    py37_0  \r\ntestpath                  0.4.2                    py37_0  \r\nthinc                     7.1.1                    pypi_0    pypi\r\ntk                        8.6.8                hfa6e2cd_0  \r\ntorchvision-cpu           0.3.0             py37_cuNone_1    pytorch\r\ntornado                   6.0.3            py37he774522_0  \r\ntqdm                      4.32.1                     py_0  \r\ntraitlets                 4.3.2                    py37_0  \r\nurllib3                   1.24.2                   py37_0  \r\nvc                        14.1                 h0510ff6_4  \r\nvs2015_runtime            14.15.26706          h3a45250_4  \r\nwasabi                    0.2.2                    pypi_0    pypi\r\nwcwidth                   0.1.7                    py37_0  \r\nwebencodings              0.5.1                    py37_1  \r\nwerkzeug                  0.16.0                   pypi_0    pypi\r\nwheel                     0.33.4                   py37_0  \r\nwidgetsnbextension        3.5.0                    py37_0  \r\nwin_inet_pton             1.1.0                    py37_0  \r\nwincertstore              0.2                      py37_0  \r\nwinpty                    0.4.3                         4  \r\nwrapt                     1.11.1                   pypi_0    pypi\r\nxlrd                      1.2.0                    pypi_0    pypi\r\nxz                        5.2.4                h2fa13f4_4  \r\nyaml                      0.1.7                hc54c509_2  \r\nzeromq                    4.3.1                h33f27b4_3  \r\nzipp                      0.6.0                    pypi_0    pypi\r\nzlib                      1.2.11               h62dcd97_3  \r\nzstd                      1.3.7                h508b16e_0  \r\n```\r\n\r\n</details>", "comments": ["@JiaxiangBU \r\nPlease, provide simple standalone code to reproduce the issue in our environment, then it is easy for localizing the issue faster. Thanks!", "@JiaxiangBU \r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 33736, "title": "AttributeError: module 'tensorflow_core._api.v2.image' has no attribute 'resize_images'", "body": "I am trying to load pspnet pretrained model and encountered the said error.\r\nAttributeError: module 'tensorflow_core._api.v2.image' has no attribute 'resize_images'\r\nCould please guide me how resolve this?\r\nConfig: Windows10\r\nusing Juyter notebook\r\ntensorflow version: 2.0.0\r\ncode source : https://github.com/divamgupta/image-segmentation-keras\r\nThe code used to reproduce the issue is:\r\nimport keras_segmentation\r\nmodel = keras_segmentation.pretrained.pspnet_101_voc12()", "comments": ["This issue is not on TF side but more on ```keras-segmentation``` module as mentioned in the template.\r\nAs mentioned in the prerequisites you have to install keras 2.0 version to make it work.\r\nSee https://github.com/divamgupta/image-segmentation-keras#prerequisites\r\nInstalling newer keras version (above 2.0) fails to load the model.\r\nFor further question https://github.com/divamgupta/image-segmentation-keras/issues github repo can be a good platform."]}, {"number": 33735, "title": "Large bias values for Inception V4 TFLite model", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nModel: Inception V4\r\nDataset: Dog 120. \r\nCalibration images: 10 images of resolution 299x299\r\n\r\nSteps to convert to TFLite model:\r\n- converter = tf.lite.TFLiteConverter.from_frozen_graph(model_file,  [input_node], [output_node])\r\n- converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n- converter.representative_dataset = representative_dataset_gen\r\n- with open(tflite_model_file, \"wb\") as w:\r\n\tw.write(converter.convert())\r\n\r\nI see the bias values of most of the convolution having values such as \"-2147483647\". Below is an example. \r\n\r\n![image](https://user-images.githubusercontent.com/5778892/67609304-e137aa00-f740-11e9-86a6-ddb9ff382f39.png)\r\n\r\nThe corresponding frozen protobuf value is:\r\n\r\n![image](https://user-images.githubusercontent.com/5778892/67609341-147a3900-f741-11e9-89b0-2a817c476dde.png)\r\n\r\nCan someone help me understand why the quantization is happening in such a way for the INT32 biases ? \r\n\r\n\r\n", "comments": ["Hi, \r\n\r\nAny update on this thread? ", "Apologies for the delayed response, reassigning to some folks who can help.", "Thanks for flagging this issue! We also found this ourselves and implemented a scale adjustment to avoid overflow when quantizing biases. Can you try again with the nightly build and let us know how it goes? Thanks!", "Thank you so much for your reply. I will try the nightly build version soon and let you know. ", "Hi @smohan10 Can you please update the bug with your results?\r\nThanks", "We've verified inception v4 works fine with post-training quantization. \r\nTop 1 accuracy, float 80.24%, and quantized 80.21%.\r\nFeel free to reopen if you run into other issues."]}, {"number": 33734, "title": "RuntimeError:Data adapters should be mutually exclusive", "body": "Today I run [transfer_learning_with_hub.ipynb](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb) **on Google Colab**, It show errors info below.\r\n**But yesterday I run this jupyter nootbook successfully.**\r\n\r\nIt seems that  using the latest TensorFlow version **2.1.0-dev20191025** cause the problem\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**Linux 5c32dbcf8bfd 4.14.137+ #1 SMP Thu Aug 8 02:47:02 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux**\r\n- TensorFlow version (use command below):**'2.1.0-dev20191025'**\r\n- Python version:**Python 3.6.8**\r\n- GCC/Compiler version (if compiling from source): **[GCC 8.3.0] on linux**\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:12.72GB\r\n\r\n\r\n**Describe the current behavior**\r\nerrors is below\r\n\r\n**Describe the expected behavior**\r\nYesterday, I run this jupyter nootbook successfully.\r\n\r\n**Code to reproduce the issue**\r\nwhen runnig codes below it show errors\r\n```\r\nsteps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\r\nbatch_stats_callback = CollectBatchStats()\r\nhistory = model.fit_generator(image_data, epochs=2,\r\n                              steps_per_epoch=steps_per_epoch,\r\n                              callbacks = [batch_stats_callback])\r\n```\r\n\r\n\r\n**Other info / logs**\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-52-dd38f4e8ca03> in <module>()\r\n      5 history = model.fit_generator(image_data, epochs=2,\r\n      6                               steps_per_epoch=steps_per_epoch,\r\n----> 7                               callbacks = [batch_stats_callback])\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in select_data_adapter(x, y)\r\n    979         \"handling inputs. Found multiple adapters {} to handle \"\r\n    980         \"input: {}, {}\".format(\r\n--> 981             adapter_cls, _type_name(x), _type_name(y)))\r\n    982   return adapter_cls[0]\r\n    983 \r\n\r\nRuntimeError: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.KerasSequenceAdapter'>] to handle input: <class 'keras_preprocessing.image.directory_iterator.DirectoryIterator'>, <class 'NoneType'>\r\n```\r\n", "comments": ["After downgrade tensorflow  tf-hub-nightly and  tf-nightly It works.", "Closing this issue since its resolved. Thanks!"]}, {"number": 33733, "title": "TF2 compilation of rule //tensorflow/lite/experimental/ruy:pack failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source, git clone\r\n- TensorFlow version: r2.0\r\n- Python version: Python 3.6.8\r\n- Installed using virtualenv? pip? condo?: git clone https://github.com/tensorflow/tensorflow.git\r\n- Bazel version (if compiling from source): 0.26.0, Build timestamp: 1559032514\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: Not part of the compilation.\r\n- GPU model and memory: No GPU support\r\n\r\nThis is built on AWS r5.large server, 16 GB RAM\r\n\r\n\r\n\r\n**Describe the problem**\r\nERROR: /srv/projects/tf2/tfgit/tensorflow/lite/experimental/ruy/BUILD:297:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:pack' failed (Exit 1)\r\nIn file included from tensorflow/lite/experimental/ruy/pack_avx512.cc:16:0:\r\n./tensorflow/lite/experimental/ruy/pack.h:489:9: warning: multi-line comment [-Wcomment]\r\n #endif  // (RUY_PLATFORM(NEON_64) || RUY_PLATFORM(NEON_32)) && \\\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["I tried to attach a log, but I suspect Github wouldn't attach it, cause my browser version isn't supported. So I am dumping a log inline here for your information:\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:30:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:19,\r\n                 from tensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:28:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'void vst1q_lane_f32(float32_t*, float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9725:31: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *(ptr) =  *((float*)&ilane);\r\n                               ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'float32_t vgetq_lane_f32(float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:11964:22: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     return *(float*)&ilane;\r\n                      ^~~~~\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc: In function 'void tflite::tensor_utils::NeonMatrixBatchVectorMultiplyAccumulate(const int8_t*, int, int, const int8_t*, const float*, int, float*, int)':\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:474:57: warning: 'int64x2_t vpaddlq_s32(int32x4_t)' is deprecated: The function may be very slow due to the serial implementation, please try to avoid it [-Wdeprecated-declarations]\r\n       int64x2_t pairwiseAdded = vpaddlq_s32(dotprod_32x4);\r\n                                                         ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:30:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:19,\r\n                 from tensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:28:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:6451:58: note: declared here\r\n _NEON2SSE_INLINE _NEON2SSE_PERFORMANCE_WARNING(int64x2_t vpaddlq_s32(int32x4_t a), _NEON2SSE_REASON_SLOW_SERIAL) // VPADDL.S32 q0,q0\r\n                                                          ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:76:109: note: in definition of macro '_NEON2SSE_PERFORMANCE_WARNING'\r\n     #define _NEON2SSE_PERFORMANCE_WARNING(function, explanation)   __attribute__((deprecated(explanation))) function\r\n                                                                                                             ^~~~~~~~\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc: In function 'void tflite::tensor_utils::NeonSparseMatrixBatchVectorMultiplyAccumulate(const int8_t*, const uint8_t*, int, int, const int8_t*, const float*, int, float*, int)':\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:612:59: warning: 'int64x2_t vpaddlq_s32(int32x4_t)' is deprecated: The function may be very slow due to the serial implementation, please try to avoid it [-Wdeprecated-declarations]\r\n         int64x2_t pairwiseAdded = vpaddlq_s32(dotprod_32x4);\r\n                                                           ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:30:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:19,\r\n                 from tensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:28:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:6451:58: note: declared here\r\n _NEON2SSE_INLINE _NEON2SSE_PERFORMANCE_WARNING(int64x2_t vpaddlq_s32(int32x4_t a), _NEON2SSE_REASON_SLOW_SERIAL) // VPADDL.S32 q0,q0\r\n                                                          ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:76:109: note: in definition of macro '_NEON2SSE_PERFORMANCE_WARNING'\r\n     #define _NEON2SSE_PERFORMANCE_WARNING(function, explanation)   __attribute__((deprecated(explanation))) function\r\n                                                                                                             ^~~~~~~~\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc: At global scope:\r\ntensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc:70:6: warning: 'bool tflite::tensor_utils::{anonymous}::HasSdotInstruction()' defined but not used [-Wunused-function]\r\n bool HasSdotInstruction() {\r\n      ^~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/lite/kernels/cpu_backend_context.cc:\r\nIn file included from external/gemmlowp/public/../internal/../fixedpoint/fixedpoint.h:895:0,\r\n                 from external/gemmlowp/public/../internal/output.h:27,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from tensorflow/lite/kernels/cpu_backend_context.cc:16:\r\nexternal/gemmlowp/public/../internal/../fixedpoint/./fixedpoint_sse.h:43:39: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n struct FixedPointRawTypeTraits<__m128i> {\r\n                                       ^\r\nIn file included from external/gemmlowp/public/../internal/simd_wrappers.h:664:0,\r\n                 from external/gemmlowp/public/../internal/output.h:29,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from tensorflow/lite/kernels/cpu_backend_context.cc:16:\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:31:72: warning: ignoring attributes on template argument 'gemmlowp::Int32x4 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 4, Int32x4, std::int32_t>::type;\r\n                                                                        ^\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:37:72: warning: ignoring attributes on template argument 'gemmlowp::Int16x8 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 8, Int16x8, std::int16_t>::type;\r\n                                                                        ^\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:45:52: warning: ignoring attributes on template argument 'gemmlowp::Uint8x16 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n                                 std::uint8_t>::type>::type;\r\n                                                    ^\r\nINFO: From Compiling tensorflow/lite/kernels/internal/tensor_utils.cc:\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:30:0,\r\n                 from tensorflow/lite/kernels/internal/tensor_utils.cc:17:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'void vst1q_lane_f32(float32_t*, float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9725:31: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *(ptr) =  *((float*)&ilane);\r\n                               ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'float32_t vgetq_lane_f32(float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:11964:22: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     return *(float*)&ilane;\r\n                      ^~~~~\r\nIn file included from external/gemmlowp/public/../internal/../fixedpoint/fixedpoint.h:895:0,\r\n                 from external/gemmlowp/public/../internal/output.h:27,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:18,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/neon_tensor_utils_impl.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.h:31,\r\n                 from tensorflow/lite/kernels/internal/tensor_utils.cc:20:\r\nexternal/gemmlowp/public/../internal/../fixedpoint/./fixedpoint_sse.h: At global scope:\r\nexternal/gemmlowp/public/../internal/../fixedpoint/./fixedpoint_sse.h:43:39: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n struct FixedPointRawTypeTraits<__m128i> {\r\n                                       ^\r\nIn file included from external/gemmlowp/public/../internal/simd_wrappers.h:664:0,\r\n                 from external/gemmlowp/public/../internal/output.h:29,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:18,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/neon_tensor_utils_impl.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.h:31,\r\n                 from tensorflow/lite/kernels/internal/tensor_utils.cc:20:\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:31:72: warning: ignoring attributes on template argument 'gemmlowp::Int32x4 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 4, Int32x4, std::int32_t>::type;\r\n                                                                        ^\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:37:72: warning: ignoring attributes on template argument 'gemmlowp::Int16x8 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 8, Int16x8, std::int16_t>::type;\r\n                                                                        ^\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:45:52: warning: ignoring attributes on template argument 'gemmlowp::Uint8x16 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n                                 std::uint8_t>::type>::type;\r\n                                                    ^\r\nERROR: /srv/projects/tf2/tfgit/tensorflow/lite/experimental/ruy/BUILD:297:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:pack' failed (Exit 1)\r\nIn file included from tensorflow/lite/experimental/ruy/pack_avx512.cc:16:0:\r\n./tensorflow/lite/experimental/ruy/pack.h:489:9: warning: multi-line comment [-Wcomment]\r\n #endif  // (RUY_PLATFORM(NEON_64) || RUY_PLATFORM(NEON_32)) && \\\r\n         ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc: In function 'void ruy::{anonymous}::HalfPackFloatAvx512(const float*, const float*, int, int, int, float*, float*)':\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:352:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi32(__m512i, __m512i)'\r\n         r0 = _mm512_unpacklo_epi32(t0, t1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:353:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi32(__m512i, __m512i)'\r\n         r2 = _mm512_unpackhi_epi32(t0, t1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:354:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi32(__m512i, __m512i)'\r\n         r1 = _mm512_unpacklo_epi32(t2, t3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:355:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi32(__m512i, __m512i)'\r\n         r3 = _mm512_unpackhi_epi32(t2, t3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:357:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi64(__m512i, __m512i)'\r\n         t0 = _mm512_unpacklo_epi64(r0, r1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:358:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi64(__m512i, __m512i)'\r\n         t2 = _mm512_unpackhi_epi64(r0, r1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:359:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi64(__m512i, __m512i)'\r\n         t1 = _mm512_unpacklo_epi64(r2, r3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:360:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi64(__m512i, __m512i)'\r\n         t3 = _mm512_unpackhi_epi64(r2, r3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:362:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r0 = _mm512_shuffle_i32x4(t0, t1, 0x88);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:363:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r1 = _mm512_shuffle_i32x4(t0, t1, 0xdd);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:364:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r2 = _mm512_shuffle_i32x4(t2, t3, 0x88);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:365:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r3 = _mm512_shuffle_i32x4(t2, t3, 0xdd);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:367:75: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(packed_ptr + 0 * 16, _mm512_castsi512_si256(r0));\r\n                                                                           ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:367:9: error: '_mm256_storeu_epi32' was not declared in this scope\r\n         _mm256_storeu_epi32(packed_ptr + 0 * 16, _mm512_castsi512_si256(r0));\r\n         ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:367:9: note: suggested alternative: '_mm256_store_epi64'\r\n         _mm256_storeu_epi32(packed_ptr + 0 * 16, _mm512_castsi512_si256(r0));\r\n         ^~~~~~~~~~~~~~~~~~~\r\n         _mm256_store_epi64\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:369:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r0, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:370:75: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(packed_ptr + 4 * 16, _mm512_castsi512_si256(r1));\r\n                                                                           ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:372:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r1, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:373:75: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(packed_ptr + 1 * 16, _mm512_castsi512_si256(r2));\r\n                                                                           ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:375:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r2, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:376:75: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(packed_ptr + 5 * 16, _mm512_castsi512_si256(r3));\r\n                                                                           ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:378:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r3, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:391:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi32(__m512i, __m512i)'\r\n         r0 = _mm512_unpacklo_epi32(t0, t1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:392:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi32(__m512i, __m512i)'\r\n         r2 = _mm512_unpackhi_epi32(t0, t1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:393:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi32(__m512i, __m512i)'\r\n         r1 = _mm512_unpacklo_epi32(t2, t3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:394:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi32(__m512i, __m512i)'\r\n         r3 = _mm512_unpackhi_epi32(t2, t3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:396:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi64(__m512i, __m512i)'\r\n         t0 = _mm512_unpacklo_epi64(r0, r1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:397:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi64(__m512i, __m512i)'\r\n         t2 = _mm512_unpackhi_epi64(r0, r1);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:398:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpacklo_epi64(__m512i, __m512i)'\r\n         t1 = _mm512_unpacklo_epi64(r2, r3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:399:42: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_unpackhi_epi64(__m512i, __m512i)'\r\n         t3 = _mm512_unpackhi_epi64(r2, r3);\r\n                                          ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:401:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r0 = _mm512_shuffle_i32x4(t0, t1, 0x88);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:402:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r1 = _mm512_shuffle_i32x4(t0, t1, 0xdd);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:403:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r2 = _mm512_shuffle_i32x4(t2, t3, 0x88);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:404:47: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_shuffle_i32x4(__m512i, __m512i, int)'\r\n         r3 = _mm512_shuffle_i32x4(t2, t3, 0xdd);\r\n                                               ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:406:77: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(trailing_buf + 0 * 16, _mm512_castsi512_si256(r0));\r\n                                                                             ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:406:9: error: '_mm256_storeu_epi32' was not declared in this scope\r\n         _mm256_storeu_epi32(trailing_buf + 0 * 16, _mm512_castsi512_si256(r0));\r\n         ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:406:9: note: suggested alternative: '_mm256_store_epi64'\r\n         _mm256_storeu_epi32(trailing_buf + 0 * 16, _mm512_castsi512_si256(r0));\r\n         ^~~~~~~~~~~~~~~~~~~\r\n         _mm256_store_epi64\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:408:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r0, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:409:77: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(trailing_buf + 4 * 16, _mm512_castsi512_si256(r1));\r\n                                                                             ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:411:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r1, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:412:77: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(trailing_buf + 1 * 16, _mm512_castsi512_si256(r2));\r\n                                                                             ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:414:60: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_extracti64x4_epi64(__m512i, int)'\r\n                             _mm512_extracti64x4_epi64(r2, 1));\r\n                                                            ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:415:77: error: cannot convert '__m512 {aka __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n         _mm256_storeu_epi32(trailing_buf + 5 * 16, _mm512_castsi512_si256(r3));\r\n                                                                             ^\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc: In function 'void ruy::Pack8bitAvx512(const int8_t*, int8_t, const int8_t*, int, int, int, int8_t*, int32_t*)':\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:469:3: error: 'memset' was not declared in this scope\r\n   memset(trailing_buf, 0, kTrailingBufSize * sizeof(std::int8_t));\r\n   ^~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:469:3: note: suggested alternative: 'Offset'\r\n   memset(trailing_buf, 0, kTrailingBufSize * sizeof(std::int8_t));\r\n   ^~~~~~\r\n   Offset\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:504:5: error: 'memcpy' was not declared in this scope\r\n     memcpy(packed_ptr + Layout::kCols * non_trailing_rows, trailing_buf,\r\n     ^~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:504:5: note: suggested alternative: '_m_empty'\r\n     memcpy(packed_ptr + Layout::kCols * non_trailing_rows, trailing_buf,\r\n     ^~~~~~\r\n     _m_empty\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc: In function 'void ruy::PackFloatAvx512(const float*, const float*, int, int, int, float*)':\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:520:5: error: 'memset' was not declared in this scope\r\n     memset(trailing_buf, 0, sizeof(trailing_buf));\r\n     ^~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:520:5: note: suggested alternative: 'Offset'\r\n     memset(trailing_buf, 0, sizeof(trailing_buf));\r\n     ^~~~~~\r\n     Offset\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:528:5: error: 'memcpy' was not declared in this scope\r\n     memcpy(packed_ptr + 16 * non_trailing_rows, trailing_buf,\r\n     ^~~~~~\r\ntensorflow/lite/experimental/ruy/pack_avx512.cc:528:5: note: suggested alternative: '_m_empty'\r\n     memcpy(packed_ptr + 16 * non_trailing_rows, trailing_buf,\r\n     ^~~~~~\r\n     _m_empty\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2730.030s, Critical Path: 87.13s\r\nINFO: 2445 processes: 2445 local.\r\nFAILED: Build did NOT complete successfully", "Here is the configure script I used and the bagel build command:\r\n\r\n$ ./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.26.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n/usr/lib/python3/dist-packages\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: Y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -march=native -Wno-sign-compare\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\n$ bazel build --config=opt --config=mkl --config=v2 //tensorflow/tools/pip_package:build_pip_package --incompatible_disallow_dict_plus=false\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=118\r\nINFO: Reading rc options for 'build' from /srv/projects/tf2/tfgit/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2\r\nINFO: Reading rc options for 'build' from /srv/projects/tf2/tfgit/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /srv/projects/tf2/tfgit/.bazelrc: --define=tf_api_version=2\r\nINFO: Found applicable config definition build:xla in file /srv/projects/tf2/tfgit/.tf_configure.bazelrc: --define with_xla_support=true\r\nINFO: Found applicable config definition build:opt in file /srv/projects/tf2/tfgit/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:mkl in file /srv/projects/tf2/tfgit/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 -c opt\r\nINFO: Found applicable config definition build:v2 in file /srv/projects/tf2/tfgit/.bazelrc: --define=tf_api_version=2\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\n\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (290 packages loaded, 26680 targets configured)", "I can not run a virtual environment. I installed r2.0 anyway to check it out. I get this message:\r\n\r\n2019-10-26 04:35:59.464054: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n\r\nSo I need to build from source.", "Uploading the log file here. \r\n[tf2_build_logs.102519.txt](https://github.com/tensorflow/tensorflow/files/3781731/tf2_build_logs.102519.txt)\r\n\r\nSorry for the long dump in the comments above. I needed to upgrade my browser. I'm very interested in a patch to fix the build. I can test it and report back. Thanks in advance.\r\n", "This was I think caused by mis-handling of the release. An interim fix (make a backup copy of the dir first) might be to copy tensorflow/lite/experimental/ruy from master and copy into the TF 2.0 release.", "Another temporary option is to edit\r\ntensorflow/lite/experimental/ruy/platform.h\r\n\r\nTo see something like\r\n\r\n// #if defined(AVX512F) && defined(AVX512DQ) && defined(AVX512CD) &&\r\ndefined(AVX512BW) && defined(AVX512VL)\r\n// #define RUY_DONOTUSEDIRECTLY_AVX512 1\r\n// #else\r\n#define RUY_DONOTUSEDIRECTLY_AVX512 0\r\n// #endif\r\n\r\nThe key thing being the macro definition to \"0\" to disable AVX512 within the Ruy library.", "I have modified tensorflow/lite/experimental/ruy/platform.h as you suggested above.\r\nThis resolves the build failure. I have deployed the TensorFlow r2.0 built from source.  The AVX2 AVX512F FMA instructions are now supported. Thank you for your help. I can wait for the r2.1 release. Can you comment on the consequences of this workaround for the build I have deployed?", "Should be fixed in r2.1", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33733\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33733\">No</a>\n"]}, {"number": 33732, "title": "[Intel MKL] Refactor MKL Eager from std::vector to std::hashmap for cleaner design", "body": "Refactoring the MKL Eager from std::vector to std::hash_map and improve performance along with a cleaner design.\r\n\r\nRelated to the PR: tensorflow/tensorflow#33540 (See comment section from @penpornk )\r\n\r\n\r\n", "comments": ["@penpornk: Related Refactor PR to #33540", "@penpornk All comments are addressed! and thank you."]}, {"number": 33731, "title": "Refactor {ParallelMap, ParallelInterleave, SparseTensorSlice, Shuffle}DatasetOpTest", "body": "This PR refactors `ParallelMapDatasetOpTest`, `ParallelInterleaveDatasetOpTest`, `SparseTensorSliceDatasetOpTest`, and `ShuffleDatasetOpTest`.", "comments": ["@aaudiber Thanks for your review! `compare_order` is added to `GetNextTestCase` and `IteratorSaveAndRestoreTestCase`. Could you please take another look at the change (https://github.com/tensorflow/tensorflow/pull/33731/commits/f80f94bdc2603e3444a889330aa4d5caff418e79)?", "Thanks, @aaudiber! The default value `bool compare_order = true` is added. The change is amended to the last commit (https://github.com/tensorflow/tensorflow/pull/33731/commits/4491d4da1667f66edf92986fcaecd09c311e0e06). Please take a look!", "@feihugis some internal tests failed due to memory leaks. I think the problem is that the `DatasetTypeString` and `DatasetNodeNade` tests call `Initialize` multiple times in the same test, which seems to leak memory. We need to either support calling `Initialize` multiple times, or parameterize the tests differently.\r\n\r\n```\r\nE1029 13:18:34.963108    7068 heap-profile-table.cc:486] RAW: Leak of 104 bytes in 1 objects allocated from:\r\n\t@ 0x56307e71590a tensorflow::data::ShuffleDatasetOp::MakeDataset()\r\n\t@ 0x7f613e31f12a tensorflow::data::UnaryDatasetOpKernel::MakeDataset()\r\n\t@ 0x7f613e31ee60 tensorflow::data::DatasetOpKernel::Compute()\r\n\t@ 0x7f6142bec036 tensorflow::data::DatasetOpsTestBaseV2::RunDatasetOp()\r\n\t@ 0x7f6142beb357 tensorflow::data::DatasetOpsTestBaseV2::Initialize()\r\n\t@ 0x7f6142c1ddb9 tensorflow::data::(anonymous namespace)::ShuffleDatasetOpTest_DatasetNodeName_Test::TestBody()\r\n\t@ 0x7f614280350a testing::Test::Run()\r\n\t@ 0x7f6142804690 testing::TestInfo::Run()\r\n\t@ 0x7f6142805087 testing::TestSuite::Run()\r\n\t@ 0x7f6142814947 testing::internal::UnitTestImpl::RunAllTests()\r\n\t@ 0x7f6142813f55 testing::UnitTest::Run()\r\n\t@ 0x7f6142a48c0e main\r\n\t@ 0x7f613617dbbd __libc_start_main\r\n\t@ 0x56307e715469 ../sysdeps/x86_64/start.S:121 _start\r\n\r\nE1029 13:18:34.963281    7068 heap-profile-table.cc:486] RAW: Leak of 104 bytes in 1 objects allocated from:\r\n\t@ 0x56307e71590a tensorflow::data::ShuffleDatasetOp::MakeDataset()\r\n\t@ 0x7f613e31f12a tensorflow::data::UnaryDatasetOpKernel::MakeDataset()\r\n\t@ 0x7f613e31ee60 tensorflow::data::DatasetOpKernel::Compute()\r\n\t@ 0x7f6142bec036 tensorflow::data::DatasetOpsTestBaseV2::RunDatasetOp()\r\n\t@ 0x7f6142beb357 tensorflow::data::DatasetOpsTestBaseV2::Initialize()\r\n\t@ 0x7f6142c1e279 tensorflow::data::(anonymous namespace)::ShuffleDatasetOpTest_DatasetTypeString_Test::TestBody()\r\n\t@ 0x7f614280350a testing::Test::Run()\r\n\t@ 0x7f6142804690 testing::TestInfo::Run()\r\n\t@ 0x7f6142805087 testing::TestSuite::Run()\r\n\t@ 0x7f6142814947 testing::internal::UnitTestImpl::RunAllTests()\r\n\t@ 0x7f6142813f55 testing::UnitTest::Run()\r\n\t@ 0x7f6142a48c0e main\r\n\t@ 0x7f613617dbbd __libc_start_main\r\n\t@ 0x56307e715469 ../sysdeps/x86_64/start.S:121 _start\r\n\r\nE1029 13:18:34.964669    7068 heap-profile-table.cc:486] RAW: Leak of 88 bytes in 1 objects allocated from:\r\n\t@ 0x56307e7553af tensorflow::data::RangeDatasetOp::MakeDataset()\r\n\t@ 0x7f613e31ee60 tensorflow::data::DatasetOpKernel::Compute()\r\n\t@ 0x7f6142bec7ed tensorflow::data::DatasetOpsTestBaseV2::MakeDatasetTensor()\r\n\t@ 0x7f6142beb851 tensorflow::data::DatasetOpsTestBaseV2::RunDatasetOp()\r\n\t@ 0x7f6142beb357 tensorflow::data::DatasetOpsTestBaseV2::Initialize()\r\n\t@ 0x7f6142c1ddb9 tensorflow::data::(anonymous namespace)::ShuffleDatasetOpTest_DatasetNodeName_Test::TestBody()\r\n\t@ 0x7f614280350a testing::Test::Run()\r\n\t@ 0x7f6142804690 testing::TestInfo::Run()\r\n\t@ 0x7f6142805087 testing::TestSuite::Run()\r\n\t@ 0x7f6142814947 testing::internal::UnitTestImpl::RunAllTests()\r\n\t@ 0x7f6142813f55 testing::UnitTest::Run()\r\n\t@ 0x7f6142a48c0e main\r\n\t@ 0x7f613617dbbd __libc_start_main\r\n\t@ 0x56307e715469 ../sysdeps/x86_64/start.S:121 _start\r\n\r\nE1029 13:18:34.964695    7068 heap-profile-table.cc:486] RAW: Leak of 88 bytes in 1 objects allocated from:\r\n\t@ 0x56307e7553af tensorflow::data::RangeDatasetOp::MakeDataset()\r\n\t@ 0x7f613e31ee60 tensorflow::data::DatasetOpKernel::Compute()\r\n\t@ 0x7f6142bec7ed tensorflow::data::DatasetOpsTestBaseV2::MakeDatasetTensor()\r\n\t@ 0x7f6142beb851 tensorflow::data::DatasetOpsTestBaseV2::RunDatasetOp()\r\n\t@ 0x7f6142beb357 tensorflow::data::DatasetOpsTestBaseV2::Initialize()\r\n\t@ 0x7f6142c1e279 tensorflow::data::(anonymous namespace)::ShuffleDatasetOpTest_DatasetTypeString_Test::TestBody()\r\n\t@ 0x7f614280350a testing::Test::Run()\r\n\t@ 0x7f6142804690 testing::TestInfo::Run()\r\n\t@ 0x7f6142805087 testing::TestSuite::Run()\r\n\t@ 0x7f6142814947 testing::internal::UnitTestImpl::RunAllTests()\r\n\t@ 0x7f6142813f55 testing::UnitTest::Run()\r\n\t@ 0x7f6142a48c0e main\r\n\t@ 0x7f613617dbbd __libc_start_main\r\n\t@ 0x56307e715469 ../sysdeps/x86_64/start.S:121 _start\r\n```", "> @feihugis some internal tests failed due to memory leaks. I think the problem is that the `DatasetTypeString` and `DatasetNodeNade` tests call `Initialize` multiple times in the same test, which seems to leak memory. We need to either support calling `Initialize` multiple times, or parameterize the tests differently.\r\n\r\n@aaudiber Thanks very much for helping check the internal tests and suggestions! I tried to support the multiple times of calling `Initialize()` via this commit(https://github.com/tensorflow/tensorflow/pull/33731/commits/b1f27526a01ad0b93f0028b6ad77c5483eab9dcb), but I'm not sure if it is fixed. Could you please take a look and trigger the internal tests?\r\n\r\n", "@aaudiber The comments are addressed here (https://github.com/tensorflow/tensorflow/pull/33731/commits/d15bf95fc305c409902149f97f884c8fdcfa5a8f). Could you please take a look?"]}, {"number": 33730, "title": "TypeError: expected str, bytes or os.PathLike object, not NoneType", "body": "\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 45, in <module>\r\n    from . _api.v2 import compat\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/__init__.py\", line 23, in <module>\r\n    from . import v1\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py\", line 666, in <module>\r\n    [_module_util.get_parent_dir(estimator)] + _current_module.__path__)\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tools/module_util.py\", line 24, in get_parent_dir\r\n    return os.path.abspath(os.path.join(os.path.dirname(module.__file__), \"..\"))\r\n  File \"/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/posixpath.py\", line 156, in dirname\r\n    p = os.fspath(p)\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType", "comments": ["Can you please provide more context to the issue by filling the template thats being provided [here](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!", "I have this same issue on Ubuntu 19.04. Only happens with venv install. Works with system Python.", "ok, i removed the current venv and created new venv. It is working now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33730\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33730\">No</a>\n"]}, {"number": 33729, "title": "TypeError: An op outside of the function building code is being passed a Graph tensor", "body": "**System information**\r\n- Have I written custom code: Yes.\r\n- OS Platform and Distribution: Mac OS Catalina: 10.15 (19A602)\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.4\r\n- GPU model and memory: Intel Iris Pro 1536 MB\r\n\r\n**Describe the current behavior**\r\n\r\nI am getting the error\r\n\r\n> tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32>]\r\n\r\nAfter having gotten the exception\r\n\r\n> TypeError: An op outside of the function building code is being passed a Graph tensor\r\n\r\nSee the detailed traceback below.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\n\r\n# tf.compat.v1.disable_eager_execution()\r\n\r\ndef get_bayesian_model(input_shape=None, num_classes=10):\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Input(shape=input_shape))\r\n    model.add(tfp.layers.Convolution2DFlipout(6, kernel_size=5, padding=\"SAME\", activation=tf.nn.relu))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add(tfp.layers.DenseFlipout(84, activation=tf.nn.relu))\r\n    model.add(tfp.layers.DenseFlipout(num_classes))\r\n    return model\r\n\r\ndef get_mnist_data(normalize=True):\r\n    img_rows, img_cols = 28, 28\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\n    if tf.keras.backend.image_data_format() == 'channels_first':\r\n        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n        input_shape = (1, img_rows, img_cols)\r\n    else:\r\n        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n        input_shape = (img_rows, img_cols, 1)\r\n\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n\r\n    if normalize:\r\n        x_train /= 255\r\n        x_test /= 255\r\n\r\n    return x_train, y_train, x_test, y_test, input_shape\r\n\r\n\r\ndef train():\r\n    # Hyper-parameters.\r\n    batch_size = 128\r\n    num_classes = 10\r\n    epochs = 1\r\n\r\n    # Get the training data.\r\n    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()\r\n\r\n    # Get the model.\r\n    model = get_bayesian_model(input_shape=input_shape, num_classes=num_classes)\r\n\r\n    # Prepare the model for training.\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\",\r\n                  metrics=['accuracy'])\r\n\r\n    # Train the model.\r\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\r\n    model.evaluate(x_test, y_test, verbose=0)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    train()\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\nWARNING:tensorflow:From /Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:104: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.add_weight` method instead.\r\n2019-10-25 20:38:32.504579: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-25 20:38:32.517426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe25e59f290 executing computations on platform Host. Devices:\r\n2019-10-25 20:38:32.517438: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nTrain on 60000 samples\r\nTraceback (most recent call last):\r\n  128/60000 [..............................] - ETA: 7:32  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\r\n    num_outputs)\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: conv2d_flipout/divergence_kernel:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/nbro/Desktop/my_project/my_module.py\", line 63, in <module>\r\n    train()\r\n  File \"/Users/nbro/Desktop/my_project/my_module.py\", line 58, in train\r\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 520, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 75, in quick_execute\r\n    \"tensors, but found {}\".format(keras_symbolic_tensors))\r\ntensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32>]\r\n```\r\n\r\nThe problem is apparently related to the layer `tfp.layers.Convolution2DFlipout`. I know that if I use `tf.compat.v1.disable_eager_execution()` after having imported TensorFlow, I do not get the mentioned error anymore, but I would like to use TensorFlow's eager execution, avoid sessions or placeholders.\r\n\r\nI opened the same issue here: https://github.com/tensorflow/probability/issues/620.", "comments": ["@nbro \r\nI tried reproducing the issue. However i am seeing different error`ValueError: No gradients provided for any variable: ['conv2d_flipout/kernel_posterior_loc:0', 'conv2d_flipout/kernel_posterior_untransformed_scale:0', 'conv2d_flipout/bias_posterior_loc:0', 'dense_flipout/kernel_posterior_loc:0', 'dense_flipout/kernel_posterior_untransformed_scale:0', 'dense_flipout/bias_posterior_loc:0', 'dense_flipout_1/kernel_posterior_loc:0', 'dense_flipout_1/kernel_posterior_untransformed_scale:0', 'dense_flipout_1/bias_posterior_loc:0'].`Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/1665e31f72a3207226543fb8d3589723/untitled313.ipynb).Thanks!", "@ravikyram If I run your notebook, yes, I get the error you're describing. However, locally, with the specifications I mentioned above, I still get the error I mentioned above.\r\n\r\nPlease, to reproduce my error, use the following dependencies\r\n\r\n```\r\nPackage                Version\r\n---------------------- -------\r\nabsl-py                0.8.1  \r\nastor                  0.8.0  \r\ncloudpickle            1.1.1  \r\ndecorator              4.4.1  \r\ngast                   0.2.2  \r\ngoogle-pasta           0.1.7  \r\ngrpcio                 1.24.3 \r\nh5py                   2.10.0 \r\nKeras-Applications     1.0.8  \r\nKeras-Preprocessing    1.1.0  \r\nMarkdown               3.1.1  \r\nnumpy                  1.17.3 \r\nopt-einsum             3.1.0  \r\npip                    10.0.1 \r\nprotobuf               3.10.0 \r\nsetuptools             39.1.0 \r\nsix                    1.12.0 \r\ntensorboard            2.0.0  \r\ntensorflow             2.0.0  \r\ntensorflow-estimator   2.0.1  \r\ntensorflow-probability 0.8.0  \r\ntermcolor              1.1.0  \r\nWerkzeug               0.16.0 \r\nwheel                  0.33.6 \r\nwrapt                  1.11.2 \r\n```\r\n\r\nI only had to install TensorFlow 2 (without GPU support, but the fact you're getting a different error in the notebook is not due to the fact you are installing TF with GPU support, given that I tried to install TensorFlow without GPU in the notebook, and I am still getting your error) and TensorFlow Probability with the following `requirements.txt` file inside an empty virtual environment (which contained only the usual setuptools and wheel packages)\r\n\r\n```\r\ntensorflow==2.0.0\r\ntensorflow-probability\r\n```\r\n\r\nThe other dependencies you see above have been installed recursively. You should also try to use Python 3.7 (given that I am using it, and I don't have Python 3.6 installed, which is the Python version used in the notebook), but I don't think this is the problem. Furthermore, you should try to use Mac OS X (with the specific version above), but I also don't think this is the problem.", "If I set the parameter `experimental_run_tf_function` to `False` when calling `model.compile`, that is, `model.compile(..., experimental_run_tf_function=False)`, I do not get this error anymore.  There's a very related (if not the same) issue: https://github.com/tensorflow/probability/issues/519, which I've found *after* having discovered that I could set `experimental_run_tf_function=False` to avoid the error. There's also this related issue https://github.com/tensorflow/addons/issues/428.\r\n\r\n**What is `experimental_run_tf_function` exactly supposed to do? Why does `experimental_run_tf_function=False` solve this issue?**  \r\n\r\nThe answer to this question is _partially_ given in https://github.com/tensorflow/probability/issues/519#issuecomment-527337880, but I would appreciate a detailed description of this argument and why it solves this issue.\r\n\r\nThis issue can also be avoided by setting `kernel_divergence_fn` of the `Convolution2DFlipout` layer to `None`, but this may create an undesirable effect. In fact, this sets the divergence between the posterior and prior to `None` and does not add anything to the `losses` field. \r\n\r\n`DenseFlipout` does not seem to cause this issue, but only probabilistic convolution layers.", "I think that this issue is related to the DEFAULT value of the parameter `kernel_divergence_fn` of `tfp.layers.Convolution2DFlipout`. In fact, if you set it to `None`or you create a custom function that returns the KL divergence, then this issue doesn't occur anymore, even without `experimental_run_tf_function=False`. \r\n\r\nAs far as I understand, `experimental_run_tf_function=False` would go back to the previous way of TensorFlow of handling computation (i.e. using multiple paths). [Here's the relevant code for TF 2.1](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py), which I haven't yet investigated. Honestly, I still don't get how and why this affects this particular issue with `tfp.layers.Convolution2DFlipout` (but e.g. not the other Bayesian layers).\r\n\r\nIf I set `run_eagerly=True` in the `compile` method before calling `fit` (and without using `experimental_run_tf_function=False`), I get another error\r\n\r\n> NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array.\r\n\r\nHowever, if I set `run_eagerly=True` with the following version of TF and TFP (which are currently the nightly versions)\r\n\r\n```\r\ntf-nightly             2.2.0.dev20200422  \r\ntfp-nightly            0.11.0.dev20200422 \r\n```\r\n\r\nI don't get the error above, but the loss is always 0.0, although the same loss is (apparently) correctly displayed as a matric.", "Can this be closed since the error is not seen in tf-nightly version? Thanks!", "@ymodak I wouldn't close this until the new stable version is released.", "TF 2.2 final version has released and this works successfully. Please give it a try. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33729\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33729\">No</a>\n"]}, {"number": 33728, "title": "[INTEL MKL] Fixing inter op default setting in intel.", "body": "Removing openmp calls in mkl default inter op settings due to side effects.", "comments": []}, {"number": 33727, "title": "Disabling eager execution while training ~90 layers of BatchNormalization exhausts RAM", "body": "Disabling eager execution while training a network with a number of BatchNormalization will take unreasonable amount of RAM before training happens. It might be related that BatchNormalization lacks an `_XlaCompiler` attribute.\r\nI find that I am in an awkward state: my script is a long-running script, and if I enable eager execution, GPU RAM will be used up due to some unknown memory leakage + my script will run ULTRA SLOWLY due to unbatched nature of queries of model.predict (GPU usage 30% in disabling eager execution mode v.s. 9% in enabling eager execution mode); if I disable eager execution, then this bug takes up my CPU RAM. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): docker: tensorflow/tensorflow latest-gpu-py3       f7932d1761bd\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nWriting ~90 layers of BatchNormalization takes around 8G RAM before training when disabling eager mode, even with matrix dimension small. Like 100M per BatchNormalization in python3.6.8, regardless of dimensions.\r\nEDIT: I did some experiment and found that the memory usage is approximately linear to the number of `BatchNormalization`s.\r\n\r\n**Describe the expected behavior**\r\nWriting ~90 layers of BatchNormalization should take smaller amount of RAM.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\nimport numpy as np\r\nDISABLE_EAGER = 1\r\nresnet_depth = 96\r\n\r\nif DISABLE_EAGER:\r\n    disable_eager_execution()\r\nif True:\r\n    from tensorflow.keras.optimizers import *\r\n    from tensorflow.keras.layers import *\r\n    from tensorflow.keras.models import *\r\n\r\n\r\ndef init():\r\n    # game params\r\n    board_x, board_y = 3, 3\r\n    action_size = 10\r\n    depth_dim = 2\r\n\r\n    input_boards = Input(\r\n        shape=(board_x, board_y, depth_dim))\r\n    num_chan = 4\r\n    h_conv1 = Activation('relu')(BatchNormalization(axis=3)(\r\n        Conv2D(num_chan, 1, padding='same', use_bias=False)(input_boards)))\r\n    for i in range(resnet_depth):\r\n        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(\r\n            Conv2D(num_chan, 1, padding='same', use_bias=False)(h_conv1)))\r\n    hf = Flatten()(h_conv1)\r\n    s_fc1 = Dropout(0.3)(Activation('relu')(BatchNormalization(axis=1)(\r\n        Dense(16, use_bias=False)(hf))))\r\n    pi = Dense(action_size, activation='softmax', name='pi')(\r\n        s_fc1)\r\n\r\n    model = Model(inputs=input_boards, outputs=pi)\r\n    model.compile(\r\n        loss=['categorical_crossentropy'], optimizer=Adam(0.001))\r\n    return model\r\n\r\n\r\nm = init()\r\nprint('inited model')\r\nm.fit(x=np.zeros((1, 3, 3, 2)), y=np.zeros((1, 10)))\r\n\r\n```\r\n\r\n**Other info / logs**\r\nNone\r\n", "comments": ["When tried running the given code for TF-2.0, it consumed more RM as per @ThinerDAS  explanation . \r\nKindly find the [gist](https://colab.sandbox.google.com/gist/oanush/2047078b9ef3140b7d38a1f2148b278b/33727.ipynb) of collab.", "@ThinerDAS Is this still an issue? I tried with `tf-nightly` and I don't see any difference between graph mode and eager mode in RAM usage. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/414870a8731cd8139ad0f9c62786ad69/33727.ipynb).\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I am closing this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33727\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33727\">No</a>\n"]}, {"number": 33726, "title": "Update documentation from `tf.contrib.checkpoint.CheckpointManager` to `tf.train.CheckpointManager`", "body": "Documentation was still using the old naming for the `CheckpointManager`.\r\n\r\nI updated the occurrences of `tf.contrib.checkpoint.CheckpointManager` with `tf.train.CheckpointManager`.", "comments": []}, {"number": 33725, "title": "`fit_generator` (tf.keras.utils.Sequence) is not supported for models compiled with tf.distribute.Strategy", "body": "**System information**\r\n- OS Platform and Distribution: Arch Linux (Linux-5.3.7-arch1-1-ARCH-x86_64-with-arch)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version:  2.0.0\r\n- Keras version: 2.2.4-tf\r\n- Python version: 3.7.4\r\n- GCC/Compiler version: 9.2.0\r\n- CUDA/cuDNN version: cuda 10.1.243-1 / cudnn 7.6.4.38-1\r\n- GPU model and memory: 2x GeForce GTX 1080 Ti 11GB\r\n\r\n**Describe the current behavior**\r\n- Model.fit_generator() invoked with generator dervied from tf.keras.utils.Sequence\r\n- execution fails with NotImplementedError\r\n\r\n```\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n         model = OCRNet.build(train_gen.output_size, img_w, img_h, max_text_len)\r\n         adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\r\n         model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam, metrics=['accuracy'])\r\nhistory = model.fit_generator(\r\n         generator=train_gen,\r\n         epochs=epochs,\r\n         validation_data=val_gen,\r\n         use_multiprocessing=True,\r\n         workers=6,\r\n         callbacks=callbacks)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> Traceback (most recent call last):\r\n>   File \"src/models/train.py\", line 119, in <module>\r\n>     main()\r\n>   File \"src/models/train.py\", line 112, in main\r\n>     fit(model, train_gen, val_gen, epochs, callbacks)\r\n>   File \"src/models/train.py\", line 39, in fit\r\n>     callbacks=callbacks)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1277, in fit_generator\r\n>     raise NotImplementedError('`fit_generator` is not supported for '\r\n> NotImplementedError: `fit_generator` is not supported for models compiled with tf.distribute.Strategy.", "comments": ["I replaced model.fit_generator() by model.fit() (fit_generator will be deprecated in next releases).\r\nBut I get a different error:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"src/models/train.py\", line 116, in <module>\r\n>     main()\r\n>   File \"src/models/train.py\", line 109, in main\r\n>     callbacks=callbacks)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 224, in fit\r\n>     distribution_strategy=strategy)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 547, in _process_training_inputs\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 606, in _process_inputs\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\", line 606, in __init__\r\n>     nested_dtypes = nest.map_structure(lambda t: t.dtype, peek)\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 535, in map_structure\r\n>     structure[0], [func(*x) for x in entries],\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 535, in <listcomp>\r\n>     structure[0], [func(*x) for x in entries],\r\n>   File \"/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\", line 606, in <lambda>\r\n>     nested_dtypes = nest.map_structure(lambda t: t.dtype, peek)\r\n> AttributeError: 'str' object has no attribute 'dtype", "removed string type from generator output - code works now", "fit_generator\u5c06\u5728\u4ee5\u540e\u7684\u7248\u672c\u4e2d\u5f03\u7528,\u4e0d\u4f1a\u5427\uff0c\u8fd9\u4e2aAPI\u6211\u8ba4\u4e3a\u5f88\u597d\u7528\u7684\r\n\u8fd9\u4e2a\u9519\u8bef\u8981\u600e\u4e48\u89e3\u51b3\u5462\uff1f\u5982\u679c\u6570\u636e\u5f88\u5927\uff0c\u4e0d\u80fd\u4e00\u6b21\u6027\u5b58\u5230\u5185\u5b58\u4e2d\r\n\u4f7f\u7528tf.data\u6765\u5b9e\u73b0\u5417?", "> I replaced model.fit_generator() by model.fit() (fit_generator will be deprecated in next releases).\r\n\r\nWhere did you hear this?\r\n\r\n", "\u6211\u4e5f\u8ba4\u4e3afit_generator will be deprecated in the future\r\n\u73b0\u5728fit\u4e5f\u652f\u6301\u751f\u6210\u5668\uff0c\u591aGPU\u7684\u8bdd\uff0c\u76f4\u63a5\u7528fit\u5c31\u53ef\u4ee5"]}, {"number": 33724, "title": "Infinite loop with generators wrapping a dataset in tf.function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `v2.0.0-rc2-26-g64c3d38 2.0.0`\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0 / 7.6.3\r\n- GPU model and memory: TITAN Xp, 12196MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nMy use case was to use `tqdm` to track progress on a training loop over a `tf.data.Dataset`:\r\n\r\n```python\r\n@tf.function\r\ndef train_one_epoch(model, dataset):\r\n    for x in tqdm(dataset):\r\n        train_step(model, x)\r\n```\r\n\r\nHowever, when the function `train_one_epoch` is wrapped in a `tf.function`, the AutoGraph is stuck in an infinite loop. \r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior would be that using `tf.function` results in the same behavior than the eager mode.\r\n\r\nThe current issue is that AutoGraph doesn't recognize `tqdm(dataset)` as a `tf.data.Dataset` (which is normal). However, iterating infinitely over the dataset in AutoGraph is weird and shouldn't happen. Maybe it should give an exception.\r\n\r\nMaybe the easiest fix would be to prevent `dataset.__iter__` being called inside `tf.function` if it is not in a loop.  \r\nSo `for x in dataset` would be fine, but `for x in tqdm(dataset)` wouldn't.\r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nclass Iterable():\r\n    def __init__(self, iterable):\r\n        self.iterable = iterable\r\n\r\n    def __iter__(self):\r\n        for obj in self.iterable:\r\n            yield obj\r\n\r\n@tf.function\r\ndef f(dataset):\r\n    for x in Iterable(dataset):\r\n        print(x)\r\n\r\ndataset = tf.data.Dataset.range(5)\r\nf(dataset)\r\n```\r\n\r\nThe minimal `Iterable` class can be replaced by `tqdm` (`from tqdm import tqdm`), and this should yield the same results.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nWithout the `@tf.function`, the wrapped dataset `Iterable(dataset)` is iterated over in eager mode:\r\n```\r\ntf.Tensor(0, shape=(), dtype=int64)\r\ntf.Tensor(1, shape=(), dtype=int64)\r\ntf.Tensor(2, shape=(), dtype=int64)\r\ntf.Tensor(3, shape=(), dtype=int64)\r\ntf.Tensor(4, shape=(), dtype=int64)\r\n```\r\n\r\nWith the `@tf.function`, the AutoGraph mode doesn't recognize the wrapped `Iterable(dataset)` as a `tf.data.Dataset`, so it tries to iterate over it in python to trace the graph. However, it looks like the `Iterable(dataset).__iter__` infinitely yields a next element named `IteratorGetNext`.\r\n\r\nThis results in an infinite iteration over the dataset:\r\n```\r\nTensor(\"IteratorGetNext:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_1:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_2:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_3:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_4:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_5:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_6:0\", shape=(), dtype=int64)\r\nTensor(\"IteratorGetNext_7:0\", shape=(), dtype=int64)\r\n...\r\n```", "comments": ["Indeed, AutoGraph does not recognize `Iterator` or the generators executed by `tqdm`. I'll explain in more detail below, but in general the objects are not recognized because they are not subclasses of a dataset or a dataset iterator.\r\n\r\nAutoGraph only transforms objects of types it recognizes - everything else is executed in Python, at function tracing time. For this reason, when running the code above, it's as if you ran it without AutoGraph (try executing `@tf.function(autograph=False)`, it should behave identically). To better understand this, have a look at the [dispatch logic for `for` loops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/operators/control_flow.py#L331\r\n). Since `Iterator` is not an instance of any of the classes listed there, AutoGraph reverts to running the for loop in Python. In Python, it will cycle infinitely because the `Tensor` objects that the hidden `Dataset` iterator returns evaluate to True. `next(iter(Dataset))` never returns `StopIteration` in graph mode - it can't, because it doesn't know how much data there is at graph construction.\r\n\r\nYou might wonder why AutoGraph doesn't detect that the for loop inside `Iterator` which does use a Dataset. The answer is because AutoGraph doesn't touch generators, however [the warning it generates is silenced by default](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/core/unsupported_features_checker.py#L40). I think we'll need to make that warning more obvious.\r\n\r\nNow, AutoGraph could detect that a `for` loop is trying to iterate over a generator and disallow it in graph mode. However, that could break legitimate uses of generators (e.g. such as those used by Keras), but again, it looks like a warning would be useful.\r\n\r\nSeparately from all that, `tqdm` itself contains console output logic and other operations that are highly dependent on the Python runtime and which are not very compatible with TF graphs. So it would be tricky to run in graph mode regardless (though it could be possible to create a more graph-friendly version). When running training loops inside `tf.function`, you can currently only use summaries and `tf.print` and tensorboard to monitor the training progress.\r\n\r\nI think adding a graph-compatible `tqdm` (one that uses TF Iterators and `tf.print`) would be a useful API, although we probably won't have the chance to build one soon (it would be a welcome contribution though).", "There is now a verification in autograph that outputs a warning in situations such as this. We could add a verification that looks specifically for tqdm, but that won't work work the custom generator in the OP so it would be of limited help.\r\n\r\nHere is an alternative that might be useful for adding a progress bar to a dataset - it modifies a dataset to print tqdm messages whenever it is being iterated, using tf.py_function:\r\n\r\n```\r\ndef tf_tqdm(ds):\r\n\r\n  # Suppress printing the initial status message - it creates extra newlines, for some reason.\r\n  bar = tqdm.tqdm(file=io.StringIO())\r\n\r\n  def advance_tqdm(e):\r\n    def fn():\r\n      bar.update(1)\r\n      # Print the status update manually.\r\n      print('\\r', end='')\r\n      print(repr(bar), end='')\r\n    tf.py_function(fn, [], [])\r\n    return e\r\n\r\n  return ds.map(advance_tqdm)\r\n\r\n\r\n@tf.function\r\ndef f(ds):\r\n  for x in tf_tqdm(ds):\r\n    pass\r\n\r\nds = tf.data.Dataset.from_tensor_slices(tf.range(3))\r\nf(ds)\r\n```\r\n\r\nAnother similar alternative is to use `Dataset.from_generator` and supply it with a custom generator that itself includes tqdm. This will work whenever you are constructing the dataset from a Python object (it will not work when using built-in datasets like TFRecordDataset, though):\r\n\r\n```\r\ndata = tf.range(3)\r\n\r\ndef f():\r\n  bar = tqdm.tqdm(file=io.StringIO())\r\n  for i in data:\r\n    bar.update(1)\r\n    # Print the status update manually.\r\n    print('\\r', end='')\r\n    print(repr(bar), end='')\r\n    yield i\r\n\r\nds = tf.data.Dataset.from_generator(f, tf.int32)\r\n\r\n\r\n@tf.function\r\ndef f():\r\n  for x in ds:\r\n    pass\r\n\r\nf()\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33724\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33724\">No</a>\n"]}, {"number": 33723, "title": "Training loop freezes and then stops when try to run Cycle-GAN on multi-GPU system on Google GCP using 'tf.distribute.MirroredStrategy()' .", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NaN\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source): NaN\r\n- GCC/Compiler version (if compiling from source): NaN\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: 4 Nvidia Tesla K80's of 11GB each\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTraining loop stops after few steps in the first epoch itself.\r\n**Describe the expected behavior**\r\nTraining loop should run smoothly.\r\n\r\n**Other info / logs**\r\nThe link below contains a zip file in which the python scripts which I used to train this model on Multi GPU using 'tf.distribute.MirroredStrategy()' is stored.\r\n[The python scripts can be found here](https://drive.google.com/file/d/17TBNfs1h0Lnolq5ZaomqE9pTzdoGjEWb/view?usp=sharing)\r\n\r\n> Running 'download.py' will download the dataset that I used.\r\n\r\n> 'model.py' contains code for the architecture of the generator and the discriminator that  I used for training this Cycle-GAN\r\n\r\n> 'utils.py' contains code that I used for preprocessing the images \r\n\r\n> 'main.py' contains the code in which I used 'tf.distribute.MirroredStrategy()' for multi-GPU training but it stops after few steps in the first epoch.", "comments": ["Please provide a minimal and hermetic repro of the issue, rather than the full model code.\r\n\r\nNothe that you can also use the virtual device configuration described in https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_virtual_device_configuration to reproduce multi-device mirrored strategy (in this case 2 CPU) in colab.", "Hello gaurav-singh1998, have you verified that it works without tf.distribute.MirroredStrategy()?", "closing due to inactiveness, please re-open if it's still an issue : )"]}, {"number": 33722, "title": "Tensorflow 2.0 error when used via pyinstaller build - ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nThis has happened after upgrade to Tensorflow 2.0 . \r\n\r\nOn executing the EXE file generated by Pyinstaller for Tensorflow 2.0, we get the following error:\r\n\r\n'ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python'\r\n\r\nThe scripts work okay in PyCharm or Jupyter. The same version of scripts when run under Tensorflow 1.x execute correctly\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1.  upgraded tensorflow to 2.0\r\n2. Adjusted python code to accommodate module dependence from Keras to tf.keras\r\n3. Build exe --onefile via pyinstaller\r\n4. on execution of exe get the following error \r\n\"ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python' \"\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@anilkdas ,\r\nCan you please refer this [link](https://stackoverflow.com/questions/35953210/error-running-basic-tensorflow-example) of similar issue ?Thanks!", "@anilkdas ,\r\nAny update on the issue ?Thanks!", "There are a couple of solutions proposed [here](https://github.com/pyinstaller/pyinstaller/issues/4400#issuecomment-550905592)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33722\">No</a>\n", "i am getting below error. Can anyone please help me on this\r\n\r\nimport tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\a658371\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\a658371\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\a658371\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\a658371\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\a658371\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\a658371\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\nImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python' (C:\\Users\\a658371\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)"]}, {"number": 33721, "title": "CancelledError:  [_Derived_]RecvAsync is cancelled. \t [[{{node Reshape_17/_52}}]] \t [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/Const/_57]] [Op:__inference_distributed_function_24912]", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NaN\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: v10.1\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nDuring fitting the data, it gives Cancelled Error in the very first batch\r\n**Describe the expected behavior**\r\nTo \"Fit\" the model without error\r\n**Code to reproduce the issue**\r\n`max_len_text=275`\r\n`max_len_summary=28`\r\n`from keras import backend as K `\r\n`K.clear_session() `\r\n`latent_dim = 500 `\r\n`encoder_inputs = Input(shape=(max_len_text,)) `\r\n`enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs)` \r\n`encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)` \r\n`encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) `\r\n`encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)` \r\n`encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) `\r\n`encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)` \r\n`encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)`  \r\n`decoder_inputs = Input(shape=(None,)) `\r\n`dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True)` \r\n`dec_emb = dec_emb_layer(decoder_inputs) `\r\n`decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)` \r\n`decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) `\r\n`attn_layer = AttentionLayer(name='attention_layer') `\r\n`attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])`\r\n`decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])`\r\n`decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) `\r\n`decoder_outputs = decoder_dense(decoder_concat_input) `\r\n`model = Model([encoder_inputs, decoder_inputs], decoder_outputs) `\r\n`model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')`\r\n`es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)`\r\n`Model_training=model.fit([X_train,Y_train[:,:-1]], Y_train.reshape(Y_train.shape[0],Y_train.shape[1], 1)[:,1:]  ,epochs=50,callbacks=[es],batch_size=256, validation_data=([X_test,Y_test[:,:-1]],Y_test.reshape(Y_test.shape[0],Y_test.shape[1], 1)[:,1:]))`\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nTrain on 314860 samples, validate on 78716 samples\r\nEpoch 1/50\r\n   256/314860 [..............................] - ETA: 5:22WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \r\n\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-30-8fb3a6c938b7> in <module>\r\n      1 Model_training=model.fit([X_train,Y_train[:,:-1]], Y_train.reshape(Y_train.shape[0],Y_train.shape[1], 1)[:,1:] \r\n      2                          ,epochs=50,callbacks=[es],batch_size=256, validation_data=([X_test,Y_test[:,:-1]], \r\n----> 3                          Y_test.reshape(Y_test.shape[0],Y_test.shape[1], 1)[:,1:]))\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    485       # In this case we have created variables on the first call, so we run the\r\n    486       # defunned version which is guaranteed to never create variables.\r\n--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    488     elif self._stateful_fn is not None:\r\n    489       # Release the lock early so that multiple threads can perform the call\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_17/_52}}]]\r\n\t [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/Const/_57]] [Op:__inference_distributed_function_24912]\r\n\r\nFunction call stack:\r\ndistributed_function", "comments": ["Also experienced this, also with LSTM models. Training runs for a while eg. 100ish batches, then this error comes up.", "@solalatus In my case only first batch is executed and then this error is encountered. Can it be something related to GPU memory?", "Well, not the first batch, the first couple hundred batches. So nothing coming from the graph definition, more like some memory leak or operations bug.", "@AniTho ,\r\nCan you share a simple and standalone code to reproduce the issue?Thanks!", "@oanush the problem was solved after downgrading tensorflow to 1.14", "I have exprerienced the exact same error message in TF 2.0.0\r\n\r\nThe problem can be reproduced with one of the tutorial on the Tensorflow website:\r\nhttps://www.tensorflow.org/tutorials/text/text_classification_rnn\r\n\r\nProblem happens right after the training is started ( in the 1st epoch):\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\n\t [[Reshape_11/_38]] [Op:__inference_distributed_function_6315]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n\r\nThe problem seems to be related to the GPU, if I executed tensorflow witth CPU only, it does not crash. I however use the tensorflow-rocm (with a Vega 56 card), but it's probably not a coincidence that I get the exact same error message than mentioned above.\r\n\r\n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Elementary OS\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NaN\r\nTensorFlow installed from (source or binary): pip\r\nTensorFlow version (use command below): 2.0.0\r\nPython version: 3.7.5\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: ROCM 2.9\r\nGPU model and memory: Vega 56 8Gb\r\n\r\n", "Closing as per @AniTho comment. Thank you ", "I don't quite understand. How is changing the TF version a solution? An explanation as to why this error is reproducible for TF 2.0 would be much appreciated, as well as a clarification whether or not this error is a TF bug or a configuration issue.", "> I don't quite understand. How is changing the TF version a solution? An explanation as to why this error is reproducible for TF 2.0 would be much appreciated, as well as a clarification whether or not this error is a TF bug or a configuration issue.\r\n\r\nI myself faced this today, and for me it was cudnn version issue", "I had same issue with latest TF 2.0.0 / CUDNN.  I see lots of hits on this issue when searching.\r\n\r\nI think this issue should be reopened @oanush as TF 2.0 experiences problem with toy / example solution.  Migrating to a previous version isn't a fix. \r\n\r\nThe code seems to be around here.\r\nhttps://github.com/tensorflow/tensorflow/blob/81f844c1ff2bee0c3a98a7fff7b308ad77d85309/tensorflow/core/framework/rendezvous.h\r\n\r\nI am testing on a smallish 6GB GEForce GTX 1660 Ti so perhaps it's just running out of memory and giving a bad error?  Might be an Nvidia driver issue rather than Tensorflow's interface.\r\n\r\nAdding validation_split seems to cause kernel shutdowns and the error above in jupyter.\r\n```\r\nhistory = model.fit(x, y, batch_size=256, epochs=2, validation_split=0.33)\r\n```\r\nSetting \r\n```\r\nTF_FORCE_GPU_ALLOW_GROWTH=1\r\n```\r\n  in system environment (Windows) and restarting the shell / restarting Jupyter worked.  \r\n\r\nPerhaps this needs to be set by default or parameter documented / set as part of Tensorflow api?\r\n```\r\ntf.config.experimental.set_memory_growth(gpu, True)\r\n```\r\n\r\n```\r\nnvidia-smi\r\n```\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 441.66       Driver Version: 441.66       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0  On |                  N/A |\r\n| 27%   38C    P8    13W / 120W |   6028MiB /  6144MiB |      8%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n```", "@asears cudnn version??  ", "cudnn-7.6.5-cuda10.0_0  - fit crashed again even after setting the environment variable so perhaps not  a fix.", "> cudnn-7.6.5-cuda10.0_0 - fit crashed again even after setting the environment variable so perhaps not a fix.\r\n\r\nFacing the same issue with the same cudnn and cuda version.  \r\nJust following this tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\r\nIt occurs randomly in the 1st epoch or 2nd on my computer.\r\nI tried in Google Colab, successfully ran one time without error.", "same issue here with LSTM on GPU\r\nappears to be solved by:\r\n\r\n```\r\nimport os\r\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n```\r\nEDIT: spoke too soon, somehow this works on one machine but not another?", "> \r\n> \r\n> same issue here with LSTM on GPU\r\n> appears to be solved by:\r\n> \r\n> ```\r\n> import os\r\n> os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n> ```\r\n> \r\n> EDIT: spoke too soon, somehow this works on one machine but not another?\r\n\r\nIt's working on my laptop as well using this method", "> same issue here with LSTM on GPU\r\n> appears to be solved by:\r\n> \r\n> ```\r\n> import os\r\n> os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n> ```\r\n\r\nWorks for me too! I had a similar problem when using `disable_v2_behavior()`, while it ran correctly without it.\r\n\r\n", "Getting the same error, with AND without the TF_FORCE_GPU_ALLOW_GROWTH flag set.\r\n\r\n`CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node ConstantFolding/assert_greater_equal_1/Assert/AssertGuard/switch_pred/_30_const_false/_117}}]] [Op:__inference_train_function_240852]`\r\n\r\n![image](https://user-images.githubusercontent.com/218582/93455960-5245fa00-f8dd-11ea-990e-23a20be6e8b6.png)\r\n![image](https://user-images.githubusercontent.com/218582/93455994-61c54300-f8dd-11ea-984e-e3c02f028658.png)\r\n![image](https://user-images.githubusercontent.com/218582/93456080-7f92a800-f8dd-11ea-8058-7b6582194ff1.png)\r\n", "> Getting the same error, with AND without the TF_FORCE_GPU_ALLOW_GROWTH flag set.\r\n> \r\n> `CancelledError: [_Derived_]RecvAsync is cancelled. [[{{node ConstantFolding/assert_greater_equal_1/Assert/AssertGuard/switch_pred/_30_const_false/_117}}]] [Op:__inference_train_function_240852]`\r\n> \r\n> ![image](https://user-images.githubusercontent.com/218582/93455960-5245fa00-f8dd-11ea-990e-23a20be6e8b6.png)\r\n> ![image](https://user-images.githubusercontent.com/218582/93455994-61c54300-f8dd-11ea-984e-e3c02f028658.png)\r\n> ![image](https://user-images.githubusercontent.com/218582/93456080-7f92a800-f8dd-11ea-8058-7b6582194ff1.png)\r\n\r\nI guess you need cudnn 8.0.2 because cudnn 7.6.4 supports cuda 10.2 (based on [Nvidia](https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html#cudnn-versions-764-765) documentation).", "> > Getting the same error, with AND without the TF_FORCE_GPU_ALLOW_GROWTH flag set.\r\n> > `CancelledError: [_Derived_]RecvAsync is cancelled. [[{{node ConstantFolding/assert_greater_equal_1/Assert/AssertGuard/switch_pred/_30_const_false/_117}}]] [Op:__inference_train_function_240852]`\r\n> > ![image](https://user-images.githubusercontent.com/218582/93455960-5245fa00-f8dd-11ea-990e-23a20be6e8b6.png)\r\n> > ![image](https://user-images.githubusercontent.com/218582/93455994-61c54300-f8dd-11ea-984e-e3c02f028658.png)\r\n> > ![image](https://user-images.githubusercontent.com/218582/93456080-7f92a800-f8dd-11ea-8058-7b6582194ff1.png)\r\n> \r\n> I guess you need cudnn 8.0.2 because cudnn 7.6.4 supports cuda 10.2 (based on [Nvidia](https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html#cudnn-versions-764-765) documentation).\r\n\r\nI upgraded to cudnn 8.0.3 / cuda 11.0 and tensorflow2.3.0 built from source, and the problem persists.\r\n![image](https://user-images.githubusercontent.com/218582/93482939-8c74c300-f900-11ea-8aa7-4c4c8de93f9b.png)\r\n", "@Zahlii no idea then", "Bringing this back to life - Getting the same error with both Cuda 11.1 and 10.1 in tf 2.3.1 when using GRU.\r\nI am running Win10.\r\nThe suggestions above with \r\n\r\n```\r\n1) import os\r\n   os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n\r\n2) TF_FORCE_GPU_ALLOW_GROWTH=1\r\n\r\n3) physical_devices = tf.config.list_physical_devices('GPU')\r\n   tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\n```\r\n\r\nDo not work.\r\n\r\nMy error is slightly different from the ones above in terms of the text I get back:\r\n\r\n```[_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_27}}]]\r\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_2598]\r\n\r\nFunction call stack:\r\ntrain_function```", "I am receiving a similar error.\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_33}}]]\r\n\t [[gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape/_30]] [Op:__inference_train_function_11493]\r\n\r\nI am using tf 2.3.1 and Cuda Toolkit 11.1", "Same issue, tf 2.3.1 cuda 10.1, with `MirroredStrategy` on 2 GPU and 1 CPU machine.\r\n\r\n-------------\r\n`CentralStorageStrategy` with 1 GPU and 1 CPU same issue.", "Same issue!\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler \r\nCopyright (c) 2005-2019 NVIDIA \r\nBuilt on Sun_Jul_28_19:07:\r\nCuda compilation tools, release 10.1, V10.1.243 \r\n```\r\n\r\nAnd tf version` 2.3.0`\r\n\r\nTraining seems to stop mid way!\r\n\r\n```\r\n#Epoch 1/10\r\nWARNING:tensorflow:From /home/aman_arora/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\nINFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\r\nINFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\r\nINFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\r\nINFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\r\n 7845/16191 [=============>................] - ETA: 40:32 - loss: 0.2051\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    805       # In this case we have created variables on the first call, so we run the\r\n    806       # defunned version which is guaranteed to never create variables.\r\n--> 807       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    808     elif self._stateful_fn is not None:\r\n    809       # Release the lock early so that multiple threads can perform the call\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2827     with self._lock:\r\n   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2830 \r\n   2831   @property\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)\r\n   1846                            resource_variable_ops.BaseResourceVariable))],\r\n   1847         captured_inputs=self.captured_inputs,\r\n-> 1848         cancellation_manager=cancellation_manager)\r\n   1849 \r\n   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1922       # No tape is watching; skip to running the function.\r\n   1923       return self._build_call_outputs(self._inference_function.call(\r\n-> 1924           ctx, args, cancellation_manager=cancellation_manager))\r\n   1925     forward_backward = self._select_forward_and_backward_functions(\r\n   1926         args,\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    548               inputs=args,\r\n    549               attrs=attrs,\r\n--> 550               ctx=ctx)\r\n    551         else:\r\n    552           outputs = execute.execute_with_cancellation(\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n [[{\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b{\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200bnode div_no_nan/ReadVariableOp_3/_596}\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b}\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b]] [Op:__inference_train_function_70284]\r\nFunction call stack:\r\ntrain_function\r\n```", "@oanush why was this issue closed?", "> I had this issue but I could fix it.\r\n> \r\n> In my case I had something along the lines:\r\n> \r\n> ```python\r\n> train_data: tf.data.Dataset = get_dataset('train').padded_batch(train_batch_size)\r\n> valid_data: tf.data.Dataset = get_dataset('valid').padded_batch(valid_batch_size)\r\n> \r\n> model.fit(\r\n>   train_data,\r\n>   validation_data=valid_data\r\n> )\r\n> ```\r\n> \r\n> Where `train_batch_size != valid_batch_size` which got me:\r\n> \r\n> ```\r\n> tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n> \t [[{{node Mean/_183}}]] [Op:__inference_test_function_88423]\r\n> \r\n> Function call stack:\r\n> test_function\r\n> ```\r\n> \r\n> ### Solution\r\n> Apparently this problem might occur if we use different batch sizes. Using only _one_ batch size solved the issue for me.\r\n\r\nI never use batch, that means my batch size always is 1.", "![image](https://user-images.githubusercontent.com/52189590/99906555-542b9f80-2d0a-11eb-8cc5-45433f3e1543.png)\r\nI still have the same problem. I try to fix it as much as I can. need help T^T\r\n\r\nMy project is image caption. My code is from https://www.kaggle.com/wikiabhi/image-caption-generator dataset flickr30k and uses colab.", "Also encountering the same error.  I'm using relatively simple Keras code as follows:\r\n\r\n```\r\ndef build_model(in_dim, embedding_dim, maxlength):\r\n    inputs = tf.keras.layers.Input(shape=(None,))\r\n    embeddings = tf.keras.layers.Embedding(in_dim, embedding_dim, input_length=maxlength)(inputs)\r\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_units, return_sequences=True))(embeddings)\r\n    x = tf.keras.layers.Dropout(0.1)(x)\r\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_units, return_sequences=True))(x)\r\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_units, return_sequences=True))(x)\r\n    x = tf.keras.layers.Dropout(0.1)(x)\r\n    x = tf.keras.layers.LSTM(LSTM_units, return_sequences=True)(x)\r\n\r\n    x_h = tf.keras.layers.concatenate([tf.keras.layers.GlobalAveragePooling1D()(x),\r\n                                     tf.keras.layers.GlobalMaxPool1D()(x)])\r\n    x_h = tf.keras.layers.Dropout(0.2)(x_h)\r\n    x_h = tf.keras.layers.Dense(dense_units, activation='relu')(x_h)\r\n    x_h = tf.keras.layers.Dropout(0.3)(x_h)\r\n    x_h = tf.keras.layers.add([x_h, tf.keras.layers.Dense(dense_units, activation='relu')(x_h)])\r\n\r\n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x_h)\r\n\r\n    model = keras.Model(inputs=inputs, outputs=outputs)\r\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n    return model\r\n\r\nmodel_1 = build_model(num_chars, embedding_dimension, max_length)\r\n\r\ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, mode='max', patience=2, min_lr=0.000001),\r\n             tf.keras.callbacks.ModelCheckpoint('/content/saved_at_{epoch}.h5', monitor='val_loss', save_best_only=True)\r\n]\r\n\r\n\r\nhistory = model_1.fit(x_train,\r\n                     np.array(y_train), \r\n                     epochs=epochs, \r\n                     batch_size=batch_size, \r\n                     callbacks=callbacks, \r\n                     validation_split=val_split,\r\n                     class_weight=class_weights\r\n                     )\r\n```\r\n\r\nAnd the stack is:\r\n\r\n```\r\nEpoch 1/20\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-11-3c53d64825d4> in <module>()\r\n     10                      callbacks=callbacks,\r\n     11                      validation_split=val_split,\r\n---> 12                      class_weight=class_weights\r\n     13                      )\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_57}}]]\r\n\t [[gradient_tape/functional_1/embedding/embedding_lookup/Reshape/_54]] [Op:__inference_train_function_18787]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\nI'm running in Colab, so everything should be up to date.  Attempting to use \r\n```\r\nimport os\r\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n```\r\nresults in \r\n```\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-12-23cb5f878315> in <module>()\r\n     13                      callbacks=callbacks,\r\n     14                      validation_split=val_split,\r\n---> 15                      class_weight=class_weights\r\n     16                      )\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInternalError: GPU sync failed\r\n```\r\n\r\nJust returned to Tensorflow after a monthlong hiatus, but I've never seen this before.  Not sure why it's a closed issue, since it's clearly been around for a year or so.  Interestingly, when I use word-level instead of character-level encodings and use a smaller model (1mil parameters instead of the current 20mil), I have no issues.\r\n\r\nEDIT:  I tried using a TPU instead of a GPU to circumvent this problem, and the session crashed after using all available memory.  Seems to be more related to the size of the model, not the GPU specifically?\r\n\r\nEDIT 2:  Slashed the network size from 20mil to 3 mil params, reduced the embedding dimensionality, and cut the batch size.  Runs on GPU perfectly fine, but it's very slow, an hour for a single epoch.  Further hyperparameter tweaking reduces it to 15 minutes per epoch.  Definitely seems to be tied to network size and memory issues.", "I ran into this problem again ([see my stackoverflow question](https://stackoverflow.com/questions/65160085/getting-cancellederror-derived-recvasync-is-cancelled-after-hours-of-train)).\r\n\r\nMy training runs for multiple hours until at some point I am getting this error:\r\n\r\n```\r\n2020-12-05 18:06:59.383572: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Unknown: CUDNN\r\n_STATUS_BAD_PARAM\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1484): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\r\n2020-12-05 18:06:59.383906: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Unknown: CUDNN_STATUS_BAD_PARAM\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1484): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\r\n2020-12-05 18:06:59.384114: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Unknown: CUDNN_STATUS_BAD_PARAM\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1484): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\r\nTraceback (most recent call last):\r\n  File \"asr/bin/train_keras.py\", line 300, in <module>\r\n    app.run(main)\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"asr/bin/train_keras.py\", line 236, in main\r\n    model.fit(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1843, in _filtered_call\r\n    return self._call_flat(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n         [[{{node div_no_nan/ReadVariableOp_5/_1620}}]]\r\n         [[GroupCrossDeviceControlEdges_2/Identity_6/_1699]] [Op:__inference_train_function_159151]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```", "@Izeple Could you provide and share a colab where we can reproduce this issue?\r\n", "I have upgraded to 2.4.0 and CUDA 11 / cuDNN 8 but the error still persists (https://github.com/tensorflow/tensorflow/issues/45594).", "I think I have fixed the issue. The root of this was [`bucket_by_sequence_length`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/bucket_by_sequence_length) and me setting `drop_remainder=False`.\r\n\r\nWhat seems to happen here is that there are batches which do not have enough samples s.t. there weren't enough examples for all cards. Since I set `drop_remainder=True` I didn't get this error anymore. So, make sure that you are not running into the same issue.", "if your are facing this error in colab then its due to dataset size.. reduce the dataset size then try it..", "Why is this issue closed? This problem is still ongoing.\r\nI have spent the past 4 hours trying to figure out what to do.. this error is not solved using any of the above solutions.", "Having this issue with TF 2.4. What is the resolution and why is this closed. ", "The issue is closed because, well, not sure.\r\n\r\nWhile I can't really help without specifics, immediate recommendations are:\r\n-Reduce model size\r\n-Reduce dataset size\r\n-Use smaller batches\r\n-Batch items into a tf.dataset object\r\n\r\nInterestingly, I finished training a large 23M param GRU on the same dataset as before without encountering issues.  Try unrolling the RNN layers and batching items in buckets of  64", "For me the issue was gpu memory settings, I ran:\r\n\r\n`import tensorflow as tf\r\nif 'session' in locals() and session is not None:\r\n    print('Close interactive session')\r\n    session.close()\r\n\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))    \r\n    \r\ngpus = tf.config.list_physical_devices('GPU')\r\nif gpus:\r\n  try:\r\n    # Currently, memory growth needs to be the same across GPUs\r\n    for gpu in gpus:\r\n      tf.config.experimental.set_memory_growth(gpu, True)\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n  except RuntimeError as e:\r\n    # Memory growth must be set before GPUs have been initialized\r\n    print(e)`\r\n\r\nat the start of my jupyter notebook and my LSTM training went through fine.  I was using keras 2.4.3 with an 8GB Nividia GPU.", "> Bringing this back to life - Getting the same error with both Cuda 11.1 and 10.1 in tf 2.3.1 when using GRU.\r\n> I am running Win10.\r\n> The suggestions above with\r\n> \r\n> ```\r\n> 1) import os\r\n>    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n> \r\n> 2) TF_FORCE_GPU_ALLOW_GROWTH=1\r\n> \r\n> 3) physical_devices = tf.config.list_physical_devices('GPU')\r\n>    tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n> ```\r\n> \r\n> Do not work.\r\n> \r\n> My error is slightly different from the ones above in terms of the text I get back:\r\n> \r\n> ```\r\n> \t [[{{node Adam/Adam/update/AssignSubVariableOp/_27}}]]\r\n> \t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_2598]\r\n> \r\n> Function call stack:\r\n> train_function```\r\n> ```\r\n\r\nIn my case(on Google Colab), I used 256 batch_size when first fitting model.(worked well)\r\nBut using kerastuner for hyperparameters tuning, I got the error similar to yours.\r\nSolved it with making lower the training BATCH_SIZE from 256 to 100 when tuning my BiLSTM model using kerastuner.\r\n", "Folks, I am facing this issue right now and opened a different issue https://github.com/tensorflow/tensorflow/issues/50296, please comment there and provide information if someone else is facing the same problem.\r\nFor me limiting GPU memory growth is not working!", "I just face this issue. Using LSTM and embedded layer. However, when I reduce 65k data to 50k data, the problem is solved. Anyone knows why is that? using TF 2.5.0"]}, {"number": 33720, "title": "Generating Arduino Libraries error", "body": "**System information**\r\n- OS Platform and Distribution : macOS 10.14.6\r\n- TensorFlow version: 1.15.0\r\n- Python version: 2.7.10 and 3.7.4 \r\n\r\n**Describe the problem**\r\nWhen i run the command \"sh test_arduino.sh\" it gaves me that error:\r\n```\r\n...\r\nFinished patching kissfft\r\nTraceback (most recent call last):\r\n  File \"tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py\", line 121, in <module>\r\n    parse_args()\r\n  File \"tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py\", line 117, in parse_args\r\n    main(unparsed, flags)\r\n  File \"tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py\", line 39, in main\r\n    six.ensure_str(flags.executable),\r\nAttributeError: 'module' object has no attribute 'ensure_str'\r\nmake: *** [tensorflow/lite/experimental/micro/examples/person_detection/Makefile.inc:56: tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection_test/keil/keil_project.uvprojx] Error 1\r\n```\r\nI tried to use python3, changing the line 304 in \"/tensorflow/tensorflow/lite/experimental/micro/tools/make/Makefile\", but nothing change.\r\n", "comments": ["upgrading the `six` module to 1.14 fixed the issue for me.\r\n```\r\npip install six --upgrade\r\n```", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33720\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33720\">No</a>\n"]}, {"number": 33719, "title": "same code run on different versions of tf cost large different gpu memory consumption.", "body": "HI,\r\nIn my two system(P40, CUDA9, CUDNN7), tf1.8 and tf1.12 are installed respectively, and the same piece of code runs in tf1.12 almost double the allocated gpu memory as in tf1.8.\r\n\r\nI wrote the following code to simplify the comparison. At this time in tf1.8, 1241MiB gpu memory is allocated and in tf1.12, 737MiB gpu memory is allocated. How could I optimize the gpu memory allocation in tf? Any suggestion would be appreciated.\r\n```\r\nimport tensorflow as tf                                                                                                              \r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.allow_soft_placement = True\r\na=tf.get_variable('a',(100,100))\r\nb=tf.get_variable('b',(10000,10000))\r\nsess=tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\n```\r\n\r\n", "comments": ["@Jar7 Please try to use most recent TF versions (TF.1.15 or TF2.0) as there were several improvements in the performance. Please check the guides and tutorials provided in the TF website as for [gpu](https://www.tensorflow.org/guide/gpu), [distributed_training](https://www.tensorflow.org/guide/distributed_training) and [`tf.data`](https://www.tensorflow.org/guide/data_performance) for best performance using machine learning pipeline. Thanks!\r\n\r\n", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "> @Jar7 Please try to use most recent TF versions (TF.1.15 or TF2.0) as there were several improvements in the performance. Please check the guides and tutorials provided in the TF website as for [gpu](https://www.tensorflow.org/guide/gpu), [distributed_training](https://www.tensorflow.org/guide/distributed_training) and [`tf.data`](https://www.tensorflow.org/guide/data_performance) for best performance using machine learning pipeline. Thanks!\r\n\r\nHi, could you please specify the reason for different gpu memory allocation for the provided code on different version of tensorflow? I have read the tutorials about gpu, and cannot find the answer. It is straightforward that some gpu memory is unnecessary allocated. Is it a bug? \r\nWhat's more, it is nothing about distrubuted_training and tf.data. ", "@Jar7 May be there was an over allocation in `TF1.8`, which is a very old version. The allocation with TF1.12 seems to be correct as I checked with `TF1.15` which is also taking similar allocation. I would suggest to use `TF1.15` as there were lots of performance improvements. Thanks!"]}, {"number": 33718, "title": "[TFLite, Converter] BERT conversion error in later version", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Yes\r\n- TensorFlow version (use command below): firsrt git version: 9edecf8, second git verison: f9c7eb4\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): GCC 8.3.0\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n**Describe the current behavior**\r\nWhen I convert BERT from tensorflow/models to tflite format by tensorflow that was built at commit with hash 9edecf8, it works. But when I do the same by tensorflow that was built at later commit with hash f9c7eb4, it doesn't work. The error in logs (Unsupported operation: Einsum).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nimport json\r\nimport os\r\n\r\nfrom absl import app\r\nfrom absl import flags\r\n\r\nfrom official.nlp.bert_models import classifier_model\r\nfrom official.nlp.bert_modeling import BertConfig\r\n\r\nflags.DEFINE_string('output_dir', default=None, help='Directory for tflite models')\r\nflags.DEFINE_string('config_path', default=None, help='Path to config file')\r\n\r\nFLAGS = flags.FLAGS\r\ndef convert_bert(model, output_dir):\r\n  if not os.path.exists(output_dir):\r\n    os.mkdir(output_dir)\r\n  converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n  tflite_model = converter.convert()\r\n  output_path = os.path.join(output_dir, 'bert.tflite')\r\n  with open(output_path, \"wb\") as f:\r\n    f.write(tflite_model)\r\n\r\ndef main(_):\r\n  output_dir = FLAGS.output_dir\r\n  config_path = FLAGS.config_path\r\n  with open(config_path, 'r') as f:\r\n    config = json.load(f)\r\n  model = classifier_model(BertConfig.from_dict(config), tf.float32, 2, 128)[0]\r\n  convert_bert(model, output_dir)\r\n\r\nif _name_ == '_main_':\r\n  app.run(main)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2019-10-25 11:49:08.546343: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\r\n2019-10-25 11:49:08.548499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x434ae80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-10-25 11:49:08.548520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-10-25 11:49:11.490358: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-10-25 11:49:11.490631: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-10-25 11:49:11.503750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize\r\n2019-10-25 11:49:11.503785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n2019-10-25 11:49:11.503790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-10-25 11:49:17.635192: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-10-25 11:49:17.635327: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-10-25 11:49:20.802742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize\r\n2019-10-25 11:49:20.802785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (-299), 1515 edges (-396), time = 1677.46204ms.\r\n2019-10-25 11:49:20.802790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (0), 1515 edges (0), time = 496.749ms.\r\nTraceback (most recent call last):\r\n  File \"convert_bert.py\", line 39, in <module>\r\n    app.run(main)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"convert_bert.py\", line 36, in main\r\n    convert_bert(model, output_dir)\r\n  File \"convert_bert.py\", line 22, in convert_bert\r\n    tflite_model = converter.convert()\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 464, in convert\r\n    **converter_kwargs)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 452, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 203, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2019-10-25 11:49:24.764527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764589: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764632: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764641: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764659: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764690: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764698: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764713: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764734: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764741: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764756: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764768: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764784: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764791: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764798: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764806: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764815: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764821: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764837: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764849: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764871: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764877: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764885: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764895: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764901: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.764918: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum\r\n2019-10-25 11:49:24.790537: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 716 operators, 1029 arrays (0 quantized)\r\n2019-10-25 11:49:24.802635: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 716 operators, 1029 arrays (0 quantized)\r\n2019-10-25 11:49:24.816756: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 564 operators, 862 arrays (0 quantized)\r\n2019-10-25 11:49:24.829191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 564 operators, 862 arrays (0 quantized)\r\n2019-10-25 11:49:24.841886: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.854403: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.866851: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 5: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.879295: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 6: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.891707: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.900833: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 563 operators, 860 arrays (0 quantized)\r\n2019-10-25 11:49:24.915554: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2032640 bytes, theoretical optimal value: 1179648 bytes.\r\n2019-10-25 11:49:24.917162: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 107896686\r\n2019-10-25 11:49:24.930715: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum.\r\nTraceback (most recent call last):\r\n  File \"/workspace/.local/bin//toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/workspace/.local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum\r\n```", "comments": ["Hi,\r\n\r\nThis is because Einsum op is not supported in TF Lite. Is it possible to replace this op with other op in the model?", "Hi!\r\nI understand why this error appeared and it's okay that einsum isn't supported. But I noticed that when I do the same with the earlier tensorflow version, this error doesn't appear. So as I understand, before now TFLiteConverter has converted einsum not as one operation, but as several operations. But now TFLiteConverter tries to convert einsum as one operation not having appropriate supporting. So is it okay that such changes were made?", "Hi,\r\n\r\nDid you pass -enable_select_tf_ops when converting the model before? tf.Einsum is a supported flex op, maybe it's working before because you enable flex mode?\r\n\r\nWhat's the tflite version that you use before that could convert the einsum op (i'm not aware of any transformation passes that in tflite converter to break the ops into several simple ops, so it sounds a bit interesting)", "I didn't use any additional flags, I used exactly the code that in \"Code to reproduce the issue\" section in issue.\r\n\r\nI used \"latest-devel-py3\" tensorflow docker container. So the hash of last commit in this docker was 9edecf8. Tensorflow was built from source with default options.", "Hi,\r\n\r\nDo you have an example to demonstrate that the 'einsum' op is actually converted to series of basic ops? Like what ops are there before/after the conversion?", "Now I can only demonstrate sequence of operation of one einsum in tflite model gotten by tflite_benchmark. I'll send the same information about model before conversion only on the next week:\r\n```\r\n                       TRANSPOSE\t           53.024\t    1.136\t    1.103\t  0.038%\t  1.867%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose]\r\n\t               TRANSPOSE\t           54.128\t    0.788\t    0.782\t  0.027%\t  1.894%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose_1]\r\n\t               TRANSPOSE\t           54.910\t    0.928\t    0.932\t  0.032%\t  1.926%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum_1/transpose]\r\n\t                 RESHAPE\t           55.842\t    0.049\t    0.048\t  0.002%\t  1.928%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/reshape_a/reshape]\r\n\t                   SLICE\t           55.891\t    0.015\t    0.014\t  0.000%\t  1.928%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_a/slice]\r\n\t                   SLICE\t           55.906\t    0.009\t    0.009\t  0.000%\t  1.928%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_a/slice]\r\n\t                   SLICE\t           55.915\t    0.005\t    0.005\t  0.000%\t  1.929%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_a/slice]\r\n\t                   SLICE\t           55.921\t    0.006\t    0.006\t  0.000%\t  1.929%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_a/slice]\r\n\t                   SLICE\t           55.927\t    0.007\t    0.007\t  0.000%\t  1.929%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_a/slice]\r\n\t                   SLICE\t           55.934\t    0.005\t    0.005\t  0.000%\t  1.929%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_a/slice]\r\n\t                   SLICE\t           55.939\t    0.006\t    0.006\t  0.000%\t  1.929%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_a/slice]\r\n\t                   SLICE\t           55.946\t    0.006\t    0.006\t  0.000%\t  1.930%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_a/slice]\r\n\t                   SLICE\t           55.952\t    0.006\t    0.006\t  0.000%\t  1.930%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_a/slice]\r\n\t                   SLICE\t           55.958\t    0.005\t    0.005\t  0.000%\t  1.930%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_a/slice]\r\n\t                   SLICE\t           55.963\t    0.006\t    0.006\t  0.000%\t  1.930%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_a/slice]\r\n\t                   SLICE\t           55.969\t    0.005\t    0.005\t  0.000%\t  1.930%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_a/slice]\r\n\t                 RESHAPE\t           55.975\t    0.058\t    0.059\t  0.002%\t  1.932%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/reshape_b/reshape]\r\n\t                   SLICE\t           56.034\t    0.005\t    0.005\t  0.000%\t  1.933%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/slice]\r\n\t               TRANSPOSE\t           56.039\t    0.008\t    0.009\t  0.000%\t  1.933%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.048\t    0.005\t    0.005\t  0.000%\t  1.933%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/slice]\r\n\t               TRANSPOSE\t           56.053\t    0.008\t    0.007\t  0.000%\t  1.933%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.061\t    0.005\t    0.005\t  0.000%\t  1.933%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/slice]\r\n\t               TRANSPOSE\t           56.066\t    0.007\t    0.007\t  0.000%\t  1.934%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.074\t    0.005\t    0.005\t  0.000%\t  1.934%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/slice]\r\n\t               TRANSPOSE\t           56.079\t    0.008\t    0.007\t  0.000%\t  1.934%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.087\t    0.005\t    0.005\t  0.000%\t  1.934%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/slice]\r\n\t               TRANSPOSE\t           56.092\t    0.007\t    0.008\t  0.000%\t  1.935%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.100\t    0.005\t    0.005\t  0.000%\t  1.935%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/slice]\r\n\t               TRANSPOSE\t           56.106\t    0.008\t    0.007\t  0.000%\t  1.935%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.114\t    0.006\t    0.006\t  0.000%\t  1.935%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/slice]\r\n\t               TRANSPOSE\t           56.120\t    0.008\t    0.007\t  0.000%\t  1.935%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.128\t    0.004\t    0.005\t  0.000%\t  1.936%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/slice]\r\n\t               TRANSPOSE\t           56.133\t    0.007\t    0.007\t  0.000%\t  1.936%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.140\t    0.005\t    0.005\t  0.000%\t  1.936%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/slice]\r\n\t               TRANSPOSE\t           56.145\t    0.008\t    0.007\t  0.000%\t  1.936%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.153\t    0.005\t    0.005\t  0.000%\t  1.936%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/slice]\r\n\t               TRANSPOSE\t           56.158\t    0.008\t    0.007\t  0.000%\t  1.937%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.166\t    0.005\t    0.004\t  0.000%\t  1.937%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/slice]\r\n\t               TRANSPOSE\t           56.171\t    0.008\t    0.007\t  0.000%\t  1.937%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/reshape/transpose]\r\n\t                   SLICE\t           56.179\t    0.004\t    0.005\t  0.000%\t  1.937%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/slice]\r\n\t               TRANSPOSE\t           56.184\t    0.008\t    0.007\t  0.000%\t  1.938%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/reshape/transpose]\r\n\t                 RESHAPE\t           56.192\t    0.004\t    0.004\t  0.000%\t  1.938%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           56.196\t    0.249\t    0.238\t  0.008%\t  1.946%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0]\r\n\t                 RESHAPE\t           56.434\t    0.004\t    0.004\t  0.000%\t  1.946%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           56.438\t    0.223\t    0.199\t  0.007%\t  1.953%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1]\r\n\t                 RESHAPE\t           56.638\t    0.003\t    0.004\t  0.000%\t  1.953%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           56.642\t    0.204\t    0.199\t  0.007%\t  1.960%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2]\r\n\t                 RESHAPE\t           56.841\t    0.004\t    0.005\t  0.000%\t  1.960%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           56.847\t    0.195\t    0.197\t  0.007%\t  1.967%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3]\r\n\t                 RESHAPE\t           57.044\t    0.004\t    0.004\t  0.000%\t  1.967%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           57.049\t    0.194\t    0.197\t  0.007%\t  1.974%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4]\r\n\t                 RESHAPE\t           57.246\t    0.003\t    0.004\t  0.000%\t  1.974%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           57.250\t    0.207\t    0.201\t  0.007%\t  1.981%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5]\r\n\t                 RESHAPE\t           57.451\t    0.005\t    0.006\t  0.000%\t  1.981%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           57.457\t    0.201\t    0.197\t  0.007%\t  1.988%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6]\r\n\t                 RESHAPE\t           57.655\t    0.005\t    0.005\t  0.000%\t  1.988%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           57.660\t    0.197\t    0.199\t  0.007%\t  1.995%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7]\r\n\t                 RESHAPE\t           57.859\t    0.005\t    0.005\t  0.000%\t  1.995%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           57.865\t    0.197\t    0.200\t  0.007%\t  2.002%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8]\r\n\t                 RESHAPE\t           58.066\t    0.003\t    0.004\t  0.000%\t  2.002%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           58.070\t    0.215\t    0.197\t  0.007%\t  2.009%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9]\r\n\t                 RESHAPE\t           58.267\t    0.004\t    0.004\t  0.000%\t  2.009%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           58.272\t    0.197\t    0.197\t  0.007%\t  2.016%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10]\r\n\t                 RESHAPE\t           58.469\t    0.004\t    0.004\t  0.000%\t  2.016%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/reshape]\r\n\t         FULLY_CONNECTED\t           58.473\t    0.195\t    0.195\t  0.007%\t  2.023%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11]\r\n\t                    PACK\t           58.669\t    0.125\t    0.127\t  0.004%\t  2.027%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/pack]\r\n\t               TRANSPOSE\t           58.797\t    1.180\t    1.195\t  0.041%\t  2.068%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose_2]\r\n\t                     MUL\t           59.992\t    0.136\t    0.148\t  0.005%\t  2.073%\t     0.000\t        1\t[model_1/bert_model/encoder/layer_0/self_attention/einsum/Reshape_2]\r\n```", "i don't see where in the tflite code base `einsum` is replaced by a sequence of other ops. is it possible that the model you generated before doesn't have `einsum` at all?", "@Vooblin \r\nCould you please update as per above comment, if this is not an issue anymore please feel free to move this issue to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33718\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33718\">No</a>\n"]}, {"number": 33717, "title": "Unable to compute gradients efficiently in TF 1.14", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7.3\r\n- GPU model: Titan X (Pascal) \r\n- CUDA Version: 10.1\r\n\r\n**Problem Statement**\r\n\r\nSo, I am trying to find the gradients of outputs with respect to inputs but my decoder model is a GRU.  First, I used the code below, which works but is quite slow since my input is a 56 dimension vector but the output is of (276,77) dimensional matrix:\r\n\r\n```\r\n        def get_gradients(i):\r\n            return tf.gradients(self.decoder_output[:, i], self.decoder_input)[0]\r\n        \r\n        output_dim = self.decoder_output.shape[1].value\r\n        J = [get_gradients(i) for i in tqdm_notebook(range(output_dim))] \r\n```\r\n\r\nThen, I looked to change it to while loop but apparently it gave me this error which means I cant have a nested while loop in which I am calculating gradients. \r\n\r\n```\r\nINFO:tensorflow:Cannot use 'while_1/gradients/f_count' as input to 'while_1/gradients/f_count_1' because they are in different while loops.\r\n\r\nwhile_1/gradients/f_count_1 while context: gru_3/while/while_context\r\nwhile_1/gradients/f_count while context: while_1/while_context\r\n```\r\n\r\n- Is there way around this? Isn't there any other way in tensorflow to compute gradients?", "comments": ["@Harshdeep1996 You can refer to the following example[ here ](https://www.cnblogs.com/xiaojieshisilang/p/10061578.html) which should help you in solving the issue.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue as it has been inactive from more than 14 days. Please add additional comments and we can open this issue again. Thanks!"]}, {"number": 33716, "title": "How to change dropout rate at runtime", "body": "I am trying to switch to tf2.0. From the documentation of Dropout it is possible to set dropout rate in the declaration. When I call the dropout operation it does not seem possible to change the dropout rateo anymore. \r\n\r\nSuppose I would like to soften my dropout rate along training how can I do? Is there a walkaround?\r\n\r\n```\r\nclass mymodel(Model):\r\n    def __init__(self, units=128):\r\n        super(mymodel, self).__init__()\r\n        self.conv1_1 = tf.keras.layers.Conv2D(filters=units, kernel_size=3, strides=1)\r\n        self.dropout1 = tf.keras.layers.Dropout(0.5)\r\n\r\n        self.fc = tf.keras.layers.Dense(units=10)\r\n\r\n\r\n    def call(self, x, training=False):\r\n\r\n        x = tf.pad(x, paddings=[[0, 0], [1, 1], [1, 1], [0, 0]])\r\n        x = self.conv1_1(x, training=training)\r\n        x = tf.keras.activations.relu(x)\r\n        x = self.dropout1(x) # how to change the rateo?\r\n        x = self.fc(x)\r\n```", "comments": ["@paolorota This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33715, "title": "TF Keras fails to concatenate batches in predict when using distributed strategy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): -\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): HPC Cluster\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): via pip\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.1\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: cuDNN 7.6.4, CUDA 10.0.130 \r\n- GPU model and memory: 8x GeForce GTX 1080 Ti with 10479 MB memory each\r\n\r\n**Describe the current behavior**\r\nWhen using the distributed mirrored strategy to train the network on multiple GPU's, the predict step fails with this error code:\r\n\r\n> File \"/cluster/home/user/localization/base_model.py\", line 76, in predict\r\n>     prediction = self.model.predict(x, use_multiprocessing = False)\r\n>   File \"/cluster/home/cspreche/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 909, in predict\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 462, in predict\r\n>     steps=steps, callbacks=callbacks, **kwargs)\r\n>   File \"/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 444, in _model_iteration\r\n>     total_epochs=1)\r\n>   File \"/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 161, in run_one_epoch\r\n>     batch_outs = _aggregate_predict_results(strategy, batch_outs, model)\r\n>   File \"/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 631, in _aggregate_predict_results\r\n>     dist_utils.concat_along_batch_dimension(nest.flatten(nested_outs)))\r\n>   File \"/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\", line 1205, in concat_along_batch_dimension\r\n>     return np.concatenate(outputs)\r\n> ValueError: all the input array dimensions except for the concatenation axis must match exactly\r\n\r\nWhen I print the dimensions of the elements in the concatenation, I get the following output:\r\n\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (32, 320, 320, 1)\r\n> (10, 320, 320, 1)\r\n> (0, 0, 0, 1)\r\n> (0, 0, 0, 1)\r\n> (0, 0, 0, 1)\r\n\r\nIt seems, that the empty sets do not inherit the dimensions of full ones and lead therefore to a crash with the numpy concatenate function.\r\n\r\nI could solve the issue with replacing\r\n> return np.concatenate(outputs)\r\n\r\nwith\r\n\r\n> out = [z for z in outputs if z.shape[0] > 0]\r\n> return np.concatenate(out)\r\n\r\n**Code to reproduce the issue**\r\n\r\n> ds_train = tfds.load(..)\r\n> ds_val = tfds.load(..)\r\n> \r\n> strategy = tf.distribute.MirroredStrategy()\r\n> num_gpu = strategy.num_replicas_in_sync\r\n> \r\n> ds_train = ds_train.batch(32 * num_gpu)\r\n> ds_val = ds_val.batch(32 * num_gpu)\r\n> \r\n> with strategy.scope():\r\n>    input_image = Input(...)\r\n>    ....\r\n>    output = ....\r\n>    model = tf.keras.Model(inputs=[input_image], outputs=[output])\r\n>    model.compile(...)\r\n> model.fit(ds_train, validation_data = ds_val)\r\n> model.predict(ds_val, use_multiprocessing = True)\r\n", "comments": ["@christiansprecher Can you please provide a simple standalone code to reproduce the issue? Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33715\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33715\">No</a>\n"]}, {"number": 33714, "title": "AdamOptimizer with Dropout is good or bad?", "body": "**AdamOptimizer with Dropout? is it good or bad?\r\n\r\nI am doing CNN for image recognition.\r\n\r\nThey said using Adamoptimizer with dropout is bad idea.\r\n\r\nis it true?\r\n\r\nWhy?**  \r\n\r\n    def get_training_model():\r\n    x, conv_layer, conv_vars = convolutional_layers()\r\n    # dropout\r\n    keep_rate = 0.8\r\n    keep_prob = tf.placeholder(tf.float32)\r\n\r\n    # fully connected layer -(densely connected layer)\r\n    W_fc1 = weight_variable([32 * 8 * 128, 2048]) \r\n    b_fc1 = bias_variable([2048])             \r\n\r\n    conv_layer_flat = tf.reshape(conv_layer, [-1, 32 * 8 * 128])\r\n    # h_fc1 -Fully connected layer\r\n    h_fc1 = tf.nn.relu(tf.matmul(conv_layer_flat, W_fc1) + b_fc1) \r\n\r\n    # Output layer\r\n    W_fc2 = weight_variable([2048, 1 + 7 * len(common.CHARS)]) \r\n    b_fc2 = bias_variable([1 + 7 * len(common.CHARS)])          \r\n\r\n    #dropout\r\n    h_fc1 = tf.nn.dropout(h_fc1, keep_rate)\r\n\r\n    #output\r\n    y = tf.matmul(h_fc1, W_fc2) + b_fc2      # h_fc1 -Fully connected layer\r\n                                             # W_fc2 -weights output layer\r\n                                             # b_fc2 -biases output layer\r\n                                             # y -output\r\n    #output\r\n    return (x, y, conv_vars + [W_fc1, b_fc1, W_fc2, b_fc2])\r\n            # output to training.py\r\n\r\n**AdamOptimizer with Dropout? is it good or bad?\r\n\r\nI am doing CNN for image recognition.\r\n\r\nThey said using Adamoptimizer with dropout is bad idea.\r\n\r\nis it true?\r\n\r\nWhy?**", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}]