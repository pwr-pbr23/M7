[{"number": 51080, "title": "Op type not registered 'NormalizeUTF8' in binary running  when reload model ", "body": "tf version: 2.4.1\r\n\r\n```\r\ndef get_model_bert(num_classes):\r\n\r\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) # shape=(None,) dtype=string\r\n\r\n    encoder = hub.KerasLayer(\"./resource/albert_en_base_2\", trainable=True)\r\n\r\n    encoder_inputs = preprocessor_layer(text_input)\r\n    outputs = encoder(encoder_inputs)\r\n    embed = outputs[\"pooled_output\"]  \r\n\r\n    if num_classes == 2:\r\n        out = layers.Dense(1, activation='sigmoid')(embed)\r\n        model = tf.keras.Model(inputs=text_input, outputs=out)\r\n        model.compile(Adam(lr=2e-5), \"binary_crossentropy\", metrics=[\"binary_accuracy\"])\r\n    else:\r\n        out = layers.Dense(num_classes, activation=\"softmax\")(embed)\r\n        model = tf.keras.Model(inputs=text_input, outputs=out)\r\n        model.compile(Adam(lr=2e-5), \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\r\n    return model\r\n\r\nmodel = get_model_bert(2)\r\nmodel.save('tttmodel').\r\n```  \r\n\r\n\r\n> 2021-08-01 03:46:36.957767: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\n> WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.\r\n> WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.\r\n> INFO:tensorflow:Assets written to: tttmodel/assets\r\n> INFO:tensorflow:Assets written to: tttmodel/assets\r\n\r\nThen I tried reload it from disk:\r\n\r\n`model = tf.keras.models.load_model('tttmodel')`\r\n\r\nThe error:\r\n\r\n\r\n\r\n> ----> 1 model = tf.keras.models.load_model('tttmodel')\r\n> \r\n> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\r\n>     210       if isinstance(filepath, six.string_types):\r\n>     211         loader_impl.parse_saved_model(filepath)\r\n> --> 212         return saved_model_load.load(filepath, compile, options)\r\n>     213 \r\n>     214   raise IOError(\r\n> \r\n> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)\r\n>     142   for node_id, loaded_node in keras_loader.loaded_nodes.items():\r\n>     143     nodes_to_load[keras_loader.get_path(node_id)] = loaded_node\r\n> --> 144   loaded = tf_load.load_partial(path, nodes_to_load, options=options)\r\n>     145 \r\n>     146   # Finalize the loaded layers and remove the extra tracked dependencies.\r\n> \r\n> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_partial(export_dir, filters, tags, options)\r\n>     763     A dictionary mapping node paths from the filter to loaded objects.\r\n>     764   \"\"\"\r\n> --> 765   return load_internal(export_dir, tags, options, filters=filters)\r\n>     766 \r\n>     767 \r\n> \r\n> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls, filters)\r\n>     891       except errors.NotFoundError as err:\r\n>     892         raise FileNotFoundError(\r\n> --> 893             str(err) + \"\\n If trying to load on a different device from the \"\r\n>     894             \"computational device, consider using setting the \"\r\n>     895             \"`experimental_io_device` option on tf.saved_model.LoadOptions \"\r\n> \r\n> FileNotFoundError: Op type not registered 'NormalizeUTF8' in binary running on jp-34805-jjj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n>  If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'.\r\n\r\n\r\n\r\nAny solution ?", "comments": ["@yananchen1989 Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51080\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51080\">No</a>\n"]}, {"number": 51079, "title": "Fix wrong instruction of TFLite iOS profiling tool", "body": "Change to \"Product > Profile\" from \"Product > Scheme\"", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51079) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@yyoon could you review this PR?", "Thanks, @hajuho :)", "@abattery @yyoon nice to see you again :)"]}, {"number": 51078, "title": "cannot use tf.keras.preprocessing.image.random_channel_shift or apply_channel_shift with tf.data.Dataset functions like image_dataset_from_directory or tensor_slices.", "body": "I am using tensorflow 2.5, i cannot use apply_channel_shift or [random_channel_shift](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_channel_shift) with tf.data.Dataset it raises the following error:\r\ntensor object has no attribute \"ndim\".\r\n can any one please write a sample code for me ? \r\ni am using .map function for apply agumentation on tf.data Dataset. many thanks.\r\n", "comments": ["@imohamadhoseins ,\r\n\r\nCan you please take a look at this [link](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) for more information on tf.keras.preprocessing.It helps.Thanks!", "@tilakrayal \r\nI did, it doesn't help, it returns a tensor object, but the preprocessing which I mentioned are not accepting tensor object, but in documentation it has written they can accept tensor. thank you", "@imohamadhoseins ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.Thanks!", "```\r\ndef augment(image, label):\r\n  image = tf.keras.preprocessing.image.apply_channel_shift(image, 100.0)\r\n  return (image, label)\r\n\r\ndef prepare(ds):\r\n  ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\r\n  return ds.prefetch(buffer_size=AUTOTUNE)\r\n\r\ntraindata_tfds = tf.keras.preprocessing.image_dataset_from_directory(\r\npath_train, labels='inferred', label_mode='categorical',\r\nclass_names=None, color_mode='rgb', batch_size=Batch_size, image_size=(256,\r\n256), shuffle=True, seed=None, validation_split=None, subset=None,\r\ninterpolation='bilinear', follow_links=False, smart_resize=True)\r\n\r\ntrain_ds = prepare(traindata_tfds)\r\n```\r\n\r\nyou can set any path containing class folders and images inside them as \"path_train\" and any batch_size you like.\r\n@tilakrayal ", "@imohamadhoseins ,\r\n\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "the problem is that in document it has written it is possible to pass tensor, but it actually doesnt.", "@imohamadhoseins ,\r\nAs mentioned above, Please post this issue on keras-team/keras repo.It would be tracked in keras repo.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51078\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51078\">No</a>\n"]}, {"number": 51077, "title": "tf.math.confusion_matrix InvalidArgumentError about incompatible shapes", "body": "I need to train a model using a custom score that is computed using TP, TN, FP, FN (values from confusion matrix). This is my custom metric:\r\n```\r\nclass MyScore(Metric):\r\n  def __init__(self, name='my_score', **kwargs):\r\n    super().__init__(name=name, **kwargs)\r\n    self.cost = self.add_weight(name='cost', initializer='zeros')\r\n    self.misprediction_cost = self.add_weight(name='misprediction_cost', initializer='zeros')\r\n    self.weighted_samples = self.add_weight(name='weighted_samples', initializer='zeros')\r\n    self.score = self.add_weight(name='score', initializer='zeros')\r\n    self.tp = self.add_weight(name='tp', initializer='zeros')\r\n    self.tn = self.add_weight(name='tn', initializer='zeros')\r\n    self.fp = self.add_weight(name='fp', initializer='zeros')\r\n    self.fn = self.add_weight(name='fn', initializer='zeros')\r\n  \r\n  def update_state(self, y_true, y_pred, sample_weight=None):\r\n    matrix = tf.math.confusion_matrix(y_true, y_pred)\r\n    self.tp += matrix[0][0]\r\n    self.tn += matrix[0][1]\r\n    self.fp += matrix[1][0]\r\n    self.fn += matrix[1][1]\r\n    self.cost.assign((self.tn + self.fp)/(self.tp + self.fn))\r\n    self.misprediction_cost.assign(self.fn * self.cost + self.fp)\r\n    self.weighted_samples.assign(self.tn + self.fp + self.cost * (self.tp + self.fn))\r\n    self.score.assign(1.0 - self.misprediction_cost / self.weighted_samples)\r\n\r\n  def result(self):\r\n    return self.score\r\n\r\n  def reset_state(self):\r\n    self.tp.assign(0)\r\n    self.tf.assign(0)\r\n    self.fp.assign(0)\r\n    self.fn.assign(0)\r\n    self.cost.assign(0.0)\r\n    self.misprediction_cost.assign(0.0)\r\n    self.weighted_samples.assign(0.0)\r\n    self.score.assign(0.0)\r\n```\r\nBut confusion_matrix() fails on its last line:\r\n ```\r\n/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: in user code:\r\n\r\n    <ipython-input-17-ad2031fe9bf3>:20 update_state  *\r\n        matrix = tf.math.confusion_matrix(y_true, y_pred)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/confusion_matrix.py:198 confusion_matrix\r\n        shape=math_ops.cast(shape, dtypes.int64))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:8997 scatter_nd\r\n        _ops.raise_from_not_ok_status(e, name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:6897 raise_from_not_ok_status\r\n        six.raise_from(core._status_to_exception(e.code, message), None)\r\n    <string>:3 raise_from\r\n        \r\n\r\n    InvalidArgumentError: Dimensions [0,2) of indices[shape=[512,2,1]] must match dimensions [0,2) of updates[shape=[512,1]] [Op:ScatterNd]\r\n```\r\nBut if i add a debug `print(y_true.shape, y_pred.shape)` into `update_state()` i get `(512, 1) (512, 1)`!", "comments": ["@8549  In order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here. please do let us know which version of tf you are using. Thanks!", "```\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, InputLayer\r\n\r\ndef build_nn():\r\n    model = Sequential([\r\n      InputLayer(input_shape=(13,)),\r\n      Dense(units=64, activation='relu'),\r\n      BatchNormalization(),\r\n      Dropout(0.25),\r\n      Dense(units=32, activation='relu'),\r\n      BatchNormalization(),\r\n      Dense(units=1, activation='sigmoid')\r\n    ])\r\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[MyScore()], run_eagerly=True)\r\n    return model\r\n\r\nX = pd.read_csv('heart.csv')\r\ny = X.pop('target')\r\nmodel = build_nn()\r\nhistory = model.fit(X, y, epochs=5)\r\n```\r\n[Here is a MWE](https://colab.research.google.com/drive/1YToXyDzQmsoe1KSvpopgPCOc2dZZOy2b?usp=sharing). It happens with tf 2.5.0.", "@Saduf2019 I am able to reproduce the error in [**`TF v2.5`**](https://colab.research.google.com/gist/kumariko/19f4ea20e7fc955cf51b782552559f47/untitled6.ipynb#scrollTo=ZSvy7S_y0qRw) and [**`TF v2.4`**](https://colab.research.google.com/gist/kumariko/97c1ee3ae75af54c8375a010b67d265b/51077.ipynb) Please find the gists for your reference . Thanks!", "@8549 \r\nCould you please refer to [similar issue](https://stackoverflow.com/questions/65144547/keras-model-fit-valueerror-the-outer-2-dimensions-of-indices-shape-1-11-1-mus), [link1](https://github.com/keras-team/keras/issues/11749) .\r\n\r\nThis is not a bug or feature request, for any further queries you may open an issue at tensorflow discussion forum.", "I am sorry, but I couldn't find any help for my problem in those two links. If this is not a bug, I would be very grateful if you could help me fix my code in order to use confusion matrix values in my metric.", "@8549 \r\nCan you open an issue in tensorflow discussion forum as there is a larger community there to guide you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51077\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51077\">No</a>\n"]}, {"number": 51076, "title": "__iter__() is only supported inside of tf.function or when eager execution is enabled", "body": "**System information**\r\n- Tensorflow version: 2.2.0 \r\n- Python version: 3.8.6\r\n\r\n![image](https://user-images.githubusercontent.com/36669308/127742743-1fcc6fe6-24a3-40cc-9433-0d244fb54276.png)\r\n\r\nIt working in tensorflow 1.10.1 and python 3.6.5, but not 2.2.0\r\nHow can anyone resolve it, please?\r\nThanks", "comments": ["@nhutthanh340 Could you please have a look at the [link1](https://stackoverflow.com/questions/63182524/runtimeerror-iter-is-only-supported-inside-of-tf-function-or-when-eager-e) ,[link2](https://stackoverflow.com/questions/55576133/tensorflow-2-0-dataset-iter-is-only-supported-when-eager-execution-is-enab/56736763) which are similar issues mentioned in stackoverflow and let us know if it helps ? Thank you!", "I have tried, but still error", "The data in my code is batch inputs", "In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51076\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51076\">No</a>\n"]}, {"number": 51075, "title": "Linux setup guide update for Ubuntu 20.04 ", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu#install_cuda_with_apt\r\n\r\n## Description of issue (what needs changing):\r\n\r\nUbuntu 20.04 installation guide for new CUDA and CUDnn versions.\r\n\r\n### Clear description\r\n\r\nSince new LTS released by Ubuntu, maybe CUDA installation can be updated.\r\n\r\n### Correct links\r\n\r\nNone\r\n\r\n### Parameters defined\r\n\r\nNone\r\n\r\n### Returns defined\r\n\r\nNone\r\n\r\n### Raises listed and defined\r\n\r\nNone\r\n\r\n### Usage example\r\n\r\nNone\r\n\r\n### Request visuals, if applicable\r\n\r\nNone\r\n\r\n### Submit a pull request?\r\n\r\nNone\r\n", "comments": ["@omerferhatt ,\r\n\r\nSimilar issue has been tracked with #43693.Can you please subscribe the issue to get the update for Ubuntu 20.04.Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51075\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51075\">No</a>\n"]}, {"number": 51073, "title": "INFO:tensorflow:Assets written to: C:\\Users\\TFLab\\AppData\\Local\\Temp\\tmpdw25wybi\\assets", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installation (pip package or built from source):\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n#### Option A: Reference colab notebooks\r\n\r\n1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.\r\n2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).\r\n\r\n```\r\n(You can paste links or attach files by dragging & dropping them below)\r\n- Provide links to your updated versions of the above two colab notebooks.\r\n- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.\r\n```\r\n\r\n#### Option B: Paste your code here or provide a link to a custom end-to-end colab\r\n\r\n```\r\n(You can paste links or attach files by dragging & dropping them below)\r\n- Include code to invoke the TFLite Converter Python API and the errors.\r\n- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.\r\n```\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\n- Model produces wrong results and/or has lesser accuracy.\r\n- Model produces correct results, but it is slower than expected.\r\n\r\n### 4. (optional) RNN conversion support\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I am not sure I follow your issue. Can you please elaborate what you are trying do? and where you are hitting problems?\r\nPerhaps you can share a code snippet to reproduce the error. Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51072, "title": "Can sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix be used in the graph mode?", "body": "tensorflow 2.5\r\n\r\nWhen I run `sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix` this function in the graph mode, it gives out the error of `    ValueError: Invalid rank: -1.  Expected a known rank of either 2 or 3. for '{{node SparseTensorToCSRSparseMatrix}} = SparseTensorToCSRSparseMatrix[T=DT_DOUBLE](SparseConcat_4, SparseConcat_4:1, SparseConcat_4:2)' with input shapes: [?,?], [?], [?].`It seems that this function cannot recognize the rank of csr matrix. However, if I run the function not in the graph mode, it works well without any debug. Why? \r\n ", "comments": ["from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops", "@sjtusmartboy ,\r\n\r\nCan you please share a reproducible code that supports your statement so that the issue can be easily understood? Thanks!", "I'm so sorry because the code requires the local dataset which is too large. Some more clues:\r\n1. The parameter of  `sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix` is from the dataset.from_generator. \r\n2. The same kind of error occurs where I use `tensor.shape` in the parameter of `tf.slice` the graph, but no error if I use `tf.shape(tensor)`to get the shape of a tensor in the graph.\r\n\r\n` index_b = tf.slice(adjacency_indices, [0, 0], [tf.shape(adjacency_values)[0], 1])`  ok\r\n` index_b = tf.slice(adjacency_indices, [0, 0], [adjacency_values.shape[0], 1])`  error", "@sjtusmartboy ,\r\n\r\nWithout the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, could you please provide completed code.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51072\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51072\">No</a>\n"]}, {"number": 51071, "title": "Add version to Zenodo", "body": "I need to cite a specific version of TensorFlow in a paper -- Any chance you could add 2.3.1 to https://zenodo.org/record/4724125?\r\n\r\nEDIT: this is no bug -- please change to Feature Request/Other Issues.", "comments": ["@dmey There is version TF2.3.3 listed there, the only difference between TF2.3.1 and 2.3.3 is security patches. Can you use that TF2.3.3 for citation? I think we may have no plans to go back and add older versions. Thanks!", "@jvishnuvardhan thanks and not really. The requirements are to cite the exact same version used however I will work around this by updating the TF version used in my repo -- I see your point. Feel free to close this issue now.", "@dmey Thanks!"]}, {"number": 51069, "title": "[Cherrypick2.6] Update XNNPACK dependency", "body": "PiperOrigin-RevId: 386400181\r\nChange-Id: Ie128b1fea6a6dfa80913c47c9de3945b09f5921a\r\n\r\nXNNPACK build error fixes.\r\nFixes an error in the XNNPACK enabled build of TensorFlow Lite by Bazel. #50920\r\nI have confirmed that the build finishes successfully on armhf and aarch64, x86_64.", "comments": ["@Maratyszcza @terryheo could you take a look at this PR?", "LGTM as well"]}, {"number": 51068, "title": "Prevent division by 0 in common shape functions.", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51068) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 51067, "title": "Fix a shape inference issue leading to nullptr deref.", "body": "PiperOrigin-RevId: 387712259\nChange-Id: I7e670772b259c068a501a187cd89f18773bb95a1", "comments": []}, {"number": 51066, "title": "Prevent dereferencing of null pointers in TFLite's `add.cc`.", "body": "PiperOrigin-RevId: 387244946\nChange-Id: I56094233327fbd8439b92e1dbb1262176e00eeb9", "comments": []}, {"number": 51065, "title": "Prevent a segfault in shape inference due to bad inputs.", "body": "PiperOrigin-RevId: 387737970\nChange-Id: Ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9", "comments": []}, {"number": 51064, "title": "Prevent a CHECK-fail due to empty tensor input in `map_stage_op.cc`", "body": "PiperOrigin-RevId: 387737906\nChange-Id: Idc52df0c71c7ed6e2dd633b651a581932f277c8a", "comments": []}, {"number": 51063, "title": "Add remaining validation to `sdca_internal.cc`", "body": "PiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808", "comments": []}, {"number": 51062, "title": "Prevent nullptr deref in validation of indexes in map ops.", "body": "PiperOrigin-RevId: 387738023\nChange-Id: I83d18d36a7b82ffd2a40b5124a4e5b4c72238f27", "comments": []}, {"number": 51061, "title": "Prevent overflow due to integer conversion to unsigned.", "body": "PiperOrigin-RevId: 387738045\nChange-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebe", "comments": []}, {"number": 51060, "title": "Prevent CHECK-fail/heap OOB in UpperBound and LowerBound", "body": "PiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a", "comments": []}, {"number": 51059, "title": "[cherryPick2.6]", "body": null, "comments": ["Moved to #51100 as this seems to have additional stuff"]}, {"number": 51058, "title": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant", "body": "PiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3", "comments": []}, {"number": 51057, "title": "Add more validation to `RequantizationRangePerChannel`.", "body": "PiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6", "comments": []}, {"number": 51056, "title": "[cheerypick2.6]Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource", "body": null, "comments": []}, {"number": 51055, "title": "Add missing validation to `RaggedTensorToSparse`.", "body": "There needs to be a check that the splits allow for valid ragged tensors.\n\nPiperOrigin-RevId: 387712169\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d", "comments": []}, {"number": 51054, "title": "Fix segfault/heap buffer overflow in `{Experimental,}DatasetToTFRecord` where dataset is numeric.", "body": "Code assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\n\nPiperOrigin-RevId: 387675909\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556", "comments": []}, {"number": 51053, "title": "remove cast of y_true to y_pred data type in sparse categorical cross\u2026", "body": "sparse_categorical_crossentropy in losses.py performs an unnecessary [cast](https://github.com/tensorflow/tensorflow/blob/35639cd25a878ecd7b97c09b48fbcd7119540db2/tensorflow/python/keras/losses.py#L1727) of y_true to y_pred.dtype since it's then [cast](https://github.com/tensorflow/tensorflow/blob/35639cd25a878ecd7b97c09b48fbcd7119540db2/tensorflow/python/keras/backend.py#L4914) to int64 in sparse_categorical_crossentropy in keras.backend.py. Eventual call to sparse_softmax_cross_entropy_with_logits in nn_ops.py is documented to expect int64 as well.\r\n\r\nThis seems to be the same code as in categorical_crossentropy, but causes issues with sparse, especially with mixed precision training and float16 as the loss in precision causes incorrect encodings or labels outside the domain resulting in incorrect or nan loss. With float16, issues start with a couple thousand labels and a couple hundred labels with bfloat16.\r\n\r\nThe error can be found in this [notebook](https://colab.research.google.com/drive/1oRbNOnCo1i2HcXD2V4_-D1Bz2EVxiT65)\r\n\r\nThe [PR](https://github.com/keras-team/keras/pull/15015) in Keras repository has been merged .", "comments": ["Closing this PR since [same](https://github.com/keras-team/keras/pull/15015) merged in keras-team/keras repo.  Thank you.\r\n@qlzh727"]}, {"number": 51052, "title": "issue with running forward passes using saved model format converted from a checkpoint ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I used a script in tf object detection API V2\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tried TF 2.3, 2.4, 2.5, 2.6,0-rc0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: RTX 3080 Max-Q 8 GIG\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI fine tuned faster_rcnn_resnet50_keras model from the TF object detection API on my own dataset and I used a script (exporter_main_v2) under `models/research/object_detection/` to convert one of my checkpoints to a saved model format to serve in a Golang application. I can load the saved model files in Golang using TF Golang client but when I do a forward pass I get the following error:\r\n```\r\n2021-07-30 15:45:06.876593: I tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 1198184 microseconds.\r\n{\"severity\":\"info\",\"timestamp\":\"2021-07-30T15:45:07.743500777Z\",\"caller\":\"/go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_init.go:30\",\"message\":\"Loading Tensorflow Model labels: /go/src/bitbucket.org/ehsai/doc-structure/models/classifiers/document_structure/object_detection/v14\"}\r\n2021-07-30 15:45:21.226358: E tensorflow/core/framework/tensor.cc:555] Could not decode variant with type_name: \"tensorflow::TensorList\".  Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?\r\n2021-07-30 15:45:21.226403: W tensorflow/core/framework/op_kernel.cc:1744] OP_REQUIRES failed at constant_op.cc:82 : Invalid argument: Cannot parse tensor from tensor_proto.\r\n2021-07-30 15:45:21.255391: E tensorflow/core/framework/tensor.cc:555] Could not decode variant with type_name: \"tensorflow::TensorList\".  Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?\r\n2021-07-30 15:45:21.255454: W tensorflow/core/framework/op_kernel.cc:1744] OP_REQUIRES failed at constant_op.cc:82 : Invalid argument: Cannot parse tensor from proto: dtype: DT_VARIANT\r\ntensor_shape {\r\n}\r\nvariant_val {\r\n  type_name: \"tensorflow::TensorList\"\r\n  metadata: \"\\001\\000\\001\\377\\377\\377\\377\\377\\377\\377\\377\\377\\001\\030\\001\"\r\n}\r\n\r\n{\"severity\":\"error\",\"timestamp\":\"2021-07-30T15:45:21.265370446Z\",\"caller\":\"/go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_run.go:135\",\"message\":\"An error occurred during forwad pass, err=Cannot parse tensor from proto: dtype: DT_VARIANT\\ntensor_shape {\\n}\\nvariant_val {\\n  type_name: \\\"tensorflow::TensorList\\\"\\n  metadata: \\\"\\\\001\\\\000\\\\001\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377\\\\001\\\\030\\\\001\\\"\\n}\\n\\n\\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/map/TensorArrayV2_1/_0__cf__4}}]]\"}\r\n    suite.go:63: test panicked: runtime error: index out of range [2] with length 0\r\n        goroutine 158 [running]:\r\n        runtime/debug.Stack(0xc001f95710, 0x9f4bc0, 0xc0000fa000)\r\n                /usr/local/go/src/runtime/debug/stack.go:24 +0x9f\r\n        github.com/stretchr/testify/suite.failOnPanic(0xc000d03e00)\r\n                /go/pkg/mod/github.com/stretchr/testify@v1.7.0/suite/suite.go:63 +0x57\r\n        panic(0x9f4bc0, 0xc0000fa000)\r\n                /usr/local/go/src/runtime/panic.go:969 +0x175\r\n        bitbucket.org/ehsai/doc-structure/internal/classifier.(*objectDetectionModelSuite).Test_modelOutputsShape(0xc0043c60a0)\r\n                /go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_test.go:146 +0xb45\r\n        reflect.Value.call(0xc00440b620, 0xc004408550, 0x13, 0xa376d8, 0x4, 0xc000325e30, 0x1, 0x1, 0xc000325cf8, 0x41142a, ...)\r\n                /usr/local/go/src/reflect/value.go:475 +0x8c7\r\n        reflect.Value.Call(0xc00440b620, 0xc004408550, 0x13, 0xc000325e30, 0x1, 0x1, 0x24, 0xcf345, 0x519dc4)\r\n                /usr/local/go/src/reflect/value.go:336 +0xb9\r\n        github.com/stretchr/testify/suite.Run.func1(0xc000d03e00)\r\n                /go/pkg/mod/github.com/stretchr/testify@v1.7.0/suite/suite.go:158 +0x379\r\n        testing.tRunner(0xc000d03e00, 0xc004155cb0)\r\n                /usr/local/go/src/testing/testing.go:1127 +0xef\r\n        created by testing.(*T).Run\r\n```\r\nWhen I tried to load the saved model files in Python using tf.saved_model.load() I had no problem, I could load the model and run a forward pass and I got the exact same predictions using the checkpoint and the saved model filed so this happens only when I load the model in Golang.\r\n\r\nWhat's wired is that when I loaded the saved model files  provided in the object detection model zoo (Pre trained model done by internal people in TF team I guess) I was able to run forward passes in Golang so I think there must be something wrong with the conversion script.  \r\n**Describe the expected behavior**\r\n\r\nI expect to load the saved model files and perform forward passes, I have done this before using TF object detection V1 so this issue happened when I started using TF objection deection V2 to fine a pre trained model on my dataset.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nstep 1: You need to download a pre trained model from  the object detection model zoo (any model) https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\r\nand then you need to use the checkpoint and convert it to a saved model format using the following code:\r\n```\r\nimport tensorflow as tf\r\nfrom PIL import Image, ImageDraw, ImageFont\r\nfrom six import BytesIO\r\nimport numpy as np\r\nfrom object_detection.utils import label_map_util\r\nfrom object_detection.utils import config_util\r\nfrom object_detection.utils import visualization_utils as viz_utils\r\nfrom object_detection.builders import model_builder\r\nfrom object_detection.exporter_lib_v2 import export_inference_graph\r\nimport os\r\nfrom object_detection.protos import pipeline_pb2\r\nfrom google.protobuf import text_format\r\n    \r\npipeline_config_path = path to the pipeline config file available in the downlaoded model folder\r\npipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\r\nwith tf.io.gfile.GFile(pipeline_config_path, 'r') as f:\r\n    text_format.Merge(f.read(), pipeline_config)\r\nmodel_dir =  path to the checkpoint in the downlaoded model\r\nsaved_model_path = a path to save exported saved model files\r\n\r\nexport_inference_graph(\"image_tensor\", pipeline_config, model_dir,  saved_model_path)\r\n```\r\n\r\nRunning the above code generates a folder called saved_model in the saved_model_path directory. You need to load the model in Golang and run a forward pass. Here is the  code to do that. \r\n\r\nstep 2:\r\n```\r\npackage main\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"fmt\"\r\n\t\"image\"\r\n\t\"image/png\"\r\n\t\"os\"\r\n\r\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n\ttf_op \"github.com/tensorflow/tensorflow/tensorflow/go/op\"\r\n)\r\n\r\nfunc main() {\r\n\r\n\ttags := []string{\"serve\"}\r\n\r\n\timagePath := \"Path to a png image to feed to the model\"\r\n\r\n\tmodelDir := \"Path to a directory that has saved model files\"\r\n\ttensorflowModel, err := tf.LoadSavedModel(modelDir, tags, nil)\r\n\tif err != nil {\r\n\t\tos.Exit(1)\r\n\t}\r\n\r\n\timageBytes, err := generateByteArrayFromPngFile(imagePath)\r\n\tif err != nil {\r\n\t\tos.Exit(1)\r\n\t}\r\n\r\n\ttensor, err := tf.NewTensor(string(imageBytes))\r\n\tif err != nil {\r\n\t\tos.Exit(1)\r\n\t}\r\n\r\n\t// Prepare image for forward pass\r\n\tscope := tf_op.NewScope()\r\n\t// @ts-ignore\r\n\tinput := tf_op.Placeholder(scope, tf.String)\r\n\tout := tf_op.ExpandDims(scope,\r\n\t\ttf_op.DecodePng(scope, input, tf_op.DecodePngChannels(3)),\r\n\t\ttf_op.Const(scope.SubScope(\"make_batch\"), int32(0)))\r\n\r\n\touts, err := runScope(scope, map[tf.Output]*tf.Tensor{input: tensor}, []tf.Output{out})\r\n\tif err != nil {\r\n\t\tos.Exit(1)\r\n\t}\r\n\r\n\tmodelOutputs, err := tensorflowModel.Session.Run(\r\n\t\tmap[tf.Output]*tf.Tensor{\r\n\t\t\ttensorflowModel.Graph.Operation(\"serving_default_input_tensor\").Output(0): outs[0],\r\n\t\t},\r\n\t\t[]tf.Output{\r\n\t\t\t// scores\r\n\t\t\ttensorflowModel.Graph.Operation(\"StatefulPartitionedCall\").Output(4),\r\n\t\t\t// classes\r\n\t\t\ttensorflowModel.Graph.Operation(\"StatefulPartitionedCall\").Output(2),\r\n\t\t\t// bounding boxes\r\n\t\t\ttensorflowModel.Graph.Operation(\"StatefulPartitionedCall\").Output(1),\r\n\t\t},\r\n\t\tnil)\r\n\r\n\tif err != nil {\r\n\t\tos.Exit(1)\r\n\t}\r\n\r\n\tfmt.Println(modelOutputs)\r\n\r\n}\r\n\r\nfunc runScope(s *tf_op.Scope, inputs map[tf.Output]*tf.Tensor, outputs []tf.Output) ([]*tf.Tensor, error) {\r\n\tgraph, err := s.Finalize()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tsession, err := tf.NewSession(graph, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer session.Close()\r\n\treturn session.Run(inputs, outputs, nil)\r\n}\r\n\r\nfunc generateByteArrayFromPngFile(filePath string) ([]byte, error) {\r\n\texistingImageFile, err := os.Open(filePath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer existingImageFile.Close()\r\n\r\n\timageData, imageType, err := image.Decode(existingImageFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif imageType != \"png\" {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tpngBytesBuffer := new(bytes.Buffer)\r\n\tpng.Encode(pngBytesBuffer, imageData)\r\n\r\n\treturn pngBytesBuffer.Bytes(), nil\r\n}\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@atahmasb,\r\n\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tilakrayal This issue is more related to tf object detection API and I think here is more related to that, isn't it?", "@atahmasb ,\r\n\r\nAs mentioned tf object detection model issues will be tracked in Tensorflow Models repo. So please feel free to move this issue to closed status and create new issue in models repo from [here](https://github.com/tensorflow/models/issues/new/choose).Thanks!", "@tilakrayal  I see, thanks. I'll move it to models repo.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51052\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51052\">No</a>\n"]}, {"number": 51051, "title": "Traing is very slow when add a custom layers. I found this tensor ops  run on cpu not on gpu,I don't konw why?", "body": "tensorFlow version (use command below): tensorflow 2.4\r\nPython version: 3.7.9\r\nCUDA/cuDNN version: 10.1\r\n\r\nTraing is very slow when add a custom layers. I found this tensor ops  run on cpu not on gpu,I don't konw why?\r\n\r\n**L2 = RuleLayer(100,420,4, 3, name='ruleLayer')(L1)**\r\n\r\n```\r\nclass RuleLayer(keras.layers.Layer):\r\n    def __init__(self,batch_size,time_steps, n_input, n_memb, **kwargs):\r\n        super(RuleLayer, self).__init__( **kwargs)\r\n        self.ts = time_steps\r\n        self.n = n_input\r\n        self.m = n_memb\r\n        self.batch_size = batch_size\r\n\r\n    def build(self, batch_input_shape):\r\n        #self.batch_size = batch_input_shape[0]\r\n        # self.batch_size = tf.shape(batch_input_shape)[0]\r\n        super(RuleLayer, self).build(batch_input_shape)  # Be sure to call this at the end\r\n        \r\n    def call(self, input_):\r\n        #for d in range(1,self.n):\r\n            \r\n        CP_batch = []\r\n        # a tensor object is not assignable*, so you cannot use it on the left-hand side of an assignment.\r\n        # build a Python list of tensors, and tf.stack() them together at the end of the loop:\r\n        for batch in range(self.batch_size):            \r\n            CP = []\r\n            for ts in range(0,self.ts):\r\n                cp = input_[batch,ts,:,0]\r\n                c_shape = [1]\r\n                xd_shape = [self.m]\r\n                \r\n                for d in range(1,self.n):\r\n                    # append shape indizes\r\n                    c_shape.insert(0,self.m)\r\n                    xd_shape.insert(0,1)\r\n                    # get cartesian product for each dimension\r\n                    #xd = tf.reshape(input_[batch,ts,:,d], (xd_shape))\r\n                    #c = tf.reshape(cp,(c_shape))\r\n                    #cp = tf.matmul(c , xd)                    \r\n                    cp = tf.matmul( tf.reshape(cp,(c_shape)) , tf.reshape(input_[batch,ts,:,d], (xd_shape)))                    \r\n                    tf.print(\"Is there a GPU available: \"),\r\n                    tf.print(tf.config.list_physical_devices(\"GPU\"))\r\n                    tf.print(\"Is the Tensor on GPU #0:  \"),\r\n                    tf.print(cp.device.endswith('GPU:0'))\r\n                    \r\n                flat_cp = tf.reshape(cp,(1, self.m**self.n))\r\n                CP.append(flat_cp)\r\n            CP = tf.reshape(CP,(1, self.ts,self.m**self.n))\r\n            CP_batch.append(CP)\r\n\r\n        return tf.reshape(tf.stack(CP_batch), (self.batch_size,self.ts, self.m**self.n))\r\n\r\n    def compute_output_shape(self, batch_input_shape):\r\n        if self.n == 1:\r\n            return tf.TensorShape([self.batch_size, self.ts,self.m])\r\n        else:\r\n            return tf.TensorShape([self.batch_size, self.ts,self.m** self.n])\r\n    \r\n    def get_config(self):\r\n        config = {\r\n            'time_steps':  self.ts,\r\n            'n_input': self.n,\r\n            'n_memb': self.m,\r\n            'batch_size':self.batch_size\r\n        }\r\n        base_config = super(RuleLayer, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n\r\n```\r\n\r\nIt tooks me almost 2 hours/epoch on my computer .\r\nEpoch 1/150\r\nIs there a GPU available: \r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nIs the Tensor on GPU #0:  \r\nFalse\r\nIs there a GPU available: \r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nIs the Tensor on GPU #0:  \r\nFalse\r\nIs there a GPU available: \r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nIs the Tensor on GPU #0:  \r\nFalse\r\nIs there a GPU available: \r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nIs the Tensor on GPU #0:  \r\nFalse\r\nIs there a GPU available: \r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nIs the Tensor on GPU #0:  \r\nFalse\r\n", "comments": ["@jackyesf  In order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51050, "title": "[CherryPick2.6]Fix bug that could cause map_fn to produce incorrect results (rather than an error) when mapping over a ragged tensor with an inappropriate fn_output_signature.  (Note: there are cases where the default value for fn_output_signature is not appropriate, so the user needs to explicitly specify the correct output signature.)", "body": "PiperOrigin-RevId: 387606546\nChange-Id: Ib4ea27b9634e6ab413f211cfe809a69a90f0e2cd", "comments": []}, {"number": 51049, "title": "using `tf.image.*` module for one channel or more than three channel? ", "body": "**Basic info**\r\n\r\n- TensorFlow 2.4\r\n- Colab / Kaggle Platform \r\n\r\n## Question\r\n\r\nIn `tf`, we have this module [`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image) to perform various image processing operations. If I'm not mistaken, most of the operations require an RGB image, e.g (`h, w, channel == 3`). However, for a reason, I need them to work on one channel (`h, w, channel == 1`) or more than three-channel (`h, w, channel > 3`); basically for a 3D model (..medical imaging). \r\n\r\n## Description \r\n\r\nLet's say, a 3d data set where each sample contains 100 sequences of frames and so technically for a sample, the shape would be (`h, w, 100`). Now, from these 100 frames 5of a sample, there are 4 modalities, and we pick 5 frames for each of these 4 modalities and end up the data set the shape of (`h, w, 20`). \r\n\r\nNow, from this point, we need to do data augmentation with the data set the shape of (`h, w, 20`). In summary\r\n\r\n```\r\n(1st modalities): h, w, 5   <- same augmentations through all 5 channel \r\n(2nd modalities): h, w, 5   <- same augmentations through all 5 channel \r\n(3rd modalities): h, w, 5   <- same augmentations through all 5 channel \r\n(4th modalities): h, w, 5   <- same augmentations through all 5 channel \r\n```\r\n\r\n**How can we apply augmentation on each modality with this shape (`h, w, 5`)?**\r\n\r\n---\r\n\r\nHowever, if we take only 1 frame from these 4 modalities, then in order to perform `tf.image.*` operation on these frames, there is a dirty approach. So, if we have some like as follows: \r\n\r\n```\r\n(1st modalities): h, w, 1   <- same augmentations through all channel \r\n(2nd modalities): h, w, 1   <- same augmentations through all channel \r\n(3rd modalities): h, w, 1   <- same augmentations through all channel \r\n(4th modalities): h, w, 1   <- same augmentations through all channel \r\n```\r\n\r\nthen we can do something like below, for example: \r\n\r\n```python\r\n# split them first \r\nsplit_img <- tf.split(h, w, 4)\r\n\r\naug_img = [] # will contain augmented image \r\n\r\nfor i, frame in enumerate(split_img): # iterate each of the frame \r\n   print(frame.shape) # h, w, 1  \r\n\r\n   # repeat 3 times to make fake rgb type. \r\n   img = tf.repeat(frame, repeats=3, axis=-1)\r\n   print(img.shape) # h, w, 3\r\n\r\n   # data augmentaiton with tf.image.* module \r\n   # seed ensure same augmentation for \r\n   # particular modality \r\n   img = tf.image.stateless_random_*(img , seed=(i, 2))\r\n   print(img.shape) # h, w, 3\r\n   \r\n   # split the rgb and go back to previous state \r\n   img, _, _ = tf.split(img, 3, axis=-1)\r\n   print(img.shape) # h, w, 1\r\n \r\n   # appending augmented image \r\n   aug_img.append(img)\r\n\r\n# lastly concate all augmented modalites \r\nimg = tf.concat(aug_img, axis=-1)\r\nprint(img.shape) # h, w, 4\r\n```\r\n\r\n\r\n\r\n", "comments": ["This also brings (I think) another issue, how to apply **batch processing** using `tf.image.*` module efficiently? I've crossed @mrry answer on SO, [here](https://stackoverflow.com/a/38922451), it's increasing the data loading time too much.  \r\n\r\n\r\n\r\n", "@innat,\r\nImage Operations with Single Channel should be possible by converting an Image from RGB to Grey Scale and then use that converted Image for the Operations. However, as per my understanding, it can't be used for 3D Images. ", "@rmothukuru \r\nyes, you're right, thanks. \r\n\r\nMay I know about the batch processing? Is [this](https://stackoverflow.com/a/38922451/9215780) currently the only optimizxed workaround? ", "@innat,\r\nI think you can use [tf.data](https://www.tensorflow.org/guide/data#batching_tensors_with_padding) for Batching. ", "@rmothukuru \r\nthank you, I'm already using `tf.data` api for batching. But for some reason still, it's performing slow. So, I'm just wondering if I'm missing some features to make it more feasible and fast efficient. ", "@innat \r\nI think what your looking for is called ```tf.keras.layers.experimental.preprocessing```. Preprocessing layers do images ops in batch, while ```tf.image``` and ```tf.keras.preprocessing.image``` do in single image.\r\nmore about preprocessing layers in https://www.tensorflow.org/guide/keras/preprocessing_layers\r\n", "@GdoongMathew \r\nThanks for your suggestion. I've already used keras preprocessing layers. An issue with that is, generally, it can be applied only on the 2D data set. But as we mentioned above, it needs to be done on the 3D data set. I've raised an [issue here](https://github.com/keras-team/keras/issues/15046) regarding the keras proc layers. But the built-in 2d image processing layer in keras can be applied to 3D data set with a bit of modification, [mention here](https://github.com/keras-team/keras/pull/15137#issuecomment-895198025). \r\n\r\nHowever, for the above query, I'm not looking for the keras solution rather tf only, with the `tf.image.random*` functionalities. IMO, it should be supported, batch processing. ", "For future reference, [Here](https://www.kaggle.com/ipythonx/tf-3d-2d-model-for-brain-tumor-classification/notebook#3D-Augmentation) is some minimal implementation regarding the issue."]}]