[{"number": 3317, "title": "handling multiple graphs", "body": "In numerous locations in the documentation, it has been mentioned that it is possible to handle multiple `Graph`s, but I couldn't find any example. \n\nSince `Session` only support a single `Graph`, it seems the only way of doing it is to create multiple `Session` instances. \n\nIs it **safe** to have multiple instances `Session` at the same time? \nif not, what is the proper way of handling multiple `Graph`s? \n\nThanks\n", "comments": ["You can do both ways:\n1. Create multiple sessions;\n2. Create a big graph which includes multiple small graphs.\n\nAnd they can share the same set of variables and you just need to make sure it picks the right graph/session to run.\n", "Please reopen if you have further questions.\n", "Did anyone actually create an explicit (maybe small) example using either of the two suggestions?\n", "I want an example, too. In principle I know how it works, but what's the details?"]}, {"number": 3316, "title": "Branch 127440874", "body": "", "comments": []}, {"number": 3315, "title": "Adding info and links regarding Bitfusion's TF AMI", "body": "Adding a link and info for TF AMI to the resources page, in the community section.  \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn Thu, Jul 14, 2016 at 10:00 AM, googlebot notifications@github.com\nwrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> \ud83d\udcdd _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3315#issuecomment-232690726,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/APW7q_xXJFgouY2yc-GKDVpzmVJecn6Jks5qVk8CgaJpZM4JMhcG\n> .\n", "(you have to sign the CLA for us to accept this)\n", "I have signed, to play it safe I went through the process again and it\nconfirmed I have already signed. (\"It looks like you've already signed this\nCLA.\")\n\nOn Thu, Jul 14, 2016 at 4:39 PM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> (you have to sign the CLA for us to accept this)\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3315#issuecomment-232800037,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/APW7qwtT_Jh9ao9F4BubN63U5eVITCYtks5qVqx0gaJpZM4JMhcG\n> .\n", "cool -- does the commit email on the commit match the email address you used to sign the CLA?\n", "Yup - should.\n\nOn Thu, Jul 14, 2016 at 5:05 PM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> cool -- does the commit email on the commit match the email address you\n> used to sign the CLA?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3315#issuecomment-232806068,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/APW7q6YK2AgoztbChjm1NfnP20AaoSnlks5qVrKfgaJpZM4JMhcG\n> .\n", "(what's the email, so I can verify?)\n", "sono@bitfusion.io\n\nOn Thu, Jul 14, 2016 at 5:34 PM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> (what's the email, so I can verify?)\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3315#issuecomment-232811837,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/APW7q3VZ5Cg5iWYjq_c0O18vgoEDnqprks5qVrllgaJpZM4JMhcG\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Shortened up the AMI entry and left the single bullet point with some details on the AMI.  \n", "Thanks! \n\nThis will appear on tensorflow.org with the next push, not long from now.\n"]}, {"number": 3314, "title": "Documentation for broadcasting behavior of binary elementwise operations", "body": "PR for #508. Uses @mrry's example in the SO question referenced in the issue.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3313, "title": "iOS tensforflow example ? ", "body": "Hi,\n\nI observed that in the latest version of tensorflow example folder, there is no iOS example, though it was available in the previous version. Could you please direct me on where do I find the iOS example for tensorflow.\n\nThanks  \n", "comments": []}, {"number": 3312, "title": "drawing random numbers in a loop", "body": "Hey tf-community,\n\nPlease consider the following example:\n`import tensorflow as tf`\n`x = tf.random_normal(shape=(1,), mean=0.0, stddev=1.0)`\n`sess = tf.Session()`\n`sess.run([x for _ in xrange(4)])`\n\nThis results in a list of four identical numbers. What I would expect, however, is a list of 4 independently drawn numbers. Is this behaviour by design? And if so, is there a way to specify that I would like to have four different numbers? \n\nDrawing a vector of numbers is not applicable to my situation...\n\nThx,\nMat\n", "comments": ["Can you give it a different seed everytime you call it? Maybe related to the time.\n", "You are just fetching the value for **x** 4 times when you running the session. The session run is not sampling from the normal distribution every time.\n\nInstead something like below will work?!\n`x = tf.random_normal(shape=(4,), mean=0.0, stddev=1.0)`\n`sess = tf.Session()`\n`sess.run(x)`\n", "For completeness, if you were to draw actually multiple times in different calls to sess.run like in `[sess.run(x) for _ in xrange(4)]`, you'd also get four different random numbers, or if you had different tensors (`x = [tf.random_normal(shape=(1,), mean=0.0, stddev=1.0) for _ in xrange(4)]; sess.run(x)`) - like @shekkizh says you have just one tensor (which has exactly one value during a computation) and read out its value 4 times.\n", "Thx for the replies. Although they explain what is happening, they do not provide me with a solution to my problem.  \nWhat I am trying to do is to sample repeatedly from a model I trained and to compute, for example, the average of the individual results. For simplicity and maybe efficiency in my code, I thought it might be possible to avoid doing a '[sess.run(x) for _ in xrange(4)]' call, which is what I have been doing so far. \n"]}, {"number": 3311, "title": "Bug with tensorflow.random_normal() when using placeholders and last dimension is 1 ", "body": "tensorflow.shape(x) gives ? for the last dimension when the last dimension is 1.\nThis is a problem if you have layers or inputs which are only one dimensional. \n### Environment info\n\nOperating System: OSX\nTensorflow 0.9.0\n\nInstalled version of CUDA and cuDNN: \nproblem not related to CUDA or cuDNN\n\n**Edit:** thanks to @cwhipkey I noticed I mischaracterized the problem, edited version below.\n### Steps to reproduce\n\n`import tensorflow as tf`\n`n=1`\n`x = tf.placeholder(tf.float32, shape=(None, None, n), name='x')`\n`shp = tf.shape(x)`\n\nshp is (?,?,n)  as it should be.\n\nBut then if I use shp to create a random_normal tensor of the same shape, it will fail if n==1.\n\n`noise = tf.random_normal(shp,mean=0,stddev=1)`\n\n`print(noise.get_shape(noise))`\nhas output (?,?,n) if n>1 but output (?,?,?) if n==1.\n\nThis is a problem, because if I then do \n`xtilde= x+noise`\n\nthis will give me an error if n==1.\nSpecifically in my case:\n\n>   File \"/anaconda/envs/hrnn/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 630, in _dynamic_rnn_loop\n>     \"Input size (depth of inputs) must be accessible via shape inference, \"\n> ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n\nwhen I feed this xtilde to dynamic_rnn\n`rnn.dynamic_rnn(rnn, xtilde,\n                                                       initial_state=self.hhat_combined_init,\n                                                       scope='RNN')`\nI get no such error if n>1.\n", "comments": ["What are you printing from shp to see the (?,?,1)?  Against the head version, I tried the following and could not reproduce it.  I also tried to run shp in my session, but that requires an actual value of the placeholder in order to run.\n\nimport tensorflow as tf\n n=1\n x = tf.placeholder(tf.float32, shape=(None, None, n), name='x')\n shp = tf.shape(x)\n print(str(shp))\n print(x.get_shape())\n\nOutput:\nTensor(\"Shape:0\", shape=(3,), dtype=int32)\n(?, ?, 1)\n", "Thank you for looking into it.\nI'm seeing this in the PyCharm debugging mode.\n\nI think you are right, I missidentified the problem. shp is actually ok, the problem occurs while using \n`tf.random_normal(shp,mean=0,stddev=1)`\n\nThis occures inside my _build_graph method of a neural network.\n\nI have the following line:\n\n`xtilde = x + noise_level * tf.random_normal(tf.shape(x),\n                                                                    mean=0.,\n                                                                    stddev=1.)`\n\nwhich fails because\nwhile x.get_shape() = (?,?,1)\ntf.random_normal(tf.shape(x),mean=0,stddev=1).get_shape() = (?,?,?)\n\nand so the addition fails because the tensors are not of the same shape.\n\nSo the problem is that tensorflow.random_normal has fails to be correctly shaped when the last dimension is 1. \n", "A ? in a shape output means \"unknown dimenson value\", and that is\nconsidered compatible with a dimension with a known size.  So I'm not sure\nit would give an error from that step.\n\nDoes it fail when running the model, or while setting up the model?  What\nis the error message you get?\n\nOn Fri, Jul 15, 2016 at 1:21 AM, isabeaups notifications@github.com wrote:\n\n> Thank you for looking into it.\n> I'm seeing this in the PyCharm debugging mode.\n> \n> I think you are right, I missidentified the problem. shp is actually ok,\n> the problem occurs while using\n> tf.random_normal(shp,mean=0,stddev=1)\n> \n> This occures inside my _build_graph methode of a neural network.\n> \n> I have the following line:\n> \n> xtilde = x + noise_level \\* tf.random_normal(tf.shape(x),\n> mean=0.,\n> stddev=1.)\n> \n> which fails because\n> while x.get_shape() = (?,?,1)\n> tf.random_normal(tf.shape(x),mean=0,stddev=1).get_shape() = (?,?,?)\n> \n> and so the addition fails because the tensors are not of the same shape.\n> \n> So the problem is that tensorflow.random_normal has fails to be correctly\n> shaped when the last dimension is 1.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3311#issuecomment-232891583,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AQw4wY_Jb42pWiJcCfNV2zrQ8MAN28HXks5qV0MngaJpZM4JMXSO\n> .\n", "It fails while setting up the model. \nAs you can see in the above revised original issue post, doing\n`xtilde = x +  tf.random_normal(tf.shape(x), mean=0., stddev=1.)`\n fails with error:\n\n> File \"/anaconda/envs/hrnn/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 630, in _dynamic_rnn_loop\n> \"Input size (depth of inputs) must be accessible via shape inference, \"\n> ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n\nwhen I feed this xtilde to dynamic_rnn\n`rnn.dynamic_rnn(rnn, xtilde,\n                                                       initial_state=self.hhat_combined_init,\n                                                       scope='RNN')`\n", "I used the test body below and get noise always as (?, ?, ?), regardless of n.  xtilde is (?, ?, ?) when n = 1, and (?, ?, 2) when n = 2.\n\nThis is because x + noise might broadcast x onto noise, and when the dim's value is 1 then the output dim could be 1 or the other side.  A fix is to use tf.add_n([x, noise]) - this ends up giving the right shape.   Does this workaround work for you?\n\nIt seems that \"random_normal\" does not infer the output shape no matter what the final dim value.  I think it's because of tensor_util.py's _ConstantValue, where tensor.op.type == \"Shape\" is handled.\n\n```\nn = 1\nx = tf.placeholder(tf.float32, shape=(None, None, n), name='x')\nshp = tf.shape(x)\nnoise = tf.random_normal(shp, mean=0, stddev=1)\nprint(\"noise: \", noise.get_shape())\nxtilde = x + noise  # tf.add_n([x, noise])\nprint(\"xtilde: \", xtilde.get_shape())\n```\n\nOutput:\n\n```\n# Output when n = 1\nnoise:  (?, ?, ?)\nxtilde:  (?, ?, ?)\n\n# Output when n = 2\nnoise:  (?, ?, ?)\nxtilde:  (?, ?, 2)\n```\n", "I'm not sure I understand your explanation completely, but the workaround works and is good enough for my purposes. Thank you! \n", "I also encountered the same problem, tf.random_normal always return a tensor with unknown shape, even when the shape parameter is set to a fixed shape. Should this be classified as a bug?", "@cwhipkey I admit I didn't entirely follow your explanation above either. Would you clarify if this should be considered a bug or not?", "Yes, it is something that could be improved in random normal.\r\n\r\nThe workaround is to do a reshape immediately after the call, or otherwise force the shape to become known.", "I think the shape has been correctly inferred with the most recent master:\r\n```\r\nubuntu@ubuntu:~/$ python\r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> n = 1\r\n>>> x = tf.placeholder(tf.float32, shape=(None, None, n), name='x')\r\n>>> shp = tf.shape(x)\r\n>>> noise = tf.random_normal(shp, mean=0, stddev=1)\r\n>>> print(noise.get_shape())\r\n(?, ?, 1)\r\n>>> n = 2\r\n>>> x = tf.placeholder(tf.float32, shape=(None, None, n), name='x')\r\n>>> shp = tf.shape(x)\r\n>>> noise = tf.random_normal(shp, mean=0, stddev=1)\r\n>>> print(noise.get_shape())\r\n(?, ?, 2)\r\n>>> \r\n```\r\n\r\nMaybe this issue could be closed?", "Closing this per comment from yongtang."]}, {"number": 3310, "title": "warning when running commands with bazel", "body": "Hello, I'm installing tensorflow following instructions of\nhttps://www.tensorflow.org/versions/r0.9/get_started/os_setup.html\nespecially in \"Installing from sources\"\n\nI almost encountered the below warnings when running commands with bazel\nAmong the warnings, I'd like to resolve the warning which says 'in includes attribute of cc_library rule //***_' resolves to '**_*' not in 'third_party'. This will be an error in the future.'\n\nbtw, what does the above warnings mean and why was the warnings occurred?\nAs I saw other person's console outputs through googling, many people also went through the warnings. However, many of them seem to ignore them.\nI'm a little concerned because of the final sentence saying 'This will be an error in the future'\nI'd appreciate any reply, thank you very much\n### Environment info\n\nOperating System: Ubuntu 14.04\nLinux seslab86 3.16.0-76-generic #98~14.04.1-Ubuntu SMP Fri Jun 24 17:04:54 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nInstalled version of CUDA and cuDNN: 7.5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n  316 -rw-r--r-- 1 root root   322936  8\uc6d4 16  2015 /usr/local/cuda/lib64/libcudadevrt.a\n    0 lrwxrwxrwx 1 root root       16  8\uc6d4 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\n    0 lrwxrwxrwx 1 root root       19  8\uc6d4 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n  376 -rwxr-xr-x 1 root root   383336  8\uc6d4 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n  704 -rw-r--r-- 1 root root   720192  8\uc6d4 16  2015 /usr/local/cuda/lib64/libcudart_static.a\n    0 lrwxrwxrwx 1 root root       13  4\uc6d4 11 01:10 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\n60020 -rwxr-xr-x 1 root root 61453024  6\uc6d4  1 22:42 /usr/local/cuda/lib64/libcudnn.so.4\n60020 -rwxr-xr-x 1 root root 61453024  6\uc6d4  1 22:42 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n    0 lrwxrwxrwx 1 root root       17  4\uc6d4 11 01:10 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.4\n60016 -rwxr-xr-x 1 root root 61453024  6\uc6d4  1 22:42 /usr/local/cuda/lib64/libcudnn.so.5.0.4\n60576 -rw-r--r-- 1 root root 62025862  6\uc6d4  1 22:42 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n1.\n2.\n3.\n### What have you tried?\n1. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nWARNING: /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/grpc/WORKSPACE:1: Workspace name in /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/grpc/WORKSPACE (@__main__) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions.\nWARNING: /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/re2/WORKSPACE:1: Workspace name in /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\n\nWARNING: /home/sujin/Desktop/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:59:16: in includes attribute of cc_library rule //google/protobuf:protobuf_lite: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:124:16: in includes attribute of cc_library rule //google/protobuf:protobuf: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:546:16: in includes attribute of cc_binary rule //google/protobuf:pyext/_message.so: 'python/' resolves to 'google/protobuf/python' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:546:16: in includes attribute of cc_binary rule //google/protobuf:pyext/_message.so: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:266:16: in includes attribute of cc_library rule //google/protobuf:protoc_lib: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\n", "comments": ["@martinwicke Could you take a look at this please?\n", "I would not worry about these just yet. We'll have to change things in order to conform to future bazel versions. @damienmg, is this something we can change now (or do we have to change things in protobuf?)\n"]}, {"number": 3309, "title": "contrib/makefile: device_attributes.pb_text.h: No such file or directory", "body": "### Environment info\n\nOperating System: Arch Linux 64-bit\nGCC: 6.1.1\nno CUDA or cdDNN used\n\nTensorflow installed from Git repo sources (v0.9.0).\n### Steps to reproduce\n\n**1.** Get a clean copy tensorflow repository\n**2.** Run `tensorflow/contrib/makefile/download_dependencies.sh`\n**3.** Run `make -f tensorflow/contrib/makefile/Makefile`\n**4.** The build sometimes fails with:\n\n```\nIn file included from tensorflow/core/kernels/stack_ops.cc:21:0:\n./tensorflow/core/common_runtime/device.h:38:65: fatal error: tensorflow/core/framework/device_attributes.pb_text.h: No such file or directory\n #include \"tensorflow/core/framework/device_attributes.pb_text.h\"\n                                                                 ^\ncompilation terminated.\nmake: *** [tensorflow/contrib/makefile/Makefile:322: tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/stack_ops.o] Error 1\nmake: *** Waiting for unfinished jobs....\n```\n\n**5.** Run `make` again and the problem disappears.\n", "comments": ["This reproduces on Ubuntu 16.04.\n", "Please provide details when you tried it on Ubuntu instead.\n", "Have you done this part?:\n\n``` bash\nsudo apt-get install autoconf automake libtool curl make g++ unzip\npushd .\ncd tensorflow/contrib/makefile/downloads/protobuf\n./autogen.sh\n./configure\nmake\nmake check\nsudo make install\nsudo ldconfig # refresh shared library cache\npopd\n```\n\nMore generally, does the issue reproduce when following the steps documented in [this section](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md#building-on-linux)?\n", "Yes, I followed that guide, including installing protobuf.\n", "@satok16: could you take a look at this?  Since I know you've been touching makefile recently.  Thanks!\n", "Could this be caused by `MAKEFLAGS=-j4`? Maybe `make` sometimes builds things in wrong order.\n", "Currently, tensorflow/contrib/makefile/download_dependencies.sh doesn't work due to the change on eigen.BUILD(https://github.com/tensorflow/tensorflow/pull/3288) and can't try reproducing the issue.  Trying to fix it first.\n", "The fix for download_dependencies.sh is here.\nhttps://github.com/tensorflow/tensorflow/pull/3428#issue-166690786\n", "This now occurred also on Raspberry Pi 2 (Raspbian Jessie). It seems a bit random when it occurs.\n", "Apparently, the current Makefile doesn't work with \"-j\" option.  See ./tensorflow/contrib/makefile/build_all_android.sh which is what we currently use.\n", "Is this issue resolved?\r\nCan we close if it is?", "Closing due to inactivity. Feel free to open a new github issue if the problem still persists in recent versions.", "Excuse me, how to resolve this  problem?  Not found  tensorflow/core/framework/device_attributes.pb_text.h when using vs 2015 to compile tensorflow, window 10.", "I got the same error, when I compile tensorflow with VS2015 in Windows 7.\r\nD:\\tensorflow\\tensorflow/core/util/tensor_slice_writer.h(36): fatal error C1083: Cannot open include file: 'tensorflow/core/util/saved_tensor_slice.pb_text.h': No such file or directory (compiling source file D:\\tensorflow\\tensorflow\\core\\kernels\\save_restore_tensor.cc)\r\ncould anyone help? Thanks a lot!\r\n", "Hi @cj741 @hushanxue ,  have you solved the problem? i am using win10 + vs2015 + r1.3", "Hi @kalluwa  ,have you solved the problem? I am using win10+vs2015+r1.7", "@chenjianwp  after i updated my vs2015 to vs2015 update3,  everything works fine.  be sure to use vs2015 **UPDATE 3**\r\n\r\nbut i haven't test r1.7 by the way", "@chenjianwp  you can reference the tutorial i wrote if you know chinese: https://www.zybuluo.com/kalluwa/note/1110511", "@Kalluwa,Thanks ,I have installed vs2015 update3 ,but the problem not be solved . I will reference your turorial.", "If your source code is on disk C, try opening vs in admin mode"]}, {"number": 3308, "title": "contrib/makefile: No session factory registered for the given session options", "body": "### Environment info\n\nOperating System: Arch Linux 64-bit\nGCC: 6.1.1\nno CUDA or cuDNN used\n\nTensorflow installed from Git repo sources. I tried v0.9.0 and current master (`c129591`).\n### Steps to reproduce\n\n**1.** Build `contrib/makefile` (`download_dependencies.sh` + `make`)\n**2.** Link produced `tensorflow-core` to a C++ project\n**3.** Try to create a new TensorFlow session:\n\n``` c++\nSession* session;\nStatus status = NewSession(SessionOptions(), &session);\n```\n\n**4.** Compile succeeds, but running the code gives:\n\n```\nE tensorflow/core/common_runtime/session.cc:69] Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\n```\n\n`tensorflow/contrib/makefile/gen/bin/benchmark` seems to be working.\n", "comments": ["This may be related to #3309 since also that occurs sometimes for me.\n", "The same issue also occurs with the C API and the following code:\n\n``` c\nTF_Session* session = TF_NewStatus();\nTF_SessionOptions* options = TF_NewSessionOptions();\nsession = TF_NewSession(options, status);\n```\n", "This works perfectly (both C++ and C API) if I build `libtensorflow.so` with bazel (instead of using `contrib/makefile`) and then link to `bazel-bin/tensorflow/libtensorflow.so`.\n", "This reproduces also on Ubuntu 16.04.\n", "This also happens on Raspberry Pi (Raspbian Jessie), but #3309 didn't occur there.\n", "Reproduced on Mac OS X (10.11) with current master\nOnly when using contrib/makefile\n", "Could you provide the details when you get the errors on Ubuntu 16?\n", "This occurs exactly the same on Ubuntu 16.04 64-bit with GCC 5.3.1. With exactly the same commands and code it will give this error in runtime:\n\n```\nE tensorflow/core/common_runtime/session.cc:69] Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\n```\n", "@martinwicke Could you take a look at this please?\n", "This is usually a sign that the global constructors that TensorFlow uses to register things like session factories and kernels have been stripped out. The short answer is that you should make sure you build with the right linker options to stop them being stripped. On Linux you will add `-Wl,--allow-multiple-definition -Wl,--whole-archive`, and on OS X `-all_load`. The benchmark binary works because it does this, and it should pick the right combination for your platform.\n\nThe longer explanation is that TensorFlow uses a C++ pattern like this for registering classes (all in pseudo-code):\n\n``` c++\n--- register.h ---\n...\ntemplate<T> Register<T> {\n public:\n    Register<T>(string name) {\n      g_registry[name] = T::Factory();\n    }\n};\n...\n---                   ---\n\n--- some_class.cc ---\n...\nRegister<SomeObject> g_some_register_object(\"SomeObject\");\n---                         ---\n```\n\nThe idea is that the g_some_register_object global will be created when the library is loaded, which will call the constructor, which adds the factory function to the list of registered classes. That allows subsequent code to ask for a \"SomeClass\" by name from the registry, and get back an object created by the factory function.\n\nThe advantage of this approach is that the registration of objects is distributed, so you only have to register a class in the file that it's implemented rather than editing a global list of factories somewhere else. When it works, it's pretty magical.\n\nUnfortunately many linkers see the g_some_register_object global, notice that no other code ever reads or writes it, and so it can be removed without affecting the program at all. What they don't realize is that its constructor has an important side-effect, registering the factory function.\n\nThis is a common problem, so most linkers have some way of turning off this stripping optimization, but it's usually a pretty indiscriminate switch and so may cause your binary size to be larger than it needs to be.\n\nDoes that help?\n", "Thanks. Adding `-Wl,--allow-multiple-definition -Wl,--whole-archive` did fix the \"No session factory registered\" issue, but now I get another one:\n\n```\nFailed to evaluate TensorFlow: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs\n[[Node: dropout/Inv = Inv[T=DT_FLOAT](keep_prob)]]\n```\n\nNote that the exact same code is working with bazel, but fails with contrib/makefile.\n\nI think this might still be related to this issue since the new error mentions `No OpKernel was registered`.\n\nIn addition, while `-Wl,--whole-archive` fixes the first error, it is suboptimal. I have several small binaries that are all using libtensorflow. This linker flag increases the binary size for each of them by around 180 MB. It is huge compared to the minimal size I get without the flag.\n", "> No OpKernel was registered to support Op 'Inv'\n\nThis is actually a different error. If you look at `tensorflow/contrib/makefile/tf_op_files.txt` you'll see a list of the kernel files that are included by default, which doesn't include the `tensorflow/core/kernels/cwise_op_inverse.cc` which defines the Inv kernel.\n\nThis is actually by design, since we have picked a minimal subset of kernels that we expect to be used for inference, skipping those that are likely to only be used for training, since inference is the focus of our mobile build. That's not always an easy thing to estimate however, and here we've missed one that you need.\n\nThe short-term answer is that you can make local changes to `tf_op_files.txt` to add `cwise_op_inverse.cc` to fix your immediate problem (and do something similar with any other kernels you're missing). The better solution is to document what ops are supported more effectively, and offer an option to have a full set of ops too, instead of the current subset.\n\n> This linker flag increases the binary size for each of them by around 180 MB. It is huge compared to the minimal size I get without the flag.\n\nIs this still true if you supply -Os to the whole build process? We tend to see a smaller increase outside of debug builds. You're right though, as I mention above this is a pretty indiscriminate switch and it would be good to figure out a nicer solution.\n", "> Is this still true if you supply -Os to the whole build process? We tend to see a smaller increase outside of debug builds.\n\nSeems that `-Os` does decrease the binary size to 112 MB, but it's still like 100 times larger than it could be.\n", "Thanks for the help. I needed to include all these:\n\n```\ntensorflow/core/kernels/cwise_op_floor.cc\ntensorflow/core/kernels/cwise_op_inverse.cc\ntensorflow/core/kernels/random_op.cc\n```\n\nCompiling and running my programs work now. You might want to add documentation and research if there are better solutions than requiring `--whole-archive`. \n", "Thanks for the update. Since this seems resolved, closing this issue.\n", "I'm having the same issue. Compiling on Ubuntu 16.04 using bazel 0.4.0 and the master branch as of today. I tried the linker options mentioned above (-Wl,--allow-multiple-definition -Wl,--whole-archive) but that didn't help. Still getting the same error message: No session factory registered for the given session options.\n\nMy BUILD file is:\n\n``` python\ncc_binary(\n    name = \"label_image\",\n    srcs = [\n        \"main.cc\",\n    ],\n    copts= [\"-Iexternal/org_tensorflow\"],\n    linkopts = [\"-lm\", \"-Wl,--allow-multiple-definition\", \"-Wl,--whole-archive\"],\n    deps = [\n        \"@org_tensorflow//tensorflow/cc:cc_ops\",\n    ],\n)\n```\n", "@waleedka \r\nI have the same issue. Compiling on Ubuntu 16.04 using bazel 0.5.4. And I tried linker options but didn't work neither. Have you finally solved this issue?", "I am able to use the static c++ tensorflow library in a standalone C++ program but not able to use the static library in a `qmake` project to use that standalone program in other files! I am encountering the error ` No session factory registered for the given session options` on running the successfully compiled program using `qmake`. I am using the linker options for  `-Wl,--allow-multiple-definition, -Wl,--whole-archive` but to no effect. Also, if it helps, I am able to use the static library in a standalone program without using these linker options. ", "@corwinliu @waleedka Chances are you guys needed `//tensorflow/core:direct_session` on the deps list. But if you're building C++ programs with Bazel, it actually gets a little bit more complicated than that. Here's an example PNG -> JPG converter program built by Bazel to explain: https://gist.github.com/jart/c8b84a17ffa9e8e5dfa30342b8feca7a It's statically linked and ends up being about 22MB with no dependencies (11MB stripped.) Although we can make that much lower in the future, once we do some code cleanup on the alwayslink=1 targets.", "@jart Thanks a lot. I found that the tensorflow serving project(https://github.com/tensorflow/serving) is a good example to learn how to build C++ program including the tensorflow headers.", "Use ldd on your binary to figure out if the lib dependencies are being added.\r\nThis changes based on the linux flavor you are using, but some versions of ld, will not link a library unless its is used.\r\nIn the tf case, tensorflow_cc was not being linked to my binary, even though I specified -l tensorflow_cc.\r\nThe solution was to add -Wl,--no-as-needed flag to gcc. GCC processes flags left to right, so specify this flag before you add -ltensorflow*\r\n\r\nldd <binary_name> | grep tensorflow", "How to solve this error in visual studio 2015 ?", "@scm-ns  @theSparta   how to solve this error while linking tensorflow 1.8.0 cmake build to visual studio ?? I am having trouble solving this error :(", "i am using windows 10 :( not linux", "@petewarden \r\nI have the same issue, even! when i link c++ library, extracted from pip package.\r\nUsing of flags -Wl,--allow-multiple-definition -Wl,--whole-archive didn't help me, but i got another error:\r\n\r\n> usr/lib/gcc/x86_64-linux-gnu/6/libgcc.a(_muldi3.o): In function `__multi3':\r\n> (.text+0x0): multiple definition of `__multi3'\r\n> /usr/lib/gcc/x86_64-linux-gnu/6/libgcc.a(_muldi3.o):(.text+0x0): first defined here\r\n> /usr/lib/gcc/x86_64-linux-gnu/6/libgcc.a(_negdi2.o): In function `__negti2':\r\n> (.text+0x0): multiple definition of `__negti2'\r\n> \r\n\r\nAfter that, i added flags: -Wl,--no-as-needed i got again:\r\n\r\n> 2019-09-03 20:44:19.587872: E tensorflow/core/common_runtime/session.cc:81] Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\r\n\r\n\r\nAlso i can't compile this string\r\n`std::cerr << \"tf error: \" << status.ToString() << \"\\n\";`\r\nwithout:\r\n-D_GLIBCXX_USE_CXX11_ABI=0\r\nWhat should i do in order to avoid this issue and don't depend on linking flags ?\r\nWhat's files are responded for this global objects ?\r\nIf python wrapping environment can work with c++ libtensorflow_framework.so.1 then why i can't ?\r\nIs there some hack in order to manually init that factory in my application ?\r\nUbuntu 18.04 gcc 7.3.0 Tensorflow 1.14", "> How to solve this error in visual studio 2015 ?\r\n\r\nI also want to how to solve it in vs2015", "> This is usually a sign that the global constructors that TensorFlow uses to register things like session factories and kernels have been stripped out. The short answer is that you should make sure you build with the right linker options to stop them being stripped. On Linux you will add `-Wl,--allow-multiple-definition -Wl,--whole-archive`, and on OS X `-all_load`. The benchmark binary works because it does this, and it should pick the right combination for your platform.\r\n> \r\n> The longer explanation is that TensorFlow uses a C++ pattern like this for registering classes (all in pseudo-code):\r\n> \r\n> ```c++\r\n> --- register.h ---\r\n> ...\r\n> template<T> Register<T> {\r\n>  public:\r\n>     Register<T>(string name) {\r\n>       g_registry[name] = T::Factory();\r\n>     }\r\n> };\r\n> ...\r\n> ---                   ---\r\n> \r\n> --- some_class.cc ---\r\n> ...\r\n> Register<SomeObject> g_some_register_object(\"SomeObject\");\r\n> ---                         ---\r\n> ```\r\n> \r\n> The idea is that the g_some_register_object global will be created when the library is loaded, which will call the constructor, which adds the factory function to the list of registered classes. That allows subsequent code to ask for a \"SomeClass\" by name from the registry, and get back an object created by the factory function.\r\n> \r\n> The advantage of this approach is that the registration of objects is distributed, so you only have to register a class in the file that it's implemented rather than editing a global list of factories somewhere else. When it works, it's pretty magical.\r\n> \r\n> Unfortunately many linkers see the g_some_register_object global, notice that no other code ever reads or writes it, and so it can be removed without affecting the program at all. What they don't realize is that its constructor has an important side-effect, registering the factory function.\r\n> \r\n> This is a common problem, so most linkers have some way of turning off this stripping optimization, but it's usually a pretty indiscriminate switch and so may cause your binary size to be larger than it needs to be.\r\n> \r\n> Does that help?\r\n\r\nAdd those link flags when compiling tensorflow_cc.so?"]}, {"number": 3307, "title": "NaN values in the learnable parameters with custom initialization, along with lasso regularization", "body": "From what I read online, getting NaN cost values can happen if someone uses a custom cross entropy calculation while doing classification. However, I use the built-in cross entropy calculation provided.\n\nMy problem is different. I have a network that consists of an RNN and a convolutional layer before that. When I initialize the convolutional layer with random values(e.g., normal random or uniform random), I do not experience any problem. However, I use a custom initialization, and start getting NaN gradients right away(i.e., starting from the first batch).\n\nMy filter initialization is as follows: All values in the filter are zero, except a single value is 1. When I initialize the filters in this manner, I start to get NaN gradients starting from the first batch, hence NaN weights and NaN cost in the following batches. \n### Environment info\n\nOperating System: Mac v10.11.3 (El Capitan)\n\nThe output of `ls -l /path/to/cuda/lib/libcud*`:\n\n-rw-r--r-- 1 root root 189170 Mar 24 16:02 libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Mar 24 16:02 libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Mar 24 16:02 libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 311596 Mar 24 16:02 libcudart.so.7.5.18\n-rw-r--r-- 1 root root 558020 Mar 24 16:02 libcudart_static.a\n- The tensorflow version is: 0.9.0rc0\n\nThe whole code is quite messy and complex, . But reproducing the code should not be hard: I initialize convolutional filters with all zeros but one \"1\" value, and I get nan values as gradients in the locations where 0's appear. \n\nOne thing to note is that I apply group lasso regularization to the convolutional filter weights. I realized when regularization lambda is set to a small value, (like 10e-3), the problem did not occur. However, when I chose values that have larger order of magnitude (like 10e-2 or 1), I observed this problem. Values other than the group initialized as \"1\" becomes all Nan.\n\nTo exemplify, suppose I initialize the weights as the matrix on the top, and each column is a group (in group lasso objective). After the first batch of data, the matrix on the bottom is what I get: \n\n0 0 0 0 0\n0 0 0 0 0\n0 0 1 0 0\n0 0 0 0 0\n0 0 0 0 0\n\nbecomes:        \n\nNaN NaN 0.3 NaN NaN \nNaN NaN 0.7 NaN NaN\nNaN NaN  0.1  NaN NaN\nNaN NaN 0.5 NaN NaN\nNaN NaN 0.2 NaN NaN \n\nLong story short; I know how to avoid this problem (using smaller lambda values), but I just wanted to know if there is an explanation for why this problem occur. Is it because of a numerical error, or it is because I am doing something wrong?\n", "comments": ["I finally understood the reason. It's due to numerical instability with the tf.sqrt function. Adding an epsilon solved the problem. Closing the issue. \n", "Sorry to bother you .  I really want to know  how to apply group lasso in tensorflow. Can you give me some instruction? Thanks very much.", "You can take a look at the following slides(Slide number ~50)\r\n\r\nftp://ess.r-project.org/Teaching/buhlmann/advanced-comput-statist/slides1.pdf\r\n\r\nIf you have an issue please let me know. ", "@mingmingDiii  [This](https://bitbucket.org/ispamm/group-lasso-for-neural-networks-tensorflow-keras/src/f9d5bd6618c04a1b3f5055fb422aef8f0c58d01e/demo_group_lasso_tensorflow.py?at=master&fileviewer=file-view-default) might also be a good resource for you."]}, {"number": 3306, "title": ".Save, .Restore for contrib.learn.DNNClassifier", "body": "The older functions like skflow.TensorFlowDNNClassifier had methods .save and .restore.  These were supposedly migrated over to the contrib.learn functions, but there are no longer save and restore methods that I can find.  Is there a new protocol for saving the graph and variables with the new contrib.learn package?   \n", "comments": ["@ispirmustafa Could you take a look at this please?\n", "Hi, any news on this? , im having hard times trying to save  a DNNClassifier , followed some examples using train.Saver() but it says (No variables to save)\n", "@ispirmustafa any thoughts? Assigning @martinwicke since @ispirmustafa is not in the TensorFlow org.\n", "Checkpoints are saved automatically, and if you specify the same directory when you create another Estimator (of the same kind/same parameters), it will load the checkpoints and you can continue training. \n\nThere is currently a bug which prevents you from using the restored Estimator for inference without running at least one step of training.\n\nI will close this issue -- for detailed questions, please ask on StackOverflow, we can track questions and answers better over there.\n"]}, {"number": 3305, "title": " .", "body": "", "comments": []}, {"number": 3304, "title": "Ran out of GPU memory", "body": "I have a network similar to A3C network described [here](http://arxiv.org/abs/1602.01783), with lots of syncing and copying tensor values between different duplicates of the model. The code crashes with a `Ran out of memory` exception (see below). This might be a little bit hard to reproduce somewhere other than my machine (since the code is not open source ... yet) but I would be more than happy to provide any logs or help to track down the issue.\n\nWhat happens is that I receiving a lot of `pool_allocator` messages like below:\n\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40664481 get requests, put_count=40664484 evicted_count=39000 eviction_rate=0.000959068 and unsatisfied allocation rate=0.000959265\n\nand then finally it crashes like this:\n\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (131072):    Total Chunks: 1, Chunks in use: 0 204.5KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 220.5KiB was 128.0KiB, Chunk State: \n> I tensorflow/core/common_runtime/bfc_allocator.cc:662]   Size: 204.5KiB | Requested Size: 1.0KiB | in_use: 0, prev:   Size: 16.0KiB | Requested Size: 16.0KiB | in_use: 1, next:   Size: 16.0KiB | Requested Size: 16.0KiB | in_use: 1\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060000 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060100 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060200 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060300 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060400 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060500 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060600 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060700 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060800 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060900 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a064a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a068a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a070a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a078a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a440a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a808a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a808e00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a809200 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a809e00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a80aa00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a80ea00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a812a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a813600 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a81b600 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a823600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0abeb600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3e00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb4a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb5600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb5a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afbda00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc1a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc1e00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc9e00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcde00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcea00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcee00 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afdd300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afddf00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe1f00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe5f00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe6b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe6f00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afeef00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff2f00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff3b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff3f00 of size 39168\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0affd800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0affdc00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b005c00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b009c00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b00a800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b00ac00 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b019100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b019d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01dd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01e900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01ed00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b022d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b023900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b023d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b02bd00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b02fd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b030900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b030d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b038d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03cd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03d900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03dd00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b045d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b049d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b04a900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b04ad00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b052d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b056d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b057900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b057d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b05fd00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b063d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b064900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b064d00 of size 51968\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b071800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b079800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07d800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07e400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07e800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b082800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b083400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b083800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b08b800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b08f800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b090400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b090800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b094800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b095400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b095800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b09d800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a1800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a2400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a2800 of size 39168\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0ac100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b4100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b8100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b8d00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b9100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c1100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c5100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c5500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0cd500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d1500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d2100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d2500 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e0a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e1600 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e5600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e5a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e9a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0ea600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0eaa00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f2a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f6a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f7600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f7a00 of size 39168\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b101300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b109300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10d300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10df00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10e300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b116300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11a300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11af00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11b300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b123300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b127300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b127f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b128300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b130300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b134300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b134f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b135300 of size 41984\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b13f700 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b147700 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b148300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14c300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14cf00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14d300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b155300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b159300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b159f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b15a300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b162300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b166300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b166f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b167300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b16f300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b173300 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b173700 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b17b700 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b17f700 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b180300 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b180700 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b18ec00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b18f800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b193800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b194400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b194800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b19c800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a0800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a1400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a1800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a9800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ad800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1adc00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1b5c00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1b9c00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ba800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1bac00 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1c9100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1c9d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1cdd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ce900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ced00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d2d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d6d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d7900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d7d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1dfd00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e3d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e4900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e4d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ecd00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f0d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f1900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f1d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f9d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fdd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fe900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fed00 of size 29184\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b205f00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b20df00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b20e300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b216300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21a300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21af00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21b300 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b229800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b22a400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b22a800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b232800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b236800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b237400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b237800 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b245d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b246900 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b247500 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b247900 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b24f900 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b253900 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b254500 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b254900 of size 55552\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b262200 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26a200 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26e200 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26ee00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b276e00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27ae00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27ba00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27be00 of size 59648\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28a700 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28ab00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28eb00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28f700 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28fb00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b297b00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29bb00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29c700 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29cb00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a4b00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a8b00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a9700 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a9b00 of size 45568\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2b4d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2b8d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bcd00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bd900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bdd00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2c5d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2c9d00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2ca100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d2100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d6100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d6d00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d7100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2df100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2e3100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2e3500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2eb500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2ef500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f0100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f0500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f8500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fc500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fd100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fd500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b305500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b309500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b30a100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b30a500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b312500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b316500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b317100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b317500 of size 21248\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31c800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31d400 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31e000 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b326000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b326c00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b327000 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32b000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32bc00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32c000 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b334000 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b338000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b338c00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b339000 of size 39168\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b342900 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34a900 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34e900 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34f500 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34f900 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b357900 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b35b900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b35bd00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b363d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b367d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b368900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b368d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b370d00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b374d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b375900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b375d00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b37dd00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b381d00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b382900 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b382d00 of size 26880\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b389600 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b38a200 of size 33792\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b392600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b392a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b396a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b75ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0bb26a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0beeea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0c2b6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0c67ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ca46a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ce0ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d1d6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d59ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d966a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0dd2ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e0f6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e4bea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e886a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ec4ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f016a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f3dea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f7a6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0fb6ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ff36a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb102fea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb106c6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb10a8ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb10e56a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1121ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb115e6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb119aea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb11d76a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1213ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb12506a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb128cea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb12c96a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1305ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13426a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb137eea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13bb6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13f7ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14346a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1470ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14ad6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14e9ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb15266a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1562ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb159f6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb15dbea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16186a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1654ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16916a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16cdea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb170a6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1746ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17836a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17bfea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17fc6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1838ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18756a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18b1ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18ee6a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb192aea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19676a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19a3ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19e06a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a1cea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a596a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a95ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ad26a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b0eea00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b0ef600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b4b7600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b87f600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1bc47600 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1bc4f600 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c017600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c017a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c01fa00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c023a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c023e00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c02be00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c02fe00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c033e00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c034a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c034e00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c03ce00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c040e00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c041a00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c041e00 of size 51712\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c04e800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c04f400 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c417400 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c418000 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e0000 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e0400 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e8400 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ec400 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ed000 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ed400 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7fb900 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7fc500 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1cbc4500 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1cf8c500 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d354500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d358500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d359100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d359500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d361500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d365500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d366100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d366500 of size 56320\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d374100 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d73c100 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1db04100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1db08100 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded0100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded0d00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded1100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded9100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1dedd100 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a5100 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a5d00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a6100 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2ae100 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2b2100 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e67a100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e67a500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e682500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e686500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e687100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e687500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e68f500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e693500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e694100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e694500 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e69c500 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a0500 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a1100 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a1500 of size 65024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6b1300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6b1f00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ea79f00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ee41f00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f209f00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f20df00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d5f00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d6b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d6f00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5def00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5e2f00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9aaf00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9abb00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9abf00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9aff00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b0b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b0f00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b4f00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b5b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b5f00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9bdf00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c1f00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c2b00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c2f00 of size 39168\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9cc800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d4800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d8800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d9400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d9800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e1800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e5800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e6400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e6800 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9ee800 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f2800 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f3400 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f3800 of size 45568\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9fea00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1fa06a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1fdcea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20196a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2055ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20926a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20ceea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb210b6a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb210baa00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21482a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21483600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21483a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2148ba00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2148fa00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21857a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21858600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21858a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21860a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21864a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2ca00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2d600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2da00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c35a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c39a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22001a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22002600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22002a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2200aa00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2200ea00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d6a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d7600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d7a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223dfa00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223e3a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227aba00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227ac600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227aca00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227b4a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227b8a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b80a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b81600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b81a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b85a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b86600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b86a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b8ea00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b92a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b93600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b93a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b9ba00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b9fa00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba0600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba0a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba8a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22baca00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bad600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bada00 of size 45568\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bb8c00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bc0c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22f88c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23350c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23718c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ae0c00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ae4c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eacc00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ead800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eadc00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eb5c00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eb9c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24281c00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24282800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24282c00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2428ac00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2428ec00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24656c00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24657800 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24657c00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2465fc00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24663c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a2bc00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a2c000 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a34000 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a38000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a38c00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a39000 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a41000 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a45000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a45c00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a46000 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a4e000 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a52000 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a52c00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a53000 of size 65024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a62e00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a63a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24e2ba00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb251f3a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb255bba00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb255bfa00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25987a00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25988600 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25988a00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25990a00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25994a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d5ca00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d5ce00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d60e00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d61200 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d69200 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6d200 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6de00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6e200 of size 58624\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d7c700 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d7d300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d81300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d81f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d82300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8a300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8e300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8ef00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8f300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d97300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9b300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9bf00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9c300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da4300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da4f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da5300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dad300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db1300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db1f00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db2300 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dba300 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbe300 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbef00 of size 1024\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbf300 of size 47872\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dcae00 of size 3072\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dcba00 of size 32768\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dd3a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2619ba00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb26563a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2692ba00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb26cf3a00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270bba00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270f2c00 of size 16384\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270f6c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb274bec00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb27886c00 of size 3964928\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb27c4ec00 of size 4219136\n> I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0xb270bfa00 of size 209408\n> I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: \n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 10 Chunks of size 256 totalling 2.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 125 Chunks of size 1024 totalling 125.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 125 Chunks of size 3072 totalling 375.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 122 Chunks of size 16384 totalling 1.91MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 21248 totalling 20.8KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 26880 totalling 26.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 29184 totalling 28.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 98 Chunks of size 32768 totalling 3.06MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 33792 totalling 33.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 39168 totalling 191.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 41984 totalling 41.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 3 Chunks of size 45568 totalling 133.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 47872 totalling 46.8KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 51712 totalling 50.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 51968 totalling 50.8KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 55552 totalling 54.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 56320 totalling 55.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 9 Chunks of size 58624 totalling 515.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 59648 totalling 58.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 2 Chunks of size 65024 totalling 127.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 124 Chunks of size 3964928 totalling 468.88MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 4219136 totalling 4.02MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 479.76MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \n> Limit:                   503270604\n> InUse:                   503061248\n> MaxInUse:                503061248\n> NumAllocs:                20717987\n> MaxAllocSize:              4219136\n> \n> W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************\n> W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 220.5KiB.  See logs for memory state.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (131072):    Total Chunks: 1, Chunks in use: 0 204.5KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n> I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 330.8KiB was 256.0KiB, Chunk State: \n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060000 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060100 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060200 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060300 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060400 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060500 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060600 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060700 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060800 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060900 of size 256\n> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060a00 of size 16384\n> Exception in thread Predictor3:\n> Traceback (most recent call last):\n>   File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 715, in _do_call\n>     return fn(*args)\n>   File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 697, in _run_fn\n>     status, run_metadata)\n>   File \"/home/mbz/anaconda3/lib/python3.5/contextlib.py\", line 66, in __exit__\n>     next(self.gen)\n>   File \"/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n>     pywrap_tensorflow.TF_GetCode(status))\n> tensorflow.python.framework.errors.InternalError: Dst tensor is not initialized.\n>      [[Node: _recv_network1/X_0/_28 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:1\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_9__recv_network1/X_0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:1\"]()]]\n>      [[Node: network1/Squeeze/_30 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:1\", send_device_incarnation=1, tensor_name=\"edge_10_network1/Squeeze\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64//libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64//libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so\n-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 May 19 18:24 /usr/local/cuda/lib64//libcudnn_static.a\n\nIf installed from binary pip package, provide:\nAnaconda3 (python3)\nTF v0.9 \n", "comments": ["It might not be easy to find the problems without the code... \n@zheng-xq Could you take a look at this please?\n", "@mbz, are you using the latest TensorFlow? Both both GPU and pinned memory, the latest TensorFlow uses BFC allocator, which has a lot less fragmentation. \n", "Maybe you can try to close and restart your Terminal every time after you run your previous program.\n", "Also please upload the entire log to website such as the following, and paste the link here. \n\nhttp://pastebin.com/\n\nAs @jmchen-g mentioned, it is better to have a small repro case. Otherwise, it might be expected to fail if the model requests more memory than what the GPU has. \n", "I'm using the latest pip3 version which has the BFC allocator. actually, bfc_allocator is the one outputting all of that log.\n\nIt's most likely a memory leak or a similar scenario. I'm using a GPU with 12G of ram and the models (as it can be seen in referenced paper) are quite tiny. \n\nPlease let me know if I can provide any other info to track down the issue.\n", "@mbz, uploading the full log to pastebin.com and paste the URL here is very helpful.\n\nIf you are using a 12G GPU, something is wrong with the memory limit BFC allocator sees: \n\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \nLimit: 503270604\n\nIt is only allowed 500M GPU memory. A few possibilities: \n1. It is currently running on a smaller GPU. \n2. The GPU config in the session only allows that amount of memory. \n\nThe full log is helpful in this case. \n", "my bad, I should have been more clear. I'm ran the same experiment on a 12G gpu and it crashed after a few days. In order to reproduce it, I re ran the code with `gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.05))` which resulted in the logs above.\n\nI'm not sure if I understand what you mean by full log. TensorFlow also outputs `See logs for memory state.`, but it doesn't say where can I find it.\n", "Could you install the latest Cuda driver as well? From another issue, older Cuda drivers could leak memory.\n\nhttps://github.com/tensorflow/tensorflow/issues/2728\n\nYou can redirect your TensorFlow output into another file, and then upload it. \n\n<your command line> |& tee /tmp/tf_output.log\n", "Closing due to lack of response, but please reopen if there is still a problem.\n", "Sorry for late answer, wasn't available.\n\nI put the full log here: [http://pastebin.com/WkU1buwx](url) . Hope this helps.\n\nI think I have the latest drivers.\n", "It seems that I cannot reopen the issue, it would be great if you do so.\n\nThanks\n", "@mbz, it seems that you have two different GPUs active at the same time. \n\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20c, pci bus id: 0000:02:00.0)\n\nCould you try the following? \n1. Set the environment variable CUDA_VISIBLE_DEVICES=1 before running TensorFlow. It should mask off the other GPU. \n2. Your BFC log shows only about 250MB memory is allowed. Could you make sure you session config code didn't specify a smaller GPU memory limit? \n\nLimit:                   251635302\n", "maybe change the batch size would help?", "When I change batch_size, the quality of training decreases. It should have had a better optimization.\r\nCuda version=10.0\r\nTensorflow-gpu==1.14.0\r\nPython=3.6.4\r\n...\r\nLimit:                  3150400716\r\nInUse:                  3148202496\r\nMaxInUse:               3150392320\r\nNumAllocs:                  545033\r\nMaxAllocSize:           2255688704\r\nW tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at concat_op.cc:153 : Resource exhausted: OOM when allocating tensor with shape[64,2048,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc", "Change the batch size", "I'm getting this behaviour loading TF models with Triton Inference Server during the model warmup. I'm getting dumps like this:\r\n```\r\n...\r\n2020-11-03 04:16:48.356608: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 2506240 totalling 7.17MiB\r\n2020-11-03 04:16:48.356612: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2640384 totalling 2.52MiB\r\n2020-11-03 04:16:48.356616: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3051520 totalling 2.91MiB\r\n2020-11-03 04:16:48.356619: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3571968 totalling 3.41MiB\r\n2020-11-03 04:16:48.356623: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 74 Chunks of size 3735552 totalling 263.62MiB\r\n2020-11-03 04:16:48.356627: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 74 Chunks of size 4194304 totalling 296.00MiB\r\n2020-11-03 04:16:48.356631: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 294 Chunks of size 6291456 totalling 1.72GiB\r\n2020-11-03 04:16:48.356635: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7641344 totalling 7.29MiB\r\n2020-11-03 04:16:48.356639: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 22 Chunks of size 9980928 totalling 209.41MiB\r\n2020-11-03 04:16:48.356643: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10460160 totalling 9.98MiB\r\n2020-11-03 04:16:48.356647: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 11162880 totalling 10.65MiB\r\n2020-11-03 04:16:48.356651: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12476160 totalling 11.90MiB\r\n2020-11-03 04:16:48.356655: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12478464 totalling 11.90MiB\r\n2020-11-03 04:16:48.356659: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 12487168 totalling 35.73MiB\r\n2020-11-03 04:16:48.356663: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 14589184 totalling 13.91MiB\r\n2020-11-03 04:16:48.356667: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 14600192 totalling 13.92MiB\r\n2020-11-03 04:16:48.356671: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 14982400 totalling 57.15MiB\r\n2020-11-03 04:16:48.356675: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 15250944 totalling 29.09MiB\r\n2020-11-03 04:16:48.356679: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 16777216 totalling 32.00MiB\r\n2020-11-03 04:16:48.356683: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16951296 totalling 16.17MiB\r\n2020-11-03 04:16:48.356687: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 17095424 totalling 32.61MiB\r\n2020-11-03 04:16:48.356692: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 17847808 totalling 34.04MiB\r\n2020-11-03 04:16:48.356696: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 19283456 totalling 36.78MiB\r\n2020-11-03 04:16:48.356700: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 19288832 totalling 18.39MiB\r\n2020-11-03 04:16:48.356705: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 19654656 totalling 18.74MiB\r\n2020-11-03 04:16:48.356709: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 24789248 totalling 23.64MiB\r\n2020-11-03 04:16:48.356719: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 26758144 totalling 178.63MiB\r\n2020-11-03 04:16:48.356724: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27076352 totalling 25.82MiB\r\n2020-11-03 04:16:48.356728: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 29264384 totalling 83.73MiB\r\n2020-11-03 04:16:48.356732: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 29265920 totalling 27.91MiB\r\n2020-11-03 04:16:48.356736: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 33860096 totalling 32.29MiB\r\n2020-11-03 04:16:48.356740: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 34943232 totalling 33.32MiB\r\n2020-11-03 04:16:48.356744: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 39245312 totalling 37.43MiB\r\n2020-11-03 04:16:48.356748: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 41305344 totalling 39.39MiB\r\n2020-11-03 04:16:48.356752: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 49077760 totalling 46.80MiB\r\n2020-11-03 04:16:48.356756: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 9.00GiB\r\n2020-11-03 04:16:48.356760: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 10085719040 memory_limit_: 10085719081 available bytes: 41 curr_region_allocation_bytes_: 17179869184\r\n2020-11-03 04:16:48.356767: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats: \r\nLimit:                 10085719081\r\nInUse:                  9662768128\r\nMaxInUse:              10083344896\r\nNumAllocs:                   55572\r\nMaxAllocSize:             49077760\r\n\r\n2020-11-03 04:16:48.358419: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ****************************************************************************************************\r\n```\r\nAll the GPU memory is consumed and the warmup takes hours as we have 75 models on a 12GB 2080 :("]}, {"number": 3303, "title": "Remove confusing section in Udacity doc.", "body": "Removing the --rm is simpler. If users want to use a named container, they can, but it's not essential.\n", "comments": ["I worry that even without the `--rm`, people unfamiliar with Docker still won't know how to resume the stopped container. I expect they'll try the `docker run` command again, which will create another fresh container.\n\nRealizing that you have to use `docker ps -a` to get the id of the stopped container and then use `docker start` to resume it seems tricky with no instructions, unless I'm missing something obvious?\n", "(Overall the most user-friendly approach might be to mount the local filesystem in the container, something like:\n\n```\ngit clone https://github.com/tensorflow/tensorflow\ncd tensorflow/tensorflow/examples/udacity\ndocker run -v $PWD:/notebooks -p 8888:8888 -it b.gcr.io/tensorflow-udacity/assignments:0.5.0\n```\n\nThen people who don't know Docker would be able to see the files in their normal filesystem, could simply run the `docker run` command again whenever they want, edit files locally, et cetera\u2026\n\nBut anyway these are just some rambling thoughts! \ud83d\ude49 It's a great course so far, thanks. I'm sure everyone figures out the nuances of Docker one way or another.)\n"]}, {"number": 3302, "title": "[Tensorboard] Make long column names in \"Images\" tab more readable", "body": "Currently it's difficult to read long experiment names in \"Images\" tab due to the lack of word-break and adaptive cell height: \n![image](https://cloud.githubusercontent.com/assets/1441616/16820454/e5bbb9c8-4905-11e6-908f-25caa0ba9027.png)\n\nAdding `word-break: break-all;` to and removing `height: 30px;` from the css class `.run-name-cell.tf-image-grid` will make it easier to read: \n![image](https://cloud.githubusercontent.com/assets/1441616/16820551/852360ba-4906-11e6-9a93-af92ae1060e1.png)\n", "comments": ["Sounds good. @danmane Could you take a look at this please?\n", "Thanks for the suggestion. I've implemented the change and it's working its way through our internal review system.\n"]}, {"number": 3301, "title": "Initialize local variables in fully_connected_preloaded example to resolve #3168", "body": "fully_connected_reader example was fixed while fully_connected_preloaded was not\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\n2016-07-13 14:21 GMT-07:00 googlebot notifications@github.com:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> \ud83d\udcdd _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3301#issuecomment-232490208,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAC3txMWIKnwrcW6NN-apewcJqMKICikks5qVVbygaJpZM4JL3Ev\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "There are no tests for this, so just merging since it looks correct :)\n"]}, {"number": 3300, "title": "Error trying to predict using skflow example dnn_autoencoder_iris", "body": "I am trying to generate new data using trained construction layer using dnn autoencoder on iris data. I run into a couple issues detailed after the system and installation information. \n### Environment info\n\nOperating System:\n\nMac OSx 10.11.5\n\nI installed from the source code and the commit hash is- \nbef942ca38d03bda48e3f39d3473973f0219933a\n\n**Error 1:** \n### Steps to reproduce\n- Add the following line to the file `tensorflow/tensorflow/examples/skflow/dnn_autoencoder_iris.py`\n\n```\nnew_data = autoencoder.generate()\nprint new_data\n```\n- Run the above file.\n  Error: `get_tensor_value()` is not a class method. \n\nI tried changing  the function name to `get_tensor()` which actually exists in the parent class. \n\nI get the following error trace \n\n```\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nTraceback (most recent call last):\n  File \"/Users/nbajaj/tensorflow_git/tensorflow/tensorflow/examples/skflow/dnn_autoencoder_rfk.py\", line 56, in <module>\n    new_data = autoencoder.generate()\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/autoencoder.py\", line 97, in generate\n    \"encoder/dnn/layer%d/Linear/Bias:0\" % last_layer)\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 270, in get_tensor\n    return self._graph.get_tensor_by_name(name)\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2519, in get_tensor_by_name\n    return self.as_graph_element(name, allow_tensor=True, allow_operation=False)\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2373, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2415, in _as_graph_element_locked\n    \"graph.\" % (repr(name), repr(op_name)))\nKeyError: \"The name 'encoder/dnn/layer1/Linear/Bias:0' refers to a Tensor which does not exist. The operation, 'encoder/dnn/layer1/Linear/Bias', does not exist in the graph.\"\n```\n\nThen I changed the line \n`new_data = autoencoder.generate()` -> `new_data = autoencoder.generate(hideen=transformed)` so that the above code path doesn't get executed in the first place. \n\nThen I get the following error trace- \n\n```\nTraceback (most recent call last):\n  File \"dnn_autoencoder_rfk.py\", line 56, in <module>\n    new_data = autoencoder.generate(hidden=[10, 20])\n  File \"/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/autoencoder.py\", line 101, in generate\n    return self._session.run(self.decoder, feed_dict={self.encoder: hidden})\nAttributeError: 'TensorFlowDNNAutoencoder' object has no attribute '_session'\n```\n\nPlease let me know if I could try something else or there is anyway I can help to fix this. \n", "comments": ["@ilblackdragon Could you take a look at this please?\n", "Hi @ilblackdragon. Did you get a chance to look into this? I would be happy to help if I could. \n", "Sorry I'm on vacation until next week. @wicke can you ask somebody to look\nat this and related issues? Thanks\nOn Fri, Jul 15, 2016 at 8:35 PM Nikunj Bajaj notifications@github.com\nwrote:\n\n> Hi @ilblackdragon https://github.com/ilblackdragon. Did you get a\n> chance to look into this? I would be happy to help if I could.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3300#issuecomment-233032254,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAKtfkLFopQxbbGeK-IVWaJqxZU7AC90ks5qV9L-gaJpZM4JLy4m\n> .\n", "Apologies for bothering again. Just checking in if someone got a chance. \n", "@ilblackdragon could you take a look now? Thanks.\n", "This example was removed as it is outdated. Closing this issue.\n"]}, {"number": 3299, "title": "Frequent dynamic memory allocation in tensorflow/core/kernels/conv_ops.cc?", "body": "I am looking at the code in tensorflow/core/kernels/conv_ops.cc, Compute(OpKernelContext\\* context)  function:\n`\n  // Output tensor is of the following dimensions:                          \n  // [ in_batch, out_rows, out_cols, out_depth ]                            \n  Tensor* output = nullptr;                                                 \n  OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output)); \n`\nDoes it mean each CONV OP will always dynamic allocate output tensor (including the buffer as the size of in_batch x out_rows x out_cols x out_depth) even if I load the graph once but iterate multiple times to inference multiple images? Where the memory was freed? \n\nThanks.\n", "comments": ["Yes. All tensors in TensorFlow are refcounted, dynamically allocated and freed. On GPU, this goes through its own non-blocking BFC memory allocator. All the tensors are freed when their refcount goes to zero. For temporary tensors, that is often when \"Compute\" finishes. For output tensors, that is when they finish being used as input tensors. \n", "Thanks, @zheng-xq . Any theory behind this design (too much volume cannot fit in I think?)  To me, make memory static is important for both performance and memory fragmentation and I am using SqueezeNet which can fit into my RAM so  I am basically looking to optimize the inference time for CPU only case and wondering whether it is doable on top of tensorflow. Thanks. \n", "For CPU, the allocation/free overhead is not an issue because we use tcmalloc internally. \n\nhttp://goog-perftools.sourceforge.net/doc/tcmalloc.html\n\nThere is a discussion on whether we should enable tcmalloc by default for the open-source build. Meanwhile, feel free to try tcmalloc yourself and it should improve things a lot. \n", "Thanks for the quick response, @zheng-xq I can close this ticket and will play with tcmalloc then. \n"]}, {"number": 3298, "title": "Branch 127324936", "body": "", "comments": []}, {"number": 3297, "title": "time_major parameter for ctc_loss op", "body": "Just as dynamic_rnn and to be more regular across the TensorFlow's code I added a flag capable of transpose the input data to be in time_major, required by gen_ctc_ops._ctc_loss. Note that, instead of set time_major=False (as the most of TensorFlow data), it was set False to be compatible with previous ctc_loss function call (but I don't think that this is a good idea).\n", "comments": ["Can one of the admins verify this patch?\n", "@ebrevdo Can you review this please?\n", "Friendly ping @ebrevdo \n", "Can you add a quick unit test ensuring that given input with batch_size > 1, max time > 1,  transposing & setting time_major=True results in the same loss?  i just want to exercise this branch of the code.\n", "Jenkins, test this please.\n", "@igormq Please rebase and resolve conflicts.\n", "I'll have to create another PR, because this repo was erased by mistake, so I'm unable to make the corrections. Sorry for that.\n", "Sorry again for the mess. I made the PR #3993  with the test.\n"]}, {"number": 3296, "title": "Add exclusive kwarg to scan ops", "body": "This adds an `exclusive` kwarg to the `cumsum` and `cumprod` ops.\nDocumentation and tests have been extended to cover this kwarg.\n", "comments": ["Can one of the admins verify this patch?\n", "Thank you for satisfying my inclusive scan pet peeve. :)\n", "Okay, I've updated the PR.\nI was trying to avoid line breaks by leaving out the kwargs, but I realize that it wasn't exactly a great solution :)\n", "Okay, I've added a default for the reverse arg as well.\n", "Jenkins, test this please.\n", "I guess switch to keyword args for `_compareAll` to satisfy http://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/771//console.\n", "Yeah, I've done that but started to wonder why this didn't throw an error when running the tests.\nTurns out my `for a, b, c in combinations([True, False], 3)` trick didn't actually do what I wanted and never executed the loop body :(\nI've then noticed a few more problems with my tests after I corrected that.\nI'll fix those and update the PR.\n", "Jenkins, test this please.\n", "I've removed the 8D tests, as they were taking a very long time to run (past the timeout on my machine).\n"]}, {"number": 3295, "title": "tf.train.Server.create_local_server  has two problems :1)performance drop 2 times compare to without it,2) gpu memory fraction limitations fails. ", "body": "tf.train.Server.create_local_server has two problems :1)performance drop 2 times compare to without it,2) gpu memory fraction limitations fails\n\nmy model is a dnn network with 12 layers, same as the alphago policy network!\n## code1: whitout server = tf.train.Server.create_local_server(start = True)\n\n```\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n\nsess =  tf.Session(config=tf.ConfigProto(log_device_placement=True,allow_soft_placement=True,gpu_options=gpu_options))\n```\n## \\- code2:  using server = tf.train.Server.create_local_server(start = True)\n\n```\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n\n    server = tf.train.Server.create_local_server(start = True)\n\n    sess= tf.Session(target=server.target,config=tf.ConfigProto(log_device_placement=True,allow_soft_placement=True,gpu_options=gpu_options))\n```\n# Questions:\n\n**1. code2 performance drop 3 times compare to code1( 3 steps/seconds vs 11 steps/seconds), why?**\n**2. code2 will broke the  limitations of gpu memory. while code1 is ok**\n\nps: Is this relevant to this issue than the training data is read from queue?\n", "comments": ["@mrry Could you take a look at this when you are back?\n", "1. Without seeing the code, it's difficult to say why you're getting a slowdown, but the most likely problem is that you're feeding and/or fetching a large amount of data, and the increased cost of copying through the RPC interface is increasing the cost of each step. We have a medium term plan to reduce this overhead, but in the meantime you might want to revise your code to avoid feeding/fetching so much data in each step.\n2. The GPU memory configuration is slightly confusing for the `tf.train.Server`. Instead of passing it in the `config` argument to the `tf.Session`, you pass the `per_process_gpu_memory_fraction` setting in the `config` argument to the `tf.train.Server` (and it affects _all_ sessions against that server).\n", "I'm not the original author, but I'm having the same performance degradation when using the server.  \n\nHere's my training loop, which I believe is straight from one of the examples: \n\n`for step in xrange(num_epochs * train_size // self.batch_size):\n    offset = (step * self.batch_size) % train_size\n    batch_data = train_data[offset:(offset + self.batch_size), :]\n    batch_labels = train_labels[offset:(offset + self.batch_size)]\n    train_step.run(feed_dict={x: batch_data, y_: batch_labels})`\n\nTried several variations on batch_size (50, 100, 1000) to saturate both processing power on the server and network usage to no avail.  Any tips / suggestions on making it more performant in the client-server scenario?  \n", "The server-based version uses an RPC (actually, two RPCs) to communicate the `feed_dict` to the TensorFlow runtime. There's a medium-term effort underway to improve the performance of this codepath when the data stays in the same process, but for now, for distributed training, we recommend using [input pipelines](https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/index.html) so that the data do not need to be copied across the session boundary.\n", "It sounds like @millisecond's question is answered, and there's been no response from the OP for a while, so I'm going to close this issue for now.\n", "Hmm, I rewrote everything for the CSV input pipeline and switched all training code over to that.  Network usage dropped off to a few KB/s (vs 2MB/s before), but it performs almost identically to the previous train.  Training directly on the worker takes 11s, using client-server it takes ~40s.\n\nThis is a CPU worker, might those be single-threaded?  Wondering if only GPU workers are expected.  On the 11s train above done locally on the worker, CPU goes to many hundred % (box with 12 cores) during the train but rarely breaks 100% on the remote train. \n", "@millisecond Maybe try feed data into a TF buffered queue, and the training OPs will read the data from that queue. It still cost more CPU cycles for RPC (protobuf is **not** suitable for TF's need, yet still being used), but hopefully it will not have visible impact to the training time.\r\n"]}, {"number": 3294, "title": "Remove the unused/orphaned code in python/package/default.", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "@tensorflow-jenkins test this please\n", "I signed it!\n", "@tensorflow-jenkins test this please\n", "@vrv @martinwicke PTAL.\n", "@ericdnielsen looks like your commits aren't using your google email? Can you `--amend --author` the commit so CLAbot is happy?\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Fixed.\n", "@tensorflow-jenkins test this please\n", "LGTM\n"]}, {"number": 3293, "title": "Slicing of rank>=6 tensor?", "body": "Currently it throws a not implemented error \"inputs rank not in [0,5]\".\n", "comments": ["It is not supported as we don't see a good use case yet. What is yours here?\n", "Some new convolutional layers invented in the last few months for superresolution etc. require further division of the H and W dimension like [N, C, H, H_sub, W, W_sub]. Although the slicing can be simulated via reshaping and slicing in a lower rank tensor, it's just doesn't feel right when T.transpose() and T.reshape() are both supported for rank 6 tensor and T.slice() isn't.\n", "Interesting, could you give a citation of papers that do this. It is difficult to extend past 5 in the current framework because it requires more Eigen template instantiation which would bloat the binary. One way to get around this would be to implement a catchall non templatized version of slice. Most ops don't really support more than 5 so you probably will hit this on many other ops as well.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3292, "title": "Minor code doc fix - cwise_ops_common.h", "body": "Found a minor error in code documentation while digging for something. The file `cwise_functors.h` does not exist, and the `functor` definitions are inside `cwise_ops.h`. Also, couldn't find the `add2 functor`, so replaced it with `add`.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3291, "title": "How to create an op like conv_ops in tensorflow?", "body": "Notice that I'm not looking for a tutorial like [this](https://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/SOURCE/how_tos/adding_an_op/index.md).\n**What I'm trying to do**\n\nI'm new to C++ and bazel and I want to make some change on the convolution operation in tensorflow, so I decide that my first step is to create an ops just like it.\n\n**What I have done**\n\nI copied conv_ops.cc from //tensorflow/core/kernels and change the name of the ops registrated in my new_conv_ops.cc. I also changed some name of the functions in the file to avoid duplication. And here is my BUILD file. \n![qq 20160713201655](https://cloud.githubusercontent.com/assets/9963412/16803076/c495f610-4936-11e6-9e28-9aa27dd55e4d.png)\n\nAs you can see, I copy the deps attributes of conv_ops from //tensorflow/core/kernels/BUILD. Then I use \"bazel build -c opt //tensorflow/core/user_ops:new_conv_ops.so\" to build the new op.\n\n**What my problem is**\n\nThen I got this error.\n![](https://cloud.githubusercontent.com/assets/9963412/16803048/9b960250-4936-11e6-90ab-7e7cd3b81b96.png)\n\nI tried to delete bounds_check and got same error for the next deps. Then I realize that there is some problem for including h files in //tensorflow/core/kernels from //tensorflow/core/user_ops. So how can I perfectely create a new op excatcly like conv_ops?\n\n---\n", "comments": ["I suggest you just create a new conv_op in the same file to avoid all such issues.\n\nPlease redirect such questions to stackoverflow.\n"]}, {"number": 3290, "title": "I think tf.nn.moments() produces negative variance.", "body": " tf.nn.normalize_moments() calculates variance like this.\n\n```\nvariance = math_ops.sub(\n        math_ops.mul(variance_ss, divisor),\n        math_ops.square(shifted_mean),\n        name=\"variance\")\n```\n\nThis code can cause negative variance due to floating point precision problem.\n\nThanks.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\ntf.Print output for variance from tf.nn.moments().\n\n```\nI tensorflow/core/kernels/logging_ops.cc:79] variance[-0.0021057129 0.00061035156 -0.00024414062...]\nI tensorflow/core/kernels/logging_ops.cc:79] variance[14.041901 5.8100648 60.691284...]\nI tensorflow/core/kernels/logging_ops.cc:79] variance[0.46612549 0.017944336 0.87060547...]\n```\n", "comments": ["Thanks for reporting. Actually @zheng-xq is already working on this. Any updates XQ?\n", "We are aware of this issue caused by numerical precision. Internally we are discussing a solution with a better tradeoff between numerical stability, memory and computation efficiency. \n\nFor now, please work around this issue by clamp the variance to zero, or a small positive value. \n", "Closing for now. Please reopen if the workaround is not suitable for you.\n", "was this fixed? I'm wondering if this can cause nan values in `tensorflow.contrib.slim.batch_norm`.\n", "We are switching to a fused batch norm implemenation. The new op is here: \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn.py#L985\n\nWe are in the process of switching the default layers.batch_norm. It will be announced when it is done.\n", "Indeed I'm observing `nan` values from `tensorflow.contrib.slim.batch_norm` due to negative variances returned from `tf.nn.moments`. Looking forward to seeing this addressed.", "It's addressed with tf.nn.fused_batch_norm\n\nOn Nov 27, 2016 4:37 AM, \"Edgar Y. Walker\" <notifications@github.com> wrote:\n\n> Indeed I'm observing nan values from tensorflow.contrib.slim.batch_norm\n> due to negative variances returned from tf.nn.moments. Looking forward to\n> seeing this addressed.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3290#issuecomment-263114692>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHCLkzfwBqqn9UStQHz8_W_I3p3Jkks5rCV1zgaJpZM4JLKyN>\n> .\n>\n", "Any update on this? Caused a mild train wreck here. Perhaps a warning in the documentation might benefit others.", "@yazabaza which version? There have been some updates to that functionality, can you reproduce with nightly?", "tf.nn.fused_batch_norm works great, because it uses \"Var = E[square(X- mean)]\" to calculate variance. I think tf.nn.moments should use it too.", "I am running version 0.12.0. Haven't yet tried 1.0 or nightly. I wanted to use tf.nn.fused_batch_norm but could not decipher its documentation. I might just create my own variance calculation with Tensorflow math ops.", "I tested in v1.0.1 and the issue is still there.", "I'm also dealing with this issue on TF 1.0.1. Furthermore, tf.nn.fused_batch_norm isn't a solution because it requires 4D input and I'm working with 5D tensors and 3D convolutions. Is there any progress on this?", "I'm also getting the negative moving variance while using `tf.contrib.layers.batch_norm(fused=True)`.\r\nShould I use `tf.nn.fused_batch_norm` ?\r\n\r\nUsing `tensorflow-gpu (1.1.0)`", "@pawni Did you find a solution? I'm also working with 3D convolutions and 5D tensors, and I'm currently using tf.nn.moments\r\n"]}, {"number": 3289, "title": "tensorflow mobile : makefile raspberry pi - protobuf build error", "body": "### Environment info\n\nOperating System:\npi@raspberrypi:~ $ cat /proc/version\nLinux version 4.4.13-v7+ (dc4@dc4-XPS13-9333) (gcc version 4.9.3 (crosstool-NG crosstool-ng-1.22.0-88-g8460611) ) #894 SMP Mon Jun 13 13:13:27 BST 2016\n### Steps to reproduce\n1. Follow instructions under Raspberry Pi section - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile\n2. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./autogen.sh\n   Google Mock not present.  Fetching gmock-1.7.0 from the web...\n   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                  Dload  Upload   Total   Spent    Left  Speed\n   100 2116k  100 2116k    0     0  1169k      0  0:00:01  0:00:01 --:--:-- 1170k\n3. autoreconf -f -i -Wall,no-obsolete\n   ./autogen.sh: 43: ./autogen.sh: autoreconf: not found\n### What have you tried?\n1. Searched for similar issues.\n", "comments": ["@petewarden Could you take a look at this please?\n", "@wfs I think this is just a missing step in the documentation. Can you try running this install command (from the Ubuntu section earlier in the readme):\n\n`sudo apt-get install autoconf automake libtool curl make g++ unzip`\n\nIf that works, let me know and I'll update the docs. I'm guessing the problem was that I already had those installed on my Pi's, so I didn't see the problem there.\n", "Thanks so much for your help @petewarden. \n\nThis got me a lot further through the build process but ran into a new error at the end :\n1. Did sudo apt-get update and dist-upgrade as usual to ensure have I the latest system.\n2. pi@raspberrypi:~ $ sudo apt-get install autoconf automake libtool curl make g++ unzip\n3. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./autogen.sh\n4. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./configure\n5. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo make\n6. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo make install\n7. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ cd ../../../../..\n8. pi@raspberrypi:~/tensorflow $ make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\"\n   PROTOC = \"protoc\"\n   CC_PREFIX = \"\"\n   protoc  tensorflow/core/util/test_log.proto --cpp_out /home/pi/tensorflow/tensorflow/contrib/makefile/gen/proto/\n   protoc: error while loading shared libraries: libprotobuf.so.10: cannot open shared object file: No such file or directory\n   tensorflow/contrib/makefile/Makefile:411: recipe for target '/home/pi/tensorflow/tensorflow/contrib/makefile/gen/proto/tensorflow/core/util/test_log.pb.cc' failed\n   make: **\\* [/home/pi/tensorflow/tensorflow/contrib/makefile/gen/proto/tensorflow/core/util/test_log.pb.cc] Error 127\n", "That looks like the protobuf installation failed. If it worked, you should have protoc in your path, as well as the libprotobuf.so.10 files that it expects. From the error message it seems like it's not finding those when it tries to run protoc though.\n\nCan you re-run the protobuf install step, and make sure that there aren't any errors shown? Once you've done that, try running protoc on its own to see if it works.\n", "I get this error when trying to run protoc :\n\npi@raspberrypi:~/tensorflow $ ls -ali /usr/local/bin/protoc\n3433 -rwxr-xr-x 1 root staff 148548 Jul 15 05:11 /usr/local/bin/protoc\npi@raspberrypi:~/tensorflow $ sudo /usr/local/bin/protoc\n/usr/local/bin/protoc: error while loading shared libraries: libprotobuf.so.10: cannot open shared object file: No such file or directory\n\nHere is a link to the terminal output text file - https://drive.google.com/open?id=0B0Oci8Q1NdEuNkRHSHNPZ2xZcW5HWTJsYUhiWkdJSVljSnlV\n", "You need to add /usr/local/lib to your lib search path.  Try this:\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\n", "Thanks @rmuss This let me run the final make (step 9) however I get a lot of warnings and then some errors at the end. [Here is the terminal output](https://drive.google.com/open?id=0B0Oci8Q1NdEuSWRrXzV4czVPQ3pCaUktSl8xR2NNY19RWmU0). \n\nThe updated protobuf build steps are now :\n1. pi@raspberrypi:~/ $ sudo apt-get install autoconf automake libtool curl make g++ unzip\n2. pi@raspberrypi:~/ $ cd ~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf\n3. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./autogen.sh\n4. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./configure\n5. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo make\n6. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo make install\n7. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ cd ../../../../..\n8. pi@raspberrypi:~/tensorflow $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\n9. pi@raspberrypi:~/tensorflow $ make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\"\n", "Sorry you're still hitting problems! I took a look at the output, and it's a known issue with gcc 4.9. I've added some extra documentation about working around this in #3398, but here's the relevant piece:\n\nIf you hit compilation errors mentioning `__atomic_compare_exchange` and you're\nusing gcc 4.9, you should try installing gcc 4.8 and using that instead:\n\n``` bash\nsudo apt-get install -y gcc-4.8 g++-4.8\nmake -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI \\\nOPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" \\\nCXX=g++-4.8\n```\n\nDoes that help?\n", "Great! These final steps work. No warnings or errors during the make. Off to test the installation now. Will provide another update when done. Thanks again for the awesome support.\n", "Segmentation fault :(\n\nTerminal output since your make command in previous comment [is stored here](https://drive.google.com/file/d/0B0Oci8Q1NdEucWg5b0FNc3huT0xTaXJTVzU4dnB1cG02SzJz/view?usp=sharing)\n", "Can you run\n\n``` bash\ngdb tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\n```\n\nand see if you get a stack trace? Also, can you confirm which Pi model you're on?\n", "pi@raspberrypi:~/tensorflow $ gdb tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\nGNU gdb (Raspbian 7.7.1+dfsg-5) 7.7.1\nCopyright (C) 2014 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"arm-linux-gnueabihf\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\nhttp://www.gnu.org/software/gdb/bugs/.\nFind the GDB manual and other documentation resources online at:\nhttp://www.gnu.org/software/gdb/documentation/.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from tensorflow/contrib/pi_examples/label_image/gen/bin/label_image...(no debugging symbols found)...done.\n(gdb) \n\nRaspberry Pi 3 Model B V1.2\n\npi@raspberrypi:~/tensorflow $ cat /proc/cpuinfo\nprocessor   : 0\nmodel name  : ARMv7 Processor rev 4 (v7l)\nBogoMIPS    : 38.40\nFeatures    : half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32 \nCPU implementer : 0x41\nCPU architecture: 7\nCPU variant : 0x0\nCPU part    : 0xd03\nCPU revision    : 4\n\nprocessor   : 1\nmodel name  : ARMv7 Processor rev 4 (v7l)\nBogoMIPS    : 38.40\nFeatures    : half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32 \nCPU implementer : 0x41\nCPU architecture: 7\nCPU variant : 0x0\nCPU part    : 0xd03\nCPU revision    : 4\n\nprocessor   : 2\nmodel name  : ARMv7 Processor rev 4 (v7l)\nBogoMIPS    : 38.40\nFeatures    : half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32 \nCPU implementer : 0x41\nCPU architecture: 7\nCPU variant : 0x0\nCPU part    : 0xd03\nCPU revision    : 4\n\nprocessor   : 3\nmodel name  : ARMv7 Processor rev 4 (v7l)\nBogoMIPS    : 38.40\nFeatures    : half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32 \nCPU implementer : 0x41\nCPU architecture: 7\nCPU variant : 0x0\nCPU part    : 0xd03\nCPU revision    : 4\n\nHardware    : BCM2709\nRevision    : a22082\nSerial      : 00000000fb49ee3b\n", "Thanks for the info, and sorry, I should have been more specific. When you run gdb and get to the prompt, type 'r' then return to run the program. Hopefully then there will be a backtrace.\n", "No problem.\n\nReading symbols from tensorflow/contrib/pi_examples/label_image/gen/bin/label_image...(no debugging symbols found)...done.\n(gdb) r\nStarting program: /home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/bin/label_image \n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00359c2c in google::protobuf::Map<std::string, int>::find(std::string const&) const ()\n(gdb) \n", "Thanks, that does at least suggest there may be something funky with the build, since that's not an error I'd expect to see. Since you switched compilers, could you try\n\n``` bash\nmake -f tensorflow/contrib/makefile/Makefile clean\n```\n\njust to make sure that there are no weird linking issues with objects from different gcc versions (though that's a bit of a stretch). I'll try this on my Pi tomorrow too, to see if I can reproduce the problem.\n", "No joy. Same segmentation fault after 1st running clean above.\n", "@petewarden ,hello \n     I also get the problem that is \"segmentation fault\" when running \"tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\"  in Raspberrypi 2. I find current branch is in master branch when running \"git branch\", is this the reason? how to solve it ? Looking forward to your reply . Thanks\n", "Unfortunately I haven't been able to reproduce this problem locally. Is it still occurring for you @wfs and @Sundy1219 ?\n", "Closing since we don't have a repro. Feel free to open a new github issue if the problem still persists in recent versions."]}, {"number": 3288, "title": "Simplify Eigen package config", "body": "I think we can avoid specifying the Eigen commit hash in multiple places by using the `strip_prefix` option to `new_http_archive`.\n\nHere, I've declared the real Eigen includes without a prefix, while the includes in `third_party` can only be reached by including `third_party/eigen3/...` (to avoid an infinite inclusion loop).\nI've used this setup to successfully build tensorflow.\n\nThis can probably still be improved by not declaring the real Eigen includes at the top level.\nMaybe it's possible to access them under `eigen_archive/...`, although I'm not sure how to set that up.\n", "comments": ["Can one of the admins verify this patch?\n", "Sorry, there's a conflict I just introduced from another update to eigen libraries -- can you rebase and we can try this again?\n", "No problem, I've rebased the PR.\n", "Sweet, let's give this a shot.  @tensorflow-jenkins test this please\n", "hm, that's an interesting failure.  Have you successfully been able to compile with this?\n", "I'm seeing the same problem now.\nI'm pretty sure managed to compile it before the rebase, though :/\n", "The cpu test failed with a more appropriate error -- maybe we can resolve the CPU ones first and then figure out what's going on with GPU?\n", "I noticed that there's a new `third_party` Eigen header (at `third_party/eigen3/unsupported/Eigen/SpecialFunctions`) but adjusting it didn't help.\n", "Okay, the CPU tests are failing because I haven't adjusted the code that creates the pip package (It still assumes that eigen is located in `eigen_archive/eigen-eigen-\\w+`).\nNot sure about the GPU tests, though.\n", "I'm still not sure what's causing the problem with the GPU build.\nMaybe the fact that Eigen is including the curand headers.\nI'll have a closer look later.\n", "Finally got around to this.\nIt turns out that that the problem is caused by [a workaround in the GPU crosstool wrapper](https://github.com/tensorflow/tensorflow/blob/e95f4e760c6b6713b6b686ebeff9a1586a5831dd/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc#L103) that's used to support CUDA <= 6.0. Does TensorFlow still support those versions? If not, I could remove it.\nI've added some extra code that makes the build work with the workaround.\n\nBoth problems from before should be solved now, so we can have another go at the tests :)\n", "I am fine dropping support for cuda 6.0, so go ahead!\n", "Okay, I've removed that part of the crosstool script and pushed my changes.\n", "Going to kick off a run just to see.  @tensorflow-jenkins test this please\n", "I've pushed a new commit that isolates the `eigen_version` and `eigen_sha256` in the bazel config and adds some code to the cmake and make builds to extract those values.\nI've used built-in tools in cmake to make sure that the config stays portable.\n", "Woohoo!  This is awesome.  \n\n@tensorflow-jenkins test this please\n\ncc @rmlarsen  -- our hacky scripts for updating eigen just got easier.\n", "Seems like an unrelated failure with cc_op_gen.cc, so merging.\n", "Thanks!\nIf there should be an issue with the cmake build as a result of this PR, you can post it here and I'll fix it.\n"]}]