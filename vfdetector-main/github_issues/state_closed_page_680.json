[{"number": 33196, "title": "minor spelling tweaks in md files", "body": "This PR addresses minor spelling tweaks in `.md` files. In addition, this PR addresses spelling tweaks in the following non-`.md` files.\r\n\r\n```\r\ntensorflow/core/api_def/base_api/api_def_QuantizeAndDequantizeV2.pbtxt\r\ntensorflow/go/op/wrappers.go\r\n```\r\n", "comments": []}, {"number": 33195, "title": "[Intel MKL] fix bias cache accuracy issue.", "body": "This PR fix the bias cache optimization accuracy reverted in https://github.com/tensorflow/tensorflow/pull/32922", "comments": ["@penpornk thanks for you comments, I have modified my code based on it, please help to check, thanks."]}, {"number": 33194, "title": "Why my tensorflow-gpu runs only on  GPU?", "body": "Not work TF 2.0\r\n```\r\nconfig = tf.compat.v1.ConfigProto(\r\n        device_count = {'GPU': 0}\r\n    )\r\nsess = tf.compat.v1.Session(config=config)\r\ntf.compat.v1.keras.backend.set_session(sess)\r\n```", "comments": ["@sonfiree, Could you please elaborate the issue and also describe the expected behavior and current behavior. Thanks!", "Using the code above, I run the execution on the CPU. But in version 2.0, it does not work.\r\nI have a version for the GPU, but sometimes I want to run code on the CPU for texts", "@sonfiree, I tried with Tf-gpu 2.0 on colab.It is working as expected. \r\nPlease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/2b6faea572041919de158666ddeb395e/untitled192.ipynb). Thanks!", "The network still runs on the GPU", "@sonfiree Is this still an issue? TF 2.0 requires CUDA 10.0. What version of cuda have you intsalled?\r\nAlso can you please print the o/p of ;\r\n```python\r\nimport tensorflow as tf\r\ntf.test.is_built_with_gpu_support()\r\n```", "> @sonfiree Is this still an issue? TF 2.0 requires CUDA 10.0. What version of cuda have you intsalled?\r\n> Also can you please print the o/p of ;\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> tf.test.is_built_with_gpu_support()\r\n> ```\r\n\r\n\r\nUnfortunately there was a wrong question.\r\nI want to run cpu code installed version for gpu", "If a TensorFlow operation has both CPU and GPU implementations, by default the GPU devices will be given priority when the operation is assigned to a device.\r\n\r\nYou can do manual placement of devices and execute ops on cpu.\r\nSee https://www.tensorflow.org/guide/gpu#manual_device_placement\r\nFor example;\r\n```python\r\ntf.debugging.set_log_device_placement(True)\r\n\r\n# Place tensors on the CPU\r\nwith tf.device('/CPU:0'):\r\n  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\n  c = tf.matmul(a, b)\r\nprint(c)\r\n```\r\nOutput:\r\n```python\r\nTensor(\"MatMul_1:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\r\n```", "\r\nAnd how to use this together with the tf.keras API?\r\n```\r\nwith tf.device('/CPU:0'):\r\n   code...\r\n\r\n```", "This is broken in tf 1.14 as well \r\ndevice_count = {'GPU': 0} is ignored and gpu is prioritized anyway.\r\nIf you run the CUDA_VISIBLE_DEVICES=0 environment variable then tensorflow just crashes saying it cannot find the gpu.\r\n\r\nMy automated tests found this one because i use the gpu to run other tests using differing ml libraries which use vram. Tensorflow will not release gpu memory once its initialized without killing the process which means i have to run tensorflow on the cpu so it does not interfere with the other tests. With this broken i may have to split the tests for the code that calls tensorflow into its own separate test library and run it first so that when its process  ends gpu ram is released. Or somehow get these broken settings to work again so that tensorflow will prioritize and run on the CPU rather than GPU.", "`device_count = {'GPU': 0}`, it`s work for me in tf1.14", "Not sure about that my tests were passing in 1.12 but broke when i upgraded to 1.14 and im seeing TF forced to gpu where it breaks tensorRT libraries im using. At any rate setting CUDA_VISIBLE_DEVICES=0 should force to CPU in 1.14 and that isn't working either.", "I launched two identical models.\r\nI launched the first one on GPU (1060) and loaded the memory to the maximum\r\nThe second on the CPU and downloaded 2x from the GPU.\r\nDepartures weren\u2019t working.", "> And how to use this together with the tf.keras API?\r\n> \r\n> ```\r\n> with tf.device('/CPU:0'):\r\n>    code...\r\n> ```\r\n\r\nApologies for the delay in response. Yes that approach will do. "]}, {"number": 33193, "title": "AutoGraph returns an empty array when I use a for-loop and TensorArray", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.x\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: - \r\n- GPU model and memory: -\r\n\r\nHello! Here is a sniped of code:\r\n```python\r\na = np.array([1, 2, 3], np.int32)\r\n\r\n@tf.function  # works without the decorator\r\ndef foo(a):\r\n  b = tf.TensorArray(tf.string, 4)\r\n  b.write(0, \"test\")\r\n  for i in tf.range(3):\r\n    if a[i] == 2:\r\n      b.write(i, \"fuzz\")\r\n    elif a[i] == 3:\r\n      b.write(i, \"buzz\")\r\n  return b.stack()\r\n\r\nprint(foo(a))\r\n```\r\nWith the decorator, the AutoGraph returns an empty array:\r\n`tf.Tensor([b'' b'' b'' b''], shape=(4,), dtype=string)`\r\n\r\nHowever, it shoud return:\r\n`tf.Tensor([b'test' b'fuzz' b'buzz' b''], shape=(4,), dtype=string)`\r\n", "comments": ["@Rendok, This works for me,\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\na = np.array([1, 2, 3], np.int32)\r\n\r\n@tf.function  # works without the decorator\r\ndef foo(a):\r\n  b = tf.TensorArray(tf.string, 4)\r\n  b = b.write(0, \"test\")\r\n  for i in tf.range(3):\r\n    if a[i] == 2:\r\n      b = b.write(i, \"fuzz\")\r\n    elif a[i] == 3:\r\n      b = b.write(i, \"buzz\")\r\n  return b.stack()\r\n\r\nprint(foo(a))\r\n```\r\nIt return:\r\n`tf.Tensor([b'test' b'fuzz' b'buzz' b''], shape=(4,), dtype=string)`\r\n", "Hi @gadagashwini,\r\n\r\nIt doesn't work on my side. I have a fresh install of TF 2.0 from binary. Probably, one of the dependencies is too fresh. Here is a [colab](https://colab.research.google.com/drive/17KHUJS9PWC_vh8Tj56eGQwTPfkSDE_eS) for reproducibility. \r\n", "@Rendok, \r\nIts strange, When I tried on Colab with TF 2.0.0, I got the expected result. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/1cbece92b179923ab9b2c34361a03176/untitled191.ipynb). Thanks! ", "@gadagashwini,\r\n\r\nI found the issue.\r\nThis version works with and withount `@tf.function`\r\n```python\r\n@tf.function\r\ndef foo(a):\r\n  b = tf.TensorArray(tf.string, 4)\r\n  b = b.write(0, \"test\")\r\n  for i in tf.range(3):\r\n    if a[i] == 2:\r\n      b = b.write(i, \"fuzz\")\r\n    elif a[i] == 3:\r\n      b = b.write(i, \"buzz\")\r\n  return b.stack()\r\n```\r\nHowever, this version works only withount `@tf.function`\r\n```python\r\n@tf.function\r\ndef foo1(a):\r\n  b = tf.TensorArray(tf.string, 4)\r\n  b.write(0, \"test\")  # here istead of b = b.write(0, \"test\")\r\n  for i in tf.range(3):\r\n    if a[i] == 2:\r\n      b.write(i, \"fuzz\")\r\n    elif a[i] == 3:\r\n      b.write(i, \"buzz\")\r\n  return b.stack()\r\n```\r\n`TensorArray` becomes immutable in GraphMode.\r\n\r\nThanks!", "@kkimdev FYI\r\n\r\nIndeed, this is a known consistency that has caused quite a bit of confusion. We are looking into ways to make the two behaviors consistent: either by making `ta.write(i, value)` work in graph or by raising an error when it's used in eager.\r\n\r\nUntil this is resolved, the workaround is to write `ta = ta.write(i, value)`, as you pointed out.", "@Rendok, This issue is not fixed in Tf2.2rc2, Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/f4e4d2a3a96058a072fccdf77748d275/33193.ipynb). Thanks", "Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/89651333269bdf262dff0ead45c7e05d/33193.ipynb). Thanks!", "@Rendok I was able to run the code without any error in the recent Tensorflow version 2.5, please find the gist [here](https://colab.research.google.com/gist/googly789/babde65dbbd022be58fdbf9ada6f7aff/203.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33193\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33193\">No</a>\n"]}, {"number": 33192, "title": "Incorrect result when subtracting 1 from exponential of Variable ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Intel Iris Plus Graphics 640 1536 MB\r\n\r\n**Describe the current behavior**\r\nWith the following setup\r\n```\r\nsession = tf.Session()\r\nvariable = tf.Variable(4j)\r\nexp = tf.exp(variable)\r\nsession.run(tf.global_variables_initializer())\r\n```\r\nthe following code\r\n```\r\nprint(session.run(exp-1))\r\nprint(session.run(exp)-1)\r\n```\r\nproduces two different outputs, specifically:\r\n```\r\n(2.897081749192498+1.3258713481172573j)\r\n(-1.6536436208636118-0.7568024953079282j)\r\n```\r\n\r\n**Describe the expected behavior**\r\nThat code should print identical arrays (the latter is correct, the former is not). \r\n\r\n**Code to reproduce the issue**\r\n```\r\nsession = tf.Session()\r\nvariable = tf.Variable(4j)\r\nexp = tf.exp(variable)\r\nsession.run(tf.global_variables_initializer())\r\n\r\nprint(session.run(exp-1))\r\nprint(session.run(exp)-1)\r\n```\r\nAlso see Colab notebook here: https://colab.research.google.com/drive/1KT2gfuWeezhWOr3zfyHhk9HvCH7JcShm\r\n\r\n**Other info / logs**\r\nI have no idea what's happening, but some observations:\r\n - there needs to be a Variable involved. If I use a constant instead of a Variable, all works as expected.\r\n - the exponent value is important. If I change the 4's to 1's then all works as expected, for example.\r\n - the TF exponential is important. If instead I calculate the exponential with numpy and then set the Variable to that exponential, subtracting 1 works correctly.\r\n - specifically subtracting 1 seems important. If instead I subtract 2, or 0.1, or 1j, all works as expected.", "comments": ["I have tried on colab with TF version 1.14, 1.15.0-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/dd87c7a8f850af52f1d667d1eac67899/untitled257.ipynb). Thanks!", "Exp and Exp-1 are two different values. How can they produce the same result.  print(session.run(exp-1)) produces the result of value which is equal to exp - 1.\r\nprint(session.run(exp)-1) produces the result equal to one subtracted from the result of value which equals exp. Hence they are two different. I guess there is no issue. It is working properly. ", "Sorry, I don't follow. In both cases you describe, the eventual value printed should be the value of e^(4j)-1.", "It looks like a bug in Eigen, specifically `expm1` seems to produce incorrect results for complex numbers with imaginary part 4 or greater. I've asked a few folks internally who are familiar with the code, but it would be nice to confirm this with the Eigen team.\r\n\r\nThe reason why the bug only manifests for variables is most likely a consequence of how the optimizer simplifies mathematical expressions.", "Ah, nice find! It hadn't even occurred to me that `exp(x)-1` might get simplified to a single function call, but in hindsight that makes sense.", "Hi, I submitted\r\nhttps://gitlab.com/libeigen/eigen/merge_requests/18\r\nin Eigen, which fixes Eigen's implementation of expm1.\r\n\r\nThis is being used in the current tf-nightly:\r\n\r\n>>> tf.math.expm1(4j)\r\n<tf.Tensor: shape=(), dtype=complex128, numpy=(-1.653643620863612-0.7568024953079282j)>\r\n\r\nThis issue should be fixed now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33192\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33192\">No</a>\n", "Thanks!", "Should we expect the next minor release (2.1.0, I guess) to have the fix?", "Turns out 2.2.0 has the fix"]}, {"number": 33191, "title": "_resampler_ops.so not found", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.10.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nin my Win10 OS,i create a virtualevn with pycharm, one of is tensorflow1.10.0, and another is tensorflow2.0.0,when tf2.0 works, that run tf1.10 project,it broken\r\nbug info:\r\ntensorflow.python.framework.errors_impl.NotFoundError: E:\\python\\lib\\site-packages\\tensorflow\\contrib\\resampler\\python\\ops\\_resampler_ops.so not found \r\nbase issues 20320,i remove this file, it works,but there is 10+ files need to remove,\r\nhttps://github.com/tensorflow/tensorflow/issues/20320\r\n\r\nand next i run this project ,it happen again\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ares5221 ,\r\nCan you confirm for both 2.0 and 1.10 you have installed TF from source using bazel? Thanks!", "> @ares5221 ,\r\n> Can you confirm for both 2.0 and 1.10 you have installed TF from source using bazel? Thanks!\r\n\r\nsorry\uff0cit is install by binary ,in linux pip install tensorflow==2.0.0", "@ares5221 ,\r\nAs some apis are removed or moved to different tf packages like `contrib` is removed in TF 2.0. The same code might not run in TF 1.X, please modify the code according to TF versions and try running.", "> @ares5221 ,\r\n> As some apis are removed or moved to different tf packages like `contrib` is removed in TF 2.0. The same code might not run in TF 1.X, please modify the code according to TF versions and try running.\r\n\r\nthks", "@ares5221 ,\r\nLet us know if the issue can be closed, thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 33190, "title": "A bug in 'MoveBinaryOperatorBeforeReshape' graph_transformations  during tflite_convert.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from source\r\n- TensorFlow version (use command below): ('v2.0.0-0-g64c3d38', '2.0.0')\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n- CUDA/cuDNN version: 10.0 / 7.5\r\n- GPU model and memory: GeForce GTX TITAN\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe outputs of the tflite model (*.tflite), converted by the tflite_convert, are totally different from the original pre-trained saved_model.\r\n\r\nWhen I tries to fix that, I finally got the right outputs by suppressing 'MoveBinaryOperatorBeforeReshape' of the graph_transformations (tensorflow/lite/toco/graph_transformations).  To do this, I removed the operations from parts of the source codes (tensorflow/lite/toco/BUILD, tensorflow/lite/toco/toco_tooling.cc, ,tensorflow/lite/toco/graph_transformations/graph_transformations.h) and built a package from it.\r\n\r\nI compared the two versions of the tflite models, by using the visualization tool (bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html). I found out that when the MoveBinaryOperatorBeforeReshape is turned on, the tflite_convert removes a specific ADD op and its one constant input tensor from my graph. Then it was the very reason I got the different output. \r\n\r\nThis seems a bug to me so that I want to report this.\r\n\r\nSince my graph is too big, and I cannot share my codes, models nor figures, I want to share the responsible part of the visualization results. I strongly recommend to draw graphs for better understanding.\r\n\r\nConsider following as tables,  columns are seperated by '|'.\r\n\r\n***Original Graph (which gives wrong output)***\r\nOperations\r\n```\r\nindex | inputs | outputs | builtin_options | opcode_index\r\n69 | [175, 43, 4154] | [185] | {u'fused_activation_function':   u'NONE', u'stride_h': 1, u'padding': u'VALID', u'stride_w': 1,   u'dilation_h_factor': 1, u'dilation_w_factor': 1} | CONV_2D (2)\r\n100 | [185, 186] | [190] | {u'new_shape': [1, 600, 512]} | RESHAPE (5)\r\n126 | [190, 1518] | [1517] | {u'keep_dims': True} | MEAN (10)\r\n127 | [190, 1517] | [1529] | {u'fused_activation_function':   u'NONE'} | SUB (11)\r\n128 | [190, 1517] | [1528] | {u'fused_activation_function':   u'NONE'} | SUB (11)\r\n341 | [1539, 190] | [1516] | {u'fused_activation_function':   u'NONE'} | ADD (0)\r\n```\r\nTensors\r\n```\r\nindex | name | type | shape | buffer | quantization\r\n43 | Identity_16 | FLOAT32 | [512, 1, 1, 240] | 2051 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n175 | body/model/parallel_0/body/ExpandDims_2 | FLOAT32 | [1, 600, 1, 240] | 1816 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n4154 | body/model/parallel_0/body/prepare_transform_before_single/Conv2D_bias | FLOAT32 | [512] | 2053 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n185 | body/model/parallel_0/body/Squeeze | FLOAT32 | [1, 600, 1, 512] | 2338 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n186 | body/model/parallel_0/body/Squeeze_shape | INT32 | [3] | 2110 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n190 | body/model/parallel_0/body/add_1 | FLOAT32 | [1, 600, 512] | 1098 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n```\r\n\r\n\r\n\r\n***Fixed Graph ('MoveBinaryOperatorBeforeReshape' suppressed and gives the right outputs)***\r\nOperations\r\n```\r\nindex | inputs | outputs | builtin_options | opcode_index\r\n69 | [175, 43, 4156] | [4155] | {u'fused_activation_function':   u'NONE', u'stride_h': 1, u'padding': u'VALID', u'stride_w': 1,   u'dilation_h_factor': 1, u'dilation_w_factor': 1} | CONV_2D (2)\r\n98 | [4155, 186] | [185] | {u'new_shape': [1, 600, 512]} | RESHAPE (5)\r\n101 | [190, 185] | [191] | {u'fused_activation_function':   u'NONE'} | ADD (0)\r\n127 | [191, 1519] | [1518] | {u'keep_dims': True} | MEAN (10)\r\n128 | [191, 1518] | [1530] | {u'fused_activation_function':   u'NONE'} | SUB (11)\r\n129 | [191, 1518] | [1529] | {u'fused_activation_function':   u'NONE'} | SUB (11)\r\n342 | [1540, 191] | [1517] | {u'fused_activation_function':   u'NONE'} | ADD (0)\r\n```\r\nTensors \r\n```\r\nindex | name | type | shape | buffer | quantization\r\n43 | Identity_16 | FLOAT32 | [512, 1, 1, 240] | 2055 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n175 | body/model/parallel_0/body/ExpandDims_2 | FLOAT32 | [1, 600, 1, 240] | 1819 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n4156 | body/model/parallel_0/body/prepare_transform_before_single/Conv2D_bias | FLOAT32 | [512] | 2057 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n4155 | body/model/parallel_0/body/prepare_transform_before_single/BiasAdd | FLOAT32 | [1, 600, 1, 512] | 1547 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n186 | body/model/parallel_0/body/Squeeze_shape | INT32 | [3] | 2114 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n190 | body/model/parallel_0/body/add | FLOAT32 | [1, 600, 512] | 1845 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n185 | body/model/parallel_0/body/Squeeze | FLOAT32 | [1, 600, 512] | 2342 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n191 | body/model/parallel_0/body/add_1 | FLOAT32 | [1, 600, 512] | 1098 | {u'quantized_dimension': 0,   u'details_type': 0}\r\n```\r\n\r\nRest of the operations are the same. Total number of graphs are different only by 1. In the fixed graph, the ADD op 101 has one constant tensor (with none-zero values) and one variable tensor input. It is missing from the original graph, I don't understand why the tflite_convert removes it.\r\n\r\n\r\n**Code to reproduce the issue**\r\nI could not find reproducing code.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@paanguin,\r\nIs this still an issue? Could you please update TensorFlow to v2.3 and check if you are facing the same issue?\r\n\r\n\r\n>Since my graph is too big, and I cannot share my codes, models nor figures, I want to share the responsible part of the >visualization results. I strongly recommend to draw graphs for better understanding.\r\n\r\nAlso, without a reproducible code it would be difficult for us to debug the issue. Could you please provide a minimal working example to reproduce the issue on our end, so that we can take a look at it. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33190\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33190\">No</a>\n"]}, {"number": 33189, "title": "TFTRT:  Huge events file generated.", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.14\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nVery very large events files  are generated  when TF-TRT is enabled.  These files are so big that Tensorboard is able to handle those.  For example,  in one network, TF produces an event file of 4.6 MB size. The  same network after TF-TRT compile, generates an event file of 1.3 GB !! \r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nA reasonable size. \r\n\r\n**Code to reproduce the issue**\r\nNot able to provide any code at this point.   However, the sympton is possibly reproducible with any large network such as ResNet1XX . \r\n\r\n**Other info / logs**\r\n\r\n", "comments": ["@sgambient Could you provide more details on TF-TRT compile so that we can find root-cause of the issue. If you can provide any standalone code would be better. Thanks!", "@sgambient Is this still an issue? Please close the issue if this was resolved already. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33189\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33189\">No</a>\n"]}, {"number": 33188, "title": "Duplicated Gradient issue during TF Lite conversion with 1.13.2", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source with tag v1.13.2\r\n- TensorFlow version (use command below): b'v1.13.2-0-g04256c89d8' 1.13.2\r\n- Python version:3.6.5\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): 4.9.2\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe following error happened when I was convert my model to tf.lite. It's quite similar to #24525 .\r\n```python\r\nTraceback (most recent call last):\r\n  File \"tfconvert.py\", line 18, in <module>\r\n    tflite_quantized_model = converter.convert()\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-10-10 10:12:14.730948: F tensorflow/core/framework/function.cc:1626] Check failed: GetOpGradFactory()->insert({op, func}).second Duplicated gradient for MapAccumulate\r\n```\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\r\n    model_path, input_arrays=input_arrays, output_arrays=output_arrays, input_shapes=input_shapes)\r\nconverter.post_training_quantize=True\r\nconverter.target_ops = [\r\n    # tf.lite.OpsSet.TFLITE_BUILTINS,\r\n    tf.lite.OpsSet.SELECT_TF_OPS\r\n]\r\ntflite_quantized_model = converter.convert()\r\nopen(\"quantized_model.tflite\", \"wb\").write(tflite_quantized_model)\r\n```\r\n\r\nAny help will be appreciated! Thanks in advance.", "comments": ["Sorry to bother you. Maybe there's sth. wrong with my environment."]}, {"number": 33187, "title": "Support \"fetch_skip_sync=false\" in Callable", "body": "**System information**\r\n- TensorFlow version (you are using): 1.15.0\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAs suggested in #5902, feeding / fetching GPU tensors is possible with Callable, however, [`fetch_skip_sync`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L764) must be set to true as the otherwise is not implemented. Based on the comment for `fetch_skip_sync` field, then the user will need to invoke `Device::Sync()`, which can be bad if the device is being shared with other models.\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\nUse case that serves multiple models on the same GPU device.\r\n\r\n**Any Other info.**\r\nAfter some digging around, it seems like Callable just adds a \"RetVal\" op to the original graph and take the original output as its input, which I don't see any data movement. So my other question is whether the `Device::Sync()` is necessary?", "comments": ["@asimshankar Thanks for your contribution to make GPU I/O possible, I know it's being a while, do you mind to provide some insight on why `Device::Sync()` is necessary?", "@GuanLuo \r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "+1 to this issue. Currently it's not totally clear how to get the CUDA streams a session is using, in order to make `Device::Sync()` possible.\r\nI think an implemented `skip_fetch_sync=false` would solve this issue.", "I don't think you need the CUDA streams being used to call `Device::Sync`, if you're comfortable writing C++ you should be able to get the set of `Device`s by `DeviceFactory::AddDevices` and then call `Device::Sync` on the correct device yourself.", "@sanjoy Thank you for your reply. Could you as well share some code snippets for your idea?", "@golden0080 I don't have a readymade example right now, but maybe you could poke at the TF codebase to see how these methods are used?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "No, the `skip_fetch_sync=false` feature is still not implemented on current master."]}, {"number": 33186, "title": "Remove deprecate warning caused by usage of parallel_interleave in tf.data", "body": "While playing with make_csv_dataset the following warning showed up:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n```\r\n\r\nThis fix adds an wrapper of _parallel_interleave so that the deprecated warning could be removed.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["So you go to the readers.py file and replace parallel_interleave with interleave instead. How do you propose the change be done?"]}, {"number": 33185, "title": "Link to TensorBoard: Graph Visualization is broken", "body": "I am reading about tensorboard here: https://www.tensorflow.org/tensorboard/r1/summaries\r\n\r\nOn this page the link to *TensorBoard: Graph Visualization* is broken. This is the link: https://www.tensorflow.org/tensorboard/guide/graph_viz", "comments": ["@abhilashshakti I agree the link is not working. We will update soon. In the mean time you can take a look at the [`TensorBoard: Graph Visualization`](https://www.tensorflow.org/tensorboard). Thanks!", "Thanks for the report @abhilashshakti\r\n\r\nI've sent a PR with a fix, but remember that you can too. The github edit button makes thios sort of thing easy to fix without ever leaving your browser.", "Thanks for looking into the request. ", "The link https://www.tensorflow.org/tensorboard/guide/graph_viz is still broken", "Thanks for the ping! The docs for TensorFlow 1.x, including the one that\r\nyou mention (<https://www.tensorflow.org/tensorboard/r1/summaries>), are\r\nnow hosted on GitHub rather than tensorflow.org. The tensorflow.org link\r\nnow redirects to the new source of truth, where the \u201cTensorBoard: Graph\r\nVisualization\u201d link works:\r\n<https://github.com/tensorflow/tensorboard/blob/master/docs/r1/summaries.md>\r\n", "Awesome, thanks!\n\nOn Mon, Dec 2, 2019 at 12:20 PM William Chargin <notifications@github.com>\nwrote:\n\n> Thanks for the ping! The docs for TensorFlow 1.x, including the one that\n> you mention (https://www.tensorflow.org/tensorboard/r1/summaries), are\n> now hosted on GitHub rather than tensorflow.org. The tensorflow.org link\n> now redirects to the new source of truth, where the \u201cTensorBoard: Graph\n> Visualization\u201d link works:\n> https://github.com/tensorflow/tensorboard/blob/master/docs/r1/summaries.md\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33185?email_source=notifications&email_token=ACCXT6WN6JWNBA4EWJ4IZ5DQWVUZ7A5CNFSM4I7GNX2KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFUYP4Q#issuecomment-560564210>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ACCXT6QFWA5GSB3D77QIGADQWVUZ7ANCNFSM4I7GNX2A>\n> .\n>\n"]}, {"number": 33184, "title": "TF-TRT batchSize > 0 && batchSize <= MAX_BATCH_SIZE", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nSeeing the following error.\r\n\r\n```\r\n2019-10-09 22:38:11.629630: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:632] Building a new TensorRT engine for XXX input shapes: [[0,28,28,128]]\r\n2019-10-09 22:38:11.629841: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger Parameter check failed at: ../builder/builder.cpp::setMaxBatchSize::113, condition: batchSize > 0 && batchSize <= MAX_BATCH_SIZE\r\n```\r\n\r\n**Describe the expected behavior**\r\nIdeally, would not like to see the error.   As currently seeing  the error,  more information along the following line will help a lot determining the root cause.\r\n\r\n1.  See more detailed  log on what the offending  layers and tensors are. \r\n2.  What  exactly is the value that is the issue, in this case batchSize ? \r\n3. Where  in  code this is  occurring - do not see any file called builder* in TF 1.14 source. \r\n    If error in happening elsewhere in third-party code ( in this case , may be in NVIDIA  TensorRT closed source )  - making that explicit. \r\n4. In this case, where is it getting 0 for batch size. \r\n\r\n**Code to reproduce the issue**\r\nIt is not possible to provide code for every issue.  Better logging is a much more  efficient way to root cause and resolve issues. \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sgambient,\r\nYou have mentioned, \r\n\r\n> See more detailed log on what the offending layers and tensors are.\r\n\r\n Can you please provide detailed log, as mentioned above. Also, if your code is confidential, can you please provide dummy code so that we can reproduce the issue. We ask for repro code because it will be difficult to provide resolution without being able to reproduce the issue at our end. Thanks.", "Would not be possible for me to spend time to get you a toy code.  You should add more logs or traces. ", "@sgambient Sorry for the delay in my response. Can you try with TF1.15 stable version as there were some known issues with TF1.14.0? Thanks!", "@sgambient Based on the log it seems the model gets an input with 0 elements, could you help to confirm that?\r\n\r\nAlso @pooyadavoodi ", "Also @sanjoy ", "This is probably a bug in TF-TRT. Somehow it generates a tensor with 0 batch size as the input to TRT. I am assuming the input to the graph has a valid shape.\r\n\r\nI also agree that the log can be improved. It needs to be improved inside TRT. I'll report that.", "> I also agree that the log can be improved. It needs to be improved inside TRT. I'll report that.\r\nThis is already improved in the future versions of TRT.\r\n", "I am also seeing this while using TF2.1 and TensorRT 7. Not sure where this should be reported, but maybe someone here knows. Here's what mine looks like:\r\n`2020-01-23 21:07:28.087833: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ClipToWindow_87/TRTEngineOp_88 with\r\ninput shapes: [[0,4]]\r\n2020-01-23 21:07:28.096508: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger Parameter check failed at: ../builder/builder.cpp::setMaxBatchSize::135, condition: batchSize > 0 && batchSize <= MAX_BATCH_SIZE`", "System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below):2.1\r\nPython version:3.6\r\nBazel version (if compiling from source): N/A\r\nGCC/Compiler version (if compiling from source): N/A\r\nCUDA/cuDNN version:10.2/7.6\r\nGPU model and memory:Nvidia Tesla V100\r\n\r\nRecreate steps:\r\n-Clone repository below and follow instructions\r\nhttps://github.com/tensorflow/tensorrt/tree/master/tftrt/examples/object_detection\r\n-Models used came from here https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nFor my specific examples I tried mask_rcnn_inception_v2_coco and faster_rcnn_inception_v2_coco", "@bixia1 could you help to take a look at the repro above? Thanks.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33184\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33184\">No</a>\n"]}, {"number": 33183, "title": "RuntimeError: dictionary changed size during iteration", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.15 Beta (virtual environment)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: virtualenv pip\r\n\r\n**Describe the problem**\r\nI run into this issue where I can't test the most basic Tensorflow program cause it gives me this error at the end:\r\nRuntimeError: dictionary changed size during iteration\r\n\r\nI was trying to work on a virtual environment I had already setup but it wasn't working either and it kept giving me that error. So I created a new one from cero and it keeps giving me the error. The tensorflow is properly installed (according to the instructions) but when I try to run the simple program to test it. It gives me the error. I'll add to the log the error and the log of when the Tensorflow is being installed. I hope this is not an unique issue. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n\u279c  ML python3 -m venv env\r\n\u279c  ML source env/bin/activate\r\n(env) \u279c  ML pip install --upgrade pip\r\n(env) \u279c  ML pip install tensorflow\r\n(env) \u279c  ML python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n_and here I get the error._ \r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n**(env) \u279c  ML pipip install tensorflow**\r\n\r\nCollecting tensorflow\r\n  Using cached https://files.pythonhosted.org/packages/2c/72/6b3264aa2889b7dde7663464b99587d95cd6a5f3b9b30181f14d78a63e64/tensorflow-2.0.0-cp37-cp37m-macosx_10_11_x86_64.whl\r\nCollecting wrapt>=1.11.1 (from tensorflow)\r\nCollecting keras-preprocessing>=1.0.5 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\r\nCollecting gast==0.2.2 (from tensorflow)\r\nCollecting keras-applications>=1.0.8 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\r\nCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl\r\nCollecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl\r\nCollecting numpy<2.0,>=1.16.0 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/b4/e8/5ececadd9cc220bb783b4ce6ffaa9266925d37ed41237bc23bc530ab4f3d/numpy-1.17.2-cp37-cp37m-macosx_10_6_intel.whl\r\nCollecting termcolor>=1.1.0 (from tensorflow)\r\nCollecting google-pasta>=0.1.6 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl\r\nCollecting grpcio>=1.8.6 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/75/07/f1d41d10519ca165b0e078949078f20beb57e7e46dc0f1d56b73bb01270a/grpcio-1.24.1-cp37-cp37m-macosx_10_9_x86_64.whl\r\nCollecting opt-einsum>=2.3.2 (from tensorflow)\r\nCollecting wheel>=0.26 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\r\nCollecting six>=1.10.0 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\r\nCollecting absl-py>=0.7.0 (from tensorflow)\r\nCollecting protobuf>=3.6.1 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/a5/c6/a8b6a74ab1e165f0aaa673a46f5c895af8780976880c98934ae82060356d/protobuf-3.10.0-cp37-cp37m-macosx_10_9_intel.whl\r\nCollecting astor>=0.6.0 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\r\nCollecting h5py (from keras-applications>=1.0.8->tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/1a/8b/4d01ae9a9d50a0bcc7b0b9aae41785d8d9de6fa9bba04dc20b1582181d2d/h5py-2.10.0-cp37-cp37m-macosx_10_6_intel.whl\r\nCollecting werkzeug>=0.11.15 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl\r\nCollecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\r\nCollecting setuptools>=41.0.0 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/6a/9a/50fadfd53ec909e4399b67c74cc7f4e883488035cfcdb90b685758fa8b34/setuptools-41.4.0-py2.py3-none-any.whl\r\nInstalling collected packages: wrapt, six, numpy, keras-preprocessing, gast, h5py, keras-applications, grpcio, wheel, werkzeug, setuptools, markdown, protobuf, absl-py, tensorboard, tensorflow-estimator, termcolor, google-pasta, opt-einsum, astor, tensorflow\r\n  Found existing installation: setuptools 40.8.0\r\n    Uninstalling setuptools-40.8.0:\r\n      Successfully uninstalled setuptools-40.8.0\r\nSuccessfully installed absl-py-0.8.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.24.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.17.2 opt-einsum-3.1.0 protobuf-3.10.0 setuptools-41.4.0 six-1.12.0 tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0 termcolor-1.1.0 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\r\n**(env) \u279c  ML pypython -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"**\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 959, in _find_and_load_unlocked\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/google/protobuf/__init__.py\", line 37, in <module>\r\n    __import__('pkg_resources').declare_namespace(__name__)\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 84, in <module>\r\n    __import__('pkg_resources.extern.packaging.requirements')\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 9, in <module>\r\n    from pkg_resources.extern.pyparsing import stringStart, stringEnd, originalTextFor, ParseException\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 668, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 638, in _load_backward_compatible\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/extern/__init__.py\", line 43, in load_module\r\n    __import__(extant)\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 4756, in <module>\r\n    _escapedPunc = Word( _bslash, r\"\\[]-*.$+^?()~ \", exact=2 ).setParseAction(lambda s,l,t:t[0][1])\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1284, in setParseAction\r\n    self.parseAction = list(map(_trim_arity, list(fns)))\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1066, in _trim_arity\r\n    this_line = extract_stack(limit=2)[-1]\r\n  File \"/Users/marialopez/projects/ML/env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1050, in extract_stack\r\n    frame_summary = traceback.extract_stack(limit=-offset+limit-1)[offset]\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 211, in extract_stack\r\n    stack = StackSummary.extract(walk_stack(f), limit=limit)\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 363, in extract\r\n    f.line\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 285, in line\r\n    self._line = linecache.getline(self.filename, self.lineno).strip()\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\", line 16, in getline\r\n    lines = getlines(filename, module_globals)\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\", line 48, in getlines\r\n    for mod in sys.modules.values():\r\nRuntimeError: dictionary changed size during iteration\r\n```", "comments": ["I tried to reproduce locally, using python3 (3.6 in my case) and your instructions as well as forcing a virtual env with python 3.7.3.\r\n\r\nIn both cases, the code run ok for me :-/ I am on a Linux though, but I never encountered this before on a Mac, either\r\n\r\nIn your log I see that the error gets outside of the virtualenv and seems to be coming from there and not from TensorFlow.\r\n\r\nLeaving open and will try more investigations", "Same issue.", "I am experiencing this same issue as well. I am using MacOS Catalina. Steps to reproduce this:\r\n\r\n```\r\npython3 -m venv myenv-env\r\nsource myenv-env/bin/activate\r\npip install tensorflow\r\npython -c 'import tensorflow'\r\n```\r\n\r\nI get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 959, in _find_and_load_unlocked\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/google/protobuf/__init__.py\", line 37, in <module>\r\n    __import__('pkg_resources').declare_namespace(__name__)\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 84, in <module>\r\n    __import__('pkg_resources.extern.packaging.requirements')\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 9, in <module>\r\n    from pkg_resources.extern.pyparsing import stringStart, stringEnd, originalTextFor, ParseException\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 668, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 638, in _load_backward_compatible\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/extern/__init__.py\", line 43, in load_module\r\n    __import__(extant)\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 4756, in <module>\r\n    _escapedPunc = Word( _bslash, r\"\\[]-*.$+^?()~ \", exact=2 ).setParseAction(lambda s,l,t:t[0][1])\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1284, in setParseAction\r\n    self.parseAction = list(map(_trim_arity, list(fns)))\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1066, in _trim_arity\r\n    this_line = extract_stack(limit=2)[-1]\r\n  File \"/Users/hari/Projects/3DDetection/3DDetection-env/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1050, in extract_stack\r\n    frame_summary = traceback.extract_stack(limit=-offset+limit-1)[offset]\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 211, in extract_stack\r\n    stack = StackSummary.extract(walk_stack(f), limit=limit)\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 363, in extract\r\n    f.line\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 285, in line\r\n    self._line = linecache.getline(self.filename, self.lineno).strip()\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\", line 16, in getline\r\n    lines = getlines(filename, module_globals)\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\", line 48, in getlines\r\n    for mod in sys.modules.values():\r\nRuntimeError: dictionary changed size during iteration\r\n```\r\n\r\nPlease let me know if you need more information", "I have two MacBook Pro running Catalina - one installation was successful - the other one not. The successful one is an inplace upgrade of the OS, so there is ton's of old stuff like Xcode, brew, .... the not successful one is a clean install, no Xocde, no brew, but Developer Tools installed. I used the same commands as harrygov plus I added\r\npip install --upgrade pip\r\npip install --upgrade setup tools\r\nIf I compare \"pip list\" on both venv - they are exactly the same. \r\n\r\nIn milg15 error dump there was a reference to /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/importlib/init.py\r\nOn my unsuccessful machine I have the same error - but on my successful machine this path does not exists  ... /Library/Developer/CommandLineTools/ only contains a usr folder...\r\n\r\nPlease ask if I can provide more info.\r\n", "So this seems to be an issue with the installed Python. Can you compare Python version on both systems, including all version metadata?\r\n\r\n```\r\nmihaimaruseac@ankh:~$ python\r\nPython 2.7.16 (default, Apr  6 2019, 01:42:57) \r\n[GCC 7.3.0] on linux2\r\n```", "I compared native and virtual environments ... they look very similar ... BUT ... the successful machine is using Clang 10.0.1 whereas the other one is using 11.0.0\r\n\r\ndetails:\r\n\r\n\r\nCatalina - Successful installation (Native)\r\n===========================================\r\n$ python\r\n\r\nWARNING: Python 2.7 is not recommended. \r\nThis version is included in macOS for compatibility with legacy software. \r\nFuture versions of macOS will not include Python 2.7. \r\nInstead, it is recommended that you transition to using 'python3' from within Terminal.\r\n\r\nPython 2.7.16 (default, Aug 24 2019, 18:37:03) \r\n[GCC 4.2.1 Compatible Apple LLVM 11.0.0 (clang-1100.0.32.4) (-macos10.15-objc-s on darwin\r\n\r\n\r\n$ python3\r\nPython 3.7.3 (default, Jun 19 2019, 07:38:49) \r\n[Clang 10.0.1 (clang-1001.0.46.4)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n\r\nCatalina - Successful installation (Virtual Env)\r\n================================================\r\nsource venv/bin/activate\r\n(venv) $ python\r\nPython 3.7.3 (default, Jun 19 2019, 07:38:49) \r\n[Clang 10.0.1 (clang-1001.0.46.4)] on darwin\r\n\r\n(venv) $ python3\r\nPython 3.7.3 (default, Jun 19 2019, 07:38:49) \r\n[Clang 10.0.1 (clang-1001.0.46.4)] on darwin\r\n\r\n`>>>` `import` tensorflow\r\n`>>>` `tensorflow.__version__`\r\n'2.0.0'\r\n\r\n\r\nCatalina - Non Successful installation (Native)\r\n================================================\r\n$ python\r\nWARNING: Python 2.7 is not recommended. \r\nThis version is included in macOS for compatibility with legacy software. \r\nFuture versions of macOS will not include Python 2.7. \r\nInstead, it is recommended that you transition to using 'python3' from within Terminal.\r\n\r\nPython 2.7.16 (default, Aug 24 2019, 18:37:03) \r\n[GCC 4.2.1 Compatible Apple LLVM 11.0.0 (clang-1100.0.32.4) (-macos10.15-objc-s on darwin\r\n\r\n\r\n$ python3\r\nPython 3.7.3 (default, Sep 18 2019, 14:29:06) \r\n[Clang 11.0.0 (clang-1100.0.33.8)] on darwin\r\n\r\n\r\n\r\nCatalina - Non Successful installation (Virtual Env)\r\n====================================================\r\n(venv) $ python\r\nPython 3.7.3 (default, Sep 18 2019, 14:29:06) \r\n[Clang 11.0.0 (clang-1100.0.33.8)] on darwin\r\n\r\n(venv) $ python3\r\nPython 3.7.3 (default, Sep 18 2019, 14:29:06) \r\n[Clang 11.0.0 (clang-1100.0.33.8)] on darwin\r\n", "I am also having the same issue. https://github.com/tensorflow/tensorflow/issues/33183#issue-504926250\r\nPython 3.7.3\r\nTensorflow 2.0\r\nmacOS Catalina", "Same issue, fresh macOS Catalina, virtualenv, python3\r\nClang 11.0.0, Python 3.7.3\r\n", "By replacing the line in linecache.py I have gotten past this:\r\n```\r\n            v = sys.modules.copy()\r\n            for mod in v:\r\n```", "> By replacing the line in linecache.py I have gotten past this:\r\n> \r\n> ```\r\n>             v = sys.modules.copy()\r\n>             for mod in v:\r\n> ```\r\n\r\nHad the same issue Clang 11.0.0, Python 3.7.3 macOS Catalina, your fix solved it for me.", "modules = sys.modules.copy()\r\nfor mod in modules.values():", "Just wanted to let you know that it's working now :)\r\nI did a complete reinstall of macos Catalina (including erasing the disks), did an\r\nxcode-select --install\r\ndownloaded python3, upgraded pip and setuptools\r\ninstalled jupyter\r\ncreated a virtual environment ... and magic ...\r\n\r\n(venv) $ python\r\nPython 3.7.5 (v3.7.5:5c02a39a0b, Oct 14 2019, 18:49:57) \r\n[Clang 6.0 (clang-600.0.57)] on darwin\r\n\r\nTo be honest - I have no idea why my \"old installations\" made use of Clang 10.0.1 or even 11.0.0 ... here we are back on 6.0 ... and tensorflow can be installed and imported without any issues.\r\n", "downgrade the python to 3.6 . python 3.7 is not supported Tensorflow \r\nhttps://www.pyimagesearch.com/2019/01/30/macos-mojave-install-tensorflow-and-keras-for-deep-learning/\r\n\r\nor \r\n\r\nyou can create a anaconda env of python3.6 \r\n`conda create -n tf_cpu6 pip python=3.6`\r\n`source activate tf_cpu6`\r\n`pip install --ignore-installed --upgrade tensorflow==1.15`", "Python3.7 is supported by TensorFlow.", "I am having the same issue I believe that the issue is Clang V11. Rather than revert back to Clang V6 I would have liked to replace a line in the file linecache.py but that file doesn't seem to exist on my local env.", "On three different laptops (both running the Catalina)\r\n\r\n## works\r\nPython 3.7.5 (default, Nov  1 2019, 02:16:23)\r\n[Clang 11.0.0 (clang-1100.0.33.8)] on darwin\r\n\r\n## works\r\nPython 3.7.4 \r\nClang 10.0.1 \r\n\r\n## does not work\r\nPython 3.7.3 (default, Oct 11 2019, 19:39:43)\r\n[Clang 11.0.0 (clang-1100.0.33.12)] on darwin", "For python 3.7.3 (native) on Catalina the following works (add `list()` to make a copy):\r\n\r\n\r\n```\r\n for mod in list(sys.modules.values()): # for mod in sys.modules.values():\r\n```\r\n\r\nNote in ln 48: /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py", "Same issue, fresh macOS Catalina, virtualenv , i just update python to 3.7.5 , i try it and its works!", "Same issue using virtualenv, Python = 3.7.3, upgraded to 3.7.5 and works fine", "Problem went away after switching back to Python 3.6.9", "> For python 3.7.3 (native) on Catalina the following works (add `list()` to make a copy):\r\n> \r\n> ```\r\n>  for mod in list(sys.modules.values()): # for mod in sys.modules.values():\r\n> ```\r\n> \r\n> Note in ln 48: /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\r\n\r\nThank, I solve my problem.\ud83e\udd23", "I confirm, updates from 3.7.3 to 3.7.5 fix the issue on macOS Catalina (v10.15.1) \ud83c\udf89", "> I confirm, updates from 3.7.3 to 3.7.5 fix the issue on macOS Catalina (v10.15.1) \ud83c\udf89\r\n\r\nHow did you update on the OS X? Is it safe to update the native python? ", "> > I confirm, updates from 3.7.3 to 3.7.5 fix the issue on macOS Catalina (v10.15.1) \ud83c\udf89\r\n> \r\n> How did you update on the OS X? Is it safe to update the native python?\r\n\r\nI haven't touch the system one, but have install one with `brew` and added an alias.", "I have the same problem on Catalina 10.15.2 with Python 3.7.3\r\nPython 3.7.3 (default, Nov 15 2019, 04:04:52) \r\n[Clang 11.0.0 (clang-1100.0.33.16)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> \r\n\r\nJust clean install tensorflow. \r\n\r\nBelow solved this problem by modify the line 48 of \"linecache.py\" file.\r\n\r\nfor mod in list(sys.modules.values()): # for mod in sys.modules.values():\r\n\r\nNote in ln 48: of ...../Python3.framework/Versions/3.7/lib/python3.7/linecache.py\r\n", "> I have the same problem on Catalina 10.15.2 with Python 3.7.3\r\n> Python 3.7.3 (default, Nov 15 2019, 04:04:52)\r\n> [Clang 11.0.0 (clang-1100.0.33.16)] on darwin\r\n> Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n> \r\n> > > >\r\n> \r\n> Just clean install tensorflow.\r\n> \r\n> Below solved this problem by modify the line 48 of \"linecache.py\" file.\r\n> \r\n> for mod in list(sys.modules.values()): # for mod in sys.modules.values():\r\n> \r\n> Note in ln 48: of ...../Python3.framework/Versions/3.7/lib/python3.7/linecache.py\r\n\r\nLY, works!", "This seems to be an issue with macos, not tensorflow. As such, I'm going to go ahead and close the issue.", "> > > I confirm, updates from 3.7.3 to 3.7.5 fix the issue on macOS Catalina (v10.15.1) \ud83c\udf89\r\n> > \r\n> > \r\n> > How did you update on the OS X? Is it safe to update the native python?\r\n> \r\n> I haven't touch the system one, but have install one with `brew` and added an alias.\r\n\r\nWould you mind sharing how specifically (commands)? thank you.", "Thanks - I ended up getting it resolved somehow.\n\nOn Sun, Feb 23, 2020 at 5:38 PM Luan Grillo <notifications@github.com>\nwrote:\n\n> Copy python3 to python, and run you script, works for me.\n> cp /usr/local/bin/python3 /usr/local/bin/python\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33183?email_source=notifications&email_token=AMXOF4RSYRKL2OQRGHLSEUDREKJ77A5CNFSM4I7FO3RKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMV62XY#issuecomment-590081375>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AMXOF4QSLVD6K4OCNQGBGMTREKJ77ANCNFSM4I7FO3RA>\n> .\n>\n", "I just found out. This Error occurs by nesting keras in a loop. After i changed variables manually and removed it from inside the loop, there are no longer errors occuring.", "> By replacing the line in linecache.py I have gotten past this:\r\n> \r\n> ```\r\n>             v = sys.modules.copy()\r\n>             for mod in v:\r\n> ```\r\n\r\nIt's works for me, thanks.", "> for mod in sys.modules.values():\r\n\r\nThanks, this worked for me as a charm.\r\nChanged to tensor flow 1.15 and just updated the linecache.py", "> For python 3.7.3 (native) on Catalina the following works (add `list()` to make a copy):\r\n> \r\n> ```\r\n>  for mod in list(sys.modules.values()): # for mod in sys.modules.values():\r\n> ```\r\n> \r\n> Note in ln 48: /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py\r\n\r\nIt WORKS for me . I find it here: /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/linecache.py"]}, {"number": 33182, "title": "tf.compat.v1.keras.backend.get_session gives erroneous deprecation warning", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nAccessing `tf.compat.v1.keras.backend.get_session` gives a deprecation warning telling you to use `tf.compat.v1.keras.backend.get_session`.\r\n\r\n**Describe the expected behavior**\r\n\r\nAccessing `tf.compat.v1.keras.backend.get_session` should not give a deprecation warning (since we're explicitly accessing the `compat.v1` namespace). Or it should direct the user to the correct function, if `tf.compat.v1.keras.backend.get_session` is not the right access point, rather than telling the user to use the namespace they're already using.\r\n\r\n**Code to reproduce the issue**\r\n``` python\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.keras.backend.get_session\r\n```\r\n\r\nThis results in the warning\r\n```\r\nThe name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\r\n```\r\n(note that we're accessing `tf.compat.v1.keras.backend.get_session`, not `tf.keras.backend.get_session`).\r\n", "comments": ["@drasmuss ,\r\nWhen tried running the given code, i didn't receive any warning for TF-2.0 and 2.0rc2. Please find the [gist](https://colab.sandbox.google.com/gist/oanush/d05cac5c0bc2d8ed785cbc67f7af0a83/33182.ipynb) of colab. \r\nCan you please provide gist if the issue is replicating from your end?Thanks!", "For some reason the warning doesn't show up when executing through colab, you need to run it as an external command. See [gist here](https://colab.research.google.com/gist/drasmuss/3be97c8968acee0c5476dba394f8a113/33182.ipynb).", "I have the same issue. ", "@drasmuss @fperrotta I ran it in my local (Mac Os) as well as in Colab. I don't see any warnings. Later today I will check it on Windows10. Thanks!", "I wonder if this is happening because i am loading a trained model file (hdf5) with tensor 1.15 and now i am importing it to apply with K.session and loader updates to tensor 2.x. @jvishnuvardhan\r\n", "Have the same issue here too ", "Have tried it in my local(ubuntu 18.02) and also on colab with tensorflow 2.2.0-rc2 and I didn't run into any issue. I am closing this issue right now. Please add additional comments for us to open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33182\">No</a>\n", "When I run the same gist from above (https://github.com/tensorflow/tensorflow/issues/33182#issuecomment-540553089), switching to TF2.2rc2, I still see exactly the same error.", "@drasmuss Can you please share the `test.py` file. Thanks!", "The file is created within the gist, see this code\r\n```\r\nwith open(\"test.py\", \"w\") as f:\r\n  f.write(\"import tensorflow as tf\\ntf.compat.v1.keras.backend.get_session\")\r\n```", "I'm also getting this problem. It doesn't happen if I paste the lines directly into an ipython console, but it does if I put them in a separate module and import that (or if I run that module directly from the command line)", "@drasmuss ,  The Warning is not showing anymore in the recent Tensorflow version 2.5, please find the [gist](https://colab.research.google.com/gist/googly789/2a8d6f5b1f3a995245acddfe1edefcbc/untitled40.ipynb) here.", "As mentioned [above](https://github.com/tensorflow/tensorflow/issues/33182#issuecomment-540553089) (and [here](https://github.com/tensorflow/tensorflow/issues/33182#issuecomment-633512048)), the warning doesn't show up when executing within colab, you have to run it as an external command. I have updated the [gist](https://colab.research.google.com/gist/drasmuss/3be97c8968acee0c5476dba394f8a113/33182.ipynb) to use 2.5.0, and it shows the same warning message as before.", "was able to replicate and resolve the issue in TF 2.5 by adding these lines. \r\n```\r\nimport logging, os\r\nlogging.disable(logging.WARNING)\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'  \r\n```\r\nplease find the gist [here ](https://colab.research.google.com/gist/mohantym/e45f039055d195f34be5b0a6b15aa42a/33182.ipynb#scrollTo=Q-l4usR8oPQw)", "That doesn't fix the problem, it just hides the erroneous warning.", "I could reproduce the issue with TF 2.6 .Please, find the gist [**`here`**](https://colab.research.google.com/gist/kumariko/962a8e4a96825e344610e728c0b957c0/untitled40.ipynb#scrollTo=IsjrTaJEiwM0).Thanks!", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "The issue still persists in TF 2.7, I created a new issue in the Keras repo here https://github.com/keras-team/keras/issues/15792", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33182\">No</a>\n"]}, {"number": 33181, "title": "Build TF 2.0 Windows", "body": "` C++ compilation of rule '//tensorflow/core/kernels:eigen_contraction_kernel_with_mkl' failed (Exit 2): python.exe failed: error executing command\r\n`\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): vs 2017\r\n- CUDA/cuDNN version: 7.4\r\n- GPU model and memory: 1060 6GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Does the command `python.exe` actually run in the console?", "> Does the command `python.exe` actually run in the console?\r\n\r\nyeap", "@sonfiree, Did you follow the instructions mentioned in [this link](https://www.tensorflow.org/install/source_windows). And also provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\npython ./configure.py \r\n       def all, Cuda try\r\nbazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n```\r\n\r\nTF 1.14 it`s work ", "@sonfiree, Please provide the CUDA version. And also include the complete error log. Thanks!", "CUDA 10.0 not work\r\nCUDA 10.1 not work", "Please provide full log. I suggest `bazel clean --expunge; bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package`", "The question can probably be hidden. I stayed at 1.4 and no longer plan to use TF. I turn to pytorch\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33181\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33181\">No</a>\n", "Well, you offered no information that could have helped in debugging and allowing us to help you"]}, {"number": 33180, "title": "_list_all_concrete_functions_for_serialization doubles the trace count when called? ", "body": "I'm seeing the new warning \"triggered tf.function retracing. Tracing is expensive and the excessive number of tracings\" and was digging into it. When I printed *everything* that went through the offending function I only saw two tensors by (type, shape). This lead me to notice the following weird event that bumps (doubles) the trace count.\r\n\r\nIs there some reason for this? If this is normal, I will try a minimal reproduction of the warning message that seems to not make sense.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef f(a):\r\n    tf.print(a.shape)\r\n    return a\r\n\r\n\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 2).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 1).astype(np.float32))); print(f._get_tracing_count())\r\nprint(f._list_all_concrete_functions_for_serialization())\r\nprint(f._get_tracing_count())\r\n```\r\n\r\nResults in \r\n\r\n```\r\nTensorShape([4, 3])\r\n1\r\nTensorShape([4, 3])\r\n1\r\nTensorShape([4, 3])\r\n1\r\nTensorShape([4, 2])\r\n2\r\nTensorShape([4, 1])\r\n3\r\n[<tensorflow.python.eager.function.ConcreteFunction object at 0x7fa32c03b438>, <tensorflow.python.eager.function.ConcreteFunction object at 0x7fa3247f4438>, <tensorflow.python.eager.function.ConcreteFunction object at 0x7fa3247f4f60>]\r\n6\r\n```\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I have tried on colab with TF version 2.0.0 ,2.0.0-dev20191002 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/39c39a352dfea0cd9375a6b6235ce995/untitled252.ipynb).Thanks!", "@cottrell \r\nCan you please let us know is this the expected behavior in the attached [gist](https://colab.sandbox.google.com/gist/ravikyram/39c39a352dfea0cd9375a6b6235ce995/untitled252.ipynb#scrollTo=x89GS3WvYGAK). I am not seeing any warning message . Can you please elaborate the issue with the context. Thanks!", "I think you just need a few more calls to trigger the tracing warning (see more below).\r\n\r\nThe tracing warning is mererly *why* I was looking into this. The doubling of the tracing count is something I don't understand at this point. Could be a feature not sure.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef f(a):\r\n    tf.print(a.shape)\r\n    return a\r\n\r\n\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 3).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 2).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 1).astype(np.float32))); print(f._get_tracing_count())\r\n\r\nf(tf.convert_to_tensor(np.random.randn(4, 12).astype(np.float32))); print(f._get_tracing_count())\r\n\r\nf(tf.convert_to_tensor(np.random.randn(4, 11).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 15).astype(np.float32))); print(f._get_tracing_count())\r\nf(tf.convert_to_tensor(np.random.randn(4, 18).astype(np.float32))); print(f._get_tracing_count())\r\nprint(f._list_all_concrete_functions_for_serialization())\r\nprint(f._get_tracing_count())\r\n```", "Hi,\r\n\r\n`f._get_tracing_count()` counts the number of times that the function is traced. When `f._list_all_concrete_functions_for_serialization()` is called, the function is actually traced again 3 times in your example.  You can verify that by inserting `print('Traced')` in the `f`'s function body.\r\n\r\nFor the warning message, it doesn't use `f._get_tracing_count()`, it uses `f._call_counter.get_tracing_count()` to count the tracing and that's not increased with `f._list_all_concrete_functions_for_serialization()`\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33180\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33180\">No</a>\n"]}, {"number": 33179, "title": "Module Not Found in docker build: tensorflow_datasets", "body": "I have been following the Docker instructions on the Tensorflow website (https://www.tensorflow.org/install/docker).\r\nTrying to run the Jupyter notebook provided in the tensorflow docker images, specifically trying to run the tutorial here: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\r\n\r\nBut when I run the code segments in sequence, I get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-3-7eaaf952f6e2> in <module>\r\n      1 from tensorflow import keras\r\n      2 \r\n----> 3 import tensorflow_datasets as tfds\r\n      4 tfds.disable_progress_bar()\r\n      5 \r\n\r\nModuleNotFoundError: No module named 'tensorflow_datasets'\r\n```\r\n\r\nThis would seem to be an issue with the Docker image since I would expect that module to be installed by default. \r\n\r\n**System information**\r\n- OS Platform and Distribution: MacOS 10.15\r\n- TensorFlow installed from (source or binary): \r\n`docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-py3-jupyter`\r\n\r\n", "comments": ["@intrepidOlivia \r\nTensorFlow datasets is a standalone package. You need to install it separately.\r\nTry,\r\n`pip install tensorflow_datasets` before executing the script.\r\nFeel free to reopen if problem still persists. Thanks!", "I can certainly try it, but the instructions do not indicate that this should be necessary. \r\n\r\nThe instructions say this:\r\n```\r\nStart a Jupyter Notebook server using TensorFlow's nightly build with Python 3 support:\r\ndocker run -it -p 8888:8888 tensorflow/tensorflow:nightly-py3-jupyter\r\nFollow the instructions and open the URL in your host web browser: http://127.0.0.1:8888/?token=...\r\n```\r\n\r\nNowhere in the instructions or in the notebook is it mentioned that there are any additional dependencies.  Nor do they make it very clear how to install a dependency inside of the Docker container. Since this is a guide for beginners, perhaps a section should be added for instructing newbies on how to install additional dependencies inside of the docker container?  And perhaps the [tutorial text](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb) should include some statement about its dependencies as well.\r\n\r\nI'd be willing to do a PR to include this information, but I'm one of the aforementioned newbies and would need the information first.", "I agree with you. Can you please try it and let me know if it helps in solving your issue. Thanks!", "Okay... I apologize, I'm new to all this.. What route do you think I should take? Should I try to modify the docker command to open a shell inside the docker container and pip install from there? That seems to defeat the purpose of having a docker container in the first place, especially one that has these notebooks installed. \r\n\r\nShould I maybe try to find and modify the Dockerfile associated with the `jupyter` tag instead to install its necessary dependencies? I found a description of the docker image here: https://hub.docker.com/layers/tensorflow/tensorflow/nightly-py3-jupyter/images/sha256-6fb0905855a23e4b202dd03535a0575b6b3ffd682cc27f1d99ab3d8be492b484\r\nbut I'm unsure how to extract or modify or make a pull request on it.", "Unfortunately, you have to do it yourself @intrepidOlivia. You can follow the answer to this [question](https://www.quora.com/How-do-you-install-packages-in-a-Docker-container) to add a command to your docker file and build again to create a new image file. For more specific questions, you can post it on stackoverflow.", "I think maybe you are not understanding the scenario. I do not have my own Dockerfile, I am installing tensorflow jupyter files with the following command:\r\n\r\n`docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-py3-jupyter`\r\n\r\nThe docker container that is installed from this command does not have the necessary dependencies to operate the  included notebooks. I believe that the docker container should have the necessary dependencies to run the notebooks that it is installing. Please let me know which part of this is unclear, or if there is some other issue.", "I could reproduce the issue with nightly-py3-jupyter and latest-py3-jupyter Tensorflow docker images. ", "@intrepidOlivia Try using the previous versions of docker images and let me know if you are still facing the same issue?", "Inside of the notebook you can run `!pip install tensorflow_datasets` before the code that imports tensorflow_datasets. Similar to how `!pip install seaborn` is done in regression.ipynb.\r\n\r\nThat change could be submitted as a pull request to https://github.com/tensorflow/docs", "@intrepidOlivia Please follow the above recommendation and let me know if it helps.!", "I am getting same error: `No module named 'tensorflow_datasets'`\r\nFollowing is the code:\r\n```\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\n!pip install tensorflow_datasets\r\nimport tensorflow_datasets as tfds\r\n```", "Sorry, for the pip package name it should have been a hyphen and not an underscore.\r\n\r\n`!pip install tensorflow-datasets`", "A fix for this problem was merged yesterday in: https://github.com/tensorflow/docs/pull/1124\r\n\r\nAll docker containers created from that point on will contain this fix.\r\n\r\nJust ensure you pull the latest image: `docker pull tensorflow/tensorflow:nightly-py3-jupyter`", "Thanks @wdirons ", "Closing this issue as it has been resolved. Please add additional comments and we can open this issue again. ", "Reproduced issue with docker latest-py3-jupyter\r\n\r\nadding the above pip to the tutorial code works as a workaround."]}, {"number": 33178, "title": "Potential memory leak when using LSTM + TimeDistributed", "body": "------------------------\r\n\r\nSystem information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Yes\r\n- **OS Platform and Distribution**: Windows 10\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- **Python version**: 3.6.9\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**:  10.0 (CUDA) / 7.5 (cuDNN)\r\n- **GPU model and memory**: TITAN RTX (24GB)\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n#### Potential memory leak when using LSTM + TimeDistributed\r\nI have a standard time series model that consists 3 layers of convolutional layers feeding into 2 LSTM layers. Up until now, I have had no problems mapping a Dense layer to the last output of the top LSTM and making a prediction etc. However, I want to implement a model where I use a TimeDistributed(Dense(..)) layer on top of the top LSTM and feed back the error signal at each time point. I have implemented this but after only training a few epochs, I get a resource exhausted error.  \r\n\r\nIt doesn't seem to be affected by how small I make the model, after training for a few epochs. The error I get is: \"ResourceExhaustedError: OOM when allocating tensor with shape[25600,9,11,128]\". This comes after a call to tape.gradients (full error reported in section below).\r\n\r\nIn my non-TimeDistributed I monitor the number of objects via len(gc.get_objects())) and during training the object count remains the same (as expected), but when I only change the model to handle this TimeDistributed change (i.e. making sure the labels are correctly repeated and making return_sequences=1 for the top-level LSTM) then all of a sudden at each training epoch, thousands of new variables are being added during each epoch of training.\r\n\r\ngc objects: 249861\r\n[TRAIN]: End (epoch 0): loss 0.693269372 ; train accuracy 0.5\r\n[TEST]:  End (epoch 0): loss 0.691318274 ; test accuracy 0.500683606\r\ngc objects: 251746 (+ 1885 objects)\r\n[TRAIN]: End (epoch 1): loss 0.691800237 ; train accuracy 0.500202894\r\n[TEST]:  End (epoch 1): loss 0.690349817 ; test accuracy 0.502343774\r\ngc objects: 254144 (+ 2398 objects)\r\n[TRAIN]: End (epoch 2): loss 0.690762699 ; train accuracy 0.500456572\r\n[TEST]:  End (epoch 2): loss 0.689480364 ; test accuracy 0.504296899\r\ngc objects: 254996 (+852 objects)\r\n[TRAIN]: End (epoch 3): loss 0.692312837 ; train accuracy 0.501090705\r\n[TEST]:  End (epoch 3): loss 0.689140499 ; test accuracy 0.505468726\r\ngc objects: 269643 (+ 14647 objects)\r\n[TRAIN]: End (epoch 4): loss 0.688487 ; train accuracy 0.501116097\r\n[TEST]:  End (epoch 4): loss 0.686942577 ; test accuracy 0.508886695\r\ngc objects: 270444 (+ 801 objects)\r\n\r\nSo in 4 epochs of training, while no other process is running, 20,583 new objects were created and I presume resulted in this resource exhausted error.\r\n\r\nI've tried to force the garbage collector to collect any unused variables but the object count increases whether this is included or not. I ran a snapshot comparison from the **tracemalloc** library, which I will include below as it might be helpful (it wasn't to me).\r\n\r\nSomething is creating variables during every epoch, vastly using up all the memory and not releasing them, leading to this resource exhausted error. This doesn't occur if I don't use TimeDistributed, so I don't think anything about this layer requires the creation of additional memory-hungry variables. It looks more like a leak. \r\n\r\nDo you have any idea of what I could do to alleviate this problem? It seems like a bug fix at a technical level. Maybe there is a technical solution. Please let me know if any further info from my end would be useful in looking at this issue.\r\n\r\n### Source code / logs\r\n\r\n#### tracemalloc top 10 differences between snapshot calls at adjacent epochs\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py:61: size=111 KiB (+69.9 KiB), count=677 (+426), average=168 B\r\n<string>:14: size=7464 B (-46.9 KiB), count=107 (-749), average=70 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\tokenize.py:609: size=2944 B (-43.6 KiB), count=46 (-698), average=64 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_shape.py:193: size=59.9 KiB (+33.8 KiB), count=1305 (+732), average=47 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py:768: size=54.0 KiB (+31.3 KiB), count=386 (+219), average=143 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_shape.py:718: size=55.7 KiB (+30.8 KiB), count=1018 (+564), average=56 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_shape.py:776: size=51.0 KiB (+28.7 KiB), count=1235 (+690), average=42 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py:564: size=40.9 KiB (+25.8 KiB), count=675 (+426), average=62 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1035: size=39.3 KiB (+23.3 KiB), count=950 (+566), average=42 B\r\nC:\\Users\\AXM1390\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py:809: size=27.1 KiB (+15.9 KiB), count=3 (+0), average=9248 B\r\n\r\n#### full error\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-14-422df5497d33> in <module>\r\n----> 1 best_val, best_epoch, tmp_history = run_model_once(0, 25, epochs=50)\r\n\r\n<ipython-input-12-61614e3bb222> in run_model_once(start, end, epochs)\r\n     36         printed_cm = False\r\n     37 \r\n---> 38         train_loss, val_loss, acc_metric, val_acc_metric = train(RCNN_model, optimizer, train_ds, test_ds, cm)\r\n     39         tf.print(f'[TRAIN]: End (epoch {i}): loss', train_loss, '; train accuracy', acc_metric.result())\r\n     40         tf.print(f'[TEST]:  End (epoch {i}): loss', val_loss, '; test accuracy', val_acc_metric.result())\r\n\r\n<ipython-input-11-00ed72fa26fb> in train(model, optimizer, train_ds, test_ds, cm)\r\n     60     for x_true, y_true in train_ds:\r\n     61         if TIME_DISTRIBUTED:\r\n---> 62             train_loss = train_one_step_timedistributed(model, optimizer, x_true, y_true, training=True)\r\n     63         else:\r\n     64             train_loss = train_one_step(model, optimizer, x_true, y_true, training=True)\r\n\r\n<ipython-input-11-00ed72fa26fb> in train_one_step_timedistributed(model, optimizer, x_true, y_true, training)\r\n     22         print(f'model trainable variables: {len(model.trainable_variables)}')\r\n     23 \r\n---> 24     gradients = tape.gradient(loss_, model.trainable_variables)\r\n     25     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n     26 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n   1012         output_gradients=output_gradients,\r\n   1013         sources_raw=flat_sources_raw,\r\n-> 1014         unconnected_gradients=unconnected_gradients)\r\n   1015 \r\n   1016     if not self._persistent:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\r\n     74       output_gradients,\r\n     75       sources_raw,\r\n---> 76       compat.as_str(unconnected_gradients.value))\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\r\n    136     return [None] * num_inputs\r\n    137 \r\n--> 138   return grad_fn(mock_op, *out_grads)\r\n    139 \r\n    140 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py in _TanhGrad(op, grad)\r\n    712   with ops.control_dependencies([grad]):\r\n    713     y = math_ops.conj(y)\r\n--> 714     return gen_math_ops.tanh_grad(y, grad)\r\n    715 \r\n    716 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py in tanh_grad(y, dy, name)\r\n  11410       else:\r\n  11411         message = e.message\r\n> 11412       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  11413   # Add nodes to the TensorFlow graph.\r\n  11414   _, _, _op = _op_def_lib._apply_op_helper(\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[25600,9,11,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TanhGrad]\r\n", "comments": ["@algrmur ,\r\nCan you share a simple and standalone code to reproduce the issue reported here? Thanks!", "Hi @algrmur \r\nThere are a couple of bugs in TF2.0, one possible reason could be variable sequence length. It would be great if you can share sample code which can produce the same error.", "Hello @oanush and @akanyaani,\r\n\r\nThanks for your replies. I've stripped down all of the non-essential code in my program and set it up to use randomly generated data to recreate the problem. Please see below for (1) code and (2) output given for me.\r\n\r\n## Imports + Data Generation\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf \r\nfrom tensorflow.keras.layers import (Conv2D, LSTM, Dense, Dropout,\r\n                                     Softmax, BatchNormalization, TimeDistributed)\r\nfrom scipy.stats import mode\r\nimport gc\r\n\r\nprint(f'Using TensorFlow {tf.__version__}, GPU available? : {tf.test.is_gpu_available()}')\r\n\r\nn_data = 5000\r\nheight = 9\r\nwidth = 11\r\nn_timepoints = 100\r\nchan_dim = 1\r\n\r\ntrain_x = np.random.rand(n_data, height, width, n_timepoints, chan_dim)\r\ntrain_y = np.random.randint(low=0, high=3, size=n_data)\r\ntrain_y = tf.keras.utils.to_categorical(train_y)\r\n\r\ntest_x = np.random.rand(n_data, height, width, n_timepoints, chan_dim)\r\ntest_y = np.random.randint(low=0, high=3, size=n_data)\r\ntest_y = tf.keras.utils.to_categorical(test_y)\r\n                           \r\nprint(f'train_x shape: {train_x.shape}')\r\nprint(f'train_y shape: {train_y.shape}')\r\nprint(f'test_x shape: {test_x.shape}')\r\nprint(f'test_y shape: {test_y.shape}')\r\n```\r\n## Model definition\r\n\r\n```\r\nclass mymodel(tf.keras.Model):\r\n    \r\n    def __init__(self, n_filters, n_fc, n_output, n_batch, n_nodes, dropout):\r\n        super(mymodel, self).__init__(name='RCNN')\r\n        \r\n        # Set model properties as instance attributes\r\n        self.n_filters = n_filters\r\n        self.n_fc = n_fc\r\n        self.n_output = n_output\r\n        self.N_BATCH = n_batch\r\n        self.N_NODES = n_nodes\r\n        self.DROPOUT = dropout\r\n        self.out_activation = \"sigmoid\" if n_output == 2 else \"softmax\"\r\n        \r\n        self.conv1 = Conv2D(filters=n_filters, strides=1,padding='same', \r\n                            activation='tanh', kernel_size=3)\r\n        \r\n        self.conv2 = Conv2D(filters=n_filters*2, strides=1,padding='same', \r\n                            activation='tanh', kernel_size=3)\r\n        \r\n        self.conv3 = Conv2D(filters=n_filters*4, strides=1,padding='same', \r\n                            activation='tanh', kernel_size=3)\r\n            \r\n        self.dense1 = Dense(n_fc)\r\n        self.dropout1 = Dropout(dropout) \r\n        \r\n        self.lstm1 = LSTM(self.N_NODES, recurrent_initializer='orthogonal', return_sequences=1)\r\n        self.lstm2 = LSTM(self.N_NODES, recurrent_initializer='orthogonal', return_sequences=1)\r\n        \r\n        self.fc2         = TimeDistributed(Dense(n_fc))\r\n        self.fc2_dropout = TimeDistributed(Dropout(dropout))\r\n        self.outputlayer = TimeDistributed(Dense(n_output, activation=self.out_activation))\r\n        \r\n    def call(self, inputs, training):\r\n        \r\n        _, height, width, n_timesteps, n_input = inputs.shape\r\n        inputs = tf.reshape(inputs, [self.N_BATCH*n_timesteps, height, width, 1])\r\n        \r\n        conv1_ = self.conv1(inputs)\r\n        conv2_ = self.conv2(conv1_)\r\n        conv3_ = self.conv3(conv2_)\r\n        \r\n        flattened_ = tf.reshape(conv3_, [-1, conv3_.shape[1]*conv3_.shape[2]*conv3_.shape[3]])\r\n        dense1_   = self.dense1(flattened_)\r\n        dropout1_ = self.dropout1(dense1_, training=training)\r\n        \r\n        lstm_in_ = tf.reshape(dropout1_, [-1, n_timesteps, self.n_fc])\r\n        lstm1_   = self.lstm1(lstm_in_)\r\n        lstm2_   = self.lstm2(lstm1_)\r\n        \r\n        fc2_         = self.fc2(lstm2_)\r\n        fc2_dropout_ = self.fc2_dropout(fc2_, training=training)\r\n        output_      = self.outputlayer(fc2_dropout_)\r\n        \r\n        return output_\r\n```\r\n## Loss/Optimiser/tf.Dataset/Model instantiation\r\n```\r\noptimizer = tf.keras.optimizers.Adam(1e-4)\r\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\r\n\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_x,\r\n                                               train_y)).batch(256, drop_remainder=True)\r\ntest_ds = tf.data.Dataset.from_tensor_slices((test_x,\r\n                                              test_y)).batch(256, drop_remainder=True)\r\n\r\nmy_model = mymodel(n_filters=32, n_fc=256, n_batch=256, dropout=0.5,\r\n                   n_output=train_y.shape[1], n_nodes=256)\r\n```\r\n## Training functions\r\n```\r\ndef train_one_step(model, optimizer, x_true, y_true, training):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = model(x_true, training)\r\n        y_true_expanded = np.repeat(y_true, n_timepoints, axis=0).reshape((y_pred.shape[0], n_timepoints, -1))\r\n        loss_ = loss_fn(y_true_expanded, y_pred)\r\n        \r\n    gradients = tape.gradient(loss_, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n    \r\n    return loss_\r\n\r\ndef test_one_step(model, optimizer, x_true, y_true, training):\r\n    y_pred = model(x_true, training)\r\n    y_true_expanded = np.repeat(y_true, n_timepoints, axis=0).reshape((y_pred.shape[0], n_timepoints, -1))\r\n    loss_ = loss_fn(y_true_expanded, y_pred)\r\n    return loss_\r\n\r\ndef train(model, optimizer, train_ds, test_ds):\r\n    \r\n    for x_true, y_true in train_ds:\r\n        train_loss = train_one_step(model, optimizer, x_true, y_true, training=True) \r\n        \r\n    for x_true, y_true in test_ds:\r\n        val_loss = test_one_step(model, optimizer, x_true, y_true, training=False)\r\n            \r\n    return (train_loss, val_loss)\r\n```\r\n## Running the model\r\n```\r\nfor i in range(200):\r\n    gc.collect()\r\n    print(f'gc objects: {len(gc.get_objects())}')\r\n    \r\n    train_loss, val_loss = train(my_model, optimizer, train_ds, test_ds)\r\n    tf.print(f'[TRAIN]: End (epoch {i}): loss', train_loss)\r\n    tf.print(f'[TEST]:  End (epoch {i}): loss', val_loss)\r\n```\r\n\r\nThe output of this shows that many objects are being created during the runs of the epochs.\r\n\r\n## Output\r\n```\r\ngc objects: 223324\r\n[TRAIN]: End (epoch 0): loss 1.09557235\r\n[TEST]:  End (epoch 0): loss 1.10084486\r\ngc objects: 225044\r\n[TRAIN]: End (epoch 1): loss 1.09603643\r\n[TEST]:  End (epoch 1): loss 1.09944308\r\ngc objects: 225427\r\n[TRAIN]: End (epoch 2): loss 1.09861755\r\n[TEST]:  End (epoch 2): loss 1.09861553\r\ngc objects: 225814\r\n[TRAIN]: End (epoch 3): loss 1.09743845\r\n[TEST]:  End (epoch 3): loss 1.09851873\r\ngc objects: 226235\r\n[TRAIN]: End (epoch 4): loss 1.09701049\r\n[TEST]:  End (epoch 4): loss 1.09853053\r\ngc objects: 226551\r\n[TRAIN]: End (epoch 5): loss 1.09691608\r\n[TEST]:  End (epoch 5): loss 1.09853923\r\ngc objects: 226912\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-6-b4dc6b381cfe> in <module>\r\n      3     print(f'gc objects: {len(gc.get_objects())}')\r\n      4 \r\n----> 5     train_loss, val_loss = train(my_model, optimizer, train_ds, test_ds)\r\n      6     tf.print(f'[TRAIN]: End (epoch {i}): loss', train_loss)\r\n      7     tf.print(f'[TEST]:  End (epoch {i}): loss', val_loss)\r\n\r\n<ipython-input-5-5f343d76c3bf> in train(model, optimizer, train_ds, test_ds)\r\n     21 \r\n     22     for x_true, y_true in train_ds:\r\n---> 23         train_loss = train_one_step(model, optimizer, x_true, y_true, training=True)\r\n     24 \r\n     25     for x_true, y_true in test_ds:\r\n\r\n<ipython-input-5-5f343d76c3bf> in train_one_step(model, optimizer, x_true, y_true, training)\r\n      5         loss_ = loss_fn(y_true_expanded, y_pred)\r\n      6 \r\n----> 7     gradients = tape.gradient(loss_, model.trainable_variables)\r\n      8     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n      9 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n   1012         output_gradients=output_gradients,\r\n   1013         sources_raw=flat_sources_raw,\r\n-> 1014         unconnected_gradients=unconnected_gradients)\r\n   1015 \r\n   1016     if not self._persistent:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\r\n     74       output_gradients,\r\n     75       sources_raw,\r\n---> 76       compat.as_str(unconnected_gradients.value))\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\r\n    136     return [None] * num_inputs\r\n    137 \r\n--> 138   return grad_fn(mock_op, *out_grads)\r\n    139 \r\n    140 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py in _TanhGrad(op, grad)\r\n    712   with ops.control_dependencies([grad]):\r\n    713     y = math_ops.conj(y)\r\n--> 714     return gen_math_ops.tanh_grad(y, grad)\r\n    715 \r\n    716 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py in tanh_grad(y, dy, name)\r\n  11410       else:\r\n  11411         message = e.message\r\n> 11412       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  11413   # Add nodes to the TensorFlow graph.\r\n  11414   _, _, _op = _op_def_lib._apply_op_helper(\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[25600,9,11,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TanhGrad]\r\n```\r\n\r\n@akanyaani - Thanks for your comment about it potentially being related to variable length input, but in my case (and also in the case of the dummy code above) there is no variable length input as there are always 100 time points in the data I am using.\r\n\r\nIf you: \r\n\r\n- take out the 3 lines using \"TimeDistributed\" in the bottom of the model's \"call\" function\r\n- alter the call to the loss function to use \"y_true\" and not \"y_true_expanded\", \r\n- set the last LSTM's return_sequences parameter to 0\r\n\r\nthen the same code runs while keeping the amount of objects relatively stable, as seen below. This is what made me sure it was related to TimeDistributed. \r\n\r\n## Output without using TimeDistributed\r\n\r\n```\r\n[TRAIN]: End (epoch 0): loss 1.11176896\r\n[TEST]:  End (epoch 0): loss 1.10250723\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 1): loss 1.10939479\r\n[TEST]:  End (epoch 1): loss 1.0968765\r\ngc objects: 224340\r\n[TRAIN]: End (epoch 2): loss 1.09383631\r\n[TEST]:  End (epoch 2): loss 1.09696317\r\ngc objects: 224338\r\n[TRAIN]: End (epoch 3): loss 1.10116696\r\n[TEST]:  End (epoch 3): loss 1.09682214\r\ngc objects: 224340\r\n[TRAIN]: End (epoch 4): loss 1.09012806\r\n[TEST]:  End (epoch 4): loss 1.09699178\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 5): loss 1.09775305\r\n[TEST]:  End (epoch 5): loss 1.09818268\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 6): loss 1.09012258\r\n[TEST]:  End (epoch 6): loss 1.09953499\r\ngc objects: 224342\r\n[TRAIN]: End (epoch 7): loss 1.08458531\r\n[TEST]:  End (epoch 7): loss 1.09981978\r\ngc objects: 224340\r\n[TRAIN]: End (epoch 8): loss 1.08050597\r\n[TEST]:  End (epoch 8): loss 1.10207307\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 9): loss 1.07563555\r\n[TEST]:  End (epoch 9): loss 1.10376084\r\ngc objects: 224340\r\n[TRAIN]: End (epoch 10): loss 1.07361245\r\n[TEST]:  End (epoch 10): loss 1.10961676\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 11): loss 1.05968428\r\n[TEST]:  End (epoch 11): loss 1.11357927\r\ngc objects: 224310\r\n[TRAIN]: End (epoch 12): loss 1.05215323\r\n[TEST]:  End (epoch 12): loss 1.11662757\r\ngc objects: 224310\r\n....\r\n```\r\n\r\nI hope you can also recreate the issue and thereby potentially see where the problem might lie.\r\nAny advice / solutions would be greatly appreciated!\r\n\r\nKind regards\r\nAlex", "Hi @algrmur \r\n![Screenshot 2019-10-10 at 5 16 14 PM (2)](https://user-images.githubusercontent.com/11317416/66566131-cdf1df80-eb81-11e9-959a-864fb9106a46.png)\r\n\r\nIt works fine on my system could you please try with smaller batch size.", "Hi @akanyaani,\r\n\r\nInteresting! I tried via notebooks, command line etc. and it always gave the same error. I will try it on my Linux laptop to see if it also breaks there. Do you mind if I ask about your specs so I can see what else I might be able to try (mainly just CUDA / cuDNN version and what version of Python you used)? Then I can try on Windows with the same things running as you, as that might fix my problem.\r\n\r\nOnce I am back at my main workstation tomorrow, I will try with a lower batch size to answer your question as to whether that might be the problem. I didn't think it would be because TimeDistributed(Dense(..)) uses the same weights for each time step so I thought the computation would be equivalent (in terms of the gradient call) to the non-TimeDistributed case (that does work). I could be wrong though. Furthermore, I don't know why it would be fine with the first 5-6 epochs and then fail afterwards. If it can handle the first few, nothing new should be done during the training so I still have no explanation as to how the OOM could occur. \r\n\r\nMore information tomorrow!\r\nThanks again!", "I am also seeing a memory leak.  No LSTM though, just TimeDistributed.  This model fails after printing 11 on a 2080Ti.  Batch Size is always 1, so that's not the problem.\r\n**EDIT:** Shrunk minimal example by quite a bit.  Is now 1 Conv1D layer, and 1 TimeDistributed Dense layer.\r\n\r\n    from tensorflow.keras.models import Model\r\n    from tensorflow.keras.layers import *\r\n    import tensorflow.keras.backend as K\r\n    import numpy as np\r\n    import tensorflow\r\n\r\n    def BuildGenerator():\r\n        i = Input(shape=(None,2,))\r\n        \r\n        n_input = 12*21\r\n        to_n = Input(shape=(n_input))\r\n        s_n = Dense(12*21, activation='softmax')(to_n)\r\n        s_n = Reshape((12,21))(s_n)\r\n        n_base = Model(inputs=[to_n], outputs=[s_n])\r\n        \r\n        b = Conv1D(n_input, 11, dilation_rate=1, padding='same', activation='relu', data_format='channels_last')(i)\r\n        n = TimeDistributed(n_base)(b)\r\n\r\n        return Model(inputs=[i], outputs=[n])\r\n\r\n    def InputGenerator():\r\n        for iter in range(1000):\r\n            print(iter)\r\n            i = np.zeros((1,10*60*1000,2))\r\n            n = np.zeros((1,10*60*1000,12,21))\r\n            yield ([i], [n])\r\n\r\n    with tensorflow.device('/device:gpu:0'):\r\n        \r\n        m2t = BuildGenerator()\r\n        \r\n        m2t.compile(optimizer='adam', loss='mse')\r\n        \r\n        for epoch in range(1):\r\n            for inout in InputGenerator():\r\n                m2t.train_on_batch(inout[0], inout[1])", "So, does this line do what I think it does?\r\n[https://github.com/tensorflow/tensorflow/blob/ed04c8639d53c284874240d58abba725865f454e/tensorflow/python/keras/layers/wrappers.py#L250](https://github.com/tensorflow/tensorflow/blob/ed04c8639d53c284874240d58abba725865f454e/tensorflow/python/keras/layers/wrappers.py#L250)\r\n\r\nBecause that looks like it's permanently storing the inputs in a map that never gets cleared, using a global UUID as the key.", "> Hi @akanyaani,\r\n> \r\n> Interesting! I tried via notebooks, command line etc. and it always gave the same error. I will try it on my Linux laptop to see if it also breaks there. Do you mind if I ask about your specs so I can see what else I might be able to try (mainly just CUDA / cuDNN version and what version of Python you used)? Then I can try on Windows with the same things running as you, as that might fix my problem.\r\n> \r\n> Once I am back at my main workstation tomorrow, I will try with a lower batch size to answer your question as to whether that might be the problem. I didn't think it would be because TimeDistributed(Dense(..)) uses the same weights for each time step so I thought the computation would be equivalent (in terms of the gradient call) to the non-TimeDistributed case (that does work). I could be wrong though. Furthermore, I don't know why it would be fine with the first 5-6 epochs and then fail afterwards. If it can handle the first few, nothing new should be done during the training so I still have no explanation as to how the OOM could occur.\r\n> \r\n> More information tomorrow!\r\n> Thanks again!\r\n\r\n@algrmur ,\r\nAny update on the issue ? Thanks!", "> > Hi @akanyaani,\r\n> > Interesting! I tried via notebooks, command line etc. and it always gave the same error. I will try it on my Linux laptop to see if it also breaks there. Do you mind if I ask about your specs so I can see what else I might be able to try (mainly just CUDA / cuDNN version and what version of Python you used)? Then I can try on Windows with the same things running as you, as that might fix my problem.\r\n> > Once I am back at my main workstation tomorrow, I will try with a lower batch size to answer your question as to whether that might be the problem. I didn't think it would be because TimeDistributed(Dense(..)) uses the same weights for each time step so I thought the computation would be equivalent (in terms of the gradient call) to the non-TimeDistributed case (that does work). I could be wrong though. Furthermore, I don't know why it would be fine with the first 5-6 epochs and then fail afterwards. If it can handle the first few, nothing new should be done during the training so I still have no explanation as to how the OOM could occur.\r\n> > More information tomorrow!\r\n> > Thanks again!\r\n> \r\n> @algrmur ,\r\n> Any update on the issue ? Thanks!\r\n\r\nHi oanush,\r\n\r\nI tried running a reduced model on a very small batch size (16) and it ran longer than it did last time but there was still a considerable increase of objects in memory on each training loop (a few hundred at each iteration). It just made a bit more space for more epochs to run, but then ran into OOM errors at a later point. \r\n\r\nI think Tetragramm (above) is having the same issue and further confirms my belief it's with the TimeDistributed layer (as without it - my model runs fine). I wanted to run the same model using the same setup as akanyaani but so far I've not seen what the exact details were in his case / whether he has much more memory available.", "I had this issue in version 2.0.0.\r\n\r\nBeta1 version is working and running faster per epoch.", "@arthurflor23 Are you sure?  The Beta1 code is nearly identical to the release 2.0.0 code.  The only change is to regularization, which has nothing that would do a memory leak.\r\n\r\nUpon further review (actually reading through the code), I'm pretty sure the _input_map variable is both the cause, and useless.  I think lines 56, 246, 247, 249, 308, and 309 can be removed, and line 310 replaced with \r\n\r\n    output_mask = self.layer.compute_mask(inputs, inner_mask)\r\n\r\nUnfortunately, I'm having trouble building tensorflow from source to test.", "Hi!\r\nI was training a model today (via google colab) using `tensorflow-gpu==2.0.0`.. I've added two TimeDistributed layer and I realized that the time of the epochs was increasing.. started with ~200s in first epoch and stopped with ~350s in the last.. then, the issue mentioned happened.\r\n\r\nI don't know if it's related to this or another module version, but Beta1 doesn't happen and make ~140s per epoch..\r\n\r\nI will do more tests with the two models that I'm studying, cause I already have another problem in the recurrent layers and `ThenRnnBackward`\r\n\r\nJust to complement, this behavior that I mentioned appears since rc0. (I installed version by version to check, via google colab)", "\r\ntwo weeks have passed since success?", "Not quite.  Some complications.  Awaiting someone with better understanding of the system than me.", "I also have a memory leak since 1.14 up to 2.0. On 1.13 the leak disappears.", "I`m used TF 1.14 and not have a memory leak", "Hi, \r\n\r\nI'm using TF-GPU 2.0.0 and having the same issue when using the TimeDistributed wrapper... \r\nAdding a \r\n\r\n> self._input_map.clear()\r\n\r\nbefore this:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/ed04c8639d53c284874240d58abba725865f454e/tensorflow/python/keras/layers/wrappers.py#L250\r\n\r\ndoes not result in an increasing gpu memory allocation... But I don't know if it is now still correct? I only saw self._input_map be called at the preparation of the training and only referring to the last input_uid. So I thought that clearing before adding the latest element would not destroy the logic behind it, but still fix the memory leakage. ", "I can verify that @arnemoos 's workaround prevents the OOM for me.", "I'm running tf-nightly-gpu today and I have no more error, can anyone confirm?", "I can confirm that using TimeDistributed also runs my model into resource allocation errors for tf 2.0.0. Using the fit_generator() training function with a model that has 3x 2DConv layers, each wrapped in TimeDistributed on a batch of 39,32 MB total memory footprint (batch size=32). \r\n\r\n@arthurflor23  Will try tf-nightly-gpu now and confirm/not-confirm ", "@arthurflor23 I can confirm that the issue has been gone for me as well :)", "@arthurflor23, yes it`s try ", "Again, confirm that TimeDistributed is the culprit. In my case, tf-nightly breaks my model. Solved the problem by writing a custom for-loop in subclassed model rather than using TimeDistributed. But this bug has to be fixed for those using non-subclassed model.", "I was able to work around this issue by reshaping my tensor to combine the first two dimensions, applying the convolution / dense layer, and reshaping back to the expected output shape.", "The fix has been merged.\r\nhttps://github.com/tensorflow/tensorflow/pull/33441#event-2967461126", "Thanks @Tetragramm . @algrmur please let us know if your issue has been fixed and we can close this issue. ", "The PR has been rollback due to a test failure. I will try to update the internal code/test to fix the memory leak.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33178\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33178\">No</a>\n", "@qlzh727 So is the problem solved? Can I put the second version?", "yes, the issue is resolved by d064c6f", "hello, I still have this problem in google colab pro ,  OOM occured when i was running the code . And once i  run ,error occured ,then GPU used 15.08GB/16.00GB and it cannot  get cleared, i have to stop my jupyternote to recreate a session to run . Can someone tell me how to solve this problem ?  ", "Hello, i  can confirm that this issue is not fixed, even in resent builds. \r\n\r\nA simpel model like:\r\n  \r\n    img_input = layers.Input(shape=(16, 640, 480, 3), name=\"input\")\r\n    x = layers.BatchNormalization()(img_input)\r\n    img_encoder = efn.EfficientNetB0(input_shape=( 640, 480, 3), include_top=False)\r\n    act_60_40_144 = img_encoder.get_layer('block3a_activation')\r\n    img_encoder = Model(inputs=img_encoder.input, outputs=act_60_40_144.output)\r\n\r\n    x = layers.TimeDistributed(img_encoder)(x)\r\n    x = layers.TimeDistributed(layers.GlobalAvgPool2D())(x)\r\n    x = layers.Bidirectional(layers.GRU(x.shape[-1], return_sequences=True), 'sum')(x)\r\n\r\n    x = layers.Conv1D(3, 1, activation='softmax')(x)\r\n    mo = Model(inputs=img_input, outputs=x)\r\n\r\nneeds ~ 25GB, even with resent nightly builds of tensorflow.\r\n\r\n"]}, {"number": 33177, "title": "Efficiency of model.fit_generator() are greatly reduced in 2.0.0", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):  2.0.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0, 7.6\r\n- GPU model and memory: Titan Xp, 12G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nMy code takes 21s/epoch in tf 2.0.0alpha while it takes 76s/epoch in tf 2.0.0. I found that the problem is model.fit_generator(). When I replace it with model.fit(), the efficiency of the code is exactly the same in both versions. But I need to use ImageDataGenerator.\r\n\r\n**Describe the expected behavior**\r\nThe efficiency of the code should be same.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n(train_images, train_labels, test_images, test_labels) = load_CIFAR('/home/user/Documents/dataset/Cifar-10')\r\ndatagen = ImageDataGenerator(horizontal_flip=True,\r\n                                 width_shift_range=0.125,\r\n                                 height_shift_range=0.125,\r\n                                 fill_mode='constant', cval=0.)\r\ndatagen.fit(train_images)\r\ndatagenflow = datagen.flow(train_images, train_labels, batch_size=batch_size)\r\nmodel.fit_generator(datagenflow,\r\n              steps_per_epoch=iterations,\r\n              epochs=epoch_num,\r\n              callbacks=[change_lr],\r\n              validation_data=(test_images, test_labels))\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Apm5 ,\r\nThanks for reporting, Can you share a standalone code to reproduce the issue?", "@oanush Thank you for your response. Here is the complete code, which has different efficiency between 2.0.0alpha and 2.0.0. \r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom tensorflow.keras import models, optimizers, regularizers\r\nfrom tensorflow.keras.callbacks import LearningRateScheduler\r\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Flatten, Dense, Input, add, Activation\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n\r\nstack_n = 3  # layers = stack_n * 6 + 2\r\nweight_decay = 1e-4\r\nbatch_size = 128\r\niterations = 50000 // batch_size + 1\r\nlearning_rate = 1e-1\r\nepoch_num = 200\r\n\r\ndef Residual_block(inputs, channels, strides=(1, 1)):\r\n    if strides == (1, 1):\r\n        shortcut = inputs\r\n    else:\r\n        shortcut = Conv2D(channels, (1, 1), strides=strides, kernel_regularizer=regularizers.l2(weight_decay))(inputs)\r\n        shortcut = BatchNormalization(momentum=0.9, epsilon=1e-5)(shortcut)\r\n    net = Conv2D(channels, (3, 3), padding='same', strides=strides, kernel_regularizer=regularizers.l2(weight_decay))(inputs)\r\n    net = BatchNormalization(momentum=0.9, epsilon=1e-5)(net)\r\n    net = Activation('relu')(net)\r\n    net = Conv2D(channels, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay))(net)\r\n    net = BatchNormalization(momentum=0.9, epsilon=1e-5)(net)\r\n    net = add([net, shortcut])\r\n    net = Activation('relu')(net)\r\n    return net\r\n\r\ndef ResNet(inputs):\r\n    net = Conv2D(16, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay))(inputs)\r\n    net = BatchNormalization(momentum=0.9, epsilon=1e-5)(net)\r\n    net = Activation('relu')(net)\r\n\r\n    for i in range(stack_n):\r\n        net = Residual_block(net, 16)\r\n\r\n    net = Residual_block(net, 32, strides=(2, 2))\r\n    for i in range(stack_n - 1):\r\n        net = Residual_block(net, 32)\r\n\r\n    net = Residual_block(net, 64, strides=(2, 2))\r\n    for i in range(stack_n - 1):\r\n        net = Residual_block(net, 64)\r\n\r\n    net = AveragePooling2D(8, 8)(net)\r\n    net = Flatten()(net)\r\n    net = Dense(10, activation='softmax')(net)\r\n    return net\r\n\r\ndef scheduler(epoch):\r\n    if epoch < epoch_num * 0.4:\r\n        return learning_rate\r\n    if epoch < epoch_num * 0.8:\r\n        return learning_rate * 0.1\r\n    return learning_rate * 0.01\r\n\r\nif __name__ == '__main__':\r\n    # load data\r\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\r\n    train_labels = tf.keras.utils.to_categorical(train_labels, 10)\r\n    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\r\n\r\n    datagen = ImageDataGenerator(horizontal_flip=True,\r\n                                 width_shift_range=0.125,\r\n                                 height_shift_range=0.125,\r\n                                 fill_mode='constant', cval=0.0)\r\n    datagen.fit(train_images)\r\n\r\n    # get model\r\n    img_input = Input(shape=(32, 32, 3))\r\n    output = ResNet(img_input)\r\n    model = models.Model(img_input, output)\r\n\r\n    # show\r\n    model.summary()\r\n\r\n    # train\r\n    sgd = optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\r\n    change_lr = LearningRateScheduler(scheduler)\r\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\r\n    datagenflow = datagen.flow(train_images, train_labels, batch_size=batch_size)\r\n    model.fit_generator(datagenflow,\r\n                        steps_per_epoch=iterations,\r\n                        epochs=epoch_num,\r\n                        callbacks=[change_lr],\r\n                        validation_data=(test_images, test_labels))\r\n```", "This is the same issue as https://github.com/tensorflow/tensorflow/issues/33024. I am working to alias `Model.fit_generator` to `Model.fit`, since `fit` now supports generators. In the mean time I would suggest that you use `Model.fit` rather than `Model.fit_generator` to unblock yourself.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33177\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33177\">No</a>\n", "This is the same issue as https://github.com/tensorflow/tensorflow/issues/33024. I am working to alias `Model.fit_generator` to `Model.fit`, since `fit` now supports generators. In the mean time I would suggest that you use `Model.fit` rather than `Model.fit_generator` to unblock yourself."]}, {"number": 33176, "title": "op name couldn't contain '_', '/' ?", "body": "Hi :\r\n\r\n```\r\nName of the node - tower_0/Concat/concat/axis\r\nName of the node - tower_0/Concat/concat\r\nName of the node - tower_0/MatMul\r\nName of the node - tower_0/Add\r\nName of the node - tower_0/MatMul_1\r\nName of the node - tower_0/Add_1\r\nName of the node - tower_0/MatMul_2\r\nName of the node - tower_0/Add_2\r\nName of the node - tower_0/Sigmoid\r\nName of the node - tower_0/pre_2/shape\r\nName of the node - tower_0/pre_2\r\nName of the node - tower_0/MatMul_3\r\nName of the node - tower_0/Add_3\r\nName of the node - tower_0/MatMul_4\r\nName of the node - tower_0/Add_4\r\nName of the node - tower_0/MatMul_5\r\n```\r\n\r\nThe above is part of op names in my model. When I use tensorflow c api:TF_GraphGetOpDef to get op detail, I found a problem: \r\nThe op name which contain '_' or '/' couldn't be found, the message is \uff1a`Op type not registered 'tower_0/Add_4' in binary running on xxx. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`\r\n\r\nThe op name which do not contain '_' or '/' could be found.  Why?\r\n", "comments": ["Both `_` and `/` are reserved characters.", "Because some node names were generated by tensorflow self, How c api access these node with name contain '_' or '/' ?  ", "@haolujun Can you please provide some reproducible code for us to expedite the process. Thanks!", "@hajuho Are you still facing the issue?", "Closing this issue as it has been inactive for more than two weeks. Please add additional comments and we can open this issue again. Thanks!"]}, {"number": 33175, "title": "tf1.12 keras input shape does not match the correct data feed", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0.176\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nimport numpy as np\r\nr_input = keras.layers.Input(shape=(), dtype=tf.float32, name='input_tensor')\r\nr_output = keras.layers.Lambda(lambda x: x+1.)(r_input)\r\nfinal_model = keras.models.Model(r_input, r_output)\r\nc_input = np.asarray([1.])\r\nret = final_model.predict(c_input)\r\nprint(ret)\r\n```\r\nRaise `ValueError: Error when checking input: expected input_tensor to have 1 dimensions, but got array with shape (1, 1)`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nIn TF2.0, the code listed above can be run correctly. So I think it is a bug in tf1.12.\r\n\r\nHow to fix in tf1.12?\r\nLine `r_input = keras.layers.Input(shape=(), dtype=tf.float32, name='input_tensor')`\r\ncan be replaced to `r_input = keras.layers.Input(shape=(1, ), dtype=tf.float32, name='input_tensor')` to fix this problem.\r\n", "comments": ["@This is a bug in Tensorflow 1.12 but has been fixed in later versions. Please find the github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/24c4c51235dbc238dc0314fd950d3d1e/untitled172.ipynb)."]}, {"number": 33174, "title": "TF2.0 OOM error training imagenet with vgg, fine when eager execution off", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: V10.0.130\r\n- GPU model and memory: GeForce RTX 2080ti, 10G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nGetting OOM error when training vgg16 on imagenet with batch_size=256. Was able to get away with OOM error with batch_size=8 or turning off eager execution.\r\n**Describe the expected behavior**\r\nThe exact same code was running fine with tf1.14 with no memory problem\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport numpy as np\r\nfrom tensorflow.keras.applications.vgg16 import VGG16\r\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\n\r\nimagenet_test = 'some image directory'\r\n\r\nmodel = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\r\nmodel.compile('adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\r\n\r\ndatagen = ImageDataGenerator(preprocessing_function=preprocess_input)\r\ntest_generator = datagen.flow_from_directory(directory=imagenet_test,\r\n                                            batch_size=256,\r\n                                            class_mode='sparse',\r\n                                            target_size=(224, 224))\r\nsteps = np.ceil(len(test_generator.classes) / 256)\r\n\r\nmodel.evaluate_generator(test_generator, steps, verbose=1)\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[256,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\r\n```", "comments": ["I could reproduce the issue with tensorflow 2.0.0. Please see the colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/e1417d6841204fb99b7056c8398b551a/untitled189.ipynb). Thanks!", "@don-tpanic Please check [the response](https://github.com/tensorflow/tensorflow/issues/32707#issuecomment-539246480) from @robieta for similar OOM issue with 2.0 and no OOM when same code ran in graph mode. The response has a nice presentation on improving the code for better performance. Thanks!", "To add to @jvishnuvardhan's answer on why eager matters, see https://github.com/tensorflow/tensorflow/issues/33024 which diagnosed that the `Model.*_generator` methods are running eagerly in 2.0. I am currently working on aliasing them to their normal counterparts (Model.fit_generator -> Model.fit, etc) which will restore graph based optimizations. (Including those around memory use.) In the mean time, you can switch to `Model.fit` and `Model.evaluate` directly in your code. Sorry for the inconvenience.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33174\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33174\">No</a>\n"]}, {"number": 33173, "title": "[tf2.0] tf.signal.fft2d causes an error when using @tf.function", "body": "tf_version: 2.0.0-beta1\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.layers import *\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.python.keras.models import Model\r\n\r\ndef build_fftNet(img_shape = (224, 512, 1)):\r\n    input_f = Input(shape=(img_shape))\r\n    \r\n    ins = Lambda(lambda x: (K.mean(x, axis=3)+1)*127.5)(input_f)\r\n    ins = Lambda(lambda x: tf.complex(tf.math.real(x), tf.zeros_like(x)))(ins) # float to complex\r\n    \r\n    fft = Lambda(lambda x: tf.signal.fft2d(ins))(ins)\r\n    fftNet = Model([input_f], [fft], name='fft')\r\n\r\n    return fftNet\r\n\r\nimg_shape = (224, 512, 1)\r\nfftNet = build_fftNet(img_shape)\r\n\r\n@tf.function\r\ndef fft(blur):\r\n    fft_true = fftNet(blur, training=False)\r\n    return fft_true\r\n\r\nblur = np.zeros((1, *img_shape), np.float32)\r\nfft(blur)\r\n```\r\n**@tf.function** gives the following error when using **tf.signal.fft2d**:\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-122-2efd6297c220>\", line 21, in <module>\r\n    fft(blur)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 434, in __call__\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 589, in _filtered_call\r\n    (t for t in nest.flatten((args, kwargs), expand_composites=True)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 445, in call\r\n    ctx=ctx)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 70, in quick_execute\r\n    raise core._SymbolicException\r\n\r\n_SymbolicException\r\n```", "comments": ["I could reproduce the issue with TF 2.0.0.beta as well with latest Tf 2.0.0. Please see the colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/bc03562ed4e574b76223e61f7825b314/untitled186.ipynb). Thanks!", "@ichae I think there was a small typo in your code. When I changed it, everything worked as expected. \r\n\r\nI changed one line in your code from\r\n`fft = Lambda(lambda x: tf.signal.fft2d(ins))(ins)`\r\nto \r\n`fft = Lambda(lambda x: tf.signal.fft2d(x))(ins)`\r\n\r\nPlease take a look at the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/86ecdbaee77d1c029754f526eef908ac/tf_33173.ipynb). \r\n\r\nI am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33173\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33173\">No</a>\n"]}, {"number": 33172, "title": "add expm_multiply functionality", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0.0\r\n- Are you willing to contribute it (Yes/No): Yes, but I need help\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIt would be great to implement the equivalent of `scipy.sparse.linalg.expm_multiply`, so that one doesn't have to create a whole matrix exponential before multiplying it with a vector, and instead compute the result directly. \r\n\r\n**Will this change the current api? How?**\r\nIt will add a new function\r\n\r\n**Who will benefit with this feature?**\r\nThose who need to use the matrix exponential on vectors\r\n\r\n**Any Other info.**\r\nSee [this paper](http://eprints.ma.man.ac.uk/1591/)  and [this paper](http://eprints.ma.man.ac.uk/1451/) for the implementation ", "comments": ["Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.", "Yes, for example transformations of quantum states are given by applying the exponential of a matrix to a vector.", "@ziofil,\r\nSorry for the delay. Can you please refer the documentation of [tf.linalg.expm](https://www.tensorflow.org/api_docs/python/tf/linalg/expm) and let us know if this is what you are looking for? Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Apparently this is stale and closed, but I'd like to bring it up again here as the original issue didn't make it very clear why this is useful. It seems like if one has `tf.linalg.expm` that it is good enough since multiplying by a vector is then trivial. However\r\n in practice one can calculate  exp(\ud835\udc34)\ud835\udc4f  without first computing  exp(\ud835\udc34)  which is cheaper. This is what `scipy.sparse.linalg.expm_multiply` does, which implements the algorithm from [ref].\r\n\r\n[[ref]](http://eprints.ma.man.ac.uk/1426/) - A. H. Al-Mohy and N. J. Higham, Computing the Action of the Matrix Exponential, with an Application to Exponential Integrators, SIAM J. Sci. Comput., 32:488-511, 2011.\r\n\r\nA quote from that paper\r\n\"Experimental comparisons with two Krylov-based MATLAB codes show the new algorithm to be sometimes much superior in terms of computational cost and accuracy. **An important application of the algorithm is to exponential integrators for ordinary differential equations.** It is shown that the sums of the form $\\sum_{k=0}^p \\varphi_k(A)u_k$ that arise in exponential integrators, where the $\\varphi_k$ are related to the exponential function, can be expressed in terms of a single exponential of a matrix of dimension\""]}, {"number": 33171, "title": "Fix for #33134 in v2.0", "body": "Updating softmax args description in v2.0 - logits can be of any type that can be passed to convert_to_tensor(), and Raises associated errors. #33134", "comments": ["Now that 2.0 has been released, no more changes to the branch can be accepted, except if we do security fixes and patch releases."]}, {"number": 33169, "title": "Can we set a proper range of bazel?", "body": "```\r\n[17:01:55] fagn:tensorflow git:(master) $ ./configure\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.23.0 installed.\r\nPlease upgrade your bazel installation to version 0.24.1 or higher to build TensorFlow!\r\n[17:02:35] fan:tensorflow git:(master) $ ./configure\r\nExtracting Bazel installation...\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.29.1 installed.\r\nPlease downgrade your bazel installation to version 0.26.1 or lower to build TensorFlow! To downgrade: download the installer for the old version (from https://github.com/bazelbuild/bazel/releases) then run the installer.\r\n\r\n```\r\n\r\nMessages said higher..... but not upper bounds.... then installed newest version got need lower....\r\n\r\nWhy one sentence can not said in one line?", "comments": ["@jinfagang, Tensorflow 1.14.0 supports 0.24.1 Bazel version and Tensorflow 2.0.0 supports 0.26.1 Bazel version. Please take a look at [tested build configurations](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "@jinfagang, Did you get a chance to look at the [link](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33169\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33169\">No</a>\n"]}, {"number": 33168, "title": "[2.0] Disable usage of GPU using the new config APIs", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFor 2.0, there are some new APIs to configure GPU devices (https://www.tensorflow.org/api_docs/python/tf/config/experimental).\r\n\r\nHowever, by using the current APIs, we have to select at least one GPU to be visible [[source code](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/eager/context.py#L1174-L1202)].\r\n\r\nA similar report is [here](https://github.com/tensorflow/tensorflow/issues/26460#issuecomment-515707199).\r\n\r\nIt would be useful if we can completely disable the usage of GPUs for `tensorflow-gpu` release.\r\n", "comments": ["Does executing your code from within the cotext of a `tf.device` statement work for you? Example:\r\n\r\n    with tf.device('/CPU:0'):\r\n        #your code here\r\n", "TF will occupy 300~400 MB of GPU memory for each GPU when it does initialization. It's a great waste in a multi-gpu machine.", "One way is that we can set the environment variable `CUDA_VISIBLE_DEVICES=\"\"` to disable the GPU initialization. But in my case, a cluster (typically, [ray](https://github.com/ray-project/ray)) reads `CUDA_VISIBLE_DEVICES` and then allocates GPUs to different remote processes.\r\n\r\nSince TF has provided some experimental APIs to configure GPU, it would be great to also support for the disability of GPUs.", "Hi, is there any update on this?  \r\n\r\nI would have expected `tf.config.experimental.set_visible_devices([], 'GPU')` to do this, but it just ends up allocating memory on all available devices.\r\n\r\nWe used to be able to set `tf.Session(tf.ConfigProto(device_count={'GPU': 0}))`, maybe something similar for 2.0?", "@jvishnuvardhan @aaroey ", "@jaingaurav could you help to take a look? Thanks.", "`tf.config.experimental.set_visible_devices([], 'GPU')` seems to work for me. What does the output of `tf.config.experimental.list_logical_devices()` return? If you are seeing a GPU there, then the visible devices configuration did not properly apply.", "Actually hold on, I was using a different build. It seems like memory is still being used even if no visible devices are being set.", "We were able to confirm that a small amount of memory is being used by XLA. We're working on a fix now.", "As per the commits referenced above, I believe this issue has already been fixed.", "Hi @jaingaurav It seems that this issue still exists. Please refer to this [notebook](https://colab.research.google.com/drive/1DiSO-TWlph6lHteWnPrOfoGytfCHs0IS).", "@llan-ml: Please try testing with the nightly by running `!pip install tf-nightly-gpu` first. Most of the memory is gone (though I still saw 10 MB on my end).", "Hey @jaingaurav, thanks for the fix!  To clarify, this feature will be available in TensorFlow 2.2?\r\n\r\nAlso, to disable GPU usage is, as suggested:\r\n\r\n```\r\ntf.config.experimental.set_visible_devices([], 'GPU')\r\n```\r\n\r\nIs that right?", "@tgaddair: Yes that is correct, we'll be cutting 2.2 in the next few days. And yes again, the tf.config API is the the way to go. Note that as of 2.1 the API is no longer experimental so you should be able to do:\r\n```\r\ntf.config.set_visible_devices([], 'GPU')\r\n```", "Thanks for clarifying @jaingaurav, that sounds good.", "Hi, I was looking for a command to disable the gpu temporarily but this (tf.config.set_visible_devices([], 'GPU')) still doesn't work, GPU is still seen and recognized.\r\n\r\nStarting with a kernel restart and outputs cleared with and without this command I get the following output plus my LSTM is taking exactly 2 seconds per epoch (which is really fast indicating the GPU is being used.\r\n\r\nin:\r\nfrom tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n\r\nout:\r\n2.1.0\r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 1101021068840087635\r\n, name: \"/device:XLA_CPU:0\"\r\ndevice_type: \"XLA_CPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 4860144077117132374\r\nphysical_device_desc: \"device: XLA_CPU device\"\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nmemory_limit: 7321806439\r\nlocality {\r\n  bus_id: 1\r\n  links {\r\n  }\r\n}\r\nincarnation: 9454423434461393270\r\nphysical_device_desc: \"device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\"\r\n, name: \"/device:XLA_GPU:0\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 105405715844467737\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\n]"]}, {"number": 33167, "title": "Typo", "body": "https://github.com/tensorflow/docs/blame/master/site/en/tutorials/load_data/text.ipynb#L166\r\n\r\nHas the word \"labeled\" twice", "comments": ["Thank you. This has been fixed now"]}, {"number": 33166, "title": "minor spelling tweaks under mlir", "body": "This PR addresses minor spelling tweaks under `tensorflow/compiler/mlir` directory. This is complementary to #33091.", "comments": ["Should these changes be made on the MLIR repo and reflected back here? Or the other way round? With the code duplication between the two, it's harder to identify proper location of changes", "> Should these changes be made on the MLIR repo and reflected back here? Or the other way round? With the code duplication between the two, it's harder to identify proper location of changes\r\n\r\nThese changes are only to files that are only in TF MLIR and not MLIR core repo.", "@kiszk Can you please resolve conflicts? Thanks!", "@gbaned Thank you for pinging me. Just resolved.", "@kiszk Still, conflicts are appearing. Can you please resolve? Thanks!", "@gbaned sure, just resolved.", "@kiszk  Can you please resolve conflicts? Thanks!", "@gbaned @jpienaar Sorry for being late. I made a business trip. I have just fixed conflict.", "Sorry missed your response. Let me approve again, if it conflicts I'll pull it manually and update."]}]