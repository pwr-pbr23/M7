[{"number": 53821, "title": "Delete MklDnnData::operator= to prevent memory leaks in the future", "body": "This is the continuation of #45593", "comments": []}, {"number": 53820, "title": "Declare Go import path in distributed XLA service protocol", "body": "PR declares `go_package` in proto and resolves protoc-gen-go error.", "comments": []}, {"number": 53819, "title": "Training a model : Error ", "body": "# Train the Model\r\nmodel.fit(x=train_batches,\r\n          steps_per_epoch=len(train_batches),\r\n          validation_data=valid_batches,\r\n          validation_steps=len(valid_batches),\r\n          epochs=10,\r\n          verbose=2\r\n)\r\n\r\n\r\n........................................................................................................................................\r\n\r\nValueError                                Traceback (most recent call last)\r\nInput In [12], in <module>\r\n      1 # Train the Model\r\n----> 2 model.fit(x=train_batches,\r\n      3           steps_per_epoch=len(train_batches),\r\n      4           validation_data=valid_batches,\r\n      5           validation_steps=len(valid_batches),\r\n      6           epochs=10,\r\n      7           verbose=2\r\n      8 )\r\n\r\nFile ~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n     65 except Exception as e:  # pylint: disable=broad-except\r\n     66   filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67   raise e.with_traceback(filtered_tb) from None\r\n     68 finally:\r\n     69   del filtered_tb\r\n\r\nFile ~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129, in func_graph_from_py_func.<locals>.autograph_handler(*args, **kwargs)\r\n   1127 except Exception as e:  # pylint:disable=broad-except\r\n   1128   if hasattr(e, \"ag_error_metadata\"):\r\n-> 1129     raise e.ag_error_metadata.to_exception(e)\r\n   1130   else:\r\n   1131     raise\r\n\r\nValueError: in user code:\r\n\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\r\n        return step_function(self, iterator)\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\r\n        outputs = model.train_step(data)\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\r\n        loss = self.compiled_loss(\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\r\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\r\n        losses = call_fn(y_true, y_pred)\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\r\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\r\n        return backend.categorical_crossentropy(\r\n    File \"C:\\Users\\leena juliet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\r\n        target.shape.assert_is_compatible_with(output.shape)\r\n\r\n    ValueError: Shapes (None, None) and (None, 7, 7, 2) are incompatible\r\n", "comments": ["@leenajuliet-cc ,\r\nPlease take a look at this SO links [1](https://stackoverflow.com/questions/61742556/valueerror-shapes-none-1-and-none-2-are-incompatible) [2](https://stackoverflow.com/questions/62449191/tensorflow-error-in-colab-valueerror-shapes-none-1-and-none-10-are-inco) and [3](https://stackoverflow.com/questions/62148806/valueerror-shapes-none-1-and-none-6-are-incompatible) with the similar error.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53819\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53819\">No</a>\n"]}, {"number": 53818, "title": "File system scheme 's3' not implemented", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below):  tensorflow==2.7.0\r\n- TensorFlow-IO version: tensorflow-io==0.23.1\r\n- Python version: Python 3.8.12\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n`tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 's3' not implemented`\r\n\r\n**Describe the expected behavior**\r\n`Should be able to connect the s3 filesystem.`\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): NA\r\n- Briefly describe your candidate solution(if contributing):\r\n Rollback to `tensorflow-io==0.17` and `tensorflow==2.4.4` seems to resolve issue\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.python.lib.io import file_io\r\nprint(file_io.stat('s3://bucketname/path/'))\r\n```\r\n\r\n```\r\nfrom tensorflow.io import gfile\r\nprint(gfile.exists(`s3://bucketname/path/`))\r\n\r\n```\r\n\r\n**Other info / logs**  Similar older issue [here- 40302](https://github.com/tensorflow/tensorflow/issues/40302)", "comments": ["#51583", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53818\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53818\">No</a>\n"]}, {"number": 53817, "title": "How to add monolithic flag when compile tensorflow-lite with cmake tools", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\nOS Platform and Distribution: \r\nLinux centos 7.6\r\nTensorFlow installed from source\r\nTensorFlow version: 2.7.0\r\nPython version: 3.9.6\r\nBazel version: 4.2.2\r\nGCC/Compiler version (if compiling from source): 7.3.1\r\n\r\n**Describe the problem**\r\n![image](https://user-images.githubusercontent.com/5045116/150095111-da33a434-1e1b-4db8-884b-6f124862f6e0.png)\r\nThe article teaches how to add monolithic flag with bazel, but I know how to add options with cmake tools. Thank you!\r\n", "comments": ["@lantianguhong \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),please refer this[ link](https://www.tensorflow.org/lite/guide/build_cmake) and let us know if it helps?\r\nThanks!", "Closing this issue due to lack of recent activity. Please feel free to reopen this ticket when new information becomes available. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53817\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53817\">No</a>\n"]}, {"number": 53815, "title": "tensorflow.datasets.load() throws an exception", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not a mobile device\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.8.0-rc0-28-g24a4b3b5e58 2.8.0-rc1\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 4.2.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.2 / 8.1.1.33\r\n- GPU model and memory: NVIDIA GeForce 940MX 1629 MB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nAfter running the script\r\n\r\n`import tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nprint(tf.__version__)\r\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)`\r\n\r\nI am getting the following output:\r\n\r\n2.8.0-rc1\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Invalid argument\r\n\r\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\r\n\r\n**Describe the expected behavior**\r\nNo exception is expected\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n`import tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nprint(tf.__version__)\r\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)`\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @vyepishov1 ! There are import issues in 2.8.rc0 in Colab.  Attaching relevant threads link [1](https://github.com/tensorflow/tensorflow/issues/14885) ,[2](https://github.com/tensorflow/tensorflow/issues/17216)  though. Can you try building from sources with tested[ specification](https://www.tensorflow.org/install/source#gpu) ? Thank you!", "> Hi @vyepishov1 ! There are import issues in 2.8.rc0 in Colab. Attaching relevant threads link [1](https://github.com/tensorflow/tensorflow/issues/14885) ,[2](https://github.com/tensorflow/tensorflow/issues/17216) though. Can you try building from sources with tested[ specification](https://www.tensorflow.org/install/source#gpu) ? Thank you!\r\n\r\nHi @mohantym! Thank you for the advice. I managed to get working tensorflow 2.7.0 that was built with the GPU support, but my aim was to try the 2.8 version. Anyway, I think I have found the working solution by removing the --config=monolithic option from the bazel build. Also, I used gcc 7 instead of gcc 9 (not sure, if the latest had also the influence onto getting proper wheel).", "Can confirm that I could manage to build working tensorflow 2.8.0-rc1 with enabled CUDA and MKL support by removing the --config=monolithic options and using GCC 7 instead of GCC 9. Anyway, some work needs to be done with the 2.8.0 version to make it possible to use the --config=monolithic option as well.", "@vyepishov1 ! if you are looking to build with mkl support , you can put **--config=mkl** instead **--config=monolithic**. Attaching relevant [thread ](https://www.tensorflow.org/install/source#preconfigured_configurations)for reference. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53815\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53815\">No</a>\n"]}, {"number": 53814, "title": "bazel compile errors", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\nOS Platform and Distribution: \r\nLinux centos 7.6\r\nTensorFlow installed from source\r\nTensorFlow version: 2.7.0\r\nPython version: 3.9.6\r\nBazel version: 4.2.2\r\nGCC/Compiler version (if compiling from source): 7.3.1\r\n\r\n**Describe the problem**\r\nHello, I want to get libtensorflowlite.so with bazel, but I met a problem.  The llvm tar file is wrong, it can't be exacted.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build -c opt --cxxopt=-std=c++11 --config=mkl --config=numa --config=monolithic //tensorflow/lite:libtensorflowlite.so\r\n\r\n**Any other info / logs**\r\nFollowing is the error logs:\r\nError in download_and_extract: java.io.IOException: Error downloading [https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/2325f363010d3176e96579628cbb96b8fca003a1.tar.gz, https://github.com/llvm/llvm-project/archive/2325f363010d3176e96579628cbb96b8fca003a1.tar.gz] to /home/cjh/.cache/bazel/_bazel_cjh/904c1e9488234a0ff2cc21c6287b3e45/external/llvm-raw/temp9533793750467514112/2325f363010d3176e96579628cbb96b8fca003a1.tar.gz: Premature EOF\r\nI try to extract the temp9533793750467514112/2325f363010d3176e96579628cbb96b8fca003a1.tar.gz file, then a same problem occurs. The downloading file is wrong.\r\n[cjh tensorflow-master]$ tar -xf llvm-project-2325f363010d3176e96579628cbb96b8fca003a1.tar.gz\r\ngzip: stdin: unexpected end of file\r\ntar: Unexpected EOF in archive\r\ntar: Unexpected EOF in archive\r\ntar: Error is not recoverable: exiting now", "comments": ["@lantianguhong \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@lantianguhong Could you please refer the [build from source ](https://www.tensorflow.org/install/source) and check the tested build configurations ?Please let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53814\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53814\">No</a>\n"]}, {"number": 53813, "title": "undefined symbol: _ZN4llvm7APFloat15getAllOnesValueERKNS_12fltSemanticsEj Target //tensorflow:libtensorflow_cc.so", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 20.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 2.7.0\r\n- Python version: 3.9.6\r\n- Bazel version: 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: GTX3060\r\n\r\n**Describe the problem**\r\nBuild tensorFlow 2.7.0 from source error:\r\nERROR: /root/Tensorflow/tensorflow-2.7.0/tensorflow/core/kernels/mlir_generated/BUILD:1146:23: Generating kernel '%{label}' failed (Exit 127): tf_to_kernel failed: error executing command bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel '--unroll_factors=4' '--tile_sizes=1024' '--max-supported-rank=5' '--arch=compute_86' ... (remaining 5 argument(s) skipped)\r\nbazel-out/k8-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel: symbol lookup error: bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel: undefined symbol: _ZN4llvm7APFloat15getAllOnesValueERKNS_12fltSemanticsEj\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 17520.571s, Critical Path: 494.07s\r\nINFO: 19740 processes: 6816 internal, 12924 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n./configure\r\nset CUDA support Yes\r\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so\r\n\r\n**Any other info / logs**\r\nthe same error at TensorFlow 2.8\r\n", "comments": ["@hujhcv ,\r\nCan you please confirm if you are trying to install from these link [1](https://github.com/tensorflow/tensorflow/blob/master/README.md) and [2](https://www.tensorflow.org/install/lang_c).Thanks!", "> @hujhcv , Can you please confirm if you are trying to install from these link [1](https://github.com/tensorflow/tensorflow/blob/master/README.md) and [2](https://www.tensorflow.org/install/lang_c).Thanks!\r\n\r\nI use \"pip install tensorflow\" to install tensorflow. and try like this\uff1aimport tensorflow as tf\r\nerror is as follows\uff1a\r\n\r\n(py39) root@bsyai:~# python\r\nPython 3.9.6 (default, Aug 18 2021, 19:38:01) \r\n[GCC 7.5.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"/opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"/opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 79, in <module>\r\n    raise ImportError(\r\nImportError: Traceback (most recent call last):\r\n  File \"/opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /opt/miniconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\r\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\r\n>>> exit()\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53813\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53813\">No</a>\n"]}, {"number": 53812, "title": "[ROCm] Add amdgpu_arch string as member variable in ir_emitter_context", "body": "This PR is a pre-req for a follow-up PR which will introduce gfx arch specific codegen in the IR emitter code.\r\n\r\n-------------------------\r\n\r\n/cc @chsigg @cheshire \r\n", "comments": ["@deven-amd Can you please check @cheshire's comments and keep us posted ? Thanks!", "@cheshire, please re-review....I have updated this branch with a subset of the changes you reviewed for the PR to introduce `RocComputeCapability` in the rocm fork.\r\n\r\nAlso I see that the `Code Check - Changed Files` is failing, but am unable to determine what exactly is causing the failure...please let me know if that is something I need to look into", "@deven-amd  Can you please check @cheshire's comments and keep us posted ? Thanks!", "@gbaned , thought @cheshire already approved the PR. Please merge....there are few other PRs we need to file, but are dependent on the changes in this PR.\r\n\r\nthanks", "@gbaned anything I can do on my end to get the PR merged? thanks", "> @gbaned anything I can do on my end to get the PR merged? thanks\r\n\r\n@deven-amd  This PR is processing internally, nothing pending from your end. Thank you."]}, {"number": 53811, "title": "AttributeError: 'Tensor' object has no attribute '_keras_mask' TF 2.7", "body": "AttributeError: 'Tensor' object has no attribute '_keras_mask'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield                   \r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 346, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 699, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nAttributeError: in user code:\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.7\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior** currently we use tf 2.2 and the code runs fine. but any version from 2.3 its failing\r\n\r\n", "comments": ["Hi @kabilan6! \r\nCould you provide a stand alone code to reproduce this issue? Attaching relevant [thread](https://github.com/tensorflow/tensorflow/issues/42403#issuecomment-751622363) for reference. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53811\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53811\">No</a>\n"]}, {"number": 53809, "title": "Remove DISC from MHLO", "body": "At the moment DISC is developed in https://github.com/alibaba/BladeDISC and no\r\nlonger actively in integration in this repository. For now we'll delete the early\r\ncontributions that aren't used. They can be brought back here any time in the future as\r\nneeded.", "comments": []}, {"number": 53808, "title": "Update version numbers for TensorFlow 2.8.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 8 -> 8\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.8.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"2.8.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:96:2.8.0rc0\n```", "comments": []}, {"number": 53807, "title": "Add missing return statement to AveragePool16", "body": "Fixes bug in AveragePool16 introduced by #51318", "comments": ["Duplicate of #53768"]}, {"number": 53806, "title": "Deprecation message for tf.compat.v1.batch_gather suggests invalid migration", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow version (use command below): `v2.7.0-0-gc256c071bb2 2.7.0`\r\n- Python version: `3.7.12`\r\n\r\n**Describe the current behavior**\r\n\r\nUsing `tf.compat.v1.batch_gather` triggers the following warning:\r\n\r\n```python\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\r\nInstructions for updating:\r\n`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\r\n```\r\n\r\nThis warning was last edited in [this commit](https://github.com/tensorflow/tensorflow/commit/50abb98b7db07adc78df883ffa7b6c6dd4273ffc).\r\n\r\nHowever, the suggested migration from `tf.compat.v1.batch_gather(...)` to `tf.gather(..., batch_dims=-1)` is invalid \u2014\u00a0e.g., see [this Colab notebook](https://colab.research.google.com/gist/dniku/7510249f61b9b00881af6c0bcfdac7a3/tf_migrate_batch_gather_to_gather.ipynb) for an example. From the [implementation](https://github.com/tensorflow/tensorflow/blob/c256c071bb26e1e13b4666d1b3e229e110bc914a/tensorflow/python/ops/array_ops.py#L5166) of `batch_gather` it seems that the correct migration is from\r\n\r\n```python\r\ntf.compat.v1.batch_gather(data, indices)\r\n```\r\nto\r\n```python\r\ntf.gather(data, indices, batch_dims=tf.rank(indices) - 1)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe warning should be amended.", "comments": ["@Saduf2019 ,\r\nI was able to reproduce the issue in tf [v2.7](https://colab.research.google.com/gist/tilakrayal/7b6fddffae4c22cb2a86fa3d63728ada/tf_migrate_batch_gather_to_gather-2-7.ipynb), [v2.5](https://colab.research.google.com/gist/tilakrayal/917e6d99b4c31b4aaee98deba7202cc4/tf_migrate_batch_gather_to_gather2-5.ipynb) and [nightly](https://colab.research.google.com/gist/tilakrayal/da1a790730efaeaaf1a2ce1fddf8d246/tf_migrate_batch_gather_to_gather.ipynb).Please find the gist here.", "This should be fixed , I made the change internally.Thank you @dniku ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53806\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53806\">No</a>\n"]}, {"number": 53805, "title": "Using scipy fsolve or other solvers (e.g. GEKKO) in combination with backpropagation models", "body": "I was wondering if there was any progress or existing methodologies to use existing solvers such as GEKKO to find/update certain values in your network.\r\nE.g: When using PINN networks on a electrical circuit, one might use a variable resistance dependent on one of your network input parameters. When this dependency is given by an explicit equation it would be nice to, given the inputs, be able to use existing solvers as scipy's fsolve to get this value and use it further on in the network.\r\n\r\nFrom my experience in order to be able to use solvers, tensors should be converted to numpy elements and used in combination with tf.numpy_function, this way I can use solvers as such, however it breaks the chain of gradients and TF can no longer find gradients for certain values and thus no longer train the network.\r\n\r\n**System information**\r\n- Tensorflow 2.3.0 (but using some TF1 functionalities from tf.compat.v1:\r\n- No possibility to share existing code, but see below for small (hypothetical) case example. \r\n\r\n\r\n\r\n### start of code\r\nfrom scipy.optimize import fsolve\r\nClass PPINlayer(tf.keras.layers.Layer)\r\n       def __init__(self):\r\n               super(PPINlayer, self).__init__(**kwargs)\r\n\r\n       def call(self, input, NN *args):\r\n               NNoutput = NN(input)                # this is a NN already initialized somewhere else with trainable parameters\r\n               output = self.f(NNoutput, input)\r\n               return output                                # the output is then used later on to compare with labeled data as loss function for training\r\n       def f(self, NNoutput, input)\r\n             R0 = input[0]\r\n             R1 = input[1]\r\n             V0 = input[2]\r\n             def R2_eq(R2, R0, R1):\r\n                    return np.exp(R2/R1) * R1/R2 + R0**2\r\n             R2 = fsolve(R2_eq, 0, args=(R0, R1))\r\n             return (V0/R0 * R2)\r\n\r\n\r\nThanks in advance!\r\nCedric\r\n", "comments": ["Hi @cevheck !\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "Hi @mohantym!\r\nI will do that, I'll close this issue then.\r\n\r\nThanks!\r\n\r\n\r\nEDIT: Here is the link if other people would want to follow the discussion https://github.com/keras-team/keras/issues/15918"]}, {"number": 53804, "title": "DeeplabV3+ Training on custom dataset", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- Platform and Distribution: Colab\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: Tesla P100, 16 GB memory\r\n\r\n**Current situation**\r\n Worked on Semantics segmentation using TensorFlow's DeepLabv3+ with the Resnet versions backbone architecture. We've trained it for our custom dataset which includes satellite images of Golf Courses extracted from the Google Map API. Our Dataset includes 109 samples for training and we have trained it and got a decent amount of accuracy (~93%) but the results are not as expected.\r\n\r\n**Current behavior**\r\nCurrently, we've referenced the test set which includes similar types of images but the results are not as good as expected. For the sake of curiosity, we have checked by inferencing on Train images also but that also not promising.\r\n\r\n**Expected behavior**\r\nExpected results with this accuracy should be descent as trained on the other custom dataset.\r\n", "comments": ["@parth29-vc \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@sushreebarsa \r\nThe gist for the code snippet is available here. [Gist](https://gist.github.com/parth29-vc/29029bd2989bfc994fedfb976af65b16)", "@parth29-vc \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "Thanks, added to Keras", "@parth29-vc Thank you for the update!\r\nClosing this issue as we will track the other ticket in keras-team/keras repo."]}, {"number": 53803, "title": "lite: Update Subgraph::RemoveUnusedInputs()", "body": "The method has a bug which doesn't count graph output tensors.\r\nThis change fixes it.\r\n\r\nPiperOrigin-RevId: 422469893\r\nChange-Id: Ie0b1a4b56b0e29fe4c5d14f0713d1eeea72f3d55", "comments": ["@mihaimaruseac, I'd like to have this fix on 2.8 release. Please review."]}, {"number": 53802, "title": "Segmentation model C++ API's based inference output different from Python tensors", "body": "**System information**\r\n- Have I written custom code:No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):  Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.3.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.1-cudnn7\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWe've trained a Segmentation model using Keras with Tensorflow backend. Now, We are trying to infer by using the TF C++ interface.\r\nI used the below code snippet to convert the .h5 model to a .pb file.\r\n\r\n```python\r\nkeras_model_path=\"keras_model.h5\"\r\nmodel = tf.keras.models.load_model(keras_model_path,  compile=False)\r\nmodel.summary()\r\ntf.saved_model.save(model, \"~/tf2_cpp/\")\r\n```\r\n\r\nOur python pipeline,\r\n```python\r\nmodel = tf.keras.models.load_model(keras_model_path,  compile=False)\r\nimg = cv2.imread(\"test.jpg\")\r\nresized_img = cv2.resize(img,(224, 224)).reshape([1, 224, 224,3]).astype(np.float32)\r\noutput = model.predict(resized_img) #7, 224, 244, 2\r\nmask = tf.argmax(output[0], axis=3) #1, 244, 244\r\n```\r\nour C++ pipeline,\r\n```c++\r\n// Pre Processing\r\ncv::Mat img = cv::imread(\"test.jpg\")\r\ncv::Size s(224,224);\r\ncv::resize(img, img, s, cv::INTER_LINEAR);\r\ntensorflow::Tensor input_tensor(tensorflow::DT_FLOAT, tensorflow::TensorShape({1, height, width, depth}));\r\nfloat *p = input_tensor.flat<float>().data();\r\ncv::Mat fakeMat(224, 224, CV_32FC3, p);\r\nimg.convertTo(fakeMat, CV_32FC3);\r\n\r\n// Prediction\r\nconst string input_node = \"serving_default_input_4:0\";\r\n// std::vector<std::pair<string, tensorflow::Tensor>> inputs_data  = {{input_node, input_tensor_mapped}};\r\nstd::vector<string> output_nodes = {{\"StatefulPartitionedCall:3\",\r\n    \"StatefulPartitionedCall:2\", \r\n    \"StatefulPartitionedCall:5\", \r\n    \"StatefulPartitionedCall:1\",\r\n    \"StatefulPartitionedCall:4\",             \r\n    \"StatefulPartitionedCall:0\",\r\n    \"StatefulPartitionedCall:6\"}};\r\n\r\nstd::vector<Tensor> predictions;\r\n\r\nthis->bundle.GetSession()->Run({{input_node, input_tensor}}, output_nodes, {}, &predictions);\r\n\r\n//Post-processing\r\nauto argOps = tensorflow::ops::ArgMax(transposeScope, predictions[1], 3);\r\nstd::vector<Tensor> temOutputs;\r\nTF_CHECK_OK(sess.Run({argOps}, &temOutputs));\r\n```\r\n\r\nThe tensor value is different when I compare the result between Python and C++. And, C++ argmax API returning zero for all the tensor as well.\r\n\r\n**Describe the expected behavior**\r\nThe output expected to be same in both Python and C++. Maybe with some precision changes. \r\n", "comments": ["@nullbyte91 ,\r\n In order to expedite the trouble-shooting process, could you please provide a complete code to reproduce the issue.Also\r\ncould you please update TensorFlow to the latest stable version v.2.7 and let us know if you are facing the same error. Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53802\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53802\">No</a>\n"]}, {"number": 53801, "title": "lower \"learning_rate\" as this is what optimizers use internally now", "body": "Lowering \"lr\" does nothing as optimizers use \"learning_rate\" now.", "comments": ["closed until further testing"]}, {"number": 53799, "title": "Update curl dependency to 7.81.0", "body": "This PR updates curl dependency to 7.81.0, as was requested\r\nin https://github.com/tensorflow/tensorflow/pull/52097#issuecomment-1014313571\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 53797, "title": "Update gpu_advanced.md", "body": "Updating \"thThis\" \"This\" as per #53775", "comments": ["In the future, can you try to fix multiple typos at once, please? It doesn't make sense to run all of these hours of CI for just 1-2 letters changes.", "@Saduf2019  Can you please check @mihaimaruseac's comments and resolve conflicts?. Thanks!\r\n", "6eb4c6bc38c81b54b93b063bee41dbe530b4174f"]}, {"number": 53796, "title": "Add linux_aarch64 target to AOT.", "body": "The lack of a target for `linux_aarch64` on AOT breaks tests under `//tensorflow/python/tools`.", "comments": ["Adding @penpornk ", "import/copybara \u2014 An error happened while migrating the change --> What does this error mean?", "Latest commit to the target file removed some lines. So maybe the patch just needs to be rebased?", "> Latest commit to the target file removed some lines. So maybe the patch just needs to be rebased?\r\n\r\nJust rebased.", "Merged as part of e826feabce35024cd00ce27d76db6196f4628970"]}, {"number": 53795, "title": "extracting features using BERT , it will do for only 96% why not upto 100% ", "body": "WARNING:tensorflow:From /home/dr/anaconda3/envs/nlp/lib/python2.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0117 15:32:11.388233 140388266755904 deprecation.py:323] From /home/dr/anaconda3/envs/nlp/lib/python2.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nINFO:tensorflow:Graph was finalized.\r\nI0117 15:32:11.432744 140388266755904 monitored_session.py:240] Graph was finalized.\r\n2022-01-17 15:32:11.432964: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2022-01-17 15:32:11.454749: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\r\n2022-01-17 15:32:11.455164: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fa5428b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2022-01-17 15:32:11.455180: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2022-01-17 15:32:11.456689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2022-01-17 15:32:11.550424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.550724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fa5539e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2022-01-17 15:32:11.550740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\r\n2022-01-17 15:32:11.550854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.551053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: NVIDIA GeForce GTX 1650 major: 7 minor: 5 memoryClockRate(GHz): 1.65\r\npciBusID: 0000:01:00.0\r\n2022-01-17 15:32:11.551208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2022-01-17 15:32:11.551998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2022-01-17 15:32:11.552706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2022-01-17 15:32:11.552874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2022-01-17 15:32:11.553788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2022-01-17 15:32:11.554510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2022-01-17 15:32:11.556731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2022-01-17 15:32:11.556814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.557061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.557242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2022-01-17 15:32:11.557267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2022-01-17 15:32:11.557561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-17 15:32:11.557573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2022-01-17 15:32:11.557578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2022-01-17 15:32:11.557643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.557860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-17 15:32:11.558063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3404 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nINFO:tensorflow:Running local_init_op.\r\nI0117 15:32:12.078099 140388266755904 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0117 15:32:12.114805 140388266755904 session_manager.py:502] Done running local_init_op.\r\n2022-01-17 15:32:12.539938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 77324/80553 [1:24:14<04:11, 12.83it/s]INFO:tensorflow:prediction_loop marked as finished\r\nI0117 16:56:37.640084 140388266755904 error_handling.py:101] prediction_loop marked as finished\r\nINFO:tensorflow:prediction_loop marked as finished\r\nI0117 16:56:37.640234 140388266755904 error_handling.py:101] prediction_loop marked as finished\r\n 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 77324/80553 [1:24:27<03:31, 15.26it/s]\r\n\r\n", "comments": ["@kusumlata123 \r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset , tensorflow version you are using. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53794, "title": "Executing genrule //tensorflow/cc:string_ops_genrule failed (Exit 127): bash failed", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.14\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version : 0.24.1\r\n- GCC/Compiler version: 4.8\r\n- CUDA/cuDNN version: 10.0\r\n- I'm using an EC2 instance\r\n   - Instance type: p2xlarge\r\n   - AMI: Deep Learning Base AMI (Ubuntu 18.04) Version 47.0\r\n\r\n\r\n**Describe the problem**\r\n- I was following installation steps from here: https://github.com/cjweeks/tensorflow-cmake/blob/master/README.md\r\n\r\n#### Step 1 => Clone tensorflow repo\r\n```\r\nsudo apt-get install autoconf automake libtool curl make g++ unzip  # Protobuf Dependencies\r\nsudo apt-get install python-numpy swig python-dev python-wheel      # TensorFlow Dependencies\r\ngit clone https://github.com/tensorflow/tensorflow\r\ngit checkout v1.14.0\r\n```\r\nEnter the cloned repository, and append the following to the tensorflow/BUILD file:\r\n\r\n#### Step 2 => Add build rule\r\n```\r\ncc_binary(\r\n    name = \"libtensorflow_all.so\",\r\n    linkshared = 1,\r\n    linkopts = [\"-Wl,--version-script=tensorflow/tf_version_script.lds\"], # Remove this line if you are using MacOS\r\n    deps = [\r\n        \"//tensorflow/core:framework_internal\",\r\n        \"//tensorflow/core:tensorflow\",\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/cc:scope\",\r\n        \"//tensorflow/c:c_api\",\r\n    ],\r\n)\r\n```\r\n#### Step 3 =>\r\n```\r\n./configure      # Note that this requires user input\r\nbazel build tensorflow:libtensorflow_all.so --verbose_failures\r\n```\r\n\r\n## Error\r\n- I'm getting some error on the last command `bazel build tensorflow:libtensorflow_all.so --verbose_failures` that the build failed\r\n- The error log is stated in the next section\r\n\r\n**Any other info / logs**\r\n```\r\nINFO: Analysed target //tensorflow:libtensorflow_all.so (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/ubuntu/downl/tensorflow/tensorflow/cc/BUILD:492:1: Executing genrule //tensorflow/cc:string_ops_genrule failed (Exit 127): bash failed: error executing command \r\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/364fbdb85a069ae1952a655335bcdb22/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib: \\\r\n    PATH=/home/ubuntu/.local/bin:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/usr/local/cuda/bin:/opt/aws/neuron/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=3.7 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n    TF_NEED_TENSORRT=0 \\\r\n  /bin/bash bazel-out/k8-opt/genfiles/tensorflow/cc/string_ops_genrule.genrule_script.sh)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nbazel-out/host/bin/tensorflow/cc/ops/string_ops_gen_cc: symbol lookup error: bazel-out/host/bin/tensorflow/cc/ops/string_ops_gen_cc: undefined symbol: _ZN10tensorflow15shape_inference36BroadcastBinaryOpOutputShapeFnHelperEPNS0_16InferenceContextENS0_11ShapeHandleES3_PS3_\r\nTarget //tensorflow:libtensorflow_all.so failed to build\r\nINFO: Elapsed time: 2.181s, Critical Path: 1.24s\r\nINFO: 3 processes: 3 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["@aashishgaba-cn ,\r\nWe see that you are using tf version 1.14, 1.x is not actively supported, please update to latest stable v2.7 and let us know if you are facing same issue.Also please take a look at this issue [1](https://stackoverflow.com/questions/33620794/how-to-build-and-use-google-tensorflow-c-api/33622489#33622489), [2](https://github.com/tensorflow/tensorflow/issues/23342) with the similar error.It helps.Thanks!", "@tilakrayal Thanks for the help.\r\n\r\nI was able to build it but the `bazel-genfiles` folder wasn't generated.\r\nI'm following this [link](https://github.com/cjweeks/tensorflow-cmake/blob/master/README.md) for building tensorflow from source. In one of the steps I need to copy the header files present in the `bazel-genfiles` [PFA: Screenshot]\r\n\r\n![image](https://user-images.githubusercontent.com/69104012/149974709-fc7273ad-838f-4466-bd43-ce5b964c19d8.png)\r\n\r\nAm I doing anything wrong?", "@aashishgaba-cn ,\r\nGlad that the build issue got resolved.Please take a look at this link [1](https://github.com/tensorflow/tensorflow/issues/53381) and [2](https://github.com/tensorflow/tensorflow/issues/35534) for the bazel files issue.It helps.Thanks! ", "Hi @tilakrayal , thanks for sharing these. I've checked those issues out but couldn't use anything from them.\r\nThey point to a StackOverflow post, to which there's no solution.\r\n\r\nMy two main concerns are\r\n1) my build doesn't create the bazel-genfiles folder needed for it.\r\n2) missing device_attributes.pb.h\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/53381\r\nThis issue talks about these but there's no clear solution mentioned there.\r\n\r\nCan you point out the steps that I should take next?", "@tilakrayal \r\nBut I don't see a solution there and that issue is closed already.\r\nThe guy resolved something himself and didn't share what he did to resolve that. [Please check screenshot attached]\r\n![image](https://user-images.githubusercontent.com/69104012/150116801-97e8fe71-9bb0-4451-b3ab-32c2b3b05519.png)\r\n\r\n\r\nIn case you know what it was, can you please share it here?", "@aashishgaba-cn , The source which you are following is from the unofficial source and which was updated long back. There could have been changes in  the build configurations since then. \r\nCould you please try the build methods mentioned in our Tensorflow website. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53794\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53794\">No</a>\n"]}, {"number": 53793, "title": "[Feature Request] Support for convolutional layers for `tf.autodiff.ForwardAccumulator`", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.7\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, the implementation of [`tf.autodiff.ForwardAccumulator`](https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator) only officially supports Dense layers.\r\n\r\n**Will this change the current api? How?**\r\nYes. The new API will be able to calculate the JVP also for convolutional layers.\r\n\r\n**Who will benefit from this feature?**\r\nAnyone who wants to implement a neural network with convolutional layers and needs forward-mode autodiff.\r\n\r\n**Any Other info.**\r\nTrying to use the current API results in a shape mismatch:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nbatch_size = 1\r\nimage_width = 4\r\nimage_height = 4\r\nchannels = 3\r\n\r\nx = tf.random.uniform((batch_size, image_width, image_height, channels))\r\nmodel = tf.keras.models.Sequential([tf.keras.layers.Conv2D(filters=6, kernel_size=2)])\r\n\r\nmodel.build(x.shape)\r\n\r\nmodel.summary()\r\n\r\nwith tf.autodiff.ForwardAccumulator(model.trainable_weights[0], tf.constant([[[[1., 0., 0., 0., 0., 0.]]]])) as acc:\r\n  out = model(x) # <----- ValueError\r\n\r\n  print(acc.jvp(out))\r\n```\r\n\r\nSummary:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\n Layer (type)                Output Shape              Param #   \r\n=================================================================\r\n conv2d (Conv2D)             (1, 3, 3, 6)              78        \r\n                                                                 \r\n=================================================================\r\nTotal params: 78\r\nTrainable params: 78\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nError:\r\n```\r\nValueError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\r\n\r\nin user code:\r\n\r\n\r\n    ValueError: Dimension 1 in both shapes must be equal, but are 4 and 3. Shapes are [1,4,4,6] and [1,3,3,6].\r\n    \tFrom merging shape 0 with other shapes. for '{{node AddN}} = AddN[N=2, T=DT_FLOAT](gradient_tape/gradient_tape/Conv2D, gradient_tape/gradient_tape/Conv2D_1)' with input shapes: [1,4,4,6], [1,3,3,6].\r\n\r\n\r\nCall arguments received by layer \"conv2d\" (type Conv2D):\r\n  \u2022 inputs=tf.Tensor(shape=(1, 4, 4, 3), dtype=float32)\r\n```\r\n", "comments": ["Closing as I was using the wrong shape for the `tangent` tensor. In this particular case, it should have been of shape =  `(2, 2, 1, 6)`."]}, {"number": 53792, "title": "Use enable_op_determinism + Fixed seed + same hardware (partial DGX) still get different results in 2.8. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.8rc0\r\n- Python version: 3.8.12\r\n- GPU model and memory:8*V100\r\n\r\nAfter I use enable_op_determinism in TensorFlow 2.8, my model still gets random results (around 0.3 mIOU) after each run. Note that, I set PYTHONHASHEED to a fixed value before start python, and also set a fixed value as the random seed for TensorFlow and numpy etc.\r\n\r\nI wonder why the result is still random in same hardware, since the UnimplementedError should be thrown if nondeterministic op is used.", "comments": ["@duncanriach ", "@edwardyehuang \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "@edwardyehuang, this could be due to issue [53771](https://github.com/tensorflow/tensorflow/issues/53771). I assume that your model uses convolution. Seconding @sushreebarsa's request for a reproducer.", "> @edwardyehuang, this could be due to issue [53771](https://github.com/tensorflow/tensorflow/issues/53771). I assume that your model uses convolution. Seconding @sushreebarsa's request for a reproducer.\r\n\r\nThanks for your reply. I will try it. However, should I set TF_CUDNN_USE_FRONTEND = 1 before python start?", "Not work, sorry. I ran the same model on two 4*v100 machine, with TF_CUDNN_USE_FRONTEND =1 , but I awarded another mentioned source of nondeterminism in the last update of #53771  ", "@edwardyehuang, yes, running with `TF_CUDNN_USE_FRONTEND=1 ` would be the workaround for the base issue discussed in #53771; thanks for adding that to your process. It is possible, although it's very unlikely, that you're running into the OOM issue discussed in #53771; I doubt it's that.\r\n\r\nYou mention that you're running on a 4*V100 machine. I assume that you're only running on one of the GPUs though. Is that correct?", "> @edwardyehuang, yes, running with `TF_CUDNN_USE_FRONTEND=1 ` would be the workaround for the base issue discussed in #53771; thanks for adding that to your process. It is possible, although it's very unlikely, that you're running into the OOM issue discussed in #53771; I doubt it's that.\r\n> \r\n> You mention that you're running on a 4*V100 machine. I assume that you're only running on one of the GPUs though. Is that correct?\r\n\r\nSorry I misunderstood it. I ran on 4*v100 or 8*v100 without OOM. However, after I set TF_CUDNN_USE_FRONTEND=1, my result still is different on each run.  Is there any other soruce can result nondeterminism?\r\n\r\nNote that, I may not use the same v100 cards in each run.", "My question is this: are you training on a single GPU or on a multi-GPU setup? If you're training using more than one GPU, what regime are you using to coordinate the work between the GPUs?", "> regime are you using to coordinate the work\r\n\r\nI am using multi-GPU setup with tf.distribute.MirroredStrategy()\r\n\r\nI think the GPUs connection is simliar like DGX, since the GPU card name is \"Tesla V100-SXM2...\".\r\n\r\nI may check further information if you need @duncanriach ", "I will try a small setup, for both single and multi-gpu, on my own machine (2 * Titan RTX), to see if the problem is still existing.", "> I will try a small setup, for both single and multi-gpu, on my own machine (2 * Titan RTX), to see if the problem is still existing.\r\n\r\nIn my own machine with multiple-gpu setup (2* Titan RTX), it can be repeated. I will try to figure out why it cannot be repeated in my company machine (maybe different v100 cards each run?)", "It's always good to narrow the issue down by discovering if it happens on a single GPU or not. If a single GPU is operating deterministically, then the problem would be related to the multi-GPU setup. If a single GPU does not operate deterministically, then you've narrowed the problem down, leading towards a smaller/simpler reproducer.", "> It's always good to narrow the issue down by discovering if it happens on a single GPU or not. If a single GPU is operating deterministically, then the problem would be related to the multi-GPU setup. If a single GPU does not operate deterministically, then you've narrowed the problem down, leading towards a smaller/simpler reproducer.\r\n\r\nPossible source of nondeterminism is located. \r\n\r\nWhen I used entire DGX (8 * v100), even not the same machine every time, the result can be repeated (deterministically).\r\nWhen I only used partial of DGX (e.g. 4 * v100), the result is nondeterminism\r\n\r\n@duncanriach \r\n", "@edwardyehuang \r\nIn order to expedite the trouble-shooting process, could you please provide a code snippet to reproduce the issue reported here. Please try with the latest tf-nightly and let us know the outcome? \r\nThanks!", "> @edwardyehuang In order to expedite the trouble-shooting process, could you please provide a code snippet to reproduce the issue reported here. Please try with the latest tf-nightly and let us know the outcome? Thanks!\r\n\r\nThanks for your reply. Please read previous replies and #53771 . \r\nWhat we diccussed in this issue and #53771  already slightly beyond (#53826) tf-nightly. And a code snippet cannot reproduce the issue since this is caused by multi-gpus.\r\n\r\nRegards", "@edwardyehuang,\r\n\r\n1. By discovering that there is nondeterminism with 4 GPUs but not with 8 GPUs, you have mostly ruled out the possibility that this is a within-GPU issue, and therefore you have mostly ruled out that your issue is related to #53771.\r\n2. Ideally, you would run on a single GPU just to confirm that it is definitely not a within-GPU issue.\r\n3. It may be possible that you are running into [this issue](https://github.com/NVIDIA/framework-determinism/issues/39), in the framework-determinism repo, which I have asked @yanniskar to move into the main TensorFlow repo. This reports a problem with `tf.data.experimental.sample_from_datasets` in the context of multi-GPU.\r\n4. Regardless, it is theoretically possible to provide a code snippet to reproduce the issue, including the code you use to configure multi-GPU operation. As @sushreebarsa states, once you provide a simple-as-possible reproducer, it makes debugging possible on our side. Up until now, I've only been able to help you to isolate the problem into a smaller scope, through this remote-guidance process.\r\n", "Close this issue for now, since I am very busy atm, and the current staus of determinism (8\u00d7v100) is enough for me to largely outperform prior art preformance deterministically.\r\n\r\nI will reopen this issue afterwards, and will ack your hard working on determinism in my paper.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53792\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53792\">No</a>\n", "Thank you, @edwardyehuang."]}, {"number": 53791, "title": "BUG Fail to save model when tf.summary is used inside keras model", "body": "**System information**\r\n- OS: Linux\r\n- Python Version: 3.6.8\r\n- Tensorflow version: Git version v2.6.0-rc2-32-g919f693420e  tf_version 2.6.0\r\n\r\n**Describe the current behavior**\r\n`tf.keras.Model.save` raises error when `tf.summary` is used inside of `call` function. A short script for reproducing the problem: \r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\n\r\nclass Mymodel(tf.keras.Model):\r\n    \r\n    def __init__(self):\r\n        super().__init__()\r\n        self.l = tf.keras.models.Sequential([\r\n            layers.Dense(64) for _ in range(3)\r\n        ] + [layers.Dense(1)])\r\n    \r\n    def call(self, inputs, training=None):\r\n        tf.summary.scalar(name='avg_1', data=tf.reduce_sum(inputs))\r\n        return self.l(inputs)\r\n\r\nm = Mymodel()\r\nm.compile(loss='mse', optimizer='adam')\r\nm.fit(np.random.randn(1000, 20), np.random.randn(1000), epochs=5)\r\n\r\nm.save('/tmp', save_format='tf')\r\n```\r\nthis raises the following error:\r\n```\r\nAssertionError: Tried to export a function which references untracked resource Tensor(\"72061:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\nTrackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops)\r\n```\r\neverything works fine if I comment out the `tf.summary.scalar` line.\r\n\r\n", "comments": ["Tried with Linux system, tf version 2.7.0 , python version 3.7.9, still has the same problem", "@MaxwellLZH ,\r\nI was facing different error while trying to execute the mentioned code.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/50606e360b18554c654e35452ad0db36/untitled190.ipynb) and share the required dependencies.Thanks!", "@tilakrayal you are missing the layers import. check it [here](https://colab.research.google.com/gist/kalosisz/bee99d0803270b8d1da5071074bbb2da/untitled190.ipynb)\r\n\r\nIt can save and load the model", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53791\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53791\">No</a>\n"]}, {"number": 53788, "title": "How to build MLIR tools on the latest master branch?", "body": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/mlir#using-local-llvm-repo\r\nSeveral files mentioned in it no longer exist. How to compile the new version?", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53788\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53788\">No</a>\n"]}, {"number": 53787, "title": "Tensorflow Lite Android Example : Insecure protocols", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android and all other examples.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWhen I build any example, I get this error :\r\n```\r\n> Using insecure protocols with repositories, without explicit opt-in, is unsupported. Switch Maven repository 'ossrh-snapshot(http://oss.sonatype.org/content/repositories/snapshots)' to redirect to a secure protocol (like HTTPS) or allow insecure protocols. See https://docs.gradle.org/7.3.2/dsl/org.gradle.api.artifacts.repositories.UrlArtifactRepository.html#org.gradle.api.artifacts.repositories.UrlArtifactRepository:allowInsecureProtocol for more details. \r\n```\r\n\r\nWe need to set `allowInsecureProtocol` to `true` in the build.gradle. \r\n```\r\nmaven {\r\n    name 'ossrh-snapshot'\r\n    url 'http://oss.sonatype.org/content/repositories/snapshots'\r\n    allowInsecureProtocol = true\r\n    }\r\n```", "comments": ["@maximecharriere \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),and let us know more details on this issue?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53786, "title": "Android Tensorflow ObjectDetection lib_task_api default number of threads?", "body": "Hello,\r\nWe are working on implementing Tensorflow object detection based on the example provided here:\r\nhttps://github.com/tensorflow/examples/tree/eb925e460f761f5ed643d17f0c449e040ac2ac45/lite/examples/object_detection/android\r\nIt seems that there are 2 implementations for that one:\r\n```\r\n(1) lib_task_api that leverages the out-of-box API from the TensorFlow Lite Task Library;\r\n(2) lib_interpreter that creates the custom inference pipleline using the TensorFlow Lite Interpreter Java API.\r\n```\r\nWe are using `lib_task_api` and we don't see the way how we can set the number of threads with it? \r\nFor the `lib_interpreter` - there is a variable that is being set up for that.\r\nhttps://github.com/tensorflow/examples/blob/a228a3460f3fdd8edee9e8b061a08ffc92629907/lite/examples/object_detection/android/lib_interpreter/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L138\r\nOn the other hand - for `lib_task_api` i see that this method is deprecated and it is not set up\r\nhttps://github.com/tensorflow/examples/blob/eb925e460f761f5ed643d17f0c449e040ac2ac45/lite/examples/object_detection/android/lib_task_api/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L87\r\n\r\nMy question being - what is the default number of threads for `lib_task_api`? \r\nI am asking this one because i would like to tune it up for different set of devices.\r\n\r\nBest Regards", "comments": ["@AleksandarTokarev ,\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]