[{"number": 37554, "title": "[r2.2:Cherrypick][TF XLA AOT PIP] Fix windows build by properly including the env_time from platform/windows/.", "body": "PiperOrigin-RevId: 300186790\nChange-Id: Iba5021aed9ed8679486ca78c7ce5089270592176", "comments": []}, {"number": 37553, "title": "[r2.2:Cherrypick]KokoroFAILURE:tensorflow_serving /github/ubuntu/cpu_tf_latest/continuous_tf_head", "body": null, "comments": ["I think we are rolling back the change at head.", "Trying to avoid rollback now", "Rollback avoided.  This should be OK to push."]}, {"number": 37552, "title": "Log learning rate to TensorBoard when using schedules", "body": "`keras.callbacks.LearningRateScheduler` automatically logs the learning rate to TensorBoard.\r\n\r\nHowever, when using `keras.optimizers.schedules.LearningRateSchedule` for step wise learning rate scheduling there is no builtin way of observing the learning rate in TensorBoard which can be crucial for debugging and experimenting with different schedules.\r\n\r\nThis PR adds support for automatic logging of the learning rate of optimizers that use `keras.optimizers.schedules.LearningRateSchedule`.", "comments": ["@lgeiger Can you please resolve conflicts? Thanks!", "> @lgeiger Can you please resolve conflicts?\r\n\r\nSure, I will resolve the conflicts.\r\n\r\nbf2cda0f8d77cb20df252a48699483366a0e70b7 introduced the conflicts. However the changes have been [reverted](1dc12b09d671606bfdcf59539ab660f3c157846a) and [reapplied](ba5e03c88b82ad0a7a0cefb3b50cb4d71656b636) and [reverted](b1e79c7a4f3231987469e52c8b97d44837599557) and then [reapplied](69565ec4003902794bc94e10ba5fe9469a0b3ae4) again.\r\n@omalleyt12 Are there any major changes or reverts planned soon, or is it save to rebase on top of master?", "@omalleyt12 Can you please assist on above question from @lgeiger . Thanks!\r\n", "@lgeiger Could you please resolve the conflicts? Thanks!", "> @lgeiger Could you please resolve the conflicts? Thanks!\r\n\r\n@gbaned I resolved the conflicts.", "@rchao @omalleyt12 Do you have time to take a look at this?", "@gbaned Any updates on this? It's been 2 months since I opened the PR and a month since I last rebased. I'm happy to close the PR if changes to this code from outside contributors are not welcome but a response would be greatly appreciated.", "@lgeiger sorry for the delay - I'd like to defer to @omalleyt12 for his familiarity with TensorBoard callback.", "I rebased and resolved the conflicts, this should be ready for review again.", "Hi @lgeiger , did you find a workaround to log learning rate in Tensorboard without applying this patch? I'm using the class PiecewiseConstantDecayWithWarmup(\r\n    tf.keras.optimizers.schedules.LearningRateSchedule) from tensorflow team and facing the same problem.\r\n\r\n`learning_rate = learning_rate.PiecewiseConstantDecayWithWarmup(\r\n        batch_size=BATCH_SIZE,\r\n        epoch_size=TRAIN_EXAMPLES,\r\n        warmup_epochs=5,\r\n        boundaries=[30, 60, 80],\r\n        multipliers=[1.0, 0.1, 0.01, 0.001])`\r\n\r\n```\r\n# TODO(b/149030439) - refactor this with\r\n# tf.keras.optimizers.schedules.PiecewiseConstantDecay + WarmupDecaySchedule.\r\nclass PiecewiseConstantDecayWithWarmup(\r\n    tf.keras.optimizers.schedules.LearningRateSchedule):\r\n  \"\"\"Piecewise constant decay with warmup schedule.\"\"\"\r\n\r\n  def __init__(self,\r\n               batch_size: int,\r\n               epoch_size: int,\r\n               warmup_epochs: int,\r\n               boundaries: List[int],\r\n               multipliers: List[float]):\r\n    \"\"\"Piecewise constant decay with warmup.\r\n\r\n    Args:\r\n      batch_size: The training batch size used in the experiment.\r\n      epoch_size: The size of an epoch, or the number of examples in an epoch.\r\n      warmup_epochs: The number of warmup epochs to apply.\r\n      boundaries: The list of floats with strictly increasing entries.\r\n      multipliers: The list of multipliers/learning rates to use for the\r\n        piecewise portion. The length must be 1 less than that of boundaries.\r\n\r\n    \"\"\"\r\n    super(PiecewiseConstantDecayWithWarmup, self).__init__()\r\n    if len(boundaries) != len(multipliers) - 1:\r\n      raise ValueError(\"The length of boundaries must be 1 less than the \"\r\n                       \"length of multipliers\")\r\n\r\n    base_lr_batch_size = 256\r\n    steps_per_epoch = epoch_size // batch_size\r\n\r\n    self._rescaled_lr = BASE_LEARNING_RATE * batch_size / base_lr_batch_size\r\n    self._step_boundaries = [float(steps_per_epoch) * x for x in boundaries]\r\n    self._lr_values = [self._rescaled_lr * m for m in multipliers]\r\n    self._warmup_steps = warmup_epochs * steps_per_epoch\r\n\r\n  def __call__(self, step: int):\r\n    \"\"\"Compute learning rate at given step.\"\"\"\r\n    def warmup_lr():\r\n      return self._rescaled_lr * (\r\n          step / tf.cast(self._warmup_steps, tf.float32))\r\n    def piecewise_lr():\r\n      return tf.compat.v1.train.piecewise_constant(\r\n          tf.cast(step, tf.float32), self._step_boundaries, self._lr_values)\r\n    return tf.cond(step < self._warmup_steps, warmup_lr, piecewise_lr)\r\n\r\n  def get_config(self) -> Mapping[str, Any]:\r\n    return {\r\n        \"rescaled_lr\": self._rescaled_lr,\r\n        \"step_boundaries\": self._step_boundaries,\r\n        \"lr_values\": self._lr_values,\r\n        \"warmup_steps\": self._warmup_steps,\r\n    }\r\n```\r\n", "@rpmunoz I am currently using the following workaround with TF 2.2:\r\n```python\r\nclass TensorBoard(tf.keras.callbacks.TensorBoard):\r\n    def _collect_learning_rate(self, logs):\r\n        logs = logs or {}\r\n        lr_schedule = getattr(self.model.optimizer, \"lr\", None)\r\n        if isinstance(lr_schedule, tf.keras.optimizers.schedules.LearningRateSchedule):\r\n            logs[\"learning_rate\"] = tf.keras.backend.get_value(\r\n                lr_schedule(self.model.optimizer.iterations)\r\n            )\r\n        return logs\r\n\r\n    def _log_metrics(self, logs, prefix, step):\r\n        super()._log_metrics(self._collect_learning_rate(logs), prefix, step)\r\n```\r\n\r\n@gbaned @omalleyt12 is there anything that is blocking this from beeing reviewed?", "@omalleyt12 Can you please review this PR ? Thanks!", "@gbaned It seems like @omalleyt12 is currently busy with other things or doesn't receive GitHub notifications, could you request a review from another member of the TensorFlow team so this PR can move forward?\r\n\r\nIt's been 4 months since the PR was opened which is not a great contributor experience (this is not my only TensorFlow PR that has been awaiting reviews for a long time which makes it even more frustrating). Just to be clear, I understand that keeping up with the amount of PRs is challenging and I am by no means trying to push towards getting the changes accepted, but I would really appreciate a review or an update on the status of this.", "> Sorry about the wait on the review! I think it looks good to me and approving. Thanks for the PR.\r\n\r\n@rchao Thanks for the review \ud83d\udc4d \r\nLooks like CI is failing due to an unrelated error, I rebased since this is probably fixed on master.", "@rchao My rebase invalidated your approval, do you mind approving it again?", "> @rchao My rebase invalidated your approval, do you mind approving it again?\r\n\r\nLooks good. Thanks!"]}, {"number": 37551, "title": "Drop experimental and v2 qualifiers from Strategy experimental_run_v2 method.   - experimental_run_v2 -> run", "body": "PiperOrigin-RevId: 300574367\nChange-Id: I5d82ea5450a4d32aea6d05ed3db4f02b8edb2eea", "comments": []}, {"number": 37550, "title": "Add `--define=no_tensorflow_py_deps=true` to all `bazel build ...:bui\u2026", "body": "\u2026ld_pip_package` statements to trim size of pips", "comments": []}, {"number": 37549, "title": "Update setup.py estimator version", "body": "", "comments": []}, {"number": 37548, "title": "Keras connectivity metadata is not set correctly in TF 2.2.0rc0", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): 2.2.0rc0\r\n- Python version: 3.6.10\r\n- Bazel\r\nversion (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from\r\nsource): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nIf a Keras model is applied to inputs with mismatched (but compatible) shape, the model is applied correctly but none of the Keras connectivity metadata (e.g. `inbound/outbound_nodes` or `keras_history`) is updated.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe Keras connectivity metadata should be updated, so after the model is applied there should be new inbound/outbound nodes for that application, and all the Tensors created by that application should have their keras_history set appropriately (this is the behaviour in TF<=2.1.0).\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n``` python\r\nimport tensorflow as tf\r\n\r\n\r\nfor input_shape in [(1,), (1, 1)]:\r\n    print(\"input_shape\", input_shape)\r\n\r\n    sub_in = tf.keras.Input((1,))\r\n    relu_layer = tf.keras.layers.ReLU()\r\n    sub_out = relu_layer(sub_in)\r\n    submodel = tf.keras.Model(sub_in, sub_out)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 1\r\n\r\n    inp = tf.keras.Input(input_shape)\r\n    out = submodel(inp)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 2\r\n```\r\n\r\nThe `assert len(relu_layer.inbound_nodes) == 2` condition fails when `input_shape=(1, 1)`, indicating that no new inbound nodes were created when `submodel` was applied to `inp`.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe issue is that when this function is applied https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926 it creates new tensors, which do not have a keras_history set. Then this condition evaluates to `False` https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L947, so the `set_connectivity_metadata` function is never called here https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L952.", "comments": ["Was able to replicate the issue with Tf 2.2.rc0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/8b75a84496af15d6c8e7a70fe383c98e/untitled448.ipynb). Thanks!", "I think gist created by @gadagashwini has some problem. \r\nHere is the gist created by @gadagashwini , \r\n```python\r\nimport tensorflow as tf\r\nfor input_shape in [(1,), (1, 1)]:\r\n    print(\"input_shape\", input_shape)\r\n    \r\n    # Code Section 1\r\n    sub_in = tf.keras.Input((1,))\r\n    relu_layer = tf.keras.layers.ReLU()\r\n    sub_out = relu_layer(sub_in)\r\n    submodel = tf.keras.Model(sub_in, sub_out)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 1\r\n\r\n    # Code section 2\r\n    inp = tf.keras.Input(input_shape)\r\n    out = submodel(inp)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 2\r\n```\r\nNow, Take a look at section code 1 & 2. Observe that there is no use of `input_shape` in code section 1. And `relu_layer` is defined in code section 1. So, `len(relu.inbound_nodes)` is independent of the value of `input_shape`. And moreover, in code section 2 assert statement, you are asserting `inbound_nodes` of `relu_layer` which is not even used in `inp` and `out` in code section 2 and is independent of value of `input_shape`.\r\nThat's why it gives assertion error. I have verified the code. Below code works fine.\r\n```python\r\nimport tensorflow as tf\r\nfor input_shape in [(1,), (1, 1)]:\r\n    print(\"input_shape\", input_shape)\r\n    \r\n    # Code Section 1\r\n    sub_in = tf.keras.Input((1,))\r\n    relu_layer = tf.keras.layers.ReLU()\r\n    sub_out = relu_layer(sub_in)\r\n    submodel = tf.keras.Model(sub_in, sub_out)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 1\r\n\r\n    # Code section 2\r\n    inp = tf.keras.Input(input_shape)\r\n    out = relu_layer(inp)\r\n\r\n    assert len(relu_layer.inbound_nodes) == 2\r\n```\r\nI have just added `relu_layer` instead of `submodel` in code section 2. \r\n\r\n@drasmuss , Please give your comments too.", "> Observe that there is no use of input_shape in code section 1. And relu_layer is defined in code section 1. So, len(relu.inbound_nodes) is independent of the value of input_shape. And moreover, in code section 2 assert statement, you are asserting inbound_nodes of relu_layer which is not even used in inp and out in code section 2 and is independent of value of input_shape.\r\n\r\n\"Code section 1\" creates `submodel`, which is used in \"Code section 2\". So effectively all of \"Code section 1\" is being repeated in \"Code section 2\". You can read more about how this works in Keras here https://www.tensorflow.org/guide/keras/functional#all_models_are_callable_just_like_layers.\r\n\r\n> That's why it gives assertion error. I have verified the code. Below code works fine\r\n\r\nYour code avoids the problem, it doesn't solve it (because the root of the issue is in this section https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926, as pointed out above, which is not called if you're not using a submodel). The original example should work if the Keras connectivity were being set correctly, which you can verify by setting the TensorFlow version to any value <2.2.", "@drasmuss We are going to be updating the code to remove metadata from all nested layers going forward. 'inbound_nodes' property on layers has been deprecated as it is an internal implementation detail.", "@pavithrasv Is there an alternate way to determine, given a tensor, what the internal layer was that generated that tensor? I.e., given the code example from above\r\n```\r\n    sub_in = tf.keras.Input((1,))\r\n    relu_layer = tf.keras.layers.ReLU()\r\n    sub_out = relu_layer(sub_in)\r\n    submodel = tf.keras.Model(sub_in, sub_out)\r\n\r\n    inp = tf.keras.Input(input_shape)\r\n    out = submodel(inp)\r\n```\r\nwhen given `out`, I need to be able to retrieve `relu_layer`. The only way I was able to do this previously was by traversing through the metadata, but if that is being removed then I'll need another method.", "@drasmuss What is the use case for this? We do not currently have a method as this is internal implementation detail of functional model construction.", "I need to be able to determine the graph structure of a functional Keras model (i.e. the full graph of which layers are connected to which other layers). And it is a model defined by external users, so I don't have direct access to the model definition, I just have the Keras Model object.", "Can you use `model.layers` to navigate and find the graph of layers in the inner model?", "No, because `model.layers` just tells you which layer objects are in the model, not how they are connected to each other. For example, consider a model like this\r\n```\r\ninp = x = tf.keras.layers.Input(shape=(2,))\r\nmy_layer = tf.keras.layers.Dense(units=2)\r\nx = my_layer(x)\r\nx = my_layer(x)\r\nx = my_layer(x)\r\nmodel = tf.keras.Model(inp, x)\r\n```\r\n`model.layers` just shows one Input layer and one Dense layer. If you want to recreate the structure of that model, you have to look at the Keras connectivity metadata of `my_layer`.", "We do not have any public properties or methods for this today. We have `tensor._keras_history` which will provide that information, but since this is a private property we do not recommend relying on it (similar as `_inbound_nodes`).", "I would love to not rely on private properties, but as you say there is no way to get this information through public properties. So if we want the Keras graph structure (which doesn't seem like a really unusual use case) that's our only option :smile:.\r\n\r\nDo you have a timeline for when you plan on removing this functionality? And are there any plans to provide equivalent information through some other data structure, or will it just be impossible to recover the Keras graph structure at that point?", "I have fixed the original issue. ie. you can use `_keras_history` or `inbound_nodes` to get the information. There are no plans at this time to add properties describing the Keras graph structure.", "@drasmuss this issue has been fixed in the latest tf-nightly and the next TF 2.3.0 release should have it. Please feel free to reopen if it does not work for you. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37548\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37548\">No</a>\n", "Confirmed that this is fixed in TF 2.3.0rc0, thanks!"]}, {"number": 37547, "title": "Remove unused private attributes from TensorBoard callback", "body": "`self._samples_seen`, `self._samples_seen_at_last_write` and `self._current_batch` were used in version 1 of the TensorBoard callback, but are not necessary anymore.\r\nThis PR removes them.", "comments": ["@lgeiger Can you please resolve conflicts? Thanks!", "bf2cda0f8d77cb20df252a48699483366a0e70b7 included these changes so this PR is not relevant anymore."]}, {"number": 37546, "title": "Android model personalization crash with keras model", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  **- no**\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10/Android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: Android Emulator\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): **2.0.0rc0** for generating model and  **org.tensorflow:tensorflow-lite:0.0.0-nightly** on the phone\r\n- Python version: - Bazel\r\nversion (if compiling from source): Anaconda version 3.7\r\n\r\nI'm fiddling with the example of model personalization on Android. It works great with model generated with https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_convert.py but fails to work with model generated with example code given in decription of model_personnalization repo:\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.regularizers import l2\r\nfrom tfltransfer import bases\r\nfrom tfltransfer import heads\r\nfrom tfltransfer import optimizers\r\nfrom tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\r\nbase = bases.MobileNetV2Base(image_size=224)\r\nhead = tf.keras.Sequential([\r\n    layers.Flatten(input_shape=(7, 7, 1280)),\r\n    layers.Dense(\r\n        units=32,\r\n        activation='relu',\r\n        kernel_regularizer=l2(0.01),\r\n        bias_regularizer=l2(0.01)),\r\n    layers.Dense(\r\n        units=4,\r\n        activation='softmax',\r\n        kernel_regularizer=l2(0.01),\r\n        bias_regularizer=l2(0.01)),\r\n])\r\nhead.compile(loss='categorical_crossentropy', optimizer='sgd')\r\nconverter = TFLiteTransferConverter(4,\r\n                                    base,\r\n                                    heads.KerasModelHead(head),\r\n                                    optimizers.SGD(3e-2),\r\n                                    train_batch_size=20)\r\nconverter.convert_and_save('custom_keras_model')\r\n\r\nThe error is:\r\n> A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 22057 (amples.transfer), pid 22057 (amples.transfer)", "comments": ["Steps to reproduce:\r\n1. Take android example of model personalization from https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization/android\r\n2. Change the model in assets to the one created by code provided in model personalization https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization#converting-the-custom-keras-model-using-the-python-api\r\n3. This will trigger the crash.", "@PawelFaron \r\nwe ran the code and face a different error, please refer to [this gist](https://colab.sandbox.google.com/gist/amahendrakar/46ff1ade36232f44cda6fa5fda9e08e7/untitled81.ipynb#scrollTo=16vjeC2sMegq) for the same", "@Saduf2019 You have the tfltransfer in the repo https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization/converter/tfltransfer", "@Saduf2019  To run the example, `python setup.py install` is prerequisite, then your python can recognize tfltransfer.\r\n@PawelFaron, I've tried to run it on my side, but it worked. You mention that you used Android Emulator. Could you specify more details about AVD setup? I could run it on both my Pixel 3a XL and its emulator,", "@@PawelFaron,\r\ncould you please update as per above comment", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37546\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37546\">No</a>\n"]}, {"number": 37545, "title": "tf.tpu.experimental.initialize_tpu_system() throwing error", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock - no\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Debian GNU/Linux 9.11 (stretch) (GNU/Linux 4.9.0-11-amd64 x86_64\\n)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): '2.2.0-dev20200309'\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nHere is the tpu config - it is in europe-west4-a:\r\n\r\n```\r\nacceleratorType: v3-8\r\ncidrBlock: 10.240.1.16/29\r\ncreateTime: '2020-03-09T19:38:19.525484434Z'\r\ndescription: A Cloud TPU created with the ctpu tool.\r\nhealth: HEALTHY\r\nipAddress: 10.240.1.18\r\nname: \r\nnetwork: global/networks/default\r\nnetworkEndpoints:\r\n- ipAddress: 10.240.1.18\r\n  port: 8470\r\nport: '8470'\r\nschedulingConfig: {}\r\nserviceAccount: \r\nstate: READY\r\ntensorflowVersion: nightly\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\n# Detect hardware, return appropriate distribution strategy\r\ntry:\r\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\r\n    print('Running on TPU ', tpu.master())\r\nexcept:\r\n    tpu = None\r\n\r\nif tpu:\r\n    tf.config.experimental_connect_to_cluster(tpu)\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\nelse:\r\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\r\n\r\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\r\n```\r\nresults in:\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-b9f7d4f857ca> in <module>\r\n     10 if tpu:\r\n     11     tf.config.experimental_connect_to_cluster(tpu)\r\n---> 12     tf.tpu.experimental.initialize_tpu_system(tpu)\r\n     13     strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n     14 else:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)\r\n    122 \r\n    123   logging.info(\"Finished initializing TPU system.\")\r\n--> 124   tpu_topology = topology.Topology(serialized=serialized_topology)\r\n    125   _INITIALIZED_TPU_SYSTEMS[tpu_name] = tpu_topology\r\n    126 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/topology.py in __init__(self, serialized, mesh_shape, device_coordinates)\r\n     76 \r\n     77     if serialized:\r\n---> 78       self._parse_topology(serialized)\r\n     79     else:\r\n     80       self._mesh_shape = np.asarray(mesh_shape, dtype=np.int32)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/topology.py in _parse_topology(self, serialized)\r\n    102     if len(self._mesh_shape) != 3 or any(self._mesh_shape < 1):\r\n    103       raise ValueError(\"`mesh_shape` must be a vector of size 3 with positive \"\r\n--> 104                        \"entries; got {}\".format(self._mesh_shape))\r\n    105 \r\n    106     if proto.num_tasks < 0:\r\n\r\nValueError: `mesh_shape` must be a vector of size 3 with positive entries; got [2 2 1 2]\r\n```\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Just had this same problem too.  Updating to the newest nightly build fixed it for me.", "@CalebEverett \r\n\r\nCan you please try with recent Nightly version (`!pip install tf-nightly`) and see if the issue still persists. I am not seeing any issue with recent Nightly version. Thanks!", "Also had the same problem but on the newest nightly build (2.2.0.dev20200313) and the previous nights (2.2.0.dev20200312). Running on Google Colab w/ TPUs.", "Thanks - it's going through now. `pip install tf-nightly --upgrade` to get version 2.2.0-dev20200313 installed and then `gcloud compute tpus reimage <tpu-name> --version nightly` to make sure the latest nightly is on the tpu as well.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37545\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37545\">No</a>\n"]}, {"number": 37544, "title": "Concat op not quantized ", "body": "This issue is related to the concat implementation used for TFlite and TFlite micro.\r\nFor uint8 there are no restrictions on having the same scaling/zeropoint in the Input/Output.\r\n\r\nBut the implementation is not quantized\r\nin concatenation.cc:\r\n// TODO(prabhumk): This is the same as the optimized implementation.\r\n// TODO(prabhumk): The quantized implementation of concatentation isn't fully\r\n// quantized as it takes scale as a floating point value. This should be fixed\r\n// when optimizng this routine further.\r\ninline void ConcatenationWithScaling(const ConcatenationParams& params,\r\n                                     const RuntimeShape* const* input_shapes,\r\n                                     const uint8* const* input_data,\r\n                                     const RuntimeShape& output_shape,\r\n                                     uint8* output_data) {\r\n...\r\n      if (input_zeropoint[i] == output_zeropoint &&\r\n          input_scale[i] == output_scale) {\r\n        memcpy(output_ptr, input_ptr, copy_size);\r\n      } else {\r\n        const float scale = input_scale[i] * inverse_output_scale;\r\n        const float bias = -input_zeropoint[i] * scale;\r\n        for (int j = 0; j < copy_size; ++j) {\r\n          const int32_t value =\r\n              static_cast<int32_t>(std::round(input_ptr[j] * scale + bias)) +\r\n              output_zeropoint;\r\n          output_ptr[j] = static_cast<uint8_t>(\r\n              std::max<int32_t>(std::min<int32_t>(255, value), 0));\r\n        }\r\n      }\r\n\r\n**Standalone code to reproduce the issue** \r\nI have attached a tflite file that includes a concat op with different scaling/zeropoint in the Input/Output.\r\n\r\n[concat_1x1x1x2048_requantize_6.zip](https://github.com/tensorflow/tensorflow/files/4325464/concat_1x1x1x2048_requantize_6.zip)\r\n\r\n\r\n", "comments": ["This is a known issue with the uint8 kernel. The int8 version of this op (the tflite recommend official quantized kernel) does not have the rescale in the op, and is purely integer. \r\n\r\nWhat is your use case where the rescaling concatenation is causing an issue with the uint8 kernel. (note we are working on making all conversion of quantization-aware-training also output only the int8 kernels, so that may resolve your issue).", "I changed the op spec of concat, so the uint8 scheme doesn't require same input/ouput scales anymore. Please check it again.", "I'm wondering how to keep the same scaling/zeropoint in the Input/Output for int8.", "@ppatrikg It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.4.1 or 2.5 and let us know if the issue still persists? Thanks!", "I'm still getting the same issue with v2.6.0-rc1.", "I see it, too. On tfnightly==2.8.0-dev20211001\r\n", "@yisongsong \r\n\r\n>I'm wondering how to keep the same scaling/zeropoint in the Input/Output for int8.\r\n\r\nHave you got the solution?", "> @yisongsong\r\n> \r\n> > I'm wondering how to keep the same scaling/zeropoint in the Input/Output for int8.\r\n> \r\n> Have you got the solution?\r\n\r\nYou can refer to this [link](https://github.com/tensorflow/tensorflow/blob/d65ffd105c438ab6693e84243c6ab7b849bb3af8/tensorflow/lite/tools/optimize/quantize_model_test.cc#L425). It will check min/max for all inputs, and insert Quantize node for some inputs or all. \r\n```\r\n// There are two inputs for concat, \"input0\" and \"input1\". \"input0\" has [0, 5]\r\n// as min/max and \"input1\" has [0, 10] as min/max. The output \"output\" for\r\n// concat has [0, 10] as min/max.\r\n// After applyging QuantizeModel(), \"input0\" will have a requant op added, along\r\n// with a tensor \"input0_reqaunt\" that has [0, 10] as min/max. So the topology\r\n// becomes:\r\n// input0 -> requant -> input0_requant \\\r\n//                                       concat - output\r\n//                              input1 /\r\n```\r\n\r\nAlso, tflite provide `HardcodeMinMaxForConcatenation()` to change min/max.\r\n```\r\n# Usage for this flag is --change_concat_input_ranges=true or\r\n# --change_concat_input_ranges=false in order to make it clear what the flag\r\n# is set to. This keeps the usage consistent with other usages of the flag\r\n# where the default is different. The default value here is False.\r\nparser.add_argument(\r\n\"--change_concat_input_ranges\",\r\ntype=str.upper,\r\nchoices=[\"TRUE\", \"FALSE\"],\r\nhelp=(\"Boolean to change behavior of min/max ranges for inputs and \"\r\n     \"outputs of the concat operator for quantized models. Changes the \"\r\n     \"ranges of concat operator overlap when true. (default False)\"))\r\n```\r\n", "Hi @ppatrikg! \r\nWe are checking to see whether you still need help in this issue . Did above [comment](https://github.com/tensorflow/tensorflow/issues/37544#issuecomment-971326816) work for you?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37544\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37544\">No</a>\n"]}, {"number": 37543, "title": "\"Another profiler is running\" in TF 2.2.0rc0", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): 2.2.0rc0\r\n- Python version: 3.6.10\r\n- Bazel\r\nversion (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from\r\nsource): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\n\"Another profiler is running\" error when using the TensorBoard callback profiling twice with `profile_batch=1` in non-eager mode.\r\n\r\n**Describe the expected behavior**\r\n\r\nThere should be no error.\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\ninp = tf.keras.Input((1,))\r\nout = tf.keras.layers.Dense(units=1)(inp)\r\nmodel = tf.keras.Model(inp, out)\r\n\r\nmodel.compile(optimizer=tf.optimizers.SGD(1), loss=tf.losses.mse)\r\n\r\nmodel.fit(\r\n    np.zeros((64, 1)),\r\n    np.zeros((64, 1)),\r\n    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=\"tmp\", profile_batch=1)],\r\n)\r\n\r\nmodel.fit(\r\n    np.zeros((64, 1)),\r\n    np.zeros((64, 1)),\r\n    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=\"tmp\", profile_batch=1)],\r\n)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nTraceback (most recent call last):\r\n  File \".../tmp.py\", line 21, in <module>\r\n    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=\"tmp\", profile_batch=1)],\r\n  File \"...\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1736, in __init__\r\n    profiler.warmup()  # Improve the profiling accuracy.\r\n  File \"...\\lib\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py\", line 124, in warmup\r\n    start('')\r\n  File \"...\\lib\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py\", line 74, in start\r\n    'Another profiler is running.')\r\ntensorflow.python.framework.errors_impl.AlreadyExistsError: Another profiler is running.\r\n```", "comments": ["I could replicate the issue with TF 2.2.rc0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/2c9946a562d22127690069c4013da8bc/untitled449.ipynb). Thanks!", "Looks like the issue here is that the profiling in the first model.fit() is still active while the profiling in the second model.fit() tries to start profiling. This shouldn't happen if the first model.fit() is done. Let me look into it in more details.", "The problem is this block here https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/callbacks.py#L1950, which starts the profiler regardless of whether eager mode is enabled or not, but then the profiler is only stopped if eager mode is enabled https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/callbacks.py#L1980.", "The fix is now included in tf-nightly.\r\n\r\nCherrypick request sent out:\r\nhttps://github.com/tensorflow/tensorflow/pull/37599", "#37599  has been merged into the r2.2 branch, this fix should be available in the next rc candidate. \r\n", "@drasmuss Can you try again and see if the error is fixed? Thanks!", "Yes this is fixed in TF2.2rc2", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37543\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37543\">No</a>\n", "Still facing the issue", "Still facing the issue. ", "@omya3, @jdserranomu could you clarify the version of TensorFlow where you are seeing the issue?", "The version I am running is 2.4.0. ", "Issue still 2.4.1.\r\n\r\n![image](https://user-images.githubusercontent.com/4510984/108051235-9ce2c280-7085-11eb-8f39-1ae24001482d.png)\r\n", "Still facing the issue in tf-nightly", "Can you try with the new nightly? The following commit makes the callback resilient to concurrent profiling:\r\nhttps://github.com/tensorflow/tensorflow/commit/53ff2339b3c05a6efbe5bdbdd6c40b8973fb8e17", "Friendly ping @drasmuss ", "What are you looking for from me?", "My bad, wrong ping. @omya3 ", "@yisitu  Just update the callbacks for the second fit, issue goes away", "The issue seems to be resolved in Tf Nightly 2.6.0-dev20210525, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/ed6bdbd914579557e7c3380656081887/untitled7.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37543\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37543\">No</a>\n", "when I used Tensorflow-GPU2.4.1, faced same error.\r\nThen I changed to 2.6.0, faced another error.\r\n*training code starts, but NaN occurs during training.\r\nhttps://github.com/matterport/Mask_RCNN/issues/2670\r\n![Untitled](https://user-images.githubusercontent.com/56009331/130339683-2d8b6433-8d3c-495b-957a-8c338c42ec0d.png)\r\n\r\n\r\nNow I using TensorFlow-GPU2.5.0, there aren't error!!!\r\nfollowing below, my environment.\r\n\r\n\r\nwindows 11 Pro (dev)\r\nPython 3.7.7\r\nNVIDIA GeForce RTX3090\r\nTensorFlow-GPU 2.5.0\r\ncuDNN 8.2.2 forCUDA11.4\r\nCUDA Toolkit 11.4.0\r\n", "After I realized such undocumented and crypted errors, I made a transition\nto another framework\n\nOn 22 Aug 2021 Sun at 05:20 nomurakeiya ***@***.***> wrote:\n\n> when I used Tensorflow-GPU2.4.1, faced same error.\n> Then I changed to 2.6.0, faced another error.\n> *training code starts, but NaN occurs during training.\n> matterport/Mask_RCNN#2670\n> <https://github.com/matterport/Mask_RCNN/issues/2670>\n> [image: Untitled]\n> <https://user-images.githubusercontent.com/56009331/130339683-2d8b6433-8d3c-495b-957a-8c338c42ec0d.png>\n>\n> Now I using TensorFlow-GPU2.5.0, there aren't error!!!\n> following below, my environment.\n>\n> windows 11 Pro (dev)\n> Python 3.7.7\n> NVIDIA GeForce RTX3090\n> TensorFlow-GPU 2.5.0\n> cuDNN 8.2.2 forCUDA11.4\n> CUDA Toolkit 11.4.0\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37543#issuecomment-903203140>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABNUVOMQBSWNQGDM7E3S6KLT6BNHZANCNFSM4LGP73JA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n", "@ckluk FYI"]}, {"number": 37542, "title": "TFLite Inference Run on Android Issues", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\n Hello I'm new on TFlite in Android. I've got issue when i wanna run my inference. i got problem in data types i don't know actually it does. My output model suppose to be array float but i still got that errors please help me!! Thankyou...\r\n\r\n### Errors\r\n![image](https://user-images.githubusercontent.com/36231029/76542439-8d431d00-64b7-11ea-8ee7-dcbba4324ece.png)\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.katadasartflite, PID: 17681\r\n    java.lang.IllegalArgumentException: DataType error: cannot resolve DataType of kotlin.Unit\r\n        at org.tensorflow.lite.Tensor.dataTypeOf(Tensor.java:319)\r\n        at org.tensorflow.lite.Tensor.throwIfTypeIsIncompatible(Tensor.java:377)\r\n        at org.tensorflow.lite.Tensor.getInputShapeIfDifferent(Tensor.java:282)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:137)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)\r\n        at org.tensorflow.lite.Interpreter.run(Interpreter.java:275)\r\n        at com.example.katadasartflite.Classifier.recognizeWord(Classifier.kt:80)\r\n        at com.example.katadasartflite.InferenceModel$initClassifier$1.onClick(InputFragment.kt:51)\r\n        at android.view.View.performClick(View.java:7352)\r\n        at android.widget.TextView.performClick(TextView.java:14177)\r\n        at android.view.View.performClickInternal(View.java:7318)\r\n        at android.view.View.access$3200(View.java:846)\r\n        at android.view.View$PerformClick.run(View.java:27800)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:214)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7050)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:965)\r\nW/System: A resource failed to call close. \r\n\r\n\r\n\r\n### Source code / logs\r\n    fun recognizeWord() {\r\n        Log.d(\"RecognizeWord\",Arrays.toString(tflite.getInputTensor(0).shape()))\r\n        val input = TensorBuffer.createFixedSize(intArrayOf(1,13,4),DataType.FLOAT32).loadArray(inputData)\r\n        Trace.beginSection(\"Start Recogize\")\r\n        var outputInference = TensorBuffer.createDynamic(DataType.FLOAT32)\r\n        Trace.beginSection(\"Feed\")\r\n        val startTimeForLoadImage = SystemClock.uptimeMillis()\r\n        tflite.run(input,outputInference.intArray)\r\n        val endTimeForReference = SystemClock.uptimeMillis()\r\n        Trace.endSection()\r\n\r\n        Log.d(\"RecognizeWord\",outputInference.toString())\r\n\r\n    }\r\n\r\n", "comments": ["I know nothing about Kotlin, but according to the error message you showed, it seems the problem is that you feed `intArray` to input but set its data type to `DataType.FLOAT32`\r\n```\r\n    val input = TensorBuffer.createFixedSize(intArrayOf(1,13,4),DataType.FLOAT32).loadArray(inputData)\r\n```", "@ramawidrap \r\nplease share the tensorflow version used and simple stand alone code for us to replicate the issue faced.\r\nAlso please refer to [link1](https://github.com/tensorflow/tensorflow/issues/34992) and [link2](https://github.com/tensorflow/tensorflow/issues/36059), if it helps resolve your issue.", "hey i think i solve this issue but i face another issue.\r\ni got new error like this \r\n![image](https://user-images.githubusercontent.com/36231029/76626348-97265800-656b-11ea-80af-b2c150e677d8.png)\r\n\r\ni assume that my input has shape 3d (1,13,4) but i feed input with 1d array. how come i can use 3d floatarray in kotlin ? i dont know this gonna solve my problem. \r\n\r\nanyone know why that error occurred ? ", "@ramawidrap \r\nFor information on using 3d array in kotlin please refer to : [link1](http://zetcode.com/kotlin/arrays/)\r\n[link2](https://stackoverflow.com/questions/42337003/multidimensional-3d-matrix-in-kotlin), [link3](https://www.ict.social/kotlin/basics/multidimensional-arrays-in-kotlin)\r\n\r\nfor the error faced please refer to similar issues [issue1](https://github.com/tensorflow/tensorflow/issues/24730)\r\n[issue2](https://github.com/tensorflow/tensorflow/issues/30187)\r\n[issue3](https://stackoverflow.com/questions/55794151/unexpected-failure-when-preparing-tensor-allocations)\r\n\r\nCould you please update as per this [comment](https://github.com/tensorflow/tensorflow/issues/37542#issuecomment-598609920)", "@ramawidrap\r\nplease update on the above comment", "hey thankyou i solved this issuee using3d array and i can run on the CPU. but when i ran on the GPU it become error. my mmodel was LSTM Bidirectional trained using keras", "@ramawidrap \r\nplease confirm if we may proceed to move this issue to closed status as it is resolved, also please share the tensorflow version used.", "@ramawidrap\r\nplease update as per above comment"]}, {"number": 37541, "title": "load_model(filename) fails on weight ordering if sublayer .trainable is modified after init", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS, Darwin-19.3.0-x86_64-i386-64bit, mac version: ('10.15.3', ('', '', ''), 'x86_64')\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-26991-g5a6ae102f0 2.2.0-dev20200311\r\n- Python version: 3.7.6\r\n\r\n**Describe the current behavior**\r\n\r\nCreating a layer and then setting `layer.trainable = False` (after creation) and then creating a model using that layer and saving that model with `model.save(filename)`, and then loading that model with `tf.keras.models.load_model(filename, custom_objects=...)`, fails because weights ordering for the layer is inconsistent.\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect to be able to load a model I saved, despite having changed the `trainable` attribute on some layer before compiling and saving. (The `trainable` attribute is documented, with no warning that it must not be mutated, nor is there any runtime warning about this.)\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n\r\nclass LayerWithSublayers(keras.layers.Layer):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.embedding = keras.layers.Embedding(3, 2)\r\n        self.dense = keras.layers.Dense(4)\r\n\r\n    def call(self, inputs, **kwargs):\r\n        return self.dense(self.embedding(inputs))\r\n\r\n\r\ninput_ids = keras.Input(shape=(4,), dtype=tf.int32, name='input_ids')\r\noutput_layer = LayerWithSublayers()\r\noutput_layer.embedding.trainable = False\r\noutput = output_layer(input_ids)\r\n\r\nmodel = keras.Model(inputs=[input_ids], outputs=[output])\r\nmodel.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\r\n\r\nmodel_file_name = 'foo.h5'\r\nmodel.save(filepath=model_file_name)\r\n\r\nloaded_model = keras.models.load_model(model_file_name, custom_objects={'LayerWithSublayers': LayerWithSublayers})\r\n```\r\n\r\nIf I change this to pass `trainable=False` when creating the `keras.layers.Embedding`, then the model loads just fine. So the problem is that the change of `trainable` is not reflected when the model is serialized to HDF5 format.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nRunning the above script outputs this traceback:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"keras_save_load_h5_nontrainable.py\", line 26, in <module>\r\n    loaded_model = keras.models.load_model(model_file_name, custom_objects={'LayerWithSublayers': LayerWithSublayers})\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 184, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 173, in load_model_from_hdf5\r\n    load_weights_from_hdf5_group(f['model_weights'], model.layers)\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 704, in load_weights_from_hdf5_group\r\n    K.batch_set_value(weight_value_tuples)\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 3402, in batch_set_value\r\n    x.assign(np.asarray(value, dtype=dtype(x)))\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 842, in assign\r\n    self._shape.assert_is_compatible_with(value_tensor.shape)\r\n  File \"/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 1117, in assert_is_compatible_with\r\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nValueError: Shapes (3, 2) and (2, 4) are incompatible\r\n```", "comments": ["when you are passing `trainable = True ` its works fine with `.h5` and when I am changing `.h5` with `.tf` it also load model with `trainable = False` but model loaded is with `trainable = True`\r\n\r\n```python\r\n import tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n\r\nclass LayerWithSublayers(keras.layers.Layer):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.embedding = keras.layers.Embedding(3, 2)\r\n        self.dense = keras.layers.Dense(4)\r\n\r\n    def call(self, inputs, **kwargs):\r\n        return self.dense(self.embedding(inputs))\r\n\r\n\r\ninput_ids = keras.Input(shape=(4,), dtype=tf.int32, name='input_ids')\r\noutput_layer = LayerWithSublayers()\r\noutput_layer.embedding.trainable = False\r\noutput = output_layer(input_ids)\r\n\r\nmodel = keras.Model(inputs=[input_ids], outputs=[output])\r\nmodel.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\r\n\r\nmodel_file_name = 'foo.tf'\r\n\r\nmodel.save(filepath=model_file_name)\r\n\r\nloaded_model = keras.models.load_model(model_file_name, custom_objects={'LayerWithSublayers': LayerWithSublayers})\r\n```\r\nOutput : \r\n\r\n> Total params: 18\r\nTrainable params: 18\r\nNon-trainable params: 0\r\n\r\nbut in actual with trainable = False model summary be like : \r\n\r\n> Total params: 18\r\nTrainable params: 12\r\nNon-trainable params: 6", "@gthb \r\nI tried to reproduce the issue in colab with TF nightly version.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/dcc1aa41b6575cee41691418d02d3d90/untitled728.ipynb).Is this the expected behavior? Thanks!", "@ravikyram Thanks for checking it, but when I save mode as `.tf `instead of `.h5` I am able to load mode with `trainabe =False` but loaded model has params same as with `trainable = True. So is model always loaded with trainable = True ?", "@ravikyram \r\n\r\n> I tried to reproduce the issue in colab with TF nightly version.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/dcc1aa41b6575cee41691418d02d3d90/untitled728.ipynb).Is this the expected behavior? Thanks!\r\n\r\nThis is the behavior I'm reporting as a bug \u2014 specifically the result in [this cell](https://colab.research.google.com/gist/ravikyram/dcc1aa41b6575cee41691418d02d3d90/untitled728.ipynb#scrollTo=3hk5lvUWNydJ&line=1&uniqifier=1), `ValueError: Shapes (3, 2) and (2, 4) are incompatible`. This is caused by trying to assign a value to the wrong variable. That in turn is because the variables are assigned in a single batch operation with the assumption that their order matches the order of variable values in the serialized file, and that assumption is undoubtedly failing because variables are ordered trainable first, then untrainable, and the `trainable` information is not correctly recorded in the serialized file if the `.trainable` attribute is assigned after layer creation.", "The expected behavior is for the serialized file to get deserialized correctly on `load_model`, yielding a model identical to the one I saved.\r\n\r\n(Or alternatively, for the `.trainable` attribute to be a read-only property, or output a warning when assigned to, or at least be documented as not safe to assign to.)", "Restoring the trainable value can be tricky.\r\n\r\nSay that `LayerWithSublayers` defines the trainable status of the embedding layer in the class definition, and is saved with the `embedding.trainable` set to True:\r\n\r\n```\r\nclass LayerWithSublayers(keras.layers.Layer):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.embedding = keras.layers.Embedding(3, 2)\r\n        self.embedding.trainable = True\r\n```\r\nThen the definition of the class is changed so that `embedding.trainable` is False:\r\n\r\n```\r\nclass LayerWithSublayers(keras.layers.Layer):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.embedding = keras.layers.Embedding(3, 2)\r\n        self.embedding.trainable = False\r\n```\r\n\r\nWhen loading the model with the new definition, should the embedding layer retain it's original trainable status, or should it use the trainable status set in the `LayerWithSublayers` class? \r\n\r\nThe current behavior is that we will load whatever is returned by  the layer's `get_config`/`from_config` (i.e. the latter of the two options). If you want LayerWithSublayers to retain the trainable status of one of its internal layers, then consider adding that to the layer's `get_config` method.\r\n\r\ne.g.\r\n```\r\nclass LayerWithSublayers(keras.layers.Layer):\r\n    def __init__(self, train_embeddings=True, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.embedding = keras.layers.Embedding(3, 2)\r\n        self.embedding.trainable = train_embeddings\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config['train_embeddings'] = self.embedding.trainable\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37541\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37541\">No</a>\n", "> Restoring the trainable value can be tricky.\r\n\r\nSure, but that's missing the point. Deserialization doesn't just fail to restore the trainable attribute, it fails _completely_, if the trainable attribute has been changed. This is because the ordering of weights _depends on_ the trainable attribute, and the serialization/deserialization _assumes_ that the ordering is unchanged.\r\n\r\n> If you want LayerWithSublayers to retain the trainable status of one of its internal layers, then consider adding that to the layer's get_config method.\r\n\r\nSure, I can do that for my own use case, but the point remains that setting `trainable` to `False` after initialization quietly causes serialization to write output which then will fail to deserialize. This violates [POLA](https://en.wikipedia.org/wiki/Principle_of_least_astonishment), and causes wasted time as people run long training runs and then can't use the result.\r\n\r\nTo avoid that, `trainable` should be a read-only property rather than an attribute \u2014 or at the very least should be clearly documented as not safe to mutate after initialization.", "A workaround (for someone who knows about this gotcha) is to set the `.trainable` attribute of all layers back to `True` before serializing. That's tested and working in my use case."]}, {"number": 37540, "title": "problem load saved model using tensorflow java ", "body": "Hello,\r\n\r\nI was using keras to build a simple MLP model, and want to use it for online prediction. Our online system is written in java, so I want to use tensorflow-java lib to load the model in savedmodel format. I saved the keras model using following scripts:\r\n`  model = tf.keras.models.load_model(path)\r\n  tf.saved_model.save(model, 'savedmodel/v1')\r\n`\r\n\r\nand write some simple test code to check all the opration nodes:\r\n`   SavedModelBundle b = SavedModelBundle.load(\"/Users/jaydone/v1\", \"serve\");\r\n    Iterator<Operation> ops = b.graph().operations();\r\n    Session sess = b.session();\r\n    List<String> opNames = new ArrayList<>();\r\n    while (ops.hasNext()) {\r\n      Operation next = ops.next();\r\n      System.out.println(next.name());\r\n    }`\r\n\r\nafter running the code above, I get the output \r\nembedding_1/embeddings\r\nembedding_1/embeddings/Read/ReadVariableOp\r\ndense_1/kernel\r\ndense_1/kernel/Read/ReadVariableOp\r\ndense_1/bias\r\ndense_1/bias/Read/ReadVariableOp\r\ndense_2/kernel\r\ndense_2/kernel/Read/ReadVariableOp\r\ndense_2/bias\r\ndense_2/bias/Read/ReadVariableOp\r\nrelevance_output/kernel\r\nrelevance_output/kernel/Read/ReadVariableOp\r\nrelevance_output/bias\r\nrelevance_output/bias/Read/ReadVariableOp\r\ntraining/SGD/iter\r\ntraining/SGD/iter/Read/ReadVariableOp\r\ntraining/SGD/decay\r\ntraining/SGD/decay/Read/ReadVariableOp\r\ntraining/SGD/learning_rate\r\ntraining/SGD/learning_rate/Read/ReadVariableOp\r\ntraining/SGD/momentum\r\ntraining/SGD/momentum/Read/ReadVariableOp\r\ntotal\r\ntotal/Read/ReadVariableOp\r\ncount\r\ncount/Read/ReadVariableOp\r\nNoOp\r\nConst\r\nserving_default_albumid_embedding\r\nserving_default_dense_input\r\nserving_default_userid_embedding\r\nStatefulPartitionedCall\r\nsaver_filename\r\nStatefulPartitionedCall_1\r\nStatefulPartitionedCall_2\r\n\r\nnone of them seems to be the output node. \r\n\r\nSo how can I identify the output node, maybe I should add some parameters to specify it when saving the model like this ? \r\n`  tf.saved_model.save(model, 'savedmodel/v1', output=['relevance_output'])\r\n`\r\nCan anyone help me, thanks very much. \r\n\r\n", "comments": ["Hey @jaydone78  `model = tf.keras.models.load_model(path)` is used for loading model which is saved using `tf.keras.models.save_model` refer [this](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) for loading model and [this](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model) for saving.\r\n\r\nOr you can just do as for saving and loading model :\r\n\r\n`model.save(\"model.h5\")`\r\n`New_Model` = tf.keras.models.load_model(\"model.h5\")\r\n`New_Model.summary()`", "> Hey @jaydone78 `model = tf.keras.models.load_model(path)` is used for loading model which is saved using `tf.keras.models.save_model` refer [this](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) for loading model and [this](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model) for saving.\r\n> \r\n> Or you can just do as for saving and loading model :\r\n> \r\n> `model.save(\"model.h5\")`\r\n> `New_Model` = tf.keras.models.load_model(\"model.h5\")\r\n> `New_Model.summary()`\r\nI want to use the model in 'saved_model' format, which can be used in c++, java. \r\n", "Can you please provide code for model also which you are saving ?", "I finally use following command \r\n`saved_model_cli show --dir v1 --tag_set serve --signature_def serving_default `\r\n\r\nand get the input, output node name like this:\r\n\r\n`The given SavedModel SignatureDef contains the following input(s):\r\n  inputs['albumid_embedding'] tensor_info:\r\n      dtype: DT_INT32\r\n      shape: (-1, 1)\r\n      name: serving_default_albumid_embedding:0\r\n  inputs['dense_input'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 10)\r\n      name: serving_default_dense_input:0\r\n  inputs['userid_embedding'] tensor_info:\r\n      dtype: DT_INT32\r\n      shape: (-1, 7)\r\n      name: serving_default_userid_embedding:0\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs['relevance_output'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 1)\r\n      name: StatefulPartitionedCall:0\r\nMethod name is: tensorflow/serving/predict`\r\nproblem solved.\r\n"]}, {"number": 37539, "title": "Corrected order of parameters in keras WideDeepModel", "body": "Fixes #37239 .\r\n@MarkDaoust , @mihaimaruseac  - Please review this PR.", "comments": []}, {"number": 37538, "title": "Added doc and examples for tf.keras.losses.get", "body": "Fixes #37240. \r\n@k-w-w , @mihaimaruseac - Please review this one.", "comments": ["@mihaimaruseac , Please approve it again. Added empty lines wherever needed.", "@mihaimaruseac and @k-w-w , Very sorry. Resolved doctest", "@mihaimaruseac , Changed class type as per your comments. Please run ci. Let's see if it works, if it's  not, then I will think about better way to write these examples."]}, {"number": 37537, "title": "Why the loss doesn't decrease in my CNN model?", "body": "Hi All,\r\nI am new to tensorflow, and I find the losses doesn't decrease when train a CNN model on Cifar100 dataset.\r\n\r\nHere is the Model code:\r\n\r\n```python\r\nnetwork = Sequential([\r\n    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu), # 32x32\r\n    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 16x16\r\n\r\n    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 8x8\r\n\r\n    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 4x4\r\n\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 2x2\r\n\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 1x1\r\n\r\n    layers.Flatten(),\r\n\r\n    layers.Dense(256, activation=tf.nn.relu),\r\n    layers.Dense(128, activation=tf.nn.relu),\r\n    layers.Dense(100, activation=None),\r\n])\r\n```\r\n\r\nand this is the link for the entire code: https://colab.research.google.com/drive/1kIT_18Z-ymEgzqgG4nh4sZdBkA1bnJdO\r\n\r\nand, It will be OK if I use only one Conv2D layer with maxpooling, like this:\r\n\r\n```python\r\nnetwork = Sequential([\r\n    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu), # 32x32\r\n    layers.MaxPooling2D((2, 2)), # 16x16\r\n\r\n    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 8x8\r\n\r\n    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 4x4\r\n\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 2x2\r\n\r\n    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    layers.MaxPooling2D((2, 2)), # 1x1\r\n\r\n   #xxxxx\r\n])\r\n```\r\n\r\nthanks~", "comments": ["@lihongxun945  You are not defining your last layer properly like you set `activation = None` replace it with `activation = \"softmax\"`  ", "@Eshan-Agarwal  Define the last layer property as activation='softmax' will not work, I have tried.", "@lihongxun945  try some things like change your optimizer to sgd with momentum or make a big network as cifar-100 is very huge data. Please have a look I train DenseNets on CIFAR-10 dataset\r\n[here](https://github.com/Eshan-Agarwal/DenseNet-on-CIFAR-10-/blob/master/CNN%20on%20CIFAR.ipynb) also keep activation = softmax in last layer", "@lihongxun945  You can try dropout layer, you need not change the Adam optimizer, rather try using a bigger network from scratch or use Transfer learning { will share an example real soon}. Finally in last layer Dense(<no of classes>, softmax) is perfect. The decision of the combination of layers is a topic of great research. The accuracy of your model touched 58.8 %, which isn't really impressive, try making a deeper network.", "Yes forgot to mention dropouts really worked much better.", "@lihongxun945,\r\nI feel two things are missing in your code:\r\n\r\n1. Input_Shape is missing in the First Layer. That is Mandatory. Please refer this Conv2D [Input Shape Link](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D#input_shape_2) for more info about it.\r\n2. As pointed by @Eshan-Agarwal, you should use \"Softmax\" activation function instead of \"None\".\r\n\r\nPlease refer this [Stack Overflow Answer](https://stackoverflow.com/questions/57061266/how-to-improve-my-cnn-high-and-constant-validation-error/59172613#59172613) which elaborates on how to decrease the loss in case if it performs well on Training Data and doesn't perform well on Testing Data (Overfitting).\r\n\r\nPlease let me know how it goes. Thanks!", "@rmothukuru yes use of early stopping helps alot which stop model to learn too much ie, prevent from overfiting. I also get better result on CIFAR -10 data set using DenseNets with early stopping, got arround 90% accuracy on test data. In above mentioned link", "@rmothukuru  Thanks~\r\nFor your two points:\r\n1. The input shape is defined after the model definition, you can see `network.build(input_shape=[None, 32, 32, 3])` in the entire code here https://colab.research.google.com/drive/1kIT_18Z-ymEgzqgG4nh4sZdBkA1bnJdO\r\n2. I have tried add a 'softmax' layer but it donesn't make any change.", "Thanks  very much @Ankuraxz and @Eshan-Agarwal , I am a beginner of TF, and don't know how to use dropout right now. But I will try it when complete my online course.", "@lihongxun945   Its very simple just use as this `layers.Dropout(rate)` , rate means how many neurons you want to be connected its in between 0 to 1, 1 means all neurons is connected it is same as with no dropouts. You can read about them [here](https://keras.io/layers/core/), and define your dropout layes just as you defining pooling layer.", "@lihongxun945,\r\nPlease refer this [Stack Overflow Answer](https://stackoverflow.com/questions/57061266/how-to-improve-my-cnn-high-and-constant-validation-error/59172613#59172613) which elaborates on how to decrease the loss and improve your accuracy, and also shows how to use the functions like Dropout, Early Stopping, Regularization, Image Data Generator, etc..", "Just add <layers.Dropout(0.5)>    0.5 is working great on your project", "@lihongxun945  You can try dropout layer, you need not change the Adam optimizer, rather try using a bigger network from scratch or use Transfer learning { will share an example real soon}. Finally in last layer Dense(<no of classes>, softmax) is perfect. The decision of the combination of layers is a topic of great research. The accuracy of your model touched 58.8 %, which isn't really impressive, try making a deeper network.", "@lihongxun945,\r\nCan you please confirm if your issue is resolved. Thanks! ", "Yes please let us know, If Transfer Learning on Cifar 100 was of any use", "@rmothukuru  Already reolved, after I changed the model structure\u3002 Thanks you guys~"]}, {"number": 37536, "title": "How to use ApplyAdam(C++API)?", "body": "Hi, I has used C++ API, but I got some problem about ApplyAdam:\r\n  ApplyAdam(const ::tensorflow::Scope& scope, ::tensorflow::Input var,\r\n          ::tensorflow::Input m, ::tensorflow::Input v, ::tensorflow::Input\r\n          beta1_power, ::tensorflow::Input beta2_power, ::tensorflow::Input lr,\r\n          ::tensorflow::Input beta1, ::tensorflow::Input beta2,\r\n          ::tensorflow::Input epsilon, ::tensorflow::Input grad);\r\n\r\nI do not know beta1_power and beta2_power in adam optimizer.", "comments": ["@minjac \r\nCould you please share a simple standalone code to replicate the issue faced by you in our local,along with the tensor flow version.", "> \r\n> \r\n> @minjac\r\n> Could you please share a simple standalone code to replicate the issue faced by you in our local,along with the tensor flow version.\r\n\r\nHi, code doesn't matter in this case, because I just don't know what the beta1_power and beta2_power mean. \r\n\r\n`/// Update '*var' according to the Adam algorithm.\r\n\r\n/// $$lr_t := \\text{learning\\_rate} * \\sqrt{1 - beta_2^t} / (1 - beta_1^t)$$\r\n\r\n/// $$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$\r\n\r\n/// $$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$\r\n\r\n/// $$variable := variable - lr_t * m_t / (\\sqrt{v_t} + \\epsilon)$$\r\n\r\n/// Arguments:\r\n\r\n/// * scope: A Scope object\r\n\r\n/// * var: Should be from a Variable().\r\n\r\n/// * m: Should be from a Variable().\r\n\r\n/// * v: Should be from a Variable().\r\n\r\n/// * beta1_power: Must be a scalar.\r\n\r\n/// * beta2_power: Must be a scalar.\r\n\r\n/// * lr: Scaling factor. Must be a scalar.\r\n\r\n/// * beta1: Momentum factor. Must be a scalar.\r\n\r\n/// * beta2: Momentum factor. Must be a scalar.\r\n\r\n/// * epsilon: Ridge term. Must be a scalar.\r\n\r\n/// * grad: The gradient.`\r\n\r\nAs the comments says, I know all the arguments mean except the beta1_power and beta2_power, because I don't find where the beta1_power and beta2_power are in Adam Optimizer's formula.", "@minjac \r\ncan you please refer to [this link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=nightly) and let us know if it helps", "> \r\n> \r\n> @minjac\r\n> can you please refer to [this link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=nightly) and let us know if it helps\r\n\r\nThanks for your help, but I cannot find some arguments as same as beta1_power or beta2_power in this API.\r\n", "@minjac \r\nhere is some info on the variables,with reference to your question \"Hi, code doesn't matter in this case, because I just don't know what the beta1_power and beta2_power mean.\"\r\n\r\nThe beta-variables are variables used by the AdamOptimizer that need to be initialized similarily to your other variables. You can either initialize them with the tf.global_variables_initializer() after creating the optimizer, or look up the variables and initialize them directly with tf.variables_initializer().\r\n\r\nhere are few links related to them [link1](https://stackoverflow.com/questions/45498342/tensorflow-adamoptimizer-beta1-power-not-initialized) [link2](https://www.tensorflow.org/api_docs/python/tf/raw_ops/ResourceApplyAdamWithAmsgrad)\r\n\r\nplease let us know if this helps.", "@minjac\r\nplease update on the above comment", "> \r\n> \r\n> @minjac\r\n> please update on the above comment\r\n\r\nHi, thanks for reply. I click your link, **beta1_power** and **beta2_power** seems to be the same as **t** in Adam Optimizer's formula.", "From https://arxiv.org/pdf/1412.6980.pdf beta1, beta2 are exponential decay rates for the moment estimates.\r\n(default values are set as \u03b21 = 0.9, \u03b22 = 0.999)\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/optimizer_v2/adam.py#L51\r\n", "> \r\n> \r\n> From https://arxiv.org/pdf/1412.6980.pdf beta1, beta2 are exponential decay rates for the moment estimates.\r\n> (default values are set as \u03b21 = 0.9, \u03b22 = 0.999)\r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/optimizer_v2/adam.py#L51\r\n\r\nThanks for reply, beta_2 seems to be the same as beta2 in my question.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 37535, "title": "Fixed missing export for Huber loss as tf.keras.losses.huber and tf.keras.metrics.huber", "body": "", "comments": ["Why is this required? Can we use the Huber loss class instead? The other loss functions are exported because they were available historically. ", "This would make the API consistent, since all the other loss function are available as classes and also as functions. And yes we can use Huber loss class just like the rest of the loss classes ", "@mihaimaruseac can you advice on how API changes ie.pbtxt files can be updated? ", "To generate the proto files used for API you need to run the `api_compatibility_test` with `--update_goldens`:\r\n\r\n```\r\nbazel build tensorflow/tools/api/tests:api_compatibility_test\r\nbazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens=True\r\n```\r\n\r\nThen, this will need an API review (there are weekly meetings for this) and API approval before being imported", "As tensorflow/api-owners: we'd rather keep Huber as class-only (as well any future losses)."]}, {"number": 37534, "title": "loading pre-trained resnet-50 for Object Detection Models on TensorFlow 2.0", "body": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/models/tree/master/official/vision/detection\r\n\r\n## Description of issue (what needs changing):\r\n\r\nHi,\r\nIn the \"Train a vanilla ResNet-50 based RetinaNet.\" it is said to use the \"path to the pre-trained Resnet-50 checkpoint\". There is no link to any pre-trained model. \r\n![image](https://user-images.githubusercontent.com/54512903/76514447-2f331d00-6458-11ea-8d63-dd474964f22c.png)\r\n\r\nI tried to use the resnet-50 which is in https://github.com/tensorflow/models/tree/master/official/vision/image_classification because it was likely to be a correct implementation as an official one. \r\n![image](https://user-images.githubusercontent.com/54512903/76515131-5b02d280-6459-11ea-973f-aabff6078c2d.png)\r\nUnfortunately, when I use :\r\npython main.py --strategy_type=one_device --num_gpus=1 --model_dir=\"my_models\" --mode=train --config_file=\"my_retinanet.yaml\"\r\n\r\nWith this yaml : \r\ntype: 'retinanet'\r\ntrain: \r\n  checkpoint:\r\n    path: pretrained_model\\home\\hongkuny\\hongkuny_keras_resnet50_gpu_8_fp32_eager_graph_cfit\\checkpoints\r\n    prefix: resnet50\\\r\n  train_file_pattern: tfrecords\\train.record\r\neval:\r\n  eval_file_pattern: tfrecords\\test.record\r\n\r\nI got nothing load because the weight seems to be wrongly named in this file, so it is not matching.\r\n\r\n![image](https://user-images.githubusercontent.com/54512903/76515306-a4532200-6459-11ea-90d7-b144b6498151.png)\r\n \r\nI also tried some other models from the zoo assuming we might load weights from resnet based objects detection models but I got the same probleme. \r\n\r\nI think we might add a link to a correct checkpoint of a compatible pre-trained model in order to avoid roaming around incompatible models. \r\n\r\nregards, \r\n\r\nSwann", "comments": ["I have reuploaded this issue there : \r\nhttps://github.com/tensorflow/models/issues/8274\r\nbecause it concerns models and not tensorflow.  "]}, {"number": 37533, "title": "Add const references", "body": "Add const references to class-type arguments.", "comments": ["Oops, sorry. Yes both StringPiece and Status should be passed by value."]}, {"number": 37532, "title": "Update year in license and fill in template", "body": "", "comments": ["License years should not be updated. They should point to the first time the file was created and not changed. If you have a file written in 2010 but license year is 2020 then any change to the file between 2010 and 2020 could be argued to not be covered by license. \r\n\r\nThe text of the license is copied verbatim in all files as comment preamble. Why not change the year in all of these files? \r\n\r\nWe will not be encouraging one liner changes as this is expensive process. Hence closing the PR.\r\nthank you for your interest.\r\nCC @mihaimaruseac", ">  They should point to the first time the file was created and not changed.\r\n\r\nThen should the license file not state 2015 instead of 2019?", "Probably, but they got updated by other similar PRs (we had at least 10 to update from 2019 to 2020 this year). So rather than continuing the bad practice, we just cut it short now"]}, {"number": 37531, "title": "Incorrect number of Total Parameters when Loading a Saved Model with Trainable = False", "body": "[Resume_Classification_Model.zip](https://github.com/tensorflow/tensorflow/files/4324479/Resume_Classification_Model.zip)\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A, as it can be reproduced in Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  N/A\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.1\r\n- Python version: Colab\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):  N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nThis issue is similar to [29535](https://github.com/tensorflow/tensorflow/issues/29535) but now occurring in `Tensorflow Version 2.x`.\r\n\r\n**Describe the current behavior**: Value of Total Parameters, when we Load the Saved Model with `Trainable = False` is Double compared to the Actual Total Parameters.\r\n\r\n**Describe the expected behavior**: Value of Total Parameters should be same even we use `Trainable = True` or `Trainable = False`\r\n\r\n**Standalone code to reproduce the issue** :  Please find the [attached Gist](https://colab.sandbox.google.com/gist/rmothukuru/a454904863d7a0e42b4497d6366a70e0/load_with_freeze_error.ipynb).\r\n\r\nPlease find the Model, \"Resume_Classification_Model.zip\", attached.", "comments": ["Was able to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/73a3b70d4f50f8a5e460e212be8c6793/tf2-1.ipynb). Thanks!", "I would just like to add to the discussion the fact that calling `compile()` after setting `trainable = False` resolves the issue, *i.e.* the correct number of parameters are displayed.", "@rakeshmothukuru1 , @amahendrakar and @jaketae , I think I have figured out the issue. \r\n`trainable_count` is calculated for summary by [this code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/layer_utils.py#L261).\r\n\r\nNote that the code on the above link\r\n```python\r\nif hasattr(model, '_collected_trainable_weights'):\r\n    trainable_count = count_params(model._collected_trainable_weights)\r\nelse:\r\n    trainable_count = count_params(model.trainable_weights)\r\n```\r\nfirst checks if there is any attribute as `_collected_trainable_weights`, if it is then it will count params based on `_collected_trainable_weights`, otherwise it will count based on `trainable_weights`.\r\n\r\nNow, since you are loading the model which was trained already so by default the layers of the model were trainable. I checked it by calling layers API and checking the weights as follows:\r\nYou can check layers with\r\n```python\r\n>>> New_Model._layers\r\n[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f694dcadcc0>,\r\n <tensorflow.python.keras.saving.saved_model.load.Embedding at 0x7f694dd3e0f0>,\r\n <tensorflow.python.keras.saving.saved_model.load.Bidirectional at 0x7f694dd3e780>,\r\n <tensorflow.python.keras.saving.saved_model.load.Bidirectional at 0x7f694dd3ecc0>,\r\n <tensorflow.python.keras.saving.saved_model.load.Dense at 0x7f694dd73128>,\r\n <tensorflow.python.keras.saving.saved_model.load.Dense at 0x7f694dd73550>]\r\n```\r\nYou can also check the trainable and non-trainable weights for each model with\r\n```python\r\n>>> New_Model._layers[5]._trainable_weights\r\n[<tf.Variable 'dense_1/kernel:0' shape=(64, 7) dtype=float32, numpy=\r\n array([[-5.22130467e-02, -1.93556882e-02,  6.19841479e-02,\r\n         -2.20982015e-01, -2.58759469e-01,  1.56931624e-01,\r\n         -1.02677837e-01],\r\n        [-2.78469831e-01, -3.55885886e-02, -3.39667916e-01,\r\n         -2.11565107e-01,  2.90678382e-01,  3.44290137e-02,\r\n         -1.20272964e-01],\r\n         ...\r\n        [-1.06683329e-01, -2.90703289e-02,  5.69653399e-02,\r\n         -1.45962730e-01,  1.51988491e-02, -4.15223390e-01,\r\n         -3.09695005e-01]], dtype=float32)>,\r\n <tf.Variable 'dense_1/bias:0' shape=(7,) dtype=float32, numpy=\r\n array([-0.04054414,  0.05413923,  0.0347003 , -0.0140862 , -0.02740904,\r\n         0.01077772, -0.01707667], dtype=float32)>]\r\n```\r\n\r\nSo, you can see here that weights of the layers are trainable by default since we have loaded the trained model. Now, the fact to know here is `_collected_trainable_weights` in `tf.keras.Model` is assigned at the time of `compile`. \r\n\r\nSo, if you compile the model before setting `trainable=False`, then it will assign `_collected_trainable_weights` non-empty list (Because layers trainable weights are non-empty). So, in this case, `trainable_weights` will be empty but `_collected_trainable_weights` will not be empty. Hence, the first [this code](https://github.com/tensorflow/tensorflow/blob/c9c38bcd20e206674e72d187c1f95046218342d1/tensorflow/python/keras/utils/layer_utils.py#L261) to count trainable parameter will consider `_collected_trainable_weights` to count trainable param.\r\n```python\r\nNew_Model = tf.keras.models.load_model(\"Resume_Classification_Model/Resume_Classification_Model/1\")\r\nNew_Model.compile()\r\nNew_Model.trainable= False\r\n```\r\nIt will generate o/p as \r\n```\r\nTotal params: 863,758\r\nTrainable params: 431,879\r\nNon-trainable params: 431,879\r\n```\r\n\r\nIn reverse case,\r\nf you compile the model after setting `trainable=False`, then it will assign `_collected_trainable_weights` empty list (Because compile will get `kwargs` as `trainable=False`). So, in this case, `trainable_weights` will be empty but `_collected_trainable_weights` will also be empty. Hence, the first [this code](https://github.com/tensorflow/tensorflow/blob/c9c38bcd20e206674e72d187c1f95046218342d1/tensorflow/python/keras/utils/layer_utils.py#L261) to count trainable parameter will consider `_collected_trainable_weights` (which is empty) to count trainable param.\r\n```python\r\nNew_Model = tf.keras.models.load_model(\"Resume_Classification_Model/Resume_Classification_Model/1\")\r\nNew_Model.trainable= False\r\nNew_Model.compile()\r\n```\r\nIt will generate o/p as \r\n```\r\nTotal params: 431,879\r\nTrainable params: 0\r\nNon-trainable params: 431,879\r\n```", "So, I think no need to change the code. We need to use `trainable` considering above thing in mind.", "Can you clarify what the workflow is?\r\n\r\nWhat do you mean by loading the SavedModel with trainable=False?", "@k-w-w,\r\nIf the question is to me, Please find this [Github Gist](https://colab.sandbox.google.com/gist/rmothukuru/a454904863d7a0e42b4497d6366a70e0/load_with_freeze_error.ipynb) for the Workflow. The Model is attached.\r\n\r\n[Resume_Classification_Model.zip](https://github.com/tensorflow/tensorflow/files/4342619/Resume_Classification_Model.zip)\r\n", "I think this is working as intended. `compile` locks down the trainable weights, I believe because the train ops are generated during compile. Therefore, you should recompile to get the correct number of parameters. (also, the summary notes that you should call `compile` after changing the `trainable` value)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37531\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37531\">No</a>\n"]}, {"number": 37530, "title": "Merge pull request #1 from tensorflow/master", "body": "Implement WindowsWritableFile::Tell", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37530) for more info**.\n\n<!-- need_sender_cla -->", "@zqzhai Please sign CLA. Thanks!", "These are spam PRs"]}, {"number": 37529, "title": "docs: update docs for tf.python.tools.import_pb_to_tensorboard", "body": "Using SavedModel instead .pb model", "comments": ["@ringw Please have a look at this PR, thanks!\r\n", "Adding @nfelt (from Tensorboard side), @k-w-w (from `SavedModel` side) and @akshaym (afaik, owner of this code) for more review", "Adding R=@davidsoergel for TensorBoard since this is relevant to https://github.com/tensorflow/tensorboard/issues/1962.  I don't have any particular context on this script or why it lives here versus in TensorBoard proper, other than that it's been around for a long time.", "We can also move the file in this PR (plus one on Tensorboard side), if that is case", "Closed by mistake, reopening", "The other reviewers have much more context here, so I'm removing myself."]}, {"number": 37528, "title": "Added example related to top_k parameter in tf.keras.metrics.Precision", "body": "Fixes #37416.\r\ncc @jvishnuvardhan, @ravikyram , @mihaimaruseac . ", "comments": []}, {"number": 37527, "title": "docs: update doc for tf.python.tools.saved_model_utils", "body": "fix wrong .pb file names", "comments": ["We will not be encouraging one liner changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac", "Let's take this one since documentation is wrong."]}, {"number": 37526, "title": "Micro: Added specific cmsis optimization for convolutions with 1xN fi\u2026", "body": "\u2026lters. Also removed deprecated output depth dependency.", "comments": ["@jvistrand Can you please resolve conflicts? Thanks!"]}, {"number": 37525, "title": "AttributeError: module 'tensorflow' has no attribute 'compat' when importing tensorflow", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: Installed with poetry\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\nAfter installing `tensorflow-cpu` 2.1.0, when I try to import it in python I get an error saying `AttributeError: module 'tensorflow' has no attribute 'compat'`. I also tried with the `tensorflow` package but I ran into the same issue.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI create and activate a virtual env with poetry:\r\n`poetry shell`\r\n\r\nI install tensorflow-cpu:\r\n`poetry add tensorflow-cpu`\r\n\r\nthen I run a python console:\r\n```\r\npython\r\n>> import tensorflow\r\n```\r\nand I get the error\r\n\r\n**Any other info / logs**\r\nThis is the traceback I get when importing tensorflow:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow/__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 46, in <module>\r\n    from . _api.v2 import compat\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py\", line 29, in <module>\r\n    from tensorflow._api.v2.compat.v1 import app\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py\", line 667, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 33, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 53, in <module>\r\n    from tensorflow_estimator.python.estimator import util as estimator_util\r\n  File \"/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py\", line 75, in <module>\r\n    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\nAttributeError: module 'tensorflow' has no attribute 'compat'\r\n```", "comments": ["@LuisCebrian,\r\nCan you install with `PIP` as follows,\r\n`pip install tensorflow==2.1`\r\nLet us know if issue still persists. Thanks", "Just had the same issue and it was solved after installing as described. Before I was installing tensorflow through poetry.\r\n\r\nWhy does not work anymore?", "Adding (as a temp workaround)\r\n`tensorflow-estimator = \"==2.1.0\"`\r\nin pyproject.toml for poetry fixes this for me under poetry.\r\n(else it gets tensorflow-estimator 2.2.0rc0 which seems to cause the issue)", "Brilliant, that was exactly the solution I needed to get things working, thanks @asequeira-os!", "> @LuisCebrian,\r\n> Can you install with `PIP` as follows,\r\n> `pip install tensorflow==2.1`\r\n> Let us know if issue still persists. Thanks\r\n\r\n@gadagashwini  The issue is solved if I install it that way. Why does tensorflow do not work if I install it with poetry?\r\n\r\n@asequeira-os Thank you so much for your workaround\r\n\r\n", "Our official documentation page recommends using `pip` to install tensorflow packages.\r\nhttps://www.tensorflow.org/install/pip?lang=python3\r\nRefer [thread](https://github.com/python-poetry/poetry/issues/1330)  to know more.\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37525\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37525\">No</a>\n", "To bo honest with you, this is a bit of a crappy response. Poetry is getting more and more traction and is really better at dependency resolution than pip... Moreover the thread on poetry issue is related to functools32 which is not related to this issue at all.", "@gadagashwini @ymodak \r\nI had the same issue with pip3. \r\n\r\n**System information:**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: Installed with pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nI uninstalled and reinstalled Tensorflow with the aforementioned command. However, get the error when `import tensorflow as tf`:\r\n\r\n-------------------------------------------------------------------------------\r\n\r\nimport tensorflow as tf\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 101 <module>\r\nfrom tensorflow_core import *\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 46 <module>\r\nfrom . _api.v2 import compat\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 39 <module>\r\nfrom . import v1\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 32 <module>\r\nfrom . import compat\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 39 <module>\r\nfrom . import v1\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 29 <module>\r\nfrom tensorflow._api.v2.compat.v1 import app\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 39 <module>\r\nfrom . import v1\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 32 <module>\r\nfrom . import compat\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 39 <module>\r\nfrom . import v1\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 667 <module>\r\nfrom tensorflow_estimator.python.estimator.api._v1 import estimator\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 10 <module>\r\nfrom tensorflow_estimator.python.estimator.api._v1.estimator import experimental\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\n__init__.py 10 <module>\r\nfrom tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\ndnn.py 33 <module>\r\nfrom tensorflow_estimator.python.estimator import estimator\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\nestimator.py 53 <module>\r\nfrom tensorflow_estimator.python.estimator import util as estimator_util\r\npydev_import_hook.py 21 do_import\r\nmodule = self._system_import(name, *args, **kwargs)\r\nutil.py 75 <module>\r\nclass _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\nAttributeError:\r\nmodule 'tensorflow' has no attribute 'compat'", "I had a look into this and think I found the root cause(s).\r\n1. a bug in poetry, which causes version 2.2.0rc0 of tensorflow-estimator to get installed despite tensorflow specifying a version of <2.2.0 (https://github.com/python-poetry/poetry/issues/2271)\r\n2. tensorflow-estimator 2.2.0rc0 has a circular import, introduced in https://github.com/tensorflow/estimator/commit/a70da58fef26d2c027cc379b15d92f16ccbd513b, where we import `tensorflow` -> ... -> `tensorflow_estimator.python.estimator.util` -> `tensorflow`; the effect of that is that `tensorflow_estimator.python.estimator.util` sees a partially-initialised `tensorflow` module, which in particular doesn't have the `compat` attribute. I've confirmed that replacing `import tensorflow as tf` with `from tensorflow.compat.v1.train import SessionRunHook` (and updating the usages of `SessionRunHook` accordingly) fixes the issue.", "Not sure what's the issue with tensorflow 2.1, but also happened to me. \r\n\r\n```\r\npip uninstall tensorflow\r\npip uninstall tensorflow-estimator\r\n```\r\n\r\nThen \r\n```\r\npip install tensorflow\r\n```\r\n\r\n", "for me, below commands in sequence solved the issue\r\n\r\npip uninstall tensorflow-estimator\r\n\r\npip install tensorflow-estimator==2.1", "> > @LuisCebrian,\r\n> > Can you install with `PIP` as follows,\r\n> > `pip install tensorflow==2.1`\r\n> > Let us know if issue still persists. Thanks\r\n> \r\n> @gadagashwini The issue is solved if I install it that way. Why does tensorflow do not work if I install it with poetry?\r\n> \r\n> @asequeira-os Thank you so much for your workaround\r\n\r\nissue solved thank you verymuch ", "> for me, below commands in sequence solved the issue\r\n> \r\n> pip uninstall tensorflow-estimator\r\n> \r\n> pip install tensorflow-estimator==2.1\r\n\r\nthis worked for me. thanks", "I really don't want to use pip to install something as full of dependencies as tensorflow. It becomes inevitable that something will break, even in a separate environment.", "I am managing multiple very complex and specialized environments, for example, nightly builds of frameworks, and your right things break. I tend to use conda which seems to work better for me for this than pip but pip often allows you to access libraries etc conda cannot. In this case I used pip in conda and conda happily now manages that environment. I am not sure what would be a better approach. do you have a recommendation. I know a lot of people have started using poetry. ", "Same with Anaconda, \r\nbut reinstall with tensorflow=2.1 does not solve issue.\r\n\"conda install tensorflow\" brings tensorflow-estimator 2.2, but 2.1 is needed.\r\n\r\nSolution: First install Estimator=2.1 then the rest:\r\n- conda remove tensorflow\r\n- conda install tensorflow-estimator 2.1\r\n- conda install tensorflow-gpu=2.1\r\n\r\nHelped here.", "@robisen1 No, sadly. I have recently heard of poetry as well, I will give it a try, or just stick to using specialized VM images to avoid major data-sci dependency conflicts for large frameworks (that's what I'm currently doing).", "> Same with Anaconda,\r\n> but reinstall with tensorflow=2.1 does not solve issue.\r\n> \"conda install tensorflow\" brings tensorflow-estimator 2.2, but 2.1 is needed.\r\n> \r\n> Solution: First install Estimator=2.1 then the rest:\r\n> \r\n> * conda remove tensorflow\r\n> * conda install tensorflow-estimator 2.1\r\n> * conda install tensorflow-gpu=2.1\r\n> \r\n> Helped here.\r\n\r\nYES! This worked great - make sure not to forget the equals sign here:\r\n* conda install tensorflow-estimator=2.1", "I am still having the same issue despite completing all of the following instructions.", "> Same with Anaconda,\r\n> but reinstall with tensorflow=2.1 does not solve issue.\r\n> \"conda install tensorflow\" brings tensorflow-estimator 2.2, but 2.1 is needed.\r\n> \r\n> Solution: First install Estimator=2.1 then the rest:\r\n> \r\n> * conda remove tensorflow\r\n> * conda install tensorflow-estimator 2.1\r\n> * conda install tensorflow-gpu=2.1\r\n> \r\n> Helped here.\r\n\r\nWorked for me on Anaconda as well. Big thnx!", "when i run the run_webcam.py command. i get this error. how can i solve this issue.\r\ni have tensorflow 2.4.0 version but i have tensorflow 2.1.0 gpu installed.\r\n i get this issue.\r\nTraceback (most recent call last):\r\n  File \"run_webcam.py\", line 8, in <module>\r\n    from tf_pose.estimator import TfPoseEstimator\r\n  File \"C:\\Users\\User\\tf-pose-estimation\\tf_pose\\__init__.py\", line 5, in <module>\r\n    from tf_pose.runner import infer, Estimator, get_estimator\r\n  File \"C:\\Users\\User\\tf-pose-estimation\\tf_pose\\runner.py\", line 7, in <module>\r\n    from tf_pose import common\r\n  File \"C:\\Users\\User\\tf-pose-estimation\\tf_pose\\common.py\", line 3, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 46, in <module>\r\n    from . _api.v2 import compat\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 29, in <module>\r\n    from tensorflow._api.v2.compat.v1 import app\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 667, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\", line 33, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 53, in <module>\r\n    from tensorflow_estimator.python.estimator import util as estimator_util\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 75, in <module>\r\n    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\nAttributeError: module 'tensorflow' has no attribute 'compat'", "I get the same error when I recently installed Tensorflow 2.4.0.\r\n\r\nWhen I run the below import \r\n`import tensorflow.compat.v1 as tf` \r\n\r\nI get the same error: `ModuleNotFoundError: No module named 'tensorflow.compat'`", "same error with: tensorflow-2.4.1", "[[Solved] module \u2018tensorflow.compat.v2.__internal__\u2019 has no attribute \u2018tf2\u2019\r\n](https://exerror.com/module-tensorflow-compat-v2-internal-has-no-attribute-tf2/)", "> > Same with Anaconda,\r\n> > but reinstall with tensorflow=2.1 does not solve issue.\r\n> > \"conda install tensorflow\" brings tensorflow-estimator 2.2, but 2.1 is needed.\r\n> > Solution: First install Estimator=2.1 then the rest:\r\n> > \r\n> > * conda remove tensorflow\r\n> > * conda install tensorflow-estimator 2.1\r\n> > * conda install tensorflow-gpu=2.1\r\n> > \r\n> > Helped here.\r\n> \r\n> YES! This worked great - make sure not to forget the equals sign here:\r\n> \r\n> * conda install tensorflow-estimator=2.1\r\n\r\nThis didnt work for me tho. Using pip or conda to get  tensorflow-estimator 2.1, got me the same error."]}]