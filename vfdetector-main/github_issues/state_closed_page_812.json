[{"number": 29175, "title": "1.14-rc1 cherry-pick request: Unexpose enable_mixed_precision_graph_rewrite in TF 2.", "body": "This needs to be cherrypicked in TF 1.14, so that the symbol is not exposed in tf.compat.v2 in a stable release of TensorFlow.", "comments": []}, {"number": 29174, "title": "[ROCm] Add ROCm support for cudnn_rnn_ops", "body": "This PR adds ROCm support for cudnn_rnn_ops\r\n\r\nNo naming changes are introduced to keep Python APIs consistent.\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n-------------------------\r\n\r\n@tatianashp @deven-amd", "comments": []}, {"number": 29173, "title": "[ROCm] adding hipclang related updates to ROCm config files", "body": "This commit adds changes required for using \"hipclang based hipcc\" as the compiler when building TF with ROCm support.\r\n\r\nThe only visible (to TF Code) change in this commit is the introduction of a #define \"TENSORFLOW_COMPILER_IS_HIP_CLANG\" which will be defined (on the command line) when the compiler is \"hipclang based hipcc\".\r\n\r\nTF code that needs to be special-cased when compiling with \"hipclang based hipcc\" will be put within \"#if  TENSORFLOW_COMPILER_IS_HIP_CLAN\". This is expectd to be a lightly used #define. As of now, there are only 4 instances of its use in our fork.\r\n\r\n--------------------------------\r\n\r\n@tatianashp @whchung \r\n\r\n", "comments": []}, {"number": 29172, "title": "[ROCm] Add ROCm support for launching GPU convolutions", "body": "This PR adds ROCm support for launching GPU convolutions.\r\n\r\nCorresponding operators aren't included in this PR and would be filed in a subsequent one. This PR focus on changing kernel implementations.\r\n\r\n-------------------------\r\n\r\n@tatianashp @deven-amd", "comments": []}, {"number": 29171, "title": "tensorflow v1.13.1 build issue on Windows 10", "body": "I am new to tensorflow and got the cuda version issue while build from source using bazel.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.3\r\n- Bazel version (if compiling from source): 0.19.2\r\n- CUDA/cuDNN version: cuda(v10.0) cudnn(7.6.0)\r\n\r\n**Any other info / logs**\r\nF:\\Work\\VS\\DNN\\tensorflow-1.13.1>bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nf:\\work\\vs\\dnn\\tensorflow-1.13.1/.bazelrc\r\nWARNING: detected http_proxy set in env, setting no_proxy for localhost.\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 1556\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 1265, in _create_local_cuda_repository\r\n                _get_cuda_config(repository_ctx)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 964, in _get_cuda_config\r\n                _cuda_version(repository_ctx, toolkit_path, cpu_va...)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 521, in _cuda_version\r\n                auto_configure_fail((\"CUDA version detected from nvc...)))\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 342, in auto_configure_fail\r\n                fail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: CUDA version detected from nvcc (10.0.130) does not match TF_CUDA_VERSION (C:Program FilesNVIDIA GPU Computing ToolkitCUDAv10.0)\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 1556\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 1265, in _create_local_cuda_repository\r\n                _get_cuda_config(repository_ctx)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 964, in _get_cuda_config\r\n                _cuda_version(repository_ctx, toolkit_path, cpu_va...)\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 521, in _cuda_version\r\n                auto_configure_fail((\"CUDA version detected from nvc...)))\r\n        File \"F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl\", line 342, in auto_configure_fail\r\n                fail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: CUDA version detected from nvcc (10.0.130) does not match TF_CUDA_VERSION (C:Program FilesNVIDIA GPU Computing ToolkitCUDAv10.0)\r\nINFO: Elapsed time: 3.871s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n\r\n", "comments": []}, {"number": 29170, "title": "Unable to serialize dict that is wrapped around tracking `_DictWrapper`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0-rc0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n`dict` objects wrapped around `_DictWrapper` by `AutoTrackable` are not serializable by pickle.\r\n\r\n**Describe the expected behavior**\r\n`dict` objects wrapped around `_DictWrapper` by `AutoTrackable` are serializable by pickle.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport pickle\r\nimport tensorflow as tf\r\nfrom tensorflow.python.training.tracking.tracking import AutoTrackable\r\n\r\n\r\nclass MyTrackable(AutoTrackable):\r\n    def __init__(self):\r\n        self.random_op = {\r\n            'tf.trandom.uniform(())': tf.random.uniform(())\r\n        }\r\n\r\n\r\ndef main():\r\n    my_trackable = MyTrackable()\r\n    value = tf.Session().run(my_trackable.random_op)\r\n    print(type(value))\r\n    pickle.dumps(value)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\nThis fails with the following error:\r\n```\r\n$ python ./dict_wrapper_test.py\r\n<class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\r\nTraceback (most recent call last):\r\n  File \"./tests/dict_wrapper_test.py\", line 20, in <module>\r\n    main()\r\n  File \"./tests/dict_wrapper_test.py\", line 16, in main\r\n    pickle.dumps(value)\r\nNotImplementedError: object proxy must define __reduce_ex__()\r\n```\r\n\r\nNot exactly sure if this is a bug or a feature. Should the built-in data structures that are tracked be serializable?", "comments": ["Thanks for the report. Just an oversight; should be working now.", "Damn, that was fast! Thanks a lot @allenlavoie!"]}, {"number": 29169, "title": "[ROCm] Add ROCm support for adjust_hue and adjust_saturation op", "body": "This PR adds ROCm support for adjust_hue and adjust_saturation op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n-------------------------\r\n\r\n@tatianashp @deven-amd", "comments": []}, {"number": 29168, "title": "Can't convert .pb to .tflite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (or github SHA if from source):1.13.1\r\n- Bazel version (if compiling from source): 0.22.0\r\n- Python version: 3.6.7\r\n\r\n**Command** \r\n./bazel-bin/tensorflow/lite/toco/toco --input_file=test.pb --output_file=test.tflite \r\n--input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_arrays=input \r\n--input_shapes=1,416,416,3 --output_arrays=output\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n2019-05-30 23:21:21.565311: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ExtractImagePatches\r\n2019-05-30 23:21:21.615470: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 211 operators, 370 arrays (0 quantized)\r\n2019-05-30 23:21:21.618923: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 211 operators, 370 arrays (0 quantized)\r\n2019-05-30 23:21:22.132104: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 97 operators, 189 arrays (0 quantized)\r\n2019-05-30 23:21:22.133428: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 97 operators, 189 arrays (0 quantized)\r\n2019-05-30 23:21:22.134795: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 68550208 bytes, theoretical optimal value: 66453504 bytes.\r\n2019-05-30 23:21:22.135184: E tensorflow/lite/toco/toco_tooling.cc:421] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.\r\n\r\n", "comments": ["@billy0705 Can you please refer the [link](https://github.com/tensorflow/tensorflow/issues/24138)", "Please have a look on [FAQ,](https://www.tensorflow.org/lite/guide/faq#why_are_some_operations_not_implemented_in_tensorflow_lite) [Select operators from TensorFlow](https://www.tensorflow.org/lite/guide/ops_select). Let us know if that resolves the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29167, "title": "[ROCm] Fix for the broken `--config=rocm` build.", "body": "This PR contains a fix for the broken `--config=rocm` build, which was broken by the following commit\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/47984a7d05937b978d7a80f2e9d60b2d32c06c07\r\n\r\nThe commit above made changes to the stream executor interface, updated the CUDA implementation to account for the interface change, but did not apply the same change to the ROCm implementation.\r\n\r\n-----------------------------------\r\n\r\n@tatianashp @whchung \r\n\r\n", "comments": []}, {"number": 29166, "title": "[ROCm] Adding ROCm support to cross_op", "body": "This PR adds ROCm support for cross_op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------\r\nTest performed: tensorflow/core/kernels:cross_op_test\r\n@tatianashp @whchung", "comments": []}, {"number": 29165, "title": "Unicode op tests fail on s390x with \"Could not create converter for input encoding: SHIFT-JIS\" error", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 s390x\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): v1.131.\r\n- Python version: 2.7.15rc1\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): gcc 7.4\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n`python ./tensorflow/python/kernel_tests/unicode_decode_op_test.py` fails with following error:\r\n\r\nInvalidArgumentError (see above for traceback): Could not create converter for input encoding: SHIFT-JIS\r\n         [[node UnicodeDecodeWithOffsets/UnicodeDecodeWithOffsets (defined at /usr/local/lib/python2.7/dist-packages/absl/testing/parameterized.py:264) ]]\r\n\r\n**Describe the expected behavior**\r\nThis should pass like Intel. \r\n\r\n**Code to reproduce the issue**\r\nbazel test -c opt //tensorflow/python/kernel_tests:unicode_decode_op_test OR \r\nbazel test -c opt //tensorflow/python/kernel_tests:unicode_transcode_op_test\r\n\r\n**Other info / logs**\r\n```\r\n> iconv -l | grep -i shift\r\nCSSHIFTJIS//\r\nSHIFT-JIS//\r\nSHIFT_JIS//\r\nSHIFT_JISX0213//\r\n```\r\nError logs are updated\r\n[unicode_decode_logs.log](https://github.com/tensorflow/tensorflow/files/3237313/unicode_decode_logs.log)\r\n\r\nCan anyone please tell us the impact of this failure on functionality? Also does anyone have any clue on this issue? Thanks in advance.", "comments": ["@kbhute-ibm This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!", "TF requires hermetic builds, so the ICU conversion data is embedded in the binary as a byte-array. It currently uses little-endian layout. The TF team doesn't have bandwidth to add big-endian support currently, but a PR would be welcome. The data embedding takes place here: https://github.com/tensorflow/tensorflow/blob/master/third_party/icu/data/BUILD.bazel. \r\n\r\nByte ordering has come up as an issue w.r.t. saved models as well, and the preference there was to store a single format on disk and byte-swap at runtime if required: https://github.com/tensorflow/tensorflow/issues/16364. The same approach is probably preferred here; at the very least, we should not be statically linking two versions of the same data in the binary.", "@hamatake Thanks for the pointers that gave us direction for further debugging.", "@hamatake, I was trying to regenerate the ICU conversion data for big endian. Followed steps mentioned here: https://github.com/tensorflow/tensorflow/blob/v2.0.0/third_party/icu/data/BUILD.bazel\r\n\r\nHowever it seems to regenerate same little endian format data. Are the pre-processing steps different for big endian? Is there some other way to reproduce the conversion data?", "icupkg lets you change byte ordering for a given .dat file. See the manpage\nfor full instructions, but '-tb' creates big-endian ASCII output and '-te'\ncreates big-endian EBCDIC output.\n\nOn Mon, Oct 14, 2019 at 7:14 AM Namrata Bhave <notifications@github.com>\nwrote:\n\n> @hamatake <https://github.com/hamatake>, I was trying to regenerate the\n> ICU conversion data for big endian. Followed steps mentioned here:\n> https://github.com/tensorflow/tensorflow/blob/v2.0.0/third_party/icu/data/BUILD.bazel\n>\n> However it seems to regenerate same little endian format data. Are the\n> pre-processing steps different for big endian? Is there some other way to\n> reproduce the conversion data?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29165?email_source=notifications&email_token=ABE4ECBPP4Z6GYJYBI54DJ3QOR5FBA5CNFSM4HRFMQT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBE2YPQ#issuecomment-541699134>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABE4ECDD2UNR6W4JNLVZAILQOR5FBANCNFSM4HRFMQTQ>\n> .\n>\n", "@hamatake, I followed below steps to recreate the data for big endian system:\r\n1. built and installed ICU v64.2\r\n2. Generated `icudt64b_dat.c` as per steps in https://github.com/tensorflow/tensorflow/blob/master/third_party/icu/data/BUILD.bazel (did not give any Data filter file here)\r\n3. Note, the above build generated `icudt64b.dat` for me( **single letter following the version number in the file name was **b****) so assuming it generated correct format data, I tried using this data file directly in TensorFlow, however test failed with `InvalidArgumentError: Could not create converter for input encoding: shift_jis`\r\n4. Further I tried using `icupkg` to convert the data file using '-tb' as well as '-te' however test still failed. \r\n\r\nAm I missing anything here? Could you please help?", "If the data package already has 'b' in the name than it should be\nappropriate for big-endian. You shouldn't need icupkg in that case. You are\ncorrect to follow the new (post v64) instructions for building icu data.\nDid you modify the filename and symbol names properly when appending\nto icudt64b_dat.c (the output of genccode)? Did you gzip/split the .c file\nand rename it to match the pattern icu_conversion_data.c.gz.*?\n\n\nOn Tue, Oct 15, 2019 at 7:22 AM Namrata Bhave <notifications@github.com>\nwrote:\n\n> @hamatake <https://github.com/hamatake>, I followed below steps to\n> recreate the data for big endian system:\n>\n>    1. built and installed ICU v64.2\n>    2. Generated icudt64b_dat.c as per steps in\n>    https://github.com/tensorflow/tensorflow/blob/master/third_party/icu/data/BUILD.bazel\n>    (did not give any Data filter file here)\n>    3. Note, the above build generated icudt64b.dat for me( *single letter\n>    following the version number in the file name was b*) so assuming it\n>    generated correct format data, I tried using this data file directly in\n>    TensorFlow, however test failed with InvalidArgumentError: Could not\n>    create converter for input encoding: shift_jis\n>    4. Further I tried using icupkg to convert the data file using '-tb'\n>    as well as '-te' however test still failed.\n>\n> Am I missing anything here? Could you please help?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29165?email_source=notifications&email_token=ABE4ECDUMNKVLJQI5GODJ3DQOXG2NA5CNFSM4HRFMQT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBI5NHY#issuecomment-542234271>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABE4ECFOPGOZMSDJLJZLBY3QOXG2NANCNFSM4HRFMQTQ>\n> .\n>\n", "@hamatake, yes, ran steps as listed below in icu4c/source :\r\n```\r\n./runConfigureICU Linux\r\nmake clean && make\r\ncd data/out/tmp\r\n\r\ngenccode icudt64b.dat\r\necho 'U_CAPI const void * U_EXPORT2 uprv_getICUData_conversion() { return icudt64b_dat.bytes; }' >> icudt64b_dat.c\r\n\r\ncp icudt64b_dat.c icu_conversion_data.c\r\ngzip -v icu_conversion_data.c\r\nsplit --number=10 icu_conversion_data.c.gz icu_conversion_data.c.gz. \r\n```\r\nThis created similar files currently present under data folder. Also tried the same with master which generated icudt66b.dat but that did not work either.", "Hmm, that looks correct to me. I don't have a big-endian platform to test\non, unfortunately. Since this is more of an ICU data packaging issue than a\ntensorflow-specific issue, I'd recommend icu-support@lists.sourceforge.net.\n\nOn Tue, Oct 15, 2019 at 11:16 AM Namrata Bhave <notifications@github.com>\nwrote:\n\n> @hamatake <https://github.com/hamatake>, yes, ran steps as listed below\n> in icu4c/source :\n>\n> ./runConfigureICU Linux\n> make clean && make\n> cd data/out/tmp\n>\n> genccode icudt64b.dat\n> echo 'U_CAPI const void * U_EXPORT2 uprv_getICUData_conversion() { return icudt64b_dat.bytes; }' >> icudt64b_dat.c\n>\n> cp icudt64b_dat.c icu_conversion_data.c\n> gzip -v icu_conversion_data.c\n> split --number=10 icu_conversion_data.c.gz icu_conversion_data.c.gz.\n>\n> This created similar files currently present under data folder. Also tried\n> the same with master which generated icudt66b.dat but that did not work\n> either.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29165?email_source=notifications&email_token=ABE4ECDDRDK3EXJTHAXV2ATQOYCHTA5CNFSM4HRFMQT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBJWH3I#issuecomment-542335981>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABE4ECDCOHCOL4WWRO7NIDLQOYCHTANCNFSM4HRFMQTQ>\n> .\n>\n", "@hamatake, issue indeed seems to be with data packaging as running CJK related tests in ICU pass on big endian (https://github.com/unicode-org/icu/blob/master/icu4c/source/samples/ucnv/convsamp.cpp#L542)\r\n\r\nHad a query about use case related to CJK conversion. How critical is this functionality in TensorFlow and how often will user encounter this?\r\n\r\nThank you for the pointers, Appreciate the help provided!", "CJK conversion happens only when the user has CJK input data and they\nexplicitly ask for it to be decoded. I can't say how often this happens, as\nthere is little visibility into what data users are loading.\n\nOn Wed, Oct 16, 2019 at 3:45 AM Namrata Bhave <notifications@github.com>\nwrote:\n\n> @hamatake <https://github.com/hamatake>, issue indeed seems to be with\n> data packaging as running CJK related tests in ICU pass on big endian (\n> https://github.com/unicode-org/icu/blob/master/icu4c/source/samples/ucnv/convsamp.cpp#L542\n> )\n>\n> Had a query about use case related to CJK conversion. How critical is this\n> functionality in TensorFlow and how often will user encounter this?\n>\n> Thank you for the pointers, Appreciate the help provided!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29165?email_source=notifications&email_token=ABE4ECCIZOH76UPAK2RJLW3QO3WD5A5CNFSM4HRFMQT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBMAKKQ#issuecomment-542639402>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABE4ECCODUKBWOIAHCS6XMLQO3WD5ANCNFSM4HRFMQTQ>\n> .\n>\n", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Hi there, problem still exists in TF 2.5.0 on s390x.  Investigation in progress to determine if the root cause of the test case failure is still the same.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29165\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29165\">No</a>\n"]}, {"number": 29164, "title": "Update from origin", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29164) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 29163, "title": "Please provide the weight pruned InceptionV3 and MobileNetV1 models", "body": "I want to try the compression performance of weight pruning of TensorFlow. Is it OK for you to provide the model after pruning? e.g., the 50% sparsity MobileNetV1?", "comments": ["@lee-bin Please have a look on this [link](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras). Let us know if that helps. Thanks!", "@gadagashwini  Thanks! I had tried that before, but it's MNIST model, not InceptionV3 and MobileNetV1.\r\nCould you please share the codes or the pruned model for these two models?\r\nI know that you have tested it from [here](https://www.tensorflow.org/model_optimization/guide/pruning#image_classification).\r\nI'm very new to this, any help would be appreciated.", "@lee-bin This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks! ", "Thanks! I asked it at https://stackoverflow.com/questions/56470335/is-there-any-keras-code-to-reproduce-the-weight-pruning-of-mobilenet."]}, {"number": 29162, "title": "tf.estimator.evaluate fails whith one_hot encoded labels", "body": "\r\n\r\n\r\n\r\n**System information**\r\n- Linux Ubuntu 16.04:\r\n- TensorFlow installed from binary\r\n- TensorFlow version: b'v1.13.1-0-g6612da8951' 1.13.1\r\n- Python version: 3.5.3\r\n- CUDA/cuDNN version: NO CUDA\r\n- GPU model and memory: NO GPU\r\n\r\n**Describe the current behavior**\r\n\r\nWhen working with one hot encoding, **tf.estimator.evaluate** thows:\r\n`    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for   'remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [?,10`].\r\n\r\n**tf.estimator.train**  works fine\r\n\r\n\r\n**Describe the expected behavior**\r\nNo ValueError\r\n\r\n**Code to reproduce the issue**\r\n\r\nI''ve changed the official CNN estimator ([https://www.tensorflow.org/tutorials/estimators/cnn](https://www.tensorflow.org/tutorials/estimators/cnn)) to work with _one_hot_ encoding on labels (only changing the _loss_ function)\r\n\r\n```\r\n# Calculate Loss (for both TRAIN and EVAL modes)\r\n  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\r\n\r\n```\r\n\r\nI've aslo create dummy labels to test it:\r\n\r\n```\r\ntrain_labels = np.ones((train_data.shape[0],10))\r\neval_labels = np.ones((eval_data.shape[0],10))\r\n\r\n\r\n", "comments": ["@stratomaster31 In order to expedite the trouble-shooting process, please provide your custom code snippet to reproduce the issue reported here. Thanks!\r\n\r\n", "```\r\ndef cnn_model_fn(features, labels, mode):\r\n  \"\"\"Model function for CNN.\"\"\"\r\n  # Input Layer\r\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n  # Convolutional Layer #1\r\n  conv1 = tf.layers.conv2d(\r\n      inputs=input_layer,\r\n      filters=32,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n  # Pooling Layer #1\r\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n\r\n  # Convolutional Layer #2 and Pooling Layer #2\r\n  conv2 = tf.layers.conv2d(\r\n      inputs=pool1,\r\n      filters=64,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n\r\n  # Dense Layer\r\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n  dropout = tf.layers.dropout(\r\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n  # Logits Layer\r\n  logits = tf.layers.dense(inputs=dropout, units=10)\r\n\r\n  predictions = {\r\n      # Generate predictions (for PREDICT and EVAL mode)\r\n      \"classes\": tf.argmax(input=logits, axis=1),\r\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\r\n      # `logging_hook`.\r\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\r\n  }\r\n\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n  # Calculate Loss (for both TRAIN and EVAL modes)\r\n  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\r\n\r\n  # Configure the Training Op (for TRAIN mode)\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(\r\n        loss=loss,\r\n        global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n  # Add evaluation metrics (for EVAL mode)\r\n  eval_metric_ops = {\r\n      \"accuracy\": tf.metrics.accuracy(\r\n          labels=labels, predictions=predictions[\"classes\"])\r\n  }\r\n  return tf.estimator.EstimatorSpec(\r\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n# Load training and eval data\r\n((train_data, train_labels),\r\n (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_data = train_data/np.float32(255)\r\n#train_labels = train_labels.astype(np.int32)  # change labels to fake (but valid) one_hot\r\ntrain_labels = np.zeros((train_data.shape[0],10))\r\ntrain_labels[:,0] = 1\r\n\r\neval_data = eval_data/np.float32(255)\r\n#eval_labels = eval_labels.astype(np.int32)  # change labels to fake (but valid) one_hot\r\neval_labels = np.zeros((eval_data.shape[0],10))\r\neval_labels[:,0] = 1\r\n\r\n# Create the Estimator\r\nmnist_classifier = tf.estimator.Estimator(\r\n    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\r\n\r\n# Set up logging for predictions\r\ntensors_to_log = {\"probabilities\": \"softmax_tensor\"}\r\n\r\nlogging_hook = tf.train.LoggingTensorHook(\r\n    tensors=tensors_to_log, every_n_iter=50)\r\n\r\n# Train the model\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": train_data},\r\n    y=train_labels,\r\n    batch_size=100,\r\n    num_epochs=None,\r\n    shuffle=True)\r\n\r\n# train one step and display the probabilties\r\nmnist_classifier.train(\r\n    input_fn=train_input_fn,\r\n    steps=1,\r\n    hooks=[logging_hook])\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": eval_data},\r\n    y=eval_labels,\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\r\nprint(eval_results)\r\n\r\n```", "@stratomaster31 I tried reproducing the issue with provided code snippet. Looks, code snippet is incomplete, please help us to reproduce the issue. Thanks!", "This script reproduces the error reported in this issue:\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\ndef cnn_model_fn(features, labels, mode):\r\n  \"\"\"Model function for CNN.\"\"\"\r\n  # Input Layer\r\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n  # Convolutional Layer #1\r\n  conv1 = tf.layers.conv2d(\r\n      inputs=input_layer,\r\n      filters=32,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n  # Pooling Layer #1\r\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n\r\n  # Convolutional Layer #2 and Pooling Layer #2\r\n  conv2 = tf.layers.conv2d(\r\n      inputs=pool1,\r\n      filters=64,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n\r\n  # Dense Layer\r\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n  dropout = tf.layers.dropout(\r\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n  # Logits Layer\r\n  logits = tf.layers.dense(inputs=dropout, units=10)\r\n\r\n  predictions = {\r\n      # Generate predictions (for PREDICT and EVAL mode)\r\n      \"classes\": tf.argmax(input=logits, axis=1),\r\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\r\n      # `logging_hook`.\r\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\r\n  }\r\n\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n  # Calculate Loss (for both TRAIN and EVAL modes)\r\n  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\r\n\r\n  # Configure the Training Op (for TRAIN mode)\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(\r\n        loss=loss,\r\n        global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n  # Add evaluation metrics (for EVAL mode)\r\n  eval_metric_ops = {\r\n      \"accuracy\": tf.metrics.accuracy(\r\n          labels=labels, predictions=predictions[\"classes\"])\r\n  }\r\n  return tf.estimator.EstimatorSpec(\r\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n# Load training and eval data\r\n((train_data, train_labels),\r\n (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_data = train_data/np.float32(255)\r\n#train_labels = train_labels.astype(np.int32)  # change labels to fake (but valid) one_hot\r\ntrain_labels = np.zeros((train_data.shape[0],10))\r\ntrain_labels[:,0] = 1\r\n\r\neval_data = eval_data/np.float32(255)\r\n#eval_labels = eval_labels.astype(np.int32)  # change labels to fake (but valid) one_hot\r\neval_labels = np.zeros((eval_data.shape[0],10))\r\neval_labels[:,0] = 1\r\n\r\n# Create the Estimator\r\nmnist_classifier = tf.estimator.Estimator(\r\n    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\r\n\r\n# Set up logging for predictions\r\ntensors_to_log = {\"probabilities\": \"softmax_tensor\"}\r\n\r\nlogging_hook = tf.train.LoggingTensorHook(\r\n    tensors=tensors_to_log, every_n_iter=50)\r\n\r\n# Train the model\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": train_data},\r\n    y=train_labels,\r\n    batch_size=100,\r\n    num_epochs=None,\r\n    shuffle=True)\r\n\r\n# train one step and display the probabilties\r\nmnist_classifier.train(\r\n    input_fn=train_input_fn,\r\n    steps=1,\r\n    hooks=[logging_hook])\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": eval_data},\r\n    y=eval_labels,\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\r\nprint(eval_results)\r\n```", "I am able to reproduce the issue on Google colab with Tensorflow 1.13.1. Thanks!", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "It feel is not a bug, its an unexpected error because:\r\n\r\n* Train method works well\r\n```\r\nmnist_classifier.train(\r\n    input_fn=train_input_fn,\r\n    steps=1,\r\n    hooks=[logging_hook])\r\n```\r\n* whereas Evaluate one not\r\n``` \r\n\r\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\r\n``` \r\n", "Apologies for the delay in response. Please post your code snippet on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29162\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29162\">No</a>\n"]}, {"number": 29161, "title": "tf.keras predict stuck with Sequence when using multi-processing", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: TITAN\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nHi,\r\n\r\nWhen using tf.keras with a custom Sequence, the program hangs during predict (with multi-processing). \r\nI was able to reproduce the issue with a simple NN that contains a single Dense layer.\r\nThis happens after setting the weights of the layer and running predict with multi-processing.\r\nWhen commenting the 'set_weights' line or running with multi-threading, the program does not hang.\r\nIssue exists also in 1.14.0-rc0,\r\nSame code works OK with tensorflow 1.12.0 and 2.0.0a0.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nfrom tensorflow import keras\r\n\r\nINPUT_SIZE = 3\r\nDENSE_OUTPUTS = 2\r\nNUM_OF_SAMPLES = 1000\r\nBATCH_SIZE = 2\r\nNUM_OF_BATCHES = 5\r\n\r\n\r\nclass DummySequence(keras.utils.Sequence):\r\n\r\n    def __len__(self):\r\n        return NUM_OF_SAMPLES // BATCH_SIZE\r\n\r\n    def __getitem__(self, index):\r\n        data = [np.full(shape=(INPUT_SIZE,), fill_value=(index*BATCH_SIZE + i)) for i in range(BATCH_SIZE)]\r\n        labels = [np.full(shape=(DENSE_OUTPUTS,), fill_value=(index*BATCH_SIZE + i))*INPUT_SIZE for i in range(BATCH_SIZE)]\r\n        return np.stack(data), np.stack(labels)\r\n\r\n\r\n\r\nx = keras.layers.Input(shape=(INPUT_SIZE,))\r\ndense_layer = keras.layers.Dense(DENSE_OUTPUTS)\r\ny = dense_layer(x)\r\nmodel = keras.Model(x, y)\r\n\r\n# remove comment in tf 1.12\r\n#model.compile(optimizer=\"sgd\", loss=keras.losses.mean_squared_error)\r\n\r\nshapes = [v.shape for v in dense_layer.weights]\r\ndense_layer.set_weights([np.full(shape=shapes[0], fill_value=1.0), np.full(shape=shapes[1], fill_value=0.0)])\r\n\r\nseq = DummySequence()\r\n\r\nworkers = 5\r\nmultiprocessing = True\r\n# works with multi-threaing\r\n#multiprocessing = False\r\nprint(\"running predict with multiprocessing: {}\".format(multiprocessing))\r\nres = model.predict(seq, workers=workers, use_multiprocessing=multiprocessing, steps=NUM_OF_BATCHES)\r\nprint(\"predict # of results: {}\\nresults:\\n{}\".format(len(res), res))\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I was able to reproduce the reported issue on google colab with Tf 1.13.1. Thanks!", "Hi,\r\n\r\nAny update?\r\n\r\nThanks.", "@mwin76 I think it was resolved sometime ago. I have tested in nightly builds (1.15 and 2.0b1) and don't see any issue. Please check the gist with [TF2.0](https://colab.sandbox.google.com/gist/jvishnuvardhan/b466a0758214055628c16026d68125d8/tf_29161_tf2p0b1.ipynb) and [tf-nightly](https://colab.sandbox.google.com/gist/jvishnuvardhan/220c6d9555b467f171b56ebbe36c6b18/tf_29161_tf1p15.ipynb). \r\n\r\nI am closing this issue as it was resolved. Please reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29161\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29161\">No</a>\n", "Hi,\r\n\r\nI tested it with tf-nightly-gpu and it is stuck.\r\n\r\nThanks,\r\nMattan.", "@mwin76 Can you check my gists or provide a gist/screenshot showing the issue? Thanks!", "Hi,\r\n\r\nTried this in colab and it is stuck. the code was the same as the code in your gist just replaced the \"pip install tf-nightly\" with \"pip install **tf-nightly-gpu**\"\r\nWhen killing the job I get the following stack:\r\n\r\nrunning predict with multiprocessing: True\r\nE0728 05:34:49.872965 140443983652736 ultratb.py:152] Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-5127600acadc>\", line 41, in <module>\r\n    res = model.predict(seq, workers=workers, use_multiprocessing=multiprocessing, steps=NUM_OF_BATCHES)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 920, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 648, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 221, in model_iteration\r\n    batch_data = _get_next_batch(generator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 363, in _get_next_batch\r\n    generator_output = next(generator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 779, in get\r\n    inputs = self.queue.get(block=True).get()\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 638, in get\r\n    self.wait(timeout)\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\r\n    self._event.wait(timeout)\r\n  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\r\n    signaled = self._cond.wait(timeout)\r\n  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\r\n    waiter.acquire()\r\nKeyboardInterrupt\r\n\r\nThanks,\r\nMattan.", "Hi @jvishnuvardhan. I tested your gist with 1.15.0-dev20190728 and it still doesn't work. Let me know if you need more information.\r\n\r\nThanks", "@mwin76 I could reproduce the issue with `tf-nightly-gpu` but TF2.0 has no issues. We will try to find the root-cause of the issue in TF1.x nightly. Thanks", "Is there any progress on the issue? \r\nThanks", "I faced the same issue and It seem to resolve it with adding this : \r\n```\r\nfrom tensorflow.python.keras import backend as K\r\nimport tensorflow as tf\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = tf.Session(config=config)\r\nK.set_session(session)\r\n```\r\nIt seem to be unrelated problem but it's works.", "Hi,\r\n\r\nThanks.\r\nUsing config.gpu_options.allow_growth works however if you clear the session and reload the model it gets stuck\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow import keras\r\n#import keras\r\n\r\nINPUT_SIZE = 3\r\nDENSE_OUTPUTS = 2\r\nNUM_OF_SAMPLES = 1000\r\nBATCH_SIZE = 2\r\nNUM_OF_BATCHES = 5\r\n\r\n\r\nclass DummySequence(keras.utils.Sequence):\r\n\r\n    def __len__(self):\r\n        return NUM_OF_SAMPLES // BATCH_SIZE\r\n\r\n    def __getitem__(self, index):\r\n        data = [np.full(shape=(INPUT_SIZE,), fill_value=(index*BATCH_SIZE + i)) for i in range(BATCH_SIZE)]\r\n        labels = [np.full(shape=(DENSE_OUTPUTS,), fill_value=(index*BATCH_SIZE + i))*INPUT_SIZE for i in range(BATCH_SIZE)]\r\n        return np.stack(data), np.stack(labels)\r\n\r\n\r\nclass CountBatchesCallback(keras.callbacks.Callback):\r\n\r\n    def __init__(self):\r\n        super(CountBatchesCallback, self).__init__()\r\n\r\n        self.batches = 0\r\n\r\n    def on_batch_begin(self, batch, logs=None):\r\n        self.batches += 1\r\n\r\n\r\ndef get_model():\r\n    x = keras.layers.Input(shape=(INPUT_SIZE,))\r\n    dense_layer = keras.layers.Dense(DENSE_OUTPUTS)\r\n    y = dense_layer(x)\r\n    model = keras.Model(x, y)\r\n    model.compile(optimizer=\"sgd\", loss=keras.losses.mean_squared_error)\r\n    shapes = [v.shape for v in dense_layer.weights]\r\n    dense_layer.set_weights([np.full(shape=shapes[0], fill_value=1.0), np.full(shape=shapes[1], fill_value=0.0)])\r\n    return model\r\n\r\n\r\ndef run_fit_and_predict(model):\r\n    seq = DummySequence()\r\n    steps = 5\r\n    batch_counter_callback = CountBatchesCallback()\r\n    use_multiprocessing = True\r\n    workers = 5\r\n    print(\"running fit with {} steps\".format(steps))\r\n    model.fit_generator(\r\n        seq,\r\n        epochs=1,\r\n        steps_per_epoch=steps,\r\n        use_multiprocessing=use_multiprocessing,\r\n        # workers=workers,\r\n        callbacks=[batch_counter_callback]\r\n    )\r\n    print(\"batches processed: {}\".format(batch_counter_callback.batches))\r\n    results = model.predict_generator(\r\n        seq,\r\n        use_multiprocessing=use_multiprocessing,\r\n        # workers=workers,\r\n        steps=steps\r\n    )\r\n    print(\"\\npredict\\nexpected number of results: {}.\\nactual number of results: {}.\\npredictions:\\n{}\".format(\r\n        steps * BATCH_SIZE, len(results), results)\r\n    )\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = get_model()\r\n    print(\"\\n************************ Running run_fit_and_predict first ************************\")\r\n    run_fit_and_predict(model)\r\n    print(\"\\n************************ clear session ************************\")\r\n    keras.backend.clear_session()\r\n    model = get_model()\r\n    print(\"\\n************************ Running run_fit_and_predict second ************************\")\r\n    run_fit_and_predict(model)\r\n\r\n\r\n```", "test_predict = model.predict_generator(\r\n    test_generator,\r\n    max_queue_size=64,\r\n    workers=4, \r\n    use_multiprocessing=True)\r\n\r\nException in thread Thread-24:\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 619, in _run\r\n    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 600, in pool_fn\r\n    workers, initializer=init_pool_generator, initargs=(seqs, None))\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\context.py\", line 119, in Pool\r\n    context=self.get_context())\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\pool.py\", line 176, in __init__\r\n    self._repopulate_pool()\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\pool.py\", line 241, in _repopulate_pool\r\n    w.start()\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\popen_spawn_win32.py\", line 89, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n  File \"D:\\Anaconda\\envs\\tfgpu\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nTypeError: can't pickle _thread.lock objects", "@mwin76 Thanks for the issue!\r\n\r\nThis looks like it is fixed in the latest tf-nightly, please give it a try: `pip install -U tf-nightly`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29161\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29161\">No</a>\n", "@omalleyt12 I'm facing the exact same issue on v2.1.0.\r\n\r\nI plan on giving `tf-nightly` a try. But will it impact my previously trained models if I upgrade?", "Hi, I am facing the exact same issue with tf-nightly==2.2.0.dev20200324. A sequential multiprocessing model woudn't start re-training.\r\n```\r\nFile \"/home/sumit/.conda/envs/sopi/lib/python3.7/threading.py\", line 296, in wait waiter.acquire()\r\n```", "Any news? I'm facing the same problem here.", "Any updates on this? I am also facing a similar issue while trying to do model.predict() with multi-processing. I made sure that the tensorflow graph and tensorflow session are unique for each process.", "My multi-process case: I can perfectly run the same code on my Windows machine, however, the same code cannot work on Ubuntu. It seems like it is caused by the differences in creating new processes between Windows and Linux. \r\nIn Linux, fork() is called to create a new process by default, and you can manually change to spawn(), which will create a new process from zero instead of sharing some environmental variables between processes.\r\n\r\nYou can try adding the following codes to the head, which will force Linux to use the spawn method:\r\n```\r\nimport multiprocess.context as ctx\r\nctx._force_start_method('spawn')\r\n```\r\n\r\nReference: (https://stackoverflow.com/questions/40615795/pathos-enforce-spawning-on-linux)", "It hangs on TF 1.15.2 or 1.15.5., works OK in TF 2.1.0, 2.3.0. Python 3.6.9.\r\n\r\nWhen I commented out the `dense_layer.set_weights()` call in the original code in the first comment it works, otherwise it hangs. That piece of code runs a TF session.\r\n\r\nIt seems that the initializer of the Pool, the `init_pool_generator()` function is not called. Thus it waits for the results indefinitely.\r\n\r\nI tried to add logging from the multiprocessing module:\r\n```\r\nimport logging\r\nfrom multiprocessing.util import log_to_stderr\r\n\r\nlog_to_stderr(level=logging.DEBUG)\r\n```\r\n\r\nIt stops after:\r\n```\r\n[DEBUG/MainProcess] added worker\r\n```\r\n\r\nI also tried to change from `fork` to `swawn`. Then it still fails but the worker get created again and again in a loop:\r\n\r\n```\r\n[DEBUG/MainProcess] added worker\r\n[DEBUG/MainProcess] cleaning up worker 0\r\n[DEBUG/MainProcess] added worker\r\n[DEBUG/MainProcess] cleaning up worker 0\r\n...\r\n```\r\n\r\nRunning on MacOS with Python 3.7.10, tensorflow-cpu 1.15.2:\r\n\r\n```\r\nlibc++abi.dylib: terminating with uncaught exception of type std::__1::system_error: thread::join failed: No such process\r\n...\r\n```\r\n\r\nWhen using the `spawn` method and guarding the code beyond definition of the sequence with `if __name__ == '__main__'` the code works.\r\n\r\nSo it looks like that after works Tensorflow tries to join on some thread from the main process which got copied but is not available in the child anymore.\r\n\r\nAdding the `allow_growth` option to Session helped even in the `fork` case."]}, {"number": 29160, "title": "[TF 2.0 API Docs] Some \"Defied in\" links are broken", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRUCell\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM\r\nAlso including (but probably not limited to) other recurrent Keras layers.\r\n## Description of issue (what needs changing):\r\nIt seems that API docs are generated using `tf-nightly` builds (`master` branch). However, links that define source code of API endpoints lead to `tensorflow==2.0.0-alpha0` build (`r2.0` branch), however using file structure of `master` branch. It causes some 404 errors (see example below).\r\n### Clear description\r\nThis problem affects (at least) documentation of all the recurrent tf.keras.layers. For example, on [tf.keras.GRU page](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU) section \"Defined in\" leads to [https://github.com/tensorflow/tensorflow/tree/**r2.0**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers/recurrent_v2.py). \r\nThis file does not exist in `r2.0`, but it exists in `master`: [https://github.com/tensorflow/tensorflow/tree/**master**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras/layers/recurrent_v2.py)\r\n### Correct links\r\n**Is the link to the source code correct?**\r\nNo - see the section above for details.\r\n### Submit a pull request?\r\nI'm pretty sure that docs generation script is ok, but there's some kind of misconfiguration problem.", "comments": ["The issue seems to be resolved."]}, {"number": 29159, "title": "TFLite GPU supported ops not working", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus3, Poco F1\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): NIL\r\n- GCC/Compiler version (if compiling from source): NIL\r\n- CUDA/cuDNN version: NIL\r\n- GPU model and memory: NIL\r\n\r\n**Describe the current behavior**\r\nSome of the GPU supported TFLite ops, does not run in GPU properly. On CPU it behaves properly and each time with a different combination even with supported ops, the behavior of the model changes and even not able to benchmark it to find the issues. Moreover, fall back mechanism is also not followed, if it is not running in GPU.\r\n\r\n**Describe the expected behavior**\r\nTFLite GPU supported ops, must run in GPU. If there are unsupported ops in the graph for which execution cannot be done, execution must fall back to CPU. \r\n\r\n**Code to reproduce the issue**\r\nWe have tried appending some nodes on top of Deeplab gpu converted model. All appended nodes are still supported ops by GPU Delegate. We have attached with this issue, the graph and the error log while trying to benchmark the TFLite model.\r\n\r\n**Attachments**\r\n\r\n**Error Log**\r\n\r\n**Command:**\r\n`adb shell taskset f0 /data/local/tmp/benchmark_model --graph=/data/local/tmp/retest_9_27.tflite --enable_op_profiling=true --use_gpu=true`\r\n\r\n**Output**\r\nSTARTING!\r\nMin num runs: [50]\r\nMin runs duration (seconds): [1]\r\nInter-run delay (seconds): [-1]\r\nNum threads: [1]\r\nBenchmark name: []\r\nOutput prefix: []\r\nMin warmup runs: [1]\r\nMin warmup runs duration (seconds): [0.5]\r\nGraph: [/data/local/tmp/retest_9_27.tflite]\r\nInput layers: []\r\nInput shapes: []\r\nUse nnapi : [0]\r\nUse legacy nnapi : [0]\r\nUse gpu : [1]\r\nAllow fp16 : [0]\r\nEnable op profiling: [1]\r\nLoaded model /data/local/tmp/retest_9_27.tflite\r\nresolved reporter\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: TfLiteGpuDelegate Prepare: Dimension can not be reduced to linear.\r\nERROR: Node number 93 (TfLiteGpuDelegate) failed to prepare.\r\n\r\nFailed to apply GPU delegate.\r\nAborted \r\n\r\n**File to reproduce the issue**\r\n[retest_9_27.tflite.zip](https://github.com/tensorflow/tensorflow/files/3235853/retest_9_27.tflite.zip)\r\n", "comments": ["@SanthoshRajendiran \r\n\r\nThanks for sharing the network.  I don't know which op requires is, but according to your log\r\n\r\n> ERROR: TfLiteGpuDelegate Prepare: Dimension can not be reduced to linear.\r\n\r\nand the function which emits that error message `Status SetAllDimensions<Linear>(const TfLiteIntArray* dimensions, Linear* shape)` (in `tensorflow/lite/delegates/gpu/common/model_builder.cc`), it looks like you have a tensor that is fed into an op that expects a linear tensor in the shape of `[1, 1, 1, x]` but that is not.  Do you think you can find out who calls this function (which op) and what the actual requested tensor shape is?", "It was expecting a linear tensor, and we tried creating a constant in its place hoping that will be straightforward doing our work, as we were expecting some basic mathematical operations..", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29159\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29159\">No</a>\n"]}, {"number": 29158, "title": "XLA int8 convolution", "body": "\r\n1 Allow int8 for cudnnConvolutionForward and cudnnConvolutionBiasActi\u2026\r\n1.1 Add cast instruction to convert int8 bias to float in cudnn_fused_conv_rewriter.\r\n1.2 Add a new transform cudnn_pad_for_integer_convolution to pad input and output\r\nfeature maps to multiple of 4 and pad weights, bias, and side inputs accordingly\r\n2 Add sanity checks for configurations according to cudnn document.\r\n2.1 Input/output feature maps must be multiple of 4.\r\n2.2 Only _IMPLICIT_PRECOMP_GEMM is supported.\r\n2.3 All tensor layouts must be NHWC.\r\n3 Set convolution layout constraints to NHWC for integer convolution.\r\n4 Remove checks for same types in convolution shape inference to allow mixing int8.\r\nacitvation with float bias.\r\n5 Refactor cudnn_pad_for_tensor_cores to share code with cudnn_pad_for_integer_convolution.\r\n5.1 Create a pimpl class CudnnConvPadFeatures to host most common code.\r\n5.2 Define callbacks to resolve desired tensor shapes and use CudnnConvPadFeatures in\r\ncudnn_pad_for_tensor_cores.cc and cudnn_pad_for_integer_convolution.cc.\r\n6 Tests\r\n6.1 Add one unit test to cudnn_conv_rewriter_test.cc for integer forward convolution cudnn API replacement.\r\n6.2 Add unit tests for the newly added CudnnPadForIntegerConvolutions.\r\n6.3 Modify tests in cudnn_fused_conv_rewriter_test.cc.\r\n6.3.1 Add S8 to the type list for testing.\r\n6.3.2 Allow integer value scales for S8 tests.\r\n6.3.3 Skip numerical verification for S8 cases till the int8 HLO evaluator visitor has proper semantics.", "comments": ["@timshen91 @jlebar  I have updated the PR with new commits, implementing the in8-to-float convolution semantics and addressing comments from Tim.  Please let me know your new comments.", "@timshen91 Hi Tim, I saw Justin dismissed the review a week ago.  Will you be able to review it?  It's been open for a long time.  Thank you.", "Sorry for the excessive delay on review. I was distracted last month, and mostly out this month.\r\n\r\nFirst off, thanks for the growing amount of work done here. I have some minor comments, but I haven't done reviewing. The PR is on the right track.\r\n\r\nAlso, in general we prefer small PRs that are potentially dependent. This PR looks likely to be divided into multiple PRs:\r\n* stream_executor change\r\n* evaluator change\r\n* convolution runner change\r\n* pattern matcher change and other changes.\r\n\r\nCan you split it if it's relatively easy to do?", "Sorry for the excessive delay on review. I was distracted last month, and mostly out this month.\r\n\r\nFirst off, thanks for the growing amount of work done here. I have some minor comments, but I haven't done reviewing. The PR is on the right track.\r\n\r\nAlso, in general we prefer small PRs that are potentially dependent. This PR looks likely to be divided into multiple PRs:\r\n* stream_executor change\r\n* evaluator change\r\n* convolution runner change\r\n* pattern matcher change and other changes.\r\n\r\nCan you split it if it's relatively easy to do?", "@timshen91 Thank you for the response.  I will try splitting the commit and merging changes with the HEAD in new PRs.  I may have to defer most tests till the last commit.  Meanwhile, please let me know your comments on the current changes.", "@timshen91 I have created 4 PRs to replace this one: https://github.com/tensorflow/tensorflow/pull/30761,\r\nhttps://github.com/tensorflow/tensorflow/pull/30762, https://github.com/tensorflow/tensorflow/pull/30771, and https://github.com/tensorflow/tensorflow/pull/30783.  \r\nMost of your comments have been addressed, except one about passing StreamExecutor* to CudnnPadForConvolutions.  Please let me know if you have further comments.  I will close this one, once we both move on to the new PRs.", "Can one of the admins verify this patch?", "Close this PR, as we have moved the necessary changes to https://github.com/tensorflow/tensorflow/pull/30762, https://github.com/tensorflow/tensorflow/pull/30771, and https://github.com/tensorflow/tensorflow/pull/30783."]}, {"number": 29157, "title": "Add implementation of LAYER conv1d_transpose", "body": "Would it be possible that someone implements a conv1d_transpose layer? \r\n\r\nThere is a tf.contrib.nn.conv1d_transpose implementation but it has many problems, such as the need for hardcoding batch size. \r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.3\r\n- Are you willing to contribute it (Yes/No): Yes.\r\n\r\n\r\n**Will this change the current api? How?**\r\nIt will create a new implementation of a layer.\r\n\r\n**Who will benefit with this feature?**\r\nMany users, in particular people working on 1d time series, etc. \r\n", "comments": ["Fixed. Closing it."]}, {"number": 29156, "title": "the cloud TPU training is trapped and do nothing ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux instance-1 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip installed\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: NO GPU\r\n\r\n**Describe the current behavior** \r\ntraining my model on the cloud TPU(3.8) through a VM instance.\r\nThe log is:\r\n```\r\n2019-05-30 02:33:14.644845: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:354] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\r\nINFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\r\nINFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\r\nINFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\r\n\r\nINFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\r\n\r\nINFO:tensorflow:Init TPU system\r\nINFO:tensorflow:Init TPU system\r\nINFO:tensorflow:Initialized TPU in 1 seconds\r\nINFO:tensorflow:Initialized TPU in 1 seconds\r\nINFO:tensorflow:Starting infeed thread controller.\r\nINFO:tensorflow:Starting infeed thread controller.\r\nINFO:tensorflow:Starting outfeed thread controller.\r\nINFO:tensorflow:Starting outfeed thread controller.\r\nINFO:tensorflow:Enqueue next (80) batch(es) of data to infeed.\r\nINFO:tensorflow:Enqueue next (80) batch(es) of data to infeed.\r\nINFO:tensorflow:Dequeue next (80) batch(es) of data from outfeed.\r\nINFO:tensorflow:Dequeue next (80) batch(es) of data from outfeed.\r\n\r\n```\r\nIt looks like everything is ok.But after a period of waiting,I found there was \r\nno new checkpoint file wrote out on the bucket.\r\nTo my supprise is that **the monitor showing the memory usage of the TPU is about 6G,the cpu usage of the TPU is 0 and the cpu usage of the host VM is 0 too**!\r\nNow that what are you doing my host VM and the costly TPU?\r\nAnyone can help?\r\n\r\n", "comments": ["![1944686123](https://user-images.githubusercontent.com/14851411/58646074-36f55b00-8337-11e9-9dfc-948485aa6cba.jpg)\r\nThe upper is running on my local PC with a Nvidia GPU card(batch_size:16) and the lower part is the cloud TPU running.\r\nIt's really really slow on TPU(more than 10 min,batch_size:4 per shard). It looks like being trapped...", "@MaeThird In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\n", "after ten hours' torment I create a new node installed with tf-1.14.1.dev and it works as expect now.", "@MaeThird Glad to hear it worked, hence this issue will be closed"]}, {"number": 29155, "title": "when i use conv algorithm", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Debian\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1,1.14.0\uff0c2.0.0a0\uff0c1.9.0\r\n- Python version:3.7,3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:Cuda 10/7.5.0,7.4.2,7.4.1,7.4.0,Cuda 9 can't support 2060\r\n- GPU model and memory:rtx 2060 6GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nconda activate base\r\n2.0.0-alpha0\r\n2019-05-29 19:58:31.543654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-05-29 19:58:31.557759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-05-29 19:58:31.670769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-05-29 19:58:31.672348: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b57a0a60 executing computations on platform CUDA. Devices:\r\n2019-05-29 19:58:31.672364: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): Graphics Device, Compute Capability 7.5\r\n2019-05-29 19:58:31.693201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz\r\n2019-05-29 19:58:31.693619: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b580db30 executing computations on platform Host. Devices:\r\n2019-05-29 19:58:31.693637: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): , \r\n2019-05-29 19:58:31.693791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties:\r\nname: Graphics Device major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 5.76GiB freeMemory: 5.17GiB\r\n2019-05-29 19:58:31.693804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0\r\n2019-05-29 19:58:31.693844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-05-29 19:58:31.694402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-29 19:58:31.694413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021] 0\r\n2019-05-29 19:58:31.694419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0: N\r\n2019-05-29 19:58:31.694516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4990 MB memory) -> physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nNumber of training examples: 60000\r\nNumber of test examples: 10000\r\nEpoch 1/5\r\n2019-05-29 19:58:32.786674: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-29 19:58:36.114172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-05-29 19:58:36.288348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-05-29 19:58:36.934479: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-05-29 19:58:36.945020: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-05-29 19:58:36.945127: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n[[{{node conv2d/Conv2D}}]]\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@proszx In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Could you provide more details about the issue. Thanks!\r\n", "> @proszx\u4e3a\u4e86\u52a0\u5feb\u6545\u969c\u6392\u9664\u8fc7\u7a0b\uff0c\u8bf7\u63d0\u4f9b\u4e00\u4e2a\u4ee3\u7801\u7247\u6bb5\u6765\u91cd\u73b0\u6b64\u5904\u62a5\u544a\u7684\u95ee\u9898\u3002\u60a8\u80fd\u63d0\u4f9b\u6709\u5173\u8be5\u95ee\u9898\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\u5417\uff1f\u8c22\u8c22\uff01\r\n\r\n i just run the demo cnn of tensorflow2.0.0a0(fashion mnist), \r\nand same problems on tensorflow from 1.13.1,1.14\r\n\r\nbeside 20\u2018s gpu doesn't support cuda9,i installed it but it's failed.\r\ni run with same netowrk structure by torch, and it's ok\r\nand nearly all 20's gpu has same problem(google knows ~)\r\n\r\nsorry for bothering you and thx\r\n\r\nhere is the code for tf 2.0.0a0\r\n\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nimport math\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tqdm\r\nimport tqdm.auto\r\ntqdm.tqdm = tqdm.auto.tqdm\r\n\r\ndataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\r\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\r\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \r\n               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\r\nnum_train_examples = metadata.splits['train'].num_examples\r\nnum_test_examples = metadata.splits['test'].num_examples\r\nprint(\"Number of training examples: {}\".format(num_train_examples))\r\nprint(\"Number of test examples:     {}\".format(num_test_examples))\r\ndef normalize(images, labels):\r\n    images = tf.cast(images, tf.float32)  # Casts a tensor to a new type\r\n    images /= 255\r\n    return images, labels\r\n\r\n\r\ntrain_dataset =  train_dataset.map(normalize)\r\ntest_dataset  =  test_dataset.map(normalize)\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\r\n                           input_shape=(28, 28, 1)),\r\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\r\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\r\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam', \r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nBATCH_SIZE = 32\r\ntrain_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\r\ntest_dataset = test_dataset.batch(BATCH_SIZE)\r\n\r\nmodel.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\r\ntest_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\r\nprint('Accuracy on test dataset:', test_accuracy)\r\n\r\nhere is the code for 1.13.1\r\n\r\n\r\nimport tensorflow as tf \r\nimport tensorflow.examples.tutorials.mnist.input_data as input_data\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)     \r\nx = tf.placeholder(tf.float32, [None, 784])                        \r\ny_actual = tf.placeholder(tf.float32, shape=[None, 10])            \r\n\r\ndef weight_variable(shape):\r\n  initial = tf.truncated_normal(shape, stddev=0.1)\r\n  return tf.Variable(initial)\r\n\r\n\r\ndef bias_variable(shape):\r\n  initial = tf.constant(0.1, shape=shape)\r\n  return tf.Variable(initial)\r\n  \r\n\r\ndef conv2d(x, W):\r\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\n\r\ndef max_pool(x):\r\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\nx_image = tf.reshape(x, [-1,28,28,1])         \r\nW_conv1 = weight_variable([5, 5, 1, 32])      \r\nb_conv1 = bias_variable([32])       \r\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)     \r\nh_pool1 = max_pool(h_conv1)                                 \r\n\r\nW_conv2 = weight_variable([5, 5, 32, 64])\r\nb_conv2 = bias_variable([64])\r\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)     \r\nh_pool2 = max_pool(h_conv2)                                   \r\n\r\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\r\nb_fc1 = bias_variable([1024])\r\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])              \r\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)    \r\n\r\nkeep_prob = tf.placeholder(\"float\") \r\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)                 \r\n\r\nW_fc2 = weight_variable([1024, 10])\r\nb_fc2 = bias_variable([10])\r\ny_predict=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)  \r\ncross_entropy = -tf.reduce_sum(y_actual*tf.log(y_predict))     \r\ntrain_step = tf.train.GradientDescentOptimizer(1e-3).minimize(cross_entropy)    \r\ncorrect_prediction = tf.equal(tf.argmax(y_predict,1), tf.argmax(y_actual,1))    \r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))                \r\nsess=tf.InteractiveSession()                          \r\nsess.run(tf.initialize_all_variables())\r\nfor i in range(20000):\r\n  batch = mnist.train.next_batch(50)\r\n  if i%100 == 0:                 \r\n    train_acc = accuracy.eval(feed_dict={x:batch[0], y_actual: batch[1], keep_prob: 1.0})\r\n    print('step',i,'training accuracy',train_acc)\r\n    train_step.run(feed_dict={x: batch[0], y_actual: batch[1], keep_prob: 0.5})\r\n\r\ntest_acc=accuracy.eval(feed_dict={x: mnist.test.images, y_actual: mnist.test.labels, keep_prob: 1.0})\r\nprint(\"test accuracy\",test_acc)", "@proszx It worked for Tensorflow 2.0.0.alpha CPU version and GPU version.have a look on colab link for [CPU](https://colab.sandbox.google.com/drive/1pCSvY0-PfFAZu8MnTco5X1-gxTCi4wi0#scrollTo=n_a432xtShru) and [GPU](https://colab.sandbox.google.com/drive/1Z9UQAluZBRWOJ2dW61uu8qBJ88-AJSFy#scrollTo=vzHHnVM2Tbxy). Please let me know if still stuck. Thanks!  ", "@proszx I tried to reproduce the issue on Tensorflow 1.13.1 but i got following error\r\nValueError: Dimensions must be equal, but are 7764 and 3136 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,7764], [3136,1024]. Thanks!", "\r\n\r\n\r\n\r\n> @proszx It worked for Tensorflow 2.0.0.alpha CPU version and GPU version.have a look on colab link for [CPU](https://colab.sandbox.google.com/drive/1pCSvY0-PfFAZu8MnTco5X1-gxTCi4wi0#scrollTo=n_a432xtShru) and [GPU](https://colab.sandbox.google.com/drive/1Z9UQAluZBRWOJ2dW61uu8qBJ88-AJSFy#scrollTo=vzHHnVM2Tbxy). Please let me know if still stuck. Thanks!\r\n\r\ni can't open that and i'm not sure that device is 20 series GPU\r\nand problem is stills stuck me\r\nok, I just know torch is ok for this problem.\r\n", "@reedwm would you help to take a look? Thanks.", "Closing, as this looks like a duplicate of #24496. It looks like there is a workaround in [this comment](https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29155\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29155\">No</a>\n"]}, {"number": 29154, "title": "[ROCm] Adding a macro wrapper for the ROCm/CUDA routine to get the error string", "body": "This PR adds a macro wrapper `GPU_GET_ERROR_STRING` that resolves to the GPU platform specific error string function.\r\n\r\nI tdo not know whether or not, the name `GPU_GET_ERROR_STRING` conforms to the TF coding standards, and any suggestions to change it something more conforming/consistent are welcome.\r\n\r\nThis is a trivial change, please review and merge....thanks\r\n\r\n----------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": ["@chsigg gentle ping\r\n\r\nalso thank you for all the PRs you have merged so far. ", "@chsigg this PR seems to have gotten stuck in the merge pipeline :( "]}, {"number": 29153, "title": "[ROCm] Making some helper classes from cuda_solvers.h visible within ROCm build", "body": "This PR makes the following helper classes (from `cuda_solvers.h`) visible within the ROCm build\r\n * ScratchSpace\r\n * HostLapaclInfo\r\n * DeviceLapackInfo\r\n\r\nThese class(es) are used in the implementation of other ops (where_op, segment_reduction_ops, etc) for which we will be filing PRs to upstream ROCm support. But before we can do that, we need to make these helper classes visible within the ROCm build\r\n\r\n--------------------------------------\r\n\r\n@tatianashp @whchung \r\n", "comments": ["@gbaned  gentle ping\r\n\r\nplease review and merge...thanks"]}, {"number": 29152, "title": "How to test a saved model trained with tf.train.batch?", "body": "By calling\r\n\r\ngraph.get_tensor_by_name(\"output:0\")\r\nI found that it returns a tensor shaped [batch_size,num]\uff0cHow to test a saved model trained with tf.train.batch ?", "comments": ["@guoguoguilai Closing since its a duplicate of  [#29110](https://github.com/tensorflow/tensorflow/issues/29110). Feel free to reopen if the solution provided on that thread doesn't work Distributed for you. Thanks!\r\n\r\n"]}, {"number": 29151, "title": "Training time for one epoch on TF 1.12 is almost 2 times slower than TF 1.5", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04) :Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.5 and 1.12\r\n- Keras version: 2.2.4\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:CUDA 9.2/ cuDNN 7600\r\n- GPU model and memory: T4 GPU with 15079MB memory\r\n\r\n**Describe the current behavior**\r\nTraining time for one epoch on TF 1.12 is almost 2 times slower than TF 1.5 when using Keras layer.\r\nI also tried to compare the training time using pure tensorflow layers, the speed is similar for TF1.12, TF1.5 and TF1.13. But I don't understand why the same Keras version will influent training time with different TF version\r\n\r\n\r\n**Describe the expected behavior**\r\nTraining time for one epoch on TF 1.12 should be similar to  TF 1.5\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport keras\r\nimport numpy as np\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\ntrain_images = train_images.repeat(10, axis=0)\r\ntrain_labels = train_labels.repeat(10, axis=0)\r\n\r\nmodel = keras.Sequential([\r\n    keras.layers.Flatten(input_shape=(28, 28)),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=5, batch_size=60000)\r\n```\r\n\r\n**Other info / logs**\r\non TF 1.5 machine:\r\n```\r\nUsing TensorFlow backend.\r\nEpoch 1/5\r\n2019-05-29 18:11:32.262359: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\n2019-05-29 18:11:32.485841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-05-29 18:11:32.486163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: \r\nname: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 14.73GiB freeMemory: 14.50GiB\r\n2019-05-29 18:11:32.486194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\n600000/600000 [==============================] - 4s 6us/step - loss: 10.4676 - acc: 0.3154\r\nEpoch 2/5\r\n600000/600000 [==============================] - 3s 4us/step - loss: 7.8949 - acc: 0.4803\r\nEpoch 3/5\r\n600000/600000 [==============================] - 3s 5us/step - loss: 7.5721 - acc: 0.4956\r\nEpoch 4/5\r\n600000/600000 [==============================] - 2s 4us/step - loss: 7.3566 - acc: 0.5021\r\nEpoch 5/5\r\n600000/600000 [==============================] - 3s 4us/step - loss: 6.2275 - acc: 0.5585\r\n```\r\nOn TF 1.12 machine:\r\n```\r\nUsing TensorFlow backend.\r\nEpoch 1/5\r\n2019-05-29 18:12:10.157740: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-05-29 18:12:10.397594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-05-29 18:12:10.398655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 14.73GiB freeMemory: 14.50GiB\r\n2019-05-29 18:12:10.398702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2019-05-29 18:12:10.938390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-29 18:12:10.938490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2019-05-29 18:12:10.938500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2019-05-29 18:12:10.938768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14028 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\n600000/600000 [==============================] - 6s 10us/step - loss: 12.2835 - acc: 0.2249\r\nEpoch 2/5\r\n600000/600000 [==============================] - 5s 8us/step - loss: 9.9552 - acc: 0.3741\r\nEpoch 3/5\r\n600000/600000 [==============================] - 4s 7us/step - loss: 9.8548 - acc: 0.3857\r\nEpoch 4/5\r\n600000/600000 [==============================] - 5s 9us/step - loss: 9.4893 - acc: 0.4046\r\nEpoch 5/5\r\n600000/600000 [==============================] - 5s 8us/step - loss: 8.4112 - acc: 0.4727\r\n```", "comments": ["I also tried to compare the training time using pure tensorflow layers, the speed is similar for TF1.12, TF1.5 and TF1.13. But I don't understand why the same Keras version will influent training time with different TF version", "I used google colab and found that performance of TF 1.12 is way superior than TF 1.5. Please use google colab to confirm since the env can vary.\r\n\r\nTF 1.12\r\n```python\r\nUsing TensorFlow backend.\r\nEpoch 1/5\r\n600000/600000 [==============================] - 18s 30us/step - loss: 9.9180 - acc: 0.3484\r\nEpoch 2/5\r\n600000/600000 [==============================] - 18s 30us/step - loss: 7.2610 - acc: 0.5190\r\nEpoch 3/5\r\n600000/600000 [==============================] - 18s 30us/step - loss: 5.0224 - acc: 0.6543\r\nEpoch 4/5\r\n600000/600000 [==============================] - 18s 30us/step - loss: 4.6111 - acc: 0.6779\r\nEpoch 5/5\r\n600000/600000 [==============================] - 18s 30us/step - loss: 4.5634 - acc: 0.6751\r\n```\r\nTF 1.5\r\n```python\r\nUsing TensorFlow backend.\r\nEpoch 1/5\r\n600000/600000 [==============================] - 29s 48us/step - loss: 9.7431 - acc: 0.3707\r\nEpoch 2/5\r\n600000/600000 [==============================] - 29s 48us/step - loss: 8.5936 - acc: 0.4560\r\nEpoch 3/5\r\n600000/600000 [==============================] - 29s 48us/step - loss: 8.4223 - acc: 0.4663\r\nEpoch 4/5\r\n600000/600000 [==============================] - 29s 48us/step - loss: 8.3482 - acc: 0.4704\r\nEpoch 5/5\r\n600000/600000 [==============================] - 29s 48us/step - loss: 8.2970 - acc: 0.4734\r\n```\r\nTF nightly : 1.14.1-dev20190531\r\n```python\r\nEpoch 1/5\r\n600000/600000 [==============================] - 11s 18us/step - loss: 10.9316 - acc: 0.3083\r\nEpoch 2/5\r\n600000/600000 [==============================] - 9s 15us/step - loss: 8.7628 - acc: 0.4512\r\nEpoch 3/5\r\n600000/600000 [==============================] - 9s 15us/step - loss: 8.5598 - acc: 0.4641\r\nEpoch 4/5\r\n600000/600000 [==============================] - 9s 15us/step - loss: 8.4503 - acc: 0.4675\r\nEpoch 5/5\r\n600000/600000 [==============================] - 9s 15us/step - loss: 8.0209 - acc: 0.4862\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29151\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29151\">No</a>\n"]}, {"number": 29150, "title": "[ROCm] Add ROCm support for crop_and_resize_op", "body": "This PR adds ROCm support for crop_and_resize_op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n-----\r\ntest preformed: //tensorflow/core/kernels:crop_and_resize_op_test\r\n\r\n@tatianashp @whchung", "comments": []}, {"number": 29149, "title": "[ROCm] Adding ROCm support for comapre_and_bitpack op", "body": "This PR adds ROCm support for comapre_and_bitpack op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n-------------------------\r\n\r\n@tatianashp @whchung ", "comments": ["@chsigg gentle ping\r\n\r\nthanks again!"]}, {"number": 29148, "title": "updated links to docker files", "body": "updated links to docker files that were not working.\r\nThis will resolve this [issue](https://github.com/tensorflow/tensorflow/issues/29105). Thanks!", "comments": ["Similar changes are merged in to master , so closing this PR, thank you @jvishnuvardhan for your contribution."]}, {"number": 29147, "title": "Fixed the problem of default rnn ops never use tensor cores", "body": "The current TF will not use the tensor cores if default cudnn RNN operation is used. This is due to a previous issue in cudnn, which has been fixed in 7.2.1.\r\n\r\nThis PR fixed this problem.\r\n\r\nFYI. @nluehr ", "comments": []}, {"number": 29146, "title": "[INTEL MKL] Fixing a build error in a test", "body": "", "comments": ["I think @ezhulenev is a better reviewer for this.", "What is the build error? This test should not be fully disabled, it tests not only custom contraction kernels, but Eigen spatial convolution in general.", "@ezhulenev this is the build error message:\r\nerror: 'QInt8' in namespace 'Eigen' does not name a type\r\nAt this line: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions_test.cc#L1758", "Can you try to add few extra headers:\r\n\r\n```\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n// Disable clang-format to prevent 'FixedPoint' header from being included\r\n// before 'Tensor' header on which it depends.\r\n// clang-format off\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint\"\r\n// clang-format on\r\n```", "If I add the above headers, I get another build error:\r\n`./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1479:3: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE\r\n   EIGEN_STATIC_ASSERT((nr == 4), YOU_MADE_A_PROGRAMMING_MISTAKE)\r\n   ^`", "I think putting just https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions_test.cc#L1837-L1845 inside #ifdef should fix the issue", "Thank you. I updated the PR with your last suggestion. ", "Thanks!"]}]