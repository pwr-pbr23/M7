[{"number": 15373, "title": "GPU memory usage changed from TF 1.3.0 to 1.4.0 - runs out of memory", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code included below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: From pip\r\n- **TensorFlow version (use command below)**: 1.3.0 and 1.4.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: cuda-8.0 cudnn-6.0\r\n- **GPU model and memory**: GTX 1080 8GB\r\n- **Exact command to reproduce**: python <example_script.py>\r\n\r\n### Describe the problem\r\nBug. TensorFlow runs out of GPU memory (ResourceExhaustedError) when using version 1.4.0 when running code that runs fine on version 1.3.0. Please see the following script to reproduce.\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim.nets as nets\r\nimport tensorflow.contrib.slim as slim\r\nfrom tensorflow.contrib.slim.nets import resnet_v2\r\n\r\nkBatchSize = 4\r\nkCropSize = 500\r\nkNumClasses = 10\r\n\r\nwith tf.device('/gpu:0'):\r\n  images = tf.random_normal([kBatchSize, kCropSize, kCropSize, 3])\r\n  labels = tf.constant(0, dtype=tf.int32, shape=[kBatchSize, kCropSize, kCropSize])\r\n\r\n  with slim.arg_scope(resnet_v2.resnet_arg_scope()):\r\n    backbone, end_points = resnet_v2.resnet_v2_101(\r\n        images, None, is_training=True, global_pool=False,\r\n        output_stride=8)\r\n\r\n    final_conv = tf.layers.conv2d(backbone, kNumClasses, [1, 1], name='final_conv')\r\n    logits = tf.image.resize_bilinear(final_conv, tf.slice(tf.shape(images), [1], [2]))\r\n\r\n  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n        labels=labels, logits=logits)\r\n\r\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=.001)\r\ntrain_op = slim.learning.create_train_op(loss, optimizer)\r\nslim.learning.train(train_op, '/tmp/resnet')\r\n```\r\n", "comments": ["This is a duplicate of #14107. Please add your comments there to help us keep the tracker focused. Thanks!"]}, {"number": 15372, "title": "Instead of \"option\" use \"set\" to define non-bool cmake build args.", "body": "", "comments": ["http://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/22/console\r\n\r\nThe job was able to correctly parse the cmakefile."]}, {"number": 15371, "title": "Standardize arguments in SessionRunHook APIs.", "body": "Some hooks inheriting from `SessionRunHook` (https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/training/basic_session_run_hooks.py) use different input argument keywords, while implementing the exact same functionality. This should be ironed out.\r\n\r\nI wanted to make a PR for this, but I realised this will be backwards incompatible. Still, I think we should standardise this.\r\n\r\nE.g.:\r\n`every_secs` (by `SecondOrStepTimer`)\r\n`every_n_secs`  (by `LoggingTensorHook`) [this seems like most descriptive one, to me]\r\n`save_secs` (by `CheckpointSaverHook`)\r\n", "comments": ["@ispirmustafa can you comment on this one? Thanks...", "we cannot do this change due to backward compatibility."]}, {"number": 15370, "title": "Add the structural similarity (SSIM) index metric as a built-in loss operation", "body": "In many cases existed built-in losses in TensorFlow do not satisfy needs.  We can add [ssim](https://en.wikipedia.org/wiki/Structural_similarity) or (1-ssim) as the loss function into TensorFlow.\r\n\r\nThere is existed solution provided on [StackOverflow](https://stackoverflow.com/questions/39051451/ssim-ms-ssim-for-tensorflow), but it is better to have the built-in function with fully covered unit tests.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Dear tensorflow,\r\n\r\nThe feature request still actual.\r\n\r\n\r\n### System information\r\n- **Have I written custom code**: No, i have not\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6.2\r\n- **CUDA/cuDNN version**: no cuda installed\r\n- **GPU model and memory**: built-in gpu \r\n- **Exact command to reproduce**:", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "That sounds reasonable. If we'd encourage a submission, then we would need to make sure we have a maintainer.", "One thing to note is that you can get different values depending on implementation details, which is not good when reporting numbers in papers. Here is yet another implementation, which I based it off scikit-image's compare_ssim implementation (and the numbers match): https://gist.github.com/alexlee-gk/cbc9bfa6e5be51b53c622684cec0a3f3", "Hi, I converted the numpy version of ms-ssim in tensorflow-contrib to a TensorFlow version. I could add it to tensorflow and maintain it, but I've never contributed to tensorflow before. I've looked at the contributing.md, so the procedure is clear to me. I just don't know in which file to put it. I see there are losses in Tensorflow contrib, but it seems depreciated. Should I still put it in there? Thanks for the help.\r\n\r\nHere is the reference implementation that I used, it seems based on the matlab reference implementation of the author of the MS-SSIM.\r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/compression/image_encoder/msssim.py\r\n\r\nPlease tell me if you're willing to have the MS-SSIM build-in in tensorflow, and if yes, in which file I should put it. I'll do a proper PR then.", "Any chance that those functions can support 3D (volumetric) data ?", "@cancan101 have you found a solution to your problem?"]}, {"number": 15368, "title": "Clean bazel `all_files` targets", "body": "Broken out of #15166", "comments": ["Can one of the admins verify this patch?", "- `tensorflow/python/platform/default` -> removed in 2b74220466957e7fbc86ebe3da5ead9a0e4f5169\r\n- `tensorflow/contrib/bayesflow/examples/**` -> removed in 2ccf3aba424405d82e69f03021435e48f54656fb\r\n- `tensorflow/contrib/ios_examples/**` -> moved to `tensorflow/examples/ios` in fdb8e29354ce93afa8c2335a6287a59eb37d42fc\r\n- `tensorflow/contrib/learn/python/learn/dataframe` -> removed in 27ad708b90cdb62e6aeb7c1378a23ff8cc9c1790\r\n- `tensorflow/contrib/metrics/ops` -> moved to `tensorflow/core/ops` in 1af94c269874440373c1d18d823110b1f5eabc19\r\n- `tensorflow/contrib/periodic_resample/python/kernels` -> never existed\r\n- `tensorflow/contrib/tensor_forest/core/ops` -> moved to `tensorflow/contrib/tensor_forest/kernels` in 877aff8a028c495ea7d2d509fb7f8bc78bf0da2d\r\n- `tensorflow/contrib/tensor_forest/data` -> moved to `tensorflow/contrib/tensor_forest/python/ops` 70b6a5d7605d28a3df93295d1b89d9eee4965ea7", "@jart The tests of PR #15166 match the lines inside some text files against the total directory structure to spot invalid paths as well as ring bells on non-existent but expected entries.\r\n\r\nTo do so, I have included `//tensorflow:all_opensource_files` as bazel `data` dependency which works just fine in principle. Although I had to work around Python resolving all imports (even generated) to the `runfiles` directory.\r\n\r\nIf you have a way at hand to access (a summary of) the directory structure (file contents not needed), I am of course all open ears.", "@tensorflow-jenkins test this please", "@jart I don't believe :all_opensource_files can be removed, or at least I don't know how. I thought that there are still rules that require data access to all files. Maybe this has changed? ", "The way I'd go about removing it, is by changing `data = [\":all_opensource_files\"]` to list legitimate top-level build targets instead, which is what [`:build_pip_package`](https://github.com/tensorflow/tensorflow/blob/3571514ec20d3da04b82abd239a4e5817dbfd5d8/tensorflow/tools/pip_package/BUILD#L141) does. Then Bazel figures out all the transitive stuff.\r\n\r\nThis would bring some small benefits aside from cleanup. For example, [`:check_futures_test`](https://github.com/tensorflow/tensorflow/blob/3571514ec20d3da04b82abd239a4e5817dbfd5d8/tensorflow/tools/test/BUILD#L108) would be able to test generated sources too.\r\n\r\nThe `:all_opensource_files` pattern is mostly useful with tools like [MOE](https://github.com/google/moe) when Bazel is building your tarball and you're willing to put up with the extra pain to avoid doing things like leaking the assembly code for some space age algorithm that got schlepped in from part of the monolithic codebase you've never seen.\r\n\r\nSo if we're 100% on board with Copybara, removing should be doable with some toil.", "The point of the check_futures_test is that it can check files that you have not thought about. So unless we have a global target which is guaranteed to include all python files, I don't see how we can replace all_opensource_files for it.\r\n\r\nAnd since bazel hides anything inside a directory with a BUILD file, all BUILD files must have their own target.", "I now understand what you meant. As far as the `:all_opensource_files` pattern goes, we implement it in pretty much the best way possible (with the presubmit and all.) I'm just talking about alternatives with different tradeoffs.\r\n\r\nFor example, on the TensorBoard team, we went along with the Copybara vision of just running these sorts of tests and tools independently of Bazel, and therefore don't include `:all_opensource_files` rules. For example, we run pylint from our [.travis.yml](https://github.com/tensorflow/tensorboard/blob/master/.travis.yml#L89) file. ", "That would be great solution -- we can add these tests to sanity, where we already run a bunch of unrelated test outside of bazel.", "Jenkins, test this please.", "Test failure `check_futures_test` due to files that were not found by the test before this cleanup.", "Jenkins, test this please.", "@martinwicke We should make e.g. `check_futures_test` a Sanity Check, not depending on things like `all_opensource_files`. Else we end up with silent errors like the ones I unexpectedly had to fix here.", "I agree. We can probably make anything currently relying on all_opensource_files into a check run in [sanity](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh). \r\n\r\nThat already contains a function to get all changed python files, so running a regex over those to check for the future imports should be super-easy. I'd love a PR for that.", "I disagree.\r\nWe should exclusively keep only quick running things on sanity build. Currently, makefile builds depends on all_opensource_files.\r\n\r\nIf @yifeif can move makefile to not use all_opensource_files, I am ok with what @martinwicke suggests.", "The futures check should be very fast (much faster than, say, pylint: it only check for the existence of from future import lines in all changed python files).\r\n\r\nI hadn't considered makefile -- why does that rely on all_opensource_files?", "It is due to the new infra. All makefile build is wrapped in a bazel target.", "Are we talking about wrapping makefile build output with bazel? The bazel part doesn't use all_opensource_files.", "I am removing the dep to `third_party/{fft2d,flatbuffers,eigen3}` which we don't control fully and doesn't work well internally for now. Also, for some reason the `contrib/mpi:all_files` and `mpi_collectives:all_files` are missing. We should figure that out internally."]}, {"number": 15367, "title": "tf.keras.backend.set_learning_phase doesn't work during evaluating model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.5.2\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen I run following script\uff0cerror  `InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'block1_conv1_bn/keras_learning_phase' with dtype bool`  occured.  After searching in keras repository and stackoverflow, I find it is caused by the design of learning phase parameter of BN layers which behave differently at training and testing time (See [here](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)). fchollet have added `K.set_learning_phase()` for tensorflow to solve this problem. So when I use `keras` instead of `tf.keras`, no issue is reported. I wonder if this part is still not integrated into tensorflow completely. \r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\n# import keras  # work normally\r\nkeras = tf.keras\r\nXception = keras.applications.Xception\r\nfrom keras import backend as K\r\n\r\ndata_path = \"val.tfrecord\"\r\nif not isinstance(data_path, (tuple, list)):\r\n    data_path = [data_path]\r\nfeature = {'image/encoded': tf.FixedLenFeature([], tf.string),\r\n           'image/class_id': tf.FixedLenFeature([], tf.int64)}\r\n# create file queue\r\nfilename_queue = tf.train.string_input_producer(data_path)\r\n# tfrecord file reader\r\nreader = tf.TFRecordReader()\r\n_, example_string = reader.read(filename_queue)\r\n# decode record\r\nfeatures = tf.parse_single_example(example_string, features=feature)\r\nimage = tf.decode_raw(features['image/encoded'], out_type=tf.uint8)\r\nimage = tf.cast(image, dtype=tf.float32)\r\n# restore shape\r\nimage = tf.reshape(image, (96, 96, 3))\r\nlabel = tf.cast(features['image/class_id'], dtype=tf.int64)\r\nimage_batch, label_batch = tf.train.shuffle_batch(tensors=[image, label],\r\n                                                  batch_size=128,\r\n                                                  capacity=10000,\r\n                                                  min_after_dequeue=3000,\r\n                                                  num_threads=8,\r\n                                                  allow_smaller_final_batch=True)\r\n\r\n# convert label to one hot label\r\nsess = K.get_session()\r\n# declare learning phase for BN/dropout\r\nK.set_learning_phase(0)\r\nlabel_batch = tf.one_hot(label_batch, 2, dtype=tf.float32)\r\nmodel_input = keras.layers.Input(tensor=image_batch)\r\nbase_model = Xception(include_top=True,\r\n                      weights=None,   # no pre-trained weights used\r\n                      pooling=\"avg\",\r\n                      input_shape=(96, 96, 3),  # modify first layer\r\n                      classes=2)\r\nmodel_output = base_model(model_input)\r\ntest_model = keras.models.Model(inputs=model_input, outputs=model_output)\r\ntest_model.load_weights(\"weights.h5\")\r\noptimizer = tf.train.RMSPropOptimizer(learning_rate=2e-3, decay=0.9)\r\ntest_model.compile(optimizer=optimizer,\r\n                   loss=\"categorical_crossentropy\",\r\n                   metrics=['accuracy'])\r\nacc_value = keras.metrics.categorical_accuracy(label_batch, model_output)\r\n# Fit model using data from tf records queue\r\ncoord = tf.train.Coordinator()\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\nacc_value_batch = sess.run([acc_value])\r\nprint(acc_value_batch)\r\ncoord.request_stop()\r\n# wait for threads to stop\r\ncoord.join(threads=threads)\r\nsess.close()\r\n```\r\n\r\nlogs:\r\n```\r\nCaused by op 'block1_conv1_bn/keras_learning_phase', defined at:\r\n  File \"/home/arkenstone/PycharmProjects/startdt/face_liveness_detect/model/patch_based_cnn/test_image.py\", line 66, in <module>\r\n    classes=2)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/applications/xception.py\", line 161, in Xception\r\n    x = BatchNormalization(name='block1_conv1_bn')(x)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 252, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/layers/normalization.py\", line 109, in call\r\n    training = K.learning_phase()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\", line 325, in learning_phase\r\n    phase = array_ops.placeholder(dtype='bool', name='keras_learning_phase')\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'block1_conv1_bn/keras_learning_phase' with dtype bool\r\n\t [[Node: block1_conv1_bn/keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\t [[Node: Cast_2/_23 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1603_Cast_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```", "comments": ["@fchollet Can you comment on this one? Thanks...", "Try to put your evaluation code in a different function. The way you've written it, you are reusing the same graph, which could be hiding some underlying issue in your code. Use `K.clear_session()` at the end of each phase, or better, put them inside graph scopes.\r\n\r\n`set_learning_phase` certainly does work, so my guess is that you are somehow reusing parts of the training model during evaluation. Using two separate functions (and graphs) should clear that up.\r\n\r\n", "@fchollet Thanks for your reply! I try to use evaluation code in a separated script by loading pre-trained model weights, together with adding `K.clear_session()` at the end of session. But the issue still exists. **But again if I use keras instead of tf.keras, it works!** \r\n\r\nBTW, I check the `K.learning_phase()` and `set_learning_phase` does work. So I think this issue should be about graph reusing as you said. Is there something different should be noted between keras and tf about graph usage?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This issue also happens to me. I have tried many different ways to resolve this issue. \r\nEither K.set_learning_phase(0) or K.learning_phase(): 0 gives random results when loading back from a checkpoint @fchollet ", "I think it's a bug, I'm looking at it.", "It's actually a user error. The problem is the following:\r\n\r\n- You are using `tf.keras`, in particular the tf.keras BN layer (part of Xception model)\r\n- You are setting the learning phase via `K` which is imported from `keras` (not tf.keras)\r\n\r\nTherefore setting the learning phase does nothing to your model: it's acting on a different python module altogether...\r\n\r\nThe solution is this:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nK = keras.backend\r\n```", "@fchollet  In my case I do not have this module bug. My environment is tf 1.3. I am sure I use modules all from the same package.\r\nSo I tried 1) using tf.contrib.keras and 2) uses keras (2.12). Both cause random results when evaluation. My code was correct in early tensorflow+keras version (probably 8 months ago). But this time it is not working, I  believe there is some bugs of K.learning_phase() ", "Then please open a new issue (since this one is not related) and provide a code standalone snippet to reproduce the problem.", "@fchollet pls checkout this [issue](https://github.com/tensorflow/tensorflow/issues/16102). I believe there is a bug. thanks a lot", "Dear @fchollet \r\nI think this is a bug,too\r\n\r\nHere is my example code\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\n#from tensorflow.python.keras import  backend\r\nfrom tensorflow import keras\r\nK = keras.backend\r\n\r\nfrom tensorflow.python.keras.layers import  Input\r\n\r\nfrom tensorflow.python.keras.layers import MaxPooling2D\r\nfrom tensorflow.python.keras.layers import BatchNormalization\r\nfrom tensorflow.python.keras.layers import Conv2D, Dense, Flatten\r\nfrom tensorflow.python.keras.layers import Activation\r\nfrom tensorflow.python.keras.models import Model\r\n\r\nprint(tf.__version__)\r\n# Load Data\r\nimport cifar10\r\n\r\nimg_size = 32\r\nnum_channels = 3\r\nnum_classes = 10\r\ncifar10.maybe_download_and_extract()\r\n\r\n\r\nclass_names = cifar10.load_class_names()\r\n\r\n\r\nimages_train, cls_train, labels_train = cifar10.load_training_data()\r\n\r\nimages_test, cls_test, labels_test = cifar10.load_test_data()\r\n\r\nprint(\"Size of:\")\r\nprint(\"- Training-set:\\t\\t{}\".format(len(images_train)))\r\nprint(\"- Test-set:\\t\\t{}\".format(len(images_test)))\r\n\r\n\r\n\r\nimg_size_cropped = 24\r\n#%%\r\ndef pre_process_image(image, training):\r\n    # This function takes a single image as input,\r\n    # and a boolean whether to build the training or testing graph.\r\n    \r\n    if training:\r\n        # For training, add the following to the TensorFlow graph.\r\n\r\n        # Randomly crop the input image.\r\n        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\r\n\r\n        # Randomly flip the image horizontally.\r\n        image = tf.image.random_flip_left_right(image)\r\n        \r\n        # Randomly adjust hue, contrast and saturation.\r\n        image = tf.image.random_hue(image, max_delta=0.05)\r\n        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\r\n        image = tf.image.random_brightness(image, max_delta=0.2)\r\n        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\r\n\r\n        # Some of these functions may overflow and result in pixel\r\n        # values beyond the [0, 1] range. It is unclear from the\r\n        # documentation of TensorFlow 0.10.0rc0 whether this is\r\n        # intended. A simple solution is to limit the range.\r\n\r\n        # Limit the image pixels between [0, 1] in case of overflow.\r\n        image = tf.minimum(image, 1.0)\r\n        image = tf.maximum(image, 0.0)\r\n    else:\r\n        # For training, add the following to the TensorFlow graph.\r\n\r\n        # Crop the input image around the centre so it is the same\r\n        # size as images that are randomly cropped during training.\r\n        image = tf.image.resize_image_with_crop_or_pad(image,\r\n                                                       target_height=img_size_cropped,\r\n                                                       target_width=img_size_cropped)\r\n\r\n    return image\r\n\r\ndef pre_process(images, training):\r\n    # Use TensorFlow to loop over all the input images and call\r\n    # the function above which takes a single image as input.\r\n    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\r\n\r\n    return images\r\n\r\n#%%\r\ndef _bn_relu(input_layer):\r\n    \"\"\"Helper to build a BN -> relu block\r\n    \"\"\"\r\n    norm = BatchNormalization(axis=3)(input_layer)\r\n    return Activation(\"relu\")(norm)\r\n#%%\r\n\r\nx = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\r\n\r\ndistorted_images = pre_process(images=x, training=True)\r\n\r\ny_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\r\n\r\ny_true_cls = tf.argmax(y_true, axis=1)\r\n\r\ndef create_network(training):\r\n    # Wrap the neural network in the scope named 'network'.\r\n    # Create new variables during training, and re-use during testing.\r\n    with tf.variable_scope('network', reuse=not training):\r\n\r\n        images = x        \r\n        images = pre_process(images=images, training=training)\r\n        \r\n        inputs = Input(tensor=images)\r\n\r\n        net_ks = Conv2D(kernel_size=5, strides=1, filters=64, padding='same',\r\n             activation='linear', name='layer_conv1')(inputs)\r\n\r\n        net_ks = _bn_relu(net_ks)\r\n        net_ks = MaxPooling2D(pool_size=2, strides=2)(net_ks)\r\n\r\n\r\n        net_ks = Conv2D(kernel_size=5, strides=1, filters=64, padding='same',\r\n        activation='relu', name='layer_conv2')(net_ks) \r\n        net_ks = MaxPooling2D(pool_size=2, strides=2)(net_ks)\r\n\r\n        \r\n        net_ks = Flatten()(net_ks)\r\n        \r\n        net_ks = Dense(256, activation='relu', name='layer_fc1')(net_ks)\r\n        net_ks = Dense(128, activation='relu', name='layer_fc2')(net_ks)\r\n        preds_ks = Dense(num_classes, activation='linear')(net_ks)\r\n        \r\n        preds_softmax = tf.nn.softmax(preds_ks)\r\n        step1 = tf.cast(y_true, tf.float32) * tf.log(preds_softmax)\r\n        step2 = -tf.reduce_sum(step1, reduction_indices=[1])\r\n        loss = tf.reduce_mean(step2)       # loss\r\n        \r\n        model = Model(inputs=inputs, outputs=preds_ks)\r\n\r\n    return preds_softmax, loss, model\r\n\r\n#%% Create Neural Network for Training Phase\r\nglobal_step = tf.Variable(initial_value=0,\r\n                          name='global_step', trainable=False)\r\n\r\ny_pred, loss, model = create_network(training=True)\r\n\r\nmodel.summary()\r\n\r\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)\r\n#%% Create Neural Network for Test Phase / Inference\r\n#y_pred, _ , _= create_network(training=False)\r\ny_pred_cls = tf.argmax(y_pred, axis=1)\r\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\nsession = tf.Session()\r\nsession.run(tf.global_variables_initializer())\r\ntrain_batch_size = 64\r\n\r\ndef random_batch():\r\n    # Number of images in the training-set.\r\n    num_images = len(images_train)\r\n\r\n    # Create a random index.\r\n    idx = np.random.choice(num_images,\r\n                           size=train_batch_size,\r\n                           replace=False)\r\n\r\n    # Use the random index to select random images and labels.\r\n    x_batch = images_train[idx, :, :, :]\r\n    y_batch = labels_train[idx, :]\r\n\r\n    return x_batch, y_batch\r\n\r\ndef optimize(num_iterations):\r\n\r\n    for i in range(num_iterations):\r\n\r\n        x_batch, y_true_batch = random_batch()\r\n\r\n\r\n        feed_dict_train = {x: x_batch,\r\n                           y_true: y_true_batch, K.learning_phase(): 1}\r\n\r\n\r\n        i_global, _ = session.run([global_step, optimizer],\r\n                                  feed_dict=feed_dict_train)\r\n\r\n        # Print status to screen every 100 iterations (and last).\r\n        if (i_global % 100 == 0) or (i == num_iterations - 1):\r\n            # Calculate the accuracy on the training-batch.\r\n            feed_dict_train = {x: x_batch,\r\n                           y_true: y_true_batch, K.learning_phase(): 0}\r\n            batch_acc = session.run(accuracy,\r\n                                    feed_dict=feed_dict_train)\r\n\r\n            # Print status.\r\n            msg = \"Global Step: {0:>6}, Training Batch Accuracy(phase 0): {1:>6.1%}\"\r\n            print(msg.format(i_global, batch_acc))\r\n            \r\n            feed_dict_train = {x: x_batch,\r\n                           y_true: y_true_batch, K.learning_phase(): 1}\r\n            batch_acc = session.run(accuracy,\r\n                                    feed_dict=feed_dict_train)\r\n\r\n            # Print status.\r\n            msg = \"Global Step: {0:>6}, Training Batch Accuracy(phase 1): {1:>6.1%}\"\r\n            print(msg.format(i_global, batch_acc))  \r\n\r\n\r\n#%%\r\noptimize(num_iterations=10000)\r\n```\r\nThe output of\" Training Batch Accuracy(phase 0) \"& \"Training Batch Accuracy(phase 1) \" is different.\r\nPlease help us to use it. Thank you!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "Same problem.\r\nI've answered on [SO](https://stackoverflow.com/a/54309538/3049753)"]}, {"number": 15366, "title": "fix that remove_nodes drops input suffixes", "body": "The transform `remove_nodes` didn't take input suffixes into consideration, and might make mistakes if the removed node used not `:0` but `:1`.\r\n\r\nE.g.: For a node of `/a/Identity (Identity): [/a/Switch_1:1]`, the old code will make the pb file generate completely unexpected outputs.\r\n\r\nThe clang-format checking and tests (`//tensorflow/tools/graph_transforms/...`) have been passed.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15365, "title": "Automatic node placement (allocating graph nodes to multiple devices) feature  in distributed tensorflow", "body": "I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration.\r\n\r\nhttps://www.reddit.com/r/MachineLearning/comments/4n6a0e/distributed_tensorflow_resource_allocation/\r\n\r\nThis post says this feature was removed because it did not perform well.\r\nHowever, it was posted a year ago and I think you are still developing this feature.\r\n\r\nIs it included in the current version of tensorflow?\r\nIf so, what code do i need to see?\r\nIf inot, do you plan to add this feature?\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15364, "title": "[BUG] Default MaxPoolingOp/AvgPoolingOp only supports NHWC", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow with virtualEnv\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 2.7.5\r\n- **Exact command to reproduce**:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\na = tf.nn.max_pool(np.random.rand(1, 1,10,10), [1,1,2,2], [1,1,1,1], 'VALID', data_format='NCHW')\r\nsess=tf.InteractiveSession()\r\nsess.run(a)\r\n```\r\n### Describe the problem\r\nWhen I try to run a node of type max or avg pool with data_format : 'NCHW' I got an error.\r\nThis seems to be a bug because the TF docs affirms that : \r\n> data_format: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.\r\n\r\n### Error logs\r\nWith max:\r\n> 2017-12-14 12:40:23.250331: E tensorflow/core/common_runtime/executor.cc:643] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC.\r\n>                 [[Node: MaxPool = MaxPool[T=DT_DOUBLE, data_format=\"NCHW\", ksize=[1, 1, 2, 2], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](MaxPool/input)]]\r\n\r\nWith Avg:\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC.\r\n         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 2, 2], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](AvgPool_1/input)]]\r\n", "comments": ["#2660", "@zheng-xq Can you comment on this? Maybe we should update docs to say that all data formats are not supported? Thanks...", "For now, many kernels only supports NCHW on GPU. In the future, we are introducing a layout optimizer so models can use NHWC and still get the best performance as if they are written for NCHW. \r\n", "@zheng-xq Thanks.\r\n@ dr4b Can we update the documentation on nn_ops.py for function \"max_pool\"?", "@andydavis1 we could do it, or if @zheng-xq wants to submit a PR fixing the docs that would also work?  You just need to update the doc string in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py", "@zheng-xq `cudnn` supports both `NCHW` and `NHWC`, doesn't it? Why the need for a layout optimizer for better performance of `NHWC` on GPU?", "Both formats are supported, with very different performance characteristics. That's why it is important to use the faster format. ", "Just to clear some potential confusion around this. If you compile tensorflow with MKL support you can use these ops with `NCHW`.", "@zheng-xq has there been progress on a layout optimizer?  Is NCHW now supported?", "I think you are getting this error because of the code you provided. You are trying to max pool from numpy array. When I run your code I got the same error. When modified it is working properly.\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\na = tf.random_uniform((1, 3,10,10))\r\nb = tf.nn.max_pool(a, ksize=[1, 1, 2, 2], strides=[1, 1, 1, 1], padding='VALID', data_format='NCHW')\r\nsess=tf.InteractiveSession()\r\nsess.run(tf.global_variables_initializer())\r\nres = sess.run(b)\r\nprint(res.shape)\r\n```", "I think this may tie to this [`Todo`](https://github.com/tensorflow/tensorflow/blob/8855b0c12433b1bdebfa1ea72b966a35fb0925bf/tensorflow/core/kernels/pooling_ops_common.h#L76).", "ping @yongtang, please see the comment of @KleinYuan ", "Closing due to staleness. Please check with the latest version of TensorFlow. Feel free to reopen if the issue still persists. Thanks!", "I tried all the aforementioed methods. nevertheless of these methods were overcome this bug. I still have had the same issue:\r\nInvalidArgumentError: Default MaxPoolingOp only supports NHWC on device type CPU\r\n\t [[{{node max_pooling2d_2/MaxPool}}]]\r\n\r\nWhen I trying to execute this code in jupyter notebooke:\r\n# Training\r\nhist = model.fit(X_train, y_train, batch_size=16, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\r\nPleasem I need your support\r\n\r\n", "[same problem here](https://github.com/suraj-deshmukh/Keras-Multi-Label-Image-Classification/issues/18)\r\n\r\n>>> tf.__version__\r\n'2.3.0'\r\n>>> import keras\r\n>>> keras.__version__\r\n'2.4.3'", "I tried all methods, but still cant solve this error. Please help me with this code:\r\nfrom keras import optimizers\r\nada = keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\r\nmodel.compile(optimizer=ada,\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nhistory = model.fit_generator(train_generator,\r\n                              validation_data=validation_generator,\r\n                              steps_per_epoch=100,\r\n                              validation_steps=100,\r\n                              epochs=10)\r\n\r\n\r\nerror:\r\n\r\nInvalidArgumentError:  Default MaxPoolingOp only supports NHWC on device type CPU\r\n\t [[node functional_3/max_pooling2d_9/MaxPool (defined at <ipython-input-30-c78b006fbd26>:10) ]] [Op:__inference_train_function_7377]\r\n\r\nFunction call stack:\r\ntrain_function"]}, {"number": 15363, "title": "how to feed a placeholder with the return values of tf.train.batch() ", "body": "Code:  \r\nimages, raw_images, labels = tf.train.batch(\r\n        [image, raw_image, label],\r\n        batch_size = batch_size,\r\n        num_threads = 1,\r\n        capacity = 4 * batch_size,\r\n        allow_smaller_final_batch = True)\r\n    return images, raw_images, labels\r\n\r\n images, _, labels = load_batch(dataset, batch_size=batch_size)\r\n        sess.run(train_op, feed_dict={x: x_img, y_true: label})\r\n\r\nErrors:\r\n sess.run(train_op, feed_dict={x: images, y_true: labels})\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1074, in _run\r\n    raise TypeError('The value of a feed cannot be a tf.Tensor object. '\r\nTypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.\r\n", "comments": ["#!/usr/bin/python\r\n#-*- coding: utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\r\nfrom tensorflow.python.platform import tf_logging as logging\r\nimport inception_preprocessing\r\nfrom inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\r\nimport os\r\nimport time\r\nslim = tf.contrib.slim\r\n\r\nimport numpy as np\r\n\r\nconfig  = tf.ConfigProto()\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9\r\n\r\n\r\n\"\"\"\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\n\r\n\"\"\"\r\n#================ DATASET INFORMATION ======================\r\n#State dataset directory where the tfrecord files are located\r\ndataset_dir = '.'\r\n\r\n#State where your log file is at. If it doesn't exist, create it.\r\nlog_dir = './log'\r\n\r\n#State where your checkpoint file is\r\ncheckpoint_file = './inception_resnet_v2_2016_08_30.ckpt'\r\n\r\n#State the image size you're resizing your images to. We will use the default inception size of 299.\r\nimg_width = 800\r\nimg_height = 600\r\n\r\nfile_pattern = 'estate_%s_*.tfrecord'\r\n#State the number of classes to predict:\r\nnum_classes = 6\r\n\r\n#State the labels file and read it\r\nlabels_file = './labels.txt'\r\nlabels = open(labels_file, 'r')\r\n\r\n#Create a dictionary to refer each label to their string name\r\nlabels_to_name = {}\r\nfor line in labels:\r\n    label, string_name = line.split(':')\r\n    string_name = string_name[:-1] #Remove newline\r\n    labels_to_name[int(label)] = string_name\r\n\r\n#Create the file pattern of your TFRecord files so that it could be recognized later on\r\nfile_pattern = 'estate_%s_*.tfrecord'\r\n\r\n#Create a dictionary that will help people understand your dataset better. This is required by the Dataset class later.\r\n\r\nitems_to_descriptions = {\r\n    'image': 'A 3-channel RGB coloured real estate image that is either bathroom, bedroom, floorplan, kitchen, or livingroom, other.',\r\n    'label': 'A label that is as such -- 0:bathroom, 1:bedroom, 2:floorplan, 3:kitchen, 4:livingroom, 5:other'\r\n}\r\n\r\n\r\n#================= TRAINING INFORMATION ==================\r\n#State the number of epochs to train\r\nnum_epochs = 1\r\n\r\n#State your batch size\r\nbatch_size = 1\r\n\r\n#Learning rate information and configuration (Up to you to experiment)\r\ninitial_learning_rate = 0.0002\r\nlearning_rate_decay_factor = 0.7\r\nnum_epochs_before_decay = 2\r\n\r\n#iteration \r\ntotal_iterations = 0\r\n#============== DATASET LOADING ======================\r\n#We now create a function that creates a Dataset class which will give us many TFRecord files to feed in the examples into a queue in parallel.\r\ndef get_split(split_name, dataset_dir, file_pattern=file_pattern, file_pattern_for_counting='estate'):\r\n    '''\r\n    Obtains the split - training or validation - to create a Dataset class for feeding the examples into a queue later on. This function will\r\n    set up the decoder and dataset information all into one Dataset class so that you can avoid the brute work later on.\r\n    Your file_pattern is very important in locating the files later. \r\n\r\n    INPUTS:\r\n    - split_name(str): 'train' or 'validation'. Used to get the correct data split of tfrecord files\r\n    - dataset_dir(str): the dataset directory where the tfrecord files are located\r\n    - file_pattern(str): the file name structure of the tfrecord files in order to get the correct data\r\n    - file_pattern_for_counting(str): the string name to identify your tfrecord files for counting\r\n\r\n    OUTPUTS:\r\n    - dataset (Dataset): A Dataset class object where we can read its various components for easier batch creation later.\r\n    '''\r\n\r\n    #First check whether the split_name is train or validation\r\n    if split_name not in ['train', 'validation']:\r\n        raise ValueError('The split_name %s is not recognized. Please input either train or validation as the split_name' % (split_name))\r\n\r\n    #Create the full path for a general file_pattern to locate the tfrecord_files\r\n    file_pattern_path = os.path.join(dataset_dir, file_pattern % (split_name))\r\n\r\n    #Count the total number of examples in all of these shard\r\n    num_samples = 0\r\n    file_pattern_for_counting = file_pattern_for_counting + '_' + split_name\r\n    tfrecords_to_count = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if file.startswith(file_pattern_for_counting)]\r\n    for tfrecord_file in tfrecords_to_count:\r\n        for record in tf.python_io.tf_record_iterator(tfrecord_file):\r\n            num_samples += 1\r\n\r\n    #Create a reader, which must be a TFRecord reader in this case\r\n    reader = tf.TFRecordReader\r\n\r\n    #Create the keys_to_features dictionary for the decoder\r\n    keys_to_features = {\r\n      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n      'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\r\n      'image/class/label': tf.FixedLenFeature(\r\n          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\r\n    }\r\n\r\n    #Create the items_to_handlers dictionary for the decoder.\r\n    items_to_handlers = {\r\n    'image': slim.tfexample_decoder.Image(),\r\n    'label': slim.tfexample_decoder.Tensor('image/class/label'),\r\n    }\r\n\r\n    #Start to create the decoder\r\n    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\r\n\r\n    #Create the labels_to_name file\r\n    labels_to_name_dict = labels_to_name\r\n\r\n   \t #Actually create the dataset\r\n    dataset = slim.dataset.Dataset(\r\n        data_sources = file_pattern_path,\r\n        decoder = decoder,\r\n        reader = reader,\r\n        num_readers = 4,\r\n        num_samples = num_samples,\r\n        num_classes = num_classes,\r\n        labels_to_name = labels_to_name_dict,\r\n        items_to_descriptions = items_to_descriptions)\r\n    return dataset\r\n\r\n\r\ndef load_batch(dataset, batch_size, height=img_height, width=img_width, is_training=True):\r\n    '''\r\n    Loads a batch for training.\r\n\r\n    INPUTS:\r\n    - dataset(Dataset): a Dataset class object that is created from the get_split function\r\n    - batch_size(int): determines how big of a batch to train\r\n    - height(int): the height of the image to resize to during preprocessing\r\n    - width(int): the width of the image to resize to during preprocessing\r\n    - is_training(bool): to determine whether to perform a training or evaluation preprocessing\r\n\r\n    OUTPUTS:\r\n    - images(Tensor): a Tensor of the shape (batch_size, height, width, channels) that contain one batch of images\r\n    - labels(Tensor): the batch's labels with the shape (batch_size,) (requires one_hot_encoding).\r\n\r\n    '''\r\n    #First create the data_provider object\r\n    data_provider = slim.dataset_data_provider.DatasetDataProvider(\r\n        dataset,\r\n        common_queue_capacity = 24 + 3 * batch_size,\r\n        common_queue_min = 24)\r\n\r\n    #Obtain the raw image using the get method\r\n    raw_image, label = data_provider.get(['image', 'label'])\r\n\r\n    #Perform the correct preprocessing for this image depending if it is training or evaluating\r\n    image = inception_preprocessing.preprocess_image(raw_image, height, width, is_training)\r\n\r\n    #As for the raw images, we just do a simple reshape to batch it up\r\n    raw_image = tf.expand_dims(raw_image, 0)\r\n    raw_image = tf.image.resize_nearest_neighbor(raw_image, [height, width])\r\n    #modify due to data type\r\n    raw_image = tf.cast(raw_image, tf.float32)\r\n    raw_image = tf.squeeze(raw_image)\r\n\r\n    #Batch up the image by enqueing the tensors internally in a FIFO queue and dequeueing many elements with tf.train.batch.\r\n    images, raw_images, labels = tf.train.batch(\r\n        [image, raw_image, label],\r\n        batch_size = batch_size,\r\n        num_threads = 1,\r\n        capacity = 4 * batch_size,\r\n        allow_smaller_final_batch = True)\r\n    \r\n    return images, raw_images, labels\r\n\r\n\r\nsess = tf.Session()\r\n    \r\n        #Create the log directory here. Must be done here otherwise import will activate this unneededly.\r\nif not os.path.exists(log_dir):\r\n    os.mkdir(log_dir)\r\n#======================= TRAINING PROCESS =========================\r\n#Now we start to construct the graph and build our model\r\ntf.logging.set_verbosity(tf.logging.INFO) #Set the verbosity to INFO level\r\ndataset = get_split('train', dataset_dir, file_pattern=file_pattern)\r\n#First create the dataset and load one batch\r\nx = tf.placeholder(tf.float32, shape=[None, img_height, img_width,3], name='x')\r\n#y_true = tf.placeholder(tf.int32, shape=[None, num_classes], name='y_true')\r\ny_true = tf.placeholder(tf.int32, shape=[num_classes], name='y_true')\r\n#images = tf.reshape(x, [-1, 800, 600, 1])\r\n\r\n#Know the number steps to take before decaying the learning rate and batches per epoch\r\nnum_batches_per_epoch = int(dataset.num_samples / batch_size)\r\nnum_steps_per_epoch = num_batches_per_epoch #Because one step is one batch processed\r\ndecay_steps = int(num_epochs_before_decay * num_steps_per_epoch)\r\n\r\n#Create the model inference\r\nwith slim.arg_scope(inception_resnet_v2_arg_scope()):\r\n    logits, end_points = inception_resnet_v2(x, num_classes = dataset.num_classes, is_training = True)\r\n\r\ny_pred = tf.nn.softmax(logits, name='y_pred')\r\n#Define the scopes that you want to exclude for restoration\r\nexclude = ['InceptionResnetV2/Logits', 'InceptionResnetV2/AuxLogits']\r\nvariables_to_restore = slim.get_variables_to_restore(exclude = exclude)\r\n\r\n#Perform one-hot-encoding of the labels (Try one-hot-encoding within the load_batch function!)\r\none_hot_labels = slim.one_hot_encoding(y_true, dataset.num_classes)\r\n\r\n#Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced with checks\r\nloss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = logits)\r\ntotal_loss = tf.losses.get_total_loss()    #obtain the regularization losses as well\r\n\r\n#Create the global step for monitoring the learning_rate and training.\r\nglobal_step = get_or_create_global_step()\r\n\r\n#Define your exponentially decaying learning rate\r\nlr = tf.train.exponential_decay(\r\n    learning_rate = initial_learning_rate,\r\n    global_step = global_step,\r\n    decay_steps = decay_steps,\r\n    decay_rate = learning_rate_decay_factor,\r\n    staircase = True)\r\n\r\n#Now we can define the optimizer that takes on the learning rate\r\noptimizer = tf.train.AdamOptimizer(learning_rate = lr)\r\n\r\n#Create the train_op.\r\ntrain_op = slim.learning.create_train_op(total_loss, optimizer)\r\n\r\n#State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\r\npredictions = tf.argmax(end_points['Predictions'], 1)\r\nprobabilities = end_points['Predictions']\r\naccuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, y_true)\r\nmetrics_op = tf.group(accuracy_update, probabilities)\r\n\r\nsess.run(tf.global_variables_initializer())\r\n\r\n#Now finally create all the summaries you need to monitor and group them into one summary op.\r\ntf.summary.scalar('losses/Total_Loss', total_loss)\r\ntf.summary.scalar('accuracy', accuracy)\r\ntf.summary.scalar('learning_rate', lr)\r\nmy_summary_op = tf.summary.merge_all()\r\n\r\n#Now we need to create a training step function that runs both the train_op, metrics_op and updates the global_step concurrently.\r\ndef train_step(sess, train_op, global_step):\r\n    '''\r\n    Simply runs a session for the three arguments provided and gives a logging on the time elapsed for each global step\r\n    '''\r\n    #Check the time for each sess run\r\n    start_time = time.time()\r\n    total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])\r\n    time_elapsed = time.time() - start_time\r\n\r\n    #Run the logging to print some results\r\n    #if global_step_count % 10 == 0:\r\n    logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)\r\n    return total_loss, global_step_count\r\n\r\n#Now we create a saver function that actually restores the variables from a checkpoint file in a sess\r\nsaver = tf.train.Saver(variables_to_restore)\r\nsaver.restore(sess, checkpoint_file)\r\n\r\ndef train(num_iteration):\r\n    global total_iterations\r\n    \r\n    for i in range(total_iterations,\r\n                   total_iterations + num_iteration):\r\n        images, _, labels = load_batch(dataset, batch_size=batch_size)\r\n        sess.run(train_op, feed_dict={x: images, y_true: labels})\r\n        saver.save(sess,  global_step = global_step)\r\n    total_iterations += num_iteration\r\n\r\ntrain(num_iteration=24000)\r\n\r\n                \r\n\r\n"]}, {"number": 15362, "title": "Fix broken image link in TensorFlow Lite's docs", "body": "I fixed the link of image in the same way as other documents in [tensorflow/tensorflow/docs_src/](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/docs_src).", "comments": ["Can one of the admins verify this patch?", "Yeah, that's fine.  I wrote it for tf.org style links when I first put it in, but I guess this change will make it compatible with viewing on Github as well. However, it looks like I'm not approved to review this?", "Thanks @dr4b!", "Thanks @dr4b !"]}, {"number": 15361, "title": "//tensorflow/python:bfloat16_test and //tensorflow/python:framework_dtypes_test failing on Windows", "body": "http://ci.tensorflow.org/job/tf-master-win-bzl/2063/console\r\n```\r\n13:00:56 INFO: From Testing //py_test_dir/tensorflow/python:framework_dtypes_test:\r\n13:00:56 ==================== Test output for //py_test_dir/tensorflow/python:framework_dtypes_test:\r\n13:00:56 .........F\\\\?\\C:\\tmp\\Bazel.runfiles_fnb6t73_\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\framework\\dtypes_test.py:277: DeprecationWarning: Please use assertEqual instead.\r\n13:00:56   self.assertEquals(dtype.min, np.finfo(numpy_dtype).min)\r\n13:00:56 ......\r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testIsUnsigned (__main__.TypesTest)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_fnb6t73_\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\framework\\dtypes_test.py\", line 219, in testIsUnsigned\r\n13:00:56     self.assertEqual(dtypes.as_dtype(\"bfloat16\").is_unsigned, False)\r\n13:00:56 AssertionError: True != False\r\n13:00:56 \r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Ran 16 tests in 0.009s\r\n13:00:56 \r\n13:00:56 FAILED (failures=1)\r\n13:00:56 <dtype: 'float32'>: -3.40282e+38 - 3.40282e+38\r\n13:00:56 <dtype: 'float64'>: -1.79769313486e+308 - 1.79769313486e+308\r\n13:00:56 <dtype: 'int32'>: -2147483648 - 2147483647\r\n13:00:56 <dtype: 'uint8'>: 0 - 255\r\n13:00:56 <dtype: 'int16'>: -32768 - 32767\r\n13:00:56 <dtype: 'int8'>: -128 - 127\r\n13:00:56 <dtype: 'int64'>: -9223372036854775808 - 9223372036854775807\r\n13:00:56 <dtype: 'bfloat16'>: 0 - 0\r\n13:00:56 <dtype: 'uint16'>: 0 - 65535\r\n13:00:56 <dtype: 'float16'>: -65504.0 - 65504.0\r\n13:00:56 <dtype: 'uint32'>: 0 - 4294967295\r\n13:00:56 <dtype: 'uint64'>: 0 - 18446744073709551615\r\n13:00:56 <dtype: 'float32_ref'>: -3.40282e+38 - 3.40282e+38\r\n13:00:56 <dtype: 'float64_ref'>: -1.79769313486e+308 - 1.79769313486e+308\r\n13:00:56 <dtype: 'int32_ref'>: -2147483648 - 2147483647\r\n13:00:56 <dtype: 'uint8_ref'>: 0 - 255\r\n13:00:56 <dtype: 'int16_ref'>: -32768 - 32767\r\n13:00:56 <dtype: 'int8_ref'>: -128 - 127\r\n13:00:56 <dtype: 'int64_ref'>: -9223372036854775808 - 9223372036854775807\r\n13:00:56 <dtype: 'bfloat16_ref'>: 0 - 0\r\n13:00:56 <dtype: 'uint16_ref'>: 0 - 65535\r\n13:00:56 <dtype: 'float16_ref'>: -65504.0 - 65504.0\r\n13:00:56 <dtype: 'uint32_ref'>: 0 - 4294967295\r\n13:00:56 <dtype: 'uint64_ref'>: 0 - 18446744073709551615\r\n13:00:56 ================================================================================\r\n13:00:56 INFO: From Testing //py_test_dir/tensorflow/python:bfloat16_test:\r\n13:00:56 ==================== Test output for //py_test_dir/tensorflow/python:bfloat16_test:\r\n13:00:56 FFF.F.FFFFFFFFFFFFFFFF.\r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testAdd (__main__.Bfloat16NumPyTest)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 189, in testAdd\r\n13:00:56     self.assertAllClose(np.array([[5, 7, 9]]), x + y)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1083, in assertAllClose\r\n13:00:56     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1053, in _assertArrayLikeAllClose\r\n13:00:56     np.testing.assert_allclose(a, b, rtol=rtol, atol=atol, err_msg=msg)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 1411, in assert_allclose\r\n13:00:56     verbose=verbose, header=header, equal_nan=equal_nan)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 796, in assert_array_compare\r\n13:00:56     raise AssertionError(msg)\r\n13:00:56 AssertionError: \r\n13:00:56 Not equal to tolerance rtol=1e-06, atol=1e-06\r\n13:00:56 None\r\n13:00:56 (mismatch 100.0%)\r\n13:00:56  x: array([[5, 7, 9]])\r\n13:00:56  y: array([[ 0.,  0.,  0.]], dtype=float16)\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testArray (__main__.Bfloat16NumPyTest)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 172, in testArray\r\n13:00:56     self.assertEqual(\"[[bfloat16(1) bfloat16(2) bfloat16(3)]]\", str(x))\r\n13:00:56 AssertionError: '[[bfloat16(1) bfloat16(2) bfloat16(3)]]' != '[[bfloat16(0) bfloat16(0) bfloat16(0)]]'\r\n13:00:56 - [[bfloat16(1) bfloat16(2) bfloat16(3)]]\r\n13:00:56 ?            ^           ^           ^\r\n13:00:56 + [[bfloat16(0) bfloat16(0) bfloat16(0)]]\r\n13:00:56 ?            ^           ^           ^\r\n13:00:56 \r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testCasts (__main__.Bfloat16NumPyTest)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 181, in testCasts\r\n13:00:56     self.assertTrue(np.all(x == y))\r\n13:00:56 AssertionError: False is not true\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testLogSumExp (__main__.Bfloat16NumPyTest)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 196, in testLogSumExp\r\n13:00:56     atol=2e-2)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1083, in assertAllClose\r\n13:00:56     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1053, in _assertArrayLikeAllClose\r\n13:00:56     np.testing.assert_allclose(a, b, rtol=rtol, atol=atol, err_msg=msg)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 1411, in assert_allclose\r\n13:00:56     verbose=verbose, header=header, equal_nan=equal_nan)\r\n13:00:56   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 796, in assert_array_compare\r\n13:00:56     raise AssertionError(msg)\r\n13:00:56 AssertionError: \r\n13:00:56 Not equal to tolerance rtol=1e-06, atol=0.02\r\n13:00:56 None\r\n13:00:56 (mismatch 100.0%)\r\n13:00:56  x: array([[ 4.048587,  5.048587,  6.048587]], dtype=float32)\r\n13:00:56  y: array([[ 0.693359,  0.693359,  0.693359]], dtype=float16)\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testAdd (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 89, in testAdd\r\n13:00:56     self._assertFloatIdentical(1, float(bfloat16(1) + bfloat16(0)))\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 48, in _assertFloatIdentical\r\n13:00:56     self.assertEqual(v, w)\r\n13:00:56 AssertionError: 1 != 0.0\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testDiv (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 123, in testDiv\r\n13:00:56     self.assertTrue(math.isnan(float(bfloat16(0) / bfloat16(0))))\r\n13:00:56 AssertionError: False is not true\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testEqual (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 156, in testEqual\r\n13:00:56     self.assertEqual(v == w, bfloat16(v) == bfloat16(w))\r\n13:00:56 AssertionError: False != True\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testGreater (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 146, in testGreater\r\n13:00:56     self.assertEqual(v > w, bfloat16(v) > bfloat16(w))\r\n13:00:56 AssertionError: True != False\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testGreaterEqual (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 151, in testGreaterEqual\r\n13:00:56     self.assertEqual(v >= w, bfloat16(v) >= bfloat16(w))\r\n13:00:56 AssertionError: False != True\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testHash (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 79, in testHash\r\n13:00:56     self.assertEqual(0x3f80, hash(bfloat16(1.0)))\r\n13:00:56 AssertionError: 16256 != 0\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testLess (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 136, in testLess\r\n13:00:56     self.assertEqual(v < w, bfloat16(v) < bfloat16(w))\r\n13:00:56 AssertionError: True != False\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testLessEqual (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 141, in testLessEqual\r\n13:00:56     self.assertEqual(v <= w, bfloat16(v) <= bfloat16(w))\r\n13:00:56 AssertionError: False != True\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testMul (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 114, in testMul\r\n13:00:56     self._assertFloatIdentical(-1, float(bfloat16(1) * bfloat16(-1)))\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 48, in _assertFloatIdentical\r\n13:00:56     self.assertEqual(v, w)\r\n13:00:56 AssertionError: -1 != 0.0\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testNegate (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 85, in testNegate\r\n13:00:56     self._assertFloatIdentical(-v, float(-bfloat16(v)))\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 48, in _assertFloatIdentical\r\n13:00:56     self.assertEqual(v, w)\r\n13:00:56 AssertionError: -0.0 != 4.591774807899561e-41\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testNotEqual (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 161, in testNotEqual\r\n13:00:56     self.assertEqual(v != w, bfloat16(v) != bfloat16(w))\r\n13:00:56 AssertionError: True != False\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testRepr (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 69, in testRepr\r\n13:00:56     self.assertEqual(\"bfloat16(1)\", repr(bfloat16(1)))\r\n13:00:56 AssertionError: 'bfloat16(1)' != 'bfloat16(0)'\r\n13:00:56 - bfloat16(1)\r\n13:00:56 ?          ^\r\n13:00:56 + bfloat16(0)\r\n13:00:56 ?          ^\r\n13:00:56 \r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testRoundTripToFloat (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 52, in testRoundTripToFloat\r\n13:00:56     self._assertFloatIdentical(v, float(bfloat16(v)))\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 48, in _assertFloatIdentical\r\n13:00:56     self.assertEqual(v, w)\r\n13:00:56 AssertionError: 1.0 != 0.0\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testRoundTripToInt (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 56, in testRoundTripToInt\r\n13:00:56     self.assertEqual(v, int(bfloat16(v)))\r\n13:00:56 AssertionError: -256 != 0\r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testStr (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 60, in testStr\r\n13:00:56     self.assertEqual(\"1\", str(bfloat16(1.0)))\r\n13:00:56 AssertionError: '1' != '0'\r\n13:00:56 - 1\r\n13:00:56 + 0\r\n13:00:56 \r\n13:00:56 \r\n13:00:56 ======================================================================\r\n13:00:56 FAIL: testSub (__main__.Bfloat16Test)\r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Traceback (most recent call last):\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 101, in testSub\r\n13:00:56     self._assertFloatIdentical(1, float(bfloat16(1) - bfloat16(0)))\r\n13:00:56   File \"\\\\?\\C:\\tmp\\Bazel.runfiles_5lnmqasq\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\lib\\core\\bfloat16_test.py\", line 48, in _assertFloatIdentical\r\n13:00:56     self.assertEqual(v, w)\r\n13:00:56 AssertionError: 1 != 0.0\r\n13:00:56 \r\n13:00:56 ----------------------------------------------------------------------\r\n13:00:56 Ran 23 tests in 0.014s\r\n13:00:56 \r\n13:00:56 FAILED (failures=20)\r\n13:00:56 not close where =  (array([0, 0, 0], dtype=int64), array([0, 1, 2], dtype=int64))\r\n13:00:56 not close lhs =  [5 7 9]\r\n13:00:56 not close rhs =  [ 0.  0.  0.]\r\n13:00:56 not close dif =  [ 5.  7.  9.]\r\n13:00:56 not close tol =  [  1.01327896e-06   1.01327896e-06   1.01327896e-06]\r\n13:00:56 dtype = int32, shape = (1, 3)\r\n13:00:56 not close where =  (array([0, 0, 0], dtype=int64), array([0, 1, 2], dtype=int64))\r\n13:00:56 not close lhs =  [ 4.04858732  5.04858732  6.04858732]\r\n13:00:56 not close rhs =  [ 0.69335938  0.69335938  0.69335938]\r\n13:00:56 not close dif =  [ 3.35522795  4.35522795  5.35522795]\r\n13:00:56 not close tol =  [ 0.02000427  0.02000427  0.02000427]\r\n13:00:56 dtype = float32, shape = (1, 3)\r\n13:00:56 ================================================================================\r\n```\r\n\r\n\r\n@gunan ", "comments": ["seems an duplicate of #15297", "@facaiy Thanks!"]}, {"number": 15360, "title": "python(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated", "body": "cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/python/tools/freeze_graph \\\r\n> --input_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/inception_v4_inf_graph.pb \\\r\n> --input_checkpoint=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/my_train_10/model.ckpt \\\r\n> --input_binary=true \\\r\n> --output_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/frozen_inception_v4.pb \\\r\n> --output_node_names=InceptionV4/Predictions/Reshape_1\r\npython(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated\r\n*** set a breakpoint in malloc_error_break to debug\r\nAbort trap: 6\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It looks like caused by incorrect python version. Do you run .configure before build freeze_graph?", "Have I written custom code: No\r\nOS Platform and Distribution: macOS High Sierra\r\nTensorFlow installed from - virtualenv\r\nTensorFlow version - 1.4.1\r\nBazel version - 0.9.0\r\nCUDA/cuDNN version\r\nGPU model and memory\r\nExact command to reproduce - bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/dir", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes, I got the same problem on Mac, CPU version", "This appears to be a Bazel issue. For tensorflow 1.4.1, I downgraded to Bazel 0.6.1 (not 0.9.0) and that fixed the `malloc pointer being freed was not allocated` error. \r\nMy specs are:\r\n- macOS Sierra,\r\n- Tensorflow r1.4\r\n- Bazel 0.6.1\r\n- No GPU/Cuda", "Tried Bazel 0.6.1 but still got the same error message:\r\npython(10450,0x7fff943f8340) malloc: *** error for object 0x1c16f928c8: pointer being freed was not allocated\r\n*** set a breakpoint in malloc_error_break to debug\r\nAbort trap: 6", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Same error with:\r\n\r\n- TensorFlow 1.6\r\n- Bazel 0.11.1-homebrew\r\n- MacOS High Sierra\r\n\r\nAny updates?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Same error with:\r\n\r\n- Tensorflow 1.5\r\n- Bazel 0.9.0\r\n- MacOS High Sierra  ", "error with:\r\n- TF 1.7.0 rc1 `CPU`\r\n- Bazel 0.11.1\r\n- MacOS Sierra\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "From my point of view, you can close the issue. I tested it with Tensorflow 1.7. It ran without problem. Thanks a lot!", "Thank you for reporting back!", "solved by:\r\n```\r\ndiff --git a/tensorflow/tensorflow/tf_version_script.lds b/tensorflow/tensorflow/tf_version_script.lds\r\nindex 6b28943f01..39d258c3b7 100644\r\n--- a/tensorflow/tensorflow/tf_version_script.lds\r\n+++ b/tensorflow/tensorflow/tf_version_script.lds\r\n@@ -6,6 +6,7 @@ tensorflow {\r\n     *TFE_*;\r\n     *nsync_*;\r\n     *pywrap_xla*;\r\n+    *stream_executor*;\r\n   local:\r\n     *;\r\n };\r\n```"]}, {"number": 15359, "title": "code is jammed when evaluate", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10\r\n- **TensorFlow installed from (source or binary)**:pip3\r\n- **TensorFlow version (use command below)**:1.4\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:8.0 6.46\r\n- **GPU model and memory**:2GB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nthe code is jammed when run `eval_results = pc_classifier.evaluate(input_fn = pcd.test_input_fn_np)`\r\nI built model under the guidance of `cnn_mnist.py` . the differences are that I change the network architecture  and using my input_functioin. Everything is normal during the training process, but it jammed during the evaluate process. \r\nthe call stack is:\r\n![default](https://user-images.githubusercontent.com/22407275/33982216-b1cba1e0-e0ea-11e7-85e6-68d8f91457ff.JPG)\r\nand it jammed at the code\r\n`    for hook in self._hooks:\r\n      hook.after_run(\r\n          run_context,\r\n          session_run_hook.SessionRunValues(\r\n              results=outputs[hook] if hook in outputs else None,\r\n              options=options,\r\n              run_metadata=run_metadata))`\r\n\r\nwhat's the problem?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15358, "title": "how can I see the graphs in tensorboard?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This looks like a simple user question. Please follow our tutorials, or reach out to stackoverflow.\r\nIf you suspect there is a bug, you will need to file an issue under tensorboard repository."]}, {"number": 15357, "title": "Could not find a version that satisfies the requirement tensorflow (from versions: )", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nCentos7\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nwhen i use \u2018pip install python\u2019\uff0ci got the follower errors\uff1a\r\n[root@compute1 Object-Detector-App]# pip install tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n[root@compute1 Object-Detector-App]# \r\n[root@compute1 Object-Detector-App]# \r\n[root@compute1 Object-Detector-App]# python -V\r\nPython 2.7.14\r\n[root@compute1 Object-Detector-App]# \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 15356, "title": "Branch 178996911", "body": "- Improvement over last PR in that we rolled back a break in the CPU tests\r\n- Fixed the same merge conflicts in tensorflow/core/platform/cloud/gcs_dns_cache.cc\r\n- Fixed a lot of trivial merge conflicts in keras", "comments": []}, {"number": 15355, "title": "Dockerfile.devel-gpu: optimize the size of the generated image", "body": "- Use `nvidia/cuda:9.0-base-ubuntu16.04` as the base image to select\r\n  just the CUDA libraries we need.\r\n- Remove the installed static libraries.\r\n- Remove the dependency on openjdk-8 since Bazel ships with a local copy.\r\n- Perform a shallow clone of the repository.\r\n\r\nThe image is 2.94GB, down from 4.87GB.\r\n\r\nSigned-off-by: Felix Abecassis <fabecassis@nvidia.com>\r\n\r\nSee initial discussion here: https://github.com/tensorflow/tensorflow/issues/15284\r\n@gunan @martinwicke @yongtang ", "comments": ["Can one of the admins verify this patch?", "Oh, per the [Dockerfile best-practices documentation](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#run), `apt-get clean` is not needed, I also removed it here.", "Jenkins, test this please.", "+1 for size optimization \ud83d\udc4d ", "@angersson FYI", "This is great! Thanks!"]}, {"number": 15354, "title": "CPU: Support for DT_STRING type in ScatterNd ", "body": "The PR is proposed to fix #15321.\r\n\r\n~~However, the solution seems not idea. Because `ScatterNdOP` use ADD op by default, which doesn't make sense for string type. I prefer to use ASSIGN than ADD, but the modification will change the op's behavior.~~\r\n\r\n### How to test \r\n\r\n+ [x] add test.\r\n+ [ ]  pass all tests.", "comments": ["Can one of the admins verify this patch?", "@facaiy sorry this has taken so long, but since the docstring has moved from the op registration to the APIDef files. Could you move the docstring there?\r\n\r\nThank you!", "@martinwicke Hi, I have moved the docstring to API def file.", "@josh11b I believe that all your comments have been resolved, and could you take a look? Thanks.", "@josh11b could you take another look?", "Thank @martinwicke . I have fixed python3 test case, and could you help restart all tests?"]}, {"number": 15353, "title": "[Go]: Make op wrapper generation more robust.", "body": "- Since Go 1.8, GOPATH has a default value, so handle\r\n  that (https://golang.org/doc/go1.8#gopath)\r\n- generate.sh expected bash (for the string substitution syntax)\r\n  while 'sh' may point to another shell. So explicitly require bash.", "comments": ["Jenkins, test this please"]}, {"number": 15352, "title": "matmul causing segmentation fault in rev1.4.0", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.4.0\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n0.8.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nHere is the output from tf_env_collect.sh\r\n\r\n== cat /etc/issue ===============================================\r\nLinux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.0.post1)\r\ntensorflow (1.4.0)\r\ntensorflow-tensorboard (0.1.8)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.0\r\ntf.GIT_VERSION = b'v1.3.0-rc1-5916-g18c864c'\r\ntf.COMPILER_VERSION = b'v1.3.0-rc1-5916-g18c864c'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/lib/nx/X11/Xinerama:/usr/lib/nx/X11\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntensorflow-src/tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nSeeing a segmentation fault on matmul operation.\r\n\r\n### Source code / logs\r\nHere is the source code:\r\nimport tensorflow as tf\r\na = tf.random_normal([100, 200])\r\nb = tf.random_normal([200, 300])\r\nres = tf.matmul(a, b)\r\ntf.Session().run(res)\r\n\r\nHere is the backtrace from gdb:\r\n\r\n#0  0x00007fff513b9296 in Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>::operator()(float*, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer> const&, long, long, long, long) ()\r\n   from /tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007fff5142ce94 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 48, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()\r\n   from /tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fff4eab29c1 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()\r\n   from /tensorflow/python/../libtensorflow_framework.so\r\n#3  0x00007fff4eab07d7 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /tensorflow/python/../---Type <return> to continue, or q <return> to quit---\r\nlibtensorflow_framework.so\r\n#4  0x00007fff4e2ecc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007ffff7bc16ba in start_thread (arg=0x7ffe06ffd700)\r\n    at pthread_create.c:333\r\n#6  0x00007ffff71e73dd in clone ()\r\n    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@rmlarsen @benoitsteiner Can you take a look at this one?", "I'm also hitting this issue (same bt with gdb) for Python 3.5.2, TF 1.4.1. It occurs with Ubuntu 16.04 on a c5 instance on AWS.", "@coolchicha any progress on this? I'm having a similar problem trying to compile a graph using tfcompile. \r\nGDB traceback is \r\n\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n0x0000000000425bed in void Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::evalProduct<true, true, false, 0>(float*) const ()\r\n(gdb) bt\r\n#0  0x0000000000425bed in void Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::evalProduct<true, true, false, 0>(float*) const ()\r\n#1  0x0000000000431465 in void tensorflow::xla::EigenConvF32Impl<Eigen::ThreadPoolDevice>(Eigen::ThreadPoolDevice const&, float*, float*, float*, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long, long long) ()\r\n#2  0x0000000000403972 in __tensorflow_compiler_aot_tests_mnist_x86__convolutional_mnist ()\r\n#3  0x000000000000001c in ?? ()\r\n#4  0x0000000000000001 in ?? ()\r\n#5  0x0000000000000003 in ?? ()\r\n#6  0x0000000000000003 in ?? ()\r\n#7  0x0000000000000001 in ?? ()\r\n#8  0x0000000000000020 in ?? ()\r\n#9  0x000000000000001a in ?? ()\r\n#10 0x000000000000001a in ?? ()\r\n#11 0x0000000000000001 in ?? ()\r\n#12 0x0000000000000001 in ?? ()\r\n#13 0x0000000000000000 in ?? ()\r\n(gdb) quit\r\n\r\n```\r\n\r\nEDIT: I already tried to disable optmization flags like those appointed by #9638, still having the issue.", "is this problem still occuring?", "i hit this problem while saved_model running online for predicting for some days. caused core dump. how to resolve it . any idea?", "Please check with the latest version of TensorFlow. Feel free to reopen if the issues still persists.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=15352\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=15352\">No</a>\n", "> is this problem still occuring?\r\n\r\nHi, Yes The problem persist till now.\r\nwhen i try to execute bellow line in python 3.5, and my feature vector is 450x512, the error occured.\r\nError: \"segmentation fault (core dumped)\"\r\nsim_mat = np.matmul(query_feats, np.transpose(gallery_feats)) \r\nany idea?\r\n"]}, {"number": 15351, "title": "questions about shared variables between CPU and GPU ", "body": "Dear developers:\r\n\r\nI looked at cifar10_multi_gpu_train.py, the idea about sharing model params among CPU and GPUs is inspiring. However, I have a few questions that I want to understand well before I can apply to my own problem. \r\n\r\nAs far as I can tell, the model params are stored in CPU by looking into the tower_loss() function since cifar10.py explicitly pinned down all variables at \"/cpu:0\". Then function train() wraps up tower_loss() with gpu device like this:\r\n\r\n`for i in xrange(FLAGS.num_gpus):`\r\n`       with tf.device('/gpu:%d' % i):`\r\n`           loss = tower_loss(scope)`\r\n`           tf.get_variable_scope().reuse_variables()`\r\n\r\nUsing this way, I bet model params are stored in CPU and there is no extra copy anywhere because it is set to just reuse the same variables in the scope, while GPU stored gradient operations written in tower_loss(). In the way, I believe the model params have to transfer from CPU to GPU whenever GPU calls for these params to operate upon. It would be inefficient if doing multiple transfer to GPU I believe. I notice \"identity\" operation in the end of tower_loss(). Is \"tf.identity(total_loss)\" doing the trick so CPU transfers model params to the GPU only once, then GPU just holds the local copy from then on?\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15350, "title": "Branch 178965261", "body": "Fixed a minor merge conflict in tensorflow/core/platform/cloud/gcs_dns_cache.cc", "comments": ["cc @gunan, looks like all the cpu python builds failed with `ERROR: /tmpfs/tmp/bazel/external/local_config_python/BUILD:163:1: declared output 'external/local_config_python/numpy_include/numpy/_numpyconfig.h' was not created by genrule`. Is there any change this could be related to the switch we did in cl/178943331?\r\ncc @ericburnett", "The other push is merged. closing this one."]}, {"number": 15349, "title": "Revert \"Add batch support for various image_ops (#14854)\"", "body": "This reverts commit 20aa9e0a9f129ed929cea1fb45ec12b7be3ac68e.\r\n\r\n@martinwicke fyi", "comments": ["@JoshVarty fyi", "@JoshVarty The issue is that the code changes make the 3D versions of these slower, and sadly, even the 4D versions are slower. @jhseu added benchmarks, let's try again with something with improved performance.", "Jenkins, test this please", "Jenkins, test this please"]}, {"number": 15348, "title": "Benchmarks for flipping and random flipping", "body": "@martinwicke fyi", "comments": ["Jenkins, test this please"]}, {"number": 15347, "title": "Object Detection frozen graph issue", "body": "# Training environment \r\n\r\n### System information\r\n- MAC OSX 10.13.2\r\n- Tensorflow 1.4-rc1 (GPU support)\r\n- Installation through source\r\n- Python 3.6 (Anaconda)\r\n- Bazel 0.8\r\n- CUDA 9/ cuDNN7\r\n- GPU 1080Ti\r\n\r\nI have trained my own model for object detection. Extracted graph from checkpoint as well. This graph is working with the Mac GPU and CPU. It is also working with Raspberry PI but when I am trying to run it on AWS EC2 (Deep Learning AMI (Amazon Linux) and Deep Learning AMI (Ubuntu) both) instance. Built tensorflow 1.4-rc1 from source as well as installed using pip but it keep giving me following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1322     try:\r\n-> 1323       return fn(*args)\r\n   1324     except errors.OpError as e:\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1301                                    feed_dict, fetch_list, target_list,\r\n-> 1302                                    status, run_metadata)\r\n   1303 \r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    472             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 473             c_api.TF_GetCode(self.status.status))\r\n    474     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nInvalidArgumentError: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-25-7493eea60222> in <module>()\r\n     20       (boxes, scores, classes, num) = sess.run(\r\n     21           [detection_boxes, detection_scores, detection_classes, num_detections],\r\n---> 22           feed_dict={image_tensor: image_np_expanded})\r\n     23       # Visualization of the results of a detection.\r\n     24       vis_util.visualize_boxes_and_labels_on_image_array(\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    887     try:\r\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 889                          run_metadata_ptr)\r\n    890       if run_metadata:\r\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1119       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1120                              feed_dict_tensor, options, run_metadata)\r\n   1121     else:\r\n   1122       results = []\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1315     if handle is None:\r\n   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n-> 1317                            options, run_metadata)\r\n   1318     else:\r\n   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1334         except KeyError:\r\n   1335           pass\r\n-> 1336       raise type(e)(node_def, op, message)\r\n   1337 \r\n   1338   def _extend_graph(self):\r\n\r\nInvalidArgumentError: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]\r\n\r\nCaused by op 'Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where', defined at:\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\r\n    self.io_loop.start()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-21-0d8b8f2357e8>\", line 7, in <module>\r\n    tf.import_graph_def(od_graph_def, name='')\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]\r\n```\r\n\r\nWhen I am extracting frozen graph on EC2 instance from the same previous checkpoint it gives me much lower accuracy than my MAC and raspberryPI", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@angersson according to me frozen graph should be platform independent but in this case it is not. Also creating graph from check point on another machine is giving different results. It should be addressed as a bug instead of installation or environment problem. I have tried t2, p2, m5 instances built tensorflow with GPU and non GPU support. Graph is working fine on raspberry pi tensorflow build from source. "]}, {"number": 15346, "title": "Update location for x86_64 android build", "body": "See https://github.com/tensorflow/tensorflow/issues/15345", "comments": []}, {"number": 15345, "title": "Using wrong location for x86_64 android build", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nA: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nA: OSX 10.13.1\r\n- **TensorFlow installed from (source or binary)**:\r\nA: Source\r\n- **TensorFlow version (use command below)**:\r\nA: 1.4.1\r\n- **Python version**: \r\nA: 2.7\r\n- **Bazel version (if compiling from source)**:\r\nA: 0.8\r\n- **GCC/Compiler version (if compiling from source)**:\r\nA:\r\n```\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 9.0.0 (clang-900.0.38)\r\nTarget: x86_64-apple-darwin17.2.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n`make -f tensorflow/contrib/makefile/Makefile TARGET=ANDROID ANDROID_ARCH=x86_64`\r\n\r\n### Describe the problem\r\nAndroid x86_64 build fails with Makefile using make -f tensorflow/contrib/makefile/Makefile TARGET=ANDROID ANDROID_ARCH=x86_64 because it cannot find the binary `x86-64-linux-android-g++`\r\n\r\nIt can be fixed by changing the `tensorflow/contrib/makefile/Makefile` at line 303 from \r\n`BIN_PREFIX := x86-64-linux-android` to\r\n`BIN_PREFIX := x86_64-linux-android`\r\n", "comments": ["I've prepped a PR for this.", "#15346 fixes this!"]}, {"number": 15344, "title": "Fix broken link in tensorflow lite readme", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 15343, "title": "Iterator on cached tf.data Dataset cannot be reinitialized ", "body": "Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets, one for validation and one for training. The iterator can however only be initialized once per cached dataset. Seems to me like the iterator should remove the lock file when being reinitialized, it is not in my case and that is why I get this issue. Here's a minimal example with only one cached dataset.\r\n\r\n(basic system information below)\r\n\r\n### Example\r\n```python\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndata = np.random.rand(10, 3).astype(np.float32)\r\ndataset = tf.data.Dataset.from_tensor_slices(data)\r\nbatches = dataset.shuffle(10).repeat().batch(5)\r\n\r\nconfig = tf.ConfigProto(device_count = {'GPU': 0})\r\nsess = tf.Session(config=config)\r\n\r\ncache_dir = os.path.join(os.getcwd(), 'cache_dir')\r\ntry:\r\n    os.makedirs(cache_dir)\r\nexcept OSError:\r\n    print('Cache directory already exists')\r\n\r\ncached = batches.cache(os.path.join(cache_dir, 'cache'))\r\niterator = tf.data.Iterator.from_structure(output_types=tf.float32, output_shapes=(5, 3))\r\nbatch = iterator.get_next()\r\n\r\ninit1 = iterator.make_initializer(cached)\r\ninit2 = iterator.make_initializer(batches)\r\n\r\nsess.run(init1)\r\nsess.run(batch)\r\n```\r\n> array([[ 0.11960778,  0.3081578 ,  0.96522039],\r\n       [ 0.90339011,  0.12458269,  0.30650312],\r\n       [ 0.58160347,  0.55877644,  0.50363588],\r\n       [ 0.2350398 ,  0.33509603,  0.4165386 ],\r\n       [ 0.76757395,  0.50134581,  0.93601096]], dtype=float32)\r\n\r\n```python\r\nsess.run(init2)\r\nsess.run(batch)\r\n```\r\n> array([[ 0.76757395,  0.50134581,  0.93601096],\r\n       [ 0.2350398 ,  0.33509603,  0.4165386 ],\r\n       [ 0.90339011,  0.12458269,  0.30650312],\r\n       [ 0.13266359,  0.82675195,  0.26691398],\r\n       [ 0.58160347,  0.55877644,  0.50363588]], dtype=float32)\r\n\r\n```python\r\nsess.run(init1)\r\nsess.run(batch)\r\n```\r\n> AlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/home/ubuntu/ai_notebooks/notebooks/projects/deep-purple/cache_dir/cache.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1513187725\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[5,3]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\n\r\n### Sytem information\r\nTensorflow version: v1.4.0-rc1-11-g130a514 1.4.0 (installed from pip)\r\nPython version: 3.5.2\r\nOS: Linux Ubuntu 16.04.3\r\nCUDA: 8.0.61\r\ncuDNN: 6", "comments": ["Brennan, can you please take a look?", "As a temporary fix I tried deleting the lockfile before reinitializing. When I do I keep getting new cache files after reinit. Here's an example from a cache directory with a larger dataset:\r\n\r\n```bash\r\n1199681441 Dec 13 19:41 cache.data-00000-of-00001.tempstate12238922573150074415\r\n1199681441 Dec 13 19:48 cache.data-00000-of-00001.tempstate18257683081874428073\r\n1199681441 Dec 13 19:45 cache.data-00000-of-00001.tempstate5944011296618694888\r\n...\r\n```\r\n\r\nDouble checked and all have the same content.", "Hey @agrinh \r\n\r\nIf you have not finished reading the underlying input data, then we do not release the lock. Can you read the entire underlying dataset before switching between the validation / training datasets?\r\n\r\nAll the best,\r\n-Brennan", "@saeta Thanks for helping out, that seemed to solve that particular problem.\r\n\r\nI was applying the `repeat()` before caching (both in the example and in my real data loader), so I assume the cache releases the lock and produces the index file on `tf.errors.OutOfRangeError`. When I move the repeat to after the caching and make sure to run through all data this example works.\r\n\r\nPerhaps this behaviour could be documented. Some interactions (e.g. `repeat` - `cache`, `shuffle` - `cache` etc.) are pretty non-obvious to me and it would save me a huge amount of time to get at least some of those details listed.\r\n\r\nThanks again,\r\nAgrin", "@agrinh Funny you should ask. I and @jsimsa have been working on a datasets performance guide we hope to publish soon, and we cover recommended order-of-operations. I'll make sure `repeat` vs `cache` and `shuffle` vs `cache` are included. :-) \r\n\r\nNice sleuthing and getting it all working!!", "Awesome, looking forward to it, thanks again @saeta ", "@saeta Sorry for hijacking the thread, is there a release date for the new performance guide? and does it include FP16 performance recommendations?", "Although it's not yet complete, the new dataset performance guide is available at: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/datasets_performance.md It doesn't include FP16 performance recommendations as that usually occurs on the accelerator device (i.e. GPU/TPU), while the input pipelines run on the attached CPU. Hope this helps!", "Thanks @saeta!\r\n", "@sata @mrry Seems that `shuffle_and_repeat` with cache doesn't work instead `dataset.shuffle(buffer_size, reshuffle_each_iteration=True).repeat(count)` works. \r\nDocs tells that is the [same call](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/shuffle_and_repeat). Is there any different internal details that invalid the iterator of `shuffle_and_repeat` combined with cache?", "@bhack Please open a new issue with complete details of the program you're running and the expected and observed behavior.", "@mrry What is the correct sequence with cache? `.cache` and then `.shuffle_and_repeat`?", "@bhack Please open a new issue with complete details of the program you're running and the expected and observed behavior.\r\n\r\n", "@mrry We will isolate the code and open an new issue but generally documenting a little bit more about the command sequence could in `dataset_performance.md` could help.", "@mrry We start with https://github.com/tensorflow/tensorflow/issues/18266"]}]