[{"number": 32707, "title": "Out of memory error during training", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 / Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (Win10)\r\n- TensorFlow version (use command below): 2.0.0rc1\r\n- Python version: 3.6.8 (Colab) / 3.6.9 (Win10)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Cuda 10 CuDNN 7.6.3.30 (Win10)\r\n- GPU model and memory: Geforce 1080 Ti, 12 GB (Win10)\r\n\r\n**Describe the current behavior**\r\nI am getting an out of memory error during the training of a encoder-decoder model using the subclassing api of tensorflow 2.\r\n\r\n**Describe the expected behavior**\r\nOnce the graph is built and the batch size is constant, the memory usage of the model should stay the same so that there is no out of memory error upcoming during the training process.\r\n\r\n**Code to reproduce the issue**\r\nI have created a minimum example out of my model in google colab:\r\nhttps://colab.research.google.com/drive/1Xbzcj0ZlALhLhJhv-JaKSVUu3rfB3Urh\r\n\r\n**Other info / logs**\r\nThe error occurs at about example index (current_index) 25000 of 80000, so there must be an issue that something is written on the gpu memory which leads to the following oom error:\r\n\r\n```\r\n<ipython-input-2-fe0e8431350e> in train_model(self, data, batch_size)\r\n     27 \r\n     28             with tf.GradientTape() as tape:\r\n---> 29                 batch_output = self.model([input_sequences_batch, output_sequences_batch])\r\n     30                 loss = self.loss_fn(data[1, current_index:current_index + batch_size, :], batch_output)\r\n     31 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    889           with base_layer_utils.autocast_context_manager(\r\n    890               self._compute_dtype):\r\n--> 891             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    892           self._handle_activity_regularization(inputs, outputs)\r\n    893           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n<ipython-input-2-fe0e8431350e> in call(self, inputs)\r\n     72 \r\n     73         decoder_output = self.sequence_decoder(self.embeddings(output_sequence[:, :-1]), initial_state=[state_h, state_c])\r\n---> 74         output = self.time_distributed_dense(decoder_output)\r\n     75         return output\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    889           with base_layer_utils.autocast_context_manager(\r\n    890               self._compute_dtype):\r\n--> 891             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    892           self._handle_activity_regularization(inputs, outputs)\r\n    893           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/wrappers.py in call(self, inputs, training, mask)\r\n    252         inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\r\n    253         kwargs['mask'] = K.reshape(mask, inner_mask_shape)\r\n--> 254       y = self.layer(inputs, **kwargs)\r\n    255       # Shape: (num_samples, timesteps, ...)\r\n    256       output_shape = self.compute_output_shape(input_shape).as_list()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    889           with base_layer_utils.autocast_context_manager(\r\n    890               self._compute_dtype):\r\n--> 891             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    892           self._handle_activity_regularization(inputs, outputs)\r\n    893           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py in call(self, inputs)\r\n   1056         outputs = gen_math_ops.mat_mul(inputs, self.kernel)\r\n   1057     if self.use_bias:\r\n-> 1058       outputs = nn.bias_add(outputs, self.bias)\r\n   1059     if self.activation is not None:\r\n   1060       return self.activation(outputs)  # pylint: disable=not-callable\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py in bias_add(value, bias, data_format, name)\r\n   2716       value = ops.convert_to_tensor(value, name=\"input\")\r\n   2717       bias = ops.convert_to_tensor(bias, dtype=value.dtype, name=\"bias\")\r\n-> 2718     return gen_nn_ops.bias_add(value, bias, data_format=data_format, name=name)\r\n   2719 \r\n   2720 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py in bias_add(value, bias, data_format, name)\r\n    753       else:\r\n    754         message = e.message\r\n--> 755       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n    756   # Add nodes to the TensorFlow graph.\r\n    757   if data_format is None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[3136,50000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd] name: model/time_distributed/dense/BiasAdd/\r\n```", "comments": ["I could reproduce the issue with Tensorflow 2.0.0.rc1. \r\nPlease take a look at colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/43f6f6ca0b5c59ebe84bb8118489db99/untitled161.ipynb). Thanks!", "@tocab Looks like shape of tensor is very big and consuming more memory. Can you try to optimize some parameters so that tensor size and memory requirements works well with your GPU? Also, can you try 2.0.0rc2? Thanks!", "I get the same error also with 2.0.0rc2. How can I optimize tensor size and memory requirements? With not using the keras api in tensorflow 1, the training never got an oom after it startet and the batch size stayed the same.\r\n\r\nAnother question: Is it possible to finalize the graph with the keras api? Then I could test if more parameters are added during the training that leads to the oom.", "I tested it with the final release 2.0.0 and got the same error", "Hi,\r\n\r\nAny news about this problem, because I have same issue. With 4x 2080Ti I have problem with simple unet model with input size 320x480", "This is expected, and stems from the fact that you're running eagerly.\r\n\r\nIn graph mode, there are a number of optimizations to reuse of aggressively free memory based on an analysis of the overall dataflow graph. A good example to illustrate this is buffer forwarding:\r\n```\r\nk = 100000  # Just some large number\r\nx = tf.ones((k, k))\r\ny = x + 1.\r\nz = y ** 2\r\n```\r\n\r\nIn graph mode, the runtime can observe that `y` is the only consumer of `x`, and `z` is the only consumer of `y`. So it just allocates one chunk of memory and does all of the operations in place because it can prove that that is safe. On the other hand, if you run that code eagerly then the Python handles for `x`, `y`, and `z` would be alive at the same time, and you could subsequently use any or all of them; the runtime has no way of knowing what you'll do next. So it has to keep 3x as much data in memory as the graph versions since it can't prove that in place mutations are safe. (And there are a number of similar optimizations. See [this presentation](https://web.stanford.edu/class/cs245/slides/TFGraphOptimizationsStanford.pdf) for a more thorough summary.)\r\n\r\nSo, back to your example. I doubled the batch size just to force an OOM in the first step (Note that you need to pass `BATCH_SIZE` to `model_trainer.train_model` in your colab to see the effect), and if instead of:\r\n```\r\n            with tf.GradientTape() as tape:\r\n                batch_output = self.model([input_sequences_batch, output_sequences_batch])\r\n                loss = self.loss_fn(data[1, current_index:current_index + batch_size, :], batch_output)\r\n\r\n            gradients = tape.gradient(loss, self.model.trainable_variables)\r\n            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\r\n```\r\n\r\nyou create a `tf.function` outside of the loop:\r\n```\r\n        @tf.function\r\n        def train_step(features, labels):\r\n          with tf.GradientTape() as tape:\r\n                batch_output = self.model([input_sequences_batch, output_sequences_batch])\r\n                loss = self.loss_fn(data[1, current_index:current_index + batch_size, :], batch_output)\r\n\r\n          gradients = tape.gradient(loss, self.model.trainable_variables)\r\n          self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\r\n          return loss\r\n```\r\nAnd then call it inside the training loop:\r\n```\r\n    loss = train_step([input_sequences_batch, output_sequences_batch],\r\n                               data[1, current_index:current_index + batch_size, :])\r\n```\r\nThe model no longer OOMs. (Because the tf.function can apply all of the same tricks that TF 1.x uses to conserve memory.)\r\n\r\nSo why doesn't the model OOM immediately? EagerTensors behave like python objects, including matching garbage collection semantics. So what happens is that after most loops python's gc is clearing out Tensors in time for the memory to ready for the next batch, but it's not guaranteed. So if gc is ever late, the last batch worth of Tensors are still waiting to be collected and the GPU OOMs.\r\n\r\nHope this helps.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32707\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32707\">No</a>\n"]}, {"number": 32706, "title": "GPU never in use with Java API", "body": "Hi, I followed the instructions with (this)(https://www.tensorflow.org/install/lang_java?hl=zh-cn).\r\nAnd I add my implementations with bert pb model, but the GPUs are never used\r\n![image](https://user-images.githubusercontent.com/7105813/65370990-769ed480-dc91-11e9-80db-244ed652ff9d.png).\r\nI got Tesla K80, and cuda 9.0 \r\n![image](https://user-images.githubusercontent.com/7105813/65371023-bd8cca00-dc91-11e9-98e2-74f53302ed3e.png)\r\n![image](https://user-images.githubusercontent.com/7105813/65371031-e0b77980-dc91-11e9-8b45-3a2a8746b0bf.png)\r\n\r\nAny suggestions?\r\n\r\n\r\n", "comments": ["@itsucks,\r\nProvide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "> @itsucks,\r\n> Provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!\r\n\r\nWell. the system is CentOS Linux release 7.2.1511,\r\nI add the dependency with maven  \r\n\r\n![image](https://user-images.githubusercontent.com/7105813/65474401-408a6c00-deae-11e9-94fc-e5a63eb5a632.png)  \r\n\r\nthe code  \r\n![image](https://user-images.githubusercontent.com/7105813/65474446-7596be80-deae-11e9-8d63-116a35d1c7c0.png)  \r\n\r\nthe results are right, but it never use the GPU\r\nThe whole platform works fine in python\r\n\r\n\r\n", "the command is `mvn -q compile exec:java`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32706\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32706\">No</a>\n", "Is your problem fixed?  how ?"]}, {"number": 32705, "title": "Reset tf.metrics.mean", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):1.8\r\n- Are you willing to contribute it (Yes/No):yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrent usage:\r\nm, op_update = tf.metrics.mean(x)\r\nm is the mean of the stream of x. op_update is the update op of local variable \"count\" and \"total\".\r\n\r\nHowever, it's natural to reset all history of the stream, that is, to reset \"count\" and \"total\" to 0. It could look like:\r\nm, op_update, op_reset = tf.metrics.mean(x).\r\n\r\n\r\n**Will this change the current api? How?**\r\nYes, tf.metrics.mean will have one more output variable.\r\nMaybe other tf.metrics functions should be alike.\r\n\r\n**Who will benefit with this feature?**\r\nI think this feature is natural.\r\nFor example, those who need to measure the mean accuracy in every 20 iterations, all accuracy \r\ndata before these 20 iterations should be discarded.\r\n\r\n\r\n**Any Other info.**\r\n", "comments": [" Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "I decide to close the issue, because I've thinked about it, maybe it's not a good ideal to change the output of a function, that will cause an error for all older versions. Altough this feature is quite natural: just like all calculators has a 'clear' button.\r\n\r\nFor anyone who read this. This 'reset' operation can be easily done outside a session without using tf.metrics.mean, although using it within a session with tf.summary would be more elegant.\r\n\r\n\r\n"]}, {"number": 32704, "title": "nn", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@Ryan-cv,\r\nPlease provide the information asked in the template. Thanks!", "Closing as nothing has been provided", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32704\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32704\">No</a>\n"]}, {"number": 32703, "title": "Keras/tensorflow not working in Command Line ", "body": "Hi Team, \r\n\r\nI am trying to execute my pyhton code using Keras and Numpy Library on command Prompt.\r\nIt is working fine with Jupyter Notebook.\r\n[keras_prediction - Copy.txt](https://github.com/tensorflow/tensorflow/files/3638219/keras_prediction.-.Copy.txt)\r\n\r\n\r\nI am facing the following error.\r\n\r\n\r\n_D:\\Vivek\\Python\\Sigmoid_basic>python keras_prediction.py\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\tensorflow\\python\\platform\\s\r\nelf_check.py\", line 47, in preload_check\r\n    ctypes.WinDLL(build_info.msvcp_dll_name)\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\ctypes\\__init__.py\", line 364, in __init__\r\n\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"keras_prediction.py\", line 2, in <module>\r\n    import keras as ks\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\__init__.py\", line 3,\r\nin <module>\r\n    from . import utils\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\utils\\__init__.py\", li\r\nne 6, in <module>\r\n    from . import conv_utils\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\utils\\conv_utils.py\",\r\nline 9, in <module>\r\n    from .. import backend as K\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\backend\\__init__.py\",\r\nline 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\backend\\load_backend.p\r\ny\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\keras\\backend\\tensorflow_bac\r\nkend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\tensorflow\\__init__.py\", lin\r\ne 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\tensorflow\\python\\__init__.p\r\ny\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\tensorflow\\python\\pywrap_ten\r\nsorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"D:\\Vivek\\Python\\Python_64\\lib\\site-packages\\tensorflow\\python\\platform\\s\r\nelf_check.py\", line 55, in preload_check\r\n    % build_info.msvcp_dll_name)\r\nImportError: Could not find 'msvcp140.dll'. TensorFlow requires that this DLL be\r\n installed in a directory that is named in your %PATH% environment variable. You\r\n may install this DLL by downloading Visual C++ 2015 Redistributable Update 3 fr\r\nom this URL: https://www.microsoft.com/en-us/download/details.aspx?id=53587_\r\n\r\n\r\nPlease find my code attached.\r\n\r\nPlease advise\r\n\r\nThanks and Regards\r\nVivek Srivastava", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\n If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Hi Ravi, \r\nI am using \r\nWindows 7 Platform \r\nPython 3.4 (64 Bit)\r\nTensorflow : 1.14.0\r\n\r\nRegards\r\nVivek Srivastava", "@vicky30mar82 \r\n\r\nI tried executing in command line. Please,find the attached file for your reference.\r\n[errorlog.tar.gz](https://github.com/tensorflow/tensorflow/files/3651913/errorlog.tar.gz)\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@vicky30mar82 \r\n\r\nPlease, let us know if the issue still persists. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 32702, "title": "Keras casts targets to incorrect dtype", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0rc1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nKeras tries to cast targets to the dtypes of the model outputs. Currently it assumes that every model output has a corresponding target, so when doing this casting it just matches outputs and targets up one-to-one. But in the case where some outputs are not part of the loss function (i.e. they were missing from the loss dictionary passed to `compile`), this may match outputs to the wrong targets. Then it casts targets to the wrong dtype, causing errors.\r\n\r\n**Describe the expected behavior**\r\n\r\nKeras should match up targets with the correct output when casting, according to the loss dictionary defined in `compile`.  If a model output is not part of the loss function, then it should be ignored when casting targets.\r\n\r\n**Code to reproduce the issue**\r\n\r\n``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninp = tf.keras.layers.Input(shape=(1,))\r\nout0 = tf.cast(inp, tf.int32)\r\nout1 = tf.cast(inp, tf.float64)\r\n\r\nmodel = tf.keras.Model(inputs=inp, outputs=[out0, out1])\r\n\r\nmodel.compile(loss={model.output_names[1]: tf.losses.mse})\r\n\r\nmodel.evaluate(\r\n    np.ones((1, 1), dtype=np.float32),\r\n    {model.output_names[1]: np.ones((1, 1), dtype=np.float32)},\r\n)\r\n```\r\n\r\nThis results in the error\r\n```\r\nTypeError: Value passed to parameter 'x' has DataType int32 not in list of allowed values: float16, float32, float64, complex64, complex128\r\n```\r\n", "comments": ["Issue replicating for TF-2.0rc1, please find the [gist](https://colab.sandbox.google.com/gist/oanush/b796d39a08fb5c287034ece6853834d3/32702.ipynb) of colab.Thanks!", "Is this issue still open?", "@drasmuss can you please check this issue with `tf-nightly`. When I ran your code with `tf-nightly`, i see the following output.\r\n\r\n```\r\n1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - tf_op_layer_Cast_1_loss: 0.0000e+00\r\n[0.0, 0.0]\r\n```\r\n\r\nPlease close the issue if this issue was resolved for you. Thanks! ", "Yep looks like this is fixed in `tf-nightly`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32702\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32702\">No</a>\n"]}, {"number": 32701, "title": "Segmentation Fault (core dumped) while training on 1.14", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Running a public github repo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): 1.14.0\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: NVIDIA TITAN\r\n\r\n**Describe the current behavior**\r\n\r\nI am attempting to train the neural network in this repo, [sketch2normal](https://github.com/Ansire/sketch2normal)\r\n\r\nEvery time I attempt to train the model, it always gives me an error message `Segmentation fault (core dumped)` at Epoch 0 sometime between 10/449 -  90/449. I'm also getting many warning messages saying that many of the methods being called, like `tf.summary.FileWriter`, `tf.summary.merge`, and more are deprecated.  \r\n\r\nAfter attempting to train with multiple print statements, I found that the place where the code seg faults is in the train function:\r\n```\r\n      def train(self, args):\r\n\r\n        self.d_optim = tf.train.RMSPropOptimizer(learning_rate=args.lr).minimize(self.d_loss, var_list=self.d_vars)\r\n        self.g_optim = tf.train.RMSPropOptimizer(learning_rate=args.lr).minimize(self.g_loss, var_list=self.g_vars)\r\n        self.clip_d_vars_ops = [val.assign(tf.clip_by_value(val, -self.clamp, self.clamp)) for val in self.d_vars]\r\n        tf.global_variables_initializer().run()\r\n\r\n        init_op = tf.global_variables_initializer()\r\n        self.sess.run(init_op)\r\n\r\n        self.g_summary = tf.summary.merge([self.fake_B_sum, self.real_B_sum,self.d_loss_fake_sum, self.g_loss_sum])\r\n        self.d_summary = tf.summary.merge([self.d_loss_real_sum, self.d_loss_sum])\r\n        self.visual_loss_summary = tf.summary.merge([self.pixel_wised_loss_sum, self.masked_loss_sum])\r\n        self.writer = tf.summary.FileWriter(\"./logs\", self.sess.graph)\r\n\r\n        counter = 1\r\n        start_time = time.time()\r\n\r\n        if self.load(args.checkpoint_dir):\r\n            print(\" [*] Load SUCCESS\")\r\n        else:\r\n            print(\" [!] Load failed...\")\r\n\r\n        for epoch in xrange(args.epoch):\r\n            data = glob('./datasets/{}/train/*.png'.format(self.dataset_name))\r\n            np.random.shuffle(data)\r\n            batch_idxs = min(len(data), 1e8) // (self.batch_size*self.n_critic)\r\n            print('[*] run optimizor...')\r\n\r\n            for idx in xrange(0, batch_idxs):\r\n                errD=.0\r\n                batch_list = [self.load_training_imgs(data, idx+i) for i in xrange(self.n_critic)]\r\n                for j in range(self.n_critic):\r\n                    batch_images = batch_list[j]\r\n                    _, errD, errd_real, errd_fake, errVis_sum, summary_str = self.sess.run([self.d_optim, self.d_loss,\r\n                                                                                self.d_loss_real, self.d_loss_fake,\r\n                                                                                            self.visual_loss_summary,\r\n                                                                                            self.d_summary],\r\n                                                                                           feed_dict={self.real_data: batch_images})\r\n                    self.sess.run(self.clip_d_vars_ops)\r\n                    self.writer.add_summary(summary_str, counter)\r\n                    self.writer.add_summary(errVis_sum, counter)\r\n\r\n                # Update G network\r\n                _, errG, summary_str = self.sess.run([self.g_optim, self.g_loss, self.g_summary],\r\n                                               feed_dict={self.real_data: batch_list[np.random.randint(0, self.n_critic, size=1)[0]]})\r\n                self.writer.add_summary(summary_str, counter)\r\n\r\n                current = time.time()\r\n                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\r\n                      % (epoch, idx, batch_idxs, current - start_time, errD, errG))\r\n                start_time = current\r\n\r\n                if np.mod(counter, 100) == 1:\r\n                    self.sample_model(args.sample_dir, epoch, idx)\r\n\r\n                if np.mod(counter, 1000) == 2:\r\n                    self.save(args.checkpoint_dir, counter)\r\n                counter += 1\r\n```\r\n\r\nSpecifically on this line, where self.sess.run is called:\r\n```\r\n                    _, errD, errd_real, errd_fake, errVis_sum, summary_str = self.sess.run([self.d_optim, self.d_loss,\r\n                                                                                self.d_loss_real, self.d_loss_fake,\r\n                                                                                            self.visual_loss_summary,\r\n                                                                                            self.d_summary],\r\n                                                                                           feed_dict={self.real_data: batch_images})\r\n```\r\n**Describe the expected behavior**\r\nThe expected behavior is that it would finish training. Can you provide any recommendations as to how to stop it from seg faulting during training (and why it stops at a different point each time)? I'm wondering if the warnings could have to do with it?  I also have seen other people online having issues with tf.Session, so I'm wondering if that could be it?\r\n", "comments": ["@allangelman,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "I would also suggest to try on 1.15 or 2.0 instead of 1.14", "> @allangelman,\r\n> In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\nI just updated my comment with the link to the repo I am trying to run, and the code snippet where I know it is seg faulting! Thank you!", "@allangelman,\r\nPlease provide the simple standalone code to replicate the issue and indeed it will help us to move faster. And did you try the @mihaimaruseac's suggestion. Thanks!", "Thank you for all the help! I was able to resolve the issue! The problem was that I hadn't installed the tensorflow-gpu package, so the entire time I was actually not even using my GPU! Running `nvidia-smi` helped me figure this out, as I was able to see the usage of my GPU.", "Closing as issue is fixed"]}, {"number": 32700, "title": "[r1.15-CherryPick] Making compute engine metadata client protected And not register GCS file system when TPU GCS file system option is ON", "body": null, "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32700) for more info**.\n\n<!-- need_sender_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32700) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 32699, "title": "[ROCm] Droppping \"contrib\" references from the ROCm CSB script", "body": "The script used to do the ROCm Community Supported Build had references to the \"tensorflow/contrib\" directory. Now that the \"contrib\" dir is gone, the references to it are causing the CSB to error out, wven the build + all the tests are passing.\r\n\r\n-------------------------\r\n\r\n@whchung @chsigg ", "comments": []}, {"number": 32698, "title": "Tensorflow v2.0rc* is impossible to install with pip 18.1", "body": "I'm installing TF on Debian 10 with python 3.6: `Debian 4.19.37-5+deb10u1rodete2 (2019-08-06 > 2018) x86_64 GNU/Linux`\r\n\r\nTF 2.0beta1 had support for the manylinux1 tag which allowed me to successfully install it.\r\nTF 2.0rc1 switched to the `manylinux2010` tag which is not supported on my Debian installation with pip 18.1 and rc1 cannot be installed.\r\n\r\nCan TF not require upgrading pip to install?\r\n\r\n```\r\nhttps://pypi.org/simple/tensorflow/ :\r\ntensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl\r\ntensorflow-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl\r\n\r\n```\r\n\r\n```\r\npython3 -c \"import wheel.pep425tags as w; print(w.get_supported())\" | tr '\\n' '\\0' | sed -E 's/\\),/),\\n/g'\r\n[('cp36', 'cp36m', 'linux_x86_64'),\r\n ('cp36', 'abi3', 'linux_x86_64'),\r\n ('cp36', 'none', 'linux_x86_64'),\r\n ('cp35', 'abi3', 'linux_x86_64'),\r\n ('cp34', 'abi3', 'linux_x86_64'),\r\n ('cp33', 'abi3', 'linux_x86_64'),\r\n ('cp32', 'abi3', 'linux_x86_64'),\r\n ('cp36', 'none', 'any'),\r\n ('cp3', 'none', 'any'),\r\n ('cp35', 'none', 'any'),\r\n ('cp34', 'none', 'any'),\r\n ('cp33', 'none', 'any'),\r\n ('cp32', 'none', 'any'),\r\n ('cp31', 'none', 'any'),\r\n ('cp30', 'none', 'any'),\r\n ('py3', 'none', 'linux_x86_64'),\r\n ('py36', 'none', 'any'),\r\n ('py3', 'none', 'any'),\r\n ('py35', 'none', 'any'),\r\n ('py34', 'none', 'any'),\r\n ('py33', 'none', 'any'),\r\n ('py32', 'none', 'any'),\r\n ('py31', 'none', 'any'),\r\n ('py30', 'none', 'any')]\r\n```", "comments": ["Unfortunately, no, we need to be manylinux2010 compatible if we want our pips to reside on PyPi.\r\n\r\nPlease update your pip via `python -m pip install --upgrade pip` or similar.\r\n\r\nClosing this issue as there is a fix (upgrade pip) and there is no way to not use the `manylinux2010` tag.", "> we need to be manylinux2010 compatible if we want our pips to reside on PyPi.\r\n\r\nCan you please elaborate a bit more on that or point me to the relevant document?\r\n\r\nThe official [python packaging doc](https://packaging.python.org/guides/distributing-packages-using-setuptools/?highlight=manylinux1#platform-wheels) says: \"Note PyPI currently supports uploads of platform wheels for Windows, macOS, and the multi-distro manylinux1 ABI. Details of the latter are defined in PEP 513.\" and does not mention \"manylinux2010\" anywhere.\r\n\r\nThe official python [platform compatibility](https://packaging.python.org/specifications/platform-compatibility-tags/) just mentions that \"manylinux2010 is not yet widely recognised by install tools.\" \r\n\r\n\r\nTF Model analysis does not publish `manylinux2010` wheels and neither does `numpy` (https://pypi.org/simple/numpy/), so I'm not sure what the issue is.\r\n", "Read more about it here\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/32627\r\n\r\nAll the Google employees in this repo will not take your issue serious, pls avoid talking to them and only talk to core TensorFlow devs. \r\n\r\nKeep posting your issue, google mostly only support 64 bit in the cloud, this is the reason they don't have any interest in getting this fixed, but most of the community and the devs know this is an issue they will look into. \r\n\r\nPython is 32 bit as default. ", "Hi there @reliefs \r\n\r\nThis issue has no relationship with 32 bits support (as you can see from the tags, all are 64 bits). Please don't spam inadvertently.", "Pinging @gunan and @angersson for more details about manylinux2010 issue.", "Hi @Ark-kun \r\n\r\nOur manylinux1 wheels were incompatible since a long time ago, see for example #8802 and https://github.com/tensorflow/tensorflow/issues/5033#issuecomment-263681255\r\n\r\nIn the end, it all boils down to the standard C/C++ library used to provide symbols in precompiled code that is then used by Python. Maybe the other packages you mentioned above don't run into these issues.\r\n\r\nRegarding the need to update tag to stay on PyPi, see https://github.com/pypa/warehouse/issues/5420"]}, {"number": 32697, "title": "In Windows, use of fit_generator and evaluate_generator result in \"builtins.TypeError: 'NoneType' object is not subscriptable\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, provided lower in the post.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 7, Python 3.7, tensorflow 1.13.1\r\n\r\n- TensorFlow installed from (source or binary):\r\nvia pip\r\n\r\n- TensorFlow version (use command below): 1.13,1\r\n\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: RTX\r\n\r\n**Describe the current behavior**\r\nIn Windows, when run on a GPU, the provided code results in th following error:\r\n```\r\nFile \"c:\\python37\\Lib\\threading.py\", line 885, in _bootstrap\r\n  self._bootstrap_inner()\r\nFile \"c:\\python37\\Lib\\threading.py\", line 917, in _bootstrap_inner\r\n  self.run()\r\nFile \"c:\\python37\\Lib\\threading.py\", line 865, in run\r\n  self._target(*self._args, **self._kwargs)\r\nFile \"c:\\python37\\Lib\\multiprocessing\\pool.py\", line 121, in worker\r\n  result = (True, func(*args, **kwds))\r\nFile \"c:\\python37\\Lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 445, in get_index\r\n  return _SHARED_SEQUENCES[uid][i]\r\n\r\nbuiltins.TypeError: 'NoneType' object is not subscriptable\r\n```\r\n\r\n**Describe the expected behavior**\r\nNo error\r\n\r\n**Code to reproduce the issue**\r\n```\r\n# system imports\r\nimport os\r\nimport random\r\n\r\n# lib imports\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport scipy as sp\r\nimport cv2\r\nimport tensorflow as tf\r\nimport sklearn\r\nimport sklearn.metrics\r\nimport tqdm\r\nimport tensorflow as tf\r\nimport os\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\nEPS = np.finfo(float).eps\r\n\r\n#=====================================================================================================================================================\r\n# Input parameters\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\nbatchSize = 16\r\nimageSize = 335\r\ntileSize = 256\r\n\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\ndef unet(numCoefs, input_size = (192,192,1), shrinkFactor = 1, name = ''):\r\n    inputs = tf.keras.layers.Input(input_size)\r\n    conv1 = tf.keras.layers.Conv2D(64//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\r\n    conv1 = tf.keras.layers.Conv2D(64//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\r\n    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)\r\n    conv2 = tf.keras.layers.Conv2D(128//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\r\n    conv2 = tf.keras.layers.Conv2D(128//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\r\n    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)    \r\n    conv3 = tf.keras.layers.Conv2D(256//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\r\n    conv3 = tf.keras.layers.Conv2D(256//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\r\n    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)    \r\n    conv4 = tf.keras.layers.Conv2D(512//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\r\n    conv4 = tf.keras.layers.Conv2D(512//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\r\n    drop4 = tf.keras.layers.Dropout(0.0)(conv4)\r\n    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2))(drop4)    \r\n\r\n    conv5 = tf.keras.layers.Conv2D(1024//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\r\n    conv5 = tf.keras.layers.Conv2D(1024//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='code_'+name)(conv5)\r\n    drop5 = tf.keras.layers.Dropout(0.0)(conv5)\r\n    \r\n    up6 = tf.keras.layers.Conv2D(512//shrinkFactor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2), interpolation='bilinear')(drop5))\r\n    merge6 = tf.keras.layers.concatenate([drop4,up6], axis = 3)\r\n    conv6 = tf.keras.layers.Conv2D(512//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\r\n    conv6 = tf.keras.layers.Conv2D(512//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\r\n\r\n    up7 = tf.keras.layers.Conv2D(192//shrinkFactor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2), interpolation='bilinear')(conv6))\r\n    merge7 = tf.keras.layers.concatenate([conv3,up7], axis = 3)\r\n    conv7 = tf.keras.layers.Conv2D(192//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\r\n    conv7 = tf.keras.layers.Conv2D(192//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\r\n\r\n    up8 = tf.keras.layers.Conv2D(128//shrinkFactor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2), interpolation='bilinear')(conv7))\r\n    merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\r\n    conv8 = tf.keras.layers.Conv2D(128//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\r\n    conv8 = tf.keras.layers.Conv2D(128//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\r\n\r\n    up9 = tf.keras.layers.Conv2D(64//shrinkFactor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2), interpolation='bilinear')(conv8))\r\n    merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\r\n    conv9 = tf.keras.layers.Conv2D(64//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\r\n    conv9 = tf.keras.layers.Conv2D(64//shrinkFactor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\r\n    conv9 = tf.keras.layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\r\n    conv10 = tf.keras.layers.Conv2D(1, 1, activation = 'relu')(conv9)\r\n    \r\n    r = tf.keras.layers.Lambda(lambda x: (x - tf.keras.backend.min(x)) / (tf.keras.backend.max(x) - tf.keras.backend.min(x)), name = 'reconstruction_'+name)(conv10)\r\n\r\n    model = tf.keras.models.Model(inputs, r)\r\n    \r\n    return model\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\ndef buildModel():           \r\n    numCoefs = 3\r\n    reconstruction = unet(numCoefs, input_size=(256,256,1), shrinkFactor=4)\r\n    model = tf.keras.models.Model(reconstruction.inputs[0], reconstruction.outputs[0])\r\n        \r\n    return model\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n#=====================================================================================================================================================\r\n# Define and create generators\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\nclass TrainGenerator(tf.keras.utils.Sequence):\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def __init__(self, batchSize, tileSize, imageSize):        \r\n        self._batchSize = batchSize\r\n        self._imageSize = imageSize\r\n        self._tileSize = tileSize\r\n        self._numFiles = 1000\r\n        return\r\n    #\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def next(self):\r\n        return self.__getitem__(0)\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def __getitem__(self, idx):\r\n        # idx intentionally not used\r\n        return self._next()\r\n    #\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Returns number of steps/iterations to perform to go through all the data once\r\n    def getStepsPerEpoch(self):\r\n        return self._numFiles // self._batchSize \r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def __len__(self):\r\n        return self.getStepsPerEpoch()\r\n    #\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Returns a batch of data.    \r\n    def _next(self):         \r\n        xRaw = np.zeros((self._batchSize, self._imageSize, self._imageSize, 1), dtype='complex64')\r\n        # Prep for net input\r\n        x = np.zeros((self._batchSize, self._tileSize, self._tileSize, 1), dtype='float32')\r\n        xSlc = np.zeros((self._batchSize, self._tileSize, self._tileSize, 1), dtype='complex64')\r\n        xDefocus = np.zeros((self._batchSize, self._tileSize, self._tileSize, 1), dtype='float32')\r\n        y = np.zeros(self._batchSize)        \r\n                \r\n        for k in range(self._batchSize):\r\n            y[k] = 1\r\n        #              \r\n        \r\n        # More augmentation\r\n        for k in range(self._batchSize):                   \r\n            # Random Crops\r\n            crop = self._imageSize - self._tileSize            \r\n            startX = np.random.randint(crop)\r\n            startY = np.random.randint(crop)\r\n            slc = xRaw[k, startX:startX + self._tileSize, startY:startY + self._tileSize, 0]     \r\n            x[k, :,:, 0] = 0                \r\n        #\r\n\r\n        return xDefocus, x\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\nclass TestGenerator(tf.keras.utils.Sequence):\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def __init__(self, batchSize, tileSize = 256, imageSize = 335):        \r\n        self._batchSize = batchSize\r\n        self._tileSize = tileSize\r\n        self._imageSize = imageSize       \r\n        self._numFiles = 5000\r\n        return\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------    \r\n    def __len__(self):\r\n        return self.getStepsPerEpoch()    \r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Returns number of steps/iterations to perform to go through all the data once\r\n    def getStepsPerEpoch(self):\r\n        return self._numFiles // self._batchSize\r\n    #\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    def __getitem__(self, idx):        \r\n        return self.next(idx)\r\n    #    \r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Returns batch sized used to iniitalize\r\n    def getBatchSize(self):\r\n        return self._batchSize    \r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Returns a batch of data.\r\n    def next(self, batch_id):\r\n        xs = np.zeros((self._batchSize, self._tileSize , self._tileSize , 1), dtype='float32')\r\n        xSlc = np.zeros((self._batchSize, self._tileSize , self._tileSize , 1), dtype='complex64')\r\n        ys = np.zeros(self._batchSize)\r\n        xsOrig = np.zeros((self._batchSize, self._tileSize , self._tileSize , 1), dtype='float32')                   \r\n\r\n        masterOffset = (self._imageSize -self._tileSize )//2\r\n        center = [self._imageSize //2, self._imageSize //2]\r\n        for k in range(self._batchSize):            \r\n            tile = np.zeros((335,335))\r\n            \r\n            # Center  Crops\r\n            crop = self._imageSize  - self._tileSize             \r\n            startX = crop//2\r\n            startY = crop//2\r\n            slc = tile[startX:startX + self._tileSize , startY:startY + self._tileSize]                                     \r\n\r\n            # Label\r\n            ys[k] = 1\r\n            \r\n        #\r\n        \r\n        return xs, xsOrig\r\n    #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\ndef main():\r\n   \r\n    #-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # So many random seeds\r\n    random.seed(1)\r\n    np.random.seed(1)\r\n    tf.random.set_random_seed(1)\r\n    \r\n    #=====================================================================================================================================================\r\n    # Create output folder of model\r\n    #-----------------------------------------------------------------------------------------------------------------------------------------------------          \r\n    # Create our two generators\r\n    trainGenerator = TrainGenerator(batchSize, 256, 335)    \r\n    testGenerator = TestGenerator(batchSize, 256, 335)\r\n        \r\n    #-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Build model\r\n    model = buildModel()\r\n    model.summary()\r\n    \r\n    #-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n    # Log the model traincompileing parameters\r\n    stepsPerEpochTrain = int(trainGenerator.getStepsPerEpoch())\r\n    stepsPerEpochTest = testGenerator.getStepsPerEpoch()\r\n    print('=== Fitting Model ===')\r\n    print(' Batch size:                  {0}'.format(batchSize))\r\n    print(' Steps per training epoch:    {0}'.format(stepsPerEpochTrain))    \r\n    print(' Steps per testing epoch:     {0}'.format(stepsPerEpochTest))\r\n    #-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n    \r\n    #=====================================================================================================================================================\r\n    # Begin training            \r\n    model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=1e-3), loss = 'mse')    \r\n    \r\n    for epoch in range(0,9999):\r\n        print('========== Epoch {0} =========='.format(epoch))\r\n        \r\n        #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n        # Train the model\r\n        history = model.fit_generator(trainGenerator, workers=5)         \r\n        trainError = history.history['loss'][0]\r\n    \r\n        #-------------------------------------------------------------------------------------------------------------------------------------------------  \r\n        # Dump out mosaic from a batch\r\n        x,y = testGenerator.next(1)\r\n               \r\n        #-------------------------------------------------------------------------------------------------------------------------------------------------\r\n        # Test the model    \r\n        r = model.evaluate_generator(trainGenerator, workers=5, verbose=1)  # idg Leaving this here for postarity. maybe keras will work someday.\r\n\r\n        # Compute test loss\r\n        test_err = np.mean(r)    \r\n    # end training epoch\r\n    return\r\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\r\n  \r\nif __name__== \"__main__\":\r\n    main()\r\n\r\n    print('done')\r\n```\r\n\r\nThis code will spit out Nan's but that is okay.  Its just to address the point.  In windows, the error you will get after the first epoch is:\r\n```\r\nFile \"c:\\python37\\Lib\\threading.py\", line 885, in _bootstrap\r\n  self._bootstrap_inner()\r\nFile \"c:\\python37\\Lib\\threading.py\", line 917, in _bootstrap_inner\r\n  self.run()\r\nFile \"c:\\python37\\Lib\\threading.py\", line 865, in run\r\n  self._target(*self._args, **self._kwargs)\r\nFile \"c:\\python37\\Lib\\multiprocessing\\pool.py\", line 121, in worker\r\n  result = (True, func(*args, **kwds))\r\nFile \"c:\\python37\\Lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 445, in get_index\r\n  return _SHARED_SEQUENCES[uid][i]\r\n\r\nbuiltins.TypeError: 'NoneType' object is not subscriptable\r\n```", "comments": ["@isaacgerg \r\n\r\nI tried to reproduce the issue with TF versions 1.13.1 , 1.15.0-rc1 and i am not seeing any `builtins.TypeError: 'NoneType' object is not subscriptable `but seeing only `loss: nan`\r\nin output for each epoch.Is this the expected output?. I am attaching the [gist](https://colab.sandbox.google.com/gist/ravikyram/a7740644411fbfbf8a753fff7f3d4346/untitled211.ipynb) for your reference.Thanks!", "Seeing nan is not a problem and is expected. I think the problem is in the threading of the the fit_generator or sequence . \r\n\r\nWhat version of windows and python did you run on? The problem only occurs in windows, not linux or the colab envirniment.", "@isaacgerg Can you try running with TF1.15.0rc1 and check whether the issue persists or not? I will run on my windows laptop later and let you know. Thanks!", "@jvishnuvardhan When i run with tf 1.15.0rc1 I get the following error.  I likely need a newer version of cuda or cudnn (or both) with this version of tf.  Unfortunatly, I cannot upgrade at this time.  \r\n\r\n```\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n(0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n[[{{node conv2d/Conv2D}}]]\r\n(1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n[[{{node conv2d/Conv2D}}]]\r\n[[loss/mul/_37]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n```", "@isaacgerg I think you can try tensorflow `cpu` version and check whether code runs with `cpu` version. If the code is running without any issue, then CUDA and cudnn might be the issue. You need to uninstall and reinstall GPU drivers and try again. When you try to find root-cause, try to use simple code from tensorflow website or keras website. By doing that you are sure that error is not in the code. Thanks!", "@jvishnuvardhan Yes, the problem still occurs even with the tensorflow CPU version.  Have you run it in windows yet? \r\n\r\nIf you cut and paste the example I posted, you should see the error just after the first epoch. I think the issue may be related to a timing bug in the internal threading of tf.keras on windows.  The windows python subsystem for threading is a bit different than for linux. Although not exactly threading, in https://github.com/keras-team/keras/issues/5510, i already found a bug in the multiprocessing on windows.", "@isaacgerg Sorry for the late reply. I tried on `TF1.15.3` and don't see any error. \r\n\r\nCan you please verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan The issue is still present. **Have you run in windows yet?**", "@isaacgerg Sorry for the late reply. As I don't have `TF1.x` and don't want to install `TF1.x` on my personal laptop, I ran your code in `TF2.2` and it works without any error. The log trace is as follows. I don't think this is an issue with TF. May be check your GPU. Did you ran it with `Tensorflow-cpu` version?\r\n\r\nPlease close the issue if this was resolved for you.\r\n\r\n```\r\nC:\\Users\\xxxxxx>python C:\\Users\\xxxxxx\\Downloads\\GitHub_models\\test2.py\r\n2020-07-07 16:14:52.946266: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-07-07 16:14:52.968822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24c79859760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-07 16:14:52.972028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nModel: \"model_1\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to\r\n==================================================================================================\r\ninput_1 (InputLayer)            [(None, 256, 256, 1) 0\r\n__________________________________________________________________________________________________\r\nconv2d (Conv2D)                 (None, 256, 256, 16) 160         input_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        conv2d[0][0]\r\n__________________________________________________________________________________________________\r\nmax_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           conv2d_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        conv2d_2[0][0]\r\n__________________________________________________________________________________________________\r\nmax_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_3[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_4[0][0]\r\n__________________________________________________________________________________________________\r\nmax_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_5[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_6 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_6[0][0]\r\n__________________________________________________________________________________________________\r\ndropout (Dropout)               (None, 32, 32, 128)  0           conv2d_7[0][0]\r\n__________________________________________________________________________________________________\r\nmax_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           dropout[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_8 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]\r\n__________________________________________________________________________________________________\r\ncode_ (Conv2D)                  (None, 16, 16, 256)  590080      conv2d_8[0][0]\r\n__________________________________________________________________________________________________\r\ndropout_1 (Dropout)             (None, 16, 16, 256)  0           code_[0][0]\r\n__________________________________________________________________________________________________\r\nup_sampling2d (UpSampling2D)    (None, 32, 32, 256)  0           dropout_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_9 (Conv2D)               (None, 32, 32, 128)  131200      up_sampling2d[0][0]\r\n__________________________________________________________________________________________________\r\nconcatenate (Concatenate)       (None, 32, 32, 256)  0           dropout[0][0]\r\n                                                                 conv2d_9[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_10 (Conv2D)              (None, 32, 32, 128)  295040      concatenate[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_10[0][0]\r\n__________________________________________________________________________________________________\r\nup_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_11[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_12 (Conv2D)              (None, 64, 64, 48)   24624       up_sampling2d_1[0][0]\r\n__________________________________________________________________________________________________\r\nconcatenate_1 (Concatenate)     (None, 64, 64, 112)  0           conv2d_5[0][0]\r\n                                                                 conv2d_12[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_13 (Conv2D)              (None, 64, 64, 48)   48432       concatenate_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_14 (Conv2D)              (None, 64, 64, 48)   20784       conv2d_13[0][0]\r\n__________________________________________________________________________________________________\r\nup_sampling2d_2 (UpSampling2D)  (None, 128, 128, 48) 0           conv2d_14[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_15 (Conv2D)              (None, 128, 128, 32) 6176        up_sampling2d_2[0][0]\r\n__________________________________________________________________________________________________\r\nconcatenate_2 (Concatenate)     (None, 128, 128, 64) 0           conv2d_3[0][0]\r\n                                                                 conv2d_15[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_16 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_2[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_17 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_16[0][0]\r\n__________________________________________________________________________________________________\r\nup_sampling2d_3 (UpSampling2D)  (None, 256, 256, 32) 0           conv2d_17[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_18 (Conv2D)              (None, 256, 256, 16) 2064        up_sampling2d_3[0][0]\r\n__________________________________________________________________________________________________\r\nconcatenate_3 (Concatenate)     (None, 256, 256, 32) 0           conv2d_1[0][0]\r\n                                                                 conv2d_18[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_19 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_3[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_20 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_19[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_21 (Conv2D)              (None, 256, 256, 2)  290         conv2d_20[0][0]\r\n__________________________________________________________________________________________________\r\nconv2d_22 (Conv2D)              (None, 256, 256, 1)  3           conv2d_21[0][0]\r\n__________________________________________________________________________________________________\r\nreconstruction_ (Lambda)        (None, 256, 256, 1)  0           conv2d_22[0][0]\r\n==================================================================================================\r\nTotal params: 1,889,333\r\nTrainable params: 1,889,333\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\n=== Fitting Model ===\r\n Batch size:                  16\r\n Steps per training epoch:    62\r\n Steps per testing epoch:     312\r\n========== Epoch 0 ==========\r\nWARNING:tensorflow:From C:\\Users\\xxxxxx\\Downloads\\GitHub_models\\test2.py:226: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use Model.fit, which supports generators.\r\n62/62 [==============================] - 393s 6s/step - loss: nan\r\nWARNING:tensorflow:From C:\\Users\\xxxxxx\\Downloads\\GitHub_models\\test2.py:235: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use Model.evaluate, which supports generators.\r\n62/62 [==============================] - 70s 1s/step - loss: nan\r\ndone \r\n```", "Adding the argument workers=0 to model.eval() and model.fit() fixed this issue."]}, {"number": 32696, "title": "[TF1.14] Network compiles localy but not on TPU with error 'InvalidArgumentError: Undeclared output of TPU computation.'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: TPU \r\n\r\nI created a DenseNet, which I succesfully compile it locally with GPU, but when I try to compile on  a TPU device, the following error appears\r\n```\r\nTraceback (most recent call last):\r\n  File \"attention_dense.py\", line 258, in <module>\r\n    model.fit(get_training_dataset(), validation_data=get_validation_dataset(),  initial_epoch=0, steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, callbacks=clbk)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\", line 649, in fit\r\n    validation_freq=validation_freq)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_distributed.py\", line 128, in fit_distributed\r\n    validation_freq=validation_freq)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_distributed.py\", line 395, in experimental_tpu_fit_loop\r\n    callbacks._call_begin_hook(mode)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py\", line 262, in _call_begin_hook\r\n    self.on_train_begin()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py\", line 378, in on_train_begin\r\n    callback.on_train_begin(logs)\r\n  File \"/home/frank_lab/clr.py\", line 122, in on_train_begin\r\n    K.set_value(self.model.optimizer.lr, self.base_lr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\", line 3038, in set_value\r\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\", line 462, in get_session\r\n    _initialize_variables(session)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\", line 879, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Undeclared output of TPU computation. A common cause of this error is variable initializers that depend on the TPU computation. Edge: node dense_1_2/re_lu_1/Relu (defined at attention_dense.py:258) :0 -> node tf_op_layer_add/add (defined at attention_dense.py:258) :0\r\n```\r\nThe code is the following\r\n\r\n```\r\ndef conv(input, kernel, filt, stride, dilation, pad='same'):\r\n    x = layers.Conv2D(filters=filt, kernel_size=kernel, strides=stride, dilation_rate=dilation, padding=pad, kernel_regularizer=tf.keras.regularizers.l2(l=0.01))(input)\r\n    return x\r\n\r\ndef conv_down(input, filters):\r\n    x = conv(input, 3, filters, 2 ,1)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    return x\r\n\r\ndef conv_block(input, filters, stride=1, dilation=2, pad='same', bottleneck=True):\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(input)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    if bottleneck:\r\n        x = conv(x, kernel=1, filt=(filters*4), dilation=dilation, stride=1, pad=pad)\r\n        x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n        x = layers.LeakyReLU(alpha=0.1)(x) \r\n    x = conv(x, kernel=3, filt=filters, stride=stride, dilation=dilation, pad=pad)\r\n    return x\r\n\r\ndef dense_block(x, filters, layers, bottleneck=True):\r\n    x_list = [x]\r\n    for i in range(layers):\r\n        cb = conv_block(x, filters, dilation=2, bottleneck=True)\r\n        x_list.append(cb)\r\n        x = tf.keras.layers.concatenate([x, cb], axis=-1)\r\n        x = attention(x)\r\n    return x\r\n\r\ndef transition_block(input, filters, att=True):\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(input)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    x = conv(x, kernel=1, filt=filters, stride=1, dilation=2, pad='same')\r\n    x = layers.AveragePooling2D((2,2), strides=(2,2))(x)\r\n    if att:\r\n        x = attention(x)\r\n    return x\r\n    \r\ndef attention(input):\r\n    x = channel_att(input)\r\n    x = spatial_att(x)\r\n    return x\r\n    \r\ndef channel_att(input, ratio=8):\r\n    channel = input.get_shape()[-1]\r\n    ####\r\n    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input)\r\n    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\r\n    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input)\r\n    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\r\n    ####\r\n    mlp_0 = layers.Dense(units=channel//ratio, activation=layers.ReLU())\r\n    mlp_1 = layers.Dense(units=channel, activation=layers.ReLU())\r\n    avg_ = mlp_1(mlp_0(avg_pool))\r\n    max_ = mlp_1(mlp_0(max_pool))\r\n    scale = keras.activations.sigmoid(avg_+max_)\r\n    return input*scale\r\n\r\ndef spatial_att(input, kernel=7):\r\n    avg_pool = tf.math.reduce_mean(input, axis=[3], keepdims=True)\r\n    max_pool = tf.math.reduce_max(input, axis=[3], keepdims=True)\r\n    concat = tf.concat([avg_pool, max_pool], axis=3)\r\n    concat = layers.Conv2D(filters=1, kernel_size=kernel, padding='same',use_bias=False)(concat)\r\n    concat = keras.activations.sigmoid(concat)\r\n    return input*concat\r\n\r\n\r\ndef create_model():\r\n    Input = layers.Input(shape=(540, 540, 3))\r\n    x = conv(Input, kernel=3, filt=64, stride=1, dilation=2)\r\n    for i in range(8):\r\n        x = dense_block(x, filters=128, layers=3, bottleneck=True)\r\n        x = transition_block(x, filters=128, att=True)\r\n    x = dense_block(x, filters=128, layers=4, bottleneck=True)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = conv(x, kernel=1, filt=45, stride=1, dilation=1)\r\n    model = tf.keras.Model(inputs=Input, outputs=x)\r\n    model.compile(optimizer=keras.optimizers.SGD(), loss=custom_loss)\r\n    return model\r\n\r\nwith tpu_strategy.scope():\r\n    model=create_model()\r\n\r\nmodel.fit(get_training_dataset(), validation_data=get_validation_dataset(),  initial_epoch=0, steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, callbacks=clbk)\r\n```", "comments": ["@nsantavas \r\nLooks like code is incomplete. I am seeing the error `NameError: name 'tpu_strategy' is not defined`. Can you please help us with simple standalone code to reproduce the issue in our environment. Thanks!", "Hi, @ravikyram \r\n\r\n```\r\ntpu=' '\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu)\r\ntf.config.experimental_connect_to_host(resolver.master())\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\ntpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\nEPOCHS=250\r\n\r\n\r\ndef conv(input, kernel, filt, stride, dilation, pad='same'):\r\n    x = layers.Conv2D(filters=filt, kernel_size=kernel, strides=stride, dilation_rate=dilation, padding=pad, kernel_regularizer=tf.keras.regularizers.l2(l=0.01))(input)\r\n    return x\r\n\r\ndef conv_down(input, filters):\r\n    x = conv(input, 3, filters, 2 ,1)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    return x\r\n\r\ndef conv_block(input, filters, stride=1, dilation=2, pad='same', bottleneck=True):\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(input)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    if bottleneck:\r\n        x = conv(x, kernel=1, filt=(filters*4), dilation=dilation, stride=1, pad=pad)\r\n        x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n        x = layers.LeakyReLU(alpha=0.1)(x) \r\n    x = conv(x, kernel=3, filt=filters, stride=stride, dilation=dilation, pad=pad)\r\n    return x\r\n\r\ndef dense_block(x, filters, layers, bottleneck=True):\r\n    x_list = [x]\r\n    for i in range(layers):\r\n        cb = conv_block(x, filters, dilation=2, bottleneck=True)\r\n        x_list.append(cb)\r\n        x = tf.keras.layers.concatenate([x, cb], axis=-1)\r\n        x = attention(x)\r\n    return x\r\n\r\ndef transition_block(input, filters, att=True):\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(input)\r\n    x = layers.LeakyReLU(alpha=0.1)(x) \r\n    x = conv(x, kernel=1, filt=filters, stride=1, dilation=2, pad='same')\r\n    x = layers.AveragePooling2D((2,2), strides=(2,2))(x)\r\n    if att:\r\n        x = attention(x)\r\n    return x\r\n    \r\ndef attention(input):\r\n    x = channel_att(input)\r\n    x = spatial_att(x)\r\n    return x\r\n    \r\ndef channel_att(input, ratio=8):\r\n    channel = input.get_shape()[-1]\r\n    ####\r\n    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input)\r\n    avg_pool = tf.keras.layers.Reshape((-1,1,1,channel))(avg_pool)\r\n    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input)\r\n    max_pool = tf.keras.layers.Reshape((-1,1,1,channel))(max_pool)\r\n    ####\r\n    mlp_0 = layers.Dense(units=channel//ratio, activation=layers.ReLU())\r\n    mlp_1 = layers.Dense(units=channel, activation=layers.ReLU())\r\n    avg_ = mlp_1(mlp_0(avg_pool))\r\n    max_ = mlp_1(mlp_0(max_pool))\r\n    scale = keras.activations.sigmoid(avg_+max_)\r\n    return input*scale\r\n\r\ndef spatial_att(input, kernel=7):\r\n    avg_pool = tf.math.reduce_mean(input, axis=[3], keepdims=True)\r\n    max_pool = tf.math.reduce_max(input, axis=[3], keepdims=True)\r\n    concat = tf.concat([avg_pool, max_pool], axis=3)\r\n    concat = layers.Conv2D(filters=1, kernel_size=kernel, padding='same',use_bias=False)(concat)\r\n    concat = keras.activations.sigmoid(concat)\r\n    return input*concat\r\n\r\n\r\ndef create_model():\r\n    Input = layers.Input(shape=(540, 540, 3))\r\n    x = conv(Input, kernel=3, filt=64, stride=1, dilation=2)\r\n    for i in range(8):\r\n        x = dense_block(x, filters=128, layers=3, bottleneck=True)\r\n        x = transition_block(x, filters=128, att=True)\r\n    x = dense_block(x, filters=128, layers=4, bottleneck=True)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = conv(x, kernel=1, filt=45, stride=1, dilation=1)\r\n    model = tf.keras.Model(inputs=Input, outputs=x)\r\n    model.compile(optimizer=keras.optimizers.SGD(), loss=custom_loss)\r\n    return model\r\n\r\n\r\nwith tpu_strategy.scope():\r\n    model=create_model()\r\n\r\n\r\nmodel.fit(get_training_dataset(), validation_data=get_validation_dataset(),  initial_epoch=0, steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, callbacks=clbk)\r\n\r\n```\r\n\r\nadd random dataset (None, 540, 540, 3) dimensions\r\n\r\n\r\n\r\n", "I tried to reproduce the issue. I am getting the error message` URLError: <urlopen error [Errno 110] Connection timed out>`. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/78dfb933e940242780cc4e97e7fdf3e5/untitled212.ipynb).Thanks!", "@ in colab you should not define tpu address. TPUClusterResolver must be empty\r\n```\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\ntf.config.experimental_connect_to_host(resolver.master())\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\ntpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n```\r\n", "I have tried on colab with TF version 1.14 and i am seeing the below error.`ValueError: Input 0 of layer conv2d_11 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, None, 540, 2, 192]`.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/92e178a10671bd6a27e6d6680c467fb9/untitled212.ipynb).Thanks!", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32696\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32696\">No</a>\n", "The [notebook](https://colab.research.google.com/gist/ymodak/c7107543736696e679c2e996a3eb4ec1/untitled212.ipynb) throws error with gpu runtime as well."]}, {"number": 32695, "title": "added flatc to third_party", "body": "this is to help assists people who are having problem running visualize.py", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32695) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32695) for more info**.\n\n<!-- ok -->", "This seems too large. Unassinging myself and assigning @gunan", "> This seems too large. Unassinging myself and assigning @gunan\r\n\r\nHi, sorry guys, I just built flatc and included it in third_party so that `tensorflow/tensorflow/lite/tools/visualize.py` can run smoothly. \r\nIt's my first pull request, not too sure if this is against tf standard practices.\r\nThanks for considering. ", "Afaik, you only need `BUILD` (and an optional `workspace.bzl`) and then add add the corresponding `tf_http_archive`, for example https://github.com/tensorflow/tensorflow/blob/235e88b123cbf742d7db91e37dd836e30bd6766d/tensorflow/workspace.bzl#L709-L718", "As @mihaimaruseac expressed, you should just create a workspace.bzl entry.\r\nWe cannot copy the whole flatbuffers codebase into our own."]}, {"number": 32694, "title": "\"TypeError: list indices must be integers or slices, not str\" in preempted_hook.py ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below):1.14\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory: Cloud TPU v2\r\n\r\n**Describe the current behavior**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/tpu/preempted_hook.py\", line 89, in run\r\n    self._cluster._tpu, response['state'], response['health'])  # pylint: disable=protected-access\r\nTypeError: list indices must be integers or slices, not str\r\n```\r\nLooks like response is a list and not a dictionary.\r\n\r\n**Describe the expected behavior**\r\nNo exception thrown\r\n\r\n**Other info / logs**\r\nN/A", "comments": ["@prashastk ,\r\nCan you share a simple and standalone code to reproduce the issue?Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 32693, "title": "Tensorflow 2.0 tf.lite.TFLiteConverter.from_keras_model giving 'str' object has no attribute 'call'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 on Amazon EC2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): pip \r\n- TensorFlow version (use command below): tensorflow 2.0 rc1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: On CPU and on google colab also\r\n- GPU model and memory: On google colab, \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nIt's not able to convert the LSTM model to tflite format\r\n\r\n**Describe the expected behavior**\r\nit should be able to convert the model to tflite format.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(\"language_small_adam-01.hdf5\")\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-58-c5d53462d122> in <module>\r\n      1 import tensorflow as tf\r\n----> 2 converter = tf.lite.TFLiteConverter.from_keras_model(\"language_small_adam-01.hdf5\")\r\n      3 tflite_model = converter.convert()\r\n      4 open(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in from_keras_model(cls, model)\r\n    380       TFLiteConverter object.\r\n    381     \"\"\"\r\n--> 382     func = _saving_utils.trace_model_call(model)\r\n    383     concrete_func = func.get_concrete_function()\r\n    384     return cls([concrete_func])\r\n\r\n~/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saving_utils.py in trace_model_call(model, input_signature)\r\n    122   \"\"\"\r\n    123   if input_signature is None:\r\n--> 124     if isinstance(model.call, def_function.Function):\r\n    125       input_signature = model.call.input_signature\r\n    126 \r\n\r\nAttributeError: 'str' object has no attribute 'call'", "comments": ["LSTMs are currently a [work in progress](https://www.tensorflow.org/lite/r2/convert/python_api#liteophint).\r\n\r\nAs we work on adding support, can you provide a minimal repro of your issue. Either provide the model or a modified version of the model / model code to help investigate the issue.", "hi @gargn ,\r\n\r\nThanks for such a quick reply. Below is the code i used to generate the model. I used tf.keras for all the functions. Please find the model file below.\r\n\r\n[language_adam-01.zip](https://github.com/tensorflow/tensorflow/files/3647337/language_adam-01.zip)\r\n\r\n\r\n\r\n`inputs1 = Input(shape=(2048,))\r\nfe1 = Dropout(0.5)(inputs1)\r\nfe2 = Dense(256, activation='relu')(fe1)\r\n\r\ninputs2 = Input(shape=(5,))\r\nse1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\r\nse2 = Dropout(0.5)(se1)\r\nse3 = LSTM(256)(se2)\r\n\r\ndecoder1 = add([fe2, se3])\r\ndecoder2 = Dense(256, activation='relu')(decoder1)\r\noutputs = Dense(vocab_size, activation='softmax')(decoder2)\r\n\r\n\r\nmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)`\r\n\r\nPlease let me know if you need any further inputs from my side.", "@gargn I tried replacing LSTM in above code with GRU, it's giving same error.", "Hi,\r\n\r\nKeras LSTM/GRU will not be supported in the current TOCO converter. We are working on a new TF Lite converter that could convert LSTMs nicely. Please stay tuned. Thanks!", "Any update?", "To try the new converter, use the `tf-nightly` pip package and then try:\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```", "Even with the tf-nightly package, I am getting the same error", "@alokmalik I have updated your code with an `experimental_new_convereter`, then everything works as expected. Please take a look at the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/4db22181f32e76dd28619c33ba79c10d/untitled636.ipynb). Thanks!\r\n\r\n```\r\nimport tensorflow as tf\r\nmodel=tf.keras.models.load_model(\"./language_adam-01.hdf5\")\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)  \r\n```\r\n\r\nI am closing this issue as it was resolved by the new converter. Please feel free to reopen if the issue persists again. Thanks!", "thanks @gargn @jvishnuvardhan , it's working now. I'll comment back if it doesn't work in mobile.", "`converter.experimental_new_converter = True`\r\nis is what I have been waiting for!\r\nI can convert my model from .h5 to .tflite.\r\nHowever, when I try to load this model to my Android APK, There are some problem:\r\n\r\nI have class that loads .tflite model as byteBuffer and predict probabilities as following:\r\n\r\n`\r\npublic class TensorFlowLiteClassifier {\r\n\r\n    private Interpreter interpreter;\r\n    public static final String MODEL_FILE = \"LSTM.tflite\";\r\n    public static final int LABEL_NUM = 2;\r\n\r\n    /**\r\n     * Registers interpreter\r\n     * \u30a4\u30f3\u30bf\u30d7\u30ea\u30bf\u306e\u767b\u9332\r\n     */\r\n    private TensorFlowLiteClassifier(Interpreter interpreter) {\r\n        this.interpreter = interpreter;\r\n    }\r\n\r\n    /**\r\n     * Loads model into interpreter\r\n     * \u30a4\u30f3\u30bf\u30d7\u30ea\u30bf\u306b\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u307f\r\n     */\r\n    public static TensorFlowLiteClassifier classifier(AssetManager assetManager, String modelPath) throws IOException {\r\n        ByteBuffer byteBuffer = loadModelFile(assetManager, modelPath);\r\n        Interpreter interpreter = new Interpreter(byteBuffer);\r\n        return new TensorFlowLiteClassifier(interpreter);\r\n    }\r\n\r\n    /**\r\n     * Loads model\r\n     * \u30e2\u30c7\u30eb\u306e\u8aad\u307f\u8fbc\u307f\r\n     */\r\n    private static MappedByteBuffer loadModelFile(AssetManager assets, String path) throws IOException {\r\n        AssetFileDescriptor file = assets.openFd(path);\r\n        FileInputStream stream = new FileInputStream(file.getFileDescriptor());\r\n        FileChannel channel = stream.getChannel();\r\n        long startOffset = file.getStartOffset();\r\n        long declaredLength = file.getDeclaredLength();\r\n        return channel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n    }\r\n\r\n    /**\r\n     * Function that actually performs inference\r\n     * \u5b9f\u969b\u306b\u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308b\u95a2\u6570\r\n     */\r\n    public float[][] predictProbabilities(float[][] input) {\r\n        float[][] output = new float[1][LABEL_NUM];\r\n        interpreter.run(input, output);\r\n        return output;\r\n    }\r\n}\r\n`\r\n\r\nAn error occurred when creating a new intepreter from byteBuffer.\r\n`Interpreter interpreter = new Interpreter(byteBuffer);`\r\n\r\nLogcat is following:\r\n`2019-11-15 20:43:04.897 19973-19973/iis.kmjlab.kazuimotn.sartips A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x70 in tid 19973 (zuimotn.sartips)`\r\n\r\nHow can I deal with this unknown error?", "@kazuimotn Can you please create a new issue so that it will be easy for others  to follow who have similar issue like to you. Thanks!", "opened [here](https://github.com/tensorflow/tensorflow/issues/34313#issue-523552107)", "> @alokmalik I have updated your code with an `experimental_new_convereter`, then everything works as expected. Please take a look at the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/4db22181f32e76dd28619c33ba79c10d/untitled636.ipynb). Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> model=tf.keras.models.load_model(\"./language_adam-01.hdf5\")\r\n> converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n> converter.experimental_new_converter = True\r\n> tflite_model = converter.convert()\r\n> open(\"converted_model.tflite\", \"wb\").write(tflite_model)  \r\n> ```\r\n> \r\n> I am closing this issue as it was resolved by the new converter. Please feel free to reopen if the issue persists again. Thanks!\r\n\r\nHi,\r\nI have a Bi-directional LSTM model and I want to use it with tflite. I get the following error while saving the model: TypeError: 'int' object is not callable.\r\nI have tried the experimental converter, but nothing works.\r\nCurrently, I am using the tf_nightly-2.6.0.dev20210614 release. The same code worked for me with \"tf-nightly-2.5.0-dev20201111\" release. \r\nAny leads on how to proceed further?\r\n\r\n", "@prerna-khanna I think you'll have to use regular tensorflow version now, it's a 2 year old issue and the feature is out of beta testing(nightly build)."]}, {"number": 32692, "title": "Hi ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please stop making spam issues/PRs"]}, {"number": 32691, "title": "TF 1.14.0 training crashes with unimplemented Conv2D errors (works fine in TF 1.13.2)", "body": "**Environment**\r\n- Ubuntu 16.04:\r\n- Docker based tensorflow/tensorflow:1.14.0-gpu\r\n- tensor2tensor==1.14.0 (pip installed in container)\r\n- Python 2.7\r\n- CUDA/cuDNN version: 10/7 (defaults from docker image)\r\n- GPUs (tested on many from 1080 to RTX Titan)\r\n\r\n**Issue**\r\nChange in Tensorflow has broken tensor2tensor librispeech training.\r\n\r\nRunning librispeech training crashes with Unimplemented Conv2D errors.\r\n```\r\n  (0) Unimplemented:  The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n         [[{{node Conv2D}}]]\r\n  (1) Unimplemented:  The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n         [[{{node Conv2D}}]]\r\n         [[Shape_3/_8]]\r\n```\r\n\r\n**Expected behavior**\r\nThis works fine in earlier versions of Tensorflow (e.g. 1.13.2).\r\n\r\n**Code to reproduce the issue**\r\nVia Nvidia Docker Hub\r\nrun tensorflow/tensorflow:1.14.0-gpu\r\npip install tensorflow-hub && pip install tensor2tensor\r\napt-get update && apt-get install sox\r\n`t2t-trainer --problem=librispeech_clean_small --model=transformer --output_dir=/models/JUNK --data_dir=/data/ --save_checkpoints_secs=1800 --schedule=train --hparams_set=transformer_librispeech`\r\n(note: sox and --generate are only needed once, to prep the dataset)\r\n\r\n**Other info / logs**\r\nRelated to closed issue #32017.", "comments": ["Hi @mschonwe \r\nIt seems you are installing a GPU version. \r\nWhy it throws the error message on CPU? Did you run the training on CPU?", "@Leslie-Fang the device placement _should_ be putting these ops on GPU (afaik).  The issue only crops up in new versions of TF code, in older versions the GPU utilization is appropriately high.", "I've tracked down the the function where it goes off the rails (_when running TF 1.14.0_):\r\n```\r\ndef add_delta_deltas(filterbanks, name=None):\r\n  \"\"\"Compute time first and second-order derivative channels.\r\n  Args:\r\n    filterbanks: float32 tensor with shape [batch_size, len, num_bins, 1]\r\n    name: scope name\r\n  Returns:\r\n    float32 tensor with shape [batch_size, len, num_bins, 3]\r\n  \"\"\"\r\n  delta_filter = np.array([2, 1, 0, -1, -2])\r\n  delta_delta_filter = scipy.signal.convolve(delta_filter, delta_filter, \"full\")\r\n\r\n  delta_filter_stack = np.array(\r\n      [[0] * 4 + [1] + [0] * 4, [0] * 2 + list(delta_filter) + [0] * 2,\r\n       list(delta_delta_filter)],\r\n      dtype=np.float32).T[:, None, None, :]\r\n\r\n  delta_filter_stack /= np.sqrt(\r\n      np.sum(delta_filter_stack**2, axis=0, keepdims=True))\r\n\r\n  filterbanks = tf.nn.conv2d(\r\n      filterbanks, delta_filter_stack, [1, 1, 1, 1], \"SAME\", data_format=\"NHWC\",\r\n      name=name)\r\n  return filterbanks\r\n```", "I found an issue that seems related: tensorflow/tensorflow/issues/26411\r\nI changed add_delta_deltas to hard code placement on CPU:\r\n```\r\n  with tf.device('/cpu:0'):\r\n    filterbanks = tf.nn.conv2d(\r\n      filterbanks, delta_filter_stack, [1, 1, 1, 1], \"SAME\", data_format=\"NHWC\",\r\n      name=name)\r\n```\r\nTraining runs without error.  Seems to me it would be preferable to place the conv2d op on GPU (except for this issue).", "@mschonwe,\r\nPlease provide the minimal standalone code to reproduce the reported issue. Thanks!", "This is based on the tensorflow/tensor2tensor project, In the initial post I describe how to reproduce.  The function that causes the trouble is the conv2d in tensor2tensor/layers/common_audio.py add_delta_deltas().\r\n\r\nThe (likely) issue is the optimization pass causing a conv2d op, which should be placed on CPU, to be rewritten to use a version of tf.nn.conv2d() that is only available on GPU.\r\n\r\nSince I have a work-around (above) for the bug, I am ok closing this issue.", "@mschonwe, thank you for reporting this issue. I am confused why placing on the CPU would help at all. The error is that the CPU only supports NHWC and that NCHW is being used. Yet, in the `add_delta_deltas` function, it explicitly uses NHWC, so the error should not occur whether the op is on the CPU or GPU. And, the error message indicates the op already is placed on the CPU, so explicitly placing on the CPU should not do anything.\r\n\r\nDo you understand why explicitly placing the op on the CPU would help? If not, I'll CC some other people to try to figure this out.", "@reedwm I don't understand why it works, only that it does.\r\n\r\nI agree that the error message seems to indicate that the offending op is placed on the CPU even without the explicit device placement.\r\n\r\nMy guess was that (w/o the explicit device placement) there are multiple optimization passes, the first choses the op for the GPU, and a later optimization places that op on CPU, which then failed.\r\n\r\n /issues/26411 relates to a different problem, but seems related.\r\n", "/CC @ezhulenev, do you know if this is an issue with the layout optimizer?\r\n\r\n@mschonwe, also try consider trying TF 1.15-rc1 (`pip install tensorflow-gpu==1.15rc1`)", "I did a quick try with TF1.15-rc1, but got an error:\r\n`AttributeError: 'RunConfig' object has no attribute '_session_creation_timeout_secs'`\r\nI tried hard coding it to be be `session_creation_timeout_secs=7200` but that didn't work (because the subfunctions didn't know about that parameter).  I'll look at this again when I have time.", "Based on my understanding that is what happens:\r\n\r\n1. Conv2D without explicit device string placed on GPU\r\n2. Layout optimizer changes data format NHWC->NCHW becasue it's optimal for the GPU\r\n3. Then **_something_** puts Conv2D back on CPU <<<---- after a discussion we have no idea what it could be\r\n\r\nWhen Conv2D explicitly placed on CPU, it prevents layout optimizer from swapping data format.\r\n\r\n@mschonwe what if you explicitly put this Conv2D on GPU?", "Hacked past the session_creation_timeout_secs issue by hardcoding a return in /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/run_config.py\r\n```\r\n@property\r\n  def session_creation_timeout_secs(self):\r\n     return 7200 #return self._session_creation_timeout_secs\r\n```\r\n\r\nStill fails in TF1.15-rc2 when no explicit device placement is given.\r\n\r\nHOWEVER, it does WORK now when **GPU** is specified (`with tf.device('/gpu:0'):`).", "Still fails in TF1.15-rc3 when no explicit device placement is given.", "Faced the same issue. The program gets stuck when using GPU but works on CPU. No error message for me, it just remains stuck due to the tf.nn.conv2d code. \r\n\r\nExplicit device placement by @mschonwe helped.\r\n\r\n> /issues/26411 relates to a different problem, but seems related.\r\n\r\nThis seems to be it; tf.nn.conv2d or tf.nn.conv1d inside tf.dataset map doesn't work with GPU enabled for me.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32691\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32691\">No</a>\n"]}, {"number": 32690, "title": "How to restore weights of model from zoo as trainable or how to train custom model with object detection script", "body": "Hello\r\nI'm trying to add some new outs to ssd mobilenet v2 taken from model zoo. How to restore graph and variables data to train my additional layers and fine tune mobilenet for better future extracting.</br>\r\nIn my tries i used tf.Saver and simple import_meta_graph and restore.</br>\r\nOr push me to right way with using TFObjectDetection API for this task", "comments": ["@VladBlat ,\r\nPlease refer the links [1](https://www.tensorflow.org/guide/saved_model) and [2](https://www.tensorflow.org/beta/guide/keras/saving_and_serializing) and let us know if it helps,thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Hello, I didn't find some useful info about this issue at links which u\ngave. Restore variables as trainable possible using object detection Api. U\ncan close topic. Good luck!\n\n\u0432\u0442, 8 \u043e\u043a\u0442. 2019 \u0433., 15:38 Alfred Sorten Wolf <notifications@github.com>:\n\n> It has been 15 days with no activity and the awaiting response label was\n> assigned. Is this still an issue?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32690?email_source=notifications&email_token=AKLIRM46MDZSAQBOS7E2T3TQNR5LRA5CNFSM4IYYUQZKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAT7N3I#issuecomment-539490029>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKLIRM5A6ZVRVSJLKTG76DDQNR5LRANCNFSM4IYYUQZA>\n> .\n>\n", "Closing since the issue is resolved.Thanks!"]}, {"number": 32689, "title": "tf.train.import_meta_graph raise ValueError(str(e)) ValueError: Cannot add function '__inference_Dataset_flat_map_read_one_file_11' because a different function with the same name already exists.", "body": "Traceback (most recent call last):\r\n  File \"test.py\", line 121, in <module>\r\n    test()\r\n  File \"test.py\", line 67, in test\r\n    saver = tf.train.import_meta_graph('checkpoint/-301.meta')\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1449, in import_meta_graph\r\n    **kwargs)[0]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1473, in _import_meta_graph_with_return_elements\r\n    **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/meta_graph.py\", line 857, in import_scoped_meta_graph_with_return_elements\r\n    return_elements=return_elements)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 431, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Cannot add function '__inference_Dataset_flat_map_read_one_file_11' because a different function with the same name already exists.\r\n\r\nusing tensorflow version 1.14\r\n\r\n\uff1f\uff1f\uff1f why? how?", "comments": ["@Gzzgz,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@Gzzgz, Please provide the standalone code to reproduce the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 32688, "title": "[r1.15-CherryPick]:Cast `inputs` array to float64 in case of big endian architecture for normalization", "body": "Hi @goldiegadde, @martinwicke,\r\n\r\nCreating this cherry-pick with reference to https://github.com/tensorflow/tensorflow/pull/31188/. Thanks.", "comments": ["Hi @goldiegadde,\r\nGentle reminder", "> Hi @goldiegadde,\r\n> Gentle reminder\r\n\r\nthanks for the reminder and sorry for the delay, will merge soon!", "Thanks @goldiegadde "]}, {"number": 32687, "title": "CocoaPods could not find compatible version for pod 'TensorFlowLiteSwift'- with iOS 8 deployment target", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["When I install 'TensorFlowLiteSwift' in my swift project with deployment target 8 it give me this error. is there any way we can achieve this?\r\n![Screenshot 2019-09-19 at 3 54 26 PM](https://user-images.githubusercontent.com/13555198/65318880-17bb5b80-dbbc-11e9-8fe0-46f4a3cc2513.png)\r\n", "Can you please elaborate about the issue & the context.Please, provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Hi @ravikyram ,  please find my Podfile in the attachment. When I run 'pod install' from my terminal then it gives me this error. I need a deployment target from iOS 8+ for my app, so is there any way to achieve this with the library. \r\n![Screenshot 2019-09-20 at 3 48 00 PM](https://user-images.githubusercontent.com/13555198/65321578-31f83800-dbc2-11e9-8b3c-423008e05de9.png)\r\n\r\n\r\n", "Any update on this?", "Could you take a look at #32780 and see if that could help?\r\n\r\nTo give you more background, `TensorFlowLiteSwift` pod depends on the `TensorFlowLiteC` binary pod, which also has iOS 9 as the minimum target.\r\n\r\nYou might also need to edit the Swift API code to remove the GPU delegate related code, and rebuild the `TensorFlowSwift` pod yourself, according to [this guide](https://www.tensorflow.org/lite/guide/build_ios#using_local_swift_or_objective-c_apis).", "@parascse \r\n\r\nAny update on this issue please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 32686, "title": "Hi,", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Closing as nothing useful has been inserted"]}, {"number": 32685, "title": "tf.function problem when slicing tensor with variable", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v2.0.0-rc0-101-gd2d2566eef 2.0.0-rc1\r\n- Python version: 3.7.4\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the behavior**\r\nSlicing tensors using slices indexed by a `tf.Variable` does not work with `tf.function`. The problem does not occur when executing eagerly or when slicing with tensors which are not variables.\r\n\r\n**Code to reproduce the issue**\r\nExecuting the code\r\n\r\n\timport tensorflow as tf\r\n\r\n\tpos = tf.Variable(0, dtype=tf.int32)\r\n\r\n\tdef ok():\r\n\t\treturn tf.zeros(5)[pos:3]\r\n\r\n\t@tf.function\r\n\tdef also_ok():\r\n\t\treturn tf.zeros(5)[pos+0:3]\r\n\r\n\t@tf.function\r\n\tdef not_ok():\r\n\t\treturn tf.zeros(5)[pos:3]\r\n\r\n\ttf.print(ok())\r\n\ttf.print(also_ok())\r\n\ttf.print(not_ok())\t\r\n\r\nproduces the output\r\n\r\n\t[0 0 0]\r\n\t[0 0 0]\r\n\tStagingError\r\n\r\n**Detailed traceback**\r\n\r\n\t---------------------------------------------------------------------------\r\n\tStagingError                              Traceback (most recent call last)\r\n\t<ipython-input-29-6470bfb94cb0> in <module>\r\n\t\t 12 \r\n\t\t 13 tf.print(ok())\r\n\t---> 14 tf.print(not_ok())\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n\t\t455 \r\n\t\t456     tracing_count = self._get_tracing_count()\r\n\t--> 457     result = self._call(*args, **kwds)\r\n\t\t458     if tracing_count == self._get_tracing_count():\r\n\t\t459       self._call_counter.called_without_tracing()\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n\t\t501       # This is the first call of __call__, so we have to initialize.\r\n\t\t502       initializer_map = object_identity.ObjectIdentityDictionary()\r\n\t--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n\t\t504     finally:\r\n\t\t505       # At this point we know that the initialization is complete (or less\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n\t\t406     self._concrete_stateful_fn = (\r\n\t\t407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n\t--> 408             *args, **kwds))\r\n\t\t409 \r\n\t\t410     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n\t   1846     if self.input_signature:\r\n\t   1847       args, kwargs = None, None\r\n\t-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n\t   1849     return graph_function\r\n\t   1850 \r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n\t   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n\t   2149         if graph_function is None:\r\n\t-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n\t   2151           self._function_cache.primary[cache_key] = graph_function\r\n\t   2152         return graph_function, args, kwargs\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n\t   2039             arg_names=arg_names,\r\n\t   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n\t-> 2041             capture_by_value=self._capture_by_value),\r\n\t   2042         self._function_attributes,\r\n\t   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n\t\t913                                           converted_func)\r\n\t\t914 \r\n\t--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n\t\t916 \r\n\t\t917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n\t\t356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n\t\t357         # the function a weak reference to itself to avoid a reference cycle.\r\n\t--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n\t\t359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n\t\t360 \r\n\r\n\t~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n\t\t903           except Exception as e:  # pylint:disable=broad-except\r\n\t\t904             if hasattr(e, \"ag_error_metadata\"):\r\n\t--> 905               raise e.ag_error_metadata.to_exception(e)\r\n\t\t906             else:\r\n\t\t907               raise\r\n\r\n\tStagingError: in converted code:\r\n\r\n\t\t<ipython-input-20-6173bf43c1fe>:11 not_ok  *\r\n\t\t\treturn tf.zeros(5)[pos:3]\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:748 _slice_helper\r\n\t\t\ts.start != sys.maxsize):\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:1111 __ne__\r\n\t\t\treturn gen_math_ops.not_equal(self, other)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:7012 not_equal\r\n\t\t\tname=name)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:527 _apply_op_helper\r\n\t\t\tpreferred_dtype=default_dtype)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1296 internal_convert_to_tensor\r\n\t\t\tret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py:52 _default_conversion_function\r\n\t\t\treturn constant_op.constant(value, dtype, name=name)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:227 constant\r\n\t\t\tallow_broadcast=True)\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:265 _constant_impl\r\n\t\t\tallow_broadcast=allow_broadcast))\r\n\t\tC:\\Users\\Daniel\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py:450 make_tensor_proto\r\n\t\t\tnparray = np.array(values, dtype=np_dt)\r\n\r\n\t\tOverflowError: Python int too large to convert to C long\r\n", "comments": ["Can you please try with `!pip install tf-nightly-2.0-preview==2.0.0.dev20190919`and see if the problem still persists. I am not seeing any error message.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/8a0f645e34569d088493c78613b72da4/untitled208.ipynb). Thanks!", "Thanks! That fixed it.\r\nBut also had to downgrade to Python 3.6.8 since nightly builds are not available for 3.7.", "I am closing this issue since the query is been resolved.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32685\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32685\">No</a>\n", "I have this same issue; I have installed tf-nightly 2.9.0.dev20211227 without any solution. \r\nI run tfp.mcmc chain that has to call a function p(t). \r\n\r\n@tf.function\r\ndef p(t):\r\n    pos = tf.raw_ops.Bucketize(t,t_obs)\r\n    \r\n    precip_t = Prec.values[pos - 1:pos]\r\n\r\n    return precip_t[0]\r\n"]}, {"number": 32684, "title": "Arguments formatting error in 1.15 keras.model.save docs + incorrect model format info/docstring mismatch?", "body": "## URL(s) with the issue: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model#save\r\n\r\n## Description of issue (what needs changing):\r\n[1.15 branch]\r\nIt appears that the docstring of keras.model.save does not match the docs in 1.15.\r\n\r\nContent is different I think.\r\n\r\nThe bullet points for the input arguments for the save method are not formatted making it hard to read (although this may be poor formatting on the current source for the documentation as the docstring appears to be correctly formatted.).\r\n\r\nA side effect of this is that it also appears that the docs conflicts with the release notes that say the default format is as a `Tensorflow SavedModel ('tf')` however the docs say that the `tf` option is disabled implying that only `.h5` formats can be saved which is contradictory. An update of the docs from the seemingly correct docstring may fix this.\r\n\r\n### Correct links\r\n\r\nThe source code link appears to be correct despite the docstring not matching that of the website docs.\r\n\r\n### Parameters defined\r\n\r\nFormatting issue and also not updated.\r\n\r\n### Returns defined\r\n\r\nDepends on model format.\r\n\r\n### Raises listed and defined\r\n\r\nDepends on model format.\r\n\r\n### Submit a pull request?\r\n\r\nI don't quite understand why this has happened so no.\r\n", "comments": ["@jubjamie I updated the doc on TF website. It is now reflecting correctly on the [TF website](https://www.tensorflow.org/api_docs/python/tf/keras/Model?authuser=1#save). \r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 32683, "title": "Update nn_impl.py", "body": "`qz` may mislead as a new variable, suggest using `q * z` instead of `qz`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32683) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 32682, "title": "tf.keras.layers.Conv2D expected axis -1 of input shape to have value 3.", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 1080TI\r\n\r\n**Describe the current behavior**\r\n\r\nHere is my code.\r\n\r\n```\r\nx = tf.placeholder(tf.float32, [None, 3072])\r\ny = tf.placeholder(tf.int64, [None])\r\n\r\nx_img = tf.reshape(x, [-1, 3, 32, 32])\r\nx_img = tf.transpose(x_img, perm=[0, 2, 3, 1])\r\n\r\n# Layers Class\r\nconvLayer_32_3_3 = tf.keras.layers.Conv2D(filters=32,\r\n                                 kernel_size=(3, 3), \r\n                                 strides=(1,1),\r\n                                 padding='same',\r\n                                 data_format='channels_last',\r\n                                 activation=tf.nn.relu, name='convLayer_32_3_3')\r\nmaxPoolLayer_2_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \r\n                                     strides=(2, 2),\r\n                                     data_format='channels_last')\r\n\r\n# conv1: feature_map\r\nconv1_1 = convLayer_32_3_3(x_img)\r\nconv1_2 = convLayer_32_3_3(conv1_1)\r\n```\r\n\r\n**Error**\r\n\r\n```\r\n<ipython-input-8-c377e720039b> in <module>\r\n     18 # conv1: feature_map\r\n     19 conv1_1 = convLayer_32_3_3(x_img)\r\n---> 20 conv1_2 = convLayer_32_3_3(conv1_1)\r\n     21 \r\n     22 # shape: [16, 16]\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    584         # the corresponding TF subgraph inside `backend.get_graph()`\r\n    585         input_spec.assert_input_compatibility(self.input_spec, inputs,\r\n--> 586                                               self.name)\r\n    587         graph = backend.get_graph()\r\n    588         with graph.as_default(), backend.name_scope(self._name_scope()):\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)\r\n    157                 ' incompatible with the layer: expected axis ' + str(axis) +\r\n    158                 ' of input shape to have value ' + str(value) +\r\n--> 159                 ' but received input with shape ' + str(shape))\r\n    160     # Check shape.\r\n    161     if spec.shape is not None:\r\n\r\nValueError: Input 0 of layer convLayer_32_3_1 is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [None, 32, 32, 32]\r\n```\r\n\r\n**But when I change the code another style:**\r\n\r\n```\r\nx = tf.placeholder(tf.float32, [None, 3072])\r\ny = tf.placeholder(tf.int64, [None])\r\n\r\nx_img = tf.reshape(x, [-1, 3, 32, 32])\r\nx_img = tf.transpose(x_img, perm=[0, 2, 3, 1])\r\n\r\n# Layers Class\r\nconvLayer_32_3_3 = tf.keras.layers.Conv2D(filters=32,\r\n                                 kernel_size=(3, 3), \r\n                                 strides=(1,1),\r\n                                 padding='same',\r\n                                 data_format='channels_last',\r\n                                 activation=tf.nn.relu, name='convLayer_32_3_3')\r\nmaxPoolLayer_2_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \r\n                                     strides=(2, 2),\r\n                                     data_format='channels_last')\r\n\r\n# conv1: feature_map\r\nconv1_1 = tf.keras.layers.Conv2D(filters=32,\r\n                                 kernel_size=(3, 3), \r\n                                 strides=(1,1),\r\n                                 padding='same',\r\n                                 data_format='channels_last',\r\n                                 activation=tf.nn.relu, name='convLayer_32_3_1')(x_img)\r\nconv1_2 = tf.keras.layers.Conv2D(filters=32,\r\n                                 kernel_size=(3, 3), \r\n                                 strides=(1,1),\r\n                                 padding='same',\r\n                                 data_format='channels_last',\r\n                                 activation=tf.nn.relu, name='convLayer_32_3_2')(conv1_1)\r\n\r\n```\r\n\r\n**The code is ok.**\r\n\r\nSo who can tell me why? I don't know why can't i create a class to use this function but it is ok when I change it as same as new instance.", "comments": ["@MikoyChinese  In the first case you are using the same layer again (which should cause an error) i.e., you are passing output of 1st layer as again the input of the same layer which is causing an error but in the second case you are using two different layers i.e., you are passing the output of 1st layer to the input of 2nd layer(with same configuration). hope this helps!", "@gowthamkpr Thanks for your help, but I have some questions about it. If I create this as a class, why can't I call it again but should create two different layers class with same configuration. To me, I think that the class should call back again and again for writing less code.", "@MikoyChinese This is how keras works at this point in time. So we will consider it in future. Closing this issue as it has been resolved. Please add additional comments and we can open the issue again\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32682\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32682\">No</a>\n"]}, {"number": 32681, "title": "add a custom op in user_ops rebuild tensorflow but no use", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\ntensorflow version:1.5.1\r\nplateform:centos cpu\r\ninstall: source and pip\r\nI have add my op in `tensorflow/core/user_ops/`  zero_out.cc with context:\r\n`#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"ZeroOut\")\r\n    .Input(\"to_zero: int32\")\r\n    .Output(\"zeroed: int32\")\r\n\r\nclass ZeroOutOp : public OpKernel {\r\n public:\r\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n  void Compute(OpKernelContext* context) override {\r\n    const Tensor& input_tensor = context->input(0);\r\n    auto input = input_tensor.flat<int32>();\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n                                                     &output_tensor));\r\n    auto output = output_tensor->template flat<int32>();\r\n    const int N = input.size();\r\n    for (int i = 1; i < N; i++) {\r\n      output(i) = 0;\r\n    }\r\n    if (N > 0) output(0) = input(0);\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n`\r\n\r\nand add a BUILD file \r\n`load(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\r\ntf_custom_op_library(\r\n        name = \"zero_out.so\",\r\n        srcs = [\"zero_out.cc\"],\r\n)\r\n`\r\nthen,  add\r\n `# user_ops\r\nFact\r\nZeroOut\r\n`  \r\nafter Fact in `tensorflow/python/ops/hidden_ops.txt`\r\n\r\nadd `@tf_export(v1=['user_ops.my_zero_out'])\r\ndef leslie_zero_out(input):\r\n  \"\"\"Example of overriding the generated code for an Op.\"\"\"\r\n  return _gen_user_ops._zero_out(input)\r\n` in tensorflow/python/user_ops/user_ops.py\r\nand rebuild tensorflow wtih `bazel build -c opt --copt=-march=native --copt=-mfpmath=both  //tensorflow/tools/pip_package:build_pip_package`, and it complite corrected, but when I installed the *.whl, I cannot find the \"zero_out\" op, I donot know whatis wrong with me?\r\nanyone can tell how to add an op in tensorflow by source?", "comments": ["update tensorflow to 1.13 it works"]}, {"number": 32680, "title": "autograph=False not respected when calling get_concrete_function()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): reproduced on Ubuntu 18.04 and MacOS 10.14\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0  v1.14.0-rc1-22-gaf24dc91b5\r\n- Python version: 2.7.16\r\n\r\n**Describe the current behavior**\r\nWhen passing in `tf.function(..., autograph=False)`, console output indicates that `autograph` still attempts to autograph the function.\r\n\r\n**Describe the expected behavior**\r\nThat the function is not going to be autographed.\r\n\r\n**Code to reproduce the issue**\r\nThis encountered when passing in a function that `autograph` fails on. For example, a python function that is actually a wrapper around an R function.\r\n\r\nThis example is in R:\r\n```R\r\n\r\n> library(reticulate)\r\n> library(tensorflow)\r\n> \r\n> Sys.setenv(AUTOGRAPH_VERBOSITY=10)\r\n> reticulate::use_virtualenv(\"~/tf1\")\r\n> \r\n> x <- tf$constant(1)\r\n> add1 <- py_func(function() x + 1)\r\n> \r\n> fn <- tf$`function`(add1, autograph = FALSE)\r\n> \r\n> fn$get_concrete_function()\r\nERROR:tensorflow:Error converting <function initialize_variables at 0x134c82140>\r\nTraceback (most recent call last):\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 524, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 306, in convert\r\n    entity, program_ctx, free_nonglobal_var_names)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 229, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 431, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 624, in convert_func_to_ast\r\n    node = node_to_graph(node, context)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 657, in node_to_graph\r\n    node = converter.standard_analysis(node, context, is_initial=True)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/core/converter.py\", line 354, in standard_analysis\r\n    node = qual_names.resolve(node)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/pyct/qual_names.py\", line 254, in resolve\r\n    return QnResolver().visit(node)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 297, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 297, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 306, in generic_visit\r\n    new_node = self.visit(old_value)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 297, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/usr/local/opt/python@2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/Users/tomasz/tf1/lib/python2.7/site-packages/tensorflow/python/autograph/pyct/qual_names.py\", line 236, in visit_Subscript\r\n    if isinstance(s.value, gast.Num):\r\nAttributeError: 'module' object has no attribute 'Num'\r\nWARNING:tensorflow:Entity <function initialize_variables at 0x134c82140> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function initialize_variables at 0x134c82140>: AttributeError: 'module' object has no attribute 'Num'\r\n<tensorflow.python.eager.function.ConcreteFunction>\r\n```", "comments": ["I just checked against TensorFlow version 1.15.0rc1 and this issue is fixed there.", "Opening back up because this is not fixed in TensorFlow version 2.0.0rc1\r\n```R\r\n> library(reticulate)\r\n> library(tensorflow)\r\n> \r\n> Sys.setenv(AUTOGRAPH_VERBOSITY=10)\r\n> reticulate::use_virtualenv(\"~/tf2\")\r\n> \r\n> tf$version$VERSION\r\n[1] \"2.0.0-rc1\"\r\n> tf$version$GIT_VERSION\r\n[1] \"v2.0.0-rc0-101-gd2d2566eef\"\r\n> \r\n> x <- tf$constant(1)\r\n2019-09-20 00:03:35.132646: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-09-20 00:03:35.146449: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc075f78db0 executing computations on platform Host. Devices:\r\n2019-09-20 00:03:35.146465: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n> add1 <- py_func(function() x + 1)\r\n> \r\n> fn <- tf$`function`(add1, autograph = FALSE)\r\n> \r\n> fn$get_concrete_function()\r\nWARNING:tensorflow:Entity <function initialize_variables at 0x10adc18c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 'module' object has no attribute 'Num'\r\n<tensorflow.python.eager.function.ConcreteFunction>\r\n\r\n```", "@t-kalinowski, \r\nI could reproduce the issue with Tf 2.0.0.rc1. Can you try with latest Tf 2.0 nightly version. Thanks! ", "Thanks,\r\nThis appears to be fixed in tf 2.0 nightly preview (tf version `2.0.0-dev20190920`) and in tf version 1.15.0-rc1 \r\n\r\nHowever, this is currently broken in the tf v1 nightly (taken from `pip install tf-nightly`, tf version `1.15.0-dev20190821`", "TF 1.15 rc1 is the latest TF 1.X release so we can expect the fix to be included in final TF 1.15 version as well.\r\nTF nightly version ```1.15.0-dev20190821``` was built on 08/21/2019 where as TF 1.15rc1 version was released on 09/16/2019. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32680\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32680\">No</a>\n"]}, {"number": 32679, "title": "MobileNet_V3: will you implement it in tensorflow? ", "body": "", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32679\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32679\">No</a>\n"]}, {"number": 32678, "title": "tensorflow 2.0.0b0 ImportError: cannot import name 'Layer'", "body": "When I import the tensorflow, it has show the following errors :\r\n(tensorflow 2.0.0b0)\r\n> import tensorflow as tf\r\n> Traceback (most recent call last):\r\n> \r\n>   File \"<ipython-input-12-64156d691fe5>\", line 1, in <module>\r\n>     import tensorflow as tf\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 40, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 83, in <module>\r\n>     from tensorflow.python import keras\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 27, in <module>\r\n>     from tensorflow.python.keras import applications\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\", line 25, in <module>\r\n>     from tensorflow.python.keras import engine\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\", line 23, in <module>\r\n>     from tensorflow.python.keras.engine.base_layer import Layer\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 50, in <module>\r\n>     from tensorflow.python.keras.saving import saved_model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\__init__.py\", line 20, in <module>\r\n>     from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 32, in <module>\r\n>     from tensorflow.python.keras.utils import conv_utils\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\__init__.py\", line 38, in <module>\r\n>     from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\multi_gpu_utils.py\", line 22, in <module>\r\n>     from tensorflow.python.keras.engine.training import Model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 39, in <module>\r\n>     from tensorflow.python.keras import metrics as metrics_module\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\", line 33, in <module>\r\n>     from tensorflow.python.keras.engine.base_layer import Layer\r\n> \r\n> ImportError: cannot import name 'Layer'\r\n> \r\n> \r\n> \r\n> \r\n> import tensorflow as tf\r\n> Traceback (most recent call last):\r\n> \r\n>   File \"<ipython-input-13-64156d691fe5>\", line 1, in <module>\r\n>     import tensorflow as tf\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 40, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 83, in <module>\r\n>     from tensorflow.python import keras\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 27, in <module>\r\n>     from tensorflow.python.keras import applications\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\", line 25, in <module>\r\n>     from tensorflow.python.keras import engine\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\", line 23, in <module>\r\n>     from tensorflow.python.keras.engine.base_layer import Layer\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 50, in <module>\r\n>     from tensorflow.python.keras.saving import saved_model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\__init__.py\", line 20, in <module>\r\n>     from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 32, in <module>\r\n>     from tensorflow.python.keras.utils import conv_utils\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\__init__.py\", line 38, in <module>\r\n>     from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\multi_gpu_utils.py\", line 22, in <module>\r\n>     from tensorflow.python.keras.engine.training import Model\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 39, in <module>\r\n>     from tensorflow.python.keras import metrics as metrics_module\r\n> \r\n>   File \"D:\\Users\\1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\", line 33, in <module>\r\n>     from tensorflow.python.keras.engine.base_layer import Layer\r\n> \r\n> ImportError: cannot import name 'Layer'\r\nHow to deal with it ? Should I pip the tensorflow 2.0 agnain ?", "comments": ["@xichuanhit,\r\nPlease uninstall available tensorflow and python and install both again. Please try installing latest Tf version 2.0.0.rc1.  Thanks!", "@xichuanhit, \r\nAny update!\r\n\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I'm having the same issue, I've tried uninstalling and installing again both python and TensorFlow and it didn't work @gadagashwini \r\n", "@prpeixoto, Which Tensorflow and python version are you trying to install?", "@gadagashwini thank you for the reply. I'm using tensorflow 2.0 and Python 3.7 on windows. I was previously using tensorflow 2.1, but downgraded since other issues were occurring that were resolved when downgrading.\r\nThe current issue is as follows:\r\nImportError(\"cannot import name 'Layer' from 'tensorflow.python.keras.engine.base_layer'\r\n Any ideas or suggestions on what could be causing this and how to resolve this? Thank you", "@prpeixoto, Could you open the new issue by providing information asked in [Template](https://github.com/tensorflow/tensorflow/issues/new/choose). Issue could be configuration specific.     ", "Of course, just did it, https://github.com/tensorflow/tensorflow/issues/36162\r\nThank you", "I have solved this problem by using anaconda.Use \"conda install -c conda-forge tensorflow\" in cmd on Windows.I have used pip and pycharm tools but failed.I uninstalled it and run \"conda install -c conda-forge tensorflow\".This works."]}]