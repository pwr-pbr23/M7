[{"number": 46949, "title": "How to use tflite on bert", "body": "I have convert a trained bert model from .pb to .tflite\u3002\r\nI have two tasks : 1) sentence pair classification 2) QA on squad2.0 format dataset which need to have more than one outputs.\r\nI have find text classification demo code on normal text classification task, but what should i do to hire tflite on bert.\r\nWonder that whether tflite BERT needs input_ids, input_mask, input_type_ids, if they are needed, how to make that kind of input to tflite interpreter.\r\nThanks", "comments": ["Hi,\r\n\r\nYou would be able to get better answers from broader folks if you ask this kind of question on Stackoverflow.\r\nIt seems not so clear what you're question targets to. If it's about BERT's inputs, [TFLite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_question_answerer) or [Text classification example](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_interpreter/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java) would be good places to start.", "+1 for what is mentioned above by @teijeong.\r\n\r\n(2) For QA task, we already provided demo code for [BERT QA](https://github.com/tensorflow/examples/blob/master/lite/examples/bert_qa/android/app/src/main/java/org/tensorflow/lite/examples/bertqa/ml/QaClient.java). \r\n\r\nIf you use a similar BERT model for (1) sentence pair classification but multiple inputs, you can adapt from either [Text classification](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_interpreter/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java) or the BERT QA app. The key is to use the right tensor inputs and shapes in java for your model, and run [`tflite.runForMultipleInputsOutputs(inputs, output)`](https://github.com/tensorflow/examples/blob/6bb09d63a8cc9813431257bfac486ebaba1da66c/lite/examples/bert_qa/android/app/src/main/java/org/tensorflow/lite/examples/bertqa/ml/QaClient.java#L230).", "Hi @TLCFYBJJHYYSND! \r\nWe are checking to see whether you still need help in this issue . Have you checked with above comment yet?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46948, "title": "keras LSTM model - a tf 1.15 equivalent that works with tflite", "body": "Hello\r\n\r\n**TLDR**: How to implement this model using `tf.lite.experimental.nn.TFLiteLSTMCell, tf.lite.experimental.nn.dynamic_rnn`instead `keras.layers.LSTM`?\r\n![image](https://user-images.githubusercontent.com/26148975/107017531-eab71b00-67a7-11eb-9a92-b161b49f439b.png)\r\n\r\nI have this network in keras:\r\n```python\r\ninputs = keras.Input(shape=(1, 52))\r\nstate_1_h = keras.Input(shape=(200,))\r\nstate_1_c = keras.Input(shape=(200,))\r\nx1, state_1_h_out, state_1_c_out = layers.LSTM(200, return_sequences=True, input_shape=(sequence_length, 52),\r\n                                               return_state=True)(inputs, initial_state=[state_1_h, state_1_c])\r\noutput = layers.Dense(13)(x1)\r\n\r\nmodel = keras.Model([inputs, state_1_h, state_1_c],\r\n                    [output, state_1_h_out, state_1_c_out])\r\n```\r\n\r\nI need to implement it in tensorflow 1.15, but in a way that will be compatible with tflite 1.15.\r\n** It means that I cannot use `keras.layers.LSTM` because it is not compatible with tflite 1.15. **\r\n\r\nFollowing this examples, I saw the tutorial: https://github.com/tensorflow/tensorflow/tree/r1.15/tensorflow/lite/experimental/examples/lstm\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/lite/experimental/examples/lstm/TensorFlowLite_LSTM_Keras_Tutorial.ipynb \r\n\r\nWhich explains how to implement LSTM in a way that is compatible with tflite 1.15. \r\nI understand I need to use the following layers: `tf.lite.experimental.nn.TFLiteLSTMCell, tf.lite.experimental.nn.dynamic_rnn`\r\n\r\nThe hard part is this line:\r\n```python\r\nx1, state_1_h_out, state_1_c_out = layers.LSTM(200, return_sequences=True, input_shape=(sequence_length, 52),\r\n                                               return_state=True)(inputs, initial_state=[state_1_h, state_1_c])\r\n\r\n```\r\n\r\nHow can I implement it? \r\n\r\nThe [dynamic_rnn documentation](https://www.tensorflow.org/api_docs/python/tf/compat/v1/lite/experimental/nn/dynamic_rnn) explains how to provide initial state to the dynamic rnn. \r\n\r\nI try to use it in the `buildLstmLayer` function provided (that should implement LSTM): \r\n\r\n```python\r\ndef buildLstmLayer(inputs, num_layers, num_units):\r\n  \"\"\"Build the lstm layer.\r\n\r\n  Args:\r\n    inputs: The input data.\r\n    num_layers: How many LSTM layers do we want.\r\n    num_units: The unmber of hidden units in the LSTM cell.\r\n  \"\"\"\r\n  lstm_cells = []\r\n  for i in range(num_layers):\r\n    lstm_cells.append(\r\n        tf.lite.experimental.nn.TFLiteLSTMCell(\r\n            num_units, forget_bias=0, name='rnn{}'.format(i)))\r\n  lstm_layers = tf.keras.layers.StackedRNNCells(lstm_cells)\r\n  # Assume the input is sized as [batch, time, input_size], then we're going\r\n  # to transpose to be time-majored.\r\n  transposed_inputs = tf.transpose(\r\n      inputs, perm=[1, 0, 2])\r\n  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(\r\n      lstm_layers,\r\n      transposed_inputs,\r\n      dtype='float32',\r\n      time_major=True)\r\n  unstacked_outputs = tf.unstack(outputs, axis=0)\r\n  return unstacked_outputs[-1]\r\n```\r\n\r\nI try to take this code:\r\n```python\r\n  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(\r\n      lstm_layers,\r\n      transposed_inputs,\r\n      dtype='float32',\r\n      time_major=True)\r\n```\r\nAnd add initial state.\r\n\r\nThis try\r\n  ```python\r\noutputs, _ = tf.lite.experimental.nn.dynamic_rnn(\r\n      lstm_layers,\r\n      transposed_inputs,\r\n      dtype='float32',\r\n      time_major=True,\r\n      initial_state=[tf.compat.v1.placeholder(tf.float32, shape=(200)), tf.compat.v1.placeholder(tf.float32, shape=(200))])\r\n```\r\nreturns error `ValueError: Shape must be rank 2 but is rank 1 for 'stacked_rnn_cells/concat' (op: 'ConcatV2') with input shapes: [?,28], [200], [].\r\n`\r\n\r\nThis try:\r\n```python\r\n  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(\r\n      lstm_layers,\r\n      transposed_inputs,\r\n      dtype='float32',\r\n      time_major=True,\r\n      initial_state=[tf.compat.v1.placeholder(tf.float32, shape=(1, 200)), tf.compat.v1.placeholder(tf.float32, shape=(1, 200))])\r\n```\r\nreturns error `ValueError: Dimensions must be equal, but are 228 and 92 for 'stacked_rnn_cells/MatMul' (op: 'MatMul') with input shapes: [1,228], [64,92].\r\n`\r\n\r\nHow can I solve it?\r\n\r\nThank you", "comments": ["@yonatanbitton,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is a larger community that reads questions there. \r\n\r\nAlso, TensorFlow 1.x is not actively supported. I'd suggest upgrading TensorFlow to the latest stable version v2.4.1. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46948\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46948\">No</a>\n"]}, {"number": 46947, "title": "Mobilenet parameters: alpha & rho", "body": "Hello, my name is Joy and I've been learning about PoseNet in order to use it in my health-related research work.\r\nI was impressed how mobilenet enables to keep high accuracy while reducing CPU (or GPU/NPU) dependency by adapting few parameters where my questions sprouted.\r\nI've noticed that in mobilenet official papers, there were two multipliers introduced: alpha and rho. I'll skip the explanation of both parameters. \r\nI wonder what is the each value of alpha and rho for the mobilenet for the newest pretrained PoseNet model. Also, I'm wondering if there is a guideline for parameters(especially alpha and rho) tuning, and how the values of both are set and validated before training the model.\r\nThank you.", "comments": ["@joyccino \r\nThe multipliers determine  how depths are adjusted in positive Convs, generally more the depths better it is but that comes along with an expense of increased number of parameters.\r\nAs this is not a bug or a feature request, can you please create an issue on [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) for this and move this to closed status."]}, {"number": 46943, "title": "Reagarding discripency in tensorboard validation accuracy and the one printed during training", "body": "When I am running a random search for hyperparameter tunning. The accuracies appearing on print screen for training and validation sets are different which is not appearing in tensorboard. In tensorboard the validation accuracy always appears lesser than the print value.\r\n\r\n![image](https://user-images.githubusercontent.com/37747800/106998754-040d9680-67ab-11eb-8833-0ed9b6b7bf4c.png)\r\n![image](https://user-images.githubusercontent.com/37747800/106998902-40d98d80-67ab-11eb-9713-f9e4efba3a5a.png)\r\n\r\nThe accuracy appearing are different. Why?", "comments": ["@ankit1-iitbhu,\r\nTensorboard issues are tracked in tensorflow/tensorboard repo. Could you please submit a new issue from [this link](https://github.com/tensorflow/tensorboard/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46942, "title": "Update array_ops.py", "body": "The current implementation of the `Split / SplitV` op's wrapper function (in Python)\r\nconvert `num_or_size_splits` to the `size_splits` tensor at the first line.\r\nHowever, if we pass `num_or_size_splits` as a `Integral` or `Dimension` type, this function calls `Split` op directly\r\n(does not use `size_splits` tensor).\r\n\r\nThis does not matter in eager mode but creates a redundant tensor (`Const` tensor or `Pack` etc...) in graph mode.\r\n(Actually, the grappler might remove this redundant tensor since it is not used anywhere, but for the neat graph in tensorboard)\r\nThen I just reordered Python statement after the first `if` statement", "comments": []}, {"number": 46941, "title": "tf.keras.backend.random_normal segfault ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the current behavior**\r\n`tf.keras.backend.random_normal` crashes(segfault) when `dtype` is integer\r\n\r\n**Describe the expected behavior**\r\nexpect an exception message if the file format is incorrect instead of crash\r\n\r\n**Standalone code to reproduce the issue**\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.keras.backend.random_normal(shape=np.ones((1)), mean=np.ones((1)), dtype=20)\r\n~~~\r\nOutput:\r\n~~~\r\nSegmentation fault (core dumped)\r\n~~~", "comments": ["I am able to reproduce the issue on TF v2.4 and TF-nightly. Please find the [gist here](https://colab.research.google.com/gist/Saduf2019/8c1d5438aa272e9137543a1bf72c57bd/untitled520.ipynb). \r\nThanks!\r\n\r\n", "@DNXie I tried to reproduce the issue in TF 2.6 and the colab doesnt crashes instead it gives an error message. Please check the gist [here](https://colab.research.google.com/gist/saikumarchalla/72c03f6c9bf56ec41f2701d8f2d33fd6/untitled92.ipynb).Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46941\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46941\">No</a>\n"]}, {"number": 46940, "title": "[TFTRT] Add Dynamic Shape Testing for ConvertConv3D", "body": "@bixia1 @tfeher for review\r\n\r\nFeature Tracker: #45481", "comments": ["@bixia1 : PR is squashed and good to go ;) ", "Hi, there is a comment you haven't addressed yet, https://github.com/tensorflow/tensorflow/pull/46940/files#r571100867.\r\n\r\nI am approving it so that I can get it for testing but please feel free to push another commit and squash it."]}, {"number": 46939, "title": "tf.nn.depth_to_space crash(aborts) with block_size is large", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the current behavior**\r\n`tf.nn.depth_to_space` crash(aborts) with `block_size` is large\r\n\r\n**Describe the expected behavior**\r\nexpect an exception message if the file format is incorrect instead of crash\r\n\r\n**Standalone code to reproduce the issue**\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.nn.depth_to_space(input=np.ones((4, 1, 1, 1)), block_size=2147483647)\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\n2021-02-05 00:28:12.102761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-02-05 00:28:12.108864: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -17179869180)\r\nAborted (core dumped)\r\n~~~", "comments": ["@DNXie \r\n\r\nI have tried in colab with TF versions 2.1, 2.4, nightly versions(`2.5.0-dev20210204`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/177654fc4b30edb5ed05136747b83ee6/untitled660.ipynb). Thanks!", "@DNXie I tried to reproduce the issue in TF 2.6 and the colab doesnt crashes instead it gives an error message. Please check the gist [here](https://colab.research.google.com/gist/saikumarchalla/c0ee174eaa10bbcd578f3f6652fe9a57/untitled92.ipynb#scrollTo=aVDdvD6FlZyv).Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46939\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46939\">No</a>\n"]}, {"number": 46937, "title": "Initialization of global pointer variable seems suspect with our current use of Renode.", "body": "@tensorflow/micro\r\n\r\nI hit this issue while working on https://github.com/tensorflow/tensorflow/pull/46904:\r\n\r\n * If I create a global pointer variable (explicitly initialized to nullptr) and check for the variable == nullptr in my factory function, the check always returns false.\r\n\r\nAFAICT, this behavior is specific to our use of Renode. I have not been able to reproduce on Linux or with the Xtensa simulator.\r\n\r\nI have a workaround that should allow #46904 to be merged and I will then update this issue with a cleaner way to reproduce this error.", "comments": ["The reason is in `_zero_initialize_bss_data` (tensorflow/lite/micro/tools/make/downloads/stm32_bare_lib/source/startup.c). It initializes the BSS data with DEADBEEF.\r\n\r\nTo verify that:\r\n\r\nBuild with debug info\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill BUILD_TYPE=debug test_renode -j`nproc`\r\n```\r\n\r\nRun in Renode:\r\n```\r\ninclude @tensorflow/lite/micro/testing/bluepill_nontest.resc; sysbus LoadELF @tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3_debug/bin/test_renode; machine StartGdbServer 3333\r\n```\r\n\r\nStart GDB:\r\n```\r\ntensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-gdb tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3_debug/bin/test_renode\r\n```\r\n\r\nIn GDB:\r\n```\r\ntar rem :3333\r\nwatch *0x20000008\r\nmon s\r\nc\r\n```\r\n\r\nIt will break in the code that actually writes this data.\r\n\r\nNow why do they go to bss instead of data? I don't know.\r\n\r\nHere's an excerpt from the objdump:\r\n\r\n```\r\nDisassembly of section .data:\r\n\r\n20000000 <a>:                        <- OK\r\n20000000:   0000002d    andeq   r0, r0, sp, lsr #32\r\n\r\n20000004 <init_to_true>:                        <- OK\r\n20000004:   00000001    andeq   r0, r0, r1\r\n\r\nDisassembly of section .bss: \r\n\r\n20000008 <init_to_false>:                        <- NOT OK\r\n20000008:   00000000    andeq   r0, r0, r0\r\n\r\n2000000c <init_to_nullptr>:                        <- NOT OK\r\n2000000c:   00000000    andeq   r0, r0, r0\r\n\r\n20000010 <g_tick_count>:                        <- NOT OK\r\n20000010:   00000000    andeq   r0, r0, r0\r\n\r\nDisassembly of section ._user_heap_stack:\r\n\r\n20000014 <._user_heap_stack>:\r\n    ...   \r\n```\r\n\r\nFor the record, this is HAL specific, so it should behave the same way on HW, not only in Renode.", "Changing 0xDEADBEEF to 0 of course fixes the problem", "Your example @advaitjain has similar results on `stm32f4` also built with `stm32_bare_lib` that causes the problem.\r\n\r\nThe `-559038737` number that is printed as `init_to_nullptr` is exactly a signed int value for `0xDEADBEEF`. The `239` in `init_to_false` is the ending `0xEF` byte.\r\n\r\nI remember stumbling upon an issue with this BSS initialization when code from such an `if` was never executed:\r\n```\r\nstatic TYPE* some_pointer = nullptr;\r\nif (!some_pointer){\r\n    // Code never called\r\n}\r\n```\r\nThe compiler simply assumed a static pointer is always `nullptr` (`0x0`) right after declaration and skipped the \"additional\" `nullptr` initialization while it was `0xDEADBEEF` instead.\r\n\r\nNow I can see there's no such problem anymore so perhaps the compiler has been fixed.\r\n\r\nNevertheless, this issue made me wonder again about what the purpose of that `0xDEADBEEF` initialization is. The binaries work well without it. Perhaps it could be simply disabled @aselle @petewarden? https://github.com/google/stm32_bare_lib/blob/55bf49816f1a9dc7d9e35951c135e852ce7a98df/source/startup.c#L114", "Thanks for the debugging @PiotrZierhoffer.\r\n\r\n@ajelinski, I'm not sure about the thinking behind the decision to go with not zero initializing the .bss -- it does seem non-standard.\r\n\r\nI have made https://github.com/tensorflow/tensorflow/pull/47382 that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data\r\n\r\nThis link has some useful info as well: https://stackoverflow.com/q/8721475\r\n", "Talked to @petewarden and we decided that changine STM32 Bare Lib is the way to go.\r\n\r\n> \r\n> I have made #47382 that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data\r\n> \r\n> This link has some useful info as well: [stackoverflow.com/q/8721475](https://stackoverflow.com/q/8721475)\r\n\r\n#47382 originally added `-fno-zero-initialized-in-bss` and verified that the globals were in the .data section instead of .bss using the tips from https://stackoverflow.com/q/8721475\r\n\r\nIt has since been updated to simply pull in an updated version of STM32 Bare Lib (with the zero initialization of .bss)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46937\">No</a>\n"]}, {"number": 46936, "title": "Cannot create mbed folder", "body": "**System information**\r\n- OS Platform and Distribution Windows 10\r\n- Mobile device STM32F746\r\n\r\nWhen I run the command:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=\"CMSIS disco_f746ng\" generate_hello_world_mbed_project\r\n\r\nI get the following error message:\r\n/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..  \r\n\r\n", "comments": ["@mdinoulis,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/46667#issuecomment-766923481) from issue [#46667](https://github.com/tensorflow/tensorflow/issues/46667) with a similar error and let us know if it helps. Thanks!", "Thanks for the quick response, however I already tried removing the TAG descriptor but I get the following error:\r\n\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed  generate_hello_world_mbed_project\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:47: pipe: No error\r\n-m was unexpected at this time.\r\n'tr' is not recognized as an internal or external command,\r\noperable program or batch file.\r\nFIND: Parameter format not correct\r\nFIND: Parameter format not correct\r\nThe syntax of the command is incorrect.\r\nprocess_begin: CreateProcess(NULL, bash D:\\Projects\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:519: pipe: Bad file descriptor\r\ntensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: .  Stop.", "Note this is using the latest version of the tensorflow repository, cloned yesterday.", "Ok, I've made some progress with this problem but it's still not working.\r\nI have installed bash for windows. I then got an error saying wget was not found and so have installed wget too.\r\n\r\nNow when I try and run make it partially compiles but I get the following error message:\r\n\r\n\r\n\r\n\r\n\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed generate_hello_world_mbed_project\r\nSYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\r\nsyswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\r\n--2021-02-06 15:18:49--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\r\nResolving mirror.tensorflow.org... 142.250.178.16, 2a00:1450:4009:815::2010\r\nConnecting to mirror.tensorflow.org|142.250.178.16|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: `C:/Users/mdino/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n\r\n     0K .......... .......... .......... .......... ..........  2% 2.13M 1s\r\n    50K .......... .......... .......... .......... ..........  5% 4.13M 1s\r\n   100K .......... .......... .......... .......... ..........  8% 4.62M 0s\r\n   150K .......... .......... .......... .......... .......... 11% 2.83M 0s\r\n   200K .......... .......... .......... .......... .......... 14% 6.34M 0s\r\n   250K .......... .......... .......... .......... .......... 17% 1.76M 0s\r\n   300K .......... .......... .......... .......... .......... 20% 96.9M 0s\r\n   350K .......... .......... .......... .......... .......... 23% 2.47M 0s\r\n   400K .......... .......... .......... .......... .......... 26% 3.98M 0s\r\n   450K .......... .......... .......... .......... .......... 29% 1.26M 0s\r\n   500K .......... .......... .......... .......... .......... 31% 12.4M 0s\r\n   550K .......... .......... .......... .......... .......... 34% 8.67M 0s\r\n   600K .......... .......... .......... .......... .......... 37% 3.93M 0s\r\n   650K .......... .......... .......... .......... .......... 40%  156M 0s\r\n   700K .......... .......... .......... .......... .......... 43% 7.60M 0s\r\n   750K .......... .......... .......... .......... .......... 46% 4.49M 0s\r\n   800K .......... .......... .......... .......... .......... 49% 4.25M 0s\r\n   850K .......... .......... .......... .......... .......... 52% 5.23M 0s\r\n   900K .......... .......... .......... .......... .......... 55% 4.00M 0s\r\n   950K .......... .......... .......... .......... .......... 58% 4.21M 0s\r\n  1000K .......... .......... .......... .......... .......... 61% 3.13M 0s\r\n  1050K .......... .......... .......... .......... .......... 63% 5.83M 0s\r\n  1100K .......... .......... .......... .......... .......... 66% 6.03M 0s\r\n  1150K .......... .......... .......... .......... .......... 69% 3.86M 0s\r\n  1200K .......... .......... .......... .......... .......... 72% 5.50M 0s\r\n  1250K .......... .......... .......... .......... .......... 75% 5.55M 0s\r\n  1300K .......... .......... .......... .......... .......... 78% 4.17M 0s\r\n  1350K .......... .......... .......... .......... .......... 81% 3.74M 0s\r\n  1400K .......... .......... .......... .......... .......... 84% 5.93M 0s\r\n  1450K .......... .......... .......... .......... .......... 87% 3.14M 0s\r\n  1500K .......... .......... .......... .......... .......... 90% 4.46M 0s\r\n  1550K .......... .......... .......... .......... .......... 93% 5.87M 0s\r\n  1600K .......... .......... .......... .......... .......... 95% 3.44M 0s\r\n  1650K .......... .......... .......... .......... .......... 98% 6.73M 0s\r\n  1700K .......... .........                                  100% 7.64M=0.4s\r\n\r\n2021-02-06 15:18:49 (4.12 MB/s) - `C:/Users/mdino/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' saved [1760478/1760478]\r\n\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 1: $'PK\\003\\004': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 2: nL8Q5: command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 3: nL8Q?: command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 4: $'\\bnL8Qw\\030B\\005\\352\\002\\304\\005V': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 4: $'\\367\\257XY': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\002T': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'v\ud78d\\265M4\\036w]\\027\\262\\036p\\250t5\\256\\367\\245f': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\225L\\347\\313l\\036\\020\\350\\341\u0435\\254\\3218\\002~\\264B\\323\\302\\371\\016XC\\2408\\313': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'@\\244\u034f\\v\\2105': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\301\\2173H2\\037.\\342,\\311N\\223\\233d}\\231^\\257\\341': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'^\\255\\342\\345:\\231g\\220\\256': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'m\\237\\220Q7\\037\u0522\\304R\\234R\\372T\\235\\317k\\347T\\347\\316\u071d\\353F\\352\\217g\\317q': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: 6\u2592m@0\u2592cs/d\u2592\u2592 \u2592j\u25924\u2592E)8\u2592&\u2592\u2592\u2592z@-i#hPo\u2592q\u2592X\u25926\u2592\u2592\r\n\u2592l\u2592\u2592{\u2592\u2592A\r\n        y+\u2592\u2592\u2592\u2592\u2592\u2592Ff\u2592%\u2592\u259232\u2592\u0707\u25925\u2592s\u2592\u2592D%k<\u2592\u0202J\u2592\u2592\u2592W\u25929\u2592\u25920\u2592ubOO\u2592\u2592\u2592_\u2592\u0255\u2592@\u2592\u2592Y\u25920\u2592!\u2592\u2592m\u2592\u2592b\u2592\u046ah\u2592R\u2592(K\u2592H\u25922@L\u259290j\u2592\u259263J\u2592^%,\u2592G\u2592\u2592j-\\\u2592\u2592liW\u2592\u2592\u2592A\r\n                                                                                                                     \u259227/\u25921\u2592\u2592\u2592U\u2592e'\u2592j\r\n   Yk\u2592u9\u2592\u2592\u2592#\u25923\u2592(l\u0da4\u2592d7\u2592\u2592Z4K\u2592Ez\u2592\u2592y}\u2592]O\u2592\u2592,\u2592m'>!\u2592(\u2592}\u2592\u2592\u2592\u2592\u2592W\u2592t\u2592\u2592|^\u2592\u25928\u2592\u2592Zu\u2592\u2592v{\u2592\u2592Jt+{\u07d0%^\u2592\u2592k<~.\u2592\u0640\u2592Z46\u2592\u2592v9\u2592\u2592      \u2592\u2592v\u2592\u2592Z\u2592\u050a\u2592\u074f\u0732{7\u2592o\u023d\u2592)\r\n                                                                                                                         H\\\u2592/   \u2592e\u2592C\u2592w\u2592\u2592@\u2592\u2592\u2592\u2592\u2592\u2592\u2592B2\u2592#-{\u2592\u25920\u2592\u2592\u2592\u2592\u2592l>9\u2592\u2592t)\u2592\u2592s_\u2592\u2592P2\u2592   PK\r\nnL8Q>   flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.bazelci/UT\u2592\u2592l_PK\r\nnL8Q=\u2592!X\u2592K      flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.bazelci/presubmit.ymlUT\u2592\u2592l_\u2592\u2592\u2592\u2592J*\u2592\u2592I\u2592L\u2592L-\u2592R\u2592I,I-.\u2592*\u2592i\u2592E\u2592\u2592V\r\n\u2592I\u2592y%\u2592\u2592f& \u2592\u2592X}|IbQzjI1DHWAIOOO  \u2592\u2592Kj\u2592\u2592\u2592ML\u2592/\u2592\u2592PK\r\nnL8Q\u25924%_\u25920B     flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.clang-formatUT\u2592\u2592l_m\u2592Mn\u2592@\r\n                                                                                              \u2592\u2592>)[v\u2592\u2592*RP\u2592\\p+\u2592y\u2592n\u2592Q\u2592E\u2592: No such file or directory\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 11: $'OO\\337\\367\u02b2\\204\\0365\\3341P]\\034\\327\\025ZL4\\237t\\364]r\\363\\024c\\020\\202\\216\\214?h\\210\\254N\\326\\b\\a\\275\\221z]P\\022\\301c\\177\\346\\2608\\274\\350\\234\\3230tl4y\\006\\244\\272h.y\\371\\214i\\201,': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 11: $'\\034Z\u00c9\u6793\\377\\b\\277\\211\\215l\\270\\247\\326\\b\\257ot[\\005\\235:\\232\\004\\235\\243\\246\\277\\231\\304m\\242\\3711\\277\\356\\361\\235$\\235\\264\\031Y\\363\\351\\2365\\363\\334\\356\\004\\343\\232-_\\346_\\332+\\355[\\264\\371\\021\\324J\\234\\256\\377B\\252\\252\\002\\370\\004PK\\003\\004': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 12: $'\\bnL8Q\\33088\u049e\\337B': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 13: $'\\302@\\020D\\373': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\\021\\301\\336\\316\\322?\\020': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: r\u2592\u2592\u2592\u2592T\u2592bLl\u2592XN\u2592\u2592\u2592QtK*4: No such file or directory\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\\202\\v%Q\\256\\253\\333\\341^\\211ulh': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 17: $'f\\345eey\\206\\310?S\u07abwZ\\270pF\\223\u01026\\306\\3236\\375{\\351\\003PK\\003\\004': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\bnL8Q\u0520P3\\211\\375A': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: command substitution: line 19: syntax error near unexpected token `)'\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: command substitution: line 19: `1\r\n                                                                                    D\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592d\u2592mJ\u2592\u2592.\u2592[\u2592^\u011d3o=&\u25929bxB \u25920j\u2592<\u2592\u2592\u2592\u2592k$\u2592x)(b\"1 \u2592\u2592P\u2592x\u2592l'\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\u0142\\205\\270\\312\\0261\u037c\\304RT\\373t\\363\\206\\036t\\371\\261\\204d\\340V\u05efv\\230\\036\\236\\332\\300U0\\330_\\246\\345\\f\\343L\\336\\027\\027mg\\252\u06ee\\230\\235g\\376\\201I\\275\\317\\037PK\\003\\004': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 17: $'\\bnL8Q\\026\\345\\365\\275OUC': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\200': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\365\\370\\243\\371PK\\003\\004': command not found\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 19: flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.github/UT\u2592\u2592l_PK: No such file or directory\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 20: syntax error near unexpected token `('\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 20: nL8Q}\u2592\u2592\u2592N   flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.github/ISSUE_TEMPLATE.mdUT\u2592\u2592l_U\u2592AO\u25920\r\n                                 \u2592\u2592\u2592o\u2592\u2592(\u2592\u2592v@ABp H\u2592^\u2592\u2592\u04a4\u2592]`\u2592\u2592C\u2592I\u2592!\u2592\u2592\u2592=\u2592\u2592\u2592\u2592\u2592!\u2592hr\u2592\u2592\u2592>\u2592\u2592\u0502\u2592\u2592\u2592\r\n                                                                                       \u2592^#\u25920z\u06b3U\u2592\u2592C\u2592q\u2592\u25921\u2592,\u2592\u2592|\u2592\u2592a\u2592\\#RjGj\u2592B.+\u2592\u2592!r\u2592'9\u034fy\u2592B\u2592\u2592D\u2592?KR\u2592\u2592I\u2592GkX\u2592$g\u2592B9B\u2592F^9\u2592\u2592A\u2592q\u2592\u2592\u2592u\u2592\u2592\u25921\u2592\u2592\u2592bj\u25921\u2592=HO\u2592\u2592\u2592\u2592\u2592,\u2592\u2592\u2592!-\u25929\u2592G     \u2592s\u2592\u2592\u2592\u2592W\u2592        \u2592=\u2592L\u2592\u2592\u2592\u2592<\\]Uh\u2592\u2592zu[\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592S\u25927\u2592dvT@J\u05bceY\u2592 \u2592q)Z\u2592\u2592r\u2592\u2592\u2592\u2592;\u2592\u2592\uda07\udc61\u2592,\u2592\u0660nV\u2592s\u03ff\u2592\u25926\u2592\u2592\u2592\u2592{4=;\u2592I%\u2592\u2592f\u2592\u2592\u2592\u2592PK'\r\ntensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: Bad checksum. Expected: aa9adc93eb9b33fa1a2a90969e48baee, Got: .  Stop.\r\n\r\n\r\n\r\n\r\n\r\n", "@mdinoulis,\r\nCould you please check if you are facing the same issue in a Linux environment as well.\r\n\r\nAlso, go through these comments from similar issues [#45033](https://github.com/tensorflow/tensorflow/issues/45033#issuecomment-732299726) and [#46916](https://github.com/tensorflow/tensorflow/issues/46916#issuecomment-774973928). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46936\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46936\">No</a>\n", "This appears to work on my OSX environment but not on Windows "]}, {"number": 46935, "title": "Tensorflow GPU Not Recognizing GPUs", "body": "**System information**\r\n- Windows 10 Pro 19042.746\r\n- TensorFlow installed from conda/pip\r\n- TensorFlow version: 2.3.0\r\n- TensorFlow GPU version: 2.3.0\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.2 as of 2/4/2021\r\n- GPU model and memory: TITAN RTX 303MiB / 24576MiB\r\n- GPU model and memory: GeForce GTX 1070 Ti 1720MiB /  8192MiB\r\n\r\n\r\n_tflow_select             2.3.0                       gpu\r\ntensorboard               2.3.0              pyh4dce500_0\r\ntensorboard-plugin-wit    1.6.0                      py_0\r\ntensorflow                2.3.0           mkl_py38h8557ec7_0\r\ntensorflow-base           2.3.0           eigen_py38h75a453f_0\r\ntensorflow-estimator      2.3.0              pyheb71bc4_0\r\ntensorflow-gpu            2.3.0                he13fc11_0\r\n\r\n\r\nThe GPUs are not displayed when querying with list_local_devices() and they are used when explicitly declaring them to be used in  with tf.device('GPU:1'). Yet, tensorflow does not complain when I reference the GPU devices, but the GPUs do not show any load whatsoever during LSTM evaluation.\r\n```\r\n>>> from tensorflow.python.client import device_lib\r\n>>> print(device_lib.list_local_devices())\r\n2021-02-04 11:37:27.094309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 18092632807336689748\r\n]\r\n```\r\nDid the following commands to verify:\r\n```\r\n>>> from tensorflow.python.client import device_lib\r\n>>> print(device_lib.list_local_devices())\r\n```\r\nOutput from nvidia-smi:\r\n\r\n```\r\nThu Feb  4 11:38:59 2021\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 461.09       Driver Version: 461.09       CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN RTX          WDDM  | 00000000:1B:00.0 Off |                  N/A |\r\n| 41%   29C    P8    16W / 280W |    303MiB / 24576MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 107... WDDM  | 00000000:68:00.0  On |                  N/A |\r\n|  0%   38C    P8    10W / 180W |   1720MiB /  8192MiB |      4%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n```", "comments": ["I also tried Theano and it barfed on trying to use version 11 of the nVidia drivers. There is no 'nvrtc64_70.dll' in the installation of version 11. There is an nvrtc.lib in the cuda install directory. Seems like none of the python libraries support version 11 of the nVidia drivers...\r\n\r\n```\r\nC:\\miniconda3\\envs\\gymgpu\\lib\\site-packages\\theano\\gpuarray\\dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\r\n  warnings.warn(\"Your cuDNN version is more recent than \"\r\nERROR (theano.gpuarray): Could not initialize pygpu, support disabled\r\nTraceback (most recent call last):\r\n  File \"C:\\miniconda3\\envs\\gymgpu\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 227, in <module>\r\n    use(config.device)\r\n  File \"C:\\miniconda3\\envs\\gymgpu\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 214, in use\r\n    init_dev(device, preallocate=preallocate)\r\n  File \"C:\\miniconda3\\envs\\gymgpu\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 95, in init_dev\r\n    context = pygpu.init(\r\n  File \"pygpu\\gpuarray.pyx\", line 658, in pygpu.gpuarray.init\r\n  File \"pygpu\\gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init\r\npygpu.gpuarray.GpuArrayException: b'Could not load \"nvrtc64_70.dll\": The specified module could not be found.\\r\\n'\r\n```", "Anaconda seems to think that it only has tensorflow 2.3:\r\n\r\nhttps://anaconda.org/anaconda/tensorflow\r\n\r\nYet, to get nVidia version 11 support we need tensorflow 2.4 ..... where do we get that?", "I was able to finally see the GPUs by specifying tensorflow==2.4.1 in the pip install section of my conda env yaml. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46935\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46935\">No</a>\n"]}, {"number": 46934, "title": "Cannot Install Tensorflow on any version of Python 3.8", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit\r\n- TensorFlow installed from (source or binary): Cannot Install\r\n- TensorFlow version: NaN\r\n- Python version: 3.8, 3.8.7, 3.9, 3.9.1 (All 64-bit)\r\n- Installed using virtualenv? pip? conda?: pip via venv\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nCannot install tensorflow. tried on all the above mentioned python version. Yes it is a 64-bit installation. \r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nTried:\r\npip install tensorflow\r\npip install --upgrade tensorflow\r\npip install --upgrade ALL_URLS_FOR_WINDOWS\r\npy -m ALL_ABOVE_COMMANDS\r\n\r\n", "comments": ["Same issue here.\r\n\r\nI was using [poetry](https://python-poetry.org/) and luckily it gives an error of sorts.\r\nOn WIndows 10 x64, whether you're trying to use the release or nightly version, I recieve this error using Python 3.8.2 and poetry:\r\n\r\n```\r\n  EnvCommandError\r\n\r\n \r\n\r\n  Command C:\\Users\\my_user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recommendation-engine-GCPmYScX-py3.8\\Scripts\\pip.exe install --no-deps file:///C:/Users/my_user/AppData/Local/pypoetry/Cache/artifacts/2f/3c/d9/0fd02d4091668a37d58877876469a9d8989635f2891a38541592711257/tensorflow-2.4.1-cp38-cp38-win_amd64.whl errored with the following return code 1, and output:\r\n\r\n  Processing c:\\users\\my_user\\appdata\\local\\pypoetry\\cache\\artifacts\\2f\\3c\\d9\\0fd02d4091668a37d58877876469a9d8989635f2891a38541592711257\\tensorflow-2.4.1-cp38-cp38-win_amd64.whl\r\n\r\n  Installing collected packages: tensorflow\r\n\r\n  ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\my_user\\\\appdata\\\\local\\\\pypoetry\\\\cache\\\\virtualenvs\\\\recommendation-engine-gcpmyscx-py3.8\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\llvm-project\\\\mlir\\\\_virtual_includes\\\\AffineMemoryOpInterfacesIncGen\\\\mlir\\\\Dialect\\\\Affine\\\\IR\\\\AffineMemoryOpInterfaces.cpp.inc'\r\n\r\n```", "I gave Python 3.8.4 a shot, and tensorflow was installed! I don't know what is going with tensorflow's development. Newb like me can literally leave the field because there is no proper doc to tell as of what to do when such error occurs.", "@kunaldas1997 \r\n\r\nWhich version of Tensorflow you are installing. Please ,see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#tested_build_configurations).Thanks!", "> @kunaldas1997 \n> \n> Which version of Tensorflow you are installing. Please ,see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#tested_build_configurations).Thanks!\n\nLatest 2.4.1", "@kunaldas1997 \r\n\r\nGlad to know it was resolved.Please, close this thread as the issue was resolved.Thanks!", "> @kunaldas1997 \n> \n> Glad to know it was resolved.Please, close this thread as the issue was resolved.Thanks!\n\nAtleast a clear mention on docs will be valuable, so that new people dont have to struggle.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46934\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46934\">No</a>\n", "I faced the same problem with Python  3.8.5\r\nThis works for me:\r\nenable \"long path\" policy using \"gpedit.msc\",  then execute \"pip install --upgrade  tensorflow\"", "See also https://stackoverflow.com/questions/66672519/could-not-install-packages-due-to-an-oserror-errno2-no-such-file-or-directory", "> I faced the same problem with Python 3.8.5 This works for me: enable \"long path\" policy using \"gpedit.msc\", then execute \"pip install --upgrade tensorflow\"\r\n\r\n\r\n\r\n> See also https://stackoverflow.com/questions/66672519/could-not-install-packages-due-to-an-oserror-errno2-no-such-file-or-directory\r\n\r\n1. follow this https://www.howtogeek.com/266621/how-to-make-windows-10-accept-file-paths-over-260-characters/ to enable long path\r\n2. pip install --upgrade tensorflow"]}, {"number": 46933, "title": "Ubuntu 20.10 and 3090 with CUDA 11.0 and cuDNN 8.0: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: 11.0.3/8.0.5.39\r\n- GPU model and memory: GeForce RTX 3090 24GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI just set up a new deep learning station with Ubuntu 20.10 and a GeForce RTX 3090. I am receiving a very large number of warnings in the form of:\r\n\r\n```\r\n2021-02-04 08:52:12.943009: W tensorflow/stream_executor/gpu/asm_compiler.cc:235] Your CUDA software stack is old. We fallback to the NVIDIA driver for some compilation. Update your CUDA version to get the best performance. The ptxas error was: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'\r\n```\r\n\r\nI followed the instructions in:\r\n* https://www.tensorflow.org/install/gpu\r\n* https://www.tensorflow.org/install/source#gpu\r\n(though the instructions are not updated since Ubuntu 18.04)\r\n\r\nTo build a setup with\r\n* Tensorflow 2.4.1\r\n* NVIDIA GPU driver: 460.32.03\r\n* CUDA toolkit: 11.0.3\r\n* cuDNN: 8.0.5.39\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n``` bash \r\nsudo apt -y install build-essential\r\nsudo apt -y install gcc-8 g++-8 gcc-9 g++-9\r\n\r\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 --slave /usr/bin/g++ g++ /usr/bin/g++-8\r\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9 --slave /usr/bin/g++ g++ /usr/bin/g++-9\r\n\r\nsudo update-alternatives --config gcc # select gcc-8 option (1)\r\ngcc --version # to check it is gcc 8\r\n\r\n# Get CUDA Toolkit\r\n# TF 2.4.0 compatibel with cuDNN 8.0 and CUDA 11.0\r\nwget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run\r\nsudo bash cuda_11.0.3_450.51.06_linux.run # Deslect CUDA driver and install\r\n# Add the following to the bashrc file\r\nexport PATH=$PATH:/usr/local/cuda-11.0/bin\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/lib64\r\n\r\n# Get cuDNN package\r\ntar -xvf cudnn-11.0-linux-x64-v8.0.5.39.tgz\r\nsudo cp cuda/include/cudnn.h /usr/local/cuda/include\r\nsudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\r\nsudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\r\nnvcc --version\r\nnvidia-smi\r\npython -c \"import tensorflow as tf; tf.config.list_physical_devices('GPU')\"\r\n```\r\n\r\n", "comments": ["@othrif,\r\nPlease check if TensorFlow is able to detect the GPU on your machine by running the below code\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n```\r\n\r\nAlso, you can suppress the warnings by changing the log level at the start of the program as shown below.  \r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\nimport tensorflow as tf\r\n```\r\n\r\nThanks!", "Thanks @amahendrakar! I am able to run with the GPU, and changing the log level suppressed these warnings.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46933\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46933\">No</a>\n", "Hi @othrif I Have a different problem but as we have similar specs I thought you might help me.\r\n\r\n    Linux Ubuntu 20.10\r\n    TensorFlow version: 2.4.1\r\n    Python version: 3.8.7\r\n    CUDA: 11.0.221\r\n    GPU model and memory: GeForce RTX 3090 24GB\r\n\r\nI am not able to install cudnn. I tried to follow Nvidia documentation for ubuntu 20.04 but it failed. Can you tell me how did you do?\r\n", "Hi @ramram1987, the Nvidia documentation is difficult to follow and a the tensorflow GPU documentation did not work for me. Have you tried the instructions i included above on how i installed tensorflow? \r\n\r\n "]}, {"number": 46932, "title": "[INTEL MKL] Supporting 2 inputs for  Mkl dequantize op", "body": " Mkl dequantize op used to support only 4 inputs. Here, we also need to support 2 inputs since it needs to be used with matmul op in some models.", "comments": []}, {"number": 46931, "title": "MultiWorkerMirroredStrategy() hanging", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n\r\nI have access to two computers and below give the info for both. \r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Computer 1: Windows 10, Computer 2: Windows 10\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.4.1 on both machines\r\n- Python version: 3.8.5 on both machines\r\n- Installed using virtualenv? pip? conda?: For both:  Installed using pip install tensorflow-gpu after manually installing the appropriate Nvidia driver, coda toolkit, cudnn versions.\r\n- CUDA/cuDNN version: CUDA 11.0 and cuDNN 8.0.4. Also both computers have an NVIDIA driver of 450x or higher\r\n- GPU model and memory: Computer 1: NVIDIA Quadro P2000 (GPU memory of 36.8 GB), Computer 2: NVIDIA Quadro P5000 (GPU memory of 79.9 GB)\r\n\r\nNote: the CUDA, cuDNN were installed on each machine manually, I am not using docker.\r\n\r\n**Describe the problem**\r\n\r\nIn case this might be an issue/helps to know, I am on a Mac remoting into my work's computer (Computer 1) using Microsoft Remote Desktop. From Computer 1 (Windows OS), I am remoting into Computer 2 (Windows OS as well) using Remote Desktop Connection (the GUI for RDP -- so not using ssh). Both these computers have a GPU as specified above and want to use them to create a two node distributed training job using tensorflow's distribute.multiworkermirroredstrategy. I believe my issue is that I do not understand if the nodes can communicate with each other.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBelow is my script \"worker.py\"\r\n\r\n```python\r\ndef create_model():\r\n    model = Sequential()\r\n    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(T, D)))\r\n    model.add(TimeDistributed(Dense(1, activation='relu')))\r\n    return model\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    random.set_seed(1)\r\n\r\n    parser = argparse.ArgumentParser()\r\n\r\n    # inputs for setting environment variable\r\n    parser.add_argument('-node1', default=None, required=True, help='Node 1 IP and port')\r\n    parser.add_argument('-node2', default=None, required=True, help='Node 2 IP and port')\r\n    parser.add_argument('-type', default=None, required=True, help='Node type')\r\n    parser.add_argument('-index', default=None, required=True, help='Node number', type=int)\r\n\r\n    args = parser.parse_args()\r\n    node_1 = args.node1\r\n    node_2 = args.node2\r\n    worker_type = args.type\r\n    worker_index = args.index\r\n\r\n    # set environment variable\r\n    os.environ['TF_CONFIG'] = json.dumps({\r\n        'cluster': {\r\n            \"worker\": [node_1, node_2]\r\n        },\r\n        'task': {'type': worker_type, 'index': worker_index}\r\n    })\r\n\r\n    # load data\r\n    with open('data/X.json', 'rb') as f:\r\n        X = pickle.load(f)\r\n\r\n    with open('data/y.json', 'rb') as f:\r\n        y = pickle.load(f)\r\n\r\n    # split data, set random state (for replicability)\r\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\r\n    _, T, D = X_train.shape\r\n\r\n    # dynamic memory allocation\r\n    # gpu = config.experimental.list_physical_devices('GPU')\r\n    # config.experimental.set_memory_growth(gpu[0], True)\r\n\r\n    # set training strategy\r\n    strategy = distribute.MultiWorkerMirroredStrategy( )\r\n    print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\r\n\r\n    num_epochs = 10000\r\n    batch_size_per_replica = 64\r\n    batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\r\n\r\n    # create data structure\r\n    train_data = data.Dataset.from_tensor_slices((X_train, y_train))\r\n    val_data = data.Dataset.from_tensor_slices((X_test, y_test))\r\n\r\n    train_data = train_data.batch(batch_size, drop_remainder=True)\r\n    val_data = val_data.batch(batch_size, drop_remainder=True)\r\n\r\n    # Disable AutoShard.\r\n    # options = data.Options()\r\n    # options.experimental_distribute.auto_shard_policy = data.experimental.AutoShardPolicy.OFF\r\n    # train_data = train_data.with_options(options)\r\n    # val_data = val_data.with_options(options)\r\n\r\n    with strategy.scope():\r\n        model = create_model()\r\n        model.compile(\r\n            loss='mse',\r\n            optimizer='adam',\r\n            metrics=[metrics.RootMeanSquaredError()],\r\n        )\r\n\r\n    # fit\r\n    model.fit(\r\n        train_data,\r\n        epochs=num_epochs,\r\n        validation_data=val_data,\r\n        # callbacks=[cp_callback, es_callback, tbd_callback]\r\n    )\r\n\r\n    # save\r\n    # model.save('model/model.h5')\r\n```\r\n\r\nFrom the documentation, I understand that this script has to be run on all machines (in my case 2) and set the TF_CONFIG environment variable correctly on both machines. And so I am doing:\r\n\r\nCommand line machine 1: python worker.py -node1 172.31.15.60:8081 -node2 172.31.15.132:8081 -type worker -index 0\r\n \r\nCommand line machine 2:  python worker.py -node1 172.31.15.60:8081 -node2 172.31.15.132:8081 -type worker -index 1\r\n\r\nOnce I run the above command I see the following on machine 1:\r\n\r\n```\r\n2021-02-04 10:24:32.161847: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-04 10:24:32.171344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-02-04 10:24:32.206509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s\r\n2021-02-04 10:24:32.213804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-04 10:24:32.233653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-04 10:24:32.237158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-02-04 10:24:32.247535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-02-04 10:24:32.254801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-02-04 10:24:32.270340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-02-04 10:24:32.278635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-02-04 10:24:32.284876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-04 10:24:32.288053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-04 10:24:32.291911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-02-04 10:24:32.300368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s\r\n2021-02-04 10:24:32.305947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-04 10:24:32.309708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-04 10:24:32.312512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-02-04 10:24:32.315162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-02-04 10:24:32.317685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-02-04 10:24:32.320235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-02-04 10:24:32.323467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-02-04 10:24:32.326515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-04 10:24:32.329607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-04 10:24:32.868210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-02-04 10:24:32.871587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-02-04 10:24:32.873963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-02-04 10:24:32.876398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3835 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\n2021-02-04 10:24:32.883411: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-04 10:24:32.889654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s\r\n2021-02-04 10:24:32.896221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-04 10:24:32.900555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-04 10:24:32.903795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-02-04 10:24:32.906767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-02-04 10:24:32.909681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-02-04 10:24:32.912606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-02-04 10:24:32.916783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-02-04 10:24:32.920150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-04 10:24:32.923249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-04 10:24:32.925742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-02-04 10:24:32.928836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-02-04 10:24:32.932095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-02-04 10:24:32.934222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 3835 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\n2021-02-04 10:24:32.939752: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-04 10:24:32.948503: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 ->  172.31.15.60:8081, 1 -> 172.31.15.132:8081}\r\n2021-02-04 10:24:32.953737: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://172.31.15.60:8081\r\n```\r\n\r\nAnd see the same similar things on machine 2, essentially hanging at \"Started server with target: grpc://172.31.15.132:8081.\"\r\n\r\nI am not sure what the issue could be? Could it be related to the ports, I chose 8081? Is it installation-wise? I have tried many things suggested on GitHub and none seem to work. Could firewalls, very secure networks be causing this issue?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nPer one of the GitHub issues I added the environment variable GRPC_VERBOSITY=DEBUG on machine 1 and got back from the command line \r\nD0204 10:40:31.617000000  8780 external/com_github_grpc_grpc/src/core/ext/filters/client_channel/resolver/dns/native/dns_resolver.cc:314] Using native dns resolver\r\nI0204 10:40:31.624000000  8780 external/com_github_grpc_grpc/src/cpp/server/server_builder.cc:332] Synchronous server. Num CQs: 1, Min pollers: 1, Max Pollers: 2, CQ timeout (msec): 10000\r\n\r\n", "comments": ["Googling I found \"Make sure the nodes can ssh into each other without the request of the password. The most convenient way to do this is to use ssh keys instead of password authentication.\" Could this be the issue? I am new to setting up multi-node training jobs and was hoping to use tensorflow's API but maybe for the setup I have it might not be ideal? ", "Hi @inespancorbo, I don't see anything immediately suspect in your code. Have you tried explicitly setting the autoshardpolicy to DATA? And can you also confirm that you're able to run the code on a single machine? You can use MultiWorkerMirroredStrategy on a single machine (just don't pass in both IP/ports in the TF Config).", "Hi @nikitamaia I will try both suggestions and see what happens (I believe I have tried setting autoshardpolicy to DATA but will try again). However, could the ssh-ing be an additional issue? As in, I am using RDP for remoting into the different machines and I do not believe ssh is set up.\r\n\r\nTo confirm, running MultiWorkerMirroredStrategy on a single machine would imply commenting out/not using TF_CONFIG?", "[log.log](https://github.com/tensorflow/tensorflow/files/5935716/log.log)\r\n\r\nI ran the same python script on both machines. One works fine and the other one get an error after some iterations of the first epoch. I have attached the log file.\r\n\r\n", "Ah okay, seems we're closer to identifying the problem! Please take a look at this similar issue here #45987. Before trying to get multi worker mirrored strategy working, we should confirm that your GPU(s) are working.", "Thanks @nikitamaia! I updated to the Nvidia driver suggested in the post and running multiworkerstrategy() on each machine individually works fine. When I do it jointly (setting the TF_CONFIG environment variable) it is able to train for a couple epochs until it raises the following error. I am attaching the command output from both machines in the form of a log file.\r\n[log.log](https://github.com/tensorflow/tensorflow/files/5947392/log.log)\r\n[log.log](https://github.com/tensorflow/tensorflow/files/5947393/log.log)\r\n\r\n", "I set the autoshardpolicy to DATA as well as GPU memory growth and now I get the following errors. See the log files of both machines.\r\n\r\n[log.log](https://github.com/tensorflow/tensorflow/files/5954404/log.log)\r\n[log.log](https://github.com/tensorflow/tensorflow/files/5954405/log.log)\r\n\r\nGiven that both my GPUs are different, could this be the issue?\r\n ", "[log.log](https://github.com/tensorflow/tensorflow/files/5962017/log.log)\r\n[log.log](https://github.com/tensorflow/tensorflow/files/5962021/log.log)\r\n\r\nUpdate: see these log files as opposed the ones above.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46931\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46931\">No</a>\n", "Hi @inespancorbo did you mean to close this issue? From the logs it seems it runs for 352 epochs and then crashes. Did you find a solution?"]}, {"number": 46930, "title": "Subgraph search & replace (graph surgery)", "body": "TensorFlow version (you are using): 2.4\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI would like to be able to do subgraph search & replace of models, basically to replace some block of operators by others automatically.\r\nCurrently there is no way to iterate over the graph with a standard graph traversal, making it hard/impossible to perform automatic subgraph search & replace.\r\n\r\n**Will this change the current api? How?**\r\nNot necessarily, Pytorch is developping torch.fx for doing something similar (in 1.8 alpha)\r\n\r\n**Who will benefit with this feature?**\r\nBusinesses wanting to write custom framework on top of tensorflow for automatic model modifications taylored to their needs.\r\n\r\n**Any Other info.**\r\n", "comments": ["I think Grappler already does this.", "It does replace blocks, but I can't use it to replace what blocks I want.\r\nBy blocks, I mean a block ranges from a single operator to a full feature extractor.\r\nGrappler seems to be a tool to do optimization for you, not exactly what I am looking for.", "I think it is better to make a RFC at https://github.com/tensorflow/community/", "The API owners are moving to a rotation based system and assigning several owners to follow along and comment. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing in light of request for RFC: https://github.com/tensorflow/tensorflow/issues/46930#issuecomment-776104414"]}, {"number": 46928, "title": "Cannot run LSTM in tensorflow lite 1.15 ", "body": "Hello.\r\n\r\n**TLDR**: Can someone show how to create LSTM, convert it to TFLite, and run it in android version 1.15?\r\n\r\nI am trying to create a simple LSTM model and run in in android application with tensorflow v115.\r\n\r\n** It is the same case when using GRU and SimpleRNN layers **\r\n\r\n# Creating simple LSTM model\r\nI am working in Python, trying two tensorflow and keras versions: LATEST (2.4.1 with built-in keras), and 1.1.5 (and I install keras version 2.2.4). \r\n\r\nI create this simple model:\r\n```python\r\nmodel = keras.Sequential()\r\nmodel.add(layers.Embedding(input_dim=1000, output_dim=64))\r\nmodel.add(layers.LSTM(128))\r\nmodel.add(layers.Dense(10))\r\nmodel.summary()\r\n```\r\n\r\n# Saving it \r\nI save it in both \"SavedModel\" and \"h5\" format:\r\n```python\r\nmodel.save(f'output_models/simple_lstm_saved_model_format_{tf.__version__}', save_format='tf')\r\nmodel.save(f'output_models/simple_lstm_{tf.__version__}.h5', save_format='h5')\r\n```\r\n\r\n# Converting to TFLite\r\nI try create & save the model in both v115 and v2 versions. \r\n\r\nThen, I try to convert it to TFLite in several methods.\r\n\r\nIn TF2: \r\n1. I try to convert from keras model:\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nwith open(f\"output_models/simple_lstm_tf_v{tf.__version__}.tflite\", 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n2. I try to convert from saved model:\r\n```python\r\nconverter_saved_model = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\r\ntflite_model_from_saved_model = converter_saved_model.convert()\r\nwith open(f\"{saved_model_path}_converted_tf_v{tf.__version__}.tflite\", 'wb') as f:\r\n    f.write(tflite_model_from_saved_model)\r\n```\r\n\r\n3. I try to convert from keras saved model (h5) - I try to use **both** tf.compat.v1.lite.TFLiteConverter and tf..lite.TFLiteConverter. \r\n```python\r\nconverter_h5 = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(h5_model_path)\r\n# converter_h5 = tf.lite.TFLiteConverter.from_keras_model_file(h5_model_path) # option 2\r\ntflite_model_from_h5 = converter_h5.convert()\r\nwith open(f{h5_model_path.replace('.h5','')}_converted_tf_v1_lite_from_keras_model_file_v{tf.__version__}.tflite\", 'wb') as f:\r\nf.write(tflite_model_from_h5)\r\n```\r\n\r\n# Android Application\r\n### build.gradle (Module: app)\r\nWhen I want to use v2, I use:\r\n```\r\n    implementation 'org.tensorflow:tensorflow-lite-task-vision:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-task-text:0.0.0-nightly'\r\n```\r\nWhen I want to use v115, I use `implementation 'org.tensorflow:tensorflow-lite:1.15.0'`\r\nin the build grade. \r\n\r\nThen, I follow common tflite loading code in android:\r\n\r\n```java\r\nprivate MappedByteBuffer loadModelFile(Activity activity) throws IOException {\r\n\r\n        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(getModelPath());\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n    }\r\n\r\n    LoadLSTM(Activity activity) {\r\n        try {\r\n            tfliteModel = loadModelFile(activity);\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n        tflite = new Interpreter(tfliteModel, tfliteOptions);\r\n        Log.d(TAG, \"*** Loaded model *** \" + getModelPath());\r\n    }\r\n```\r\n\r\nWhen I use v2, the model is loaded.\r\nWhen I use the v115, in ALL of the options i've tried, I receive errors as the following:\r\n`A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x70 in tid 17686 (CameraBackgroun), pid 17643 (flitecamerademo)\r\n`\r\n\r\nI need a simple outcome - create LSTM and make it work in android v115. \r\n\r\nWhat am I missing? Thanks", "comments": ["@yonatanbitton \r\nCurrently there is no support on tf 1.x, there is support only for 2.x, if you face any issues with 2.x let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46928\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46928\">No</a>\n"]}, {"number": 46927, "title": "PPO implementation does not converge", "body": "I'm not sure whether the problem is implementation / tensorflow specific. Following this [repo](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail) as a reference, I re-implemented the same thing over and over for like 5 times in different ways. Every single time, I end up with the same results, despite the code is almost identical to the pytorch implementation. Here's a colab [notebook](https://colab.research.google.com/drive/1rvCYd9xJDQNAutpAHUBYc42ElHCXWNNd?usp=sharing) containing the full code. If anyone can help me fix the issue, I'd really be very grateful. \r\n", "comments": ["@emadboctorx \r\n\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "I know, thanks anyway and I did ask on SO already."]}, {"number": 46926, "title": "Output range changes when converted to TFLite", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): Pip package\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): TF 1.14\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n#### Code A: Tensorflow to TFLite conversion\r\n\r\n\r\n```\r\ndef save(self):\r\n        \r\n        graph = tf.get_default_graph()\r\n        with graph.as_default():\r\n        if self.quant == True:\r\n           tf.contrib.quantize.create_eval_graph()\r\n\r\n        out_def = graph.as_graph_def()\r\n        with tf.gfile.GFile(self.out_graph, 'wb') as f:\r\n            f.write(out_def.SerializeToString())\r\n\r\ndef freeze(self):\r\n        checkpoint = os.path.join(self.checkpoint_dir, 'Model%d' % self.trial)\r\n        ckpt= tf.train.get_checkpoint_state(checkpoint)\r\n        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\r\n        ckpt_path = os.path.join(checkpoint, ckpt_name)\r\n\r\n        self.out_name = 'output'\r\n        freeze_graph.freeze_graph(self.out_graph,'',True,ckpt_path, self.out_name, restore_op_name='save/restore_all', filename_tensor_name='save/Const:0' , initializer_nodes='', output_graph= self.fr_graph ,clear_devices=True)\r\n\r\n\r\ndef convert(self):\r\n        print(self.fr_graph)\r\n        converter= tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file= self.fr_graph, input_arrays= ['input'],\\\r\n                                                  input_shapes= {'input': self.input_shape}, output_arrays=[self.out_name])\r\n        \r\n        if self.quant == True:\r\n            in_array = converter.get_input_arrays()\r\n            converter.quantized_input_stats = {in_array[0] : (0, 1)}  # mean, std_dev (input range is [-1, 1])\r\n\r\n            converter.inference_type = tf.uint8\r\n\r\n            tflite_model = converter.convert()\r\n            print('Save the model.')\r\n\r\n            with open('int_qat_%d.tflite'%self.trial, 'wb') as f:\r\n                f.write(tflite_model)\r\n\r\n```\r\n\r\n#### Option B:  TFLite inference code\r\n\r\n```\r\ndef run_tflite(modelpath, labelpath, datapath, trial, height, weight):\r\n\r\n    interpreter = tf.lite.Interpreter(model_path=modelpath)\r\n    interpreter.allocate_tensors()\r\n\r\n    # Get input and output tensors.\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n\r\n    # Test the model on random input data.\r\n\r\n    in_s = input_details[0]['shape']\r\n\r\n    num = len(label_list)\r\n    tf_img, label, num = load_and_slice_img(img_list,label_list, num, height, weight)\r\n    output_data= []\r\n    for i in range(num):\r\n        input_= tf_img[i].reshape((1, height//2, weight//2, 3))\r\n\r\n        interpreter.set_tensor(input_details[0]['index'], input_)\r\n        interpreter.invoke()\r\n\r\n        out_data = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n        output_data.append(out_data)\r\n    output_data = np.array(output_data).reshape((num, height, weight, 3))\r\n\r\n```\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nI am trying to quantize a SR model (EDSR), using Quantization Aware Training.\r\n\r\nI am using same codes used in Jacob et al. (2017) to perform quantization (create_training_graph etc)\r\n\r\nFake Quantization (Stimulated) works rather well, but when I convert them using TFLiteconverter (from freeze_model), the result becomes very poor (PSNR below that of bicubic interpolation)\r\n\r\nWhen I draw histogram with the output and HR image, the range of image has decreased about 20% (e.g 0-200 to 25-180). Histogram structure seems to be identical.\r\n\r\n\r\nI tried to cross-check this using a simple model for MNIST, and found out following things\r\n- Almost zero performance change when converted to TFLite file, both with QAT and Post Integer Quantization\r\n- Output, before applying softmax function, changes dramatically between TFLite and Float (real float and fake/stimulated quantization one) models.\r\n\r\n\r\nI used images in raw form, without normalizing to [0,1] to train the floating point models. When converting the float model, I used exact codes written in relevant document in tf==1.14 github. I also used same codes for inference in TFLite\r\n\r\nI would like to reproduce the issue, but since it requires a lot of computation to train SR model, I did not upload the file initially. If required though, I will try to upload snippets of MNIST code (+ conversion code) that I have used to produce this error\r\n**Update - I have uploaded some codes and pb/tflite file of the models I produced**\r\n\r\nWhen I had a look into each nodes, the only difference between tflite and QAT(float) was a small change in min/max values for 'act_quant' stage, when activation function is not applied.\r\n\r\n\r\nWhat might be the possible cause of this error (happens in both classification and SR model)? One easy thought is that the input image might have slightly changed after converting the format into float32 (from uint8) for inference in floating model.\r\nAlso, I think it might be the case that random bias has been added.\r\n\r\n![KakaoTalk_20210204_233632390](https://user-images.githubusercontent.com/29692100/106907712-e8ba7100-6741-11eb-94b4-3ad0aff0ab5d.jpg)\r\n\r\nTop Image- TFLite model after quantization (QAT)\r\nBottom Image - HR image\r\n\r\n\r\n![KakaoTalk_20210204_233632390_01](https://user-images.githubusercontent.com/29692100/106907721-eb1ccb00-6741-11eb-8717-b1e5a1041913.jpg)\r\n\r\nHistogram of above image for TFLite model after QAT\r\n\r\n\r\n![KakaoTalk_20210204_233632390_02](https://user-images.githubusercontent.com/29692100/106907723-ebb56180-6741-11eb-864d-f2d46f27c66e.jpg)\r\n\r\n\r\nHistogram of same image for floating point model\r\n\r\n\r\nIt is ok if there is no exact solution, but I would like to know possible cause of this phenomenon, so that I can try to debug it.\r\n\r\n\r\n* I used non keras layers to create the model, and also manually recreated depth_to_space layer of EDSR, as it was not supported in the version of TFLite converter I used.\r\n\r\n\r\n[Graphs.zip](https://github.com/tensorflow/tensorflow/files/5929670/Graphs.zip)\r\nfrozen graph (fake quant)  and corresponding tflite file (qat)\r\n", "comments": ["It might be similar issue to this one, as result between vanilla and Fake Quant model is not very different in my case as well, and also, output of the model (although this is not an output from one Conv2d op) changes when converted to TFLite.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/38845\r\n\r\nJust for the information, the Post Integer Quantization using TFLite version for TF 1.14 resulted with even worse result than that of QAT", "@KevSr,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I will try with newer version of Tensorflow at later times, but I need to use v1.14 for this model.\r\n\r\nThank you for the help anyways", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46926\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46926\">No</a>\n"]}, {"number": 46925, "title": "TF.js Error: TensorList shape mismatch:  Shapes -1 and 3 must match", "body": "I'm currently trying to convert to TF.js one of the Object Detection models from the TF2 OD ZOO, in particular SSD MobileNet V2 FPNLite 320x320.\r\n\r\nWhen I convert the model pre-existing SavedModel from the saved_model folder I'm able to import it in my browser and launch it through executeAsync(). If I keep the original pipeline.config and try to create another SavedModel from the provided checkpoint using this line\r\n\r\n```\r\npython exporter_main_v2.py --input_type image_tensor \\\r\n    --pipeline_config_path ./pre-trained-models/ssd320/pipeline.config \\\r\n    --trained_checkpoint_dir ./pre-trained-models/ssd320/checkpoint_0 \\\r\n    --output_directory ./pre-trained-models/ssd320/exported_model\r\n```\r\n\r\nafter I convert it to TF.js with the following line\r\n\r\n```\r\ntensorflowjs_converter \\\r\n    --input_format=tf_saved_model \\\r\n    --saved_model_tags=serve \\\r\n    ./pre-trained-models/ssd320/path-to-savedmodel-folder \\\r\n    ./pre-trained-models/tfjs_test\r\n```\r\n\r\nI encounter the following error when I try to launch the inference on my browser\r\n\r\n```\r\nutil_base.js?a6b2:141 Uncaught (in promise) Error: TensorList shape mismatch:  Shapes -1 and 3 must match\r\n    at Module.assert (util_base.js?a6b2:141)\r\n    at assertShapesMatchAllowUndefinedSize (tensor_utils.js?74aa:24)\r\n    at TensorList.setItem (tensor_list.js?41f7:182)\r\n    at Module.executeOp (control_executor.js?de9e:188)\r\n    at eval (operation_executor.js?be85:52)\r\n    at executeOp (operation_executor.js?be85:94)\r\n    at GraphExecutor.processStack (graph_executor.js?33ef:390)\r\n    at GraphExecutor.executeWithControlFlow (graph_executor.js?33ef:350)\r\n    at async GraphExecutor._executeAsync (graph_executor.js?33ef:285)\r\n    at async GraphModel.executeAsync (graph_model.js?9724:316)\r\n```\r\n\r\nI'm currently working in Colab with the standard modules (TF 2.4.1, Python 3.6.9 and tensorflowjs 3.0.0) and didn't manage to find infos on similiar issues elsewhere.\r\n\r\nI tried with SSD MobileNet v2 320x320 (no FPN here) and the outcome is the same. I'm starting to think that it may be connected to the use of exporter_main_v2.py but I wouldn't know how to convert the model without it.\r\n\r\nCould you please help me figure out something more about the cause of this issue?", "comments": ["@VernengoSimone \r\nCould you please open this issue in tfjs repo and move this to closed status.", "Thank you. Done."]}, {"number": 46924, "title": "RuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 3 (TensorArrayV3) failed to prepare.", "body": "I'm not so professional in python! I'm trying to convert frozen graph to tflite file in colab to start inference it using jetson nano. I get this error! \r\n\r\nconverter.allow_custom_ops = True\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_model = converter.convert()\r\nopen('tflite_file', 'wb').write(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()", "comments": ["@najme22 \r\n\r\nCan you please fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi,\r\n\r\nSeems you need to convert your model with select TF ops https://www.tensorflow.org/lite/guide/ops_select", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46922, "title": "[quantization] Post-training quantization using TFLiteConverter isn't working in TF 2.3", "body": "Hello there :wave: \r\n\r\n**System information**\r\n- Have I written custom code: not one bit\r\n- OS Platform and Distribution: Linux, Ubuntu 20.04\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.5\r\n- GPU model and memory: GeForce RTX 2070 Max Q, 8Gb RAM\r\n\r\n\r\n**Describe the current behavior**\r\nThere seems to be an issue in TF 2.3, where post-training quantization does not seem to actually work: quantized version are no smaller than fp16 counterpart using the conversion tutorial from the documentation (post-training). This seems to have been fixed in tf2.4 but I din't see any related issue or mention of a fix (I may have missed a few things :sweat_smile: ).\r\n\r\n**Describe the expected behavior**\r\nUsing the same TFLite converter, the bare TFLite model should be strictly bigger than its FP16 counterpart, which in turn should be strictly bigger than its int8 counterpart.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe following code raises an error in TF2.3.1 but no longer in TF 2.4.* :\r\n```\r\nimport sys\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers, Sequential\r\n\r\n_layers = [\r\n    layers.Conv2D(8, 3, activation='relu', padding='same', input_shape=(224, 224, 3)),\r\n    layers.GlobalAveragePooling2D(),\r\n    layers.Flatten(),\r\n    layers.Dense(10),\r\n]\r\nmock_model = Sequential(_layers)\r\n\r\ndef convert_to_fp16(tf_model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\r\n\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_spec.supported_types = [tf.float16]\r\n    return converter.convert()\r\n\r\n\r\ndef quantize_model(tf_model, input_shape):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\r\n\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\n    # Float fallback for operators that do not have an integer implementation\r\n    def representative_dataset():\r\n        for _ in range(100):\r\n            data = np.random.rand(1, *input_shape)\r\n            yield [data.astype(np.float32)]\r\n\r\n    converter.representative_dataset = representative_dataset\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.inference_input_type = tf.int8\r\n    converter.inference_output_type = tf.int8\r\n\r\n    return converter.convert()\r\n\r\n\r\nassert sys.getsizeof(convert_to_fp16(mock_model)) > sys.getsizeof(quantize_model(mock_model, (224, 224, 3)))\r\n```\r\n\r\n**Other info / logs** No error is actually thrown during the execution, but the behaviour is not as expected. The same test is passing between a bare tflite conversion (in fp32), and fp16 conversion, but fails between fp16 and int8.\r\n", "comments": ["Hi @frgfm, it's possbile that the changelog missed misc. bug fixes. Also, afaik it's not likely for bug fixes to be applied to previous releases. Are you looking for bug fixes without upgrading TF version?", "Well, I understand the release process so: no, not really. But since I didn't see it mentioned anywhere, I was afraid it was not on purpose, or worse: that it's still not working.\r\n\r\nAnyway, the issue here is that for projects having flexible dependencies on the TF side would experience silent issues here. I think this should be highlighted in the documentation or as a warning somewhere :man_shrugging: ", "@teijeong so what do you suggest? Opening a PR to edit the documentation?\r\nSince this isn't assigned to anyone anymore, either you decide that this should not be worked on and we close the issue, or we do something about it. I just wouldn't like to grow the pile of unhandled issues on the project :pray: ", "Any update @teijeong ? :pray: ", "Hi, I have the same issue, this is my system information:\r\n\r\n  OS Platform and Distribution: Linux, Ubuntu 18.04\r\n  TensorFlow installed from: pip\r\n  TensorFlow version: 2.3.1\r\n  Python version: 3.7\r\n  CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5\r\n  GPU model and memory: GeForce RTX 2080 Ti\r\n", "@frgfm I tried to run the code in colab with TF 2.6.0-dev20210603 and didn't face any issue,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/c4591ed6d13af508ced2d17f5ea856ed/untitled157.ipynb?authuser=1#scrollTo=L51E5SZFhQug)..Thanks !", "Hi @sushreebarsa,\r\n\r\nWhat do you mean? Did you have issues with TF nightly? Because, as mentioned earlier, this issue is about TF < 2.4. Starting from TF 2.4, I didn't experience any issue.", "@frgfm I also didn't experience any issue in TF-nightly,provided gist is only for reference..Thanks !", "So @teijeong, should we consider that TF 2.3 is too far back and close this?\r\nIt's not really helping to leave issues open like this :/", "@frgfm Generally we don't patch it back to an old version unless there is any security related patches. I am closing this issue as this was resolved in recent TF versions.\r\n\r\nFeel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46922\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46922\">No</a>\n"]}, {"number": 46921, "title": "MeanIoU not ignoring background", "body": "According to https://en.wikipedia.org/wiki/Jaccard_index and the MeanIoU documentation : https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/metrics.py#L2722-L2850\r\nThe IoU score is TP / (TP+FP+FN)\r\n\r\nHowever the MeanIoU seems to calculate this per class not ignoring the background class.\r\nMinimum working example.\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nm = tf.keras.metrics.MeanIoU(num_classes=2)\r\nm.update_state([0, 0, 1, 1, 1], [0, 1, 0, 1, 1])\r\n\r\ntp = m.total_cm[1,1]\r\ntn = m.total_cm[0,0]\r\nfn = m.total_cm[1,0]\r\nfp = m.total_cm[0,1]\r\n\r\nprint(m.total_cm)\r\nprint(m.result())\r\nprint(tp/(tp+fp+fn))\r\n```\r\nWhere tensorflow calculates the IoU to be (0.5 + 0.3333) / 2, however to my understanding the correct answer should be 0.5.\r\n\r\nIs there a way to get the IoU scores mean for Classes that are not background? (Ignoring cm[0,0] in true positives)\r\n\r\nBest regards", "comments": ["I have tried in colab with TF version 2.4, nightly version (`2.5.0-dev20210204`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/e0a078b207fc59e59f83e073dd488435/untitled659.ipynb). Thanks!", "Note that `tf.keras.metrics.MeanIoU` computes IoUs for all individual classes and then returns the mean of these values, which is why you are seeing the difference in result from manual computation vs `tf.keras.metrics.MeanIoU`.\r\nRefer this [gist](https://colab.research.google.com/gist/sachinprasadhs/cd107230793b43c349646b5f7c47f03d/46921.ipynb) which calculates the individual IoU and then does the average.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46921\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46921\">No</a>\n"]}, {"number": 46920, "title": "tf.abs() crashes when dtype=float32", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 20H2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): using pip inside conda\r\n- TensorFlow version (use command below): 2.5.0-dev20210203\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.0 / 8\r\n- GPU model and memory: RTX 1070 8GB\r\n\r\n**Describe the current behavior**\r\ntf.abs() works fine when provided with integer values but crashes when dtype=float32.\r\nIf run in Jupyter the cell will hang and never execute. If run in Anaconda prompt python will crash and kick you back out to conda.\r\n\r\n**Describe the expected behavior**\r\nReturn absolute value\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nx = tf.constant([-2.25, 3.25])\r\ntf.abs(x)\r\n```\r\n", "comments": ["@jessyprociv,\r\nI was able to run the code without any issues on [TF v2.4](https://colab.research.google.com/gist/amahendrakar/6814282816d3d7430ba9bb6714c8b49b/46920.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a1e2e3ec2fc182e9e1af317e1a628d3f/46920-tf-nightly.ipynb). Please check the linked gist for reference. \r\n\r\nCould you please run the code in new virtual environment and check if you are facing the same issue? Thanks!", "Hi @amahendrakar \r\n\r\nI created a new environment and am unfortunately still having the same issue. Of course it might still just be an issue with my computer so am happy for this issue to be closed if it doesn't seem like a legitimate bug.\r\n\r\nNew environment created using the following commands in conda:\r\n```\r\nconda create -n new-tf python=3.8\r\nconda activate new-tf\r\npip install tf-nightly-gpu==2.5.0.dev20210203\r\nconda install cudatoolkit=11.0\r\n```\r\n\r\nThen inside python once again running:\r\n```\r\nimport tensorflow as tf\r\ntf.__version__ #returns '2.5.0-dev20210203'\r\nx = tf.constant([-2.25, 3.25])\r\ntf.abs(x)\r\n```\r\n\r\nAttached screenshot shows a big spike in cuda and GPU memory usage while running tf.abs(x) before python crashes.\r\n![Capture3](https://user-images.githubusercontent.com/53418753/106899490-882f3200-6749-11eb-9fbf-36ec285ea768.PNG)\r\n\r\nAppreciate any further advice if you have it, but perfectly happy to accept that this may be my own problem!", "After running into some other issues today I've been able to identify and solve my problem by downgrading to tensorflow 2.4 as per:\r\n\r\nhttps://medium.com/analytics-vidhya/using-tensorflow-on-windows-10-with-nvidia-rtx-3000-series-gpus-637ab2a4b163\r\n\r\nhttps://medium.com/@JeansPantRushi/fix-for-tensorflow-v2-failed-to-get-convolution-algorithm-b367a088b56e\r\n\r\nThank you again for your help and sorry to have raised a false bug report!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46920\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46920\">No</a>\n"]}, {"number": 46919, "title": "In tf.keras, can i use model(x).numpy() with disable_eager_execution()?", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\n- Python version: 3.7\r\n- TensorFlow version (use command below):2.2\r\n\r\n**Describe the current behavior**\r\nAs is known to us, for predicting, there are two options to use the model. I can call `model.predict(x)` or I can call `model(x).numpy()`. `model(x)` is faster than `model.predict(x)`  for small amount of inputs in eager mode. Since i want to  deploy the model in production environment\uff0ci should disable the eager mode with `tf.compat.v1.disable_eager_execution()`.For better performance\uff0ci want to use `model(x).numpy()` to predict instead of  `model.predict(x)` for small amount of inputs ,but i found that i can't convert tensor to numpy with  `tf.compat.v1.disable_eager_execution()`\r\n**Describe the expected behavior**\r\nis there any solutions to use `model(x).numpy()` with `tf.compat.v1.disable_eager_execution()` for faster prediction", "comments": ["You shouldn't use disable_eager_execution() in the first place.\r\n\r\n1. model(x) is faster for single example inference, whereas model.predict(x) is better for bulk/batch example inference.\r\n2. model(x).numpy() is only working in eager mode. numpy() is a method for eager tensor, which is not available when eager execution is disabled.\r\n3. the performance between eager mode and graph mode should be similar, and please report performance issue if you see any."]}, {"number": 46918, "title": "Model is working fine in CPU but in GPU it consumes all RAM. ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code:- Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: Tesla K4, RAM=15GB\r\n\r\n\r\n**Current behavior**\r\nI am trying to run face identification using the face_identification library based on dlib and object detection using the mobilenet_ssd model. Both of them combined working fine in CPU on local machine and on AWS CPU but when we use GPU, RAM is used completely. The issue is with the object detection model. Before loading the model it uses 300MB RAM, but when it loads the pre-trained model, RAM is suddenly jumped to 15GB. Both models are working fine in the CPU. \r\n\r\n**Expected behavior**\r\nIt should run on GPU without RAM overflow.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info/logs** \r\nTraceback (most recent call last):\r\n  File \"StreamingService.py\", line 252, in <module>\r\n    streamingService.start()\r\n  File \"StreamingService.py\", line 104, in start\r\n    verification_service.verify(studentExamId, studentId, verificationCode)\r\n  File \"/home/ubuntu/screening-service-test/screening-service/computerVision/VerificationService.py\", line 84, in verify\r\n    studentFaceEncoding  = self.getFaceEncoding(studentPicDict[key])\r\n  File \"/home/ubuntu/screening-service-test/screening-service/computerVision/VerificationService.py\", line 20, in getFaceEncoding\r\n    face_locations = face_recognition.face_locations(rgb_small_frame, model = \"cnn\")\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/face_recognition/api.py\", line 119, in face_locations\r\n    return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, \"cnn\")]\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/face_recognition/api.py\", line 103, in _raw_face_locations\r\n    return cnn_face_detector(img, number_of_times_to_upsample)\r\nRuntimeError: Error while calling cudnnFindConvolutionForwardAlgorithm( context(), descriptor(data), (const cudnnFilterDescriptor_t)filter_handle, (const cudnnConvolutionDescriptor_t)conv_handle, descriptor(dest_desc), num_possible_algorithms, &num_algorithms, perf_results.data()) in file /home/ubuntu/dlib/dlib/cuda/cudnn_dlibapi.cpp:820. code: 2, reason: CUDA Resources could not be allocated.\r\n", "comments": ["@Engineer1999 \r\n \r\nCan you please share complete code and error log.It helps us in debugging further.\r\nTry to limit GPU memory using this [link](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and see if it helps you.Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46918\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46918\">No</a>\n"]}, {"number": 46917, "title": "TypeError: can't pickle _thread.RLock objects when using multiprocessing", "body": "Information:\r\n\r\n```\r\nTensorflow version 2.1.0\r\nPython 3.7\r\n```\r\nThe minimal example to reproduce the error:\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\n\r\nfrom multiprocessing import Pool\r\nfrom multiprocessing.dummy import Pool as ThreadPool\r\nfrom functools import partial\r\n\r\ndef simple_model():\r\n    model = keras.models.Sequential([\r\n        keras.layers.Dense(units = 10, input_shape = [1]),\r\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\r\n    ])\r\n    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\r\n    return model\r\n\r\ndef clone_model(model):\r\n    model_clone = tf.keras.models.clone_model(model)\r\n    model_clone.set_weights(model.get_weights())\r\n    return model_clone\r\n\r\ndef work(model, seq):\r\n    return model.predict(seq)\r\n    \r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,100).reshape(n, -1)\r\n    pool = Pool()\r\n    # model_list = [clone_model(model) for _ in range(n)]\r\n    # results = pool.map(work, zip(model_list,seqences))\r\n    partial_work = partial(work, model=model)\r\n    results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n    \r\n    return np.reshape(results, (-1, ))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = simple_model()\r\n    out = worker(model, n=4)\r\n    print(out)\r\n```\r\n\r\n\r\ngives the following error trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"c:/****/test4.py\", line 43, in <module>\r\n    out = worker(model, n=4)\r\n  File \"c:/****/test4.py\", line 33, in worker\r\n    results = pool.map(partial_work, seqences)\r\n  File \"C:\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 268, in map\r\n    return self._map_async(func, iterable, mapstar, chunksize).get()\r\n  File \"C:\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 657, in get\r\n    raise self._value\r\n  File \"C:\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 431, in _handle_tasks\r\n    put(task)\r\n  File \"C:\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\connection.py\", line 206, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"C:\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\r\n    cls(buf, protocol).dump(obj)\r\nTypeError: can't pickle _thread.RLock objects\r\n```", "comments": ["@asokraju,\r\nThis issue has already been addressed by a member of the TensorFlow team.\r\n\r\nPlease take a look at this comment from similar issue [#46316](https://github.com/tensorflow/tensorflow/issues/46316#issuecomment-760339753) for more information. \r\n\r\n> Keras models are not multiprocessing-safe. I recommend simply creating multiple independent copies of your model for use in each process.\r\n\r\nThanks!", "Hi, I made independent copies of each.\r\n```\r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,100).reshape(n, -1)\r\n    pool = Pool()\r\n    model_list = [clone_model(model) for _ in range(n)]\r\n    results = pool.map(work, zip(model_list,seqences))\r\n    # partial_work = partial(work, model=model)\r\n    # results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n```\r\nBut the error still persists.\r\n", "I cloned the list of these models for each process. But the error still remains the same. Full code and the error trace.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\n\r\nfrom multiprocessing import Pool\r\nfrom multiprocessing.dummy import Pool as ThreadPool\r\nfrom functools import partial\r\n\r\ndef simple_model():\r\n    model = keras.models.Sequential([\r\n        keras.layers.Dense(units = 10, input_shape = [1]),\r\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\r\n    ])\r\n    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\r\n    return model\r\n\r\ndef clone_model(model):\r\n    model_clone = tf.keras.models.clone_model(model)\r\n    model_clone.set_weights(model.get_weights())\r\n    return model_clone\r\n\r\ndef work(model, seq):\r\n    return model.predict(seq)\r\n\r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,100).reshape(n, -1)\r\n    pool = Pool()\r\n    model_list = [clone_model(model) for _ in range(n)]\r\n    results = pool.map(work, zip(model_list,seqences))\r\n    # partial_work = partial(work, model=model)\r\n    # results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n    \r\n    return np.reshape(results, (-1, ))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = simple_model()\r\n    out = worker(model, n=4)\r\n    print(out)\r\n\r\n```\r\n\r\nError trace:\r\n  ```\r\nFile \"c:/Users/***/Documents/GitHub/COVID-NSF/test4.py\", line 42, in <module>\r\n    out = worker(model, n=4)\r\n  File \"c:/Users/****/Documents/GitHub/COVID-NSF/test4.py\", line 30, in worker\r\n    results = pool.map(work, zip(model_list,seqences))\r\n  File \"C:\\Users\\****\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 268, in map\r\n    return self._map_async(func, iterable, mapstar, chunksize).get()\r\n  File \"C:\\Users\\****\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 657, in get\r\n    raise self._value\r\n  File \"C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\", line 431, in _handle_tasks\r\n    put(task)\r\n  File \"C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\connection.py\", line 206, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\r\n    cls(buf, protocol).dump(obj)\r\nTypeError: can't pickle _thread.RLock objects\r\n\r\n```\r\n\r\nThe root cause of the error might be different.", "Alternatively, I have tried saving the model and loading it to multiple independent copies. It still does not work\r\n\r\n```\r\ndef load_model(model_savepath):\r\n    return tf.keras.models.load_model(model_savepath)\r\n\r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,100).reshape(n, -1)\r\n    pool = Pool()\r\n    model_savepath = './simple_model.h5'\r\n    model.save(model_savepath)\r\n    model_list = [load_model(model_savepath) for _ in range(n)]\r\n    # model_list = [clone_model(model) for _ in range(n)]\r\n    results = pool.map(work, zip(model_list,seqences))\r\n    # partial_work = partial(work, model=model)\r\n    # results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n    \r\n    return np.reshape(results, (-1, ))\r\n\r\n```", "I asked the question [here](https://stackoverflow.com/questions/66068180/tensflow-keras-typeerror-cant-pickle-thread-rlock-objects-when-using-multipr). @amahendrakar following your suggestion I modified the code such that the code sends the path of the model, rather than the model itself, to the child processes. Below is the working code\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\n\r\n# from multiprocessing import Pool\r\nfrom multiprocessing.dummy import Pool as ThreadPool\r\nfrom pathos.multiprocessing import ProcessingPool as Pool\r\nfrom functools import partial\r\nimport time\r\n\r\ndef simple_model():\r\n    model = keras.models.Sequential([\r\n        keras.layers.Dense(units = 10, input_shape = [1]),\r\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\r\n    ])\r\n    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\r\n    return model\r\n\r\ndef clone_model(model):\r\n    model_clone = tf.keras.models.clone_model(model)\r\n    model_clone.set_weights(model.get_weights())\r\n    model_clone.build((None, 1))\r\n    model_clone.compile(optimizer = 'sgd', loss = 'mean_squared_error')\r\n    return model_clone\r\n\r\ndef work(model, seq):\r\n    return model.predict(seq)\r\n\r\ndef work_new(seq):\r\n    model_savepath = './simple_model.h5'\r\n    model = tf.keras.models.load_model(model_savepath)\r\n    return model.predict(seq)\r\n\r\ndef load_model(model_savepath):\r\n    return tf.keras.models.load_model(model_savepath)\r\n\r\ndef worker(model, n = 4):\r\n    seqences = np.arange(0,10*n).reshape(n, -1)\r\n    pool = Pool()\r\n    model_savepath = './simple_model.h5'\r\n    model.save(model_savepath)\r\n    # model_list = [load_model(model_savepath) for _ in range(n)]\r\n    # model_list = [clone_model(model) for _ in range(n)]\r\n    # results = pool.map(work, zip(model_list,seqences))\r\n    # path_list = [[model_savepath] for _ in range(n)]\r\n    # print(np.shape(path_list), np.shape(seqences))\r\n    # work_new_partial = partial(work_new, path=model_savepath)\r\n    results = pool.map(work_new,  seqences)\r\n    # partial_work = partial(work, model=model)\r\n    # results = pool.map(partial_work, seqences)\r\n    pool.close()\r\n    pool.join()\r\n    # print(t1-t0)\r\n    return np.reshape(results, (-1, ))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    model = simple_model()\r\n    t0 = time.perf_counter()\r\n    out = worker(model, n=40)\r\n    t1 = time.perf_counter()\r\n\r\n    # print(out)\r\n    print(f\"time taken {t1 - t0}\")\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46917\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46917\">No</a>\n", "When I was running the above code in windows using anaconda, the code works fine ( I checked with every 2.x version). However, when I try it on ubuntu it gives me an issue. I reported here: https://github.com/tensorflow/tensorflow/issues/47275\r\n\r\nThe package I am using in anaconda windows are:\r\n\r\n```\r\nname: tf-gpu\r\nchannels:\r\n  - defaults\r\n  - conda-forge\r\ndependencies:\r\n  - _tflow_select=2.1.0=gpu\r\n  - absl-py=0.11.0=py37haa95532_0\r\n  - aiohttp=3.6.3=py37he774522_0\r\n  - astor=0.8.1=py37_0\r\n  - async-timeout=3.0.1=py37_0\r\n  - async_generator=1.10=py37h28b3542_0\r\n  - attrs=20.3.0=pyhd3eb1b0_0\r\n  - backcall=0.2.0=py_0\r\n  - blas=1.0=mkl\r\n  - bleach=3.2.1=py_0\r\n  - blinker=1.4=py37_0\r\n  - brotlipy=0.7.0=py37he774522_1000\r\n  - ca-certificates=2021.1.19=haa95532_0\r\n  - cachetools=4.1.1=py_0\r\n  - certifi=2020.12.5=py37haa95532_0\r\n  - cffi=1.14.3=py37h7a1dbc1_0\r\n  - chardet=3.0.4=py37_1003\r\n  - click=7.1.2=py_0\r\n  - colorama=0.4.4=py_0\r\n  - cryptography=3.1.1=py37h7a1dbc1_0\r\n  - cudatoolkit=10.1.243=h74a9793_0\r\n  - cudnn=7.6.5=cuda10.1_0\r\n  - cycler=0.10.0=py37_0\r\n  - decorator=4.4.2=py_0\r\n  - defusedxml=0.6.0=py_0\r\n  - dill=0.3.3=pyhd3eb1b0_0\r\n  - entrypoints=0.3=py37_0\r\n  - freetype=2.10.4=hd328e21_0\r\n  - gast=0.2.2=py37_0\r\n  - google-auth=1.23.0=pyhd3eb1b0_0\r\n  - google-auth-oauthlib=0.4.2=pyhd3eb1b0_2\r\n  - google-pasta=0.2.0=py_0\r\n  - grpcio=1.31.0=py37he7da953_0\r\n  - h5py=2.10.0=py37h5e291fa_0\r\n  - hdf5=1.10.4=h7ebc959_0\r\n  - icc_rt=2019.0.0=h0cc432a_1\r\n  - icu=58.2=ha925a31_3\r\n  - idna=2.10=py_0\r\n  - importlib-metadata=2.0.0=py_1\r\n  - importlib_metadata=2.0.0=1\r\n  - intel-openmp=2020.2=254\r\n  - ipykernel=5.3.4=py37h5ca1d4c_0\r\n  - ipython_genutils=0.2.0=py37_0\r\n  - jedi=0.17.2=py37_0\r\n  - jinja2=2.11.2=py_0\r\n  - joblib=0.17.0=py_0\r\n  - jpeg=9b=hb83a4c4_2\r\n  - jsonschema=3.2.0=py_2\r\n  - jupyter_client=6.1.7=py_0\r\n  - jupyter_core=4.6.3=py37_0\r\n  - jupyterlab_pygments=0.1.2=py_0\r\n  - keras-applications=1.0.8=py_1\r\n  - keras-preprocessing=1.1.0=py_1\r\n  - kiwisolver=1.3.0=py37hd77b12b_0\r\n  - libpng=1.6.37=h2a8f88b_0\r\n  - libprotobuf=3.13.0.1=h200bbdf_0\r\n  - libsodium=1.0.18=h62dcd97_0\r\n  - libtiff=4.1.0=h56a325e_1\r\n  - lz4-c=1.9.2=hf4a77e7_3\r\n  - m2w64-gcc-libgfortran=5.3.0=6\r\n  - m2w64-gcc-libs=5.3.0=7\r\n  - m2w64-gcc-libs-core=5.3.0=7\r\n  - m2w64-gmp=6.1.0=2\r\n  - m2w64-libwinpthread-git=5.0.0.4634.697f757=2\r\n  - markdown=3.3.2=py37_0\r\n  - markupsafe=1.1.1=py37hfa6e2cd_1\r\n  - matplotlib=3.3.2=0\r\n  - matplotlib-base=3.3.2=py37hba9282a_0\r\n  - mistune=0.8.4=py37hfa6e2cd_1001\r\n  - mkl=2020.2=256\r\n  - mkl-service=2.3.0=py37hb782905_0\r\n  - mkl_fft=1.2.0=py37h45dec08_0\r\n  - mkl_random=1.1.1=py37h47e9c7a_0\r\n  - msys2-conda-epoch=20160418=1\r\n  - multidict=4.7.6=py37he774522_1\r\n  - multiprocess=0.70.11.1=py37hcc03f2d_1\r\n  - nbclient=0.5.1=py_0\r\n  - nbconvert=6.0.7=py37_0\r\n  - nbformat=5.0.8=py_0\r\n  - notebook=5.7.4=py37_0\r\n  - numpy=1.19.2=py37hadc3359_0\r\n  - numpy-base=1.19.2=py37ha3acd2a_0\r\n  - oauthlib=3.1.0=py_0\r\n  - olefile=0.46=py37_0\r\n  - openssl=1.1.1i=h2bbff1b_0\r\n  - opt_einsum=3.1.0=py_0\r\n  - packaging=20.4=py_0\r\n  - pandas=1.1.3=py37ha925a31_0\r\n  - pandoc=2.11=h9490d1a_0\r\n  - pathos=0.2.7=pyhd3deb0d_0\r\n  - pickleshare=0.7.5=py37_1001\r\n  - pillow=8.0.1=py37h4fa10fc_0\r\n  - pip=20.2.4=py37haa95532_0\r\n  - pox=0.2.9=pyhd3deb0d_0\r\n  - ppft=1.6.6.3=pyhd3deb0d_0\r\n  - prometheus_client=0.8.0=py_0\r\n  - prompt-toolkit=3.0.8=py_0\r\n  - protobuf=3.13.0.1=py37ha925a31_1\r\n  - pyasn1=0.4.8=py_0\r\n  - pyasn1-modules=0.2.8=py_0\r\n  - pycparser=2.20=py_2\r\n  - pygments=2.7.2=pyhd3eb1b0_0\r\n  - pyjwt=1.7.1=py37_0\r\n  - pyopenssl=19.1.0=py_1\r\n  - pyparsing=2.4.7=py_0\r\n  - pyqt=5.9.2=py37h6538335_2\r\n  - pyreadline=2.1=py37_1\r\n  - pyrsistent=0.17.3=py37he774522_0\r\n  - pysocks=1.7.1=py37_1\r\n  - python=3.7.9=h60c2a47_0\r\n  - python-dateutil=2.8.1=py_0\r\n  - python_abi=3.7=1_cp37m\r\n  - pytz=2020.1=py_0\r\n  - pywinpty=0.5.7=py37_0\r\n  - pyyaml=5.3.1=py37he774522_1\r\n  - qt=5.9.7=vc14h73c81de_0\r\n  - requests=2.24.0=py_0\r\n  - requests-oauthlib=1.3.0=py_0\r\n  - rsa=4.6=py_0\r\n  - scikit-learn=0.23.2=py37h47e9c7a_0\r\n  - scipy=1.5.2=py37h9439919_0\r\n  - seaborn=0.11.0=py_0\r\n  - send2trash=1.5.0=py37_0\r\n  - sip=4.19.8=py37h6538335_0\r\n  - six=1.15.0=py_0\r\n  - sqlite=3.33.0=h2a8f88b_0\r\n  - tensorboard=2.3.0=pyh4dce500_0\r\n  - tensorboard-plugin-wit=1.6.0=py_0\r\n  - tensorflow=2.1.0=gpu_py37h7db9008_0\r\n  - tensorflow-base=2.1.0=gpu_py37h55f5790_0\r\n  - tensorflow-estimator=2.1.0=pyhd54b08b_0\r\n  - tensorflow-gpu=2.1.0=h0d30ee6_0\r\n  - termcolor=1.1.0=py37_1\r\n  - terminado=0.9.1=py37_0\r\n  - testpath=0.4.4=py_0\r\n  - threadpoolctl=2.1.0=pyh5ca1d4c_0\r\n  - tk=8.6.10=he774522_0\r\n  - tornado=5.1.1=py37hfa6e2cd_0\r\n  - tqdm=4.56.0=pyhd3eb1b0_0\r\n  - urllib3=1.25.11=py_0\r\n  - vc=14.1=h0510ff6_4\r\n  - vs2015_runtime=14.16.27012=hf0eaf9b_3\r\n  - wcwidth=0.2.5=py_0\r\n  - werkzeug=0.16.1=py_0\r\n  - wheel=0.35.1=py_0\r\n  - win_inet_pton=1.1.0=py37_0\r\n  - wincertstore=0.2=py37_0\r\n  - winpty=0.4.3=4\r\n  - wrapt=1.12.1=py37he774522_1\r\n  - xz=5.2.5=h62dcd97_0\r\n  - yaml=0.2.5=he774522_0\r\n  - yarl=1.6.2=py37he774522_0\r\n  - zeromq=4.3.2=ha925a31_3\r\n  - zipp=3.4.0=pyhd3eb1b0_0\r\n  - zlib=1.2.11=h62dcd97_4\r\n  - zstd=1.4.5=h04227a9_0\r\n  - pip:\r\n    - cloudpickle==1.6.0\r\n    - future==0.18.2\r\n    - gym==0.17.3\r\n    - ipython==7.18.1\r\n    - ipython-genutils==0.2.0\r\n    - json5==0.9.5\r\n    - jupyterlab==2.2.9\r\n    - jupyterlab-server==1.2.0\r\n    - nest-asyncio==1.4.2\r\n    - pandocfilters==1.4.3\r\n    - parso==0.7.1\r\n    - pyglet==1.5.0\r\n    - pywin32==228\r\n    - pyzmq==19.0.2\r\n    - setuptools==50.3.2\r\n    - traitlets==4.3.3\r\n    - webencodings==0.5.1\r\nprefix: C:\\Users\\kkris\\anaconda3\\envs\\tf-gpu\r\n\r\n```"]}, {"number": 46916, "title": "window10 make file error", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window10\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): 2.4.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): heimax we1\r\n\r\n**Describe the problem**\r\nHello, I have problem build makefile in window10\r\nI've download the migw to use \"make\".\r\n\r\nin Powershell\r\n\r\n```\r\nPS C:\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\n-m\uc740(\ub294) \uc608\uc0c1\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\r\n'tr'\uc740(\ub294) \ub0b4\ubd80 \ub610\ub294 \uc678\ubd80 \uba85\ub839, \uc2e4\ud589\ud560 \uc218 \uc788\ub294 \ud504\ub85c\uadf8\ub7a8, \ub610\ub294\r\n\ubc30\uce58 \ud30c\uc77c\uc774 \uc544\ub2d9\ub2c8\ub2e4.\r\nFIND: \ub9e4\uac1c \ubcc0\uc218 \ud615\uc2dd\uc774 \ud2c0\ub9bd\ub2c8\ub2e4.\r\nFIND: \ub9e4\uac1c \ubcc0\uc218 \ud615\uc2dd\uc774 \ud2c0\ub9bd\ub2c8\ub2e4.\r\n\uba85\ub839 \uad6c\ubb38\uc774 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\r\nprocess_begin: CreateProcess(NULL, bash C:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: .  \uba48\ucda4.\r\n\r\n```\r\n\r\n```\r\nPS C:\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=himax_we1_evb third_party_downloads\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\n-m\uc740(\ub294) \uc608\uc0c1\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\r\n'tr'\uc740(\ub294) \ub0b4\ubd80 \ub610\ub294 \uc678\ubd80 \uba85\ub839, \uc2e4\ud589\ud560 \uc218 \uc788\ub294 \ud504\ub85c\uadf8\ub7a8, \ub610\ub294\r\n\ubc30\uce58 \ud30c\uc77c\uc774 \uc544\ub2d9\ub2c8\ub2e4.\r\nFIND: \ub9e4\uac1c \ubcc0\uc218 \ud615\uc2dd\uc774 \ud2c0\ub9bd\ub2c8\ub2e4.\r\nFIND: \ub9e4\uac1c \ubcc0\uc218 \ud615\uc2dd\uc774 \ud2c0\ub9bd\ub2c8\ub2e4.\r\n\uba85\ub839 \uad6c\ubb38\uc774 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\r\nprocess_begin: CreateProcess(NULL, bash C:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: .  \uba48\ucda4.\r\n```\r\n\r\nI can't find the reason of this problem. I guess I have to change environment setting\r\n\r\n", "comments": ["@SunBeenMoon \r\nCan you please refer to similar issues and let us know, #45033, #42765, #42476", "Thank you for response my issue. @Saduf2019 \r\n\r\nI've checked all three of issues, but none of them was fit my error. \r\n\r\nI've check my gcc and make version\r\n```\r\nPS C:\\tensorflow> gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=C:\\MinGW\\bin\\gcc.exe\r\nCOLLECT_LTO_WRAPPER=c:/mingw/bin/../libexec/gcc/mingw32/6.3.0/lto-wrapper.exe\r\nTarget: mingw32\r\nConfigured with: ../src/gcc-6.3.0/configure --build=x86_64-pc-linux-gnu --host=mingw32 --target=mingw32 --with-gmp=/mingw --with-mpfr --with-mpc=/mingw --with-isl=/mingw --prefix=/mingw --disable-win32-registrThread model: win32\r\ngcc version 6.3.0 (MinGW.org GCC-6.3.0-1)\r\nPS C:\\tensorflow> make -v\r\nGNU Make 3.82\r\nBuilt for i386-pc-mingw32\r\nCopyright (C) 2010  Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\n\r\n```\r\n\r\nStill I can't find the reason of this make file problem ..", "So, I've have question 2 of it. \r\n\r\n1. Is this a problem because the Makefile version is lower than 4.1?\r\n2. Another micro issue says that the latest tensorflow has a build problem. Is that the cause? The haimax-we1 I want to use is only in the latest tensorflow.\r\n\r\n@Saduf2019  @ymodak ", "Actually I solved some of the problem.\r\nbut not sure this solution is perfect\r\n\r\nfirst of all, can't download or build in window system(cmd or powershell) you have to build in linux environment.\r\nPlus, haimax we1 makefile is not supported recent version of TF.\r\nTFversion 2.4.0 is available. \r\n\r\nIt is not perfect but i've solved it(I can't find a way to build in window environment). \r\n\r\nso I'll close this issue. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46916\">No</a>\n"]}, {"number": 46914, "title": "tf.keras.layers.UpSampling2D crashes(aborts) when size is large", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.keras.layers.UpSampling2D` crashes(aborts) when `size` is large\r\n**Describe the expected behavior**\r\nexpect an exception message if the input unexpected instead of crash. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.keras.layers.UpSampling2D(size=1610637938, data_format='channels_first', interpolation='bilinear')(np.ones((5,1,1,1)))\r\n~~~\r\nOutput:\r\n~~~python\r\n2021-02-04 04:44:48.936606: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -5475971237085092396)\r\nAborted (core dumped)\r\n~~~", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/d0a9213b5a7d785b1aa18665710c18e8/46929.ipynb). Thanks!", "Colab crashes till in TF 2.6 Nightly as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/2904b0ac3ee60c44defe00f3f2f5e72d/untitled93.ipynb).Thanks!", "Added a PR #51497 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46914\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46914\">No</a>\n"]}, {"number": 46913, "title": "tf.keras.layers.RepeatVector crashes(aborts) when n is large", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the current behavior**\r\n`tf.keras.layers.RepeatVector` crashes(aborts) when `n` is large\r\n\r\n**Describe the expected behavior**\r\nexpect an exception message if the input unexpected instead of crash. \r\n\r\n**Standalone code to reproduce the issue**\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((3, 1)))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\n2021-02-04 04:42:07.262027: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)\r\nAborted (core dumped)\r\n~~~", "comments": ["@rmothukuru \r\nI ran the code shared on tf 2.4 and nightly, colab crashes. Please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a19ece73799cb1d602387e840fe98574/untitled520.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913\">No</a>\n", "BTW, tf.keras.layers.RepeatVector thorws segmentation fault when data is empty:\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((0,0)))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~", "Colab crashes in TF 2.6 as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/4ef0fe758f11af629a9485dbfaa17e17/untitled93.ipynb).", "Added a PR #51359 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913\">No</a>\n"]}]