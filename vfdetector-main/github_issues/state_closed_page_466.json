[{"number": 39832, "title": "Wrong result when calling 'multi-line' lambda inside @tf.function", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen decorating a function using `tf.function` that uses a lambda that extends to multiple lines,\r\nonly the first line is considered. When not decorating the function using `tf.function` the result is correct.\r\n\r\n**Describe the expected behavior**\r\n\r\n`tf.function` should not alter the function behaviour. In the example below, it prints `1` instead of `0`. Removing the `tf.function` decorator gives the correct result. Moving the lambda into a single line gives again a correct result.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = (\r\n     lambda y: lambda x: x*y \r\n     - y\r\n    )(1)\r\n\r\n@tf.function\r\ndef test_lambda():\r\n    tf.print(a(1))\r\n    \r\ntest_lambda()\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe issue was noticed after applying black formatting changed the code output.", "comments": ["I have tried in colab with TF version 2.2 , nightly version and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/313709a5c0c9e445aee01e37d8c1d99f/untitled36.ipynb).Thanks!", "This looks like an underlying Python bug:\r\n\r\n```\r\nl = (\r\n     lambda y: lambda x: x*y\r\n     - y\r\n    )\r\n\r\nimport inspect\r\nprint(inspect.getsource(l))\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n     lambda y: lambda x: x*y\r\n```\r\n\r\nIt looks like the parser misses the second line.\r\n\r\nTo fix this, we'll need to work around this bug.", "Is there any update maybe on this issue? It is concerning that code formatting / linting cannot be safely applied with tf.function", "We have confirmed this is caused by a bug in Python, but I think we'll have a workaround in TF 2.4. In the mean time, these practices should help avoid running into this bug:\r\n\r\n1. Avoid placing lambdas inside expressions that could break them across multiple lines, and instead define them on a separate line:\r\n\r\n```\r\npartial = lambda y: lambda x: x*y - y\r\nl = partial(1)\r\n```\r\n\r\n2. Prefer using normal local functions when the body might be too long to fit on a single line:\r\n\r\n```\r\ndef partial(y):\r\n  return lambda x, y: x*y - y\r\nl = partial(1)\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39832\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39832\">No</a>\n", "Quick update: a more robust fix for this is now in and should be available in tf-nightly and TF 2.4 later this year. The new parsing method should robustly process all cases, and raises an error when it can't determine the proper function with certainty (which should only happen in rare cases).", "Fantastic, thanks!\n\nOn Tue, Jul 7, 2020, 16:18 Dan Moldovan <notifications@github.com> wrote:\n\n> Quick update: a more robust fix for this is now in and should be available\n> in tf-nightly and TF 2.4 later this year. The new parsing method should\n> robustly process all cases, and raises an error when it can't determine the\n> proper function with certainty (which should only happen in rare cases).\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39832#issuecomment-654895251>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADTBRJ2PGTOJYCP3B5FQ7MLR2MVBZANCNFSM4NI4CCVQ>\n> .\n>\n"]}, {"number": 39831, "title": "Tensorflow keras fit - accuracy and loss both increasing drastically", "body": "ubuntu - 20.04\r\n\r\ntensorflow 2.2\r\n\r\ndataset used = MNIST\r\n\r\nI am testing tensorflow and i notice that validation `sparse_categorical_accuracy` (accuracy) and validation `SparseCategoricalCrossentropy` (loss) both are increasing together which, does not make sense to me. **This is not a case of overfitting**. I think the validation loss should be going down and validation accuracy increasing as the training progresses or, in case of overfitting, validation accuracy going down and validation loss going up. But, validation loss and validation accuracy both are increasing as the training progresses. The training schedule however, is progressing according to expectation i.e training loss going down and training accuracy going up\r\n\r\nHere is the code and the output:\r\n\r\n```\r\n#testing without preprocess monsoon\r\nimport tensorflow as tf\r\nfrom tensorflow import keras as k\r\nfrom tensorflow.keras import layers as l\r\nimport tensorflow_addons as tfa\r\n\r\nmnist = tf.keras.datasets.mnist\r\n(x_t,y_t),(x_te,y_te) = mnist.load_data()\r\nx_t = x_t.reshape(60000,-1)\r\nx_te = x_te.reshape(10000,-1)\r\n\r\nd_x_t = tf.data.Dataset.from_tensor_slices(x_t)\r\nd_y_t = tf.data.Dataset.from_tensor_slices(y_t)\r\ndataset = tf.data.Dataset.zip((d_x_t,d_y_t)).shuffle(1000).batch(32)\r\n\r\nd_x_te = tf.data.Dataset.from_tensor_slices(x_te)\r\nd_y_te = tf.data.Dataset.from_tensor_slices(y_te)\r\ndataset_test = tf.data.Dataset.zip((d_x_te,d_y_te)).shuffle(1000,seed=42).batch(32)\r\n\r\ninp = k.Input((784,))\r\nx = l.BatchNormalization()(inp)\r\nx1 = l.Dense(1024,activation='relu',name='dense_1')(x)\r\nx1=l.Dropout(0.5)(x1)\r\nx1 = l.BatchNormalization()(x1)\r\nx2 = l.Dense(512,activation='relu',name='dense_2')(x1)\r\nx3 = l.Dense(512,activation='relu',name='dense_3')(x)\r\nx = x3+x2\r\n\r\nx=l.Dropout(0.5)(x)\r\nx = l.BatchNormalization()(x)\r\nx = l.Dense(10,activation='relu',name='dense_4')(x)\r\npredictions = l.Dense(10,activation=None,name='preds')(x)\r\nmodel = k.Model(inputs=inp,outputs=predictions)\r\n\r\nopt=tfa.optimizers.MovingAverage(\r\n    k.optimizers.Adam(),\r\n    True,\r\n    0.99,\r\n    None,\r\n    'MovingAverage',\r\n    clipnorm=5\r\n)\r\n\r\nmodel.compile(optimizer=opt,\r\n              loss=k.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['sparse_categorical_accuracy'])\r\nprint('# Fit model on training data')\r\nhistory = model.fit(dataset,\r\n                    epochs=30,\r\n                    steps_per_epoch=1875,\r\n                    validation_data = dataset_test,\r\n                    validation_steps = 313)\r\n\r\nprint('\\nhistory dict:', history.history)\r\nmodel.evaluate(dataset_test,batch_size=32,steps=331)\r\n\r\n```\r\n\r\nThe learning evolution that i am getting is:\r\n\r\n```\r\n# Fit model on training data\r\nEpoch 1/30\r\nWARNING:tensorflow:From /home/nitin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n1875/1875 [==============================] - 49s 26ms/step - loss: 0.3614 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.9548\r\nEpoch 2/30\r\n1875/1875 [==============================] - 49s 26ms/step - loss: 0.1899 - sparse_categorical_accuracy: 0.9427 - val_loss: 1.2028 - val_sparse_categorical_accuracy: 0.9641\r\nEpoch 3/30\r\n1875/1875 [==============================] - 51s 27ms/step - loss: 0.1546 - sparse_categorical_accuracy: 0.9521 - val_loss: 1.6385 - val_sparse_categorical_accuracy: 0.9673\r\nEpoch 4/30\r\n1875/1875 [==============================] - 38s 20ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9585 - val_loss: 2.8285 - val_sparse_categorical_accuracy: 0.9697\r\nEpoch 5/30\r\n1875/1875 [==============================] - 38s 20ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9608 - val_loss: 3.8489 - val_sparse_categorical_accuracy: 0.9697\r\nEpoch 6/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9646 - val_loss: 2.1872 - val_sparse_categorical_accuracy: 0.9699\r\nEpoch 7/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9646 - val_loss: 2.9429 - val_sparse_categorical_accuracy: 0.9695\r\nEpoch 8/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9667 - val_loss: 5.6166 - val_sparse_categorical_accuracy: 0.9710\r\nEpoch 9/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9688 - val_loss: 3.9547 - val_sparse_categorical_accuracy: 0.9710\r\nEpoch 10/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9701 - val_loss: 4.8149 - val_sparse_categorical_accuracy: 0.9713\r\nEpoch 11/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9727 - val_loss: 7.4974 - val_sparse_categorical_accuracy: 0.9712\r\nEpoch 12/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9719 - val_loss: 4.3669 - val_sparse_categorical_accuracy: 0.9714\r\nEpoch 13/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9743 - val_loss: 9.2499 - val_sparse_categorical_accuracy: 0.9725\r\nEpoch 14/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9737 - val_loss: 7.5436 - val_sparse_categorical_accuracy: 0.9716\r\nEpoch 15/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9751 - val_loss: 14.2331 - val_sparse_categorical_accuracy: 0.9712\r\nEpoch 16/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9757 - val_loss: 7.9517 - val_sparse_categorical_accuracy: 0.9715\r\nEpoch 17/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9761 - val_loss: 7.9719 - val_sparse_categorical_accuracy: 0.9702\r\nEpoch 18/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9763 - val_loss: 13.8696 - val_sparse_categorical_accuracy: 0.9665\r\nEpoch 19/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9760 - val_loss: 20.2949 - val_sparse_categorical_accuracy: 0.9688\r\nEpoch 20/30\r\n1875/1875 [==============================] - 45s 24ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9775 - val_loss: 8.8696 - val_sparse_categorical_accuracy: 0.9713\r\nEpoch 21/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9777 - val_loss: 12.9682 - val_sparse_categorical_accuracy: 0.9723\r\nEpoch 22/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9781 - val_loss: 61.1677 - val_sparse_categorical_accuracy: 0.9692\r\nEpoch 23/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9798 - val_loss: 21.3270 - val_sparse_categorical_accuracy: 0.9697\r\nEpoch 24/30\r\n1875/1875 [==============================] - 31s 16ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9800 - val_loss: 62.2778 - val_sparse_categorical_accuracy: 0.9685\r\nEpoch 25/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9792 - val_loss: 24.9327 - val_sparse_categorical_accuracy: 0.9687\r\nEpoch 26/30\r\n1875/1875 [==============================] - 46s 24ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9805 - val_loss: 42.0141 - val_sparse_categorical_accuracy: 0.9700\r\nEpoch 27/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9806 - val_loss: 54.8586 - val_sparse_categorical_accuracy: 0.9695\r\nEpoch 28/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9811 - val_loss: 25.3613 - val_sparse_categorical_accuracy: 0.9680\r\nEpoch 29/30\r\n1875/1875 [==============================] - 29s 16ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9811 - val_loss: 23.2299 - val_sparse_categorical_accuracy: 0.9710\r\nEpoch 30/30\r\n1875/1875 [==============================] - 30s 16ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9817 - val_loss: 16.5671 - val_sparse_categorical_accuracy: 0.9728\r\n\r\nhistory dict: {'loss': [0.36135926842689514, 0.1898646354675293, 0.15456895530223846, 0.13569727540016174, 0.12525275349617004, 0.1148592159152031, 0.10943067818880081, 0.1066298857331276, 0.09912335127592087, 0.09476170688867569, 0.08501157909631729, 0.0879492461681366, 0.08170024305582047, 0.08047273010015488, 0.07976552098989487, 0.07453753799200058, 0.07450901716947556, 0.07413797080516815, 0.07278618961572647, 0.0698995441198349, 0.06988336145877838, 0.06740442663431168, 0.06507138162851334, 0.06242847815155983, 0.0665266141295433, 0.06050613150000572, 0.06005210056900978, 0.05830719694495201, 0.05763527378439903, 0.05664650723338127], 'sparse_categorical_accuracy': [0.8913000226020813, 0.9427499771118164, 0.9521499872207642, 0.9585333466529846, 0.9607999920845032, 0.9645500183105469, 0.9645666480064392, 0.9666833281517029, 0.9687666893005371, 0.9701166749000549, 0.9726999998092651, 0.9719499945640564, 0.9742666482925415, 0.9736999869346619, 0.9750999808311462, 0.9757000207901001, 0.9760833382606506, 0.9763166904449463, 0.9759833216667175, 0.977483332157135, 0.9777166843414307, 0.9780833125114441, 0.9798333048820496, 0.9800000190734863, 0.9792333245277405, 0.9805499911308289, 0.9805999994277954, 0.9810666441917419, 0.9810666441917419, 0.9816833138465881], 'val_loss': [0.33551061153411865, 1.2028071880340576, 1.6384732723236084, 2.828489065170288, 3.8488738536834717, 2.187160015106201, 2.9428975582122803, 5.6166462898254395, 3.954725503921509, 4.814915657043457, 7.4974141120910645, 4.366909503936768, 9.24986457824707, 7.543578147888184, 14.233136177062988, 7.951717853546143, 7.971870422363281, 13.869564056396484, 20.29490089416504, 8.869643211364746, 12.968180656433105, 61.167701721191406, 21.327049255371094, 62.27778625488281, 24.932708740234375, 42.01411437988281, 54.85857009887695, 25.361297607421875, 23.229896545410156, 16.56712532043457], 'val_sparse_categorical_accuracy': [0.954800009727478, 0.9641000032424927, 0.9672999978065491, 0.9696999788284302, 0.9696999788284302, 0.9699000120162964, 0.9695000052452087, 0.9710000157356262, 0.9710000157356262, 0.9713000059127808, 0.9711999893188477, 0.9714000225067139, 0.9725000262260437, 0.9715999960899353, 0.9711999893188477, 0.9714999794960022, 0.9702000021934509, 0.9664999842643738, 0.9688000082969666, 0.9713000059127808, 0.9722999930381775, 0.9692000150680542, 0.9696999788284302, 0.968500018119812, 0.9686999917030334, 0.9700000286102295, 0.9695000052452087, 0.9679999947547913, 0.9710000157356262, 0.9728000164031982]}\r\n302/331 [==========================>...] - ETA: 0s - loss: 17.1192 - sparse_categorical_accuracy: 0.9725WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 331 batches). You may need to use the repeat() function when building your dataset.\r\n313/331 [===========================>..] - 1s 3ms/step - loss: 16.5671 - sparse_categorical_accuracy: 0.9728\r\n[16.567113876342773, 0.9728000164031982]\r\n```", "comments": ["@nitinmnsn This also indicates that the model is overfitting. It continues to get better at fitting the training data while getting worse at fitting the validation data. The validation accuracy looks to be more or less flat after the first iterations or so. It almost remain flat while the loss gets worse. To give an example, accuracy only measures you got the prediction right where as cross entropy measures how confident we are about the prediction.\r\n\r\nAssume, model A predicts {bike: 0.9, car: 0.1} and model B predicts {bike: 0.6, car: 0.4}. Both model will score the same accuracy, but model A will have a lower loss compared to model B.", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/1b8d44a74fb883f4fd6087fd20824878/39831.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/bd166e9f0f663efa4edc5a4b3458f0b3/39831-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@nitinmnsn Batch normalization is used to standardize the inputs to a network and applied either before activations or after activations depending on type of activations. Generally it is used between two conv layers or two dense layers or a conv and dense layer. However, AFAIK, it should not be used as a first layer as standardization using a batch statistics will affects the statistics of next batch. Can you please explain the reasoning behind using it as a first layer? what is your use-case that require this BN layer as first layer. Thanks!\r\n\r\nI ran your code without the first BN layer and the training and validation loss are similar. Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/ba85c40e59fefe3e38908923e8163551/39831-tf-nightly.ipynb).\r\n\r\nPlease verify once and close the issue if this resolved for you. Thanks!", "Thank you for response.\r\n\r\nYes the issue stands resolved if i do not use batch normalization as the preprocessing step.\r\n\r\nI did not get what you meant by 'it should not be used as a first layer as standardization using a batch statistics will affects the statistics of next batch'. Do you mean the effect will propogate through beta and gamma? Because, my understanding is that each batch will be normalized using its own statistics (and then rescaled and recentred using beta and gamma which, are learned) and a moving first and second moments would be maintained and that will be used during inference time normalization.\r\n\r\nSo, i basically tried to learn the best preprocessing using batch normalization. I have hude csvs and i tried to do away with having to iterate over entire data once in calculating the mean and standard deviation", "Is this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 or v2.7 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39831\">No</a>\n"]}, {"number": 39830, "title": "Stop .flow_from_dataframe from printing", "body": "Can you please add a 'verbose' parameter to flow_from_dataframe to prevent printing?\r\n\r\nI've implemented a custom generator that calls ```ImageDataGenerator```'s method ```flow_from_dataframe``` for each batch, to create a randomly sampled batch, which has one instance of each class:\r\n```lang-python\r\n  def __getitem__(self, idx):\r\n\r\n        batch_df = pd.DataFrame()\r\n\r\n        # create a dataframe with one random sample for each class\r\n        for class_name in batch_class_names:\r\n            rand_row = self.df_dict[class_name].sample(n = 1)\r\n            batch_df = batch_df.append(rand_row, ignore_index=True)\r\n            \r\n        # create generator\r\n        batch_gen = self.generator.flow_from_dataframe(\r\n            dataframe=batch_df, directory=self.directory, x_col=\"filename\",\r\n            y_col=\"brand\", classes=self.class_names,\r\n            class_mode=\"categorical\",\r\n            target_size=self.image_dims, color_mode=\"rgb\", batch_size=batch_df.shape[0], shuffle=self.shuffle)\r\n\r\n        # return batch\r\n        return next(batch_gen)\r\n```\r\n\r\nThis causes ```flow_from_dataframe to``` print **a new line for each batch**, which ruins the epochs outputs.\r\nInstead of printing a new line after each epoch (which has 100 batches), a new line is printed after each batch:\r\n\r\n```lang-python\r\n  1/100 [..............................] - ETA: 20:05 - loss: 3.4795 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  2/100 [..............................] - ETA: 11:11 - loss: 3.4328 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  3/100 [..............................] - ETA: 8:10 - loss: 3.4140 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  4/100 [>.............................] - ETA: 6:39 - loss: 3.4309 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  5/100 [>.............................] - ETA: 5:45 - loss: 3.4323 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  6/100 [>.............................] - ETA: 5:08 - loss: 3.4221 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n  7/100 [=>............................] - ETA: 4:41 - loss: 3.4188 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.\r\n```\r\n\r\nI've tried placing ```sys.stdout = open(os.devnull, 'w')``` before I call ```flow_from_dataframe``` and ```sys.stdout = sys.__stdout__``` right after, but this stopped all printing (epoch printing as well).\r\n\r\n\r\n", "comments": ["@michalCyberfish Can you please provide a standalone code to reproduce the issue? Thanks!", "```python\r\n\r\n# custom generator\r\nclass BalancedBatchGenerator(Sequence):\r\n    def __init__(self, generator, data , directory, image_dims, class_names, batch_size=9, shuffle=True):\r\n        self.generator = generator\r\n        self.data = data\r\n        self.directory = directory\r\n        self.image_dims = image_dims\r\n        self.class_names = class_names\r\n        self.batch_size = batch_size\r\n        self.shuffle = shuffle\r\n        self.class_index = 0\r\n        self.filenames = self.data['filename']\r\n        self.classes = self.data['brand']\r\n        \r\n        \r\n        self.df_dict = {}\r\n        self.class_indices = self.generator.flow_from_dataframe(\r\n            dataframe=self.data, directory=self.directory, x_col=\"filename\",\r\n            y_col=\"brand\", classes=self.class_names,\r\n            class_mode=\"categorical\",\r\n            target_size=self.image_dims, color_mode=\"rgb\", batch_size=1, shuffle=self.shuffle).class_indices\r\n        \r\n       # create a dataframe for each class\r\n        for class_name in self.class_names:\r\n            self.df_dict[class_name] = self.data[self.data['brand'] == class_name]\r\n\r\n\r\n    def __len__(self):\r\n        return math.ceil(self.data.shape[0]/self.batch_size)\r\n\r\n    def __getitem__(self, idx):\r\n       # create a batch containing one random sample of each class\r\n\r\n       # decide which classes will be added to this batch (since number of classes is greater than batch size)\r\n        if self.class_index + self.batch_size - 1 < len(self.class_names):\r\n            batch_class_names = self.class_names[self.class_index:self.class_index+self.batch_size]\r\n        else:\r\n            batch_class_names = self.class_names[self.class_index:self.class_index+self.batch_size]\r\n            from_zero = self.batch_size - len(batch_class_names)\r\n            batch_class_names += self.class_names[0:from_zero]\r\n\r\n        self.class_index+=self.batch_size\r\n        if self.class_index >= len(self.class_names):\r\n            self.class_index = self.class_index%self.batch_size + 1\r\n\r\n\r\n        # sample one random instance of each class and store it in a dataframe\r\n        batch_df = pd.DataFrame()\r\n        for class_name in batch_class_names:\r\n            rand_row = self.df_dict[class_name].sample(n = 1)\r\n            batch_df = batch_df.append(rand_row, ignore_index=True)\r\n\r\n        # create a batch of images from the batch dataframe\r\n        batch_gen = self.generator.flow_from_dataframe(\r\n            dataframe=batch_df, directory=self.directory, x_col=\"filename\",\r\n            y_col=\"brand\", classes=self.class_names,\r\n            class_mode=\"categorical\",\r\n            target_size=self.image_dims, color_mode=\"rgb\", batch_size=batch_df.shape[0], shuffle=self.shuffle)\r\n        \r\n        return (next(batch_gen))\r\n\r\n```\r\nMain code:\r\n```python\r\n# create train, validation and test datasets\r\ntrain, test = train_test_split(df, test_size=0.2, random_state=42)\r\ntrain, valid = train_test_split(train, test_size=0.25, random_state=42)\r\n\r\n# create image generators\r\n# generator with augmentation for training, no augmentation for validation and test\r\n\r\ndef add_noise(image_matrix):\r\n    return  image_matrix + np.random.normal(loc=0.0, scale=50)\r\n\r\naugmentation_generator = ImageDataGenerator(\r\n        rescale=1. / 255,\r\n        preprocessing_function=add_noise,\r\n        zoom_range=[0.5, 1.5])\r\n\r\nsimple_generator = ImageDataGenerator(rescale=1. / 255)\r\n\r\ntrain_generator = BalancedBatchGenerator(augmentation_generator, train , image_dir_path,\r\n                                                          image_dims, class_names, batch_size=9, shuffle=True)\r\nvalid_generator = BalancedBatchGenerator(simple_generator, valid , image_dir_path, \r\n                                                                              image_dims, class_names, shuffle=True)\r\ntest_generator = BalancedBatchGenerator(simple_generator, test , image_dir_path, \r\n                                                                             image_dims, class_names, shuffle=False)\r\n\r\n# create model\r\n\r\nbase_model = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\r\nx = base_model.output\r\nx = GlobalAveragePooling2D()(x)\r\nx = Dense(1024, activation='relu')(x)\r\npredictions = Dense(num_classes, activation='softmax')(x)\r\nmodel = Model(inputs=base_model.input, outputs=predictions)\r\nmodel.compile(optimizer=SGD(lr=lr),\r\n                      loss='categorical_crossenropy')\r\n\r\n# train model\r\ntrain_steps = 100\r\nvalidation_steps=100\r\n\r\nmodel.fit_generator(\r\n        generator=train_generator,\r\n        steps_per_epoch=train_steps,\r\n        validation_data=valid_generator,\r\n        validation_steps=validation_steps,\r\n        epochs=epochs,\r\n        verbose=1\r\n )\r\n```", "@michalCyberfish Is this still an issue for you? Can you please check with recent TF/keras versions and let us know whether it is resolved. If this was not resolve, please share a standalone code (code with public data  or tf.random) so that I can try to reproduce the issue.\r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39829, "title": "CUDA compiling include file path failure inside tensorflow python installation directory in Windows 10", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: (not related with this issue)\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nCreate a CUDA source file, e.g. named *test.cu*, with content:\r\n\r\n```\r\n#define EIGEN_USE_GPU\r\n#define __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n```\r\n\r\nThen run command:\r\n `nvcc ./test.cu --include-path \"C:\\Users\\xxx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\include\"`\r\n\r\nThen you will got error like this:\r\n\r\n> C:/Users/xxx/AppData/Local/Programs/Python/Python36/lib/site-packages/tensorflow/include\\unsupported/Eigen/CXX11/Tensor(74): fatal error C1083: Cannot open include file: 'unistd.h': No such file or directory \r\n\r\n**Describe the expected behavior**\r\n\r\nCompiling succeed.\r\n\r\n**My Research**\r\n\r\nThe error occurred in an Eigen C++ file named `Tensor`:\r\n\r\n```\r\n#ifdef EIGEN_USE_GPU\r\n  #include <iostream>\r\n  #if defined(EIGEN_USE_HIP)\r\n    #include <hip/hip_runtime.h>\r\n  #else\r\n    #include <cuda_runtime.h>\r\n  #endif\r\n  #include <atomic>\r\n  #include <unistd.h>\r\n#endif\r\n```\r\n\r\nYou can see that `unistd.h` including is not excluded by some conditional compiling branch of *_WIN32*.\r\n\r\nIt seems a bug within *Eigen*, but I found the original source [here](https://github.com/PX4/eigen/blob/master/unsupported/Eigen/CXX11/Tensor#L85):\r\n\r\n```\r\n#ifdef EIGEN_USE_GPU\r\n#include <iostream>\r\n#include <cuda_runtime.h>\r\n#if __cplusplus >= 201103L\r\n#include <atomic>\r\n#include <unistd.h>\r\n#endif\r\n#endif\r\n```\r\n\r\nThis is different, and I haven't found any uniform record in their committing history. So this seems modified by Tensorflow team or someone else already.\r\n\r\nAnd I solved this issue just by commenting out the line of `#include <unistd.h>` in the tensorflow python installation directory. Expecting the official fix.", "comments": ["@k-l-lambda \r\n\r\nCan you please refer [link1](https://stackoverflow.com/questions/22705751/cannot-open-include-file-unistd-h-no-such-file-or-directory) and[ link2 ](https://stackoverflow.com/questions/341817/is-there-a-replacement-for-unistd-h-for-windows-visual-c)and see if it helps you.Thanks!", "> @k-l-lambda\r\n> \r\n> Can you please refer [link1](https://stackoverflow.com/questions/22705751/cannot-open-include-file-unistd-h-no-such-file-or-directory) and[ link2 ](https://stackoverflow.com/questions/341817/is-there-a-replacement-for-unistd-h-for-windows-visual-c)and see if it helps you.Thanks!\r\n\r\nNo, it doesn't help.\r\n\r\nThe simple workaround is just remove the include line of *unistd.h*. But when I publish a middle-ware library, client developers expect that can work directly, without some bothering manual edition in a third-party source code, following a complicated instruction list.\r\n\r\nSome one should take the responsibility to correct this, if not tensorflow team, please tell me the where the code come from.\r\n\r\n> **C:/Users/xxx/AppData/Local/Programs/Python/Python36/lib/site-packages/tensorflow/include\\unsupported/Eigen/CXX11/Tensor**\r\n\r\nPlease read my issue description for details.", "@k-l-lambda It looks like you are using an older Version of Tensorflow (2.2). Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version (2.6) and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39829\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39829\">No</a>\n"]}, {"number": 39828, "title": "Python project bug", "body": "Hi I'm new to python and I start my first project but when I type \"minus\" it execute addition part of program and I try and try but I fail to fix it\r\n\r\nx = int(input(\"X Value: \"))\r\ny = int(input(\"Y Value: \"))\r\ni = 0\r\n\r\nwhile i == 0:\r\n    print(\" \")\r\n    print(f\"({x}, {y})\")\r\n    cmd = input(\"> \")\r\n    cmd = cmd.lower()\r\n\r\n    # plus\r\n    if cmd == \"plus\" or \"Addition\":\r\n        i = 1\r\n        while i == 1:\r\n            sub_cmd_pos = input(\"(x) + y  or  (y) + x \")\r\n            sub_cmd_pos = sub_cmd_pos.lower()\r\n            if sub_cmd_pos == 'x':\r\n                print(x + y)\r\n                i = 1\r\n            elif sub_cmd_pos == 'y':\r\n                print(y + x)\r\n                i = 1\r\n            else:\r\n                print(\"Invalid Command, For help type 'help' \")\r\n\r\n    # minus\r\n    elif cmd == \"minus\" or \"subtraction\":\r\n        i = 2\r\n        while i == 2:\r\n            sub_cmd_neg = input(\"(x) - y  or  (y) - x \")\r\n            sub_cmd_neg = sub_cmd_neg.lower()\r\n            if sub_cmd_neg == 'x':\r\n                print(x - y)\r\n                i = 0\r\n            elif sub_cmd_neg == 'y':\r\n                print(y - x)\r\n                i = 0\r\n            else:\r\n                print(\"Invalid Command, For help type 'help' \")\r\n", "comments": ["1. You are taking the value of i=0 from previously so, the code did not execute to when i=1 or 2\r\n2. Your while loop for i=0 cannot be executed because it has an indentation problem.", "@ocean-invader,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/ask) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "Not TF related"]}, {"number": 39827, "title": "InvalidArgumentError while using GRU layer in custom training loop", "body": "**System information**\r\n- TensorFlow version `2.1.0`\r\n- Python version: `3`\r\n- GPU model and memory: `NVIDIA Tesla P100`\r\n- CUDA Version: `10.1`\r\n- Environment: This happens both on Kaggle and Colab\r\n\r\n**Describe the current behavior**\r\nI'm trying to train a Hugging face transformer model (roBERTa base) with a custom training loop, and got the error below:\r\n\r\n```\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24\r\n\t [[{{node while/body/_1/StatefulPartitionedCall}}]]\r\n  (1) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24\r\n\t [[{{node while/body/_1/StatefulPartitionedCall}}]]\r\n\t [[while/body/_1/Adam/Cast_6/ReadVariableOp/_30]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_step_35635]\r\n\r\nFunction call stack:\r\ntrain_step -> train_step\r\n```\r\nThe thing is I can run the same model using `model.fit()` API, and this error only happens when I use a LSTM or GRU layer on top of the transformer\r\n\r\n**Describe the expected behavior**\r\nTraining should go normal", "comments": ["@dimitreOliveira \r\nCan you please share a simple stand alone code for us to replicate the issue faced or if possible please share colab gist with the error", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi @Saduf2019  , this is the model architecture, I don't have a colab gist or a stand-alone coded, but I can provid some of the code I have used.\r\n\r\n```\r\nmodule_config = RobertaConfig.from_pretrained(config['config_path'], output_hidden_states=False)\r\n\r\ndef model_fn(MAX_LEN):\r\n    input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\r\n    attention_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\r\n    \r\n    base_model = TFRobertaModel.from_pretrained(config['base_model_path'], config=module_config, name=\"base_model\")\r\n    last_hidden_state, _ = base_model({'input_ids': input_ids, 'attention_mask': attention_mask})\r\n    \r\n    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(last_hidden_state)\r\n    x = layers.Dropout(.1)(x)\r\n    \r\n    x_start = layers.TimeDistributed(layers.Dense(1))(x)\r\n    x_start = layers.Flatten()(x_start)\r\n    y_start = layers.Activation('softmax', name='y_start')(x_start)\r\n    \r\n    x_end = layers.TimeDistributed(layers.Dense(1))(x)\r\n    x_end = layers.Flatten()(x_end)\r\n    y_end = layers.Activation('softmax', name='y_end')(x_end)\r\n\r\n    model = Model(inputs=[input_ids, attention_mask], outputs=[y_start, y_end])\r\n    \r\n    return model\r\n```\r\n\r\nAnd I was using it for a QA problem, so I also did:\r\n\r\n```\r\nmodel.compile(optimizer, loss={'y_start': losses.CategoricalCrossentropy(),\r\n                                   'y_end': losses.CategoricalCrossentropy()})\r\n```\r\n\r\nThe tricky part is that is jsut happens inside a custom training loop. Here are some of the code I have used.\r\n\r\n```\r\n# Step functions\r\n    @tf.function\r\n    def train_step(data_iter):\r\n        def train_step_fn(x, y):\r\n            with tf.GradientTape() as tape:\r\n                probabilities = model(x, training=True)\r\n                loss_start = loss_fn_start(y['y_start'], probabilities[0])\r\n                loss_end = loss_fn_end(y['y_end'], probabilities[1])\r\n                loss = tf.math.add(loss_start, loss_end)\r\n            grads = tape.gradient(loss, model.trainable_variables)\r\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n            # update metrics\r\n            train_acc_start.update_state(y['y_start'], probabilities)\r\n            train_acc_end.update_state(y['y_end'], probabilities)\r\n            train_loss.update_state(loss)\r\n            train_loss_start.update_state(loss_start)\r\n            train_loss_end.update_state(loss_end)\r\n        for _ in tf.range(step_size):\r\n            strategy.experimental_run_v2(train_step_fn, next(data_iter))\r\n\r\nloss_fn_start = losses.categorical_crossentropy\r\nloss_fn_end = losses.categorical_crossentropy\r\n\r\ntrain_acc_start = metrics.CategoricalAccuracy()\r\ntrain_acc_end = metrics.CategoricalAccuracy()\r\ntrain_loss = metrics.Sum()\r\ntrain_loss_start = metrics.Sum()\r\ntrain_loss_end = metrics.Sum()\r\n```\r\n\r\nLet me know if you need any more information.", "@dimitreOliveira \r\nPlease share code such that i can replicate the issue faced, i ran the code shared and face a different error.\r\nplease find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/1496558d57374d9b904a394bc1eb9309/untitled217.ipynb)", "@dimitreOliveira\r\nPlease update on the above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it cant be reproduced as the code cannot be provided by the user and has been inactive for more than 4 weeks. Please add additional comments for us to open this issue again.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39827\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39827\">No</a>\n"]}, {"number": 39826, "title": "Fix incorrect reference of np.assert_allclose (should be np.testing.assert_allclose)", "body": "In the docstring of `tf.debugging.assert_near`, the numpy compatibility part incorrectly uses `np.assert_allclose`.\r\n\r\nThis should be `np.testing.assert_allclose` instead.\r\n\r\nThis PR fixes the incorrect docstring.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 39825, "title": "Add complex tensor support for tf.debugging.assert_near", "body": "This PR tries to address the issue raised in #39815 where\r\ntf.debugging.assert_near does not support complex tensors as was specified\r\nin docstring.\r\n\r\nThis PR adds complex tensor support for tf.debugging.assert_near.\r\n\r\nThis PR fixes #39815.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 39824, "title": " C++ compilation of rule '//tensorflow/core/kernels:mkl_softmax_op' failed - Win 10 / VS2019", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: Master Branch\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 2.0.1\r\n- GCC/Compiler version (if compiling from source):  VS2019\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 2070 Max-Q\r\n\r\n**Describe the problem**\r\n\r\nBuild of mkl version of TF fails to build from source, errors with the following\r\n\r\nERROR: C:/sdks/tensorflow-dev/tensorflow/core/kernels/BUILD:8207:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_softmax_op' failed (Exit 2)\r\n.\\tensorflow/core/util/mkl_util.h(1285): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1284): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1284): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1286): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1284): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1284): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1288): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\n.\\tensorflow/core/util/mkl_util.h(1289): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=mkl //tensorflow/tools/pip_package:build_pip_package\r\n\r\n", "comments": ["@oracle3001 We will check as soon!", "@oracle3001 The PR should fix this issue: https://github.com/tensorflow/tensorflow/pull/37785", "@oracle3001 Is it possible to close this issue?", "@oracle3001 \r\nCould you feedback the fix in https://github.com/tensorflow/tensorflow/pull/37785?\r\n\r\n\r\n", "@oracle3001 \r\n\r\nIf your issue is fixed, could you close this issue?", "@oracle3001 \r\n\r\nCould you feedback?\r\n\r\nThank you!", "Yes, it appears to be fixed in TF 2.4.", "@oracle3001 \r\nIt's great!\r\n\r\nCould you close this issue?\r\n\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39824\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39824\">No</a>\n"]}, {"number": 39823, "title": "TFLite conversion of Conv1D layer with dilation_rate>1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nAfter converting a TF ```Conv1D``` op with ```dilation_rate>1``` to TFLite op, the interpreter cannot allocate tensors:\r\n\r\n```\r\nRuntimeError: tensorflow/lite/kernels/space_to_batch_nd.cc:98 NumDimensions(op_context.input) != kInputDimensionNum (3 != 4)Node number 0 (SPACE_TO_BATCH_ND) failed to prepare.\r\n```\r\n\r\n**Describe the expected behavior**\r\nTFLite model should be able to load and execute by the interpreter.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import *\r\n\r\n\r\ndef get_model():\r\n  input = tf.keras.Input(shape=(10, 40))\r\n\r\n  # No error when dilation rate == 1\r\n  layer = Conv1D(32, (3), dilation_rate=2, padding='same', use_bias=False)(input)\r\n  layer = GlobalMaxPooling1D()(layer)\r\n  output = Dense(2)(layer)\r\n\r\n  model = Model(inputs=[input], outputs=[output])\r\n  return model\r\n\r\n\r\nmodel = get_model()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntflite_model = converter.convert()\r\nopen(\"./trained_model.tflite\", \"wb\").write(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=\"./trained_model.tflite\")\r\n\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\n**Other info / logs** \r\nThe problem does not occur when ```dilation_rate==1```\r\n", "comments": ["#30315", "@petros-giannakopoulos,\r\nI was able to reproduce the error with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/5b883e85d2751137e47421183a0e9c9b/39823.ipynb#scrollTo=dSKM0rtCI_L3). However, the issue seems to be fixed with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a8c3ae96c71321b37485754754ead583/39823-tf-nightly.ipynb). Please check the linked gist. Thanks!", "@petros-giannakopoulos,\r\nAny updates regarding this issue? Thanks!\r\n", "I confirm the issue is fixed in latest TF-nightly. Thanks! I'm closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39823\">No</a>\n", "Although the issues do not exist in the tf-nightly builds, the stable versions of tensorflow does not yet support conv1d layers with dilations > 1. When will this be pushed to the stable release? I worked with 2.4.1 and this issue still persists. "]}, {"number": 39822, "title": "Translation from frozen graph to lite model is incorrect when quantization is enabled.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.1.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nFrom a correct frozen graph, I try to use quantized tflite conversion which fails to give a correct prediction while unquantized version DOES give correct prediction. I attach all the code to generate these conversion as follows.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.compat.v1 as tf1\r\n\r\ndef tf2lite(model_file, input_img_size, quantized=False):\r\n    # We only run this function with CPU\r\n    my_devices = tf.config.list_physical_devices(device_type='CPU')\r\n    tf.config.set_visible_devices(devices=my_devices, device_type='CPU')\r\n\r\n    assert os.path.isfile(model_file), 'File {} does not exist'.format(model_file)\r\n    assert os.path.splitext(model_file)[1] == '.pb', 'File {} is not TF model'.format(model_file)\r\n\r\n    converter  = tf1.lite.TFLiteConverter.from_frozen_graph(\r\n                    model_file,\r\n                    input_arrays=['input_images'],\r\n                    output_arrays=['classification_result'],\r\n                    input_shapes={\"input_images\": [1, input_img_size, input_img_size, 3]})\r\n    if quantized: # enable quantization\r\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n        rep = Representative_data(input_img_size)\r\n        converter.representative_dataset = rep.data_gen\r\n    tflite_net = converter.convert()\r\n    return tflite_net\r\n\r\ndef tf2lite_save(model_file, input_img_size, save_file, quantized=False):\r\n    net = tf2lite(model_file, input_img_size, quantized)\r\n    with open(save_file, 'wb') as f:\r\n        f.write(net)\r\n\r\nfrozen_file = './frozen_imgsize_{}.pb'.format(224)\r\ntflite_file = './converted_imgsize_{}.tflite'.format(224)\r\ntf2lite_save(frozen_file, 224, tflite_file, quantized=True)\r\n\r\n# Verify TFLite model vs TF model\r\nlite_model = tf.lite.Interpreter(model_path=tflite_file)\r\nlite_model.allocate_tensors()\r\ninput_details = lite_model.get_input_details()\r\noutput_details = lite_model.get_output_details()\r\nlite_model.set_tensor(input_details[0]['index'], tf_input)\r\nlite_model.invoke()\r\nlite_classify = lite_model.get_tensor(output_details[0]['index'])\r\nprint('TFLite: prediction={}'.format(np.argmax(lite_classify)))\r\nprint(lite_classify)\r\nassert np.argmax(lite_classify) == 20\r\n```\r\n\r\nI miss out two things:\r\n1. tf_input is No.1000 picture in ImageNet validation dataset whose correct classification index should be 20. I did the following picture transformation.\r\n- resize picture size to 256\r\n- center crop 224\r\n- normalize with   mean=[0.485, 0.456, 0.406],\r\n                            std=[0.229, 0.224, 0.225]\r\n\r\n2. Representative_data class has too much code to upload. It is a ImageNet data loader which read val data and give 100 samples randomly for quantization to use. the image preprocessing is the same as above.\r\n\r\nIf we modify the above code to \r\ntf2lite_save(frozen_file, 224, tflite_file, quantized=False)\r\n\r\nIt will pass with correct result (see converted_imgsize_224_unquantized.tflite and log.txt). Otherwise, it will produce almost all 0 with incorrect classification (see converted_imgsize_224_quantized.tflite and log.txt).\r\n\r\nPlease help me to figure out what I did wrong. Many thanks.\r\n\r\n\r\n\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n[frozen_imgsize_224.pb.txt](https://github.com/tensorflow/tensorflow/files/4672384/frozen_imgsize_224.pb.txt)\r\n[converted_imgsize_224_unquantized.tflite.txt](https://github.com/tensorflow/tensorflow/files/4672386/converted_imgsize_224_unquantized.tflite.txt)\r\n[converted_imgsize_224_quantized.tflite.txt](https://github.com/tensorflow/tensorflow/files/4672387/converted_imgsize_224_quantized.tflite.txt)\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/4672396/log.txt)\r\n\r\n\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["oops! I just notice that the frozen graph that I upload is incorrect. Reload:\r\n[frozen_imgsize_224.pb.txt](https://github.com/tensorflow/tensorflow/files/4672412/frozen_imgsize_224.pb.txt)\r\n", "@lucaoyuan  \r\nThe text shared is not in readable format, you can share a colab gist for us to analyse the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39821, "title": "[Lite]: Fix memory leak from model", "body": "Signed-off-by: Gaurav Singh <gaurav1086@gmail.com>\r\nDelete model to avoid memory leak.", "comments": []}, {"number": 39819, "title": "not able to run %tensorboard --logdir logs\\fit", "body": "TypeError                                 Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py in __call__(self, obj)\r\n    691                 type_pprinters=self.type_printers,\r\n    692                 deferred_pprinters=self.deferred_printers)\r\n--> 693             printer.pretty(obj)\r\n    694             printer.flush()\r\n    695             return stream.getvalue()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py in pretty(self, obj)\r\n    377                             meth = cls._repr_pretty_\r\n    378                             if callable(meth):\r\n--> 379                                 return meth(obj, self, cycle)\r\n    380             return _default_pprint(obj, self, cycle)\r\n    381         finally:\r\n\r\nTypeError: _repr_pretty_() takes 1 positional argument but 3 were given\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py in __call__(self, obj)\r\n    691                 type_pprinters=self.type_printers,\r\n    692                 deferred_pprinters=self.deferred_printers)\r\n--> 693             printer.pretty(obj)\r\n    694             printer.flush()\r\n    695             return stream.getvalue()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py in pretty(self, obj)\r\n    377                             meth = cls._repr_pretty_\r\n    378                             if callable(meth):\r\n--> 379                                 return meth(obj, self, cycle)\r\n    380             return _default_pprint(obj, self, cycle)\r\n    381         finally:\r\n\r\nTypeError: _repr_pretty_() takes 1 positional argument but 3 were given\r\n", "comments": ["@prashkjha,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39818, "title": "tensorflow cannot use feature columns to keras model", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://tensorflow.google.cn/versions/r2.1/api_docs/python/tf/feature_column/numeric_column\r\n\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI tried to input a feature column to the keras model, but it was not available and the error was as follows:\r\n\r\n```\r\n    input_wide2 = keras.layers.Dense(300, activation=dnn_activation, )(input_lstm)\r\n  File \"/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 818, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2098, in _maybe_build\r\n    self.input_spec, inputs, self.name)\r\n  File \"/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 163, in assert_input_compatibility\r\n    if x.shape.ndims is None:\r\nAttributeError: 'DenseFeatures' object has no attribute 'shape'\r\n```\r\n\r\nI tried to search the solution of the problem through google, and the answer I got was to use tf.keras.Sequential () to solve the problem, but my model cannot use tf.keras.Sequential (), because I need to make a multi-input and more complex model . Sequential () cannot meet my requirements. Is this error a bug? Or am I using the wrong method? My case\r\n[text.txt](https://github.com/tensorflow/tensorflow/files/4672214/text.txt)\r\n code is as follows\r\n\r\n\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow import feature_column\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras import Input, Model\r\nfrom tensorflow.keras import regularizers\r\nimport tensorflow as tf\r\n\r\n\r\ndef read_tfrecord_input( tf_dir, batch_size, df_columns_list, which_labels, output_size):\r\n    raw_dataset = tf.data.TFRecordDataset(tf_dir)\r\n    feature_description = {}\r\n\r\n    def _parse_function(record):\r\n        for n in df_columns_list:\r\n\r\n            # if n =='KDJ_gold':                            \r\n[text.txt](https://github.com/tensorflow/tensorflow/files/4672218/text.txt)\r\n\r\n            #     feature_description['%s'%n]=tf.io.FixedLenFeature([], tf.string, default_value='')\r\n            if 'pred' in n:\r\n                pass\r\n            else:\r\n                feature_description['%s' % n] = tf.io.FixedLenFeature([], tf.float32, default_value=0.0)\r\n            feature_description['pred'] = tf.io.FixedLenFeature([output_size], tf.float32)\r\n\r\n        parsed = tf.io.parse_single_example(serialized=record, features=feature_description)\r\n\r\n        labels = parsed['pred']\r\n        # kdj_gold = tf.cast(parsed['KDJ_gold'], tf.string)\r\n        input_dict = {}\r\n        for n in df_columns_list:\r\n            if 'pred' in n:\r\n                print(n, 'pass')\r\n                pass\r\n            # elif n=='KDJ_gold':\r\n            #     input_dict['%s'%n]=kdj_gold                \r\n            else:\r\n                input_dict['%s' % n] = parsed['%s' % n]\r\n        return input_dict, labels\r\n\r\n    parsed_dataset = raw_dataset.map(_parse_function, num_parallel_calls=24)  \r\n    parsed_dataset = parsed_dataset.batch(batch_size, drop_remainder=True)\r\n    parsed_dataset = parsed_dataset.repeat()\r\n\r\n    return parsed_dataset\r\ndropout_rate=0.5\r\ndnn_activation='relu'\r\nvolume = tf.feature_column.numeric_column('volume', shape=(1,))\r\nlstm_list=[volume]\r\n\r\ninput_deep = keras.layers.DenseFeatures(lstm_list)\r\ninput_lstm = keras.layers.DenseFeatures(lstm_list)\r\ninput_wide2 = keras.layers.Dense(300, activation=dnn_activation, )(input_lstm)\r\ninput_wide2 = keras.layers.Dropout(0.5)(input_wide2)\r\nlstm = keras.layers.LSTM(units=300, return_sequences=True, return_state=True, activation='tanh')\r\nwhole_seq_output, final_memory_state, final_carry_state = lstm(input_wide2)\r\nlstm_drop_layer = keras.layers.Dropout(0.5)(whole_seq_output)\r\n\r\ndnn1 = keras.layers.Dense(units=800, activation=dnn_activation)(input_deep)\r\ndnn1 = keras.layers.BatchNormalization(axis=1)(dnn1)\r\ndnn1 = keras.layers.SpatialDropout1D(dropout_rate)(dnn1)\r\ndnn2 = keras.layers.Dense(units=600, activation=dnn_activation)(dnn1)\r\n\r\ncancat_all = keras.layers.concatenate([dnn2, lstm_drop_layer])\r\noutput = keras.layers.Dense(1, activation='tanh')(cancat_all)\r\nmodel = Model(inputs=[input_lstm, input_deep], outputs=[output])\r\n\r\nmodel.compile(loss=\"mae\", optimizer=\"Adam\")\r\nestimatoer = keras.estimator.model_to_estimator(keras_model=model, model_dir='model/ld')\r\nestimatoer.train(input_fn=lambda: read_tfrecord_input(\r\n    tf_dir='data/train.tfrecord', batch_size=9600, df_columns_list=lstm_list,\r\n    which_labels='pred_d', output_size=1), max_steps=500)\r\n```\r\n\r\nplease help me ,thank you!!\r\n\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@anavanab99 \r\nCan you share a simple stand alone code that replicates your issue, indented code.", "> @anavanab99\r\n> Can you share a simple stand alone code that replicates your issue, indented code.\r\n\r\nOk, I have uploaded the code in txt format, if you can't receive it, you can give me your email address. Thank you.\r\n\r\n[the_code.txt](https://github.com/tensorflow/tensorflow/files/4683301/the_code.txt)\r\n\r\n", "@anavanab99 \r\nI ran the code shared by you and face [this error](https://colab.sandbox.google.com/gist/Saduf2019/266a4d82f620d7d8a2298b2ef4f1c83e/untitled200.ipynb), please share all dependencies.\r\n", "> @anavanab99\r\n> I ran the code shared by you and face [this error](https://colab.sandbox.google.com/gist/Saduf2019/266a4d82f620d7d8a2298b2ef4f1c83e/untitled200.ipynb), please share all dependencies.\r\nOkay, I use anaconda to configure the tensorflow environment, which is all my environment dependent files\r\n[tf2_env.txt](https://github.com/tensorflow/tensorflow/files/4683463/tf2_env.txt)\r\n\r\n", "> @anavanab99\r\n> I ran the code shared by you and face [this error](https://colab.sandbox.google.com/gist/Saduf2019/266a4d82f620d7d8a2298b2ef4f1c83e/untitled200.ipynb), please share all dependencies.\r\n@Saduf2019 \r\n[tf2_env.txt](https://github.com/tensorflow/tensorflow/files/4686151/tf2_env.txt)\r\n\r\nOkay, I use anaconda to configure the tensorflow environment, which is all my environment dependent files\r\n", "@anavanab99 \r\nThe error is face is because the training data is missing, which needs to be shared for us to replicate.", "> @anavanab99\r\n> The error is face is because the training data is missing, which needs to be shared for us to replicate.\r\n\r\nThis error is not a lack of training data. I do not want to train a neural network that can be used, but I want to make this program run even if it can not fit pred or loss nan. I solved some errors through the following methods.\r\nthe code: \r\n[feature_columns_solve.txt](https://github.com/tensorflow/tensorflow/files/4702368/feature_columns_solve.txt)\r\n\r\nBy using this method ,feature columns like categorical_column_with_hash_bucket can already run smoothly.\r\n\r\nHowever, using the same method,   feature columns such as sequence_categorical_column_with_hash_bucket that with **sequence** still cannot run.\r\nIts error is as follows\r\nValueError: The two structures don't have the same nested structure.\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(None,), dtype=tf.float64, name=None)\r\n\r\nSecond structure: type=SparseTensor str=SparseTensor(indices=Tensor(\"volume/indices:0\", shape=(None, 2), dtype=int64), values=Tensor(\"volume/values:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"volume/shape:0\", shape=(2,), dtype=int64))\r\n\r\nMore specifically: Substructure \"type=SparseTensor str=SparseTensor(indices=Tensor(\"volume/indices:0\", shape=(None, 2), dtype=int64), values=Tensor(\"volume/values:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"volume/shape:0\", shape=(2,), dtype=int64))\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(None,), dtype=tf.float64, name=None)\" is not\r\nEntire first structure:\r\n\r\n\r\nmycode\uff1a\r\n[my_code.txt](https://github.com/tensorflow/tensorflow/files/4702404/my_code.txt)\r\n\r\nThank you.\r\n\r\n", "This is similar to this question [here](https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model) where the workaround has been provided.", "> This is similar to this question [here](https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model) where the workaround has been provided.\r\nYes, this problem is indeed very similar, but he can only solve the feature series of dense layers. It is used to input the **sequence** characteristic column of the lstm layer, which cannot be run by this method. You can try my code. There will be an error that I cannot understand. thank you very much\r\n[my_code.txt](https://github.com/tensorflow/tensorflow/files/4708173/my_code.txt)\r\n\r\n", "> This is similar to this question [here](https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model) where the workaround has been provided.\r\n\r\n\r\n\r\n> This is similar to this question [here](https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model) where the workaround has been provided.\r\n@Saduf2019 \r\nHello, my problem has not been solved, is it forgotten? Thank you\r\n\r\n", "@anavanab99\r\nIs this still an issue, can you please try on tf-nigtly and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39818\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39818\">No</a>\n"]}, {"number": 39817, "title": "AttributeError: 'Tensor' object has no attribute 'numpy'", "body": "I use tensorflow with Google Colaboratory\r\nI have TensorFlow 2.x selected.\r\n\r\nI wrote a small error metrics but could not succeed to transform the result to numpy array.\r\nI got AttributeError: 'Tensor' object has no attribute 'numpy'\r\n\r\nI thought I could transform my tensor to numpy array with a .numpy() call\r\n\r\n```\r\ndef custom__error(y_true, y_pred):\r\n  # ---- y_pred\r\n  yp = tf.nn.softmax( y_pred)\r\n  bp = tf.argsort(yp,axis=-1,direction='DESCENDING',stable=False,name=None)\r\n  #cp = bp.numpy()\r\n  xcp = bp[None,:10]\r\n  # ---- y_true\r\n  yt = tf.nn.softmax( y_true )\r\n  bt = tf.argsort(yt,axis=-1,direction='DESCENDING',stable=False,name=None)\r\n  #ct = bt.numpy()\r\n  xct = bt[None,:10]\r\n  # ---- common\r\n  count =  tf.sets.intersection(xcp,xct)\r\n  dcount = tf.sparse.to_dense(count)\r\n  return dcount.numpy()\r\n```\r\n```\r\n<ipython-input-46-10646c4f8b46> in custom__error(y_true, y_pred)\r\n     15   count =  tf.sets.intersection(xcp,xct)\r\n     16   dcount = tf.sparse.to_dense(count)\r\n---> 17   return dcount.numpy()\r\n     18 \r\n     19 \r\n\r\nAttributeError: 'Tensor' object has no attribute 'numpy'\r\n```\r\n\r\n", "comments": ["> I use tensorflow with Google Colaboratory\r\n> I have TensorFlow 2.x selected.\r\n> \r\n> I wrote a small error metrics but could not succeed to transform the result to numpy array.\r\n> I got AttributeError: 'Tensor' object has no attribute 'numpy'\r\n> \r\n> I thought I could transform my tensor to numpy array with a .numpy() call\r\n> \r\n> ```\r\n> def custom__error(y_true, y_pred):\r\n>   # ---- y_pred\r\n>   yp = tf.nn.softmax( y_pred)\r\n>   bp = tf.argsort(yp,axis=-1,direction='DESCENDING',stable=False,name=None)\r\n>   #cp = bp.numpy()\r\n>   xcp = bp[None,:10]\r\n>   # ---- y_true\r\n>   yt = tf.nn.softmax( y_true )\r\n>   bt = tf.argsort(yt,axis=-1,direction='DESCENDING',stable=False,name=None)\r\n>   #ct = bt.numpy()\r\n>   xct = bt[None,:10]\r\n>   # ---- common\r\n>   count =  tf.sets.intersection(xcp,xct)\r\n>   dcount = tf.sparse.to_dense(count)\r\n>   return dcount.numpy()\r\n> ```\r\n> \r\n> ```\r\n> <ipython-input-46-10646c4f8b46> in custom__error(y_true, y_pred)\r\n>      15   count =  tf.sets.intersection(xcp,xct)\r\n>      16   dcount = tf.sparse.to_dense(count)\r\n> ---> 17   return dcount.numpy()\r\n>      18 \r\n>      19 \r\n> \r\n> AttributeError: 'Tensor' object has no attribute 'numpy'\r\n> ```\r\n\r\nIt works fine for me. This usually happens in older version of tensorflow where you have to enable eager execution. Are you sure that tensorflow version is >= 2.x?", "Hello abhipn\r\nI wrote\r\n`%tensorflow_version 2.x`\r\nAnd got\r\n```\r\n`%tensorflow_version` only switches the major version: 1.x or 2.x.\r\nYou set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\r\n\r\nTensorFlow 2.x selected.\r\n```\r\nIf you want to check\r\n[https://colab.research.google.com/drive/14TC0Hgf_aKtSTwlZvUKMlVYZUdvUuVJv?usp=sharing](url)", "@Harvey13 Can you provide minimal reproducible notebook so I can execute the code and get the error you are facing?\r\n\r\nYou can try this example code here, it works just fine for me\r\n\r\n```\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\nsparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\r\n                                       values=[1, 2],\r\n                                       dense_shape=[3, 4])\r\n\r\n# We can convert sparse tensors to dense\r\nprint(tf.sparse.to_dense(sparse_tensor).numpy())\r\n```", "@Harvey13 \r\n\r\nRequest you to provide colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "[https://colab.research.google.com/drive/12fkayzNa0uOIRkKJYsZ0J7VjwS0P-BXd?usp=sharing](url)", "My problem is only inside a callback function (tf backend)\r\n[https://colab.research.google.com/drive/1wFKDQjlPuB0ax0g-ZSU8ge1ukzBBn3TR?usp=sharing](url)", "Access for everyone with the link", "@Harvey13 I was able to replicate the issue and I believe it is not possible to extract numpy arrays in Keras loss functions (or) metrics. You have to operate on tensors using either keras backend functions or tensorflow functions but not using numpy to calculate the loss. ", "@Harvey13 \r\n\r\nCan you please provide correct colab link to understand the issue better.Thanks!", "@ravikyram \r\n[https://colab.research.google.com/drive/1wFKDQjlPuB0ax0g-ZSU8ge1ukzBBn3TR?usp=sharing](https://colab.research.google.com/drive/1wFKDQjlPuB0ax0g-ZSU8ge1ukzBBn3TR?usp=sharing)\r\n\r\nI don't know why the link stopped working\r\nLook like a github problem : when copied in address bar it works ...", "I have tried in colab with TF 2.2 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d8858bca32d165a6091d4558d269597a/untitled43.ipynb).Thanks!", "I have tried in TF nightly version`(2.3.0-dev20200526`) and i am seeing below error message`.AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'`.Please, find the gist [here.](https://colab.research.google.com/gist/ravikyram/597eacdc5051d3368b7ce7740b50dfb8/untitled43.ipynb#scrollTo=umFa7Ez8wr46)Thanks!", "@Harvey13 Looks like this was resolved. I am not able to reproduce the issue. Can you please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/eb63a5055c5c04903f0c672fae789dec/untitled43.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan The gist works fine, even with original custom__error function.\r\nUnfortunatly my own project, no more works, even without numpy() call inside backend function : it's a new bug because it was working fine former the nightlty installed\r\n\r\nI tried differents old projects they all have the same error with tf-nightly 2.3.0-dev20200605\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-45-2a71bdab68f1> in <module>()\r\n----> 1 model = make_model()\r\n      2 print(str(training_data_width) + \"=>\" + str(target_data_width))\r\n      3 model.compile(loss=custom__loss, optimizer='adam', metrics=['binary_accuracy','accuracy',custom__error])\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in is_tensor(x)\r\n    701 \r\n    702 def is_tensor(x):\r\n--> 703     return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\r\n    704 \r\n    705 \r\n\r\nAttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'\r\n```", "\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n> Message du 06/06/20 09:40> De : \"Vishnuvardhan Janapati\" > A : \"tensorflow/tensorflow\" > Copie \u00e0 : \"Harvey13\" , \"Mention\" > Objet : Re: [tensorflow/tensorflow] AttributeError: 'Tensor' object has no attribute 'numpy' (#39817)> >\n>\n> @Harvey13 Looks like this was resolved. I am not able to reproduce the issue. Can you please check the gist here. Thanks!\n> Please verify once and close the issue if this was resolved for you. Thanks!\n\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or unsubscribe.\n[ { \"@context\": \"http://schema.org\", \"@type\": \"EmailMessage\", \"potentialAction\": { \"@type\": \"ViewAction\", \"target\": \"https://github.com/tensorflow/tensorflow/issues/39817#issuecomment-640005373\", \"url\": \"https://github.com/tensorflow/tensorflow/issues/39817#issuecomment-640005373\", \"name\": \"View Issue\" }, \"description\": \"View this Issue on GitHub\", \"publisher\": { \"@type\": \"Organization\", \"name\": \"GitHub\", \"url\": \"https://github.com\" } } ]", "@Harvey13 When error description include `'_TensorLike'`, then mostly it is due to using mixing of functions from `keras` and `tf.keras` in the code. Can you please share a standalone code that is throwing an error. Thanks!", "@jvishnuvardhan\nHello\nYou were right I do have a mixture\nAfter corrections I have no more errors\nThank you\n\u00a0", "@Harvey13 I am closing this issue as you confirmed that the issue was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39817\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39817\">No</a>\n", "how to have a mixture?"]}, {"number": 39816, "title": "no specification for blank index for ctc_batch_cost", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\nhttps://tensorflow.google.cn/api_docs/python/tf/keras/backend/ctc_batch_cost\r\n\r\n## Description of issue (what needs changing):\r\n\r\nthere is no specification for blank index. I can see default blank index for tf.nn.ctc_loss from [here](https://tensorflow.google.cn/api_docs/python/tf/nn/ctc_loss). is tf.keras.backend.ctc_batch_cost uses the same token for blank index? the old keras interface use a different default blank index. so, I am not sure about tf.keras's ctc_batch_cost's behavior.\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\nthe specification is important for people building recurrent neural network with tf.keras interfaces.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\nyes.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\nyes.\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\nyes.\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\nno.\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\nno.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\nno.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n\r\nno.", "comments": ["Hi @breadbread1984, sorry for the late response here. I'm not seeing the `tf.keras.backend.ctc_batch_cost` symbol in 2.4\r\nLet me know if I'm missing something, or if we should close this issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39815, "title": "tf.debugging.assert_near raises InvalidArgumentError for complex tensors", "body": "**System information**\r\n- Linux (different setups), other OS not tested\r\n- tensorflow-cpu installed from pip\r\n- TensorFlow version 2.2.0\r\n- Python version 3.8.3\r\n\r\n**Describe the current behavior**\r\n`tf.debugging.assert_near` raises `InvalidArgumentError` for `complex64` or `complex128` inputs, although the documentation says complex inputs are allowed.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf  \r\na = tf.constant([1j], dtype=tf.complex64) \r\nb = tf.constant([1j], dtype=tf.complex64) \r\ntf.debugging.assert_near(a, b)  \r\n```\r\n\r\n**Output** \r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-7-ddb632344d16> in <module>\r\n----> 1 tf.debugging.assert_near(a, b)\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py in assert_near_v2(x, y, rtol, atol, message, summarize, name)\r\n    756   @end_compatibility\r\n    757   \"\"\"\r\n--> 758   return assert_near(x=x, y=y, rtol=rtol, atol=atol, summarize=summarize,\r\n    759                      message=message, name=name)\r\n    760 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py in assert_near(x, y, rtol, atol, data, summarize, message, name)\r\n    833           'x (%s) = ' % x_name, x, 'y (%s) = ' % y_name, y\r\n    834       ]\r\n--> 835     tol = atol + rtol * math_ops.abs(y)\r\n    836     diff = math_ops.abs(x - y)\r\n    837     condition = math_ops.reduce_all(math_ops.less(diff, tol))\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    982     with ops.name_scope(None, op_name, [x, y]) as name:\r\n    983       if isinstance(x, ops.Tensor) and isinstance(y, ops.Tensor):\r\n--> 984         return func(x, y, name=name)\r\n    985       elif not isinstance(y, sparse_tensor.SparseTensor):\r\n    986         try:\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in _mul_dispatch(x, y, name)\r\n   1281   is_tensor_y = isinstance(y, ops.Tensor)\r\n   1282   if is_tensor_y:\r\n-> 1283     return gen_math_ops.mul(x, y, name=name)\r\n   1284   else:\r\n   1285     assert isinstance(y, sparse_tensor.SparseTensor)  # Case: Dense * Sparse.\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py in mul(x, y, name)\r\n   6087         pass  # Add nodes to the TensorFlow graph.\r\n   6088     except _core._NotOkStatusException as e:\r\n-> 6089       _ops.raise_from_not_ok_status(e, name)\r\n   6090   # Add nodes to the TensorFlow graph.\r\n   6091   _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   6651   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6652   # pylint: disable=protected-access\r\n-> 6653   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6654   # pylint: enable=protected-access\r\n   6655 \r\n\r\n/usr/lib/python3.8/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a complex64 tensor but is a float tensor [Op:Mul]\r\n\r\n```", "comments": ["Added a PR #39825 for complex tensor support.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39815\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39815\">No</a>\n"]}, {"number": 39814, "title": "tf.random.uniform array minval/maxval with dtype=tf.int*", "body": "Hi,\r\n\r\nThe current implementation of `tf.random.uniform` allows for non-scalar `minval` and `maxval` if `dtype=tf.float32` (or `tf.float64`).  However, this is not the case for `dtype=tf.int32` (or `tf.int64`).\r\n\r\ne.g.\r\n```python\r\ntf.random.uniform(shape=(), minval=[0, 0], maxval=[10, 10], dtype=tf.int32)\r\nValueError: minval must be a scalar; got a tensor of shape [2] ....\r\n```\r\ngenerates a `ValueError` whereas\r\n```python\r\ntf.random.uniform(shape=(), minval=[0., 0.], maxval=[10., 10.], dtype=tf.float32)\r\ntf.Tensor([5.918947 5.918947], shape=(2,), dtype=float32)\r\n```\r\nworks as expected.\r\n\r\nThe documentation doesn't indicate that the integer version of `tf.random.uniform` has this restriction.  Is it expected behaviour, and if so what is the workaround?\r\n\r\nThanks,\r\n\r\nChris\r\n\r\n----\r\nTF version 2.3.0-dev20200521 (tf-nightly)\r\nPython 3.7.6 (Anaconda 3)\r\n", "comments": ["@chrism0dwk The ValueError should be the correct behavior, as `shape=()` expect minval and maxval to be a scalar.\r\n\r\nThe behavior of the float32 type is actually incorrect, and should have thrown out the same error as well. The issue is being fixed in #34363 #38585", "Ah, I see.  Thanks.  From the doc of `minval` and `maxval`, \"for integer types, broadcasting is not supported, so it needs to be a scalar\".  I guess this means that `minval` and `maxval` are therefore intended to be scalars at least for Uniform integers.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39814\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39814\">No</a>\n"]}, {"number": 39813, "title": "can't convert a string tensor to  python string when using Dataset.list_files(PATH).map(fun)", "body": "![image](https://user-images.githubusercontent.com/63587875/82728893-e59f6200-9d25-11ea-9f30-297c82594922.png)\r\n\r\nas showed in the image. the wavPath is Tensor(\"args_0:0\", shape=(), dtype=string). and then librosa.load(wavPath) raise error. there is noway to convert Tensor(\"args_0:0\", shape=(), dtype=string) to the correct python string path\r\n", "comments": ["@rick-wang-musetalk,\r\nIn order to reproduce the issue reported here, could you please provide the complete code, the dataset and TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39812, "title": "ruy optimized library enabling for tf-lite", "body": "Per blog [What\u2019s new in TensorFlow Lite](https://blog.tensorflow.org/2020/04/whats-new-in-tensorflow-lite-from-devsummit-2020.html) there's supposed to be developed an optimized matrix multiplication library  [(ruy).](https://github.com/google/ruy)\r\n\r\nHow to check if this ([ruy](https://github.com/google/ruy)) optimized library is enabled during a build (compilation) from the source or how to check or make sure it's either enabled or disabled?\r\n", "comments": ["@peter197321 \r\nPlease refer to [this link](https://stackoverflow.com/questions/28188833/how-to-know-the-optimzation-options-used-to-build-a-shared-library-in-c) l[ink1](https://developer.android.com/studio/build/optimize-your-build) and let us know if this helps.", "Unfortunately, it does not really help much :(  I am looking for a way to check if the lib has been compiled with \"ruy\" option (a version of ruy) and want to check if this option has been applied (enabled) during a build process.  I guess this requires to build particularly library with option `-frecord-gcc-switches`\r\n\r\nI applied `readelf -a` to binary file used where I found some versions info\r\n\r\nsnippet :\r\n```\r\nVersion needs section '.gnu.version_r' contains 9 entries:\r\n Addr: 0x00000000002eba48  Offset: 0x2eba48  Link: 4 (.dynstr)\r\n  000000: Version: 1  File: libgcc_s.so.1  Cnt: 1\r\n  0x0010:   Name: GCC_3.0  Flags: none  Version: 24\r\n  0x0020: Version: 1  File: ld-linux-x86-64.so.2  Cnt: 1\r\n  0x0030:   Name: GLIBC_2.3  Flags: none  Version: 23\r\n  0x0040: Version: 1  File: libcudart.so.10.0  Cnt: 1\r\n  0x0050:   Name: libcudart.so.10.0  Flags: none  Version: 15\r\n  0x0060: Version: 1  File: libm.so.6  Cnt: 1\r\n  0x0070:   Name: GLIBC_2.2.5  Flags: none  Version: 14\r\n  0x0080: Version: 1  File: libpthread.so.0  Cnt: 1\r\n  0x0090:   Name: GLIBC_2.2.5  Flags: none  Version: 12\r\n  0x00a0: Version: 1  File: libstdc++.so.6  Cnt: 14\r\n  0x00b0:   Name: GLIBCXX_3.4.14  Flags: none  Version: 29\r\n  0x00c0:   Name: CXXABI_1.3.8  Flags: none  Version: 27\r\n  0x00d0:   Name: GLIBCXX_3.4.17  Flags: none  Version: 26\r\n  0x00e0:   Name: GLIBCXX_3.4.19  Flags: none  Version: 25\r\n  0x00f0:   Name: CXXABI_1.3.5  Flags: none  Version: 22\r\n  0x0100:   Name: CXXABI_1.3.7  Flags: none  Version: 21\r\n  0x0110:   Name: GLIBCXX_3.4.15  Flags: none  Version: 17\r\n  0x0120:   Name: GLIBCXX_3.4.18  Flags: none  Version: 16\r\n  0x0130:   Name: GLIBCXX_3.4.9  Flags: none  Version: 13\r\n  0x0140:   Name: GLIBCXX_3.4.11  Flags: none  Version: 11\r\n  0x0150:   Name: CXXABI_1.3  Flags: none  Version: 10\r\n  0x0160:   Name: GLIBCXX_3.4.20  Flags: none  Version: 9\r\n  0x0170:   Name: GLIBCXX_3.4  Flags: none  Version: 8\r\n  0x0180:   Name: GLIBCXX_3.4.21  Flags: none  Version: 6\r\n  0x0190: Version: 1  File: libdl.so.2  Cnt: 1\r\n  0x01a0:   Name: GLIBC_2.2.5  Flags: none  Version: 5\r\n  0x01b0: Version: 1  File: libcudnn.so.7  Cnt: 1\r\n  0x01c0:   Name: libcudnn.so.7  Flags: none  Version: 4\r\n  0x01d0: Version: 1  File: libc.so.6  Cnt: 6\r\n  0x01e0:   Name: GLIBC_2.7  Flags: none  Version: 28\r\n  0x01f0:   Name: GLIBC_2.3.4  Flags: none  Version: 20\r\n  0x0200:   Name: GLIBC_2.4  Flags: none  Version: 19\r\n  0x0210:   Name: GLIBC_2.6  Flags: none  Version: 18\r\n  0x0220:   Name: GLIBC_2.2.5  Flags: none  Version: 7\r\n  0x0230:   Name: GLIBC_2.11  Flags: none  Version: 3\r\n\r\n```\r\n\r\nSo what either would see if ruy used or other methods to check with?\r\nWhat if I use a python - which library to check?\r\n\r\nanyway - I'll investigate more :)\r\n", "Hi,\r\n\r\nHopefully I can help you but I just want to make sure I understand the case you are interested in. Please add additional clarification if my answers below don't help. My understanding is that you are concerned with enabling/detecting enablement of Ruy in (at least) one of the following scenarios:\r\n\r\n1. Create a build of TF Lite that has Ruy enabled.\r\n\r\nAnswer: with a bazel build, add the command line flag `--define=tflite_with_ruy=true` to the bazel build command. This is already the default for ARM builds, but it does no harm to add it.  For Makefile-based builds, ensure that `-DTFLITE_WITH_RUY` is added to CXXFLAGS, as shown here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/580219546f81b50a0e627d29d8e36ab2245578a5/tensorflow/lite/tools/make/Makefile#L184\r\n\r\n2. You have a TFLite binary from somewhere and wish to inspect it to see if Ruy is enabled without executing the binary.\r\nAnswer: there's no supported way to do this, but one could imagine a few ideas.\r\n\r\n3. You have the TF Lite library linked to your application and you wish to, at run time, determine if Ruy is being used for matrix multiplication.\r\nAnswer: there is also no supported way to check here, i.e. a flag of some kind, but you can always compile with `-DRUY_PROFILER` and then run your program to make sure you get Ruy for the expected GEMM operations. The output at the end of program execution will tell you which GEMMs were done with Ruy (with size info) as well as what Ruy path was selected and how much time was spent on various parts of the GEMM operation.\r\n\r\nDoes that help?", "Thank you. \r\nIs it apply for the Cross-compile build of TensorFlow Lite for ARM64 board?"]}, {"number": 39811, "title": "ResourceExhaustedError with a RNN compiled with XLA", "body": "Hi,\r\n\r\nI experimented with a custom RNN compilation with XLA and I hit OOM with only a single layer RNN (used LayerNormLSTMCell cell).\r\n\r\nRepro in collab (tested on tf-nightly)  https://colab.research.google.com/drive/1YWfuRX72A-819S_YqFZ0A0BNBAR5cTFv?usp=sharing\r\nI understand that XLA maybe more memory hungry than cuDNN LSTM implementation, but its relatively small model to not fit to one GPU (single-layer layernorm LSTM with 1536 units)", "comments": ["@EgorLakomkin \r\n\r\nRequest you to provide us the access for the colab link you have given.Thanks!", "Sorry, should work now!", "@EgorLakomkin \r\n\r\nI have tried in colab with TF nightly version.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ef80fccfb02b8328a6dcc1dbaa5269d2/untitled40.ipynb).Is this the expected behavior? Thanks!", "Hi @ravikyram, I am getting ResourceExhaustedError as it looks like 15GB of GPU memory is asked to be allocated", "I've looked at the issue briefly. At the peak (at least) a 10GB array is alive, so while 15GB is excessive and we could do better (as shown by TF), it's not completely outside of the scope of reasonable.", "Though it is kind of strange that without XLA compilation, <200MB are seemingly used. Investigating further.", "The underlying issue is how tf2xla represents stacks as tensors instead of an array of pointers to tensors. When this interacts with an rnn, every matmul pushes the lhs and rhs operands onto a stack. In the case of a matmul the RNN is an unchanging ReadVariableOp. In native tf this would be a stack of the same pointer. in XLA this ends up the weights of the model replicated by sequence length.", "@cheshire Right, this was mainly the reason for filing this ticket, that the memory consumption was much larger than expected. ", "@EgorLakomkin what Blake is saying is correct, fixing this would require large non-trivial changes to tf2xla conversion (from what I understand, in practice users who wish to use XLA end up changing their model to make it more suitable for compilation). ", "I see, many thanks! Is there are any examples of using RNN-like architectures with XLA? Just trying to get an idea of how the model is needed to be changed to be more suitable for compilation.", "Sorry I don't really know, maybe @blakehechtman could provide more details?", "@EgorLakomkin Could you please try on the latest TF version 2.7.0 and let us know if it helps?Thanks!", "I was getting different error in TF 2.7 . Attaching [Gist](https://colab.sandbox.google.com/gist/mohantym/0782670ce2dbad63233510b4e8e7a9d0/xla_oom.ipynb#scrollTo=kpu9ge8Oand_) for reference. Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39810, "title": "Introduce a groundtruths argument in the call method of tf.keras.layer", "body": "**System information**: Ubuntu 16.04\r\n- TensorFlow version (you are using): 2.2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nToday, the API only support three arguments (inputs, training, masks):\r\n\r\n```python\r\nclass MyNetwork(tf.keras.layers.Layer):\r\n\r\n  def call(self, inputs, training=None):  \r\n     # Do somestuff\r\n      return stuff\r\n```\r\n\r\nI propose to introduce a fourth one (groundtruths or other):\r\n\r\n```python\r\nclass MyNetwork(tf.keras.layers.Layer):\r\n\r\n  def call(self, inputs, training=None, groundtruths=None):  \r\n     # Do somestuff\r\n      return stuff\r\n```\r\n\r\nYou could tell: why don't you put your groundtruths inside the inputs? It leads to issue with the SavedModel format. My inputs in training and inference won't be the same which leads to errors.\r\n\r\nExample:\r\n\r\n```python\r\ntraining_inputs = {'image': tf.zeros((1, 800, 800, 3)), 'gt_bbox':  tf.constant([[0, 0, 1, 1]], tf.float32)}\r\ninference_inputs = {'image': tf.zeros((1, 800, 800, 3))}\r\n```\r\n**Will this change the current api? How?**\r\n\r\nIt will change the interface of the `call` method from `tf.keras.layers.Layer`.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nPeople working on algorithms like FasterRCNN need to pass during the training the groundtruths \r\nto perform sampling on it. Currently you need to perform lot of hacks to be able to export your model.\r\n\r\n**Any Other info.**\r\n\r\nMaybe adding new arguments to the call method isn't the right way. Allowing saved_model to understand that you have two types of signatures, when training is True or False, for your model would be great.  It would make the following behavior compatible to saved_model.\r\n\r\nExample:\r\n\r\n```python\r\nclass MyNetwork(tf.keras.Model):\r\n\r\n  def call(self, inputs, training=None):  \r\n     if training:\r\n          groundtruths = inputs['groundtruths']\r\n          # Do somestuff with the groundtruths\r\n      return stuff\r\n\r\n    def train_step(self, data):\r\n        data = data_adapter.expand_1d(data)\r\n        x, y, _ = data_adapter.unpack_x_y_sample_weight(data)\r\n\r\n        with tf.GradientTape() as tape:\r\n            x['ground_truths'] = y\r\n            y_pred = self(x, training=True)\r\n            loss = self.compiled_loss(None, y_pred, None, regularization_losses=self.losses)\r\n        training._minimize(self.distribute_strategy, tape, self.optimizer, loss,\r\n                           self.trainable_variables)\r\n        return {m.name: m.result() for m in self.metrics}\r\n\r\n```\r\n", "comments": ["@EmGarr Thanks for filing the request! This is a rather important feature which I think we should support. However special-casing an argument for detection models would make things too complicated. In general I don't think we can make that into keras.Layer. But likely into keras.layers.ImageLayer which inherits from it and deals with both image and gt boxes", "@tanzhenyu I think the issue can be closed. It seems that the futur handling of nested arguments for a tf.function will solve this issue:\r\nhttps://www.tensorflow.org/guide/concrete_function#changes_for_tensorflow_23."]}, {"number": 39809, "title": "Upgrading Tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 'Windows-10-10.0.18362-SP0'\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version: 1.12.0\r\n- Python version: Python 3.6.8 :: Acaconda, : lnc\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): No Bazel\r\n- GCC/Compiler version (if compiling from source): I have no GCC/compiler\r\n- CUDA/cuDNN version: I have no CUDA\r\n- GPU model and memory: I have no GPU\r\n\r\n**Describe the problem**\r\nHi, I'm a beginner of tensorflow. I want to upgrade tensorflow version from 1.12.0 to 2.2.0 using Anaconda prompt, but it didn't work at all. How can I solve this problem? \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n![cpature](https://user-images.githubusercontent.com/60909846/82727392-32366d80-9d25-11ea-80e6-7a83346304c0.JPG)\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Not a TF issue. You have to manually uninstall `wrapt`.\r\n\r\nSuggesting creating a fresh virtual environment and installing there instead of in the global namespace.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39809\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39809\">No</a>\n"]}, {"number": 39808, "title": "ValueError: Could not find matching function to call loaded from the SavedModel", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, it's an example code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): from binary, using `pip install tensorflow-gpu==2.2.0-rc0` \r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 9.1\r\n- GPU model and memory: Nvidia 1050Ti\r\n\r\n(Full tensorflow version: `v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2`)\r\n\r\n**Describe the current behavior**\r\n\r\nFollowing the example code described [here](https://github.com/tensorflow/community/blob/master/rfcs/20181116-saved-model.md#python-objects-and-nests-in-function-signatures):\r\n\r\n```python\r\n@tf.function\r\ndef f(x, training):\r\n  return x if training else 2.\r\nf(-1., training=True)\r\nf(-1., training=False)\r\nobj = tf.train.Checkpoint(f=f)  # save() exports objects, so we wrap f\r\ntf.saved_model.save(obj, \"/tmp/f\")\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nAfter loading the model again, when calling the exported function:\r\n\r\n```python\r\nimported = tf.saved_model.load(\"/tmp/f\")\r\nimported.f(10., training=True)  # 10 -> expected value.\r\n```\r\n10 should be the output\r\n\r\n**Actual behavior** \r\n\r\nIt yields an error: \r\n\r\n```python\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (2 total):\r\n    * 10\r\n    * True\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 2 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (2 total):\r\n    * -1.0\r\n    * False\r\n  Keyword arguments: {}\r\n\r\nOption 2:\r\n  Positional arguments (2 total):\r\n    * -1.0\r\n    * True\r\n  Keyword arguments: {}\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nExample code given.\r\n\r\n**Other info / logs** \r\n\r\nIt works if I put a value used before in the function, before saving the model: \r\n\r\n```python\r\n# Code\r\nimported.f(-1., training=False) # I HAVE called the function with these exact arguments before saving the model\r\n\r\n# Result\r\n<tf.Tensor: shape=(), dtype=float32, numpy=-1.0>\r\n```\r\nThis could be the desired behavior of the library (to only work with previously evaluated inputs), however:\r\n- I don't see the point of using such tool if it's just a lookup table\r\n- Conflicts with the example given\r\n", "comments": ["Ok so apparently this is actually a feature, namely [tracing](https://www.tensorflow.org/guide/concrete_function#tracing). \r\nEach time the function is called with a different type of input variables, it will be re-traced. In the aforementioned example code, in order for it to work properly, the function needs to be called (and effectively, traced) using a `tf.Tensor()`, instead of an integer:\r\n```python\r\n@tf.function\r\ndef f(x, training):\r\n  return x if training else 2.\r\nf(tf.constant(-1), training=tf.constant(True))\r\nobj = tf.train.Checkpoint(f=f)  # save() exports objects, so we wrap f\r\ntf.saved_model.save(obj, \"/tmp/f\")\r\n# ...\r\nimported = tf.saved_model.load(\"/tmp/f\")\r\nimported.f(10, training=True)  # yields 10, the expected value\r\n```\r\nThat's because tensorflow will create a _concrete function_ for each different type of input called. However, [immutable values such as integer's will trigger the tracing for every different input](https://www.tensorflow.org/guide/concrete_function#immutable_python_objects), and so it does act as a look up table on that case.  \r\n\r\nThe doc's is very extensive and this went unnoticed by me. I hope this helps someone facing the same questions. \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39808\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39808\">No</a>\n"]}, {"number": 39807, "title": "XLA Interpreter is not being compiled in Tensorflow 2.2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): from source\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nInterpreter jit and services does not compile in Tensorflow 2.2.\r\n\r\nThe configuration was the default values displayed.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nSteps to reproduce:\r\n1) git clone -b r1.15 https://github.com/tensorflow/tensorflow.git\r\n2) cd tensorflow\r\n3) Add random character (e.g. \"dfgfsdg\") in the code area of xla_interpreter_device.cc (located in tensorflow/compiler/jit/).\r\n4) bazel build -c dbg //tensorflow/tools/pip_package:build_pip_package\r\n\r\nThe compilation should fail. However it does not.\r\n\r\nNote: my objective is to insert a custom backend. I was successful in TF version 1.15. However, when I reproduce those steps, the backend is not detected.", "comments": [" python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n>>> v2.2.0-0-g2b96f3662b 2.2.0\r\n", "Small changes to source.\r\nIn .bazelrc, add:\r\n\\# AWS SDK must be compiled in release mode. see: https://github.com/tensorflow/tensorflow/issues/37498\r\nbuild:dbg --copt -DDEBUG_BUILD\r\n\r\nIn third_party/aws/aws-checksums.bazel, add:\r\n    defines = [\r\n        \"DEBUG_BUILD\"\r\n    ],", "adding: 'build:xla --define with_xla_support=true' to the bazelrc file solved the issue. It seems that xla support is not enabled by default in 2.2. This flag is required to trigger the jit BUILD rules.\r\n\r\nThank you.", "Closing this issue since it's resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39807\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39807\">No</a>\n"]}, {"number": 39806, "title": "Error after run category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)", "body": "\r\n![Capture](https://user-images.githubusercontent.com/63918976/82724724-56cd1e00-9d02-11ea-91e8-34f99eb57dec.PNG)\r\nThis template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["Please fill in issue template for the bug category, not for the miscellanous one.", "@goms12  \r\nPlease update as per above comment", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39805, "title": "Error after run", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["No info provided. Duplicated by #39804 #39806"]}, {"number": 39804, "title": "error", "body": "![Capture](https://user-images.githubusercontent.com/63918976/82724698-18376380-9d02-11ea-955d-a37c6e2c9278.PNG)\r\n<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nError after run category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39804\">No</a>\n", "No info provided. Duplicated by #39805 #39806"]}, {"number": 39803, "title": "Invalid output Tensor index: 1 when trying to run a tiny-yolov3 model on TFLite", "body": "Following @jvishnuvardhan suggestion in https://github.com/tensorflow/tensorflow/issues/39157#issuecomment-632788236_, I'm creating a new issue\r\n\r\nI'm facing an error when trying to run a tiny-yolov3 model on TensorFlow Lite's Object Detection Android Demo. \r\nWhen I try to run the app on mobile phone, the app crashed with the following error \r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.lite.examples.detection, PID: 5535\r\n    java.lang.IllegalArgumentException: Invalid output Tensor index: 1\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.getOutputTensor(NativeInterpreterWrapper.java:292)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:166)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)\r\n        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:204)\r\n        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:214)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n```\r\n\r\nI'm using yolov3-tiny that was trained (using transfer learning) with [Alexey](https://github.com/AlexeyAB/darknet)'s implementation to detect 2 custom objects (knife and machete).\r\n\r\n[mystic's](https://github.com/mystic123/tensorflow-yolo-v3) implementation was then used  to convert the .weight file to a .pb\r\n\r\nThen I used the following code to convert the .pb file to .tflite\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"frozen_darknet_yolov3_model.pb\"\r\ninput_arrays = [\"inputs\"]\r\noutput_arrays = [\"output_boxes\"]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n        graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n(I'm using tensorflow 1.15 to run this code)\r\n\r\nThe .tflite that was created is then moved to the assets folder of the object_detection example of tflite https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android\r\n\r\nThe tflite and labelfile that I used can be found here https://drive.google.com/file/d/1Av7Q1mjLdOIEE81oNnt8cLENlXykxnEu/view?usp=sharing\r\n\r\nI changed the following on DetectorActivity.java\r\n```\r\nTF_OD_API_INPUT_SIZE from 300 to 416\r\nTF_OD_API_IS_QUANTIZED from true to false\r\n```\r\nThen I changed the following on TFLiteObjectDetectionAPIModel.java\r\n```\r\nNUM_DETECTIONS from 10 to 2535\r\nd.outputLocations = new float[1][NUM_DETECTIONS][4] to d.outputLocations = new float[1][NUM_DETECTIONS][7];\r\n```\r\nHere's the DetectorActivity.java and TFLiteObjectDetectionAPIModel.java that I use [here](https://drive.google.com/file/d/1Zf0i2Y_Tjyh7Li3UcxteKRB_k5Bwhhgt/view?usp=sharing)\r\n\r\n\r\nAny assistance would be appreciated", "comments": ["@SirTapir Happy that you re-opened the issue really hope that someone can help", "@SirTapir still having the same problem ?", "@Anasel23 Yes, no progress yet", "@SirTapir do you think that it can be a problem in the architecture of the model itself? I mean the tiny version has been created so it can be used on mobiles can we change it architecture by removing some layers and do another training ", "@Anasel23 I'll be honest, I have no idea. I've been facing this error for weeks now, not really sure where the problem lies. \r\nCould be a conversion problem from .weights to .pb then to .tflite or maybe something else that I've changed from the TensorFlow Lite's Object Detection Android Demo. ", "@SirTapir facing the same problem too for weeks now.  You must know that i've followed the exact same process !!Hope to find the solution.", "@jvishnuvardhan  \r\n[Here](https://drive.google.com/file/d/1QqJTQuKwu6QVWifvuDVlr8ya5qhYUJJB/view?usp=sharing)'s my .weight, cfg, and .pb if needed", "@SirTapir Any updates on this error ? did you train your yolov3_tiny_obj with this weights that you installed using this command\r\n./darknet partial cfg/yolov3-tiny.cfg yolov3-tiny.weights yolov3-tiny.conv.15 15?", "@Anasel23 Yes, I trained the model with the same command. Btw, I've also opened a question at stack overflow [here](https://stackoverflow.com/questions/62025209/invalid-output-tensor-index-1-when-running-a-custom-yolov3-tiny-model-on-google) maybe it could be of some help.\r\nOn the topic of updates regarding this error:\r\n\r\n- I've successfully ran the model without crashing. I did this by only putting one array into the output map, like this\r\n```\r\nMap<Integer, Object> outputMap = new HashMap<>();\r\noutputMap.put(0, outputLocations);\r\n\r\ntfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n\r\n```\r\n- Now the problem is translating said output into actual data like locations of object, scores, class label, and  number of detections. Here is the output of said array\r\n```\r\n Array at: 0 values: [-25.297955] [-6.9190693] [65.46178] [35.47879] [6.7820656E-6] [0.51488364] [0.5272327]\r\n    TFLiteObjectDetectionAPIModel: Array at: 1 values: [-91.8242] [-40.757454] [129.2085] [72.019424] [2.2218128E-6] [0.37300995] [0.5925319]\r\n    TFLiteObjectDetectionAPIModel: Array at: 2 values: [-240.25125] [-186.38759] [274.3983] [222.5612] [1.127338E-5] [0.27641284] [0.67838424]\r\n    TFLiteObjectDetectionAPIModel: Array at: 3 values: [-16.850494] [-2.0965796] [118.82944] [28.96283] [1.1363889E-5] [0.3750859] [0.53759706]\r\n    TFLiteObjectDetectionAPIModel: Array at: 4 values: [-74.77507] [-21.789557] [171.89941] [58.995293] [2.7761434E-6] [0.3655538] [0.72778356]\r\n    TFLiteObjectDetectionAPIModel: Array at: 5 values: [-187.20813] [-144.38745] [278.30975] [174.90073] [3.4437292E-6] [0.3618639] [0.5931993]\r\n    TFLiteObjectDetectionAPIModel: Array at: 6 values: [14.077995] [1.0179415] [152.3075] [27.06137] [1.11327045E-5] [0.3666517] [0.54309994]\r\n    TFLiteObjectDetectionAPIModel: Array at: 7 values: [-48.26387] [-15.610519] [214.6371] [55.597824] [1.2245713E-6] [0.49970642] [0.5791726]\r\n    TFLiteObjectDetectionAPIModel: Array at: 8 values: [-146.7292] [-127.653015] [309.5728] [160.98468] [2.0313819E-6] [0.60291785] [0.3433442]\r\n    TFLiteObjectDetectionAPIModel: Array at: 9 values: [36.78253] [-0.8245907] [190.24797] [27.01309] [2.506639E-5] [0.36374664] [0.48420942]\r\n    TFLiteObjectDetectionAPIModel: Array at: 10 values: [-18.765198] [-14.468082] [247.22986] [54.61629] [2.6518353E-6] [0.39860374] [0.5662671]\r\n```\r\nThere are 2535 array with differing values, I only provided 10 of them as an example. \r\nCan anybody help translate these values into a workable data? I would like to know which values correspond to locations of object, scores of detection, class label, and number of detection\r\n\r\n[Here](https://drive.google.com/file/d/1a1yH7NtNm77jw7xiSCkhqyGRoaRdf50q/view?usp=sharing)'s my latest TFLiteObjectDetectionAPIModel.java if needed @jvishnuvardhan \r\n", "Alright, I got it now. Why the array is shaped [1][2535][7]\r\n\r\nYOLO v3 makes prediction across 3 different scales. The detection layer is used make detection at feature maps of three different sizes, having strides 32, 16, 8 respectively. This means, with an input of 416 x 416, we make detections on scales `13 x 13`, `26 x 26` and `52 x 52`.\r\n\r\nTiny Version of Yolov3 apparently only use 2 size, strides 32 and 16 only. This means, with an input of 416 x 416, it makes detection on scales `13 x 13` and `26 x 26`\r\n\r\nThe shape [1][2535][7] is created because mystic's implementation concatenate the results of (13x13) detection and (26x26). So, we got 2353 from `( (13x13)+(26x26) ) * 3`\r\n\r\nThe [7] last array is the bounding boxes, confidences, and probability of that class being there.\r\nAs my custom model only detect 2 classes, it resulted in [7] `(4 box coordinates + 1 object confidence + n number of class confidences)` If you convert the original yolov3-tiny model that was trained on COCO, it will result in [85] because num_of_classes of coco is 80\r\nArray 0-3: Bounding Boxes\r\nArray 4: Confidences of any object appearing on said box\r\nArray 5-end of array: Probability of said class appearing on that bound box location.\r\n\r\nTrying to convert said array into a working detector is a challenge. But at least I understand where to begin. \r\n\r\nResource:\r\n[Understanding Mystic's implementation](https://itnext.io/implementing-yolo-v3-in-tensorflow-tf-slim-c3c55ff59dbe) \r\n[Where Mystic's implementation was inspired from](https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/)", "@SirTapir  \r\n```\r\n       final float xPos = outputLocations[0][i][0];\r\n        final float yPos = outputLocations[0][i][1];\r\n        final float w = outputLocations[0][i][2];\r\n        final float h = outputLocations[0][i][3];\r\n        final RectF rectF = new RectF(\r\n               xPos - w / 2,\r\n                yPos - h / 2,\r\n                 xPos + w / 2,\r\n                yPos + h / 2);\r\n\r\n```\r\nDo you extract the bounding box information like this? I'm getting weird results after doing this.\r\n\r\n\r\nHere is my complete code...All the bounding boxes in my frame are stacked on top left, and there is only one class title showing for all the bounding boxes.\r\n\r\nHere is the full code\r\n\r\n```\r\n outputLocations = new float[1][2535][15];\r\n\r\n    Object[] inputArray = {imgData};\r\n    Map<Integer, Object> outputMap = new HashMap<>();\r\n    outputMap.put(0, outputLocations);\r\n\r\n    Trace.endSection();\r\n\r\n    // Run the inference call.\r\n    Trace.beginSection(\"run\");\r\n    tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n    Trace.endSection();\r\n\r\n\r\n  \r\n    final ArrayList<Recognition> recognitions = new ArrayList<>();\r\n\r\n\r\n    for (int i = 0; i < outputLocations[0].length; ++i) {  //2535\r\n\r\n      float maxClass = 0;\r\n      int detectedClass = -1;\r\n      final float[] classes = new float[labels.size()];\r\n      final float confidence = sigmoid(outputLocations[0][i][4]);\r\n\r\n      for (int c = 0;c< labels.size();c++){\r\n        classes [c] = outputLocations[0][i][5+c];\r\n\r\n      }\r\n      for (int c = 0;c<labels.size();++c){\r\n        if (classes[c] > maxClass){\r\n          detectedClass = c;\r\n          maxClass = classes[c];\r\n        }\r\n      }\r\n      final float score = maxClass;\r\n      Log.d(\"Scores: \",\" \"+score );\r\n\r\n      if (score > 0.5) {\r\n        final float xPos = outputLocations[0][i][0];\r\n        final float yPos = outputLocations[0][i][1];\r\n        final float w = outputLocations[0][i][2];\r\n        final float h = outputLocations[0][i][3];\r\n        final RectF rectF = new RectF(\r\n               xPos - w / 2,\r\n                yPos - h / 2,\r\n                 xPos + w / 2,\r\n                yPos + h / 2);\r\n\r\n        recognitions.add(\r\n                new Recognition(\r\n                        \"\" + i, labels.get((int) detectedClass), score, rectF));\r\n\r\n      }\r\n    }\r\n    Trace.endSection(); // \"recognizeImage\"\r\n    return recognitions;\r\n  }\r\n\r\n```", "@agh372 Ah, I didn't continue with mystic's converter. I've changed my converter to hunlgc007's converter at  https://github.com/hunglc007/tensorflow-yolov4-tflite\u00a0and used the android example in their repo as a reference to implement yolov3 to work in mobile app.", "@SirTapir Do we need anchors and masks? But that is YoloClassifier4 right? Is there any difference between their implementation.", "@agh372 It's been a while, but IIRC yes. We still need anchors and masks. In that repo you could also convert yolov3 models. You just need to put yolov3's mask and anchor values", "Sorry to bother, but I have been struggling to get the bounding boxes. I have a yolov3-tiny.tflite model\r\n\r\nCould you tell me the name of the function you used..There are many functions commented in this class\r\n[YoloV4Classifier.java)](https://github.com/hunglc007/tensorflow-yolov4-tflite/blob/master/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/YoloV4Classifier.java)\r\nI would be really grateful! Thank you!", "@agh372 I used most of them, just change the mask and achors value so that it matches with yolov3 and you should be good to go.", "Thank you! Last question, so anchors and masks are fixed for all yolov3-tiny models right (irrespective of the shape) right?", "@agh372 AFAIK yes. But don't quote me on that. I haven't refreshed my memory on YOLOv3", "Thank you so much! @SirTapir ", "@SirTapir \r\nI used this https://github.com/hunglc007/tensorflow-yolov4-tflite and still I'm getting like this! Did you face or have any idea what it could be?\r\n![WhatsApp Image 2020-11-13 at 3 23 28 AM](https://user-images.githubusercontent.com/37753430/99056289-b690dd00-255f-11eb-8b2c-76646fca2784.jpeg)\r\n\r\n", "@agh372 Sorry, I don't know where the problem is that could result in your picture. Maybe try opening an issue in that repo? ", "@SirTapir I figured the post-processing part! I have a question regarding the order. So I observed that your tflite model has a shape of [1, 2535, 7]\r\n\r\nWhat I don't understand is, so each grid cell of 13 scales are used to predict 3 bounding box is what I read. Hence the formula ( B * ( C + 5)). Here B = 3 in my case.\r\n\r\nSo in the array of 2535, If the 0th index represents the first cell (0,0) of 13 scale for the first bounding box\r\n\r\nwhat does the 1st index represent then?\r\n\r\nDoes it represent the second bounding box information for the first cell (0,0) of 13 scale\r\n\r\nor\r\n\r\nDoes it represent the first bounding box information for the second cell (0,1) of 13 scale?"]}, {"number": 39802, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below):  tensorflow_cpu-2.2.0-cp37-cp37m-win_amd64\r\n- Python version: Python 3.7.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\npip install tensorflow-cpu\r\nimport tensorflow\r\nI went through all these github issue links [1](https://github.com/tensorflow/tensorflow/issues/22794), [2](https://github.com/tensorflow/tensorflow/issues/22794) and [3](https://www.tensorflow.org/install/errors) but I am unable to find any solution. I have installed Microsoft Visual C++ 2015 Redistributable Update 3 mentioned in one of the solutions, still no help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-d6579f534729> in <module>\r\n----> 1 import tensorflow\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\shivam\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\shivam\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\shivam\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\shivam\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\shivam\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["You need **2019** redistributable.", "yes that works. It should be mentioned in the requirements.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39802\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39802\">No</a>\n", "It is already: https://www.tensorflow.org/install/pip#system-requirements\r\n\r\n> Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019\r\n\r\nAlso on https://www.tensorflow.org/install/source_windows#install_visual_c_build_tools_2019", "yes okay, my bad. It would be great if it is included here in the https://github.com/tensorflow/tensorflow/blob/master/README.md"]}]