[{"number": 24476, "title": "[XLA] tf.where not working with xla.compile", "body": "tf.where doesn't seem to be supported when using xla.compile. Are there any ways around the issue, or would it be possible to implement?\r\n\r\nExample code:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.compiler.xla as xla\r\n\r\ntest_tensor = tf.constant([[1, 2, 3, 0.00004, 5], [6, 7, 8, 9, 10]], dtype=tf.float32)\r\n\r\n\r\ndef func():\r\n    return tf.where(test_tensor < 1e-2)\r\n\r\n\r\nwith tf.device(\"/device:CPU:0\"):\r\n    compiled_func = xla.compile(func)\r\n\r\nwith tf.Session() as session:\r\n    res = session.run(compiled_func)\r\n    print(res)\r\n```\r\n\r\nError output:\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph cluster_5308246905621824101[] on XLA_CPU_JIT: Where (No registered 'Where' OpKernel for XLA_CPU_JIT devices compatible with node node Where\r\n\t.  Registered:  device='CPU'; T in [DT_BOOL]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_INT8]\r\n  device='CPU'; T in [DT_UINT8]\r\n  device='CPU'; T in [DT_INT16]\r\n  device='CPU'; T in [DT_UINT16]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]", "comments": ["> tf.where doesn't seem to be supported when using xla.compile.\r\n\r\nCorrect, this is due to a fundamental design choice in XLA, see https://medium.com/tensorflow/pushing-the-limits-of-gpu-performance-with-xla-53559db8e473.  We are currently working on relaxing this, but it is a lot of work.\r\n\r\n> Are there any ways around the issue\r\n\r\nNot that I know of today with `xla.compile`.\r\n\r\nYou could try using autoclustering instead of xla.compile, by setting the `TF_XLA_FLAGS` environment variable to include `--tf_xla_auto_jit=2`.  Or you could try moving the `where` out of xla.compile.\r\n\r\nSince this is working as intended (but not necessarily desired) I'm going to close this, but I don't mean to end the conversation if you have other questions."]}, {"number": 24475, "title": "Can't build TF Model Lite Benchmark tool on Windows", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 Pro 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:nightly build\r\n- Python version:3.5\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):0.20.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\nCan't build TF Model Lite Benchmark tool on Windows.\r\nThis code seems to dispatch using PLATFORM_WINDOWS macro.\r\nHowever PLATFORM_WINDOWS is not defined in the first place.\r\nWhy not use portable std::this_thread::sleep_for()?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel --output_base $(Build.BinariesDirectory) build -c opt //tensorflow/lite/tools/benchmark:benchmark_model\r\n\r\n**Any other info / logs**\r\n\r\n```\r\n2018-12-20T15:02:11.7495615Z tensorflow/lite/tools/benchmark/benchmark_model.cc(41): error C3861: 'nanosleep': identifier not found\r\n2018-12-20T15:02:11.7840550Z INFO: Elapsed time: 2.614s, Critical Path: 0.99s\r\n2018-12-20T15:02:11.7840932Z INFO: 0 processes.\r\n2018-12-20T15:02:11.7841202Z FAILED: Build did NOT complete successfully\r\n```\r\nFor further information visit [our CI environment](https://dev.azure.com/mlops/build-tflite/_build/results?buildId=11)", "comments": ["Thanks for flagging. We have several platforms that don't have std::thread support, so we can't use that path unconditionally. I'll send out a fix."]}, {"number": 24474, "title": "How to build from source with hdfs support on. No option in configure?", "body": "**System information**\r\n- OS Platform and Distribution: Mac OS Mojave 10.14.1 (18B75)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: branch r1.12\r\n- Python version: 3.6.6 \r\n- Installed using virtualenv? pip? conda?: building is in a virtualenv created by `pyenv virtualenv 3.6.6 my_tf_build_env`\r\n- Bazel version (if compiling from source): from source. 0.15.0\r\n- GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.0 (clang-1000.11.45.5)\r\n- CUDA/cuDNN version:  no cuda, build only for cpu\r\n- GPU model and memory: Intel Core i7, 16 GB\r\n\r\n**Describe the problem**\r\nWhen I reading threcord in my local hdfs, I encounter error below:\r\n\r\n```\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/ops/io_ops.py\", line 166, in read\r\n    return gen_io_ops.reader_read_v2(self._reader_ref, queue_ref, name=name)\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 944, in reader_read_v2\r\n    queue_handle=queue_handle, name=name)\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"/Users/eva/.pyenv/versions/pycharm_v3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nNotFoundError (see above for traceback): dlopen(libhdfs.dylib, 6): image not found\r\n```\r\nI fallowed [this guide](https://www.tensorflow.org/deploy/hadoop) to set hadoop pathes, and I'm sure my `libhdfs.dylib` is in my `HADOOP_HDFS_HOME`. (I build hadoop natively for mac)\r\n\r\nI'm not sure if my tensorflow, which is installed via brew, is hdfs enabled. So I just want to build from source with hdfs enable, but when I run `./configure`, there is no option for hdfs?  My questions are:\r\n\r\n1/ is the tensorflow shipped via brew hdfs enabled?\r\n2/ how to build from source with hdfs turn on?", "comments": ["HDFS is already enabled in your installation, otherwise it wouldn't attempt to open the libhdfs.dylib file. I would suggest checking your HDFS installation to see if it's standard. It's possible libhdfs has other dependencies that aren't able to be loaded. macOS lib search paths are weird.\r\n\r\nNormally, libhdfs.dylib is supposed to be under $HADOOP_HDFS_HOME/lib/native, but we do attempt to load it from $HADOOP_HDFS_HOME.", "I don't know if the hdfs lib is loaded now, because the problem is now changed to `No Java runtime present, requesting install.`. Below is my settings:\r\n\r\n![image](https://user-images.githubusercontent.com/1506580/50326480-95ffaa00-0525-11e9-8b18-22ea750b6b96.png)\r\n\r\nthe code is simple , I just want to read some tfrecord out from local hdfs:\r\n```\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nfilenames = [\"hdfs://localhost:8020/dataset/training/eval.tfrecord\"]\r\ndataset = tf.data.TFRecordDataset(filenames)\r\nvalue = dataset.make_one_shot_iterator().get_next()\r\n\r\nsess = tf.Session()\r\nsess.run(value)\r\n```\r\n\r\nI build tensorflow with `--march=native`.\r\nThank you so much.\r\n", "I find something else.\r\n1/ for mac, it should be `DYLD_LIBRARY_PATH`, not `LD_LIBRARY_PATH`\r\n2/ it seems using `DYLD_LIBRARY_PATH` to define shared libraries is not the best options. I dont know how dynamic linker works in mac os, but `libhdfs.dylib` strangely has the rpath to `libjvm.dylib`\r\n\r\n![image](https://user-images.githubusercontent.com/1506580/50334588-c2c2ba00-0543-11e9-9f32-aeea4874f5bc.png)\r\n\r\n", "I am having a similar issue on mac.\r\nI built hadoop on mac and copied libhdfs.dylib to the HDFS_HOME/lib/native path.\r\nUnfortunately even after that i am getting the below error\r\n\r\n```\r\nFile \"/datarpm/agent/miniconda3/envs/dask-distributed/lib/python3.6/site-packages/tensorflow/python/lib/io/tf_record.py\", line 210, in __init__\r\n    compat.as_bytes(path), options._as_record_writer_options(), status)\r\n  File \"/datarpm/agent/miniconda3/envs/dask-distributed/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unknown error: 255\r\n```\r\n\r\nI am using the below code to write a tfrecord to hdfs\r\n\r\n```\r\ndata = {\r\n            'Age': 29,\r\n            'Movie': ['The Shawshank Redemption', 'Fight Club'],\r\n            'Movie Ratings': [9.0, 9.7],\r\n            'Suggestion': 'Inception',\r\n            'Suggestion Purchased': 1.0,\r\n            'Purchase Price': 9.99\r\n        }\r\n        example = tf.train.Example(features=tf.train.Features(feature={\r\n            'Age': tf.train.Feature(\r\n                int64_list=tf.train.Int64List(value=[data['Age']])),\r\n            'Movie': tf.train.Feature(\r\n                bytes_list=tf.train.BytesList(\r\n                    value=[m.encode('utf-8') for m in data['Movie']])),\r\n            'Movie Ratings': tf.train.Feature(\r\n                float_list=tf.train.FloatList(value=data['Movie Ratings'])),\r\n            'Suggestion': tf.train.Feature(\r\n                bytes_list=tf.train.BytesList(\r\n                    value=[data['Suggestion'].encode('utf-8')])),\r\n            'Suggestion Purchased': tf.train.Feature(\r\n                float_list=tf.train.FloatList(\r\n                    value=[data['Suggestion Purchased']])),\r\n            'Purchase Price': tf.train.Feature(\r\n                float_list=tf.train.FloatList(value=[data['Purchase Price']]))\r\n        }))\r\n        with tf.python_io.TFRecordWriter('hdfs://localhost:8020/tmp/test/tf/customer_1.tfrecord') as writer:\r\n            writer.write(example.SerializeToString())\r\n```\r\nTensorflow version : 1.12.0\r\n\r\nEDIT:\r\nIt was a CLASSPATH issue, had to use --glob for expanding all the paths. Now getting the java runtime install error\r\nNo Java runtime present, requesting install.\r\n\r\njava version\r\njava version \"1.8.0_144\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\r\n\r\n![image](https://user-images.githubusercontent.com/9332650/50445095-4f012280-0932-11e9-95f4-cab72e655a32.png)\r\n", "Any update on the above issue related to JDK mismatch.??\r\nVery hard to find why tensorflow jobs are asking for legacy java when accessing hdfs.", "same problem with @pranav-kohli", "After a year long time, finally we have an update for the above issue.\r\nTurned out to be the compatibility problem between libhdfs and java on Mac.\r\nlibhdfs on mac seems to create a mismatch with the java security policy.\r\n **Switching to OpenJdk solved the issue**.\r\nLet me know if this helps..\r\n ", "> \r\n> \r\n> same problem with @pranav-kohli\r\n\r\nHave you solved the problem yet", "@legatoo We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. please check https://github.com/tensorflow/tensorflow/issues/24474#issuecomment-600544122 Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24474\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24474\">No</a>\n"]}, {"number": 24473, "title": "num_examples issue", "body": "For the value of num_examples, what value should we get from the original value? When the amount we get is close to the total number of data.\r\n\u00a0\u00a0 Has anyone solved this problem?\r\n the errors:\r\nValueError: not enough values to unpack (expected 2, got 1)", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "i think the value  depend's on code ....\r\n"]}, {"number": 24472, "title": "get ctc_greedy_decoder results error C-api ?", "body": "\r\n**System information**\r\n- Have I written custom code \r\n- OS Platform and Distribution (Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: not available\r\n- GPU model and memory: not available\r\n\r\nPython code:\r\nself.seqLen = tf.placeholder(tf.int32, [None])\r\ndecoder = tf.nn.ctc_greedy_decoder(inputs=ctcIn3dTBC, sequence_length=self.seqLen)\r\n\r\nPython result:\r\n`([SparseTensorValue(indices=array([[ 0,  0],\r\n       [ 0,  1],\r\n       [ 0,  2],\r\n       [ 0,  3],\r\n       [ 1,  0],\r\n       [ 1,  1],\r\n       [ 1,  2],\r\n       [ 1,  3],\r\n       [ 2,  0],\r\n       [ 2,  1],\r\n       [ 2,  2],\r\n       [ 2,  3],\r\n       [ 3,  0],\r\n       [ 3,  1],\r\n       [ 3,  2],\r\n       [ 3,  3],\r\n       [ 4,  0],\r\n       [ 4,  1],\r\n       [ 4,  2],\r\n       [ 4,  3],\r\n       [ 5,  0],\r\n       [ 5,  1],\r\n       [ 5,  2],\r\n       [ 5,  3],\r\n       [ 6,  0],\r\n       [ 6,  1],\r\n       [ 6,  2],\r\n       [ 6,  3],\r\n       [ 7,  0],\r\n       [ 7,  1],\r\n       [ 7,  2],\r\n       [ 7,  3],\r\n       [ 8,  0],\r\n       [ 8,  1],\r\n       [ 8,  2],\r\n       [ 8,  3],\r\n       [ 9,  0],\r\n       [ 9,  1],\r\n       [ 9,  2],\r\n       [ 9,  3],\r\n       [10,  0],\r\n       [10,  1],\r\n       [10,  2],\r\n       [10,  3],\r\n       [11,  0],\r\n       [11,  1],\r\n       [11,  2],\r\n       [11,  3],\r\n       [12,  0],\r\n       [12,  1],\r\n       [12,  2],\r\n       [12,  3],\r\n       [13,  0],\r\n       [13,  1],\r\n       [13,  2],\r\n       [13,  3],\r\n       [14,  0],\r\n       [14,  1],\r\n       [14,  2],\r\n       [14,  3],\r\n       [15,  0],\r\n       [15,  1],\r\n       [15,  2],\r\n       [15,  3],\r\n       [16,  0],\r\n       [16,  1],\r\n       [16,  2],\r\n       [16,  3],\r\n       [17,  0],\r\n       [17,  1],\r\n       [17,  2],\r\n       [17,  3],\r\n       [18,  0],\r\n       [18,  1],\r\n       [18,  2],\r\n       [18,  3],\r\n       [19,  0],\r\n       [19,  1],\r\n       [19,  2],\r\n       [19,  3],\r\n       [20,  0],\r\n       [20,  1],\r\n       [20,  2],\r\n       [20,  3],\r\n       [21,  0],\r\n       [21,  1],\r\n       [21,  2],\r\n       [21,  3],\r\n       [22,  0],\r\n       [22,  1],\r\n       [22,  2],\r\n       [22,  3],\r\n       [23,  0],\r\n       [23,  1],\r\n       [23,  2],\r\n       [23,  3],\r\n       [24,  0],\r\n       [24,  1],\r\n       [24,  2],\r\n       [24,  3],\r\n       [25,  0],\r\n       [25,  1],\r\n       [25,  2],\r\n       [25,  3],\r\n       [26,  0],\r\n       [26,  1],\r\n       [26,  2],\r\n       [26,  3],\r\n       [27,  0],\r\n       [27,  1],\r\n       [27,  2],\r\n       [27,  3],\r\n       [28,  0],\r\n       [28,  1],\r\n       [28,  2],\r\n       [28,  3],\r\n       [29,  0],\r\n       [29,  1],\r\n       [29,  2],\r\n       [29,  3],\r\n       [30,  0],\r\n       [30,  1],\r\n       [30,  2],\r\n       [30,  3],\r\n       [31,  0],\r\n       [31,  1],\r\n       [31,  2],\r\n       [31,  3],\r\n       [32,  0],\r\n       [32,  1],\r\n       [32,  2],\r\n       [32,  3],\r\n       [33,  0],\r\n       [33,  1],\r\n       [33,  2],\r\n       [33,  3],\r\n       [34,  0],\r\n       [34,  1],\r\n       [34,  2],\r\n       [34,  3],\r\n       [35,  0],\r\n       [35,  1],\r\n       [35,  2],\r\n       [35,  3],\r\n       [36,  0],\r\n       [36,  1],\r\n       [36,  2],\r\n       [36,  3],\r\n       [37,  0],\r\n       [37,  1],\r\n       [37,  2],\r\n       [37,  3],\r\n       [38,  0],\r\n       [38,  1],\r\n       [38,  2],\r\n       [38,  3],\r\n       [39,  0],\r\n       [39,  1],\r\n       [39,  2],\r\n       [39,  3],\r\n       [40,  0],\r\n       [40,  1],\r\n       [40,  2],\r\n       [40,  3],\r\n       [41,  0],\r\n       [41,  1],\r\n       [41,  2],\r\n       [41,  3],\r\n       [42,  0],\r\n       [42,  1],\r\n       [42,  2],\r\n       [42,  3],\r\n       [43,  0],\r\n       [43,  1],\r\n       [43,  2],\r\n       [43,  3],\r\n       [44,  0],\r\n       [44,  1],\r\n       [44,  2],\r\n       [44,  3],\r\n       [45,  0],\r\n       [45,  1],\r\n       [45,  2],\r\n       [45,  3],\r\n       [46,  0],\r\n       [46,  1],\r\n       [46,  2],\r\n       [46,  3],\r\n       [47,  0],\r\n       [47,  1],\r\n       [47,  2],\r\n       [47,  3],\r\n       [48,  0],\r\n       [48,  1],\r\n       [48,  2],\r\n       [48,  3],\r\n       [49,  0],\r\n       [49,  1],\r\n       [49,  2],\r\n       [49,  3]], dtype=int64), values=array([53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53,\r\n       59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59,\r\n       64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64,\r\n       57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57,\r\n       53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53,\r\n       59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59,\r\n       64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64,\r\n       57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57,\r\n       53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53,\r\n       59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59,\r\n       64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64,\r\n       57, 53, 59, 64, 57, 53, 59, 64, 57, 53, 59, 64, 57], dtype=int64), dense_shape=array([50,  4], dtype=int64))], array([[-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455],\r\n       [-297.2455]], dtype=float32))`\r\n\r\nGraph-def:\r\n`483: CTCGreedyDecoder type: CTCGreedyDecoder device:  number inputs: 2 number outputs: 4\r\nNumber inputs: 2\r\n0 type : TF_FLOAT\r\n1 type : TF_INT32\r\nNumber outputs: 4\r\n0 type : TF_INT64\r\n dims: 2 [-1,2]\r\n1 type : TF_INT64\r\n dims: 1 [-1]\r\n2 type : TF_INT64\r\n dims: 1 [2]\r\n3 type : TF_FLOAT\r\n dims: 2 [50,1]`\r\n\r\nC-API result:\r\n\r\nraw ouput:\r\n0 0\r\n1 0\r\n2 0\r\n3 0\r\n4 0\r\n5 0\r\n6 0\r\n7 0\r\n8 0\r\n9 0\r\n10 0\r\n11 0\r\n12 0\r\n13 0\r\n14 0\r\n15 0\r\n16 0\r\n17 0\r\n18 0\r\n19 0\r\n20 0\r\n21 0\r\n22 0\r\n23 0\r\n24 0\r\n25 0\r\n26 0\r\n27 0\r\n28 0\r\n29 0\r\n30 0\r\n31 0\r\n32 0\r\n33 0\r\n34 0\r\n35 0\r\n36 0\r\n37 0\r\n38 0\r\n39 0\r\n40 0\r\n41 0\r\n42 0\r\n43 0\r\n44 0\r\n45 0\r\n46 0\r\n47 0\r\n48 0\r\n49 0\r\n-1759315024 1332898372\r\n-1746890864 -1804888032\r\n-1759345360 -1759345360\r\n-1759317136 -1759317136\r\n-1759345360 -1759345360\r\n-1759343376 -1759343376\r\n-572662307 -572662307\r\n-572662307 -572662307\r\n-572662307 2104715895\r\n544096522 544498024\r\n1702258025 1768778100\r\n1881173615 1919251557\r\n1696623983 1735289188\r\n1953722216 779711087\r\n1700929652 1701078371\r\n1126195488 1701999975\r\n1684365933 1953722184\r\n1952540788 1886724211\r\n1919902496 1651336480\r\n1948280686 1852793632\r\n1769234802 544370502\r\n744844400 1886330995\r\n1684370293 1920230770\r\n1685091616 1918988320\r\n544436837 1931502962\r\n543236199 1768910955\r\n1918988298 980644453\r\n1869835877 1767994478\r\n1701344288 1768186981\r\n1701601889 1952804193\r\n1931505524 1953068832\r\n1634732645 1936876916\r\n1835343981 543649385\r\n544433524 1752440935\r\n1634887521 1768778100\r\n1629515375 1835562089\r\n1970107747 540701554\r\n1919906670 1852399988\r\n543516788 1852400740\r\n543517794 1634497901\r\n544175136 1769414757\r\n1879729512 1919251557\r\n1696623983 1735289188\r\n1936028769 1948280686\r\n1919377764 1835627632\r\n544108393 1752459634\r\n1701601889 1310734949\r\n1948280431 1818386804\r\n544502645 543236200\r\n544106784 1347690528\r\n1768186981 1734960750\r\n544108393 1864900719\r\n1936024681 1767859564\r\n1601009006 540701540\r\n1864397413 1935962721\r\n1752637551 543516788\r\n1852400740 1936026722\r\n1986618400 1752369710\r\n540697705 1768319348\r\n1752375398 544370534\r\n1701867296 170815087\r\n1684627301 544761188\r\n544434536 1852383333\r\n1651328288 1632397166\r\n1768320623 1852795252\r\n537554804 1667592816\r\n667177 1768319348\r\n1752375398 1081240139\r\n-1804996768 -1804848800\r\n1684627301 544761188\r\n544434536 1852383333\r\n1651328288 1632397166\r\n1768320623 1852795252\r\n537554804 1667592816\r\n667177 74672654\r\n544096522 544498024\r\n1886330995 1769234810\r\n1835102817 1852383347\r\n1713392962 1684365933\r\n1967988782 1919945317\r\n1646290021 1718513475\r\n1431327845 1852400740\r\n1886330996 1702043764\r\n1752440944 1667592818\r\n1684301154 1818386804\r\n1734960750 778989417\r\n1635280160 1752440876\r\n1936269424 1869881444\r\n1819042164 1952804193\r\n1952540788 1634692128\r\n1836020326 1801676136\r\n1700929652 1948279072\r\n543649385 175335712\r\n1684370549 1835102817\r\n1092631155 544370547\r\n1768843617 1763730792\r\n1696623713 1735289188\r\n1881171308 1919251557\r\n1702065440 1700949349\r\n1869351527 1937055859\r\n543516788 1953525536\r\n1869182049 1769107303\r\n1836018954 541139002\r\n1663070831 1852403305\r\n1852383333 1835343980\r\n543649385 1869422693\r\n1869881441 544106784\r\n1852400740 1886743407\r\n543649385 1296122945\r\n2053729641 1818304622\r\n778922100 1953063791\r\n1948270880 1868767346\r\n1735289198 1768843552\r\n1651336480 1948280686\r\n1818588704 544433513\r\n1763730803 1684301154\r\n1802465132 1852404597\r\n1145118821 1835627632\r\n544108393 1752459634\r\n1701601889 1310734949\r\n1948280431 1818386804\r\n544502645 543236200\r\n544106784 1347690528\r\n1768186981 1734960750\r\n544108393 1864900719\r\n1936024681 1767859564\r\n1601009006 540701540\r\n1864397413 1935962721\r\n1752637551 543516788\r\n1852400740 1936026722\r\n1986618400 1752369710\r\n540697705 1768319348\r\n1752375398 544370534\r\n1701867296 170815087\r\n1684627301 544761188\r\n544434536 1852383333\r\n1651328288 1632397166\r\n1768320623 1852795252\r\n537554804 1667592816\r\n667177 0\r\n0 175335936\r\n544096522 544498024\r\n1886330995 1769234810\r\n1835102817 1852383347\r\n1713392962 1684365933\r\n1967988782 1919945317\r\n1646290021 1718513475\r\n1431327845 1852400740\r\n1886330996 1702043764\r\n1752440944 1667592818\r\n\r\nI'am blocked to correctly get  result of ctc_greedy_decoder in c-API, please help?\r\nThanks.\r\n", "comments": ["I found the problem. I forgot to normalize the input batch data. "]}, {"number": 24471, "title": "Error installing Tensorflow GPU with CUDA 10.0 for python on Windows ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): -- Error Installing\r\n- TensorFlow version: -- Error Installing\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.4.2\r\n- GPU model and memory: GeForce GTX 1060 6gb\r\n\r\nI followed instructions in this tutorial:\r\nhttps://www.pytorials.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-windows/\r\nonly difference is I'm using CuDNN version 7.4.2 instead of 7.3.1\r\n\r\nEverything went well till step 12:\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nError Trace:\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nLoading:\r\nLoading: 0 packages loaded\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (2 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (7 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (11 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (14 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (18 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (21 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (23 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (26 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (28 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (57 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (71 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (73 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (74 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (74 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (75 packages loaded)\r\nDEBUG: C:/users/lb/_bazel_lb/wvk7snnt/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: 'BAZEL_VC' is not set, start looking for the latest Visual C++ installed.\r\nDEBUG: C:/users/lb/_bazel_lb/wvk7snnt/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for VS%VERSION%COMNTOOLS environment variables, eg. VS140COMNTOOLS\r\nDEBUG: C:/users/lb/_bazel_lb/wvk7snnt/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Visual C++ build tools found at C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (77 packages loaded)\r\nWARNING: C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lb/_bazel_lb/wvk7snnt/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (80 packages loaded)\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:354:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (82 packages loaded).\r\nINFO: Found 1 target...\r\n[0 / 2] [-----] BazelWorkspaceStatusAction stable-status.txt\r\n[1,100 / 5,102] Compiling tensorflow/contrib/lite/profiling/time.cc; 1s local ... (2 actions, 1 running)\r\nINFO: From Compiling tensorflow/contrib/lite/profiling/time.cc:\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(36): warning C4820: '_timespec64': '4' bytes padding added after data member '_timespec64::tv_nsec'\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(43): warning C4820: 'timespec': '4' bytes padding added after data member 'timespec::tv_nsec'\r\ntensorflow/contrib/lite/profiling/time.cc(32): warning C4365: 'return': conversion from '__int64' to 'uint64_t', signed/unsigned mismatch\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(290): warning C4514: 'fpclassify': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(295): warning C4514: 'fpclassify': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(300): warning C4514: 'fpclassify': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(305): warning C4514: 'signbit': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(310): warning C4514: 'signbit': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(315): warning C4514: 'signbit': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(320): warning C4514: '_fpcomp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(325): warning C4514: '_fpcomp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(330): warning C4514: '_fpcomp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(808): warning C4514: '_chgsignl': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(815): warning C4514: '_copysignl': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_math.h(869): warning C4514: '_hypotl': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(17): warning C4514: 'abs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(22): warning C4514: 'pow': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(30): warning C4514: 'abs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(35): warning C4514: 'acos': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(40): warning C4514: 'acosh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(45): warning C4514: 'asin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(50): warning C4514: 'asinh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(55): warning C4514: 'atan': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(60): warning C4514: 'atanh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(65): warning C4514: 'atan2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(70): warning C4514: 'cbrt': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(75): warning C4514: 'ceil': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(80): warning C4514: 'copysign': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(86): warning C4514: 'cos': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(91): warning C4514: 'cosh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(96): warning C4514: 'erf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(101): warning C4514: 'erfc': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(106): warning C4514: 'exp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(111): warning C4514: 'exp2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(116): warning C4514: 'expm1': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(121): warning C4514: 'fabs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(126): warning C4514: 'fdim': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(131): warning C4514: 'floor': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(136): warning C4514: 'fma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(142): warning C4514: 'fmax': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(147): warning C4514: 'fmin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(152): warning C4514: 'fmod': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(157): warning C4514: 'frexp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(162): warning C4514: 'hypot': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(167): warning C4514: 'ilogb': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(172): warning C4514: 'ldexp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(177): warning C4514: 'lgamma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(182): warning C4514: 'llrint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(187): warning C4514: 'llround': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(192): warning C4514: 'log': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(197): warning C4514: 'log10': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(202): warning C4514: 'log1p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(207): warning C4514: 'log2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(212): warning C4514: 'logb': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(217): warning C4514: 'lrint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(222): warning C4514: 'lround': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(227): warning C4514: 'modf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(232): warning C4514: 'nearbyint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(237): warning C4514: 'nextafter': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(242): warning C4514: 'nexttoward': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(248): warning C4514: 'pow': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(254): warning C4514: 'pow': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(262): warning C4514: 'remainder': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(267): warning C4514: 'remquo': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(273): warning C4514: 'rint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(278): warning C4514: 'round': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(283): warning C4514: 'scalbln': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(288): warning C4514: 'scalbn': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(293): warning C4514: 'sin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(298): warning C4514: 'sinh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(303): warning C4514: 'sqrt': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(308): warning C4514: 'tan': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(313): warning C4514: 'tanh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(318): warning C4514: 'tgamma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(323): warning C4514: 'trunc': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(328): warning C4514: 'abs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(333): warning C4514: 'acos': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(338): warning C4514: 'acosh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(343): warning C4514: 'asin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(348): warning C4514: 'asinh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(353): warning C4514: 'atan': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(358): warning C4514: 'atanh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(363): warning C4514: 'atan2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(369): warning C4514: 'cbrt': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(374): warning C4514: 'ceil': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(379): warning C4514: 'copysign': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(385): warning C4514: 'cos': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(390): warning C4514: 'cosh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(395): warning C4514: 'erf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(400): warning C4514: 'erfc': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(405): warning C4514: 'exp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(410): warning C4514: 'exp2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(415): warning C4514: 'expm1': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(420): warning C4514: 'fabs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(425): warning C4514: 'fdim': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(431): warning C4514: 'floor': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(436): warning C4514: 'fma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(442): warning C4514: 'fmax': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(448): warning C4514: 'fmin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(454): warning C4514: 'fmod': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(460): warning C4514: 'frexp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(466): warning C4514: 'hypot': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(472): warning C4514: 'ilogb': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(477): warning C4514: 'ldexp': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(483): warning C4514: 'lgamma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(488): warning C4514: 'llrint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(493): warning C4514: 'llround': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(498): warning C4514: 'log': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(503): warning C4514: 'log10': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(508): warning C4514: 'log1p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(513): warning C4514: 'log2': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(518): warning C4514: 'logb': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(523): warning C4514: 'lrint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(528): warning C4514: 'lround': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(533): warning C4514: 'modf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(539): warning C4514: 'nearbyint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(544): warning C4514: 'nextafter': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(550): warning C4514: 'nexttoward': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(556): warning C4514: 'pow': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(562): warning C4514: 'pow': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(571): warning C4514: 'remainder': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(577): warning C4514: 'remquo': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(583): warning C4514: 'rint': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(588): warning C4514: 'round': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(593): warning C4514: 'scalbln': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(599): warning C4514: 'scalbn': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(605): warning C4514: 'sin': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(610): warning C4514: 'sinh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(615): warning C4514: 'sqrt': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(620): warning C4514: 'tan': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(625): warning C4514: 'tanh': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(630): warning C4514: 'tgamma': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cmath(635): warning C4514: 'trunc': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdlib.h(359): warning C4514: 'abs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdlib.h(364): warning C4514: 'abs': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdlib.h(369): warning C4514: 'div': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdlib.h(374): warning C4514: 'div': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_memcpy_s.h(64): warning C4514: 'memmove_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(100): warning C4514: '_vcwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(127): warning C4514: '_vcwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(154): warning C4514: '_vcwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(167): warning C4514: '_cwprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(185): warning C4514: '_cwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(202): warning C4514: '_cwprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(220): warning C4514: '_cwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(237): warning C4514: '_cwprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(255): warning C4514: '_cwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(303): warning C4514: '_vcwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(335): warning C4514: '_vcwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(348): warning C4514: '_cwscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(371): warning C4514: '_cwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(393): warning C4514: '_cwscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wconio.h(411): warning C4514: '_cwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wio.h(225): warning C4514: '_wopen': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wio.h(238): warning C4514: '_wsopen': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(311): warning C4514: 'vfwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(342): warning C4514: 'vfwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(373): warning C4514: '_vfwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(387): warning C4514: '_vwprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(401): warning C4514: 'vwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(414): warning C4514: '_vwprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(430): warning C4514: 'vwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(445): warning C4514: '_vwprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(459): warning C4514: '_vwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(472): warning C4514: '_fwprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(491): warning C4514: 'fwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(509): warning C4514: '_fwprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(530): warning C4514: 'fwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(550): warning C4514: '_fwprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(569): warning C4514: '_fwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(587): warning C4514: '_wprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(605): warning C4514: 'wprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(622): warning C4514: '_wprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(642): warning C4514: 'wprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(661): warning C4514: '_wprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(679): warning C4514: '_wprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(728): warning C4514: 'vfwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(761): warning C4514: 'vfwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(776): warning C4514: '_vwscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(790): warning C4514: 'vwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(803): warning C4514: '_vwscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(819): warning C4514: 'vwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(834): warning C4514: '_fwscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(853): warning C4514: 'fwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(871): warning C4514: '_fwscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(892): warning C4514: 'fwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(912): warning C4514: '_wscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(930): warning C4514: 'wscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(947): warning C4514: '_wscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(967): warning C4514: 'wscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1094): warning C4514: '_vsnwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1122): warning C4514: '_vsnwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1171): warning C4514: '_vswprintf_c': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1223): warning C4514: '_vswprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1276): warning C4514: 'vswprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1323): warning C4514: '_vswprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1358): warning C4514: '_vscwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1391): warning C4514: '_vscwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1405): warning C4514: '__swprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1425): warning C4514: '_swprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1446): warning C4514: '_swprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1465): warning C4514: 'swprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1508): warning C4514: '_swprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1530): warning C4514: 'swprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1559): warning C4514: '_swprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1580): warning C4514: '_swprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1600): warning C4514: '_swprintf_c_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1621): warning C4514: '_swprintf_c': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1641): warning C4514: '_snwprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1667): warning C4514: '_snwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1692): warning C4514: '_snwprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1714): warning C4514: '_snwprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1742): warning C4514: '_scwprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1761): warning C4514: '_scwprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1779): warning C4514: '_scwprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1798): warning C4514: '_scwprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1822): warning C4514: 'swprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1837): warning C4514: 'vswprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1848): warning C4514: '_swprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1863): warning C4514: '_vswprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1921): warning C4514: 'vswscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(1956): warning C4514: 'vswscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2019): warning C4514: '_swscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2039): warning C4514: 'swscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2058): warning C4514: '_swscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2080): warning C4514: 'swscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2101): warning C4514: '_snwscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2127): warning C4514: '_snwscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2152): warning C4514: '_snwscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstdio.h(2173): warning C4514: '_snwscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(166): warning C4514: 'wcsnlen_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(247): warning C4514: '_wcstok': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(261): warning C4514: 'wcstok': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(539): warning C4514: 'wcschr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(545): warning C4514: 'wcspbrk': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(551): warning C4514: 'wcsrchr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wstring.h(558): warning C4514: 'wcsstr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wtime.h(185): warning C4514: '_wctime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_wtime.h(192): warning C4514: '_wctime_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\sys/stat.h(234): warning C4514: 'fstat': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\sys/stat.h(239): warning C4514: 'stat': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\wchar.h(180): warning C4514: 'fwide': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\wchar.h(189): warning C4514: 'mbsinit': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\wchar.h(268): warning C4514: 'wmemchr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(648): warning C4514: 'vfprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(679): warning C4514: 'vfprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(710): warning C4514: '_vfprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(724): warning C4514: '_vprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(738): warning C4514: 'vprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(751): warning C4514: '_vprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(767): warning C4514: 'vprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(782): warning C4514: '_vprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(796): warning C4514: '_vprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(809): warning C4514: '_fprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(828): warning C4514: 'fprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(852): warning C4514: '_fprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(873): warning C4514: 'fprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(893): warning C4514: '_fprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(912): warning C4514: '_fprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(930): warning C4514: '_printf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(948): warning C4514: 'printf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(965): warning C4514: '_printf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(985): warning C4514: 'printf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1004): warning C4514: '_printf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1022): warning C4514: '_printf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1070): warning C4514: 'vfscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1104): warning C4514: 'vfscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1120): warning C4514: '_vscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1134): warning C4514: 'vscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1147): warning C4514: '_vscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1163): warning C4514: 'vscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1178): warning C4514: '_fscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1197): warning C4514: 'fscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1215): warning C4514: '_fscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1236): warning C4514: 'fscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1256): warning C4514: '_scanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1274): warning C4514: 'scanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1291): warning C4514: '_scanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1311): warning C4514: 'scanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1469): warning C4514: 'vsprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1510): warning C4514: 'vsprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1557): warning C4514: '_vsprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1595): warning C4514: '_vsnprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1623): warning C4514: 'vsnprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1668): warning C4514: '_vscprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1733): warning C4514: '_vsnprintf_c': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1749): warning C4514: '_sprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1774): warning C4514: 'sprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1810): warning C4514: '_sprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1833): warning C4514: 'sprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1862): warning C4514: '_sprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1883): warning C4514: '_sprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1903): warning C4514: '_snprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1940): warning C4514: 'snprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1961): warning C4514: '_snprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(1991): warning C4514: '_snprintf_c_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2012): warning C4514: '_snprintf_c': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2032): warning C4514: '_snprintf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2054): warning C4514: '_snprintf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2082): warning C4514: '_scprintf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2100): warning C4514: '_scprintf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2117): warning C4514: '_scprintf_p_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2135): warning C4514: '_scprintf_p': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2183): warning C4514: 'vsscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2244): warning C4514: '_sscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2263): warning C4514: 'sscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2281): warning C4514: '_sscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2302): warning C4514: 'sscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2330): warning C4514: '_snscanf_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2354): warning C4514: '_snscanf': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2378): warning C4514: '_snscanf_s_l': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\stdio.h(2402): warning C4514: '_snscanf_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\corecrt_memory.h(100): warning C4514: 'memchr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\string.h(371): warning C4514: 'strnlen_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\string.h(504): warning C4514: 'strchr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\string.h(510): warning C4514: 'strpbrk': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\string.h(516): warning C4514: 'strrchr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\string.h(522): warning C4514: 'strstr': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime_new.h(86): warning C4514: 'operator new': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime_new.h(92): warning C4514: 'operator delete': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime_new.h(101): warning C4514: 'operator new[]': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime_new.h(107): warning C4514: 'operator delete[]': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(476): warning C4514: 'ctime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(487): warning C4514: 'difftime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(496): warning C4514: 'gmtime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(506): warning C4514: 'localtime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(517): warning C4514: '_mkgmtime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(525): warning C4514: 'mktime': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(532): warning C4514: 'time': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(540): warning C4514: 'timespec_get': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(550): warning C4514: 'ctime_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(560): warning C4514: 'gmtime_s': unreferenced inline function has been removed\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt\\time.h(569): warning C4514: 'localtime_s': unreferenced inline function has been removed\r\nINFO: From Compiling external/com_google_absl/absl/base/dynamic_annotations.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting_posix.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting_windows.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\n[1,414 / 5,840] Compiling external/protobuf_archive/src/google/protobuf/compiler/js/embed.cc; 0s local ... (2 actions, 1 running)\r\nINFO: From Executing genrule //tensorflow/core:version_info_gen:\r\nfatal: Invalid path '/c/users/lb/_bazel_lb/wvk7snnt/execroot/org_tensorflow/C:': No such file or directory\r\nINFO: From Linking external/protobuf_archive/python/google/protobuf/internal/_api_implementation.so:\r\n   Creating library bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/lib_api_implementation.so.ifso and object bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/lib_api_implementation.so.exp\r\n[1,536 / 5,952] Executing genrule @local_config_cuda//cuda:cuda-include; 72s local ... (2 actions, 1 running)\r\nINFO: From Compiling external/com_google_absl/absl/numeric/int128.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\n[1,630 / 5,967] Executing genrule @local_config_cuda//cuda:cuda-include; 162s local ... (2 actions, 1 running)\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/utf8.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/ostringstream.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nERROR: C:/users/lb/_bazel_lb/wvk7snnt/external/jpeg/BUILD.bazel:401:1: Executing genrule @jpeg//:simd_win_x86_64_assemble failed (Illegal instruction): bash.exe failed: error executing command\r\n  cd C:/users/lb/_bazel_lb/wvk7snnt/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\bazel;C:\\msys64\\usr\\local\\bin;C:\\msys64\\usr\\bin;C:\\msys64\\usr\\bin;C:\\msys64\\opt\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\libnvvp;C:\\Program Files\\Microsoft MPI\\Bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn;C:\\Program Files\\Microsoft SQL Server\\140\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\DTS\\Binn;C:\\Program Files\\Microsoft SQL Server\\140\\DTS\\Binn;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\130\\Tools\\Binn;C:\\Program Files\\dotnet;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\Client SDK\\ODBC\\130\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn\\ManagementStudio;C:\\WINDOWS\\System32\\OpenSSH;C:\\Program Files\\nodejs;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Microsoft VS Code\\bin;C:\\Users\\LB\\AppData\\Local\\Programs\\Python\\Python36\\Scripts;C:\\Users\\LB\\AppData\\Local\\Programs\\Python\\Python36;C:\\Users\\LB\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\LB\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\LB\\AppData\\Roaming\\npm;C:\\Users\\LB\\AppData\\Local\\Programs\\Microsoft VS Code Insiders\\bin;C:\\Program Files\\JetBrains\\PyCharm 2018.3.2\\bin;C:\\msys64\\usr\\bin\\site_perl;C:\\msys64\\usr\\bin\\vendor_perl;C:\\msys64\\usr\\bin\\core_perl\r\n    SET PYTHON_BIN_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jccolor-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jccolor-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcgray-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcgray-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jchuff-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcphuff-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcsample-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcsample-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdcolor-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdcolor-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdmerge-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdmerge-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdsample-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdsample-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctflt-sse.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctfst-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctint-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctint-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctflt-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctfst-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctint-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctint-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctred-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquantf-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquanti-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquanti-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jsimdcpu.obj; do\r\n  bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64__    -I $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/    -I $(dirname external/jpeg/simd/nasm/jdct.inc)/    -I $(dirname external/jpeg/simd/nasm/jdct.inc)/../../win/    -o $out    $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\ndone: bash.exe failed: error executing command\r\n  cd C:/users/lb/_bazel_lb/wvk7snnt/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\bazel;C:\\msys64\\usr\\local\\bin;C:\\msys64\\usr\\bin;C:\\msys64\\usr\\bin;C:\\msys64\\opt\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\libnvvp;C:\\Program Files\\Microsoft MPI\\Bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn;C:\\Program Files\\Microsoft SQL Server\\140\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\DTS\\Binn;C:\\Program Files\\Microsoft SQL Server\\140\\DTS\\Binn;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\130\\Tools\\Binn;C:\\Program Files\\dotnet;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\Client SDK\\ODBC\\130\\Tools\\Binn;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn\\ManagementStudio;C:\\WINDOWS\\System32\\OpenSSH;C:\\Program Files\\nodejs;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Microsoft VS Code\\bin;C:\\Users\\LB\\AppData\\Local\\Programs\\Python\\Python36\\Scripts;C:\\Users\\LB\\AppData\\Local\\Programs\\Python\\Python36;C:\\Users\\LB\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\LB\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\LB\\AppData\\Roaming\\npm;C:\\Users\\LB\\AppData\\Local\\Programs\\Microsoft VS Code Insiders\\bin;C:\\Program Files\\JetBrains\\PyCharm 2018.3.2\\bin;C:\\msys64\\usr\\bin\\site_perl;C:\\msys64\\usr\\bin\\vendor_perl;C:\\msys64\\usr\\bin\\core_perl\r\n    SET PYTHON_BIN_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jccolor-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jccolor-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcgray-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcgray-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jchuff-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcphuff-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcsample-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jcsample-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdcolor-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdcolor-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdmerge-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdmerge-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdsample-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jdsample-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctflt-sse.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctfst-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctint-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jfdctint-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctflt-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctfst-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctint-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctint-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jidctred-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquantf-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquanti-avx2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jquanti-sse2.obj bazel-out/x64_windows-opt/genfiles/external/jpeg/simd/x86_64/jsimdcpu.obj; do\r\n  bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64__    -I $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/    -I $(dirname external/jpeg/simd/nasm/jdct.inc)/    -I $(dirname external/jpeg/simd/nasm/jdct.inc)/../../win/    -o $out    $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\ndone\r\n/usr/bin/bash: line 1:  1896 Illegal instruction     bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64__ -I $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/../../win/ -o $out $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 713.407s, Critical Path: 172.97s\r\nINFO: 192 processes: 192 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n", "comments": ["I have already reported a similar issue (see #24233).\r\nIn the current situation, disabling XLA may solve this problem.", "I'm new to this.... I selected this option during configuration\r\n   Do you wish to build TensorFlow with XLA JIT support? [y/N]: N\r\n\r\nHow do I disable XLA...", "> I'm new to this.... I selected this option during configuration\r\n> Do you wish to build TensorFlow with XLA JIT support? [y/N]: N\r\n> \r\n> How do I disable XLA...\r\n\r\n\r\nIt seems that you have disabled XLA. What is the version number of Bazel you are using? Using the bazel version recommended by tensorflow.org instead of the latest version can sometimes avoid some errors.The issue I submitted directly seems to have been fixed, and I will try to compile it later today.\r\nBy analyzing your error log, the problem seems to be here:\r\n/usr/bin/bash: line 1: 1896 Illegal instruction bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64 -I $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/../../win/ -o $out $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)", "bazel-0.17.2 ", "> bazel-0.17.2\r\n\r\n\r\nI have successfully compiled the current version of Tensorflow (commit cd8c6c995e0b29e793854e712d2fbd683b5cbd3f) with bazel 0.20.0 .\r\nDisabling XLA avoids some problems.\r\nOn my workstation (AMD Threadripper 1950x + 4*8GB DDR4 RAM + Samsung 970PRO SSD) it took a total of 7937 seconds.\r\nIt is recommended that you try to use bazel0.20.0 and update the tensorflow code, then run CMD as an administrator to compile.\r\nIn addition, the use of CUDA10.0 seems to improve the performance in FP16 mode, and has no effect on FP32 performance(with RTX2080TI).\r\n", "Changed to bazel 0.20.0  now I get a different error\r\n\r\n\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\tensorflow\\tensorflow/.bazelrc\r\nc:\\tensorflow\\tensorflow/tools/bazel.rc\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=0 --terminal_columns=80\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Users/LB/AppData/Local/Programs/Python/Python36/python.exe\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/python.exe --action_env PYTHON_LIB_PATH=C:/Users/LB/AppData/Local/Programs/Python/Python36/lib/site-packages --python_path=C:/Users/LB/AppData/Local/Programs/Python/Python36/python.exe --define with_ignite_support=true --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_ROCM=0 --action_env TF_NEED_CUDA=1 --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0 --action_env TF_CUDA_VERSION=10.0 --action_env CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0 --action_env TF_CUDNN_VERSION=7 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.0 --action_env TF_CUDA_CLANG=0 --config=cuda --config monolithic --copt=-w --host_copt=-w --verbose_failures --distinct_host_configuration=false --experimental_shortened_obj_file_path=true --define=no_tensorflow_py_deps=true --define=override_eigen_strong_inline=true\r\n**ERROR: Config value cuda is not defined in any .rc file**\r\nINFO: Invocation ID: 37e77b2d-258b-4814-b13a-a30b3d621f34\r\n\r\n", "Apologies, didn't mean to close", "Changed to bazel 0.18.1 now I am back to the original Error:\r\n\r\n/usr/bin/bash: line 1: 1896 Illegal instruction bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64 -I $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/ -I $(dirname external/jpeg/simd/nasm/jdct.inc)/../../win/ -o $out $(dirname external/jpeg/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\n", "Have you tried to install CUDA 9.0 instead of 10.0? \r\nAs the system requirements mentioned :\r\n`CUDA\u00ae Toolkit \u2014TensorFlow supports CUDA 9.0.`\r\n\r\nhttps://www.tensorflow.org/install/gpu", "@ChineduLB Apologies for the delay in response. TF 1.13.0-rc0 is released and comes with cuda 10 pre-built binaries. Give it try. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "What CPU are you using?\r\n Whether the AVX and AVX2 of the CPU available?"]}, {"number": 24470, "title": "Error installing Tensorflow 1.12", "body": "Hi - \r\n\r\nI have \r\n- Windows 7\r\n- Anaconda 3\r\n- Python 3.6.5\r\n- Tensorflow upgraded from 1.10 to 1.12 (via anaconda)\r\n- No GPU\r\n- CUDA toolkit 9.0 (conda installed)\r\n- cuDNN 7.1.4 (conda installed)\r\n- Bazel version: not installed\r\n- Mobile device: None\r\n\r\nAll I did was updating tensorflow via anaconda: conda update tensorflow. It updated from 1.10 to 1.12:\r\n2018-12-20 13:54:12  (rev 4)\r\n     conda  {4.5.11 -> 4.5.12}\r\n     tensorboard  {1.10.0 -> 1.12.0}\r\n     tensorflow  {1.10.0 -> 1.12.0}\r\n     tensorflow-base  {1.10.0 -> 1.12.0}\r\n    +_tflow_select-2.1.0\r\n    +cudatoolkit-9.0\r\n    +cudnn-7.1.4\r\n    +keras-applications-1.0.6\r\n    +keras-preprocessing-1.0.5\r\n\r\n\r\nI get the error message below when importing tensorflow into python:\r\n\r\n\r\n\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: DLL load failed: Det angivne modul blev ikke fundet.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-9b31ac0d4d77> in <module>()\r\n      1 import pandas as pd\r\n----> 2 import tensorflow as tf\r\n      3 from datetime import datetime\r\n      4 import matplotlib.pyplot as plt\r\n      5 import numpy as np\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 try:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 from tensorflow.python.tools import component_api_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\jet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\jet\\Anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\jet\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Det angivne modul blev ikke fundet.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n", "comments": ["Please provide following information. Thanks!\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Hi - \r\n\r\nI already updated my question with additional information you requested. So, hope that you will take a look at my question again, please. Otherwise, I have to repost ?\r\n\r\nThanks.\r\n ", "Can you try following and confirm if that works for you?\r\nconda install -c conda-forge tensorflow", "I tried to run that line of code ... conda install -c conda-forge tensorflow\r\n\r\nPython was able to import tensorflow (now 1.10):\r\n\r\n2018-12-27 20:24:47  (rev 25)\r\n     certifi  {2018.4.16 -> 2018.4.16 (conda-forge)}\r\n     conda  {4.5.12 -> 4.5.12 (conda-forge)}\r\n     tensorboard  {1.12.0 -> 1.10.0 (conda-forge)}\r\n     tensorflow  {1.12.0 -> 1.10.0 (conda-forge)}\r\n\r\nBut I now got the following traceback;\r\n\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-5-94dcbe54bc91> in <module>()\r\n     10 \r\n     11 layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\r\n---> 12           for layer in range(n_layers)]\r\n     13 multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\r\n     14 rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\r\n\r\n<ipython-input-5-94dcbe54bc91> in <listcomp>(.0)\r\n     10 \r\n     11 layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\r\n---> 12           for layer in range(n_layers)]\r\n     13 multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\r\n     14 rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in __getattr__(self, item)\r\n     51 \r\n     52   def __getattr__(self, item):\r\n---> 53     module = self._load()\r\n     54     return getattr(module, item)\r\n     55 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in _load(self)\r\n     40   def _load(self):\r\n     41     # Import the target module and insert it into the parent's namespace\r\n---> 42     module = importlib.import_module(self.__name__)\r\n     43     self._parent_module_globals[self._local_name] = module\r\n     44 \r\n\r\n~\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    124                 break\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n    128 \r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py in exec_module(self, module)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py in <module>()\r\n     29   from tensorflow.contrib import cloud\r\n     30 from tensorflow.contrib import cluster_resolver\r\n---> 31 from tensorflow.contrib import coder\r\n     32 from tensorflow.contrib import compiler\r\n     33 from tensorflow.contrib import constrained_optimization\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\coder\\__init__.py in <module>()\r\n     20 \r\n     21 # pylint: disable=wildcard-import\r\n---> 22 from tensorflow.contrib.coder.python.layers.entropybottleneck import *\r\n     23 from tensorflow.contrib.coder.python.ops.coder_ops import *\r\n     24 # pylint: enable=wildcard-import\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\layers\\entropybottleneck.py in <module>()\r\n     22 import numpy as np\r\n     23 \r\n---> 24 from tensorflow.contrib.coder.python.ops import coder_ops\r\n     25 \r\n     26 from tensorflow.python.eager import context\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\coder_ops.py in <module>()\r\n     28 \r\n     29 _coder_ops = loader.load_op_library(\r\n---> 30     resource_loader.get_path_to_datafile(\"_coder_ops.so\"))\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\util\\loader.py in load_op_library(path)\r\n     54       return None\r\n     55   path = resource_loader.get_path_to_datafile(path)\r\n---> 56   ret = load_library.load_op_library(path)\r\n     57   assert ret, 'Could not load %s' % path\r\n     58   return ret\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py in load_op_library(library_filename)\r\n     54     RuntimeError: when unable to load the library or get the python wrappers.\r\n     55   \"\"\"\r\n---> 56   lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\n     57 \r\n     58   op_list_str = py_tf.TF_GetOpList(lib_handle)\r\n\r\nNotFoundError: C:\\Users\\jet\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\_coder_ops.so not found", "Apologies for the delay in response. Is this still an issue for you? Can you please provide the minimal code snippet to reproduce the error message? Thanks!", "Closing this issue since original installation error is resolved. Please post a new issue if running into bug/performance issue and provide all the info. asked by the template. Thanks!", "I'm also receiving the same error.\r\nI've installed tensorflow as per [these](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) instructions and when I try to run\r\n\r\n`python object_detection/builders/model_builder_test.py`\r\n\r\nI am receiving the following error along with this message box:\r\n![screenshot 7](https://user-images.githubusercontent.com/28893609/53617708-6ac4c580-3c0e-11e9-9622-0fd11e98635b.png)\r\n\r\n\r\n______________________________________\r\nTraceback (most recent call last):\r\n  File \"object_detection/builders/model_builder_test.py\", line 23, in <module>\r\n    from object_detection.builders import model_builder\r\n  File \"C:\\Users\\765349\\Downloads\\models\\research\\object_detection\\builders\\model_builder.py\", line 22, in <module>\r\n    from object_detection.builders import box_predictor_builder\r\n  File \"C:\\Users\\765349\\Downloads\\models\\research\\object_detection\\builders\\box_predictor_builder.py\", line 20, in <module>\r\n    from object_detection.predictors import convolutional_box_predictor\r\n  File \"C:\\Users\\765349\\Downloads\\models\\research\\object_detection\\predictors\\convolutional_box_predictor.py\", line 22, in <module>\r\n    slim = tf.contrib.slim\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\", line 53, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\", line 42, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 31, in <module>\r\n    from tensorflow.contrib import coder\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\coder\\__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.coder.python.layers.entropybottleneck import *\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\layers\\entropybottleneck.py\", line 24, in <module>\r\n    from tensorflow.contrib.coder.python.ops import coder_ops\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\coder_ops.py\", line 30, in <module>\r\n    resource_loader.get_path_to_datafile(\"_coder_ops.so\"))\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\util\\loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: C:\\Users\\765349\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\_coder_ops.so not found\r\n_______________________________________\r\n\r\nAnd I tried to check that directory and _coder_ops.so was present there."]}, {"number": 24469, "title": "Practical use of CudnnRNN", "body": "Hi @houtoms @protoget @ebrevdo \r\n\r\nI imagined that #23588 would replace TensorFlow's `LSTMCell` implementation, but some main limitations at the moment are the `RNNCell` wrappers such as Dropout, Attention or Residual, all frequently used in research projects and essential for learning. Even if cuDNN was open-source, it would still be impractical for people to code research ideas in c++ and compile the toolkit every time.\r\n\r\nWould it be possible to make `LSTMCell` run as fast as `CudnnLSTM` while retaining the flexibility of the Python API ? Could XLA-generated code match the performance of cudnn given sufficient effort from both TF and Nvidia ? Or are there any plans to support these popular features in cuDNN soon ?\r\n", "comments": ["Thank you for the comment.\r\n\r\n#23588 does not change `LSTMCell`, but adds support if using `tf.contrib.cudnn_rnn.LSTM`. There's no feature parity between TF LSTM and CudnnLSTM.\r\n\r\nUsers could use `UnifiedLSTM` in Keras (probably in the next release, we just implemented internally) which would pick CudnnLSTM if the LSTM config is satisifed in CudnnLSTM. You're right at present , feature-wise, CudnnLSTM is a subset of regular LSTM.\r\n\r\nI guess your goal is to have a backend that can pattern-match LSTM in a graph and replace it with high-perf LSTM kernels. I'm sure XLA is interested. I'm not aware of NV's plan, regarding if 1) NV would OSS Cudnn 2) How NV's compile toolchain interacts with XLA. I'll add relevant ppl in the thread to comment.\r\n\r\n@azaks2 \r\n@jlebar ", "Getting XLA:GPU to perform well on LSTMs is definitely on our roadmap for next year.  No promises that we'll be able to match the performance of cudnn, as nvidia gets to do some things (like access the machine code, SASS) that we can't.  Nonetheless we are working very closely with nvidia on XLA.\r\n\r\nFundamentally most of our work internally is driven by Google's needs.  That means I cannot commit to doing any particular optimization for any particular models within any particular timeframe.\r\n\r\nIf this is important to you and you're interested in contributing, we'd definitely welcome that and help you get started.", "@ymodak Based on my comment above, I'm confused what caused this to be assigned to me.  Would you be willing to elaborate on what further action you're looking for from me?", "@jlebar Currently I am waiting for the user to respond. If he's willing to make a contribution then it will require your inputs. At this point we don't need any action from your side. I will reassign it to you/other assignee depending on its progress. Thanks!", "@ymodak Since we are not looking for any action from me, would it be OK if the bug was not assigned to me?\r\n\r\nThis way I can maintain the invariant that when I look at the set of bugs assigned to me, it's the set of things that need action from me.  This is helpful for keeping things from falling through the cracks.", "Hi,\r\nThanks a lot for the explanations, and apologies if my lack of response led to a sub-optimal workflow.\r\nI mainly wanted to see if the updated `CudnnRNN` API could be used in machine translation or speech recognitions applications, and, if not, which of its aspects could further improve the performance of the `RNNCell` implementation. Since I may not have the technical expertise in XLA (sorry for not being very helpful at this stage), I am thinking of a workaround based on `CudnnRNN` bypassing some cell wrappers. Nevertheless, I am happy to hear that XLA:GPU for LSTMs is already on your roadmap.\r\n\r\nWill also close the issue unless you consider it is better otherwise."]}, {"number": 24468, "title": "Allow workers to be extensible/scalable in distributed training with PS servers", "body": "Inside an AI-driven business organization, we are exploring large-scale asynchronized & distributed training with help of TensorFlow. Below is the feature contribution from our industrial practice.\r\n\r\n**System information**\r\n- TensorFlow version (you are using): **TensorFlow r1.13**\r\n- Are you willing to contribute it (Yes/No): **Yes**\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nOne of the most helpful feature is ClusterSpec Propagation which simplifies the setup of TF servers. TF worker sessions can get cluster topology from the master session in runtime.\r\n\r\nHowever, we have found that when ClusterSpec Propagation is enabled, the stateful OPs like VariableV2 are no longer shared among worker sessions in the same PS server. Digging into the source, we found the sharing switch is hard coded to be off at [master_session.cc](\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/core/distributed_runtime/master_session.cc#L1287).\r\n\r\nI have submitted a pull request titled \"**Respect isolate_session_state in config when ClusterSpec propagation is enabled**(#24466)\". By canceling the isolation, we may achieve the scenario where worker number can be dynamic-increased in a between-graph distributed training.\r\n\r\nWith this code change, newly launched workers can join the existing distributed training in a peaceful way without restarting all PS servers and workers using an updated ClusterSpec.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo API change.\r\n\r\nHowever, in the old version, if 2 master sessions are created with the ClusterSpec field set in `tf.ConfigProto`, worker sessions sessions won't share the state in default when they are owned by different master sessions.\r\n\r\nAfter my code change, a customer need explicitly set `isolate_session_state` to `True` in `tf.ConfigProto` if he or she want to keep the old behavior where variable values are isolated between 2 worker sessions. Otherwise, variables with the same name in a PS server will be shared.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThose exploring large-scale distributed training with help of TensorFlow PS servers, like data scientists and cloud engineers.\r\n\r\n**Any Other info.**\r\nThere is no performance or data corruption after we enabled this feature in our scenario with tens of PS servers and hundreds of workers.\r\n", "comments": ["Close this as #24466 is merged."]}, {"number": 24467, "title": "fix typo", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "I signed it!", "@innovimax I was not able to see your CLA. Can you please sign and submit again. Apologies for the delay.", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 24466, "title": "Respect isolate_session_state in config when ClusterSpec propagation is enabled", "body": "Currently, the `isolate_session_state ` is hard coded to be true when ClusterSpec propagation is enabled.\r\nHowever, here comes the large-scale distributed training case where workers are running on fragile machines. In this case:\r\n- It is common to see worker N failed and then is restarted on another machine by the infrastructure like Yarn. Then the ClusterSpec held by PS servers are out-of-dated as the IP of worker N has changed.\r\n- It is reasonable that in some time period, the inbound training data increased heavily in size and we want to increase the worker number without restarting the whole job including PS servers.\r\n- It can be helpful to manually replace slow workers detected with new ones on a healthy machine without interrupting the existing training job.\r\n\r\nWith code change in this pull request, users can decide whether to share state of his Session like Variable values with others through the `isolate_session_state` switch in the session configuration.\r\nIn industry, the resource isolation among multiple distributed-training jobs is usually ensured by infrastructure using something like Cgroup or Docker. Hence it is definitely safe and popular to turn off the session isolation for workers inside the same job.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@saeta Hello Brennan, would mind taking a look at this PR? Thanks!", "Nagging Reviewer @jaingaurav, @saeta: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "My last comment was:\r\n\r\n\"Okay, I'm fine with this description assuming the other reviewers agree that this description actually matches what the code does.\"\r\n\r\n@saeta @mrry  ?", "@josh11b @saeta Thanks a lot for your comments!\r\nHas this PR been accepted after these changes or is there anything I can do to push forward this PR?", "@josh11b @saeta @mrry Kindly ping~", "Hi @shishaochen Just to let you know, over the past few days, we've been working this PR though the machinery. It's getting closer. Sorry again for the massive delay."]}, {"number": 24465, "title": "Unexpected result for tf.sqrt under certain conditions", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.1\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n\r\nThe output `a_sqrt_1` of [tf.sqrt](https://www.tensorflow.org/api_docs/python/tf/math/sqrt) in the provided snippet is incorrect. Concretely, when `a` is a [tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable) and `a_sqrt` is run together with `a_scaled`, the output `a_sqrt_1` is `a_sqrt_2 ** -1`.\r\n\r\n**Describe the expected behavior**\r\nThe expected result is `a_sqrt_2`.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nx = 100.0\r\na = tf.Variable(x)\r\n# a = tf.constant(x)  # Interestingly, it works when `a` is a constant\r\na_sqrt = tf.sqrt(a)\r\na_scaled = a / a_sqrt\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    a_sqrt_1, _ = sess.run([a_sqrt, a_scaled])\r\n    print(a_sqrt_1)  # prints 0.1  (!!!)\r\n\r\n    a_sqrt_2 = sess.run(a_sqrt)\r\n    print(a_sqrt_2)  # prints 10.0\r\n```\r\n", "comments": ["@ezhulenev this looks like another case of fetches not being preserved by grappler. Can you take a look?", "Tested with nightly tensorflow, the code produces the correct output.\r\nSimilar to #23196."]}, {"number": 24464, "title": "Tensorboard could not bind to unsupported address family", "body": "Hi,\r\n\r\nI am not convinced whether this a bug or not but I believe it is nice information to report anyway.\r\n\r\n**System information**\r\nUnder OS Debian Stretch\r\ntensorboard               1.12.1\r\ntensorflow                1.12.0          \r\ntensorflow-base           1.12.0 \r\npython                    3.6.7 \r\n\r\n**Describe the current behavior**\r\nWhen executing in terminal : \r\n`tensorboard --logdir=logs/`\r\nI get the following error : \r\n`E1220 09:47:24.720813 MainThread program.py:201] Tensorboard could not bind to unsupported address family ::\r\nE1220 09:47:24.720813 139960141604608 program.py:201] Tensorboard could not bind to unsupported address family ::\r\nERROR: Tensorboard could not bind to unsupported address family ::`\r\n\r\nHowever, when downgrading tensorboard to 1.8.0, everything works fine !\r\n\r\nI found this workaround on a  blog, but I have not found any reporting of this bug... Sorry in advance if it an obvious mistake of my part or a known bug / error\r\n\r\n", "comments": ["This issue is more suitable on tensorflow/tensorboard repo. Please post this issue on tensorboard repo from [here](https://github.com/tensorflow/tensorboard). Thanks!"]}, {"number": 24463, "title": "Raspberry pi build fix for 1.13", "body": "", "comments": []}, {"number": 24462, "title": "Additional fixes cherry-picked for r1.13.", "body": "", "comments": []}, {"number": 24461, "title": "Initialize only CPU devices in optimize_dataset_op", "body": "optimize_dataset_op is making a rouge device initialization for all devices in the system through grappler_item_builder even though only CPU devices are used. This is causing problems mentioned in #24303  and #23458. This PR initializes only CPU devices to workaround these issues. Adding @asimshankar @jlebar and @azaks2 review. Please forward to correct responsible if needed.", "comments": ["Thank you for the change!\r\n\r\n> Adding @asimshankar @jlebar and @azaks2 review. \r\n\r\nYou'll want someone who works on Grappler to review this.\r\n\r\nLooking over this commit, I'll mention again what I said in a previous PR that you may want to get someone who sits near you to read over the comments.", "@tfboyd This PR is needed with #24303 to run TF+XLA with HOROVOD or any other multi-process environment.", "@hgadig anything we can do to help this PR to be merged ? Thanks a lot for your time", "@DEKHTIARJonathan  I'm taking care of this one and an internal CL has been submitted. I'll keep you posted.", "@feihugis @hgadig thanks a lot for the merge in master. What are the odds that the commits \r\nb2fa0df and a427c13 will be cherry picked for TF 1.13 release ?\r\n\r\nThanks a lot", "^ @tfboyd ", "@DEKHTIARJonathan @jlebar : @aselle is looking into cherrypicking the two for the 1.13 release. Will keep you posted.", "Hi @jlebar and @aselle any news regarding the cherrypicking for TF 1.13 ?\r\nI tested the current release (rc0) and the latest version of the branch r1.13. It looks like the issue is not fixed and thus the commits: b2fa0df and a427c13 are likely not merged/cherrypicked.\r\n\r\nAs TF 1.13 will probably be the last release for TF 1.x, it would be very damageable if these bug fixes could not be merged in TF 1.13.\r\n\r\nThanks a lot for your help.", "Any chance https://github.com/tensorflow/tensorflow/commit/a427c1361a281dff6e6cd55a39bb84116314d8fb can be cherry-picked before TF 1.13.0 is out?  Since XLA is compiled-in by default, this causes many multi-process use cases, including Horovod, to fail with TF 1.13.0rc2:\r\n\r\n```\r\nMon Feb 18 23:23:54 2019[1,1]<stderr>:2019-02-18 23:23:54.160127: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nMon Feb 18 23:23:54 2019[1,1]<stderr>:2019-02-18 23:23:54.163429: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nMon Feb 18 23:23:54 2019[1,1]<stderr>:I0218 23:23:54.176867 139666301507328 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n```\r\n\r\nExcerpt from `nvidia-smi`:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     80320      C   python                                     10445MiB |\r\n|    0     80321      C   python                                       147MiB |\r\n|    0     80322      C   python                                       147MiB |\r\n|    0     80323      C   python                                       147MiB |\r\n|    1     80320      C   python                                       147MiB |\r\n|    1     80321      C   python                                     10445MiB |\r\n|    1     80322      C   python                                       147MiB |\r\n|    1     80323      C   python                                       147MiB |\r\n|    2     80320      C   python                                       147MiB |\r\n|    2     80321      C   python                                       147MiB |\r\n|    2     80322      C   python                                     10445MiB |\r\n|    2     80323      C   python                                       147MiB |\r\n|    3     80320      C   python                                       147MiB |\r\n|    3     80321      C   python                                       147MiB |\r\n|    3     80322      C   python                                       147MiB |\r\n|    3     80323      C   python                                     10445MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\ncc @martinwicke ", "@gunan assuming @aselle is gone already. Not sure what the status is.", "Leaving note to say I totally missed this in my mail box.  Including Justin's direct forward.  It seems it will not make the release which has gone on for 45+ days.", "Falling on sword aside.  We have a weekly meeting with NVIDIA now where we are tracking PRs/Tasks more closely which should reduce these items being missed and speedup resolution. ", "Hi,\r\nAccording to #24799 it has already been merged on Jan9. Did someone revert it accidentally?", "@samikama  it was not in the 1.13 branch that was cut before Jan 8th.  That is the discussion.", "I think the branch already has this change:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/core/grappler/grappler_item_builder.cc#L110", "As @samikama pointed out, @aselle already cherrypickd this.", "@gunan, @tfboyd, @samikama, I think the piece that has been lost along the lines is commit https://github.com/tensorflow/tensorflow/commit/a427c1361a281dff6e6cd55a39bb84116314d8fb, which is also necessary.  Without that commit, XLA uses a bit of memory of adjacent GPUs which is often enough to make cuDNN go mad.  Unfortunately, XLA and `--allow_growth` do not seem to live together well: https://github.com/tensorflow/tensorflow/issues/23888.\r\n\r\nAny chance https://github.com/tensorflow/tensorflow/commit/a427c1361a281dff6e6cd55a39bb84116314d8fb could be cherrypicked before the release?", "@gunan, congrats on 1.13.1 release!\r\n\r\nWhat is a good path forward for this issue - will there be another `1.13.x` release with https://github.com/tensorflow/tensorflow/commit/a427c1361a281dff6e6cd55a39bb84116314d8fb  included, is `1.14.0rc0` around the corner, or should we recommend folks to stick with `1.12.1` or `tf-nightly-gpu` if they have issues with XLA grabbing adjacent GPUs?", "I dislike answers that are not good but they are better than silence.\r\n\r\nI think the answer is to stick with 1.12 or roll the dice with a tf-nightly-gpu.  1.13 other than cherry picks was cut back in December.  I do not have a crystal ball on 1.14 and a wild guess is well wild and likely not useful.  \r\n\r\nI am sorry I did not see this problem back in December and get this picked in.  That is on me, I also thought we might finish 1.13 mid-Jan so many things did not go well for any of us for various reasons.  :-)", "@tfboyd, thanks for the quick response!  I hope 1.14 is not too far ahead, moving to CUDA 10 would be great :-)\r\n\r\nOn a systematic side, I think adding an integration test that runs on multi-GPU VM and tests that visible_devices fencing works properly (using `nvidia-smi`) in various use cases would be great.", "I think such a test would be fantastic. We have multi-GPU machines for CI, so we could definitely do that. The tests would have to be whitelisted (since we run tests in parallel), but I *think* that's possible. @annarev do you know about the setup for running tests on more than one GPU on Kokoro?", "It does sound possible. Right now, we we just run 1 test per GPU because we set CUDA_VISIBLE_DEVICES to a single gpu index. So, we could just set it to multiple indexes.\r\nI suppose we can either whitelist or create a separate build for multi-gpu tests.", "Yeah, i guess it would have to be a separate build or a separate step in\nthe same build (chained, with different ENV variable). Alex, want to try\nadding such a test? How would you test the isolation works?\n", "As a small fork, we should have horovod added (it may get added due to some other testing) to our \"sandbox\" tensorflow/models/offiical/resnet (this is becoming a tf_cnn_benchmarks but focused on using only High Level APIs with some FLAGed exceptions.   It would be great to have a single machine horovod test running with my other nightly tests.  This is separate from the unit test you are talking about above and get it working with TF 2.0.", "@annarev, @martinwicke,\r\n\r\nI was looking into adding the test.  From what I reverse engineered, you're using https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/gpu_build/parallel_gpu_execute.sh to run tests on available GPUs, and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/linux/gpu/run_py3_core.sh is one of the test suites.\r\n\r\nIn order to support multi-GPU tests, I imagine we'd have to enhance `parallel_gpu_execute.sh` to support reserving multiple GPUs and make another test suite for these multi-GPU tests.\r\n\r\nOne simple way to verify memory usage would be to run `nvidia-smi --query-gpu=index,memory.used --format=csv` in a subprocess after running various steps, such as importing TensorFlow or creating a session, and analyze its output.\r\n\r\nDoes all sound reasonable?\r\n\r\n@tfboyd,\r\n\r\nThis ResNet model could be a great test case for the upcoming HorovodDistributionStrategy, since it relies on Estimators.  I'll check up on that thread with @guptapriya and @yuefengz.", "Great meeting you at the devsummit! As discussed, I think it is better to setup a separate build where we don't use parallel_gpu_execute.sh and run multi-gpu tests sequentially. I will work on setting one up."]}, {"number": 24460, "title": "Problem on bazel building target with GPU support(Ubuntu16.04)", "body": " >>bazel build --config=opt --config=cuda tensorflow/tools/pip_package:build_pi\r\np_package:\r\nDEBUG: /home/ubuntu/.cache/bazel/_bazel_ubuntu/712f0e98e13675fc83790945ec267f95/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nERROR: cc_toolchain_suite '@local_config_cuda//crosstool:toolchain' does not contain a toolchain for CPU 'k8', you may want to add an entry for 'local|compiler' into toolchains and toolchain_identifier 'local_linux' into the corresponding cc_toolchain rule (see --incompatible_disable_cc_toolchain_label_from_crosstool_proto).\r\nINFO: Elapsed time: 0.181s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n", "comments": ["I had this problem with bazel-0.18.0. Try 0.19.0 instead. ", "@iweigele Thank you, I try bazel-0.19.2,this problem is sloved but new problem arise...\r\n\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@icu//': java.io.IOException: thread interrupted\r\n\r\nDo u know how to deal?\r\n", "No, sorry. I haven't seen that one.  I will post back if I come across something helpful though.", "If this is still an issue, Can you please provide following information? Thanks!\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n", "@ymodak \r\nSystem information\uff1a\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version:1.12.0\r\nPython version:3.6.5\r\nInstalled using virtualenv? pip? conda?: pip\r\nBazel version (if compiling from source):19.2\r\nGCC/Compiler version (if compiling from source):5.4.0\r\nCUDA/cuDNN version: cuda10.0/cuDNN v7.4.1\r\nGPU model and memory: 12G per GPU", "Apologies for the delay in response. TensorFlow 2.0 will officially support cuda 10, for TF 1.12 cuda 9 is supported. Can you please switch to cuda 9 and try again? Thanks!", "TensorFlow 1.13.0-rc0 is released and comes with GPU binaries built against CUDA 10.\r\nYou can give it a try. Thanks!"]}, {"number": 24459, "title": "Tensorflow crashes when trying to feed > 2GiB to TPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu Linux 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): Bazel 0.20.0\r\n- GCC/Compiler version (if compiling from source): 7.2.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Cloud TPU\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to feed a cloud TPU (v3) some data. However, whenever the total feed size goes above 2GiB, I get the following crash inside libtensorflow:\r\n\r\n```\r\nE1220 02:28:43.129226740   14451 proto_buffer_writer.h:83]   assertion failed: byte_count_ < total_size_\r\n\r\nsignal (6): Aborted\r\nin expression starting at no file:0\r\ngsignal at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)\r\nabort at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)\r\n_ZN4grpc11CoreCodegen11assert_failEPKcS2_i at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN4grpc17ProtoBufferWriter4NextEPPvPi at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN6google8protobuf2io17CodedOutputStream7RefreshEv at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow_framework.so (unknown line)\r\n_ZN6google8protobuf2io17CodedOutputStreamC2EPNS1_20ZeroCopyOutputStreamEb at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow_framework.so (unknown line)\r\n_ZNK6google8protobuf11MessageLite25SerializeToZeroCopyStreamEPNS0_2io20ZeroCopyOutputStreamE at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow_framework.so (unknown line)\r\n_ZN4grpc16GenericSerializeINS_17ProtoBufferWriterEN10tensorflow14RunStepRequestEEENS_6StatusERKN6google8protobuf7MessageEPNS_10ByteBufferEPb at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN4grpc8internal21BlockingUnaryCallImplIN10tensorflow14RunStepRequestENS2_15RunStepResponseEEC1EPNS_16ChannelInterfaceERKNS0_9RpcMethodEPNS_13ClientContextERKS3_PS4_ at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN10tensorflow4grpc13MasterService4Stub7RunStepEPN4grpc13ClientContextERKNS_14RunStepRequestEPNS_15RunStepResponseE at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN10tensorflow16GrpcRemoteMaster7RunStepEPNS_11CallOptionsEPNS_21RunStepRequestWrapperEPNS_29MutableRunStepResponseWrapperE at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN10tensorflow11GrpcSession8RunProtoEPNS_11CallOptionsEPNS_28MutableRunStepRequestWrapperEPNS_29MutableRunStepResponseWrapperE at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN10tensorflow11GrpcSession9RunHelperERKNS_10RunOptionsERKSt6vectorISt4pairISsNS_6TensorEESaIS7_EERKS4_ISsSaISsEESF_PS4_IS6_SaIS6_EEPNS_11RunMetadataERKSs at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZN10tensorflow11GrpcSession3RunERKNS_10RunOptionsERKSt6vectorISt4pairISsNS_6TensorEESaIS7_EERKS4_ISsSaISsEESF_PS4_IS6_SaIS6_EEPNS_11RunMetadataE at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n_ZL13TF_Run_HelperPN10tensorflow7SessionEPKcPK9TF_BufferRKSt6vectorISt4pairISsNS_6TensorEESaISA_EERKS7_ISsSaISsEEPP9TF_TensorSI_PS4_P9TF_Status at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\nTF_SessionRun at /home/keno/.julia/packages/TensorFlow/YWnga/src/../deps/usr/lib/libtensorflow.so (unknown line)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nIdeally it should work (after all there's 128GiB of HBM on the other side of this pipe so 2GiB is really not unreasonable here), worst case I'd have expected an error status to be returned rather than a hard assert.\r\n\r\n**Code to reproduce the issue**\r\n\r\nAny code that passes feeds totaling > 2GiB to TF_SessionRun connected over a grpc connection. In this particular example, I was trying to use the `InfeedEnqueueTuple` op (with the inputs being placeholders that I'm feeding).\r\n", "comments": ["Hey @Keno , I think you're running into the 2 GiB proto-size limit. (Proto sizes are `int32`'s, and so you're starting to overflow the proto headers.) Unfortunately, for reasons, this is unlikely to be switched either to a `uint32` or an `int64`. ", "Could tensorflow somehow chunk the message across multiple protos or at least give me a nicer error message here? Killing the entire client and all its state seems a bit drastic.", "@Keno, Did you ever find a solution / workaround to this issue? Having the same problem.", "Running into the same issue :S any news ?", "have the same. it did work in TF 1.3 .. so i am not sure where these proto bufs are coming from.. whats the solution?"]}, {"number": 24458, "title": "XLA Invalid __global__ read in fusion_514 (cublas bug?)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nMaybe. I modified the BERT network to do fp16 math and compiled with XLA.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nn/a\r\n- TensorFlow installed from (source or binary):\r\nNVIDIA 18.12 development container\r\n- TensorFlow version (use command below):\r\n1.12\r\n- Python version:\r\n3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n10.0.130\r\n- GPU model and memory:\r\nTesla V100-SXM2-32GB\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nCode runs for a while and then suddenly generates NaNs. Code runs normally when XLA is disabled.\r\ncuda-memcheck caught a bunch of these:\r\n\r\n========= Invalid __global__ read of size 4\r\n=========     at 0x00000880 in fusion_514\r\n=========     by thread (959,0,0) in block (10,0,0)\r\n=========     Address 0x7f359f6e6e04 is out of bounds\r\n=========     Device Frame:fusion_514 (fusion_514 : 0x880)\r\n=========     Saved host backtrace up to driver entry point at kernel launch time\r\n\r\n\r\n[xla_invalid_read_fusion_514_hlo_dumps.zip](https://github.com/tensorflow/tensorflow/files/2697101/xla_invalid_read_fusion_514_hlo_dumps.zip)\r\n**Describe` the expected behavior**\r\nCode runs without generating NaNs.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nShould be reviewed by @jlebar \r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I can reproduce...something.  Not the same failure you're seeing.\r\n\r\n```\r\nCUDA_LAUNCH_BLOCKING=1 cuda-memcheck tensorflow/compiler/xla/tools:replay_computation_gpu --use_fake_data=true --print_result=false --logtostderr --num_runs=100 $(ls ~/Downloads/xla-invalid-read-fusion/unoptimized_hlo_proto/* | grep _80__) --vmodule=gpu_executable=10\r\n\r\n[...]\r\n\r\nI1220 14:16:10.896196   49661 gpu_executable.cc:142] Executing the thunk for %dot.20474.9628 = f16[4096,768]{1,0} dot(f16[4096,768]{1,0} %fusion.1215, f16[768,768]{1,0} %convert.20474.8970), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type=\"MatMul\" op_name=\"bert/encoder/layer_0/attention/self/key/MatMul\"} on stream 0\r\n\r\nI1220 14:16:10.896224   49661 gpu_executable.cc:142] Executing the thunk for %fusion.1213 = f16[32,12,128,64]{3,2,1,0} fusion(f16[4096,768]{1,0} %dot.20474.9628, f32[768]{0} %arg167.20474.8683), kind=kLoop, calls=%fused_computation.1213, metadata={op_type=\"Transpose\" op_name=\"bert/encoder/layer_0/attention/self/transpose_1\"} on stream 0\r\n\r\nE1220 14:16:10.899636   49661 cuda_driver.cc:1027] Internal: could not synchronize on CUDA stream: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered :: Stack trace:\r\n    @     0x55fc241a94cb  stream_executor::cuda::CUDADriver::SynchronizeStream()\r\n    @     0x55fc241a1ee7  stream_executor::cuda::CUDAExecutor::BlockHostUntilDone()\r\n    @     0x55fc241dc03f  stream_executor::StreamExecutor::BlockHostUntilDone()\r\n    @     0x55fc241af4a3  stream_executor::Stream::BlockHostUntilDone()\r\n    @     0x55fc214f8f9d  xla::gpu::GpuExecutable::ExecuteThunks()\r\n```\r\n\r\nInterestingly this only happens on the second run of cluster 80.\r\n\r\nI am not sure if this is a failure in XLA's generated code or in the cublas kernel that ran right before fusion.1213.  But in general ILLEGAL_INSTRUCTION is not our bug...\r\n\r\nAnyway let me dig in a bit to this.  Strange that it's different from what you're seeing (i.e. no cuda-memcheck failure), but maybe the two failure modes are related somehow.\r\n\r\nI'm on cuda 10.0.130 with cudnn 7.4.1 and driver 410.78.", "(I'm using XLA compiled from head, so it's also possible that we fixed the error that was causing your cuda-memcheck failure after the TF 1.12 release.)", "I added a H2D sync after each thunk and now I'm seeing the very first kernel fail in the second run of the computation.\r\n\r\n```\r\nI1220 14:24:23.870854   64887 replay_computation.cc:223] Done executing in 6.77555s: cluster_80__XlaCompiledKernel_true__XlaNumConstantArgs_34__XlaNumResourceArgs_1_20474\r\n\r\n# ^^ Marks the end of the first run.\r\n\r\nI1220 14:24:23.965730   64887 gpu_executable.cc:142] Executing the thunk for %fusion.1225 = f32[4096,2]{1,0} fusion(s32[32,128]{1,0} %arg179.20474.8695), kind=kLoop, calls=%fused_computation.1225, metadata={op_type=\"OneHot\" op_name=\"bert/embeddings/one_hot\"} on stream 0\r\nE1220 14:24:23.971307   64887 cuda_driver.cc:1027] Internal: could not synchronize on CUDA stream: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered :: Stack trace:\r\n```", "If I make all `dot` ops (i.e. matmuls) nops, the ILLEGAL_INSTRUCTION error goes away.\r\n\r\nThis strongly points a bug in cublas, at least for the failure I'm hitting.  Still no idea why what I'm seeing is different than what you're seeing.\r\n\r\nLet me add optimization fuel to `gemm_thunk` to figure out which gemm call is the problem. http://blog.ezyang.com/2011/06/debugging-compilers-with-optimization-fuel/", "It still hits an `ILLEGAL_INSTRUCTION` if I disable gemm autotuning and use the default gemm algorithm for each call.", "I'm having some difficulty pinning this down, it seems to be nondeterministic exactly which gemm causes the problem.  :-/", "Based on everything I've been able to see, I think what I'm seeing is a cublas bug.  I've filed nvbugs/2470403.  Let's see what they say.\r\n\r\nMy best guess is that you're seeing something different from me because you were using TF 1.12 instead of building from head or using an XLA nightly.", "Because of the nondeterminism and the likelihood that it's cublas, I think this will be hard for me to debug much further.\r\n\r\ncc @mruberry", "cc @timshen91 ", "Thanks for taking a look, Justin. We're investigating now. ", "We discussed this at a meeting today.  @benbarsdell indicated that he can't reproduce the failure he was seeing at head, and neither can I reproduce the failure I was seeing at head.\r\n\r\nI want to bisect to see what changed to make this work.", "I bisected the fix to 3a10998daf52ea922aa7ff895af3012afe956866.  That is extremely interesting, as I didn't expect that change to fix any actual bugs.\r\n\r\nI think what may have been happening is that we were creating \"too many\" active cubins, and, when I tested, cublas was not properly handling the \"cannot load a cubin\" case, thus leading to the illegal_instruction error.  When you tested, some other kernel must have been failing to launch.\r\n\r\nAs for how we ended up with so many cubins in the first place, my guess is that making the fake arguments to the computation is the problem, as that uses the plain Client API, see implementation of MakeFakeArgumentsOrDie.\r\n\r\nIt does seem like there's a bug in error reporting somewhere...  This situation should not lead to illegal-instruction errors.", "We would like to investigate the \"too many\" active cubins theory on our side, as a separate issue.", "@mx8435, the problem fixed by that commit is the problem referenced in the subject of this bug -- an invalid __global__ read, apparently caused by the XLA replay_computation tool that I was using for debugging loading too many cubins at once.\r\n\r\nI wouldn't expect fixing that issue to affect the TF case.  That is, now that we understand this bug, we understand that it's actually unrelated to the TF bug, and is a separate bug in the XLA tool we were using to isolate the TF issue.  I believe @thorjohnsen has updated the BERT PR to incorporate some fixes that make it work.\r\n\r\nI'm going to close this particular issue, as it's resolved by that commit.\r\n\r\nSorry this is confusing.  :("]}, {"number": 24457, "title": "Latest code in master branch won't compile on CentOS", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nCentOS Linux release 7.5.1804\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nSource\r\n- TensorFlow version:\r\nLatest code in master branch\r\n- Python version:\r\n2.7\r\n- Installed using virtualenv? pip? conda?:\r\npip\r\n- Bazel version (if compiling from source):\r\n1.9\r\n- GCC/Compiler version (if compiling from source):\r\n6.3.0\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen compile with the following command line: \r\nbazel build -c dbg //tensorflow/tools/pip_package:build_pip_package\r\nI got the following error:\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h: In member function 'void Eigen::internal::gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs>::operator()(const DataMapper&, const LhsScalar*, const RhsScalar*, Index, Index, Index, Eigen::internal::gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs>::ResScalar, Index, Index, Index, Index) [with LhsScalar = float; RhsScalar = float; Index = long int; DataMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0>; int mr = 8; int nr = 4; bool ConjugateLhs = false; bool ConjugateRhs = false]':\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h:1419:13: error: inconsistent operand constraints in an 'asm'\r\n             EIGEN_GEBGP_ONESTEP(0);\r\n             ^\r\nand more similar errors.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nsee the commands above\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["It can be fixed temporary by changing the line 1394 in external/eigen_archive/Eigen/src/Core/productsGeneralBlockPanelKernel.h:\r\n\r\nChange line 1394 from \r\n#if EIGEN_GNUC_AT_LEAST(6,0) \r\nto\r\n#if EIGEN_GNUC_AT_LEAST(6,0) && NDEBUG\r\n\r\nBasically disable EIGEN_GEBP_2PX4_SPILLING_WORKAROUND when compile debug version\r\n", "Was this with Eigen 3.3.6? Does Eigen 3.3.5 work? If so, ~~please report back to upstream (see http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1651)~~ this is probably http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1643.", "Could you check if it works with Eigen 3.3.7? Otherwise, feel free to re-open http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1651 with more details.", "The master branch of tensorflow still used 9f48e814419e of Eigen library which does not includes the fix (88fc23324517) yet.\r\n\r\nJust created a PR #24647 that bumps Eigen to fix the issue."]}, {"number": 24456, "title": "Replace deprecated FastGFile with GFile", "body": "\r\nFastGFile has been deprecated and replaced with GFile, though\r\nthe example in speech_commands still uses FastGFile. This fix\r\nfix the issue to remove the deprecated warning:\r\n```\r\nWARNING:tensorflow:From <stdin>:1: __init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.gfile.GFile.\r\n```\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Nagging Reviewer @yifeif: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 24455, "title": "upgrade aws-sdk-cpp to the earliest release that enables authentication retries", "body": "The version currently in use, 1.3.15, attempts role based authentication with the MetadataService only once during initialization, which can result in a failure scenario when the MetadataService returns an error response or rate limits requests.\r\n\r\nThis changeset does the following:\r\n\r\n- updates the aws-sdk-cpp lib to the earliest release that contains the retry logic introduced in this commit https://github.com/aws/aws-sdk-cpp/commit/c14746b997be16f294233ab7bc0900b3c7edb58e\r\n- updates the corresponding BUILD.bazel file to define the major, minor, and patch variables that are now provided at compile time via cmake due to this commit https://github.com/aws/aws-sdk-cpp/commit/7142e6eb510b67371d576bca97585e14874db0c8 as copts", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Here's a little extra context for this change.\r\n\r\nI recently attempted to deploy tf_serving to an EKS cluster using a S3 bucket as the model path. In order for deployments within EKS to auth with other AWS resources, we rely on the EC2MetadataService to provide that information.\r\n\r\nWhen I initially attempted to deploy the container, I saw in the following in the logs:\r\n\r\n```\r\n2018-12-10 23:05:07.308072: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /root//.aws/config and using profilePrefix = 1\r\n2018-12-10 23:05:07.308162: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /root//.aws/credentials and using profilePrefix = 0\r\n2018-12-10 23:05:07.308235: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /root//.aws/credentials for credentials file and /root//.aws/config for the config file , for use with profile default\r\n2018-12-10 23:05:07.308531: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Creating HttpClient with max connections2 and scheme http\r\n2018-12-10 23:05:07.308585: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2\r\n2018-12-10 23:05:07.308605: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 900000\r\n2018-12-10 23:05:07.308706: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Unable to open config file /root//.aws/credentials for reading.\r\n2018-12-10 23:05:07.308720: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.\r\n2018-12-10 23:05:07.308737: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Unable to open config file /root//.aws/config for reading.\r\n2018-12-10 23:05:07.308746: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.\r\n2018-12-10 23:05:07.308756: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Credentials have expired attempting to repull from EC2 Metadata Service.\r\n2018-12-10 23:05:07.308870: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2\r\n2018-12-10 23:05:07.308887: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-10 23:05:08.308109: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-10 23:05:08.308158: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:60] Http request to Ec2MetadataService failed.\r\n2018-12-10 23:05:08.308172: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.\r\n2018-12-10 23:05:08.308389: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25\r\n2018-12-10 23:05:08.308623: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2\r\n2018-12-10 23:05:08.308642: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-10 23:05:08.360619: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 403\r\n2018-12-10 23:05:08.360679: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-10 23:05:08.360763: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-10 23:05:08.362648: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] Encountered AWSError\r\nAccessDenied\r\nAccess Denied:\r\n2018-12-10 23:05:08.362742: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-10 23:05:08.362856: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:369] FileSystemStoragePathSource encountered a file-system access error: Could not find base path s3://XXXXXXX/yyyyyyy for servable yyyyyyy\r\n2018-12-10 23:05:08.362972: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-10 23:05:08.366745: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 403\r\n2018-12-10 23:05:08.366777: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-10 23:05:08.366834: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-10 23:05:08.368216: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] Encountered AWSError\r\nAccessDenied\r\nAccess Denied:\r\n2018-12-10 23:05:08.368247: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-10 23:05:08.368274: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:369] FileSystemStoragePathSource encountered a file-system access error: Could not find base path s3://XXXXXXX/yyyyyyy for servable yyyyyyy\r\n2018-12-10 23:05:09.363019: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n```\r\n\r\nAfter digging in, and verifying within the container that:\r\n- curling the EC2MetadataService worked\r\n- using the AWS CLI and querying s3 worked\r\n- installing python and using the tensorflow api to pull the model from s3 worked\r\n\r\nI dug into the aws-sdk-cpp library and found that there was a change that introduced retries around the auth logic where we were currently experiencing failures.\r\n\r\nOnce I upgraded the library to 1.5.8 in tensorflow and redeployed, I was able to successfully authenticate with S3 and pull the model down.\r\n\r\n```\r\n2018-12-18 17:28:10.346503: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:88] Initializing AWS logger with log level 0\r\n2018-12-18 17:28:10.346621: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Initializing config loader against fileName /root//.aws/config and using profilePrefix = 1\r\n2018-12-18 17:28:10.346639: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Initializing config loader against fileName /root//.aws/credentials and using profilePrefix = 0\r\n2018-12-18 17:28:10.346652: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Setting provider to read credentials from /root//.aws/credentials for credentials file and /root//.aws/config for the config file , for use with profile default\r\n2018-12-18 17:28:10.346670: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Creating AWSHttpResourceClient with max connections2 and scheme http\r\n2018-12-18 17:28:10.346680: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Initializing CurlHandleContainer with size 2\r\n2018-12-18 17:28:10.346689: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Creating Instance with default EC2MetadataClient and refresh rate 300000\r\n2018-12-18 17:28:10.346696: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Added EC2 metadata service credentials provider to the provider chain.\r\n2018-12-18 17:28:10.348901: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Unable to open config file /root//.aws/credentials for reading.\r\n2018-12-18 17:28:10.348921: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Failed to reload configuration.\r\n2018-12-18 17:28:10.348932: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Unable to open config file /root//.aws/config for reading.\r\n2018-12-18 17:28:10.348990: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Failed to reload configuration.\r\n2018-12-18 17:28:10.349003: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Credentials have expired attempting to repull from EC2 Metadata Service.\r\n2018-12-18 17:28:10.349204: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Pool grown by 2\r\n2018-12-18 17:28:10.349221: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Connection has been released. Continuing.\r\n2018-12-18 17:28:11.348787: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:67] Curl returned error code 28\r\n2018-12-18 17:28:11.348837: E external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:67] Http request to retrieve credentials failed\r\n2018-12-18 17:28:11.348908: W external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:64] Request failed, now waiting 0 ms before attempting again.\r\n2018-12-18 17:28:11.349068: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Connection has been released. Continuing.\r\n2018-12-18 17:28:11.351869: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Connection has been released. Continuing.\r\n2018-12-18 17:28:11.355230: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Successfully pulled credentials from metadata service with access key XXXXXXXXXXXXXXXXXXXX\r\n2018-12-18 17:28:11.355341: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Connection has been released. Continuing.\r\n2018-12-18 17:28:11.358553: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Detected current region as us-west-2\r\n2018-12-18 17:28:11.358575: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Successfully reloaded configuration.\r\n2018-12-18 17:28:11.358674: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Initializing CurlHandleContainer with size 25\r\n2018-12-18 17:28:11.358870: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Pool grown by 2\r\n2018-12-18 17:28:11.358885: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:61] Connection has been released. Continuing.\r\n```\r\n\r\nI kept the changeset scoped to upgrading to 1.5.8, instead of upgrading to something new (i.e. 1.7.x), in order to reduce the amount of changes being introduced.", "CLAs look good, thanks!\n\n<!-- ok -->", "Is it possible to update to the most recent release instead?", "I took a pass at it last week. I didn't continue down the path at the time due to the API updates on their end that was causing the changeset to grow.\r\nIf we went that path, do you have a target version that you'd prefer tensorflow was upgraded to? It looks like they release a new version roughly every day https://github.com/aws/aws-sdk-cpp/releases.", "The test failures seem unrelated, rerunning.", "> The test failures seem unrelated, rerunning.\r\n\r\n@jhseu  can you please look at the CL once."]}, {"number": 24454, "title": "TFTRT: Fix bug with renaming output bindings + test case", "body": "If the same tensor is considered as an output multiple times, that tensor will be renamed which will result in a runtime error when the first output binding cannot be found.\r\n\r\nThis can occur if two or more separate identity ops are used on a tensor and those identity ops are the output of the network. Since our ConvertIdentity implementation just returns the input tensor, the output of both identity ops will be the same tensor. This is very similar to the \"rename input tensors\" issue (convert_nodes.cc line 944-958). Both of these would be solved by actually using a TRT layer in ConvertIdentity. However we can't do that yet without interfering with fusions and therefore performance.\r\n\r\nI've added a new test identity_output_test with a repro for the bug. The test passes after this fix.", "comments": ["Thanks for reviewing. This bug came up in the Transformer model where a node was feeding 3 identity nodes which were all considered outputs of the engine. I was getting runtime error when the output bindings were not being found and this reminded me of the exact same issue we previously had with the input bindings.", "The test seems to be failing because there are not enough dimensions. Please take a look.\r\n\r\nassert.h assertion failed at helpers.cpp:56 in nvinfer1::DimsCHW nvinfer1::getCHW(const nvinfer1::Dims&): d.nbDims >= 3", "> The test seems to be failing because there are not enough dimensions. Please take a look.\r\n> \r\n> assert.h assertion failed at helpers.cpp:56 in nvinfer1::DimsCHW nvinfer1::getCHW(const nvinfer1::Dims&): d.nbDims >= 3\r\n\r\nDo you know which TRT version is being used? I am unable to reproduce this on my machine. I am guessing the Shuffle layer used to require 4D inputs.", "The test is still using TensorRT 4.0.\r\n\r\ntrt_convert.py:265] Running against TensorRT version 4.0.1", "Hi Smit, it looks like IElementWise layer used to require 4D (NCHW) inputs in TRT 4.0. I will fix this by reshaping the tensor inside of BinaryTensorOpTensor with an \\#ifdef.\r\n\r\nEdit: Nevermind, that wasn't the problem. There is a bug with tensors with rank < 3 in INT8 mode with TRT4.0. Looks like we knew about this for some other tests and fixed it by disabling INT8 mode for those tests.", "This PR is ready to go."]}, {"number": 24453, "title": "DLPack support in tensorflow", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): v1.12.0\r\n- Are you willing to contribute it (Yes/No): I could help but I'm not a Tensorflow expert.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n[DLPack](https://github.com/dmlc/dlpack) is a community effort to define a common tensor data structure that could be shared by different frameworks. Currently, Pytorch and MXNet have adopted this interface. Using DLPack can benefit many projects in the ecosystem: let it be backend compiler like [TVM](https://github.com/dmlc/tvm) or front-end package like [DGL](https://github.com/dmlc/dgl). So it will be really great if Tensorflow can also adopt this interface to help new ideas derived from the mainstream tensor-based frameworks.\r\n\r\n**Will this change the current api? How?**\r\nHere is a draft proposal. Two new APIs to convert `tf.Tensor` from/to dlpack format. Examples in `torch` are `dl = torch.utils.dlpack.to_dlpack(tsor)` and `tsor = torch.utils.dlpack.from_dlpack(dl)`.\r\n\r\n**Who will benefit with this feature?**\r\nMany projects that wish to improve, optimize or be complementary to the mainstream tensor frameworks.\r\n\r\n@tqchen @zzhang-cn", "comments": ["+1", "Hi, is there any help from the dev team or the community on this?", "@jermainewang : I'm not familiar enough with DLPack to offer any insightful comments, but at a high level this seems reasonable.\r\n\r\nFrom a very very cursory look, it seems that it should be easy to translate between `TF_Tensor` or `TFE_TensorHandle` types and the [`DLTensor`](https://github.com/dmlc/dlpack/blob/5c792cef3aee54ad8b7000111c9dc1797f327b59/include/dlpack/dlpack.h#L147) types using the existing C APIs of TensorFlow ([`tensorflow/c/c_api.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h) and [`tensorflow/c/eager/c_api.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/eager/c_api.h)). I'm probably missing something, but this could be a simple extension.\r\n\r\nIf you or someone else would like to drive this, I'd encourage you to follow the [TensorFlow RFC process](https://github.com/tensorflow/community/blob/master/governance/TF-RFCs.md). Or if there are specific questions about details, feel free to use [the appropriate forums](https://www.tensorflow.org/community/) to discuss. It should be simple enough to provide something similar to the API you proposed, so if you are interested in doing so we'd be happy to help you through the details.\r\n\r\nThanks!\r\n\r\n", "@asimshankar, Could I have a try on this?", "@a6802739 - sure. Though, I am no longer actively working on the TensorFlow project, so won't be participating much.  My note from above is still valid though :):\r\n\r\n> I'd encourage you to follow the [TensorFlow RFC process](https://github.com/tensorflow/community/blob/master/governance/TF-RFCs.md). Or if there are specific questions about details, feel free to use [the appropriate forums](https://www.tensorflow.org/community/) to discuss.", "@asimshankar, Thanks a lot, So who do you think will be most likely be involved into this part from the core team? Maybe I could ask for some help directly.", "Hey @a6802739 , that's awesome! I could provide any help you want on the DLPack side.", "Hi,\r\n\r\nI would also love that tensorflow would support DLPack.\r\n\r\nIf so, integration with RAPIDS (rapids.ai) would be straight-forward.\r\n\r\nI can imagine by doing all the data prep and dimensionality reduction using RAPIDS, and then train a neural network by using the outcome of the previous steps. Everything on GPU and GPU memory.\r\n\r\nRegards,\r\nMiguel", "@alextp we discussed doing this at SysML would be interesting for zero-overhead integration of TF and TVM. It came up in TVM land again wanted to ping you on this thread. ", "@a6802739 are you still interested in implementing dlpack for TF?\r\n\r\nIf so, I think Asim's earlier comments are the way to go; look at the implementation of TFE_TensorHandle and use that to make a two-way bridge.", "It seems easy to write the C code to convert between the structs but where would the Python bridge code be put?", "tf.to_dlpack() and registering a handler for tf.convert_to_tensor() to\nhandle dlpack inputs?\n\nOn Wed, May 1, 2019 at 8:21 AM Jared Roesch <notifications@github.com>\nwrote:\n\n> It seems easy to write the C code, to convert between the structs but\n> where would the Python bridge code be put?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24453#issuecomment-488310993>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJDPH32XU222CQ3JA3PTGYRLANCNFSM4GLLV5CQ>\n> .\n>\n\n\n-- \n - Alex\n", "+1 on having support for this in TF! Has there been any movement around this?", "\ud83d\udc4d ML Engineers at Spotify would love it to be supported and unlock the RAPIDS work as suggested by @miguelangel ", "+1 I would love to have this! \r\n\r\nMight be open to working on this too, if I have the skills for what needs to be done. ", "Somehow related:\r\n\r\nhttps://github.com/pytorch/pytorch/pull/20584\r\n\r\nhttps://twitter.com/adbreind/status/1163604646394335233?s=21", "@tatianashp allowing TF to share CUDA memory with other python libraries would be really useful. Do you know who could work on this?", "A new motivation for dlpack support is that it may increase transfer speed to/from CPU<->GPU. With Pytorch, there is a speed increase of 4x to GPU, and 110x to CPU\r\n\r\nhttps://github.com/Santosh-Gupta/SpeedTorch", "Here are the implementations of [pytorch](https://github.com/pytorch/pytorch/search?l=C%2B%2B&q=dlpack) and [mxnet](https://github.com/apache/incubator-mxnet/search?l=C%2B%2B&q=dlpack) respectively.", "Any progress about this? Before waiting for the TensorFlow RFC process, we can discuss about the detail of implementation so that developers can extend with TensorFlow custom op. \r\n\r\nThe TensorFlow `Tensor` object provide API to get the array data of tensor.\r\n\r\n```\r\ninput_tensor.flat<T>().data()\r\n```\r\n\r\nCan we get the data from the above function and use to initialize the `DLTensor` like this?\r\n\r\n```\r\n  DLTensor* x;\r\n  int ndim = 1;\r\n  int dtype_code = kDLFloat;\r\n  int dtype_bits = 32;\r\n  int dtype_lanes = 1;\r\n  int device_type = kDLCPU;\r\n  int device_id = 0;\r\n\r\n  TVMArrayAlloc(shape, ndim, dtype_code, dtype_bits, dtype_lanes,\r\n                device_type, device_id, &x);\r\n  static_cast<float*>(x->data) = data;\r\n```\r\n", "https://github.com/dmlc/dgl/issues/909#issuecomment-540348053\r\n\r\n@yzh119  Would you like to provide more details on the progress?", "@tobegit3hub The key difficulty is described here https://github.com/tensorflow/tensorflow/issues/29039#issuecomment-527520270. On cpu side, we already have zero-copy between tf and numpy, which should not be the problem. \r\n\r\nHowever, I didn't see the issue mentioned above is hard to resolve, something like `cuda.synchronize` should be enough. But tf engineer seems not interested in implementing this feature. I think we may need to do this by ourselves. If you are familiar with tf C++ API, I think we can discuss together on how to do this.", "[Tensor constructs Buffer  with Allocator](https://github.com/tensorflow/tensorflow/blob/4213d5c1bd921f8d5b7b2dc4bbf1eea78d0b5258/tensorflow/core/framework/tensor.cc#L742). Buffer calls [TypedAllocator::Allocate](https://github.com/tensorflow/tensorflow/blob/4213d5c1bd921f8d5b7b2dc4bbf1eea78d0b5258/tensorflow/core/framework/tensor.cc#L448) to allocate memory through [Allocator::AllocateRaw](https://github.com/tensorflow/tensorflow/blob/b4bf76a4314450234329e7f0a6690f63b6c2659d/tensorflow/core/framework/typed_allocator.h#L47). [GPUcudaMallocAllocator::AllocateRaw](https://github.com/tensorflow/tensorflow/blob/a5b0d690466063c9eb1e024cba9a74db9f13f1c2/tensorflow/core/common_runtime/gpu/gpu_cudamalloc_allocator.cc#L39) calls [cudaMalloc](https://github.com/tensorflow/tensorflow/search?p=1&q=cudaMalloc&unscoped_q=cudaMalloc). \r\n\r\nMaybe `cuda.synchronize` related API should be added to every class involved in the above pipeline.\r\n\r\nRuntime uses [DeviceFactory](https://github.com/tensorflow/tensorflow/search?q=devicefactory&unscoped_q=devicefactory) to [CreateDevices](https://github.com/tensorflow/tensorflow/search?p=1&q=CreateDevices&unscoped_q=CreateDevices). [BaseGPUDeviceFactory::CreateGPUDevice allocates GPUDevice containing GPUAllocator](https://github.com/tensorflow/tensorflow/blob/a3e722870f45c5a7cee259b193b23c338c128aea/tensorflow/core/common_runtime/gpu/gpu_device.cc#L1208). [GPUProcessState::GetGPUAllocator](https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=GetGPUAllocator&type=) [composes](https://github.com/tensorflow/tensorflow/blob/73260e03aaa5c18a9bd9bc46d9fcb16ed091cbbd/tensorflow/core/common_runtime/gpu/gpu_process_state.cc#L136) [AllocatorParts](https://github.com/tensorflow/tensorflow/search?q=AllocatorParts&unscoped_q=AllocatorParts) including [GPUcudaMallocAllocator](https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=GPUcudaMallocAllocator&type=).\r\n\r\n[GpuExecutor::Allocate](https://github.com/tensorflow/tensorflow/blob/aba83497f568b15f9b86d3571c1f9acfcb0c1a0e/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L545) is a simple wrapper of [GpuDriver::DeviceAllocate](https://github.com/tensorflow/tensorflow/blob/b3aa334d3a199ef5d0717ef737dd40b271e1412f/tensorflow/stream_executor/cuda/cuda_driver.cc#L789) which utilizes [cuMemAlloc](https://github.com/tensorflow/tensorflow/search?q=cuMemAlloc&unscoped_q=cuMemAlloc).\r\n\r\nTensorFlow has added conversion [between CPU Tensor and numpy array](https://github.com/tensorflow/tensorflow/issues/29039#issuecomment-541040889).", "I'm also interested in helping and can take a crack at the objective, motivation, and user benefit side of the RFC.  I'm not a TF expert so the design proposal and detailed design would need to be added by someone here but it looks like @futurely has an initial idea of what's necessary.\r\n\r\n@alextp @tatianashp Are either of you willing to sponsor? \r\n@Santosh-Gupta @a6802739 @futurely @jermainewang VoVAllen Are you interested in implementing?\r\n(+1 to this if so and i'll add your names to the RFC or add your comments below)\r\n\r\nOn the RAPIDS side we've developed on GPU preprocessing capabilities for transforming tabular data using cuDF that allows for very fast dataloading and I'm asked on a regular basis when it will be available for TensorFlow.  It would be amazing to see this support in place.\r\n", "@EvenOldridge I'm willing to help. Based on my investigation, I found nvidia/dali did similar things we want, zero-copy on GPU between different frameworks and raw cuda operations (zero-copy on CPU should be easier). They wrote a tf plugin and registered some OP to do this, which I think is the proper level to implement this feature. Since I saw you are also from nvidia, could you try to involve the author of dali's tf plugin also? I believe this would make the implementation process much easier for us. Also based on dali's practice, I think it's possible to implement this outside tf repo.", "Also I found the synchronize API is exposed at `context.async_wait` ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/benchmarks/resnet50/resnet50_test.py#L103)). Seems tf has many undocumented things...\r\n", "Thanks @VoVAllen and @EvenOldridge . We have implemented the TensorFlow custom op to convert TensorProto to DLPack and run TVM as TensorFlow op in https://github.com/tobegit3hub/tftvm . It would be much better to support the native zero-copy from TensorFlow API. Before that, we still need to convert the data type by ourselves.", "> \r\n> \r\n> @EvenOldridge I'm willing to help. Based on my investigation, I found nvidia/dali did similar things we want, zero-copy on GPU between different frameworks and raw cuda operations (zero-copy on CPU should be easier). They wrote a tf plugin and registered some OP to do this, which I think is the proper level to implement this feature. Since I saw you are also from nvidia, could you try to involve the author of dali's tf plugin also? I believe this would make the implementation process much easier for us. Also based on dali's practice, I think it's possible to implement this outside tf repo.\r\n\r\nThat is not true. DALI asks [TF to allocate memory](https://github.com/NVIDIA/DALI/blob/master/dali_tf_plugin/daliop.cc#L273) and then [copy is made](https://github.com/NVIDIA/DALI/blob/master/dali_tf_plugin/daliop.cc#L310L315). Although it is GPU2GPU so it is fast.", "Thanks Janusz.  Per our conversation I'm going to add DALI to the list of frameworks that would benefit from dlpack support.", "Here's the draft proposal: https://github.com/EvenOldridge/community/blob/EvenOldridge-dlpack-support/rfcs/20191016-dlpack-support.md\r\n\r\nThe design proposal side is very light at the moment and needs support.\r\n\r\n", "@EvenOldridge @jroesch Thanks a lot. Now I think there's no trivial way to do this. I think the key difficulty is the management on the momery lifetime, which may need input from tf engineers.\r\n\r\nHere's my [investigation](https://github.com/tensorflow/tensorflow/issues/33254) on share memory on cpu, FYI.", "@alextp has agreed to sponsor, and we're going to take a look into how feasible it is to implement the way we hope with the possibility of zero copy.  Here's Alex's input:\r\n\r\n> AFAICT it should be easy to take cuda pointers in and out of TF and use them to build dlpack structures from tensors or vice versa. The tricky part is that TF does not use cudamalloc to allocate memory but its own allocator whose internal state is stored on the CPU and matches the head of TF's compute stream, so we need to sync TF's stream before the memory is usable from dlpack and similarly sync other cuda streams before memory is made usable by TF tensors (and similarly we need to sync the streams when trying to free the buffers).\r\n\r\nIf zero copy isn't possible we'll fall back to an implementation that copies the data.", "@EvenOldridge That's great! As I mentioned, there's api in Python to sync all streams. I think this would be enough for most scenarios. \r\nThe difficulty for DLPack I think is the memory lifetime management. It's more than exposing a pointer.\r\n\r\n> `context.async_wait` ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/benchmarks/resnet50/resnet50_test.py#L103)).\r\n\r\n", "@EvenOldridge \r\nHere's my general thoughts on implementation:\r\n\r\n- to_dlpack\r\n  - Exposing the `TensorBuffer` and its `void* data()` under `Tensor` class. `Ref` it and enclosing `UnRef` into the deleter of DLManagedTensor\r\n- from_dlpack\r\n  - Write a Custom `Allocator` such as `ExternalMemAllocator`, and use this to deallocate buffer at deconstruction. \r\n\r\nFeel free to comment.", "Hello everyone, some great news. @VoVAllen and I just prototyped a solution for this feature. It is zero-copy and can be used quite easily as a standalone python package. Many solutions are inspired from this discussion thread. Thanks everyone! Here is the RFC (https://github.com/VoVAllen/tf-dlpack/issues/3). Feel free to leave any feedback. We will try to push the release soon.", "Great job!  Is this going to be merged into Tensorflow proper like Chainer and Pytorch or are we going to have to load a module to get this functionality.  I can help test.", "I'm going to add the package solution to the RFC proposal which hopefully should put some weight behind it.  Huge thanks and props to @VoVAllen and @jermainewang for their work on this.", "/cc @sanjoy ", "Hi,\r\n\r\nI'd be happy to sponsor an [RFC](https://www.tensorflow.org/community/contribute/rfc_process) if someone else is willing to drive the design and implementation.", "Hi everyone, we just released the `tfdlpack` package. Now, everyone could install it by simply `pip install tfdlpack` or `pip install tfdlpack-gpu` for CUDA support. Feel free to give any feedback if anything goes wrong. We are also looking forward to the official support of this feature. Please refert to the [RFC](https://github.com/tensorflow/community/pull/180).", "Nice work, kudos to @VoVAllen .", "Closing this issue because the RFC and DLPack support in TF have landed (though it is still experimental)."]}, {"number": 24452, "title": "Internal change.", "body": "PiperOrigin-RevId: 226115035", "comments": []}, {"number": 24451, "title": "Update version to 1.13.0-rc0", "body": "", "comments": []}, {"number": 24450, "title": "TF RPI build fails to work properly with Go API", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux rpi3-0 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l GNU/Linux\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNope\r\n\r\n- TensorFlow installed from (source or binary):\r\nSource\r\n\r\n- TensorFlow version (use command below):\r\nAt 9fd8253129\r\n\r\n- Python version:\r\nPython 2.7.13\r\n\r\n- Bazel version (if compiling from source):\r\n```\r\n$ bazel version\r\nINFO: Invocation ID: e77ca562-1751-40be-9b60-addbf843411d\r\nBuild label: 0.20.0- (@non-git)\r\nBuild target: bazel-out/arm-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Dec 13 03:56:33 2018 (1544673393)\r\nBuild timestamp: 1544673393\r\nBuild timestamp as int: 1544673393\r\n```\r\n\r\n- GCC/Compiler version (if compiling from source):\r\ngcc (Raspbian 4.8.5-4) 4.8.5\r\n\r\n- CUDA/cuDNN version:\r\nN/A\r\n\r\n- GPU model and memory:\r\nN/A\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI am using Go API for TensorFlow on Raspberry PI. `go test` fails with following error mesg:\r\n```\r\n$ go test -v github.com/tensorflow/tensorflow/tensorflow/go\r\n# github.com/tensorflow/tensorflow/tensorflow/go [github.com/tensorflow/tensorflow/tensorflow/go.test]\r\n./attrs.go:173:15: type [1073741824]_Ctype_longlong larger than address space\r\n./attrs.go:173:15: type [1073741824]_Ctype_longlong too large\r\nFAIL\tgithub.com/tensorflow/tensorflow/tensorflow/go [build failed]\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@asimshankar It is great to see that TF master is cross-compiling fine for Raspberry PI (I tried at commit `92b598a32d`). Just wondering if team is planning to bring up Go API to work properly in master. I see following errors:\r\n```\r\n$ go test -v github.com/tensorflow/tensorflow/tensorflow/go\r\n# github.com/tensorflow/tensorflow/tensorflow/go\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_ContextListDevices':\r\n/tmp/go-build/cgo-gcc-prolog:44: undefined reference to `TFE_ContextListDevices'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_ContextOptionsSetAsync':\r\n/tmp/go-build/cgo-gcc-prolog:61: undefined reference to `TFE_ContextOptionsSetAsync'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_ContextOptionsSetConfig':\r\n/tmp/go-build/cgo-gcc-prolog:76: undefined reference to `TFE_ContextOptionsSetConfig'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_DeleteContext':\r\n/tmp/go-build/cgo-gcc-prolog:88: undefined reference to `TFE_DeleteContext'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_DeleteContextOptions':\r\n/tmp/go-build/cgo-gcc-prolog:100: undefined reference to `TFE_DeleteContextOptions'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_NewContext':\r\n/tmp/go-build/cgo-gcc-prolog:116: undefined reference to `TFE_NewContext'\r\n/tmp/go-build505912479/b048/_x003.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_NewContextOptions':\r\n/tmp/go-build/cgo-gcc-prolog:133: undefined reference to `TFE_NewContextOptions'\r\n/tmp/go-build505912479/b048/_x004.o: In function `_cgo_70e30ee47b92_Cfunc_TF_AddGradientsWithPrefix':\r\n/tmp/go-build/cgo-gcc-prolog:61: undefined reference to `TF_AddGradientsWithPrefix'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_DeleteTensorHandle':\r\n/tmp/go-build/cgo-gcc-prolog:40: undefined reference to `TFE_DeleteTensorHandle'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_NewTensorHandle':\r\n/tmp/go-build/cgo-gcc-prolog:56: undefined reference to `TFE_NewTensorHandle'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleBackingDeviceName':\r\n/tmp/go-build/cgo-gcc-prolog:75: undefined reference to `TFE_TensorHandleBackingDeviceName'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleCopyToDevice':\r\n/tmp/go-build/cgo-gcc-prolog:96: undefined reference to `TFE_TensorHandleCopyToDevice'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleDataType':\r\n/tmp/go-build/cgo-gcc-prolog:114: undefined reference to `TFE_TensorHandleDataType'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleDeviceName':\r\n/tmp/go-build/cgo-gcc-prolog:133: undefined reference to `TFE_TensorHandleDeviceName'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleDim':\r\n/tmp/go-build/cgo-gcc-prolog:153: undefined reference to `TFE_TensorHandleDim'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleNumDims':\r\n/tmp/go-build/cgo-gcc-prolog:172: undefined reference to `TFE_TensorHandleNumDims'\r\n/tmp/go-build505912479/b048/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleResolve':\r\n/tmp/go-build/cgo-gcc-prolog:191: undefined reference to `TFE_TensorHandleResolve'\r\ncollect2: error: ld returned 1 exit status\r\nFAIL\tgithub.com/tensorflow/tensorflow/tensorflow/go [build failed]\r\n```\r\n", "@sdeoras : those messages seems symptomatic of having an older version of the C library. Could it be that you are linking against an old version?", "@asimshankar : thank you. yes, it was an older library i was linking against. Previous errors are gone but one last issue still remains:\r\n```\r\n$ go test -v github.com/tensorflow/tensorflow/tensorflow/go\r\n# github.com/tensorflow/tensorflow/tensorflow/go [github.com/tensorflow/tensorflow/tensorflow/go.test]\r\n./attrs.go:173:15: type [1073741824]_Ctype_longlong larger than address space\r\n./attrs.go:173:15: type [1073741824]_Ctype_longlong too large\r\nFAIL\tgithub.com/tensorflow/tensorflow/tensorflow/go [build failed]\r\n```\r\nI am able to get past this error simply by reducing the slice length in `attrs.go:173` to:\r\n`slice := (*[1 << 27]C.int64_t)(unsafe.Pointer(dim))[:numDim:numDim]`\r\n", "```\r\nroot@pc:/home/deslum/src/test# go get github.com/tensorflow/tensorflow/tensorflow/go\r\n# github.com/tensorflow/tensorflow/tensorflow/go\r\n/tmp/go-build375822434/b001/_x011.o: In function `_cgo_70e30ee47b92_Cfunc_TFE_TensorHandleBackingDeviceName':\r\n/tmp/go-build/cgo-gcc-prolog:75: undefined reference to `TFE_TensorHandleBackingDeviceName'\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n", "@deslum : Sorry about that, the issue you encountered is different from what @sdeoras and is more like https://github.com/tensorflow/tensorflow/issues/23257#issuecomment-433751410 (Which I agree is a problem regardless). For now, you could work around this by doing what is suggested in the comment there. I'll send out a fix so that the `master` branch compiles again. Longer term probably want to figure something out with go modules or something.\r\n\r\n@sdeoras : Sorry, haven't been able to dig into this - from a cursory look seems like something to do with `long long*` pointers on a 32-bit architecture?", "@asimshankar the issue i am facing is resolved by reducing the length to `1<<27` in [attrs.go:173](https://github.com/tensorflow/tensorflow/blob/9ad0810fd55096fc86a58300c5a2710b2f3b5175/tensorflow/go/attrs.go#L173)", "@sdeoras: Oh, right, sorry missed that last sentence of your previous message. Would you like to contribute a PR for this?", "@asimshankar: sure, i'll send out a pr for this bug.", "For the record, fixed by #24840\r\nThanks @sdeoras "]}, {"number": 24449, "title": "Update doc references to use `tfp.distributions`", "body": "Update all references in documentation to use `tfp.distributions` instead of `tf.contrib.distributions`, as `tf.contrib.distributions` is deprecated.", "comments": ["Nagging Reviewer @jvdillon: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied."]}, {"number": 24448, "title": "I run the code in distributed mode and my code run good in asynchronous mode; but the  code run unsuccessful in synchronous mode", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.11\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.19\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:no GPU\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n292, in _do_call    return fn(*args)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n277, in _run_fn    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n367, in _call_tf_sessionrun    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef missing attr 'reduction_type'\r\n from Op<name=ConditionalAccumulator; signature= -> handle:Ref(string); attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=reduction_type:string,default=\"MEAN\",allowed=[\"MEAN\", \"SUM\"]; is_stateful=true>; NodeDef: {{node sync_replicas/conditional_accumulator}} = ConditionalAccumulator[_class=[\"loc:@sync_replicas/SetGlobalStep\"], container=\"\", dtype=DT_FLOAT, shape=[3,3,3,16], shared_name=\"conv0/conv:0/grad_accum\", _device=\"/job:ps/replica:0/task:0/device:CPU:0\"]()\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"distributed1.py\", line 318, in <module>\r\n    main()\r\n  File \"distributed1.py\", line 217, in main\r\n    with tf.train.MonitoredTrainingSession(master=server.target, is_chief=True,hooks=[sync_replicas\r\n_hook]) as sess:  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 504, in MonitoredTrainingSession    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 921, in __init__    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 643, in __init__    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 1107, in __init__    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 1112, in _create_session    return self._sess_creator.create_session()\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session\r\n.py\", line 807, in create_session    hook.after_create_session(self.tf_sess, self.coord)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_opt\r\nimizer.py\", line 494, in after_create_session    session.run(self._local_init_op)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 8\r\n87, in run    run_metadata_ptr)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n110, in _run    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n286, in _do_run    run_metadata)\r\n  File \"/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1\r\n308, in _do_call    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef missing attr 'reduction_type'\r\n from Op<name=ConditionalAccumulator; signature= -> handle:Ref(string); attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=reduction_type:string,default=\"MEAN\",allowed=[\"MEAN\", \"SUM\"]; is_stateful=true>; NodeDef: {{node sync_replicas/conditional_accumulator}} = ConditionalAccumulator[_class=[\"loc:@sync_replicas/SetGlobalStep\"], container=\"\", dtype=DT_FLOAT, shape=[3,3,3,16], shared_name=\"conv0/conv:0/grad_accum\", _device=\"/job:ps/replica:0/task:0/device:CPU:0\"]()", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "the code is here:\r\nopt = tf.train.MomentumOptimizer(learning_rate=lr_placeholder, momentum=0.9)       opt=tf.train.SyncReplicasOptimizer(opt,replicas_to_aggregate=len(worker_hosts),total_num_replicas=len(worker_hosts),use_locking=True)\r\ntrain_op = opt.minimize(full_loss, global_step=global_step)\r\nval_op = validation_op(validation_step, vali_top1_error, vali_loss)\r\nsync_replicas_hook = opt.make_session_run_hook(True)\r\ninit=tf.global_variables_initializer()\r\nwith training.MonitoredTrainingSession(master=server.target, is_chief=True,hooks=[sync_replicas_hook]) as sess:", "> In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\nthe code is here:\r\nopt = tf.train.MomentumOptimizer(learning_rate=lr_placeholder, momentum=0.9) opt=tf.train.SyncReplicasOptimizer(opt,replicas_to_aggregate=len(worker_hosts),total_num_replicas=len(worker_hosts),use_locking=True)\r\ntrain_op = opt.minimize(full_loss, global_step=global_step)\r\nval_op = validation_op(validation_step, vali_top1_error, vali_loss)\r\nsync_replicas_hook = opt.make_session_run_hook(True)\r\ninit=tf.global_variables_initializer()\r\nwith training.MonitoredTrainingSession(master=server.target, is_chief=True,hooks=[sync_replicas_hook]) as sess:\r\n", "Please try opt.make_session_run_hook(is_chief) instead of opt.make_session_run_hook(True)", "> Please try opt.make_session_run_hook(is_chief) instead of opt.make_session_run_hook(True)\r\n\r\n\u8fd9\u6709\u5565\u4e0d\u540c\u4e48\uff0cis_chief\u8fd9\u91cc\u4e5f\u662ftrue\u5427", "@Crishuang95   \r\nis_chief\u662f\u4e0d\u662f\u5e94\u8be5\u5728worker 0\u4e0a\u662fTrue\uff0c\u5176\u4ed6worker\u4e0a\u662fFalse\u3002", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24447, "title": "Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.13\r\n- Python version: 2.7.12\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.19.1\r\n- GCC/Compiler version (if compiling from source): gcc 5.4.0\r\n- CUDA/cuDNN version: 9.2 / 7\r\n- GPU model and memory: 4x Titan XP\r\n\r\n```\r\n$ bazel clean\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\n$ ./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.19.1 installed.\r\nPlease specify the location of python. [Default is /home/erick/.virtualenvs/p2/bin/python]: \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'getsitepackages'\r\nFound possible Python library paths:\r\n  /home/erick/.virtualenvs/p2/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/erick/.virtualenvs/p2/lib/python2.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.2\r\n\r\n\r\nPlease specify the location where CUDA 9.2 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: \r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]: \r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apacha Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nERROR: /home/erick/dev/tensorflow/tensorflow/tools/pip_package/BUILD:41:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: \r\n\r\n/home/erick/dev/tensorflow/tensorflow/tools/pip_package/BUILD:41:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nINFO: Elapsed time: 12.939s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (132 packages loaded, 419 targets configured)\r\n    currently loading: tensorflow/core ... (3 packages)\r\n```\r\n\r\n", "comments": ["Can you update your cuDNN version and build again?. You need cuDNN SDK (>= 7.2).", "My bad, my cuDNN version is indeed 7.2.", "Is this still an issue for you? Were you able to get it running?", "To be honest I don't remember what exactly I did, but it is not an issue anymore.", "Hi,\r\nthis issue just happened to me.\r\nCuda - 10.0\r\nCudaDNN - 7.4\r\n\r\n./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 9cf9c46b-c379-4fdc-a9f5-13ad76711061\r\nYou have bazel 0.22.0 installed.\r\nPlease specify the location of python. [Default is /home/peter/PycharmProjects/Virtual_envs/tensorflow/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/peter/PycharmProjects/Virtual_envs/tensorflow/lib/python3.6/site-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/home/peter/PycharmProjects/Virtual_envs/tensorflow/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10.0]: 10.0\r\n\r\n\r\nPlease specify the location where CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 7.4\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]: \r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 7.5]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: y\r\nClang will be downloaded and used to compile tensorflow.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apache Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\nbash: ./bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package/tmp/tensorflow_pkg\r\nbash: ./bazel-bin/tensorflow/tools/pip_package/build_pip_package/tmp/tensorflow_pkg: No such file or directory\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: e9e2dd08-b8a0-4807-b1fe-cd6842a67a51\r\nDEBUG: Rule 'build_bazel_rules_swift' modified arguments {\"commit\": \"001736d056d7eae20f1f4da41bc9e6f036857296\", \"shallow_since\": \"1547844730 -0800\"} and dropped [\"tag\"]\r\nDEBUG: /home/peter/.cache/bazel/_bazel_peter/21121c77bac67ad4a1aed68d97d6cb00/external/build_bazel_rules_apple/apple/repositories.bzl:35:5: \r\nWARNING: `build_bazel_rules_apple` depends on `bazel_skylib` loaded from https://github.com/bazelbuild/bazel-skylib.git (tag 0.6.0), but we have detected it already loaded into your workspace from None (tag None). You may run into compatibility issues. To silence this warning, pass `ignore_version_differences = True` to `apple_rules_dependencies()`.\r\n\r\nERROR: /home/peter/tensorflow/tensorflow/tools/pip_package/BUILD:34:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: \r\n\r\n/home/peter/tensorflow/tensorflow/tools/pip_package/BUILD:34:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nINFO: Elapsed time: 41.489s\r\nINFO: 0 processes.\r\n\r\n", "@psandev Try not to use clang to compile the tf. It works for me. "]}]