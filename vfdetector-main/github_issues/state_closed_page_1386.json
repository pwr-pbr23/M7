[{"number": 11483, "title": "update word2vec_basic.py", "body": "Fix TSNE invocation in tutorials word2vec assignment", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "I can not run  word2vec_basic.py by command :  `python  word2vec_basic.py  ` It shows that the script can not download data, connection time out `Traceback (most recent call last):\r\n  File \"word2vec_basic.py\", line 49, in <module>\r\n    filename = maybe_download('text8.zip', 31344016)\r\n  File \"word2vec_basic.py\", line 39, in maybe_download\r\n    filename, _ = urllib.request.urlretrieve(url + filename, filename)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/urllib.py\", line 98, in urlretrieve\r\n    return opener.retrieve(url, filename, reporthook, data)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/urllib.py\", line 245, in retrieve\r\n    fp = self.open(url, data)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/urllib.py\", line 213, in open\r\n    return getattr(self, name)(url)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/urllib.py\", line 350, in open_http\r\n    h.endheaders(data)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/httplib.py\", line 1053, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/httplib.py\", line 897, in _send_output\r\n    self.send(msg)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/httplib.py\", line 859, in send\r\n    self.connect()\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/httplib.py\", line 836, in connect\r\n    self.timeout, self.source_address)\r\n  File \"/home/deepinsight/anaconda2/lib/python2.7/socket.py\", line 575, in create_connection\r\n    raise err\r\nIOError: [Errno socket error] [Errno 110] Connection timed out`  how can I fix it?"]}, {"number": 11482, "title": "Fix TSNE invocation in Udacity word2vec assignment", "body": "Default TSNE method recently changed to the approximate `method='barnes_hut'` which fails to converge per https://github.com/tensorflow/tensorflow/pull/11455", "comments": ["thank you!"]}, {"number": 11481, "title": "Fix on 'Use mcpu instead of march for ppc64le'", "body": "Use of [] around 'if is_ppc64le; then' makes it always return true, \r\ncausing \"deprecated: -mcpu\" gcc warnings on every other arch.\r\nThis fixes commit 9f57dc8", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "PR merged. Thanks, @elefthei "]}, {"number": 11480, "title": "Adding a comma to a Python snippet", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11479, "title": "Not able to install tensflow on Windows 7", "body": "Hi,\r\n\r\nI am not able to tensor flow on Windows7 machine. I searched it and found it seems to b a proxy server problem which is trying to connect to pypi.python.org. I configured it also & tried to install tensorflow, it's still not working. Can anyone tell me how can I install it without compromising the security?\r\n\r\nThanks, \r\nYugank Narula\r\n", "comments": ["_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nSounds like this is happening during the `pip install tensorflow` phase and you're unable to access the file. This is better off on Stack Overflow. In the meantime, please try one of the following:\r\n(Assuming CPU)\r\n\r\n**Python 3.5**\r\n`pip install https://ci.tensorflow.org/view/Release/job/release-win/lastStableBuild/M=windows,PY=35/artifact/cmake_build/tf_python/dist/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl`\r\n\r\n**Python 3.6**\r\n`pip install https://ci.tensorflow.org/view/Release/job/release-win/lastStableBuild/M=windows,PY=36/artifact/cmake_build/tf_python/dist/tensorflow-1.2.1-cp36-cp36m-win_amd64.whl`\r\n\r\nEDIT: The S/O question is here: https://stackoverflow.com/questions/45081429/\r\n~~If you decide to move this issue to Stack Overflow, please post the link here so that myself (or others that stumble upon this issue) can find the S/O thread.~~", "Create a separate environment in your Local Machine and then download and install Tensor Flow.", "Try installing tensorflow under Anaconda?", "Thank you community members for supporting our friend. Please use [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) in the future, since this issue tracker is for bugs and feature requests. There is also a larger community that reads questions there."]}, {"number": 11478, "title": "Does inception model detect multiple object in one image?", "body": "I have use retrain.py to train tensorflow with my own dataset of traffic sign but it seems it doesn't capture multi-object in one image.I am using the label_image.py to detect the object in my image.I have an image of two road sign which exists in my dataset but i get only one sign with high accuracy.It doesn't detect other sign.", "comments": ["Inception is a classification model, not a detection model. It only labels entire images. Please don't use bugs as a question forum, prefer StackOverflow for that."]}, {"number": 11477, "title": "dequeue or dequeue_many will fail immediately after close the queue", "body": "After close the queue, subsequent `dequeue` and `dequeue_many` operations that won't block waiting for more elements to be enqueued and will fail immediately.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11476, "title": "Cannot restore faster_rcnn checkpoint", "body": "I want to reload faster_rcnn_resnet101 model parameters and run as follows: \r\n\r\npython export_inference_graph.py --input_type image_tensor --pipeline_config_path samples/configs/faster_rcnn_resnet101_coco.config --checkpoint_path checkpoints/faster_rcnn_resnet101_coco_checkpoint/model.ckpt --inference_graph_path checkpoints/faster_rcnn_resnet101_coco_checkpoint/test.pb\r\n\r\nBut it poses OutOfRangeError.\r\nOutOfRangeError (see above for traceback): Read less bytes than requested\r\n\t [[Node: save/RestoreV2_408 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_408/tensor_names, save/RestoreV2_408/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_528/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1164_save/RestoreV2_528\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nWhat can I do for this error? ", "comments": ["There seems to be a problem with the checkpoint file you are using. Due to the use of a wrong checkpoint value it might be throwing this error. Please try to verify and get back.\r\n", "I hope that works and make sure you close the issue if it does so. If you get any further errors please get back.", "Hi, @shreyneil , It works on r1.1.0(another machine with 11G video memory). When I decrease my tensorflow to r1.1.0, it still works wrong (Only 6G video memory). What's your machine configuration?  Does the video memory is the main reason?"]}, {"number": 11475, "title": "PR again: Enable building label_image with jpeg/gif/png decoder for Android. ", "body": "Modify #11451 according to @petewarden's comments.\r\n\r\nEnable building label_image with jpeg/gif/png decoder for Android. \r\nAdd dependency \"android_tesnorflow_image_op\" to label_image, which\r\nis not overlapped with android_tensorflow_kernels.\r\n\r\nHi Pete,\r\nPlease review it again. Looking forward to your advice, if any.\r\nThank you!\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "I would like to ask Peter to review it. @petewarden ", "Jenkins, test this please.", "Mind running buildifier (https://github.com/bazelbuild/buildtools/releases) on the BUILD files so it passes our sanity checks?", "Hi,\r\nIt seems that timeout happens for those regression tests.\r\nAll the Jenkins console logs are ended with almost the same information:\r\n\r\n----------\r\n16:47:08 Build was aborted\r\n16:47:08 Aborted by unknown\r\n16:47:08 [Set GitHub commit status (universal)] **PENDING on repos [] (sha:3c55ad6) with context:tensorflow-pull-requests-android**\r\n16:47:08 Unable to get pull request builder trigger!!\r\n16:47:08 Setting status of b3ab099dfc9330ba38f26b76351aa5271509e87f to FAILURE with url https://ci.tensorflow.org/job/tensorflow-pull-requests-android/5776/ and message: 'FAILURE\r\n16:47:08  '\r\n16:47:08 Using context: Android Demo App\r\n16:47:08 Finished: ABORTED\r\n---------------\r\n\r\nPlease launch the test again.\r\nThanks! ", "Check the Sanity Checks test. When that one fails, it aborts all the other tests.", "@qjivy ping?  Have you looked at the sanity test logs to understand what is blocking further testing?  Thanks!", "@vrv  I have done the buildifier reformat for the BUILD files. Could you please help to launch the sanity check again?\r\nThank you!", "Jenkins, test this please."]}, {"number": 11474, "title": "fail to run android example", "body": "### System information\r\nbazel version:\r\nBuild label: 0.5.2-homebrew\r\n\r\njava version: \"1.8.0_131\"\r\n\r\n### workspace config:\r\nandroid_sdk_repository(\r\n  name = \"androidsdk\",\r\n  api_level = 23,\r\n  build_tools_version = \"25.0.1\",\r\n  path = \"/Users/scucheri/Library/Android/sdk\",\r\n)\r\n\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/Users/scucheri/Library/Android/sdk/ndk-bundle\",\r\n    api_level=14) \r\n\r\n\r\n### Describe the problem\r\nerror when I run 'bazel build //tensorflow/examples/android:tensorflow_demo' in terminal, could you tell me how to solve this?\r\n\r\n### Source code / logs\r\nbazel build //tensorflow/examples/android:tensorflow_demo\r\nWARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 15. The major revisions supported by Bazel are [10, 11, 12, 13, 14]. Defaulting to revision 14.\r\nERROR: /private/var/tmp/_bazel_scucheri/f55efc3e55d5b53a9cbb2375bb9bdf55/external/androidsdk/BUILD.bazel:64:1: Traceback (most recent call last):\r\n        File \"/private/var/tmp/_bazel_scucheri/f55efc3e55d5b53a9cbb2375bb9bdf55/external/androidsdk/BUILD.bazel\", line 64\r\n                create_system_images_filegroups(system_image_dirs = [\"system-ima...\", <53 more arguments>])\r\n        File \"/private/var/tmp/_bazel_scucheri/f55efc3e55d5b53a9cbb2375bb9bdf55/external/bazel_tools/tools/android/android_sdk_repository_template.bzl\", line 246, in create_system_images_filegroups\r\n                int(apidir.split(\"-\")[1])\r\ninvalid literal for int() with base 10: \"MNC\".\r\nERROR: /private/var/tmp/_bazel_scucheri/f55efc3e55d5b53a9cbb2375bb9bdf55/external/androidsdk/BUILD.bazel:8:1: Target '@androidsdk//:build-tools/25.0.1/lib/dx.jar' contains an error and its package is in error and referenced by '@androidsdk//:dx_jar'.\r\nERROR: /private/var/tmp/_bazel_scucheri/f55efc3e55d5b53a9cbb2375bb9bdf55/external/androidsdk/BUILD.bazel:8:1: Target '@androidsdk//:dx_jar' contains an error and its package is in error and referenced by '@androidsdk//:dx_jar_import'.\r\nERROR: /Users/scucheri/AllMyProjects/AndroidStudioProjects/TmallAndroidProjects/tensorflow/WORKSPACE:20:1: Target '@androidsdk//:dx_jar_import' contains an error and its package is in error and referenced by '//external:android/dx_jar_import'.\r\nERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.\r\nINFO: Elapsed time: 3.653s\r\n", "comments": ["@scucheri Make sure you have the paths correct. /Users/scucheri/Library/Android/sdk/ndk-bundle should contain ndk-build, and /Users/scucheri/Library/Android/sdk should contain tools/android.\r\n\r\nIt seems to somehow be getting confused and splitting -MNC out of one of the sdk/.../android-MNC/ dirs rather than the appropriate API level. Do you have the indicated APIs installed? You can check via sdk/tools/android.", "yeah,  /Users/scucheri/Library/Android/sdk/ndk-bundle  contains ndk-build. \r\n\r\nFinally I solve this problem by changing the tensorflow source code from r1.2 to r1.0 and change bazel version from 0.5.2 to 0.4.3 .\r\n\r\nIs it caused by incompatibility ?", "There shouldn't be any incompatibility. My guess is that changing to TensorFlow 1.0 changed the default SDK level to one you actually have installed. I'd try ensuring that the `android` tool packaged with the SDK shows you have the relevant API levels installed.", "where is the default SDK level configured  ?   The workspace.bzl file config is always like below when I build the project of deferent versions :\r\n\r\nworkspace config:\r\n\r\nandroid_sdk_repository(\r\nname = \"androidsdk\",\r\napi_level = 23,\r\nbuild_tools_version = \"25.0.1\",\r\npath = \"/Users/scucheri/Library/Android/sdk\",\r\n)\r\n\r\nandroid_ndk_repository(\r\nname=\"androidndk\",\r\npath=\"/Users/scucheri/Library/Android/sdk/ndk-bundle\",\r\napi_level=14)\r\n\r\n", "Have you confirmed that these versions are installed in your SDK with the `android `tool?", "yeah , they have been installed correctly", "Based on the other issue it seems like you were able to get past this, is that correct?", "No, That question is different from this.  This question is about bazel build error.\r\n\r\ntensorflow r1.2 & bazel 0.5.2 cause error\r\ntensorflow r1.0 & bazel 0.4.3 build successfully\r\n\r\n\r\n", "Have you tried r1.0 with bazel 0.5.2?\r\n\r\nMy best guess at the cause is that something is causing it to evaluate the wrong paths when searching the SDK directory looking for API level (it's trying to evaluate \"MNC\" from a partial path as an integer).\r\n\r\nYou might have better luck over at https://github.com/bazelbuild/bazel with this, as I doubt it has anything directly to do with TF.", "Closing due to inactivity; please respond with additional details if the issue persists."]}, {"number": 11473, "title": "Update github link in roadmap.md", "body": "Update github link with latest labels.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Transient failure, try again.\r\n\r\nJenkins, test this please."]}, {"number": 11472, "title": "Sorry to Reply you.My problem is tensor-flow un-incompatible with windows IIS?", "body": "Sorry, i just have time to reply you. Thanks for replying me.\r\nI means I use Flask to call tensor-flow py. And mount Flask to windows IIS. Local run ok. But in IIS will show FastCgi error. Check local run is ok,no error. But when in IIS, when i import keras, it will show fastcgi error. but when don't import keras, it will ok. If tensor-flow isun-incompatible with IIS?\r\n![image](https://user-images.githubusercontent.com/22673941/28158872-b733b454-67ed-11e7-914e-303340bdc081.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28158879-bc5bc0c0-67ed-11e7-90f2-e7f72fd69e02.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28158885-c147b828-67ed-11e7-96da-6bd9324bdba0.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28158983-0ff8cca0-67ee-11e7-8fc7-8a063950b19d.png)\r\n", "comments": ["Looks like you are meant to be replying to #11310 instead of creating a new issue.\r\n\r\nSee @gunan response here: https://github.com/tensorflow/tensorflow/issues/11310#issuecomment-315064408\r\n\r\nFastCGI error is not a Tensorflow error but one from IIS I think. As @gunan has said, it is not supported on those platforms. Continue the conversation on #11310. Good luck!"]}, {"number": 11471, "title": "XLA crash on Wasserstein GAN", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: TensorFlow installed from source\r\n- **TensorFlow version (use command below)**: v1.2.0-1382-g708cbaf 1.2.0\r\n- **Python version**:  Python 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 8 / cudnn 6\r\n- **GPU model and memory**: 2x1080 Ti, 12 Gb\r\n### Describe the problem\r\nWhen I'm running this code: https://github.com/Randl/WassersteinGAN.tensorflow with XLA, I get the following error message:\r\n```\r\nLLVM ERROR: Cannot select: 0x7f4c300d4878: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7f4c30093858, 0x7f4c300d5098, 0x7f4c300d5168, 0x7f4c300e6c20\r\n  0x7f4c300d5098: i64,ch = CopyFromReg 0x7f4c30093858, Register:i64 %vreg0\r\n    0x7f4c300d5100: i64 = Register %vreg0\r\n  0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\r\n    0x7f4c300d56b0: i16 = Register %vreg3\r\n  0x7f4c300e6c20: i16 = and 0x7f4c300d5168, 0x7f4c300d5370\r\n    0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\r\n      0x7f4c300d56b0: i16 = Register %vreg3\r\n    0x7f4c300d5370: i16 = AssertZext 0x7f4c300d4c20, ValueType:ch:i1\r\n      0x7f4c300d4c20: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg1\r\n        0x7f4c300d4948: i16 = Register %vreg1\r\nIn function: _fusion__1\r\n*** Error in `python3': free(): invalid size: 0x00007f4ac8091fe0 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f4e6c2507e5]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f4e6c25937a]\r\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f4e6c25d53c]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0x6b98aa)[0x7f4a9f3f48aa]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xdb80e)[0x7f4a9ee1680e]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xc034b)[0x7f4a9edfb34b]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(__cuda_CallJitEntryPoint+0xdcc)[0x7f4a9edf1aec]\r\n/usr/lib/nvidia-375/libnvidia-fatbinaryloader.so.375.66(fatBinaryCtl_Compile+0x302)[0x7f4df0b125c2]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a1ee2)[0x7f4e07c31ee2]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a2a63)[0x7f4e07c32a63]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a3133)[0x7f4e07c33133]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0xcf7b3)[0x7f4e07b5f7b3]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(cuModuleLoadDataEx+0x75)[0x7f4e07c77055]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x4d0b7ba)[0x7f4e1370d7ba]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0xff)[0x7f4e139e998f]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x2d)[0x7f4e139e977d]\r\n```\r\n\r\nWithout XLA it works OK.\r\n", "comments": ["I assumed the problem might be with memory, but for smaller batches I get the same error:\r\n```\r\nLLVM ERROR: Cannot select: 0x7fe90c0d4608: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7fe90c07f388, 0x7fe90c0d4e28, 0x7fe90c0d4ef8, 0x7fe90c0e6fe0\r\n  0x7fe90c0d4e28: i64,ch = CopyFromReg 0x7fe90c07f388, Register:i64 %vreg0\r\n    0x7fe90c0d4e90: i64 = Register %vreg0\r\n  0x7fe90c0d4ef8: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg3\r\n    0x7fe90c0d5440: i16 = Register %vreg3\r\n  0x7fe90c0e6fe0: i16 = and 0x7fe90c0d4ef8, 0x7fe90c0d5100\r\n    0x7fe90c0d4ef8: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg3\r\n      0x7fe90c0d5440: i16 = Register %vreg3\r\n    0x7fe90c0d5100: i16 = AssertZext 0x7fe90c0d49b0, ValueType:ch:i1\r\n      0x7fe90c0d49b0: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg1\r\n        0x7fe90c0d46d8: i16 = Register %vreg1\r\nIn function: _fusion__1\r\n```\r\nSecond part (with `free()`) desn't appear each time, I don't know what it depends on", "@hawkinsp XLA crash reported with \"free(): invalid size\".", "We are seeing similar crash with ArrayFire, which is doing just like XLA (JIT).\r\nnvidia driver 375.51 seems more stable and we dont see crash with it...\r\nTBC\r\n", "The crash in \r\ncuModuleLoadDataEx>fatBinaryCtl_Compile>__cuda_CallJitEntryPoint \r\nalso disappears with nvidia drivers 384.59. \r\nThere seems to be a background bug in nvidia driver sources that is randomly effective according to the version of the drivers. The bugtracker of nvidia is not public so hard to say if they are aware of that bug.", "I got the similar (or the same) error when turning on XLA jit for the WDL example: [https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/examples/learn/wide_n_deep_tutorial.py](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/examples/learn/wide_n_deep_tutorial.py)\r\n\r\n```\r\nLLVM ERROR: Cannot select: t24: i16,ch = AtomicCmpSwap<Volatile LDST1[%fusion.1.typed27(addrspace=1)]> t0, t11, t2, t21\r\n\r\n  t11: i64,ch = CopyFromReg t0, Register:i64 %vreg1\r\n    t10: i64 = Register %vreg1\r\n  t2: i16,ch = CopyFromReg t0, Register:i16 %vreg18\r\n    t1: i16 = Register %vreg18\r\n  t21: i16 = and t2, t7\r\n    t2: i16,ch = CopyFromReg t0, Register:i16 %vreg18\r\n      t1: i16 = Register %vreg18\r\n    t7: i16 = AssertZext t5, ValueType:ch:i1\r\n      t5: i16,ch = CopyFromReg t0, Register:i16 %vreg14\r\n        t4: i16 = Register %vreg14\r\nIn function: _fusion_1__1\r\n```\r\nI tried to use a newer stable version of LLVM in: `workspace.bzl`:\r\n```\r\ntemp_workaround_http_archive(\r\n      name = \"llvm\",\r\n      urls = [\r\n          \"https://github.com/llvm-mirror/llvm/archive/stable.tar.gz\",\r\n      ],\r\n      sha256 = \"5491bd0608ca59b94d5fe0a9892494fac263c9e1bd6ab2d4f4dc0e495e29670e\", \r\n      strip_prefix = \"llvm-stable\",\r\n      build_file = str(Label(\"//third_party/llvm:llvm.BUILD\")),\r\n      repository = tf_repo_name,\r\n  )\r\n```\r\nBut the problem still exist, I am wondering if there is something wrong in the `LLVM IR emitter` of the XLA code?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Sorry: I didn't notice this was assigned to me and I'm not working on this code at the moment.\r\n\r\nJustin: I think this may have been fixed recently?", "Yes, this should be fixed by 6605938c280590ee981470abe87386396cf0e438.\r\n\r\nI'm pretty confident this will fix the problem, so closing this issue.  But please reopen if you all see this problem after this commit."]}, {"number": 11470, "title": "Variable values are not present in Java when saving a model in python and restoring in Java", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nYes. Provided bellow\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12.5\r\n- **TensorFlow installed from (source or binary)**: pip install \r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: No compiled\r\n- **CUDA/cuDNN version**: No\r\n- **GPU model and memory**: No\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nI've a script where a graph and variables are being saved using add_meta_graph_and_variables and tried to load it in Java but the weights seems that not are present. \r\nI've created two mini-examples of what it seems to me a bug.\r\n\r\n### Source code / logs\r\nHere it's how I have saved the things:\r\n\r\n```\r\nwith tf.Session(graph=tf.Graph()) as session:\r\n    ##HERE IS THE CODE OF MY NETWORK (Very long)\r\n\r\n    session.run(tf.global_variables_initializer())\r\n    #Load\r\n    saver = tf.train.Saver()\r\n    saver.restore(session, \"newModel.chkpt\")\r\n\r\n    features = loadFeatures([\"cat2.jpg\"])\r\n    res = predictions.eval(\r\n            feed_dict={\r\n                x: features,\r\n                keep_prob: 1.0, })\r\n    print('Image {} has a prob {} '.format(image, res))\r\n\r\n    b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\r\n    b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING])\r\n    b.save()\r\n```\r\n\r\nAnd here is how I tried to load in the Java side:\r\n\r\n```\r\npublic static void main(String[] args) throws Exception {\r\n\r\n        final int IMG_SIZE = 128;\r\n        final String value = \"Hello from \" + TensorFlow.version();\r\n\r\n        byte[] imageBytes = readAllBytesOrExit(Paths.get(\"./cat1.jpg\"));\r\n        Tensor image = constructAndExecuteGraphToNormalizeImage(IMG_SIZE, imageBytes);\r\n\r\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNew/model\", \"train\");\r\n\r\n        long[] sitio2;\r\n        try (Graph g = load.graph()) {\r\n            try (Session s = load.session();\r\n                 Tensor result = s.runner()\r\n                         .feed(\"keep_prob\", Tensor.create(1.0F))\r\n                         .feed(\"input_jm\", image)\r\n                         .fetch(\"predictions\").run().get(0))\r\n            {\r\n                sitio2 = result.copyTo(new long[1]);\r\n                System.out.print(sitio2[0]+\"\\n\");\r\n            }\r\n        }\r\n        load.close();\r\n    }\r\n```\r\n\r\nI've checked the content of some Tensor variables and in the python side the values are correct but the same variable in the Java side have another values (I can paste the code if needed), as a result the predictions are always wrong. \r\n\r\nI can provide the model saved or any other thing that is needed.\r\n\r\nThanks. \r\n", "comments": ["@josemlopez: The issue title says that \"variable values\" aren't being present - did you check the contents of the actual variables or did you inspect other tensors? If you can share some data and code that reproduces the problem, that would be great. I was unable to reproduce the problem with a trivial model of my own (where I observed that the variable values were restored correctly).\r\n\r\nDo the input tensor contents match? In particular, I'm wondering if there is any discrepancy between `loadFeatures` in your Python code and `constructGraphToNormalizeImage` in your Java code which results in the input values for the same image being different in the two cases.\r\n\r\nLet us know. Thanks.", "Hi asimshankar, \r\n\r\nThis is my python side:\r\n```\r\n#!/usr/bin/env python\r\n\r\ntry:\r\n    import cPickle as pickle\r\n    from urllib2 import urlopen\r\nexcept ImportError:\r\n    import pickle\r\n    from urllib.request import urlopen\r\n\r\nimport logging\r\n\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.losses.python.losses import loss_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.saved_model import builder as saved_model_builder\r\n\r\nFILE_SEED = 42\r\nIMG_SIZE = 128\r\n\r\npathToSaveModel = './tmpTestNewX/model'\r\n\r\n\r\ndef loadFeatures(files):\r\n    data = np.ndarray((len(files), IMG_SIZE * IMG_SIZE * 3))\r\n    for n, f in enumerate(files):\r\n        logging.debug('loading file #%d' % n)\r\n        img = cv2.imread(f)\r\n        h, w, _ = img.shape\r\n        if w > h:\r\n            diff = w - h\r\n            img = img[:, diff / 2: diff / 2 + h]\r\n        elif w < h:\r\n            diff = h - w\r\n            img = img[diff / 2: diff / 2 + w, :]\r\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\r\n        data[n] = img.ravel()\r\n\r\n    return data\r\n\r\ndef conv2d(x, W):\r\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\ndef max_pool_2x2(x):\r\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\nxavier = tf.contrib.layers.xavier_initializer\r\n\r\nif __name__ == '__main__':\r\n    with tf.Session(graph=tf.Graph()) as session:\r\n        x = tf.placeholder(tf.float32, shape=[None, IMG_SIZE * IMG_SIZE * 3], name=\"input_jm\")\r\n        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=\"y_\")\r\n\r\n        x_image = tf.reshape(x, [-1, IMG_SIZE, IMG_SIZE, 3])  # 128\r\n\r\n        W_conv1 = tf.get_variable(\"W_conv1\", shape=[3, 3, 3, 6], initializer=xavier())\r\n        b_conv1 = tf.get_variable('b_conv1', [1, 1, 1, 6])\r\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n        h_pool1 = max_pool_2x2(h_conv1)  # 64\r\n\r\n        W_conv2 = tf.get_variable(\"W_conv2\", shape=[3, 3, 6, 6], initializer=xavier())\r\n        b_conv2 = tf.get_variable('b_conv2', [1, 1, 1, 6])\r\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n        h_pool2 = max_pool_2x2(h_conv2)  # 32\r\n\r\n        W_conv3 = tf.get_variable(\"W_conv3\", shape=[3, 3, 6, 12], initializer=xavier())\r\n        b_conv3 = tf.get_variable('b_conv3', [1, 1, 1, 12])\r\n        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\r\n        h_pool3 = max_pool_2x2(h_conv3)  # 16\r\n\r\n        W_conv4 = tf.get_variable(\"W_conv4\", shape=[3, 3, 12, 24], initializer=xavier())\r\n        b_conv4 = tf.get_variable('b_conv4', [1, 1, 1, 24])\r\n        h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\r\n        h_pool4 = max_pool_2x2(h_conv4)  # 8\r\n\r\n        h_pool4_flat = tf.reshape(h_pool4, [-1, 8 * 8 * 24])\r\n\r\n        W_fc1 = tf.get_variable(\"W_fc1\", shape=[8 * 8 * 24, 1024], initializer=xavier())\r\n        b_fc1 = tf.get_variable('b_fc1', [1024], initializer=init_ops.zeros_initializer)\r\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\r\n\r\n        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\r\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n\r\n        W_fcO = tf.get_variable(\"W_fcO\", shape=[1024, 2], initializer=xavier())\r\n        b_fcO = tf.get_variable('b_fcO', [2], initializer=init_ops.zeros_initializer)\r\n\r\n        logits = tf.matmul(h_fc1_drop, W_fcO) + b_fcO\r\n        y_conv = tf.nn.softmax(logits)\r\n\r\n        cross_entropy = loss_ops.softmax_cross_entropy(logits, y_)\r\n\r\n        train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)\r\n\r\n        predictions = predictions = tf.argmax(y_conv, 1, name=\"predictions\")\r\n\r\n        #Load\r\n        saver = tf.train.Saver()\r\n        saver.restore(session, \"./newModel.ckpt\")\r\n\r\n        collection_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\n\r\n        r1 = session.run(W_conv1)\r\n        path = \"./\"\r\n        classS = [\"girl1.jpg\"]\r\n        classS_1 = [\"car1.jpg\", \"cat1.jpg\", \"girlOk1.jpg\"]\r\n        classNS_running = [\"manRunning.jpg\", \"manRunning1.jpg\", \"girlRunning.jpg\"]\r\n        classS_other = [\"baby-shower-cap.jpg\", \"Bottle.jpg\"]\r\n        images = classS + classS_1 + classNS_running + classS_other\r\n        images2 = [path + i for i in images]\r\n        for image in images2:\r\n            features = loadFeatures([image])\r\n            res = predictions.eval(\r\n                 feed_dict={\r\n                     x: features,\r\n                     keep_prob: 1.0, }\r\n            )\r\n            print('Image {} has a prob {} '.format(image, res))\r\n\r\n\r\n        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n        b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\r\n        b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING]) #, legacy_init_op=legacy_init_op)\r\n        b.save()\r\n```\r\n\r\n\r\nAnd this is my Java side:\r\n\r\n```\r\nimport org.tensorflow.*;\r\n\r\nimport java.io.IOException;\r\nimport java.nio.charset.Charset;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\nimport java.util.List;\r\n\r\npublic class LoadModelSample {\r\n\r\n    // In the fullness of time, equivalents of the methods of this class should be auto-generated from\r\n    // the OpDefs linked into libtensorflow_jni.so. That would match what is done in other languages\r\n    // like Python, C++ and Go.\r\n    static class GraphBuilder {\r\n        GraphBuilder(Graph g) {\r\n            this.g = g;\r\n        }\r\n\r\n        Output div(Output x, Output y) {\r\n            return binaryOp(\"Div\", x, y);\r\n        }\r\n\r\n        Output sub(Output x, Output y) {\r\n            return binaryOp(\"Sub\", x, y);\r\n        }\r\n\r\n        Output resizeBilinear(Output images, Output size) {\r\n            return binaryOp(\"ResizeArea\", images, size);\r\n        }\r\n\r\n        Output expandDims(Output input, Output dim) {\r\n            return binaryOp(\"ExpandDims\", input, dim);\r\n        }\r\n\r\n        Output cast(Output value, DataType dtype) {\r\n            return g.opBuilder(\"Cast\", \"Cast\").addInput(value).setAttr(\"DstT\", dtype).build().output(0);\r\n        }\r\n\r\n        Output decodeJpeg(Output contents, long channels) {\r\n            return g.opBuilder(\"DecodeJpeg\", \"DecodeJpeg\")\r\n                    .addInput(contents)\r\n                    .setAttr(\"channels\", channels)\r\n                    .build()\r\n                    .output(0);\r\n        }\r\n\r\n        Output constant(String name, Object value) {\r\n            try (Tensor t = Tensor.create(value)) {\r\n                return g.opBuilder(\"Const\", name)\r\n                        .setAttr(\"dtype\", t.dataType())\r\n                        .setAttr(\"value\", t)\r\n                        .build()\r\n                        .output(0);\r\n            }\r\n        }\r\n\r\n        private Output binaryOp(String type, Output in1, Output in2) {\r\n            return g.opBuilder(type, type).addInput(in1).addInput(in2).build().output(0);\r\n        }\r\n\r\n        private Graph g;\r\n    }\r\n\r\n    private static byte[] readAllBytesOrExit(Path path) {\r\n        try {\r\n            return Files.readAllBytes(path);\r\n        } catch (IOException e) {\r\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\r\n            System.exit(1);\r\n        }\r\n        return null;\r\n    }\r\n\r\n    private static Tensor constructAndExecuteGraphToNormalizeImage(int img_size, byte[] imageBytes) {\r\n        try (Graph g = new Graph()) {\r\n            GraphBuilder b = new GraphBuilder(g);\r\n            // Some constants specific to the pre-trained model at:\r\n            // https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\r\n            //\r\n            // - The model was trained with images scaled to img_sizeXimg_size pixels.\r\n            // - The colors, represented as R, G, B in 1-byte each were converted to\r\n            //   float using (value - Mean)/Scale.\r\n            final int H = img_size; //224;\r\n            final int W = img_size; //224;\r\n            final float mean = 117f;\r\n            final float scale = 1f;\r\n\r\n            // Since the graph is being constructed once per execution here, we can use a constant for the\r\n            // input image. If the graph were to be re-used for multiple input images, a placeholder would\r\n            // have been more appropriate.\r\n            final Output input = b.constant(\"input\", imageBytes);\r\n            final Output output =\r\n                    b.div(\r\n                            //b.sub(\r\n                            b.resizeBilinear(\r\n                                    b.expandDims(\r\n                                            b.cast(b.decodeJpeg(input, 3), DataType.FLOAT),\r\n                                            b.constant(\"make_batch\", 0)\r\n                                    ),\r\n                                    b.constant(\"size\", new int[] {H, W})),\r\n                            //       b.constant(\"mean\", mean)),\r\n                            b.constant(\"scale\", scale));\r\n            try (Session s = new Session(g)) {\r\n                Tensor result = s.runner().fetch(output.op().name()).run().get(0);\r\n                return result;\r\n            }\r\n        }\r\n    }\r\n\r\n    private static List<String> readAllLinesOrExit(Path path) {\r\n        try {\r\n            return Files.readAllLines(path, Charset.forName(\"UTF-8\"));\r\n        } catch (IOException e) {\r\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\r\n            System.exit(0);\r\n        }\r\n        return null;\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n\r\n        final int IMG_SIZE = 128;\r\n        final String value = \"Hello from \" + TensorFlow.version();\r\n        System.out.print(value+\"\\\\n\");\r\n\r\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNewX/model\", \"train\");\r\n\r\n        long[] sitio2;\r\n        try (Graph g = load.graph()) {\r\n            try (Session s = load.session();)\r\n            {\r\n                String[] images = new String[] { \"./cat1.jpg\", \"./girl1.jpg\", \"./bottle.jpg\" };\r\n                for (String imgName : images) {\r\n                    byte[] imageBytes = readAllBytesOrExit(Paths.get(imgName));\r\n                    Tensor image = constructAndExecuteGraphToNormalizeImage(IMG_SIZE, imageBytes); //constructImage(IMG_SIZE, imageBytes);\r\n                    Tensor result = s.runner()\r\n                            .feed(\"keep_prob\", Tensor.create(1.0F))\r\n                            .feed(\"input_jm\", image)\r\n                            .fetch(\"predictions\").run().get(0);\r\n                    sitio2 = result.copyTo(new long[1]);\r\n                    System.out.print(imgName+\" -> \"+sitio2[0]+\"\\n\");\r\n                }\r\n\r\n            }\r\n        }\r\n        load.close();\r\n    }\r\n}\r\n```\r\n\r\nMy example is pretty simple, I think. Maybe is a problem with versions or something I'm missing?", "Hi, to isolate the problems that could appear in the preprocessing part I've done other versions, where the image is preprocess in the python part and only read in the Java part:\r\n\r\n```\r\n#!/usr/bin/env python\r\n\r\ntry:\r\n    import cPickle as pickle\r\n    from urllib2 import urlopen\r\nexcept ImportError:\r\n    import pickle\r\n    from urllib.request import urlopen\r\n\r\nimport logging\r\n\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.losses.python.losses import loss_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.saved_model import builder as saved_model_builder\r\n\r\nFILE_SEED = 42\r\nIMG_SIZE = 128\r\n\r\npathToSaveModel = './tmpTestNewX/model'\r\n\r\n\r\ndef loadFeatures(files):\r\n    data = np.ndarray((len(files), IMG_SIZE * IMG_SIZE * 3))\r\n    for n, f in enumerate(files):\r\n        logging.debug('loading file #%d' % n)\r\n        img = cv2.imread(f)\r\n        h, w, _ = img.shape\r\n        if w > h:\r\n            diff = w - h\r\n            img = img[:, diff / 2: diff / 2 + h]\r\n        elif w < h:\r\n            diff = h - w\r\n            img = img[diff / 2: diff / 2 + w, :]\r\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\r\n        cv2.imwrite(\"./converted_in_pyton_\"+f.split(\"./\")[1], img)\r\n        data[n] = img.ravel()\r\n    return data\r\n\r\ndef conv2d(x, W):\r\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\ndef max_pool_2x2(x):\r\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\nxavier = tf.contrib.layers.xavier_initializer\r\n\r\nif __name__ == '__main__':\r\n    with tf.Session(graph=tf.Graph()) as session:\r\n        x = tf.placeholder(tf.float32, shape=[None, IMG_SIZE * IMG_SIZE * 3], name=\"input_jm\")\r\n        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=\"y_\")\r\n\r\n        x_image = tf.reshape(x, [-1, IMG_SIZE, IMG_SIZE, 3])  # 128\r\n\r\n        W_conv1 = tf.get_variable(\"W_conv1\", shape=[3, 3, 3, 6], initializer=xavier())\r\n        b_conv1 = tf.get_variable('b_conv1', [1, 1, 1, 6])\r\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n        h_pool1 = max_pool_2x2(h_conv1)  # 64\r\n\r\n        W_conv2 = tf.get_variable(\"W_conv2\", shape=[3, 3, 6, 6], initializer=xavier())\r\n        b_conv2 = tf.get_variable('b_conv2', [1, 1, 1, 6])\r\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n        h_pool2 = max_pool_2x2(h_conv2)  # 32\r\n\r\n        W_conv3 = tf.get_variable(\"W_conv3\", shape=[3, 3, 6, 12], initializer=xavier())\r\n        b_conv3 = tf.get_variable('b_conv3', [1, 1, 1, 12])\r\n        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\r\n        h_pool3 = max_pool_2x2(h_conv3)  # 16\r\n\r\n        W_conv4 = tf.get_variable(\"W_conv4\", shape=[3, 3, 12, 24], initializer=xavier())\r\n        b_conv4 = tf.get_variable('b_conv4', [1, 1, 1, 24])\r\n        h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\r\n        h_pool4 = max_pool_2x2(h_conv4)  # 8\r\n\r\n        h_pool4_flat = tf.reshape(h_pool4, [-1, 8 * 8 * 24])\r\n\r\n        W_fc1 = tf.get_variable(\"W_fc1\", shape=[8 * 8 * 24, 1024], initializer=xavier())\r\n        b_fc1 = tf.get_variable('b_fc1', [1024], initializer=init_ops.zeros_initializer)\r\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\r\n\r\n        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\r\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n\r\n        W_fcO = tf.get_variable(\"W_fcO\", shape=[1024, 2], initializer=xavier())\r\n        b_fcO = tf.get_variable('b_fcO', [2], initializer=init_ops.zeros_initializer)\r\n\r\n        logits = tf.matmul(h_fc1_drop, W_fcO) + b_fcO\r\n        y_conv = tf.nn.softmax(logits)\r\n\r\n        cross_entropy = loss_ops.softmax_cross_entropy(logits, y_)\r\n\r\n        train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)\r\n\r\n        predictions = predictions = tf.argmax(y_conv, 1, name=\"predictions\")\r\n\r\n        #Load\r\n        saver = tf.train.Saver()\r\n        saver.restore(session, \"./newModel.ckpt\")\r\n\r\n        collection_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\n\r\n        r1 = session.run(W_conv1)\r\n        path = \"./\"\r\n        classS = [\"girl1.jpg\"]\r\n        classS_1 = [\"car1.jpg\", \"cat1.jpg\", \"girlOk1.jpg\"]\r\n        classNS_running = [\"manRunning.jpg\", \"manRunning1.jpg\", \"girlRunning.jpg\"]\r\n        classS_other = [\"baby-shower-cap.jpg\", \"Bottle.jpg\"]\r\n        images = classS + classS_1 + classNS_running + classS_other\r\n        images2 = [path + i for i in images]\r\n        for image in images2:\r\n            features = loadFeatures([image])\r\n            res = predictions.eval(\r\n                 feed_dict={\r\n                     x: features,\r\n                     keep_prob: 1.0, }\r\n            )\r\n            print('Image {} has a prob {} '.format(image, res))\r\n\r\n\r\n        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n        b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\r\n        b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING]) #, legacy_init_op=legacy_init_op)\r\n        b.save()\r\n```\r\n\r\n\r\n```\r\nimport org.tensorflow.*;\r\n\r\nimport java.io.IOException;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\n\r\npublic class LoadModelSample3 {\r\n\r\n    private static byte[] readAllBytesOrExit(Path path) {\r\n        try {\r\n            return Files.readAllBytes(path);\r\n        } catch (IOException e) {\r\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\r\n            System.exit(1);\r\n        }\r\n        return null;\r\n    }\r\n\r\n\r\n    private static Tensor constructImage(byte[] imageBytes) {\r\n        try (Graph g = new Graph()) {\r\n            LoadModelTF.GraphBuilder b = new LoadModelTF.GraphBuilder(g);\r\n            final Output input = b.constant(\"input\", imageBytes);\r\n            final Output output =\r\n                    b.expandDims(\r\n                            b.cast(b.decodeJpeg(input, 3), DataType.FLOAT),\r\n                            b.constant(\"make_batch\", 0)\r\n                    );\r\n\r\n            try (Session s = new Session(g)) {\r\n                Tensor result = s.runner().fetch(output.op().name()).run().get(0);\r\n                return result;\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    public static void main(String[] args) throws Exception {\r\n\r\n        final int IMG_SIZE = 128;\r\n        final String value = \"Hello from \" + TensorFlow.version();\r\n        System.out.print(value+\"\\\\n\");\r\n\r\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNewX/model\", \"train\");\r\n\r\n        long[] sitio2;\r\n        try (Graph g = load.graph()) {\r\n            try (Session s = load.session();)\r\n            {\r\n                String[] images = new String[] { \"./converted_in_pyton_car1.jpg\", \"./converted_in_pyton_girl1.jpg\", \"./converted_in_pyton_Bottle.jpg\" };\r\n                for (String imgName : images) {\r\n                    byte[] imageBytes = readAllBytesOrExit(Paths.get(imgName));\r\n                    Tensor image = constructImage(imageBytes);\r\n                    Tensor result = s.runner()\r\n                            .feed(\"keep_prob\", Tensor.create(1.0F))\r\n                            .feed(\"input_jm\", image)\r\n                            .fetch(\"predictions\").run().get(0);\r\n                    sitio2 = result.copyTo(new long[1]);\r\n                    System.out.print(imgName+\" -> \"+sitio2[0]+\"\\n\");\r\n                }\r\n            }\r\n        }\r\n        load.close();\r\n    }\r\n}\r\n\r\n```\r\nMaybe I'm missing something?. The classification is not correct this time either. ", "@josemlopez : It would be very helpful if you could cut this down to a small piece of code that I can use to reproduce the problem. The code you have provided above is pretty extensive with many unrelated things and is missing some information (e.g., the definition of `LoadModelTF` and data files that I do not have access to). Isolating the problem to the smallest code snippet possible that can be reproduced will help a lot.\r\n\r\nThat said, I was able to try out a stripped down version and I think the problem lies in the discrepancy of how input is being processed. In particular, you want to compare what `loadFeatures` in Python returns with what `constructImage` in Java returns and I suspect that the two are not the same.\r\n\r\nFor example, try the following in Python:\r\n\r\n```python\r\ndata = loadFeatures(['/tmp/cat.jpg'])\r\nprint(data[0].shape)\r\nprint(data[0])\r\n```\r\n\r\nFor my cat image I get something like:\r\n\r\n```\r\n(49152,)\r\n[   0.    5.   20. ...,   96.  105.  114. ]\r\n```\r\n\r\nsuggesting that when you feed the `x` node in python (`input_jm`), a vector with 49152 elements is being provided.\r\n\r\nHowever, examining the same in Java:\r\n\r\n```java\r\nbyte[] imageBytes = readAllBytesOrExit(Paths.get(\"/tmp/cat.jpg\"));\r\ntry (Tensor image = constructAndExecuteGraphToNormalizeImage(128, imageBytes)) {\r\n  System.out.println(image.shape());\r\n  \r\n  // Print a sample of the contents\r\n  FloatBuffer buf = FloatBuffer.allocate(128*128*3);\r\n  image.writeTo(buf);\r\n  float[] flat = buf.array();\r\n  System.out.println(flat[0] + \" \" + flat[1] + \" \" + flat[2]);\r\n}\r\n```\r\n\r\nI get:\r\n```\r\nFLOAT tensor with shape [1, 128, 128, 3]\r\n64.23073 51.70092 38.50939\r\n```\r\n\r\nSuggesting that neither the shape nor the values of the input being provided matches between Python and Java. If that's the case, it would explain why the classifications are different :).\r\n\r\nThe shape difference should have been flagged (since the shape of the Java `image` Tensor doesn't match the shape corresponding to the `input_jm` placeholder in the graph). Is there some other code that I'm missing? Regardless, my suggestion would be for you to validate that the shape and value of the input image being fed to the model is the same in both Python and Java.\r\n", "Hi, \r\nThank you very much for the response. Sorry for including a long example, I was trying to give exactly the same case as I had. \r\n\r\nI've changed to a Windows with GPU environment and the things seems to be running now. Not sure what I've touch because I've done a lot of changes in my code to \"clean the things up\" and improving the network. I'll try this same code (running) in the Mac Os environment and will give some feedback again. For the moment, I think you can close this issue as is almost sure you are right and the problem was I was doing something wrong. Sorry for the time taken and thanks for the checking. \r\n"]}, {"number": 11469, "title": "No graph definition files were found. ", "body": "hello I was learn to use the tensorflow, Now I can run softmax , nn , cnn and other model on it , this is a really good framework.\r\nbut now I suffered some problem.\r\nI want to use the tensorboard, this is my code:\r\nhttps://github.com/catpanda/tensorflow_demo/blob/master/minist/mnist_bp.py\r\nyou can see the result is very good. to celebrate that. I want to show them in graph.You see I use `writer = tf.summary.FileWriter('board/', graph=graph)` in line 56 and define the graph in line 53. then I run the tensorboard by `tensorboard --logdir='board/'`.\r\n\r\n![qq 20170713125732](https://user-images.githubusercontent.com/6506928/28151076-040ad3f2-67cb-11e7-8f63-2cda654357ca.png)\r\n\r\nbut the page shows `No graph definition files were found. `\u3002\r\n![_2017-07-13t04-58-05 105z](https://user-images.githubusercontent.com/6506928/28151070-fd6f2746-67ca-11e7-8a45-1134e1dfecc6.png)\r\n\r\nI use tensorflow on windows10 and by python3.5 and tensorflow1.2 I hope you can help me find out what is the problem.\r\n", "comments": ["OK I finally solved it .\r\nbecause the document has some problme that the dir did not need the \"\"", "Please ask questions like these on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) in the future. This issue tracker is for bugs and feature requests.\r\n\r\nOut of curiosity, how did you solve your problem? What do you mean by empty string? I work on TensorBoard. What can we do to make it friendlier?", "I am sorry , because my mother laungue is not English, so I hard to read the express my question\u3002\r\nI suffered the problem because I can hardly understand the english document too. so I read the Chinese Document .In the Chine document we run the tensorboard by `tensorboard --logdir='dir'` but finally I found I shoud use  `tensorboard --logdir=dir` without quotation marks.\r\n", "That's peculiar because because the `tensorboard --logdir='dir'` should mean the same thing as `tensorboard --logdir=dir` if you're using bash and don't have any `$` in there."]}, {"number": 11468, "title": "Fine tuning tutorial without Bazel", "body": "I am using this tutorial provided by Google Research to fine tune the Inception model fro my own images.\r\n\r\nhttps://github.com/tensorflow/models/blob/master/inception/README.md#how-to-fine-tune-a-pre-trained-model-on-a-new-task\r\n\r\nI have access to a GPU provided by my institution. The problem is that the GPU doesn't have Bazel installed.\r\n\r\nIs it possible to complete this tutorial without using Bazel? ", "comments": ["This question is better asked on [Stack Overflow](https://stackoverflow.com/questions/tagged/tensorflow). But if you pip install the GPU CUDA version of TensorFlow, and then run bazel normally inside the models repository, things will most likely be fine.", "Hi Jart, \r\n\r\nThank you for your reply. I am pretty sure that the Tensorflow is the GPU CUDA version. I tried running Bazel from inside the models repository like you suggested. \r\nBut it says Bazel not found.\r\n\r\nI am not an admin user for the GPU and I don't have the permissions to install Bazel. ", "Hi, \r\nI encountered the same issue. "]}, {"number": 11467, "title": "Change if_x86 to if_linux_x86_64", "body": "VC doesn't have -msse3 and -msse4.2 options.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.\r\n\r\n@meteorcloudy would you like me to test this for windows bazel?", "@gunan Sure, I can also do it.\r\nHere: http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/31/"]}, {"number": 11466, "title": "Custom Beam Search Decoder with sampling", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: 3.4.3\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 7.5\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\nI want to incorporating sampling into the  beam search decoder for seq2seq model. Is there any example or document on how to implement it? \r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@yangshao hi i also want to implement this. any progress?"]}, {"number": 11465, "title": "Use Windows Threadpool for SchedClosure", "body": "Before this change, the distributed runtime will create a new thread for each mini-batch. Quite wasteful.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please."]}, {"number": 11464, "title": "Fix broken AttentionMechanism docstrings", "body": "Currently, for all AttentionMechanisms, the `memory_sequence_length` arg does not get formatted correctly in the docs, making it easy to miss. \r\n\r\nI believe this is because the `(optional)` modifier is not preceded by a colon, as in the other (working) args.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please.", "@jagthebeetle Can you merge into master rather than a release branch? The r1.2 release is already frozen.", "Can one of the admins verify this patch?", "@jagthebeetle Can you rebase to the latest master and apply your commit on top of that? Github is showing thousands of commits right now. I think it is better to create a new PR for this rather than reusing this."]}, {"number": 11463, "title": "Copyright on first line of LICENSE (Apache 2) is incorrect", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nN/A\r\n- **TensorFlow version (use command below)**:\r\nN/A\r\n- **Python version**: \r\nN/A\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nThe LICENSE file in the tensorflow github repository has an incorrect copyright assignment.\r\nThe first line of the file reads:\r\nCopyright 2017 The TensorFlow Authors.  All rights reserved.\r\n\r\nThis is incorrect.  \"The TensorFlow Authors\" are not the copyright holders for the Apache 2.0 license.\r\nThis line should be removed.  It makes a legal claim which is expressly false.\r\n\r\nA separate issue is whether the line in the LICENSE file which provides an example of how to attribute\r\nthe copyright for new code in the TensorFlow project (which also includes a line assigning copyright\r\nto \"The TensorFlow Authors\") is incorrect as well.\r\n\r\nIn general I can't see how the copyright assignment works in the project.  Yuan Tang was recently\r\nadded to the AUTHORS file.  Does that person now have full copyright over the entire TensorFlow\r\nwork?  The Contributor agreement only grants a copyright *license* to Google and the downstream\r\nrecipients of the code.  It does not grant copyright to the contributed code.\r\n\r\n### Source code / logs\r\nN/A\r\n", "comments": ["\r\n@sillsm Our friend has questions about TensorFlow's license and copyright policy.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I guess no one is going to look at this.  Here - I'll help your open issues stats by closing this issue as unresolved.\r\n -- Tim"]}, {"number": 11462, "title": "Retrieving LLVM IR from AOT tfcompile", "body": "Is it possible to get LLVM intermediate representation (.ll) files from tfcompile instead of object code? If so, how can it be done? Alternatively, can one get source code instead of object code from tfcompile?", "comments": ["@williamjeremy there isn't a mechanism right now, but I'm adding simple support for this right now.  Once it's in, you'll be able to set the --xla_dump_ir_to flag to specify a directory to dump out the LLVM IR, pre and post optimization.\r\n\r\nThere is no way to dump source code, if by \"source code\" you mean something like C or C++.  tfcompile takes as input the TensorFlow graph, which is lowered to XLA HLO, which is lowered to LLVM IR, which is lowered to machine code.\r\n\r\nI'll update this issue once the support has been merged.", "https://github.com/tensorflow/tensorflow/commit/201fa224e178b76ece4723c433a17df10005341c added the `--xla_dump_ir_to` support to the AOT codepath, so I'm closing this out.", "> Is it possible to get LLVM intermediate representation (.ll) files from tfcompile instead of object code? If so, how can it be done? Alternatively, can one get source code instead of object code from tfcompile?\r\n\r\n@williamjeremy were you able to get the LLVM files, if yes, can you please send a complete example with the commands. Thank you in advance!"]}, {"number": 11461, "title": "Branch 161686867", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 11460, "title": "Print default when CUDA and CuDNN versions are not specified", "body": "Fix #10456.", "comments": ["@tensorflow-jenkins test this please", "I am OOO, but @caisq should be a better reviewer than me for any bash code.", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "the xla failure is irrelevant, here is a passing run https://ci.tensorflow.org/job/tensorflow-pull-requests-xla/1743/"]}, {"number": 11459, "title": "Deleted unnecessary repetition of the same text.", "body": "The same text was repeated two times. I deleted the repetition.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11458, "title": "Add a code of conduct.", "body": "", "comments": []}, {"number": 11457, "title": "How to use pre-trained models for fine tuning on different dataset ?", "body": "Hi,\r\n\r\nI have downloaded a pre-trained model for inception v3 (inception_v3_2016_08_28.tar.gz file)from [https://github.com/tensorflow/models/tree/master/slim#Pretrained](url) which contains the file inception_v3.ckpt. Could anyone please help me how to use this file to fine-tune on a different dataset ?\r\n\r\nThanks in advance.\r\n", "comments": ["[The resource](https://github.com/tensorflow/models/tree/master/slim#Tuning) you've already linked has a thorough example, no? Anyway, try asking on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) for help. I believe GitHub is meant for bug reports and feature requests.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11456, "title": "GPU-Isolated docker containers fail in a distributed training with more than one worker.", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: No\r\n- **TensorFlow version**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version**: -\r\n- **CUDA/cuDNN version**: 'CUDA_VERSION': '8.0.61' / 'CUDNN_VERSION': '5.1.10'\r\n- **GPU model and memory**: 8x GCE K80 Tesla\r\n\r\n### Context:\r\n1) I have created a Cloud Compute Engine instance with 8 GPUs.\r\n2) I have started a couple of GPU-isolated containers with intention to run each as a separate worker:\r\n`sudo NV_GPU=0 nvidia-docker run -it --name tf_worker_0 -p 8000:8000 -v /$(pwd)/repo:/notebooks/repo gcr.io/tensorflow/tensorflow:latest-gpu-py3 /bin/bash` \r\n\r\n3) To create a loopback to the host I run following:\r\n`echo $(netstat -nr | grep '^0\\.0\\.0\\.0' | awk '{print $2}') dockerhost >> /etc/hosts`\r\nThrough `dockerhost` it properly detects and pings all the open ports on the host including processes running in other containers that are exposed with `-p hostport:containerport`.\r\n\r\n### Problem:\r\n*Case 1 - Normal*: When I run a distributed TensorFlow script using `dockerhost` with only one `worker` and any number of `ps` servers (e.g.  `--ps_hosts=dockerhost:7000,dockerhost:7001 --worker_hosts=dockerhost:8000`) everything works as intended - local grcp servers are launched, worker and ps communicate well. \r\n\r\n*Case 2 - Issue*: When I increase the number of worker jobs (e.g.  `--worker_hosts=dockerhost:8000,dockerhost:8001`) i get `Master init: Unavailable` and `Master init: Internal` Errors. \r\n\r\n*Case 3 - Normal*: BTW, everything works smoothly when I run all the workers inside a single container isolating GPUs with `CUDA_VISIBLE_DEVICES`.\r\n\r\n*Case 4 - Issue*: Also, it is worth mentioning here, that using queues solution to shutdown `ps` proposed in https://github.com/tensorflow/tensorflow/issues/4713 fails in both Case 1 and Case 2. This results in immediate `tensorflow.python.framework.errors_impl.UnavailableError` when starting `ps`.\r\n\r\n### Statement:\r\nIs this an intended behaviour? Or does such setting is insufficient for a distributed training and a special `master` server or a cluster manager is needed? It just seems interesting that it would work for one worker but not for more.\r\n\r\n**Reproducible Toy Example**:\r\n[repr.txt](https://github.com/tensorflow/tensorflow/files/1142032/repr.txt)\r\n\r\n**Log**:\r\n[worker_log.txt](https://github.com/tensorflow/tensorflow/files/1142041/worker_log.txt)\r\n\r\n", "comments": ["Also, I posted an SO question under `tensorflow` tag and it was not answered by a tensorflow team just yet:\r\nhttps://stackoverflow.com/questions/44804982/google-compute-engine-tesla-k80-has-additional-htod-an-dtoh-ops-and-a-way-lower\r\nIt would be really nice to get an answer to it.", "It sounds like the two docker containers aren't reachable from one another. Can you verify that if you start a  `tf.train.Server` in one container, you can connect to it (create a `tf.Session(server_target)` where `server_target` is the address you expect the server to have) in the other?", "Thanks for a quick reply @mrry.\r\nIf I understand you correctly, here are my steps:\r\n\r\n**Container I: port:8000**\r\n1] Launch `tf_worker_0`:\r\n```\r\nsudo NV_GPU=0 nvidia-docker run -it --name tf_worker_0 -p 8000:8000 -v /$(pwd)/repo:/notebooks/repo gcr.io/tensorflow/tensorflow:latest-gpu-py3 /bin/bash\r\n```\r\n2] Install dependencies and establish a loopback connection:\r\n```\r\napt-get update && apt-get upgrade &&  apt-get install net-tools\r\necho $(netstat -nr | grep '^0\\.0\\.0\\.0' | awk '{print $2}') dockerhost >> /etc/hosts\r\n```\r\n3] In `tf_worker_0` run and launch a local server:\r\n```\r\nimport tensorflow as tf\r\ncluster = tf.train.ClusterSpec({\"local\": [\"dockerhost:8000\", \"dockerhost:8001\"]})\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=0)\r\n```\r\nOut: `... Started server with target: grpc://localhost:8000 ...`\r\n\r\n**Container II: port:8001**\r\n1] Launch `tf_worker_1`:\r\n```\r\nsudo NV_GPU=1 nvidia-docker run -it --name tf_worker_1 -p 8001:8001 -v /$(pwd)/repo:/notebooks/repo gcr.io/tensorflow/tensorflow:latest-gpu-py3 /bin/bash\r\n```\r\n2] Install dependencies and establish a loopback connection:\r\n```\r\napt-get update && apt-get upgrade &&  apt-get install net-tools\r\necho $(netstat -nr | grep '^0\\.0\\.0\\.0' | awk '{print $2}') dockerhost >> /etc/hosts\r\n```\r\n3] In `tf_worker_1` launch:\r\n```\r\nimport tensorflow as tf\r\ncluster = tf.train.ClusterSpec({\"local\": [\"dockerhost:8000\", \"dockerhost:8001\"]})\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=1)\r\n```\r\nOut: `... Started server with target: grpc://localhost:8001 ...`\r\n\r\n4] Run an op on a Container I:\r\n```\r\nwith tf.Session('grpc://dockerhost:8000'.encode()) as sess:\r\n    print(sess.run(tf.constant(0)))\r\n```\r\nOut: `0`. \r\n\r\nSo it looks like they reach each other properly.\r\n\r\nMeanwhile the issue persists. Here are the commands to reproduce issue from `repr.py` toy example:\r\n```\r\nCUDA_VISIBLE_DEVICES='' python3 repr.py --ps_hosts=dockerhost:7000 --worker_hosts=dockerhost:8000,dockerhost:8001 --job_name=ps --task_index=0\r\npython3 repr.py --ps_hosts=dockerhost:7000 --worker_hosts=dockerhost:8000,dockerhost:8001 --job_name=worker --task_index=0\r\npython3 repr.py --ps_hosts=dockerhost:7000 --worker_hosts=dockerhost:8000,dockerhost:8001 --job_name=worker --task_index=1\r\n```", "Can you try expanding the working example to include three servers in two jobs (i.e. using the same `tf.train.ClusterSpec`, but just creating a `tf.Session` and running a single op)?", "@mrry do you mean keeping the same `tf.train.ClusterSpec`:\r\n```\r\ncluster = tf.train.ClusterSpec({\"local\": [\"dockerhost:8000\", \"dockerhost:8001\"]})\r\n```\r\n, but just creating three `tf.Session` or `tf.train.Server`? With what targets?\r\n\r\nCreating the same `tf.train.Server(cluster, job_name=\"local\", task_index=1)` not surprisingly shows `UnknownError: Could not start gRPC server`, because `task_index` job is already started.\r\n\r\nRunning this:\r\n```\r\nwith tf.Session('grpc://dockerhost:8000'.encode()) as sess:\r\n    print(sess.run(tf.constant(0)))\r\n```\r\nmultiple times with any targets (8000 or 8001) does not show any errors.\r\n\r\nIf this is not what you wanted me to reproduce, please, provide a snippet to run, thanks.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Catching up on very old issues: I don't have a way to reproduce this issue, and it is most likely a Docker configuration problem rather than a TensorFlow problem, so I'm going to mark it as \"community support\".", "I have already migrated from this setup, so feel free to close this, as it's not relevant any more.", "Thanks!"]}, {"number": 11455, "title": "update word2vec_basic.py:\tFix TSNE invocation in Udacity word2vec assignment", "body": "Update 5_word2vec.ipnb-\r\n\r\nFix TSNE invocation in Udacity word2vec assignment\r\n\r\n#add method='exact' .fix ValueError\r\n\r\nnum_points = 400\r\ntsne = TSNE(perplexity=30, n_components=2, init='pca',n_iter=5000,**method='exact'**)\r\ntwo_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Sorry, I meant to just have the one line change in the pull request code. Right now your diff is very large and unreadable as a result. Does the colab no longer work with the default method? I see that it now defaults to \u2018barnes_hut\u2019. Thanks!", "Thanks for this! Again, the diff in the .ipynb file is 900 lines long at this point. I can't accept a large change like that. Ideally, it would be a 1 line diff, with just the addition of `,method='exact'` on the right line. Then we can commit it.", "That was unnecessary. I've created a PR with the minimal fix (#11482) which makes the change easy to review. Thanks for pointing out the issue!", "@Shuolongbj  Maybe you can repoen this PR with just the change the word2vec_basic.py change and retitle it. I'd be happy to approve that. Thanks!", "Can one of the admins verify this patch?", "@vincentvanhoucke thank you.i resend here #11483"]}, {"number": 11454, "title": "Windows: Build TensorFlow with wrapper-less CROSSTOOL", "body": "After https://github.com/tensorflow/tensorflow/pull/11317 is merged, we can now build TF with the wrapper-less CROSSTOOL!\r\n\r\n@gunan ", "comments": []}]