[{"number": 53667, "title": "r2.8 cherry-pick request: Updating oneDNN to v2.5.1", "body": "Updating oneDNN from v2.5-rc to v2.5.1 which has a performance fix for 4k x 4k x 4k matmuls and also [many other fixes](https://github.com/oneapi-src/oneDNN/compare/v2.5-rc...v2.5.1).\r\n\r\nOriginal PR: https://github.com/tensorflow/tensorflow/pull/53527", "comments": []}, {"number": 53666, "title": "r2.8 cherry-pick request: [oneDNN] Remove is_filter_const attr from _FusedConv3D registration", "body": "This fixes a failure in TF-oneDNN. (The unused parameter was added by accident.)\r\n\r\nOriginal PR: https://github.com/tensorflow/tensorflow/pull/53479", "comments": []}, {"number": 53665, "title": "Do we have any way to avoid memory copy in tf.convert_to_tensor ?", "body": "**System information**\r\n- TensorFlow version (use command below): 2.4.1\r\n\r\n**Describe the current behavior**\r\n\r\nCode:\r\n\r\n```python\r\n@tf.function\r\ndef inference(model, image):\r\n    return model(image)\r\n\r\n\r\ndef test_model():\r\n    model = tf.keras.Sequential([tf.keras.layers.Conv2D(filters=3, kernel_size=3)])\r\n\r\n    np_image = np.random.randn(256, 256, 256, 3)\r\n    model(np_image)\r\n    # passing a python object to tf.function is not a recommend way, so this is slow.\r\n    inference(model, np_image)\r\n\r\n    tf_image = tf.convert_to_tensor(np_image)\r\n    inference(model, tf_image)\r\n\r\n    total_time = 0\r\n    for _ in range(10):\r\n        np_image = np.random.randn(256, 256, 256, 3)\r\n        start_time = time.time()\r\n        model(np_image)\r\n        total_time += time.time() - start_time\r\n    print(\"inference by model: {0} s\".format(total_time))\r\n\r\n    total_time = 0\r\n    for _ in range(10):\r\n        np_image = np.random.randn(256, 256, 256, 3)\r\n        start_time = time.time()\r\n        inference(model, np_image)\r\n        total_time += time.time() - start_time\r\n    print(\"inference by np_image: {0} s\".format(total_time))\r\n\r\n    total_time = 0\r\n    for _ in range(10):\r\n        np_image = np.random.randn(256, 256, 256, 3)\r\n        tf_image = tf.convert_to_tensor(np_image)\r\n        start_time = time.time()\r\n        inference(model, tf_image)\r\n        total_time += time.time() - start_time\r\n    print(\"inference by tf_image: {0} s\".format(total_time))\r\n```\r\n\r\nThe result:\r\n\r\n```txt\r\ninference by model: 2.4521803855895996 s\r\ninference by np_image: 2.472818374633789 s\r\ninference by tf_image: 0.007699012756347656 s, convert time: 2.4546449184417725 s\r\n```\r\n\r\nMy question is:\r\n\r\n1. What does  `tf.convert_to_tensor` do ? Does it copy cpu data from numpy to tf.Tensor and also copy it to GPU ?\r\n2. How can I avoid memory copy when using tf.convert_to_tensor ? In my case I will not modify the input image at all, so it's safe for me to make a memory view for the numpy data to tf.Tensor.\r\nI can restrict the numpy data to be continuous and C order if it is needed.\r\n\r\nFrom official docs I can find that it's recommended to create data from tf.data.Dataset which is already a tf.Tensor. But in my case we cannot use tf.data.Dataset API because I want to use some data which is mutable when training.\r\n\r\nThe alternative is to produce tf.Tensor by multiprocessing and push it to main process for training, but it will dump and reload the tf.Tensor object when using multiprocessing.Queue.\r\nAnd I cannot run `tf.queue.FIFOQueue` in multiprocessing. Is this a good way to sharing tensor between different processes? (For numpy, we can use memmap to share numpy data.)\r\n\r\n**Describe the expected behavior**\r\n\r\nMy expected behavior is that the convert time is very small.\r\n", "comments": ["@JansonZhu Could you please have a look at the similar [issue1](https://stackoverflow.com/questions/47519802/does-tensorflow-convert-to-tensor-do-memory-copy),[issue2](https://stackoverflow.com/questions/50109996/whats-the-difference-between-tf-constant-and-tf-convert-to-tensor) and [issue3](https://stackoverflow.com/questions/67116476/memory-leak-for-custom-tensorflow-training-using-tf-function) ?Please let us know if it helps?Thanks!", "Sorry, they don't help in my case.\r\nI think an alternative is to support `tf.convert_to_tensor` with a specific cuda_stream, so that we can convert my data to cuda tensor in another cuda stream in background.\r\nNotes: `tf.convert_to_tensor` can only be called in training process because passing tensor between processes is expensive, so we call it in a python thread. For this reason, we should support it without blocking python GIL.\r\nOr is there any other api that can achieve it ?", "@JansonZhu \r\nCould you please try with the latest TF v2.7.0 and if the issue still persists, please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53664, "title": "When allocate_output 200MB tensor, op kernel will execute twice", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.15\r\n\r\n\r\nThe op code is as follows:\r\n```\r\nREGISTER_OP(\"ZeroOut\")\r\n    .Input(\"to_zero: int32\")\r\n    .Output(\"zeroed: int32\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      c->set_output(0, c->input(0));\r\n      return Status::OK();\r\n    });\r\n\r\nint times = 0;\r\n\r\nclass ZeroOutOp : public OpKernel {\r\n public:\r\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    const Tensor& input_tensor = context->input(0);\r\n    auto input = input_tensor.flat<int32>();\r\n\r\n    LOG(INFO) << \"execute times:\" << (++times);\r\n\r\n    Tensor* output_tensor = NULL;\r\n    //right: \r\n    //OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n    //                                                 &output_tensor));\r\n    //wrong: \r\n    OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({200000000, 1}), &output_tensor));\r\n  }\r\n};\r\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n\r\n```\r\n\r\n\r\nThe test code is as follows:\r\n```\r\nimport tensorflow as tf\r\nimport heap.tensorflow as hp\r\n\r\nresult = hp.zero_out([5, 4, 3, 2, 1])\r\nwith tf.Session() as sess:\r\n  sess.run(result)\r\n```\r\n\r\n**Describe the current behavior**\r\n![image](https://user-images.githubusercontent.com/70072713/148356663-33e93475-a92d-43a9-8c71-71e0e0b40142.png)\r\n\r\n\r\n", "comments": ["@yuanbopeng ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to tf v2.7 and let us know if you are using same issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53664\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53664\">No</a>\n"]}, {"number": 53663, "title": "Cross-compilation error by Bazel of TensorFlow Lite in 2.7", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.7\r\n- Python version: 3.9\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 4.2.2\r\n- GCC/Compiler version (if compiling from source): 10.1\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n\r\n**Describe the problem**\r\nI try to build libtensorflowlite.so for android and it return an error.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n1. git clone https://github.com/tensorflow/tensorflow\r\n2. cd tensorflow && ./configure\r\n3. bazel build -c opt --cxxopt=--std=c++11 --fat_apk_cpu=arm64-v8a --config=android_arm64 //tensorflow/lite:libtensorflowlite.so\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nThe full log:\r\n```\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=146\r\nINFO: Reading rc options for 'build' from /data/offline/deps/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /data/offline/deps/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from /data/offline/deps/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/root/miniconda2/envs/py36/bin/python3 --action_env PYTHON_LIB_PATH=/root/miniconda2/envs/py36/lib/python3.6/site-packages --python_path=/root/miniconda2/envs/py36/bin/python3 --define=PREFIX=/data/offline/deps/prefix --action_env ANDROID_NDK_HOME=/data/offline/deps/android-ndk-r21e --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=30.0.2 --action_env ANDROID_SDK_API_LEVEL=30 --action_env ANDROID_SDK_HOME=/opt/android-sdk\r\nINFO: Reading rc options for 'build' from /data/offline/deps/tensorflow/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /data/offline/deps/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /data/offline/deps/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:android_arm64 in file /data/offline/deps/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /data/offline/deps/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false\r\nINFO: Analyzed target //tensorflow/lite:libtensorflowlite.so (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /data/offline/deps/tensorflow/tensorflow/lite/schema/BUILD:98:22: Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs failed: (Exit 126): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n/bin/bash: bazel-out/host/bin/external/flatbuffers/flatc: cannot execute binary file\r\nTarget //tensorflow/lite:libtensorflowlite.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 0.242s, Critical Path: 0.01s\r\nINFO: 2 processes: 2 internal.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["It's about the CC parametet which was set to ndk version. export CC=gcc works.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53663\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53663\">No</a>\n"]}, {"number": 53662, "title": "Resurrecting Swift bindings / how much of the core C++ API can run on iOS?", "body": "I'm directly addressing TensorFlow's admins and maintainers of the core C/C++ code with this issue.\r\n\r\nBefore starting out, I am not using TensorFlow for _inference_ on iOS. I am doing _training_, which is orders of magnitude more difficult to support. It has never been done on a high-level, feature-complete ML framework except for [DL4S](https://github.com/palle-k/dl4s) (MPSGraph and ArrayFire don't count). Using an iPhone or iPad for training may seem strange, but I have numerous reasons for doing so (leaving out those reasons for brevity).\r\n\r\nThe existing TensorFlow training API is only compatible with macOS, Linux, and Windows. I am concerned with the C API used internally by [Swift for TensorFlow](https://github.com/tensorflow/swift-apis). iOS can't run Python, which means it certainly can't run the TensorFlow in this repository. However, Swift for TensorFlow brings an opportunity to take Python out of the equation. C and C++ can run on iOS, and I assume a lot of the code is platform-agnostic. Has anyone ever succeeded in training TensorFlow models on an Android device?\r\n\r\nApple released a PluggableDevice implementation of GPU acceleration for Macs. However, it's closed-source, missing several ops it could support, and shuts out low-end Intel Macs. I'm looking for universal training support just like [DL4S](https://github.com/palle-k/dl4s). Is there any chance that I could reuse the C TensorFlow API as a component of my Metal backend for iOS?\r\n\r\nThis would save time and make DirectML acceleration for Swift for TensorFlow easier. Also, there are several ops like Cholesky grad which aren't in Metal Performance Shaders or Accelerate. I don't have the slightest clue how to implement them in CPU code. I assume that TensorFlow's core C API contains CPU kernels for those obscure ops.\r\n\r\nOne more thing - if I could use PluggableDevice for my backend, it would be much more in line with TensorFlow and less likely that my S4TF branch would diverge from main and eventually die. I'm approaching this  with the objective of realistically resurrecting S4TF. Whether TensorFlow's owners can change their mind and officially support my work has a massive impact on its long-term viability. How can I contact the people who have authority over this?", "comments": ["After scanning the core C/C++ code, there\u2019s no mention of iOS - outside of TensorFlow Lite (again, not my goal). However, iOS and macOS are very similar, and the same can be said for Linux and Android. Are there any fundamental barriers to bringing it to iOS using macOS?\r\n\r\nFor example, loading a specific dynamic library at runtime, JIT compiling CPU code, relying on the structure of the macOS file system in a way that deviates from generic Darwin.\r\n\r\nIf I do find out how to modify the macOS code to run on iOS, how much of a chance is there for TensorFlow to merge my additions into main? I expect you might also want something similar for Android to make it equal and consistent. I won\u2019t be able to bring it to Android without other contributors\u2019 assistance.\r\n\r\nI would be okay with keeping Swift for TensorFlow exclusive to desktop platforms initially, as long as I could guarantee it\u2019s possible to train on iOS in the future. There are other problems (Swift autodiff) that currently prevent deployment on iOS anyway, which won\u2019t be resolved for several months.", "CC: @sachinprasadhs", "@rohan100jain the information in this issue should be helpful: https://github.com/tensorflow/swift-apis/issues/1190", "@saeta I think you're the person I should be talking to. From https://github.com/tensorflow/swift/issues/620, if the reason was that \"MLers all use Python and are not willing to learn Swift\", that is definitely untrue. I'm a MLer and it's the other way around: I use Swift and don't care to learn Python.\r\n\r\nIf it's about funding to support software infrastructure in Google Colab, that's trivial. I already got Swift working in Colab again and soon, S4TF too with zero money spent. See [Swift-Colab](https://github.com/philipturner/swift-colab) for more on that.\r\n\r\nIf it was archived for some other more serious or not publicly disclosable reason, I imagine that my request will be very controversial and require a lot of discussion internally at Google. That's why I'm reaching out to you and building support in the community so that Google can't say no \ud83d\ude04", "Thank you so much @philipturner for reaching out!\r\n\r\n> If it was archived for some other more serious or not publicly disclosable reason, I imagine that my request will be very controversial and require a lot of discussion internally at Google. That's why I'm reaching out to you and building support in the community so that Google can't say no \ud83d\ude04\r\n\r\nThe decision to archive S4TF was based on (among many other things) private discussions between two companies. Suffice it to say, while no one wanted to shut down S4TF, it was (unfortunately) not reasonable to continue forward with the project as envisioned at Google. Sorry!\r\n\r\nThat said, I'd be _delighted_ for you to take over the project and move things forward in whatever way you envision (feel free to fork it!). There will likely be a number of choices you'll have to make. S4TF evolved from targeting a library of kernels (i.e. TF's kernel library) to targeting XLA. (The reasons for doing this are beyond the scope of this comment, but I'd be happy to share.) The problem with this approach (historically) on iOS has been that JIT compilation was forbidden (it seems that this might have changed in the last year or so); as a result, I don't know of anyone who has tried getting XLA to work on iOS. (Related to this is your autodiff strategy; I see @ProfFan has [already mentioned the associated caveats](https://github.com/tensorflow/swift-apis/issues/1185#issuecomment-985143540).) This affects what C APIs you need, and what portion of the Core TensorFlow codebase must be ported to work on iOS.\r\n\r\nAlthough I don't want to dissuade you, I'd be remiss if I didn't mention that I believe you can do some forms of on-device training with TFLite (although this won't save you from having to author the model in Python)."]}, {"number": 53661, "title": "OSError: SavedModel file does not exist at: final_model_weights.hdf5/{saved_model.pbtxt|saved_model.pb}", "body": "Hey a have a problem whn i try to load the module :\r\n\r\nmy code : index.py\r\n\r\n```\r\ndef getPrediction(filename):\r\n     model = tf.keras.models.load_model(\"final_model_weights.hdf5\")\r\n     img = load_img('static/'+filename, target_size=(180, 180))\r\n     img = img_to_array(img)\r\n     img = img / 255\r\n     img = np.expand_dims(img,axis=0)\r\n     category = model.predict_classes(img)\r\n     answer = category[0]\r\n     probability = model.predict(img)\r\n     probability_results = 0\r\n\r\n     if answer == 1:\r\n          answer = \"Recycle\"\r\n          probability_results = probability[0][1]\r\n     else:\r\n          answer = \"Organic\"\r\n          probability_results = probability[0][0]\r\n\r\n     answer = str(answer)\r\n     probability_results=str(probability_results)\r\n\r\n     values = [answer, probability_results, filename]\r\n     return values[0], values[1], values[2]\r\n```\r\n\r\nwhen i upload the image to my code i get this error :\r\n\r\n```\r\nOSError\r\nOSError: SavedModel file does not exist at: final_model_weights.hdf5/{saved_model.pbtxt|saved_model.pb}\r\n\r\nTraceback (most recent call last)\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 2091, in __call__\r\nreturn self.wsgi_app(environ, start_response)\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 2076, in wsgi_app\r\nresponse = self.handle_exception(e)\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 2073, in wsgi_app\r\nresponse = self.full_dispatch_request()\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 1518, in full_dispatch_request\r\nrv = self.handle_user_exception(e)\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 1516, in full_dispatch_request\r\nrv = self.dispatch_request()\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/flask/app.py\", line 1502, in dispatch_request\r\nreturn self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\nFile \"/home/devokba/Documents/waste-classification-model/index.py\", line 42, in submit_image\r\ngetPrediction(filename)\r\nFile \"/home/devokba/Documents/waste-classification-model/main.py\", line 14, in getPrediction\r\nmodel = tf.keras.models.load_model(\"final_model_weights.hdf5\")\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\nraise e.with_traceback(filtered_tb) from None\r\nFile \"/home/devokba/.local/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 118, in parse_saved_model\r\nraise IOError(\r\nOSError: SavedModel file does not exist at: final_model_weights.hdf5/{saved_model.pbtxt|saved_model.pb}\r\nThe debugger caught an exception in your WSGI application. You can now look at the traceback which led to the error.\r\nTo switch between the interactive traceback and the plaintext one, you can click on the \"Traceback\" headline. From the text traceback you can also create a paste of it. For code execution mouse-over the frame you want to debug and click on the console icon on the right side.\r\n\r\nYou can execute arbitrary Python code in the stack frames and there are some extra helpers available for introspection:\r\n\r\ndump() shows all variables in the frame\r\ndump(obj) dumps all that's known about the object\r\n\r\n\r\n```\r\n\r\nstructure of my code : \r\n```\r\n\u2523 Resources/\r\n\u2503 \u2523 Dataset/\r\n\u2503 \u2523 Images/\r\n\u2503 \u2517 Model/\r\n\u2523 __pycache__/\r\n\u2503 \u2523 main.cpython-38.pyc\r\n\u2503 \u2517 main.cpython-39.pyc\r\n\u2523 static/\r\n\u2503 \u2523 Empty_Coca_Cola_Bottle.jpg\r\n\u2503 \u2523 O_1.jpg\r\n\u2503 \u2523 O_2.jpg\r\n\u2503 \u2517 img1.jpeg\r\n\u2523 templates/\r\n\u2503 \u2517 index.html\r\n\u2523 .gitattributes\r\n\u2523 Procfile.txt\r\n\u2523 Project 3 Proposal.docx\r\n\u2523 README.md\r\n\u2523 final_model.ipynb\r\n\u2523 final_model_weights.hdf5\r\n\u2523 index.py\r\n\u2523 main.py\r\n\u2523 presentation_notebook.ipynb\r\n\u2517 requirements.txt\r\n\r\n```\r\nany solution for that ??", "comments": ["@3kba ,\r\nCan you please look at this comment from the [issue](https://github.com/tensorflow/tensorflow/issues/22480) with similar error.It helps.Thanks", "> @3kba , Can you please look at this comment from the [issue](https://github.com/tensorflow/tensorflow/issues/22480) with similar error.It helps.Thanks\r\n\r\ni looked before to all this issues but i didn't get the solution that's why i made this issues, So you have any solution for that ? ", "Any solution?", "@3kba ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and tensorflow version you are using to reproduce the issue reported here.", "Removing comp:lite because this seems irrelevant to TFLite. ", "sorry for late reply : \r\ntensorflow version 2.7.0\r\nall code : \r\nmain.py\r\n```\r\n# Dependencies\r\nimport numpy as np\r\nimport keras\r\nfrom keras.preprocessing.image import load_img\r\nfrom keras.preprocessing.image import img_to_array\r\nfrom keras.applications.vgg16 import preprocess_input\r\nfrom keras.applications.vgg16 import decode_predictions\r\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\r\nfrom keras.applications.vgg16 import VGG16\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import load_model\r\n\r\n\r\n# def predict(img_path):\r\ndef getPrediction(filename):\r\n     model = tf.keras.models.load_model(\"final_model_weights.hdf5\")\r\n     img = load_img('static/'+filename, target_size=(180, 180))\r\n     img = img_to_array(img)\r\n     img = img / 255\r\n     img = np.expand_dims(img,axis=0)\r\n     category = model.predict_classes(img)\r\n     answer = category[0]\r\n     probability = model.predict(img)\r\n     probability_results = 0\r\n\r\n     if answer == 1:\r\n          answer = \"Recycle\"\r\n          probability_results = probability[0][1]\r\n     else:\r\n          answer = \"Organic\"\r\n          probability_results = probability[0][0]\r\n\r\n     answer = str(answer)\r\n     probability_results=str(probability_results)\r\n\r\n     values = [answer, probability_results, filename]\r\n     return values[0], values[1], values[2]\r\n\r\n```\r\n\r\nindex.py \r\n```\r\n# Import Dependencies\r\nfrom flask import Flask, render_template, request, redirect, flash, url_for\r\nimport main\r\nimport urllib.request\r\nfrom werkzeug.utils import secure_filename\r\nfrom main import getPrediction\r\nimport os\r\n\r\n\r\n#################################################\r\n# Flask Setup\r\n#################################################\r\n\r\nUPLOAD_FOLDER = 'static/'\r\n\r\napp = Flask(__name__)                    \r\napp.secret_key = '8662747133'\r\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\r\n\r\n# Route to HTML    \r\n@app.route('/')\r\ndef index():\r\n    return render_template('index.html')\r\n\r\n\r\n@app.route(\"/\", methods = ['POST']) #/file\r\n# Our function for pushing the image to the classifier model\r\ndef submit_image():\r\n     if request.method == 'POST':\r\n          if 'file' not in request.files:\r\n               flash('No file part')\r\n               return redirect(request.url)\r\n          file = request.files['file']\r\n        # Error message if no file submitted\r\n          if file.filename == '':\r\n            flash('No file selected for uploading')\r\n            return redirect(request.url)\r\n        # Return results predictive data\r\n          if file:\r\n            filename = secure_filename(file.filename)\r\n            file.save(os.path.join('static/', filename))\r\n            getPrediction(filename)\r\n            answer, probability_results, filename = getPrediction(filename)\r\n            flash(answer)\r\n            flash(probability_results) # accuracy\r\n            flash(filename)\r\n            return redirect('/')\r\n\r\nif __name__ == \"__main__\":\r\n    app.run(debug=True)\r\n\r\n```\r\n\r\n\r\n", "@3kba ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53660, "title": "`tf.sparse.split` crashes when axis is a tuple", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ndata = tf.random.uniform([1, 32, 32], dtype=tf.float32)\r\naxis = [1, 2]\r\nx = tf.sparse.from_dense(data)\r\nresult = tf.sparse.split(x,3, axis=axis) # crash\r\n```\r\nSession crashes. `tf.sparse.split` failed to do proper checking for `axis`.\r\n\r\n**Describe the expected behavior**\r\n`tf.sparse.split` should raise `InvalidArgumentError` when `axis` is not a 0-D tensor, instead of crashing.", "comments": ["Hi @Saduf2019 ! Could you please look at this issue? It's replicating in [2.7](https://colab.sandbox.google.com/gist/mohantym/599ed1f5134314a960fff561fc369737/github_53660.ipynb) ,[2.6 ](https://colab.sandbox.google.com/gist/mohantym/98348f4572ffac7b91f30d94f930644d/github_53660.ipynb#scrollTo=qjuBqEkMup9X)and [nightly](https://colab.sandbox.google.com/gist/mohantym/fec4b007291137635e74b18b70423929/github_53660.ipynb#scrollTo=qjuBqEkMup9X) .Thank you!", "Added a PR #53695 for the fix."]}, {"number": 53656, "title": "[jax] Add default_device config to JitState", "body": "This can be used to override the system default device when running a\r\njit'd function. This is the prioritized list which determines which\r\nsettings take precedence when determining which device a jit'd\r\nfunction runs on:\r\n\r\n1. `device` or `backend` argument to jit\r\n2. Input(s) with sticky device\r\n3. default_device config (new!)\r\n4. System default device\r\n\r\nThis also changes the `jit` C++ binding to take a `jit_device`\r\nargument, which is the device determined by the `device` or `backend`\r\nargument to jit (or None if not set), rather than determining it by\r\ncalling back into Python.", "comments": []}, {"number": 53654, "title": "[TF:TRT] Update Rejected Algorithms for Newer TRT Versions", "body": "- Lower performance on TRT algorithms fixed as of TRT 8.0.3, so the gated patch only applies between 8.0.0 and 8.0.3\r\n\r\n@bixia1 @DEKHTIARJonathan ", "comments": ["Converting PR to draft to re-address logic for TRT < 8.0 and TRT >= 8.2.  Changes will be ready this afternoon", "This PR ensures that both the TRT 7.x and 8.0.0 rejected tactics as introduced in PR [50408](https://github.com/tensorflow/tensorflow/pull/50408) are properly gated for more recent versions of TRT", "@MattConley Can you please check @bixia1's comments and keep us posted ? Thanks!", "@MattConley can you please address [this comment](https://github.com/tensorflow/tensorflow/pull/53654#discussion_r779633183)", "I think this PR is correct in that it will have the intended effect. I can add tests for the class in #53760. The entire surrounding code is precarious (not a fault of this PR). In particular, the enum defined to identify shuffle algorithm is only valid for TRT 8.0 and TRT 7.2. So actually the code would logically ban random formats of unary layer for TRT 7.1 (although alg selector is not currently active for TRT 7.1).", "The existing code is buggy in that it bans formats in TRT 8.2 for a layer that is _not_ a shuffle layer, despite what the code intends, so we should probably prefer this change over existing code", "@MattConley please squash the commits.", "@MattConley Can you please check @bixia1's comments and keep us posted ? Thanks!", "Squashed the changes together, thanks @bixia1 and @christopherbate "]}, {"number": 53653, "title": "tf.sparse.to_dense don't support complex dtypes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nx = tf.cast(tf.constant([1.0, 2.0]), tf.complex128)\r\nx_sparse = tf.sparse.from_dense(x)\r\nprint(\"from_dense pass:\", x_sparse) # pass\r\nx_dense = tf.sparse.to_dense(x_sparse) # fail\r\nprint(\"to_dense pass:\", x_dense) \r\n```\r\n**Describe the current behavior**\r\n`tf.sparse.from_dense` can convert a complex dense tensor to a sparse tensor, however, `tf.sparse.to_dense` fails to convert a complex sparse tensor back to a dense tensor.\r\nFor the above code snippet, the output is:\r\n```\r\nfrom_dense pass: SparseTensor(...)\r\nNotFoundError: Could not find device for node: {{node SparseToDense}} = SparseToDense[T=DT_COMPLEX128, Tindices=DT_INT64, validate_indices=true]\r\nAll kernels registered for op SparseToDense:\r\n  device='CPU'; T in [DT_STRING]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_STRING]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_BOOL]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_BOOL]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT32]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT32]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT64]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT64]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_BOOL]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_BOOL]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_INT32]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_INT32]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_INT8]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_INT8]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT8]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT8]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_INT16]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_INT16]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT16]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT16]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT32]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT32]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_INT64]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT64]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT64]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\r\n  device='GPU'; T in [DT_HALF]; Tindices in [DT_INT64]\r\n  device='GPU'; T in [DT_HALF]; Tindices in [DT_INT32]\r\n [Op:SparseToDense]              \r\n```\r\n**Describe the expected behavior**\r\n`tf.sparse.to_dense` should also support complex dtypes.", "comments": ["Added PR #53694 for the fix."]}, {"number": 53652, "title": "[TF:TRT] Remove redundant helpers from trt_optimization_pass", "body": "The TRT custom Grappler pass contains a set of helper functions that are redundant to those in TF's `NodeDefUtils.h`. This change removes the redundant helpers and call sites as necessary.", "comments": []}, {"number": 53650, "title": "Question on implicit transpose in HLO bitcast/copy/reshape instruction #2", "body": "In below dumped hlo instruction:\r\n```\r\n%bitcast.94 = f16[1,128,2,64]{3,1,2,0} bitcast(f16[1,2,128,64]{3,2,1,0} %bitcast.50)\r\n```\r\n\r\nboth tensor shape and memory layout are permuted between dimension 1 and dimension 2.\r\n\r\nHowever in this instruction\r\n```\r\n%copy.6 = f16[2,128,128]{2,1,0} copy(f16[2,128,128]{1,2,0} %bitcast.70)\r\n```\r\n\r\nDimension 1 and dimension 2 have same size, I cannot infer from dumped IR about whether tensor share are permuted between dim 1 and dim 2.\r\n\r\nMay I ask how can I get complete information shape/layout permutation?\r\n\r\n", "comments": ["Hi @Saduf2019 ! Could you please look at this issue?", "Copy always uses the same (logical) dimensions, but permutes the layout (physical) dimensions. So a copy actually moves dimensions around.\r\nBitcast however is a no-op, it does not copy any data. It can do that by changing the physical layout in the same way as the (logical) dimensions, so that it still is the same data as before. The bitcast you show here is in fact a Transpose op in disguise. For Transpose op, layout assignment always assigns a layout such that it becomes a bitcast.\r\nHope this makes it a bit clearer :)", "@akuegel Thanks a lot!!! That makes me much more clear on this.\r\n\r\nI have two further questions on these instructions:\r\n\r\n# Q1 \r\nI am still a little bit confused about Reshape instruction, consider:\r\n```\r\n%reshape.103 = f16[4,128,2,64]{3,1,2,0} reshape(f16[512,128]{1,0} %slice.20)\r\n```\r\n\r\nLooks this reshape.103 instruction is combined of two steps:\r\n1. [512,128]{1,0} -> [4,128,2,64]{3,2,1,0}\r\n2. [4,128,2,64]{3,2,1,0} -> [4,128,2,64]{3,1,2,0}\r\n\r\nSo, is it functionally equivalent to a Bitcast (step 1) followed by a Copy (step 2) instruction?\r\n\r\n# Q2:\r\nIn addition, I am also wondering about which instructions can incur underlying data change.\r\nConsider Reshape/Transpose/Copy/Bitcast instructions. Underlying data change only happens on Copy and Reshape instructions as these two instructions both can permute layout (physical) dimensions in a way that is not aligned with logical dimension change. In contrast, Transpose and Bitcast do not change data, only change meta-data in HLO IR. Am  I understanding correctly in this regard?\r\n\r\n\r\nLooking forward to your reply, many thanks in advance.", "Regarding question 1) yes, for reshape, layout assignment also assigns a layout such that the reshape is a bitcast (i.e. no data has to be moved around). It can happen that this chosen layout can be propagated to other ops so that we don't need the copy. In this case, it seems we still need the copy.\r\n\r\nRegarding question 2) In fact, after layout assignment we should only have Copy which moves data. Reshape and Transpose become bitcasts, however we don't replace Transpose ops inside fusion nodes with bitcasts because that allows to generate more efficient code (we may be able to reuse multi-dimensional iteration variables if we know the no-op is a transpose, so we only need to permute the multi-dimensional index instead of recalculating it; the Bitcast op loses this information).", "Thanks for the detailed explanation. Closing the issue now:)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53650\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53650\">No</a>\n"]}, {"number": 53649, "title": "Question on implicit transpose in HLO bitcast/copy/reshape instruction", "body": "HLO instructions like bitcast/copy/reshape often conduct implicit transpose. I am confusing on how the reshape/transpose performed exactly, as I am not aware of they are documented anywhere else including official operation semantics. \r\n\r\nTake tensor A[2,3]{1,0} as an example, suppose tensor A have element [[1,2,3], [4,5,6]] with memory layout [1,2,3,4,5,6], consider following two transposition performed by bitcast/copy/reshape:\r\n\r\n1. %bitcast = f32[2,3]{0,1} bitcast(f32[2,3]{1, 0} %A)\r\nwe get tensor elements [[1,2,3], [4,5,6]] with memory layout [1,4,2,5,3,6] \r\n2. %bitcast = f32[3,2]{0,1} bitcast(f32[2,3]{1, 0} %A)\r\nFor this case both tensor shape and memory layout are permutes, I suppose technically tensor A first reshape to [3,2] (get [3,2]{1,0}), then permute memory layout to get the final result.\r\nSo the process would be [[1,2,3], [4,5,6]] [1,2,3,4,5,6]  --reshape--> [[1,2],[3,4],[5,6]] [1,2,3,4,5,6] --transpose--> [[1,2],[3,4],[5,6]] [1,3,5,2,4,6]\r\n\r\nAm I understanding implicit transpose correctly?\r\n\r\nThanks a lot:)", "comments": ["@donglinz We see that there is another issue #53650 which we are tracking. Could you please confirm if it is  a duplicate ticket and close this one so that we can get you the right help in other issue ?Thank you!", "Hi @sushreebarsa, it not a duplicated ticket. Two issues are both targeting hlo bitcast instruction however the question are unique. ", "@donglinz   Thank you for the update!\r\nCould you please refer to [bitcast](https://www.tensorflow.org/api_docs/python/tf/bitcast),[operation_semantics](https://www.tensorflow.org/xla/operation_semantics) and[ this thread ](https://stackoverflow.com/questions/50128777/tensorflow-concat-with-transpose-using-the-broadcast-semantic),please let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53648, "title": "Unit test builds broken by recent commit", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.8.10\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nCommit https://github.com/tensorflow/tensorflow/commit/fea79a29ad16aa3081e2c0c1c6cf8b81771d46b1 introduced an error that prevents the unit test build from completing\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --remote_http_cache=\"\"  --remote_cache_proxy=\"\" --noremote_accept_cached --config=nonccl --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --copt=-ffp-contract=off --verbose_failures -- //tensorflow/python/... -//tensorflow/python/tools/... -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/ops/ragged:ragged_dispatch_test -//tensorflow/python:quantized_ops_test\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --remote_http_cache=\"\"  --remote_cache_proxy=\"\" --noremote_accept_cached --config=nonccl --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --copt=-ffp-contract=off --verbose_failures -- //tensorflow/python/... -//tensorflow/python/tools/... -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/ops/ragged:ragged_dispatch_test -//tensorflow/python:quantized_ops_test\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=180\r\nINFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:\r\n  Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:\r\n  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3\r\nINFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:\r\n  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:\r\n  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium\r\nINFO: Found applicable config definition build:short_logs in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition test:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only\r\nINFO: Found applicable config definition build:nonccl in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:linux in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nWARNING: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/python/ops/distributions/BUILD:6:11: target '//tensorflow/python/ops/distributions:distributions' is deprecated: TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/core/profiler/lib/BUILD:286:11: //tensorflow/core/profiler/lib:profiler_disabled_test: no such attribute 'env' in 'cc_test' rule\r\nERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/python/BUILD:3324:10: Target '//tensorflow/core/profiler/lib:profiler_session_impl' contains an error and its package is in error and referenced by '//tensorflow/python:win_lib_files_for_exported_symbols'\r\nINFO: Repository cython instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:686:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository go_sdk instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:23:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace0.bzl:120:20: in workspace\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/io_bazel_rules_go/go/toolchain/toolchains.bzl:379:28: in go_register_toolchains\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/io_bazel_rules_go/go/private/sdk.bzl:65:21: in go_download_sdk\r\nRepository rule _go_download_sdk defined at:\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/io_bazel_rules_go/go/private/sdk.bzl:53:35: in <toplevel>\r\nINFO: Repository rules_java instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:23:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace0.bzl:120:20: in workspace\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:29:18: in grpc_extra_deps\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/com_google_protobuf/protobuf_deps.bzl:34:21: in protobuf_deps\r\nRepository rule http_archive defined at:\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in <toplevel>\r\nINFO: Repository typing_extensions_archive instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:380:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository rules_python instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:786:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository remote_coverage_tools instantiated at:\r\n  /DEFAULT.WORKSPACE.SUFFIX:11:13: in <toplevel>\r\nRepository rule http_archive defined at:\r\n  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in <toplevel>\r\nINFO: Repository gast_archive instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:362:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository termcolor_archive instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:371:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository com_google_pprof instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:668:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository dill_archive instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:429:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository flatbuffers instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:881:28: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:66:16: in _initialize_third_party\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/flatbuffers/workspace.bzl:6:20: in repo\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository wrapt instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:855:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nINFO: Repository six_archive instantiated at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/WORKSPACE:15:14: in <toplevel>\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/workspace2.bzl:318:20: in _tf_repositories\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/builder/1/tensorflow_build/tensorflow-git/third_party/repo.bzl:81:35: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/python:pybind_symbol_target_libs_file' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 66.952s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (229 packages loaded, 3869 targets configured)\r\nFAILED: Build did NOT complete successfully (229 packages loaded, 3869 targets configured)\r\n    currently loading: @com_google_protobuf// ... (3 packages)\r\n    Fetching @io_bazel_rules_docker; Cloning 9bfcd7dbf0294ed9d11a99da6363fc28df904502 of https://github.com/bazelbuild/rules_docker.git\r\n", "comments": ["@hrw @cfRod @nSircombe ", "Fixed by https://github.com/tensorflow/tensorflow/commit/4a3e89423182a3fbf008eaedc86b169bd3461c64", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53648\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53648\">No</a>\n"]}, {"number": 53646, "title": "Tensorflow is unable to detect my GTX 1650 GPU with CUDA 11.2", "body": "I have CUDA drivers installed on my pc with Nvidia GTX 1650.\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Sun_Feb_14_21:12:58_PST_2021\r\nCuda compilation tools, release 11.2, V11.2.152\r\nBuild cuda_11.2.r11.2/compiler.29618528_0\r\n```\r\nAnd I have Tensorflow-gpu 2.7.0\r\n\r\nThe following TensorFlow code is unable to recognize the GPU.\r\n```\r\nimport tensorflow as tf\r\nprint(tf.test.gpu_device_name())\r\n```\r\nThe error :-\r\n```\r\n2022-01-01 11:38:54.599751: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-01-01 11:38:54.601786: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\r\n2022-01-01 11:38:54.601803: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2022-01-01 11:38:54.601817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wasseypur): /proc/driver/nvidia/version does not exist\r\n```", "comments": ["@Samar-080301 Could you please have a look at the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu) and check the compatible versions ? Please refer to the similar [issue](https://stackoverflow.com/questions/65870397/installed-tensorflow-but-cant-detect-gtx-1650-super) and let us know if it helps?Thanks!", "I'm having \r\n```\r\npython3 --version\r\nPython 3.8.10\r\n```\r\ndo I need CudNN also?", "@Samar-080301 Yes please,verify the compatible CudNN version.Could you please have a look at the SO [thread](https://stackoverflow.com/questions/65381073/tensorflow-gpu-not-using-gpu-with-cuda-cudnn) , [GPU support](https://www.tensorflow.org/install/gpu)  ?  \r\nThis is not a bug or feature request, for any further queries you may open this issue in [TF discussion forum](https://discuss.tensorflow.org/) as there is a larger community there  to get you the right help.Thank you!", "I followed [thsi medium tutorial](https://medium.com/@redowan/no-bullshit-guide-on-installing-tensorflow-gpu-ubuntu-18-04-18-10-238924cc4a6a), and the problem was solved."]}, {"number": 53645, "title": "Conv2DTranspose have a non-deterministic behavior ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 8.1\r\n- GPU model and memory: GeForce GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nIt seems that Conv2DTranspose behaves in a non-deterministic way.\r\n\r\n**Describe the expected behavior**\r\nI would expect to get the exact same output when I run the same model with the same input.\r\n\r\n**Standalone code to reproduce the issue**\r\n#*****************************************\r\nimport numpy as np\r\nfrom keras.layers import Conv2DTranspose, Input\r\nfrom keras.models import Model\r\n\r\ninput_layer = Input(shape=(8, 8, 3))\r\noutput = Conv2DTranspose(3, 4)(input_layer)\r\nmodel = Model(input_layer, output)\r\ndata = np.random.randn(1, 8, 8, 3)\r\n\r\nfor _ in range(10):\r\n    output_sum = np.sum(model.predict(data))\r\n    print(f'output_sum: {output_sum}')\r\n#*****************************************\r\n\r\nOutput I get:\r\noutput_sum: 1.6755037307739258\r\noutput_sum: 1.675503134727478\r\noutput_sum: 1.675502896308899\r\noutput_sum: 1.6755034923553467\r\noutput_sum: 1.6755017042160034\r\noutput_sum: 1.675503134727478\r\noutput_sum: 1.6755036115646362\r\noutput_sum: 1.6755034923553467\r\noutput_sum: 1.6755030155181885\r\noutput_sum: 1.6755015850067139\r\n\r\n\r\n\r\n", "comments": ["@reuvenperetz ,\r\nI was able to run the code without any issues on TF v2.7. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/79dcd03c352cd86f2a7cc17cc170dc82/untitled179.ipynb).Also please create a virtual environment and test your code again. It helps. Thanks!\r\n", "I tried it with google colab and it worked perfectly . \r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53645\">No</a>\n"]}, {"number": 53644, "title": "How to check the total no of neurons of model?", "body": "My question is about the Neural Network neuron's numbers.\r\nNo of neurons in input layer is equal to no of input features..say 32,32,1 if MNIST dataset \r\nand no of neurons in Output layer is equal to no of target variable say,,in MNIST it is 10\r\nbut how can we know about the neurons of hidden layers?\r\nhttps://colab.research.google.com/github/AviatorMoser/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb#scrollTo=BL0AhUGJwT6M\r\nin this colab notebook, there are 2 network defined.\r\nHow can we know the total no of neurons of the architecure?\r\n\r\nSame question is for TFLite model too.\r\nAlso, How to check the performance in terms of TOPs/Power consumption/GPU-CPU usage etc?\r\n\r\n", "comments": ["Hi @neso613 ! Can you check these  threads [1](https://stackoverflow.com/questions/56518924/how-we-can-get-the-total-number-of-neurons-from-a-model-in-keras-is-there-any-f) ,[2 ](https://stackoverflow.com/questions/54408347/count-neurons-in-keras-with-different-layers-is-my-approach-correct) for counting neurons in a keras model ? You can check memory usage of CPU/GPU  using [memory_usage](https://www.tensorflow.org/api_docs/python/tf/config/experimental/get_memory_usage) api . You can use a USB Power Meter along your micro-controllers to check the power usage during inference .\r\n\r\nPlease post in [TF forum](https://discuss.tensorflow.org/)/SO for further assistance. Thank you!", "I will assume that, you already have some knowledge about Neural Nets. So, when you write this:\r\n```\r\nmodel.add(Dense(512, input_shape=(784,)))\r\n```\r\nThis line means your Input neurons is = total number of pixels in MNIST (here)\r\nAnd this is `connected` to a hidden layer of `512` neurons. So the next hidden layer `h1` will have `512` neurons. Now suppose after this you add this line.\r\n```\r\nmodel.add(Dense(64, activation =\"relu\")\r\n```\r\nSo, this means that the next layer `h2` will have `64` number of neurons. And `h1` is connected to `h2`. And this is how it goes on.\r\nSo, the first hidden layer has `h1` has `512` neurons. Second layer `h2` has `64` neurons. And similarly, you can count number of neurons for other layers. \r\n\r\n# \r\nAbout total number of neurons:\r\n\r\nSuppose your NN architecture is defined as:\r\n```\r\nmodel.add(Dense(512, input_shape=(784,)))\r\nmodel.add(Dense(64, activation =\"relu\")\r\nmodel.add(Dense(32, activation =\"relu\")\r\nmodel.add(Dense(10, activation =\"softmax\")\r\n```\r\nSo, here Input layer `I` has `784` Neurons. Hidden Layer `h1` has `512` neurons. Hidden Layer `h2` has `64` neurons. Hidden Layer `h3` has `32` neurons. Last layer `h4` has `10` neurons. So  total number of hidden neurons in this architectures is :\r\n```\r\n512 + 64 + 32  = 608 neurons.\r\n```\r\n\r\nNow I am excluding the input and the last layer. As these two layer `input` and `last layer` is independent of our choice, as `784` neurons is due to flatten size of image, and there are `10` classes. So hidden neuron number would be here 608. There are some sources, where we see last layer (and sometime input is also considered). Hope this helps. Please feel free to correct me if I missed out at some thing.", "> Hi @neso613 ! Can you check these threads [1](https://stackoverflow.com/questions/56518924/how-we-can-get-the-total-number-of-neurons-from-a-model-in-keras-is-there-any-f) ,[2 ](https://stackoverflow.com/questions/54408347/count-neurons-in-keras-with-different-layers-is-my-approach-correct) for counting neurons in a keras model ? You can check memory usage of CPU/GPU using [memory_usage](https://www.tensorflow.org/api_docs/python/tf/config/experimental/get_memory_usage) api . You can use a USB Power Meter along your micro-controllers to check the power usage during inference .\r\n> \r\n> Please post in [TF forum](https://discuss.tensorflow.org/)/SO for further assistance. Thank you!\r\n\r\nThanks for reply but can USB Power Meter works with rasp?", "> I will assume that, you already have some knowledge about Neural Nets. So, when you write this:\r\n> \r\n> ```\r\n> model.add(Dense(512, input_shape=(784,)))\r\n> ```\r\n> \r\n> This line means your Input neurons is = total number of pixels in MNIST (here) And this is `connected` to a hidden layer of `512` neurons. So the next hidden layer `h1` will have `512` neurons. Now suppose after this you add this line.\r\n> \r\n> ```\r\n> model.add(Dense(64, activation =\"relu\")\r\n> ```\r\n> \r\n> So, this means that the next layer `h2` will have `64` number of neurons. And `h1` is connected to `h2`. And this is how it goes on. So, the first hidden layer has `h1` has `512` neurons. Second layer `h2` has `64` neurons. And similarly, you can count number of neurons for other layers.\r\n> \r\n> About total number of neurons:\r\n> \r\n> Suppose your NN architecture is defined as:\r\n> \r\n> ```\r\n> model.add(Dense(512, input_shape=(784,)))\r\n> model.add(Dense(64, activation =\"relu\")\r\n> model.add(Dense(32, activation =\"relu\")\r\n> model.add(Dense(10, activation =\"softmax\")\r\n> ```\r\n> \r\n> So, here Input layer `I` has `784` Neurons. Hidden Layer `h1` has `512` neurons. Hidden Layer `h2` has `64` neurons. Hidden Layer `h3` has `32` neurons. Last layer `h4` has `10` neurons. So total number of hidden neurons in this architectures is :\r\n> \r\n> ```\r\n> 512 + 64 + 32  = 608 neurons.\r\n> ```\r\n> \r\n> Now I am excluding the input and the last layer. As these two layer `input` and `last layer` is independent of our choice, as `784` neurons is due to flatten size of image, and there are `10` classes. So hidden neuron number would be here 608. There are some sources, where we see last layer (and sometime input is also considered). Hope this helps. Please feel free to correct me if I missed out at some thing.\r\n\r\nSo, how model parameters are different from no of neurons?", "@neso613 ! You can check this [thread ](https://forums.raspberrypi.com/viewtopic.php?t=288867)for Raspberry pi power meter. Thanks for the lucid explanation @Anindyadeep . You can check more on model parameters and HyperParameters from below threads. Link [1](https://www.geeksforgeeks.org/difference-between-model-parameters-vs-hyperparameters/) ,[2](https://www.kaggle.com/questions-and-answers/190624) .Thank you!", "> @neso613 ! You can check this [thread ](https://forums.raspberrypi.com/viewtopic.php?t=288867)for Raspberry pi power meter. Thanks for the lucid explanation @Anindyadeep . You can check more on model parameters and HyperParameters from below threads. Link [1](https://www.geeksforgeeks.org/difference-between-model-parameters-vs-hyperparameters/) ,[2](https://www.kaggle.com/questions-and-answers/190624) .Thank you!\r\n\r\nMy Model parameters means, after model.summary() in Tensorflow, it shows model architecture and below to it prints abput parameter..say..trainable parameters, non-trainable parameters.\r\n\r\nWhat is these trainable parameters, non-trainable parameters? Is it models neurons information?", "Generally, what the `model.summary()` shows the architecture of the model. Like how many dense blocks u have used, how many convolutional blocks u have used etc. At the very end you will see that there is written about this much `trainable param` and this much `non-trainable` parameters. Trainable parameters are those parameters, which will be updated over time, during the time of back propagation. If you know that the hidden neurons, which we set in the dense layers, are nothing but some sort of `weight` matrix. The weights (elements of that matrix) are the trainable parameters. At the same time, suppose non-trainable params are those, which are not updated over time. Some of them are `Dropout layer`, `MaxPool layer` etc. As these parameters do not provide a learnable paradigm in the models. So this combination of trainable and non-trainable parameters, both constitutes as parameters of the model, and that whole information of that model architecture is being provided by the summary. \r\n\r\nAlso, fun fact, Do not get confused with hyper-parameter, and non-trainable parameter. Hyper parameter are some sort of user defined values, which are tweakable and are set to the models. Like the number of hidden neurons in layers, the learning rate, the value of `p` in dropout etc. Non trainable parameters originates from the model, and have some dependency of set up of hyper parameters. Like suppose in case of dropout layer, the value of p. Or the strides taken in maxpool etc. \r\n\r\nGo through this [link](https://towardsdatascience.com/how-to-calculate-the-number-of-parameters-in-keras-models-710683dae0ca), to have more in-depth understanding of trainable and non-trainable parameters. \r\n\r\nAlso, correct me, if I missed out at some thing. Thank you.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53644\">No</a>\n"]}, {"number": 53643, "title": "How to build tensorflow 1.15 with docker build\uff1fI can only compile the latest tensorflow2.9 according to the official tutorial", "body": "![image](https://user-images.githubusercontent.com/44188056/148175006-782c6cef-fb0a-4c80-bdae-c83d2212497f.png)\r\n\r\nI want to switch branch r1.15, but it didn't work\uff01thankyou\uff01\r\n\r\n", "comments": ["@chensusu11 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Ubuntu 18.04\r\n- docker Linux build \uff08https://www.tensorflow.org/install/source#docker_linux_builds\uff09\r\n- TensorFlow version:   2.9\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?:    source code build and pip generated whl\r\n- Bazel version (if compiling from source):  4.2.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  7\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n1 docker pull tensorflow/tensorflow:devel-gpu  \r\n\r\n2 docker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=\"$(id -u):$(id -g)\" \\\r\n    tensorflow/tensorflow:devel-gpu bash   \r\n\r\n3 git pull  # within the container, download the latest source code\r\n\r\n4 ./configure\r\n\r\n5 bazel build --congif=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n6 ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /mnt\r\n\r\n7 chown $HOST_PERMS /mnt/tensorflow-2.9.0-cp38-cp38-linux_x86_64.whl\r\n8 pip3 install tensorflow-2.9.0-cp38-cp38-linux_x86_64.whl\r\n\r\n", "How to build tensorflow 1.15 with docker build\uff1f", "I want to know bazel's version of build tensorflow1.15", "@chensusu11 We see that you're using older version of  TF 1.x(v1.15) which is not actively supported .Could you please try to upgrade to latest stable TF version 2.7.0 and let us know the outcome?Thanks!  ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53643\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53643\">No</a>\n"]}, {"number": 53642, "title": "How to build tensorflow 1.15 with docker build\uff1fI can only compile the latest tensorflow2.9 according to the official tutorial", "body": "![image](https://user-images.githubusercontent.com/44188056/148174661-c22df66d-c624-4d87-8a7c-02ff97837443.png)\r\n\r\nI want to switch branch r1.15, but it didn't work\uff01thankyou\uff01", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53642\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53642\">No</a>\n"]}, {"number": 53641, "title": "\u5982\u4f55\u901a\u8fc7 docker build\uff0c\u6765build tensorflow\u6307\u5b9a\u7248\u672c\uff0c\u6bd4\u5982\u6211\u60f3build  tensorflow1.15", "body": "![image](https://user-images.githubusercontent.com/44188056/148174262-c83fd792-c10c-4e46-8a62-59c4aee815cd.png)\r\n\r\n\u6211\u6309\u7167 docker build\u7684\u65b9\u6cd5 build\u51fa\u6765\u65f6\u6700\u65b0\u7684tensorflow 2.9\u7684\u7248\u672c\uff0c\u91cc\u9762\u6211\u4e5f\u4e0d\u80fdgit checkout \u6765\u5207\u6362\u5206\u652f\uff0c\u8bf7\u95ee\u6709\u4ec0\u4e48\u597d\u7684\u89e3\u51b3\u65b9\u6cd5\u5417\uff1f\r\n\r\n\u8c22\u8c22", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53641\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53641\">No</a>\n"]}, {"number": 53640, "title": "Failed build: Problem getting numpy include path.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Monterey 12.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.6.2(latest - cloned yesterday)\r\n- Python version: 3.7.2\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 4.2.2\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI wan to build GPU Metal Delegate and get the error `Problem getting numpy include path.`. I'm pretty sure I have numpy installed for python3 and python2.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI've tried to fix the problem with this [suggestion](https://github.com/tensorflow/tensorflow/issues/53467#issuecomment-996688168), but still get the same output. Running on this command:\r\n`bazel build --action_env PYTHON_BIN_PATH=/usr/bin/python3 --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n**NumPy logs on python3 and python2**\r\n```\r\nadityadwipamungkas@Adityas-MacBook-Pro tensorflow-2.6.2 % pip3 show numpy\r\nName: numpy\r\nVersion: 1.21.5\r\nSummary: NumPy is the fundamental package for array computing with Python.\r\nHome-page: https://www.numpy.org\r\nAuthor: Travis E. Oliphant et al.\r\nAuthor-email: None\r\nLicense: BSD\r\nLocation: /usr/local/lib/python3.7/site-packages\r\nRequires: \r\nRequired-by: \r\nadityadwipamungkas@Adityas-MacBook-Pro tensorflow-2.6.2 % pip show numpy\r\nDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\r\nName: numpy\r\nVersion: 1.16.6\r\nSummary: NumPy is the fundamental package for array computing with Python.\r\nHome-page: https://www.numpy.org\r\nAuthor: Travis E. Oliphant et al.\r\nAuthor-email: None\r\nLicense: BSD\r\nLocation: /Users/adityadwipamungkas/Library/Python/2.7/lib/python/site-packages\r\nRequires: \r\nRequired-by: matplotlib\r\n```\r\n\r\n**Configure**\r\n```\r\nadityadwipamungkas@Adityas-MacBook-Pro tensorflow-2.6.2 % ./configure\r\nFound possible Python library paths:\r\n  /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages\r\nPlease input the desired Python library path to use.  Default is [/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nDo you wish to build TensorFlow with iOS support? [y/N]: y\r\niOS support will be enabled for TensorFlow.\r\n```\r\n\r\n**Output when run bazel build**\r\n```\r\nadityadwipamungkas@Adityas-MacBook-Pro tensorflow-2.6.2 % bazel build --action_env PYTHON_BIN_PATH=/usr/bin/python3 --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=159\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages --python_path=/usr/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:ios_arm64 in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --config=ios --cpu=ios_arm64\r\nINFO: Found applicable config definition build:ios in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/b570a1921c9e55ac53c8972bd2bfd37cd0eb510d.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nINFO: Repository local_execution_config_python instantiated at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/WORKSPACE:15:14: in <toplevel>\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace2.bzl:1088:19: in workspace\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace2.bzl:85:27: in _tf_toolchains\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/tf_toolchains/toolchains/remote_config/configs.bzl:6:28: in initialize_rbe_configs\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/tf_toolchains/toolchains/remote_config/rbe_config.bzl:158:27: in _tensorflow_local_config\r\nRepository rule local_python_configure defined at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl:275:41: in <toplevel>\r\nINFO: Repository local_config_python instantiated at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/WORKSPACE:15:14: in <toplevel>\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace2.bzl:1088:19: in workspace\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace2.bzl:95:21: in _tf_toolchains\r\nRepository rule python_configure defined at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl:294:35: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_python':\r\n   Traceback (most recent call last):\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 267, column 40, in _python_autoconf_impl\r\n                _create_local_python_repository(repository_ctx)\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 213, column 39, in _create_local_python_repository\r\n                numpy_include = _get_numpy_include(repository_ctx, python_bin) + \"/numpy\"\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 187, column 19, in _get_numpy_include\r\n                return execute(\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/remote_config/common.bzl\", line 230, column 13, in execute\r\n                fail(\r\nError in fail: Problem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 267, column 40, in _python_autoconf_impl\r\n                _create_local_python_repository(repository_ctx)\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 213, column 39, in _create_local_python_repository\r\n                numpy_include = _get_numpy_include(repository_ctx, python_bin) + \"/numpy\"\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/py/python_configure.bzl\", line 187, column 19, in _get_numpy_include\r\n                return execute(\r\n        File \"/Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/third_party/remote_config/common.bzl\", line 230, column 13, in execute\r\n                fail(\r\nError in fail: Problem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nINFO: Repository go_sdk instantiated at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/WORKSPACE:23:14: in <toplevel>\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace0.bzl:120:20: in workspace\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/io_bazel_rules_go/go/toolchain/toolchains.bzl:379:28: in go_register_toolchains\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/io_bazel_rules_go/go/private/sdk.bzl:65:21: in go_download_sdk\r\nRepository rule _go_download_sdk defined at:\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/io_bazel_rules_go/go/private/sdk.bzl:53:35: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/lite/ios:TensorFlowLiteCMetal_framework' failed; build aborted: Problem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nINFO: Elapsed time: 24.504s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (27 packages loaded, 26 targets configured)\r\n    Fetching @local_config_xcode; fetching\r\n```\r\n\r\nCC: @yyoon ", "comments": ["Have you run the `./configure` script from the repository root directory, before executing the `bazel build` command?\r\nThe way you specify `PYTHON_BIN_PATH` is non-standard. Usually, you'd specify the Python executable path as well as the Python package path when running the `./configure` script, and those settings will be used for all of your subsequent `bazel build` command. (i.e., you shouldn't be manually specifying `--action_env PYTHON_BIN_PATH=...` from the command line)", "I've run `./configure` once again:\r\n\r\n<img width=\"888\" alt=\"Screen Shot 2022-01-05 at 15 15 21\" src=\"https://user-images.githubusercontent.com/41611726/148183587-dac99989-85dc-4776-9796-00a20be43a11.png\">\r\n\r\nAnd when i take a look at the site-packages it doesn't have numpy:\r\n\r\n<img width=\"740\" alt=\"Screen Shot 2022-01-05 at 15 21 24\" src=\"https://user-images.githubusercontent.com/41611726/148184244-9091fa89-e683-4f27-8882-6f5355a9803d.png\">\r\n\r\nIs that possible to running the command `/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install numpy` to install numpy inside Xcode Contents? Or it must be re-installing the Command Line Tools?\r\n ", "And when I use different Python library paths `/usr/local/lib/python3.7/site-packages` which has numpy in it. It's give me another another error message:\r\n\r\n```\r\nadityadwipamungkas@Adityas-MacBook-Pro tensorflow-2.6.2 % bazel build --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=159\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/site-packages --python_path=/usr/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:ios_arm64 in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --config=ios --cpu=ios_arm64\r\nINFO: Found applicable config definition build:ios in file /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/b570a1921c9e55ac53c8972bd2bfd37cd0eb510d.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/WORKSPACE:23:14: in <toplevel>\r\n  /Users/adityadwipamungkas/Downloads/tensorflow-2.6.2/tensorflow/workspace0.bzl:108:34: in workspace\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nERROR: /private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/build_bazel_rules_apple/tools/realpath/BUILD:9:14: in _apple_genrule_inner rule @build_bazel_rules_apple//tools/realpath:realpath_genrule: \r\nTraceback (most recent call last):\r\n        File \"/private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/build_bazel_apple_support/rules/apple_genrule.bzl\", line 78, column 28, in _apple_genrule_impl\r\n                apple_support.run_shell(\r\n        File \"/private/var/tmp/_bazel_adityadwipamungkas/5c73181a29c264533309cd4aec522b90/external/build_bazel_apple_support/lib/apple_support.bzl\", line 339, column 26, in _run_shell\r\n                ctx.actions.run_shell(**_kwargs_for_apple_platform(ctx, **kwargs))\r\nError in run_shell: 'command' must be of type string. passing a sequence of strings as 'command' is deprecated. To temporarily disable this check, set --incompatible_run_shell_command_string=false.\r\nERROR: Analysis of target '//tensorflow/lite/ios:TensorFlowLiteCMetal_framework' failed; build aborted: Analysis of target '@build_bazel_rules_apple//tools/realpath:realpath_genrule' failed\r\nINFO: Elapsed time: 0.551s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)\r\n```", "In your screenshot, the Python lib path definitely doesn't look right: It's pointing to a python module directory contained within your Xcode installation. It should be something like `/Library/Python/3.7/site-packages` or something along this line.\r\n\r\nFor the following error:\r\n```\r\nError in run_shell: 'command' must be of type string. passing a sequence of strings as 'command' is deprecated. To temporarily disable this check, set --incompatible_run_shell_command_string=false.\r\n```\r\n\r\nTry running `bazel build` with the suggested flag:\r\n```\r\nbazel build --incompatible_run_shell_command_string=false --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework\r\n```", "> In your screenshot, the Python lib path definitely doesn't look right: It's pointing to a python module directory contained within your Xcode installation. It should be something like `/Library/Python/3.7/site-packages` or something along this line.\r\n> \r\n> For the following error:\r\n> \r\n> ```\r\n> Error in run_shell: 'command' must be of type string. passing a sequence of strings as 'command' is deprecated. To temporarily disable this check, set --incompatible_run_shell_command_string=false.\r\n> ```\r\n> \r\n> Try running `bazel build` with the suggested flag:\r\n> \r\n> ```\r\n> bazel build --incompatible_run_shell_command_string=false --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework\r\n> ```\r\n\r\nYes it works! Successfully build with no error, the problem it's just wrong Python path library. But I can't use TensorFlowLiteCMetal_framework \ud83d\ude05 which brings up another problem. There might be a problem with the framework I'm using. Thanks @yyoon ", "Closing the issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53640\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53640\">No</a>\n", "This isn't working for me\r\n```\r\n\r\n\u279c  tensorflow git:(master) \u2717 bazel build --config opt  --incompatible_run_shell_command_string=false --verbose_failures --config=ios_arm64 //tensorflow/tools/lib_package:libtensorflow\r\n\r\nWARNING: Option 'java_toolchain' is deprecated\r\nWARNING: Option 'host_java_toolchain' is deprecated\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=80\r\nINFO: Reading rc options for 'build' from /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=//tensorflow/tools/toolchains/java:tf_java_toolchain --host_java_toolchain=//tensorflow/tools/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from /Users/juan.crescente/Documents/lib/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/opt/homebrew/opt/python@3.9/bin/python3.9 --action_env PYTHON_LIB_PATH=/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages --python_path=/opt/homebrew/opt/python@3.9/bin/python3.9\r\nINFO: Reading rc options for 'build' from /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:opt in file /Users/juan.crescente/Documents/lib/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare\r\nINFO: Found applicable config definition build:ios_arm64 in file /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc: --config=ios --cpu=ios_arm64\r\nINFO: Found applicable config definition build:ios in file /Users/juan.crescente/Documents/lib/tensorflow/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1596824487 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /Users/juan.crescente/Documents/lib/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /Users/juan.crescente/Documents/lib/tensorflow/tensorflow/workspace0.bzl:110:34: in workspace\r\n  /private/var/tmp/_bazel_juan.crescente/7d4fd1924864d2d6fce922e4404d7479/external/bazel_toolchains/repositories/repositories.bzl:35:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /private/var/tmp/_bazel_juan.crescente/7d4fd1924864d2d6fce922e4404d7479/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nERROR: /private/var/tmp/_bazel_juan.crescente/7d4fd1924864d2d6fce922e4404d7479/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'ios_arm64'\r\nERROR: /private/var/tmp/_bazel_juan.crescente/7d4fd1924864d2d6fce922e4404d7479/external/local_config_cc/BUILD:48:19: Analysis of target '@local_config_cc//:toolchain' failed\r\nERROR: Analysis of target '//tensorflow/tools/lib_package:libtensorflow' failed; build aborted: \r\nINFO: Elapsed time: 7.847s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (162 packages loaded, 2279 targets\\\r\n configured)\r\n    Fetching @icu; fetching 5s\r\n    Fetching ...al/icu; Extracting /private/var/tmp/_bazel_juan.crescente/7d4f\\\r\nd1924864d2d6fce922e4404d7479/external/icu/temp3335231244032830633/release-69-1\\\r\n.zip\r\n    Fetching @com_google_absl; fetching\r\n    Fetching ...e_absl; Extracting /private/var/tmp/_bazel_juan.crescente/7d4f\\\r\nd1924864d2d6fce922e4404d7479/external/com_google_absl/temp8830191500362278687/\\\r\n215105818dfde3174fe799600bb0f3cae233d0bf.tar.gz\r\n    Fetching @sobol_data; fetching\r\n    Fetching ...l_data; Extracting /private/var/tmp/_bazel_juan.crescente/7d4f\\\r\nd1924864d2d6fce922e4404d7479/external/sobol_data/temp13275797610274825581/835a\\\r\n7d7b1ee3bc83e575e302a985c66ec4b65249.tar.gz\r\n\r\n```"]}, {"number": 53637, "title": "Add missing comma", "body": "As per  https://github.com/tensorflow/tensorflow/issues/53636\r\n\r\nNote I found this issue while integration testing some new checks we've written. I'm a GitHub code review bot and part of my integration testing of new checks includes running against 1000 codebases (this one included).\r\n\r\nIf you're interested: you can [add me to GitHub](https://github.com/marketplace/django-doctor/) so I review PRs automatically and prevent issues like this being merged in the first place :)", "comments": ["I've now signed the CLA, please re-run the check :)", "It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 53636, "title": "Missing comma in test results in unexpected string concatenation", "body": "**System information**.\r\n- Have I written custom code (as opposed to using a stock example script provided in Keras): NA\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NA\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version (use command below): NA\r\n- Python version: NA\r\n- Bazel version (if compiling from source): NA\r\n- GPU model and memory: NA\r\n- Exact command to reproduce: NA\r\n\r\n**Describe the problem**.\r\n\r\nAbsent comma results in unwatned string concatenation on line 330:\r\nhttps://github.com/tensorflow/tensorflow/blob/0d8705c82c64dfb39c49e346de1a66182e5eabd1/tensorflow/python/keras/engine/training_generator_test.py#L330-L336\r\n\r\nSo `'matmul'` gets appended with 'Yaks are also quite nice' resulting in `matmulYaks are also quite nice` being used in the test.\r\n\r\n**Describe the current behavior**.\r\n\r\n`'matmulYaks are also quite nice'` is used in the test\r\n\r\n**Describe the expected behavior**.\r\n\r\n`'matmul', 'Yaks are also quite nice'` is used in the test\r\n\r\n**[Contributing](https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md)**.\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\nAdd the missing comma\r\n\r\n**Standalone code to reproduce the issue**.\r\n\r\nNA\r\n\r\n\r\n**Source code / logs**.\r\n\r\nNA", "comments": ["Would you like to create a PR for the same", "Could you please create the PR in github.com/keras-team/keras repo as per the above linked PR. Let us know if you need any help with that. Thanks!", "this is now fixed upstream", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53636\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53636\">No</a>\n"]}, {"number": 53635, "title": "Update upper bound to numpy to 1.20.", "body": "PiperOrigin-RevId: 419625181\r\nChange-Id: Ic610b47386d029d293a4ab99daf5f3098838d28b\r\n(cherry picked from commit a66666b5ef4baed419ee7d32d1eb60b88486178c)", "comments": ["@pranve @mihaimaruseac the title of this PR says \"Update upper bound to numpy to 1.20\" but the actual commit places a lower bound on numpy. Hopefully this is not a mistake!", "Also, thank you! https://github.com/tensorflow/tensorflow/pull/48935/files#r683906422", "Mistake in language, thank you for flagging"]}, {"number": 53634, "title": "tf.keras k-fold save weights failed! RuntimeError: Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')", "body": "# Background:\r\nI want to train a two-dense-layer classification model, I use the k-fold strategy to train it and use tf.keras.callback.checkpoint utils to save the best model weights:\r\n\r\n`RuntimeError: Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')`\r\n\r\nI tried to change the version of h5py to fix this bug, but it did not work.(2.10.0 ~ 3.6.0).\r\nThis bug will be occured `randomly`, it seems like bugs more frequently when training cost time shorter\uff0cIt seems like when training a k-fold model, the model will be saveing parallel, then this bug will be occurred.\r\n\r\n# when I track to source code of keras, the save_weights function is just like that:\r\n```python\r\ndef save_weights(self, filepath, overwrite=True):\r\n    ...\r\n    with h5py.File(filepath, 'w') as f:\r\n        saving.save_weights_to_hdf5_group(f, self.layers)\r\n        f.flush()\r\nsaving.save_weights_to_hdf5_group means save weights into the HDF5 group\r\n```\r\n# This bug can be repeated by those codes:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom sklearn.model_selection import KFold\r\nimport numpy as np\r\n\r\ninput_dim = 256\r\ninput_x = Input(input_dim,)\r\nx = Dense(128, activation='relu')(input_x)\r\np = Dense(2, activation='sigmoid')(x)\r\nmodel = Model(inputs=input_x, outputs=p)\r\n\r\nmodel.compile(loss='mse', optimizer=Adam(1e-5), metrics = ['acc'])\r\n\r\nsample_num = 2000\r\ntrain, label = np.random.random((sample_num, input_dim)), np.random.random((sample_num, 2))\r\nkfold = KFold(n_splits=5)\r\nfor i, (train_ind, valid_ind) in enumerate(kfold.split(list(range(sample_num)))):\r\n    model_path = f'model-{i}.h5'\r\n    ckpt = ModelCheckpoint(model_path, monitor='val_loss')\r\n    model.fit([train[train_ind], label[train_ind]], label[train_ind], validation_data=[train[valid_ind], label[valid_ind]], epochs=10, batch_size=64, callbacks=[ckpt])\r\n```\r\n# More detailed bug information is:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/notebook/code/personal/test_sihao/gitcode/oCTS_lsh/train_tf2.py\", line 36, in <module>\r\n    current_train_pickle_path, n_fold=5, monitor='val_categorical_crossentropy')\r\n  File \"/home/notebook/data/group/sihao_work/gitcode/oCTS_lsh/classifier/b4k_classifier_tf2.py\", line 186, in model_train_kfold\r\n    self.train(model, train_D, valid_D, tmp_model_save_path, monitor=monitor)\r\n  File \"/home/notebook/data/group/sihao_work/gitcode/oCTS_lsh/classifier/b4k_classifier_tf2.py\", line 159, in train\r\n    callbacks=[early_stopping, plateau, checkpoint])\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1433, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 331, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 311, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 969, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 998, in _save_model\r\n    self.model.save_weights(filepath, overwrite=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1315, in save_weights\r\n    self._ckpt_saved_epoch).encode('utf8')\r\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\", line 544, in __exit__\r\n    self.close()\r\n  File \"/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\", line 526, in close\r\n    self.id._close_open_objects(h5f.OBJ_LOCAL | h5f.OBJ_FILE)\r\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/h5f.pyx\", line 358, in h5py.h5f.FileID._close_open_objects\r\nRuntimeError: Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')\r\nSegmentation fault\r\n```", "comments": ["Hi @mechsihao ! I was  getting different error in 2.7 and able to resolve this issue  by removing square bracket from input data, Attaching [Gist ](https://colab.sandbox.google.com/gist/mohantym/bd6018e0f034de475be01c3414470e73/github_53634.ipynb#scrollTo=sDltZUhPofRp)for reference. Thanks!", "> \r\n\r\nthanks for your reply, but I don't have permission to visit your link, could you please paste your core code here? thanks again~", "Sorry ! I have updated the above[ Gist](https://colab.sandbox.google.com/gist/mohantym/bd6018e0f034de475be01c3414470e73/github_53634.ipynb#scrollTo=sDltZUhPofRp) link . Thanks!", "> Sorry ! I have updated the above[ Gist](https://colab.sandbox.google.com/gist/mohantym/bd6018e0f034de475be01c3414470e73/github_53634.ipynb#scrollTo=sDltZUhPofRp) link . Thanks!\r\n\r\nThanks~!", "> Sorry ! I have updated the above[ Gist](https://colab.sandbox.google.com/gist/mohantym/bd6018e0f034de475be01c3414470e73/github_53634.ipynb#scrollTo=sDltZUhPofRp) link . Thanks!\r\n\r\nIt seems not repeat this bug, I am testing it by updatding tf version to 2.7.0 ", "> Sorry ! I have updated the above[ Gist](https://colab.sandbox.google.com/gist/mohantym/bd6018e0f034de475be01c3414470e73/github_53634.ipynb#scrollTo=sDltZUhPofRp) link . Thanks!\r\n\r\nit really odd, this bug cannot be repeated in the collab, but it can be easily repeated in my local ubuntu when I use the same version TensorFlow even same version of Ubuntu\r\n\r\nbugs detail:\r\n```python\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom sklearn.model_selection import KFold\r\nimport numpy as np\r\n\r\ninput_dim = 256\r\ninput_x = Input(input_dim,)\r\nx = Dense(128, activation='relu')(input_x)\r\np = Dense(2, activation='sigmoid')(x)\r\nmodel = Model(inputs=input_x, outputs=p)\r\n\r\nmodel.compile(loss='mse', optimizer=Adam(1e-5), metrics = ['acc'])\r\n\r\nsample_num = 2000\r\ntrain, label = np.random.random((sample_num, input_dim)), np.random.random((sample_num, 2))\r\nkfold = KFold(n_splits=5)\r\nfor i, (train_ind, valid_ind) in enumerate(kfold.split(list(range(sample_num)))):\r\n    model_path = f'model_{i}.h5'\r\n    ckpt = ModelCheckpoint(model_path, monitor='val_loss')\r\n    model.fit(train[train_ind], label[train_ind], validation_data=[train[valid_ind], label[valid_ind]], epochs=10, batch_size=64, callbacks=[ckpt])\r\n```\r\n\r\n[output]\r\n```python \r\n2.7.0\r\nEpoch 1/10\r\n25/25 [==============================] - 1s 9ms/step - loss: 0.0925 - acc: 0.5031 - val_loss: 0.0940 - val_acc: 0.4800\r\nEpoch 2/10\r\n25/25 [==============================] - 0s 4ms/step - loss: 0.0899 - acc: 0.5044 - val_loss: 0.0920 - val_acc: 0.4875\r\nEpoch 3/10\r\n25/25 [==============================] - 0s 5ms/step - loss: 0.0888 - acc: 0.5063 - val_loss: 0.0914 - val_acc: 0.5000\r\nEpoch 4/10\r\n25/25 [==============================] - 0s 4ms/step - loss: 0.0884 - acc: 0.5088 - val_loss: 0.0911 - val_acc: 0.5050\r\nEpoch 5/10\r\n25/25 [==============================] - 0s 6ms/step - loss: 0.0883 - acc: 0.5088 - val_loss: 0.0910 - val_acc: 0.5125\r\nEpoch 6/10\r\n25/25 [==============================] - 0s 5ms/step - loss: 0.0882 - acc: 0.5056 - val_loss: 0.0909 - val_acc: 0.5225\r\nEpoch 7/10\r\n 1/25 [>.............................] - ETA: 0s - loss: 0.0884 - acc: 0.4844\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-4a6bc3ee19e9> in <module>\r\n     22     model_path = f'model_{i}.h5'\r\n     23     ckpt = ModelCheckpoint(model_path, monitor='val_loss')\r\n---> 24     model.fit(train[train_ind], label[train_ind], validation_data=[train[valid_ind], label[valid_ind]], epochs=10, batch_size=64, callbacks=[ckpt])\r\n\r\n/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py in close(self)\r\n    441                 for id_ in file_list:\r\n    442                     while id_.valid:\r\n--> 443                         h5i.dec_ref(id_)\r\n    444 \r\n    445                 self.id.close()\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/h5i.pyx in h5py.h5i.dec_ref()\r\n\r\nRuntimeError: Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')\r\n```", "Hi @mechsihao ! I think it might be due to environment configuration or installation. Can you please update the [template](https://github.com/tensorflow/tensorflow/issues/new/choose) which will help investigate this issue further? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53634\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53634\">No</a>\n"]}, {"number": 53633, "title": "Dataset.batch() change tensor shape and abort LSTM fit", "body": "**System information**\r\n- TensorFlow version: v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Platform: Kaggle TPU\r\n\r\nHi, my LSTM code give this error using dataset.batch():\r\n\r\n```\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:540 run\r\n        return self.extended.tpu_run(fn, args, kwargs, options)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:1296 tpu_run\r\n        return func(args, kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:1364 tpu_function\r\n        xla_options=tpu.XLAOptions(use_spmd_for_xla_partitioning=False))\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/tpu/tpu.py:968 replicate\r\n        xla_options=xla_options)[1]\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/tpu/tpu.py:1439 split_compile_and_replicate\r\n        outputs = computation(*computation_inputs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:1325 replicated_fn\r\n        result[0] = fn(*replica_args, **replica_kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\r\n        y_pred = self(x, training=True)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\r\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\r\n        str(tuple(shape)))\r\n\r\n    ValueError: Input 0 of layer model is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, 3, 13)\r\n```\r\n\r\nMeanwhile without dataset.batch() the code works correctly.\r\n\r\nI'm using Tensorflow dataset from tfrecord files:\r\n\r\n```\r\ndef read_tfrecord(example_proto):\r\n    feature_description = {\r\n    'x': tf.io.FixedLenFeature([], tf.string),\r\n    'y': tf.io.FixedLenFeature([], tf.string),\r\n    }\r\n    example = tf.io.parse_single_example(example_proto, feature_description)\r\n    vect = tf.io.parse_tensor(example['x'], tf.float16)\r\n    label = tf.io.parse_tensor(example['y'], tf.int8)\r\n\r\n    vect = tf.reshape(vect, [-1, ws, num_features])\r\n    label = tf.reshape(label, [-1, 1])\r\n\r\n    return vect, label\r\n```\r\nI have to add the reshape because without i get this error:\r\n\r\n    TypeError: can't multiply sequence by non-int of type 'NoneType'\r\n\r\nand here suggest to add reshape: [link][1]\r\n\r\n\r\n```\r\ndef load_dataset(filenames):\r\n    ignore_order = tf.data.Options()\r\n    ignore_order.experimental_deterministic = False  # disable order, increase speed\r\n    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\r\n    dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order\r\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\r\n    dataset = dataset.batch(bs)\r\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\r\n    return dataset\r\n```\r\n\r\n```\r\n    model = Sequential(name = \"model\")\r\n    model.add(LSTM(units=units, input_shape=(ws, num_features), return_sequences=False, dropout = dropout))\r\n    model.add(Dense(units=num_labels, activation = \"sigmoid\"))\r\n    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=[BinaryAccuracy(), AUC(), Precision(), Recall()])\r\n```\r\nHere you can see the dataset with: \r\n```\r\nfor parsed_record in parsed_dataset.take(10):\r\n  print(repr(parsed_record))\r\n```\r\n![MicrosoftTeams-image](https://user-images.githubusercontent.com/48318112/148097080-fcb05ce4-9769-421f-9815-90ddf1506ad8.png)\r\n\r\n\r\n  [1]: https://github.com/tensorflow/tensorflow/issues/40864\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53633\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53633\">No</a>\n"]}, {"number": 53632, "title": "Updating bazel causes python to abort during build on AARCH64", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 4.2.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild fails with an abort from Python when using Bazel 4.2.2. The same build works with bazel 3.7.2\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures --copt=-ffp-contract=off --cxxopt=-ffp-contract=off\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nhttps://ci.linaro.org/job/ldcg-python-manylinux-tensorflow-nightly/225/console\r\n18:51:45     Execution platform: @local_execution_config_platform//:platform\r\n18:51:45     *** Error in `/tmp/workspace/venv-cp37-cp37m/bin/python3': free(): invalid pointer: 0x0000fffef8184fa8 ***\r\n18:51:45     ======= Backtrace: =========\r\n18:51:45     /lib64/libc.so.6(+0x7d1ec)[0xffff9694d1ec]\r\n18:51:45     /lib64/libstdc++.so.6(_ZNSt6locale5_Impl16_M_install_facetEPKNS_2idEPKNS_5facetE+0x138)[0xfffef80d08dc]\r\n18:51:45     /lib64/libstdc++.so.6(_ZNSt6locale5_ImplC1Em+0x188)[0xfffef80d0cfc]\r\n18:51:45     /lib64/libstdc++.so.6(+0x717dc)[0xfffef80d17dc]\r\n18:51:45     /lib64/libpthread.so.0(+0x5db0)[0xffff96b85db0]\r\n18:51:45     /lib64/libstdc++.so.6(+0x71828)[0xfffef80d1828]\r\n18:51:45     /lib64/libstdc++.so.6(_ZNSt6localeC2Ev+0x1c)[0xfffef80d1864]\r\n18:51:45     /lib64/libstdc++.so.6(_ZNSt8ios_base4InitC2Ev+0xbc)[0xfffef80ceb58]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/pyext/_message.cpython-37m-aarch64-linux-gnu.so(+0xa89dc)[0xfffef7eb89dc]\r\n18:51:45     /lib/ld-linux-aarch64.so.1(+0xe470)[0xffff96c5e470]\r\n18:51:45     /lib/ld-linux-aarch64.so.1(+0x12a68)[0xffff96c62a68]\r\n18:51:45     /lib/ld-linux-aarch64.so.1(+0xe28c)[0xffff96c5e28c]\r\n18:51:45     /lib/ld-linux-aarch64.so.1(+0x12124)[0xffff96c62124]\r\n18:51:45     /lib64/libdl.so.2(+0xfa4)[0xffff96b50fa4]\r\n18:51:45     /lib/ld-linux-aarch64.so.1(+0xe28c)[0xffff96c5e28c]\r\n18:51:45     /lib64/libdl.so.2(+0x1614)[0xffff96b51614]\r\n18:51:45     /lib64/libdl.so.2(dlopen+0x38)[0xffff96b5104c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyImport_FindSharedFuncptr+0x1ac)[0x4ff20c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyImport_LoadDynamicModuleWithSpec+0x124)[0x4d5834]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x4d3604]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyMethodDef_RawFastCallDict+0x304)[0x436bc4]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyCFunction_Call+0x184)[0x436df8]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x61c8)[0x426188]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalCodeWithName+0x82c)[0x4bb34c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyFunction_FastCallKeywords+0x7c)[0x435ea0]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x5ad0)[0x425a90]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41eb4c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x4a04)[0x4249c4]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41eb4c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x44a4)[0x424464]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41eb4c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x44a4)[0x424464]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41eb4c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x44a4)[0x424464]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41eb4c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x437fc0]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyObject_CallMethodIdObjArgs+0x9c)[0x43827c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyImport_ImportModuleLevelObject+0x580)[0x4d48e0]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x4b6a40]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyCFunction_Call+0x114)[0x436d88]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x61c8)[0x426188]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalCodeWithName+0x82c)[0x4bb34c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyFunction_FastCallKeywords+0x7c)[0x435ea0]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x41fc30]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x44a4)[0x424464]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalCodeWithName+0x82c)[0x4bb34c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyFunction_FastCallDict+0x1d0)[0x435d10]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x437fc0]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyObject_CallMethodIdObjArgs+0x9c)[0x43827c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyImport_ImportModuleLevelObject+0x334)[0x4d4694]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x7188)[0x427148]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalCodeWithName+0x82c)[0x4bb34c]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyEval_EvalCode+0x38)[0x4bb5fc]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3[0x4b8738]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyMethodDef_RawFastCallDict+0x304)[0x436bc4]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(PyCFunction_Call+0x184)[0x436df8]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalFrameDefault+0x61c8)[0x426188]\r\n18:51:45     /tmp/workspace/venv-cp37-cp37m/bin/python3(_PyEval_EvalCodeWithName+0x82c)[0x4bb34c]\r\n18:51:45     ======= Memory map: ========\r\n18:51:45     00400000-00640000 r-xp 00000000 fd:02 405195408                          /opt/_internal/cpython-3.7.12/bin/python3.7\r\n18:51:45     00650000-00660000 r--p 00240000 fd:02 405195408                          /opt/_internal/cpython-3.7.12/bin/python3.7\r\n18:51:45     00660000-006d0000 rw-p 00250000 fd:02 405195408                          /opt/_internal/cpython-3.7.12/bin/python3.7\r\n18:51:45     006d0000-006f0000 rw-p 00000000 00:00 0\r\n18:51:45     3ca80000-3dd70000 rw-p 00000000 00:00 0                                  [heap]\r\n18:51:45     fffef0000000-fffef0030000 rw-p 00000000 00:00 0\r\n18:51:45     fffef0030000-fffef4000000 ---p 00000000 00:00 0\r\n18:51:45     fffef7e10000-fffef8040000 r-xp 00000000 fd:02 405409191                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/pyext/_message.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8040000-fffef8050000 r--p 00220000 fd:02 405409191                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/pyext/_message.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8050000-fffef8060000 rw-p 00230000 fd:02 405409191                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/pyext/_message.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8060000-fffef8150000 r-xp 00000000 fd:02 270523991                  /usr/lib64/libstdc++.so.6.0.19\r\n18:51:45     fffef8150000-fffef8160000 ---p 000f0000 fd:02 270523991                  /usr/lib64/libstdc++.so.6.0.19\r\n18:51:45     fffef8160000-fffef8170000 r--p 000f0000 fd:02 270523991                  /usr/lib64/libstdc++.so.6.0.19\r\n18:51:45     fffef8170000-fffef8180000 rw-p 00100000 fd:02 270523991                  /usr/lib64/libstdc++.so.6.0.19\r\n18:51:45     fffef8180000-fffef8210000 rw-p 00000000 00:00 0\r\n18:51:45     fffef82f0000-fffef8300000 r-xp 00000000 fd:02 276318214                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/internal/_api_implementation.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8300000-fffef8310000 rw-p 00000000 fd:02 276318214                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/google/protobuf/internal/_api_implementation.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8310000-fffef8390000 rw-p 00000000 00:00 0\r\n18:51:45     fffef8390000-fffef8430000 r-xp 00000000 fd:02 276318271                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8430000-fffef8440000 r--p 00090000 fd:02 276318271                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8440000-fffef8470000 rw-p 000a0000 fd:02 276318271                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8470000-fffef8480000 r-xp 00000000 fd:02 276318277                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_sfc64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8480000-fffef8490000 r--p 00000000 fd:02 276318277                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_sfc64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8490000-fffef84a0000 rw-p 00010000 fd:02 276318277                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_sfc64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef84a0000-fffef84b0000 r-xp 00000000 fd:02 276318268                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_pcg64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef84b0000-fffef84c0000 r--p 00000000 fd:02 276318268                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_pcg64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef84c0000-fffef84d0000 rw-p 00010000 fd:02 276318268                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_pcg64.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef84d0000-fffef84f0000 r-xp 00000000 fd:02 276318282                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_philox.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef84f0000-fffef8500000 r--p 00010000 fd:02 276318282                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_philox.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8500000-fffef8510000 rw-p 00020000 fd:02 276318282                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_philox.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8510000-fffef8530000 r-xp 00000000 fd:02 276318285                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_mt19937.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8530000-fffef8540000 r--p 00010000 fd:02 276318285                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_mt19937.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8540000-fffef8550000 rw-p 00020000 fd:02 276318285                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_mt19937.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8550000-fffef85b0000 r-xp 00000000 fd:02 276318298                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_bounded_integers.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef85b0000-fffef85c0000 r--p 00050000 fd:02 276318298                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_bounded_integers.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef85c0000-fffef85d0000 rw-p 00060000 fd:02 276318298                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_bounded_integers.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef85d0000-fffef85e0000 r-xp 00000000 fd:02 272114734                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/binascii.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef85e0000-fffef85f0000 r--p 00000000 fd:02 272114734                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/binascii.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef85f0000-fffef8600000 rw-p 00010000 fd:02 272114734                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/binascii.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8600000-fffef8640000 r-xp 00000000 fd:02 276318288                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_common.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8640000-fffef8650000 r--p 00030000 fd:02 276318288                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_common.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8650000-fffef8660000 rw-p 00040000 fd:02 276318288                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/_common.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8660000-fffef8690000 r-xp 00000000 fd:02 276318291                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/bit_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8690000-fffef86a0000 r--p 00020000 fd:02 276318291                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/bit_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef86a0000-fffef86b0000 rw-p 00030000 fd:02 276318291                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/bit_generator.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef86b0000-fffef86f0000 rw-p 00000000 00:00 0\r\n18:51:45     fffef86f0000-fffef8770000 r-xp 00000000 fd:02 276318287                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/mtrand.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8770000-fffef8780000 r--p 00070000 fd:02 276318287                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/mtrand.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8780000-fffef87b0000 rw-p 00080000 fd:02 276318287                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/random/mtrand.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef87b0000-fffef87f0000 rw-p 00000000 00:00 0\r\n18:51:45     fffef87f0000-fffef8810000 r-xp 00000000 fd:02 276318311                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/fft/_pocketfft_internal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8810000-fffef8820000 r--p 00010000 fd:02 276318311                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/fft/_pocketfft_internal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8820000-fffef8830000 rw-p 00020000 fd:02 276318311                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/fft/_pocketfft_internal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8830000-fffef8880000 r-xp 00000000 fd:02 272114701                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_decimal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8880000-fffef8890000 r--p 00040000 fd:02 272114701                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_decimal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8890000-fffef88a0000 rw-p 00050000 fd:02 272114701                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_decimal.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef88a0000-fffef88e0000 rw-p 00000000 00:00 0\r\n18:51:45     fffef88e0000-fffef88f0000 r-xp 00000000 fd:02 272114737                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/grp.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef88f0000-fffef8900000 r--p 00000000 fd:02 272114737                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/grp.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8900000-fffef8910000 rw-p 00010000 fd:02 272114737                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/grp.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8910000-fffef8940000 r-xp 00000000 fd:02 270522138                  /usr/lib64/liblzma.so.5.2.2\r\n18:51:45     fffef8940000-fffef8950000 r--p 00020000 fd:02 270522138                  /usr/lib64/liblzma.so.5.2.2\r\n18:51:45     fffef8950000-fffef8960000 rw-p 00030000 fd:02 270522138                  /usr/lib64/liblzma.so.5.2.2\r\n18:51:45     fffef8960000-fffef8970000 r-xp 00000000 fd:02 272114708                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_lzma.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8970000-fffef8980000 r--p 00000000 fd:02 272114708                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_lzma.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8980000-fffef8990000 rw-p 00010000 fd:02 272114708                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_lzma.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8990000-fffef89a0000 r-xp 00000000 fd:02 272114683                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bz2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef89a0000-fffef89b0000 r--p 00000000 fd:02 272114683                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bz2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef89b0000-fffef89c0000 rw-p 00010000 fd:02 272114683                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bz2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef89c0000-fffef89e0000 r-xp 00000000 fd:02 405192202                  /usr/lib64/libz.so.1.2.7\r\n18:51:45     fffef89e0000-fffef89f0000 r--p 00010000 fd:02 405192202                  /usr/lib64/libz.so.1.2.7\r\n18:51:45     fffef89f0000-fffef8a00000 rw-p 00020000 fd:02 405192202                  /usr/lib64/libz.so.1.2.7\r\n18:51:45     fffef8a00000-fffef8a10000 r-xp 00000000 fd:02 272158592                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/zlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8a10000-fffef8a20000 r--p 00000000 fd:02 272158592                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/zlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8a20000-fffef8a30000 rw-p 00010000 fd:02 272158592                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/zlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8a30000-fffef8af0000 rw-p 00000000 00:00 0\r\n18:51:45     fffef8af0000-fffef8b20000 r-xp 00000000 fd:02 7592199                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/_umath_linalg.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8b20000-fffef8b30000 r--p 00020000 fd:02 7592199                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/_umath_linalg.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8b30000-fffef8b60000 rw-p 00030000 fd:02 7592199                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/_umath_linalg.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8b60000-fffef8b70000 r-xp 00000000 fd:02 7592203                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8b70000-fffef8b80000 r--p 00000000 fd:02 7592203                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8b80000-fffef8bb0000 rw-p 00010000 fd:02 7592203                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8bb0000-fffef8c30000 rw-p 00000000 00:00 0\r\n18:51:45     fffef8c30000-fffef8c60000 r-xp 00000000 fd:02 276318408                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_tests.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8c60000-fffef8c70000 r--p 00020000 fd:02 276318408                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_tests.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8c70000-fffef8c80000 rw-p 00030000 fd:02 276318408                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_tests.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     fffef8c80000-fffef8d00000 rw-p 00000000 00:00 0\r\n18:51:45     fffef8d00000-fffefcd00000 rw-p 00000000 00:00 0\r\n18:51:45     fffefcd00000-fffefcd10000 ---p 00000000 00:00 0\r\n18:51:45     fffefcd10000-fffefd510000 rw-p 00000000 00:00 0\r\n18:51:45     fffefd510000-fffeff510000 rw-p 00000000 00:00 0\r\n18:51:45     fffeff510000-fffeff520000 ---p 00000000 00:00 0\r\n18:51:45     fffeff520000-fffeffd20000 rw-p 00000000 00:00 0\r\n18:51:45     fffeffd20000-ffff01d20000 rw-p 00000000 00:00 0\r\n18:51:45     ffff01d20000-ffff01d30000 ---p 00000000 00:00 0\r\n18:51:45     ffff01d30000-ffff02530000 rw-p 00000000 00:00 0\r\n18:51:45     ffff02530000-ffff04530000 rw-p 00000000 00:00 0\r\n18:51:45     ffff04530000-ffff04540000 ---p 00000000 00:00 0\r\n18:51:45     ffff04540000-ffff04d40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff04d40000-ffff06d40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff06d40000-ffff06d50000 ---p 00000000 00:00 0\r\n18:51:45     ffff06d50000-ffff07550000 rw-p 00000000 00:00 0\r\n18:51:45     ffff07550000-ffff09550000 rw-p 00000000 00:00 0\r\n18:51:45     ffff09550000-ffff09560000 ---p 00000000 00:00 0\r\n18:51:45     ffff09560000-ffff09d60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff09d60000-ffff0bd60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff0bd60000-ffff0bd70000 ---p 00000000 00:00 0\r\n18:51:45     ffff0bd70000-ffff0c570000 rw-p 00000000 00:00 0\r\n18:51:45     ffff0c570000-ffff0e570000 rw-p 00000000 00:00 0\r\n18:51:45     ffff0e570000-ffff0e580000 ---p 00000000 00:00 0\r\n18:51:45     ffff0e580000-ffff0ed80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff0ed80000-ffff10d80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff10d80000-ffff10d90000 ---p 00000000 00:00 0\r\n18:51:45     ffff10d90000-ffff11590000 rw-p 00000000 00:00 0\r\n18:51:45     ffff11590000-ffff13590000 rw-p 00000000 00:00 0\r\n18:51:45     ffff13590000-ffff135a0000 ---p 00000000 00:00 0\r\n18:51:45     ffff135a0000-ffff13da0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff13da0000-ffff15da0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff15da0000-ffff15db0000 ---p 00000000 00:00 0\r\n18:51:45     ffff15db0000-ffff165b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff165b0000-ffff185b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff185b0000-ffff185c0000 ---p 00000000 00:00 0\r\n18:51:45     ffff185c0000-ffff18dc0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff18dc0000-ffff1adc0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff1adc0000-ffff1add0000 ---p 00000000 00:00 0\r\n18:51:45     ffff1add0000-ffff1b5d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff1b5d0000-ffff1d5d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff1d5d0000-ffff1d5e0000 ---p 00000000 00:00 0\r\n18:51:45     ffff1d5e0000-ffff1dde0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff1dde0000-ffff1fde0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff1fde0000-ffff1fdf0000 ---p 00000000 00:00 0\r\n18:51:45     ffff1fdf0000-ffff205f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff205f0000-ffff225f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff225f0000-ffff22600000 ---p 00000000 00:00 0\r\n18:51:45     ffff22600000-ffff22e00000 rw-p 00000000 00:00 0\r\n18:51:45     ffff22e00000-ffff24e00000 rw-p 00000000 00:00 0\r\n18:51:45     ffff24e00000-ffff24e10000 ---p 00000000 00:00 0\r\n18:51:45     ffff24e10000-ffff25610000 rw-p 00000000 00:00 0\r\n18:51:45     ffff25610000-ffff27610000 rw-p 00000000 00:00 0\r\n18:51:45     ffff27610000-ffff27620000 ---p 00000000 00:00 0\r\n18:51:45     ffff27620000-ffff27e20000 rw-p 00000000 00:00 0\r\n18:51:45     ffff27e20000-ffff29e20000 rw-p 00000000 00:00 0\r\n18:51:45     ffff29e20000-ffff29e30000 ---p 00000000 00:00 0\r\n18:51:45     ffff29e30000-ffff2a630000 rw-p 00000000 00:00 0\r\n18:51:45     ffff2a630000-ffff2c630000 rw-p 00000000 00:00 0\r\n18:51:45     ffff2c630000-ffff2c640000 ---p 00000000 00:00 0\r\n18:51:45     ffff2c640000-ffff2ce40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff2ce40000-ffff2ee40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff2ee40000-ffff2ee50000 ---p 00000000 00:00 0\r\n18:51:45     ffff2ee50000-ffff2f650000 rw-p 00000000 00:00 0\r\n18:51:45     ffff2f650000-ffff31650000 rw-p 00000000 00:00 0\r\n18:51:45     ffff31650000-ffff31660000 ---p 00000000 00:00 0\r\n18:51:45     ffff31660000-ffff31e60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff31e60000-ffff33e60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff33e60000-ffff33e70000 ---p 00000000 00:00 0\r\n18:51:45     ffff33e70000-ffff34670000 rw-p 00000000 00:00 0\r\n18:51:45     ffff34670000-ffff36670000 rw-p 00000000 00:00 0\r\n18:51:45     ffff36670000-ffff36680000 ---p 00000000 00:00 0\r\n18:51:45     ffff36680000-ffff36e80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff36e80000-ffff38e80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff38e80000-ffff38e90000 ---p 00000000 00:00 0\r\n18:51:45     ffff38e90000-ffff39690000 rw-p 00000000 00:00 0\r\n18:51:45     ffff39690000-ffff3b690000 rw-p 00000000 00:00 0\r\n18:51:45     ffff3b690000-ffff3b6a0000 ---p 00000000 00:00 0\r\n18:51:45     ffff3b6a0000-ffff3bea0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff3bea0000-ffff3dea0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff3dea0000-ffff3deb0000 ---p 00000000 00:00 0\r\n18:51:45     ffff3deb0000-ffff3e6b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff3e6b0000-ffff406b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff406b0000-ffff406c0000 ---p 00000000 00:00 0\r\n18:51:45     ffff406c0000-ffff40ec0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff40ec0000-ffff42ec0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff42ec0000-ffff42ed0000 ---p 00000000 00:00 0\r\n18:51:45     ffff42ed0000-ffff436d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff436d0000-ffff456d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff456d0000-ffff456e0000 ---p 00000000 00:00 0\r\n18:51:45     ffff456e0000-ffff45ee0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff45ee0000-ffff47ee0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff47ee0000-ffff47ef0000 ---p 00000000 00:00 0\r\n18:51:45     ffff47ef0000-ffff486f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff486f0000-ffff4a6f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4a6f0000-ffff4a700000 ---p 00000000 00:00 0\r\n18:51:45     ffff4a700000-ffff4af00000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4af00000-ffff4cf00000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4cf00000-ffff4cf10000 ---p 00000000 00:00 0\r\n18:51:45     ffff4cf10000-ffff4d710000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4d710000-ffff4f710000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4f710000-ffff4f720000 ---p 00000000 00:00 0\r\n18:51:45     ffff4f720000-ffff4ff20000 rw-p 00000000 00:00 0\r\n18:51:45     ffff4ff20000-ffff51f20000 rw-p 00000000 00:00 0\r\n18:51:45     ffff51f20000-ffff51f30000 ---p 00000000 00:00 0\r\n18:51:45     ffff51f30000-ffff52730000 rw-p 00000000 00:00 0\r\n18:51:45     ffff52730000-ffff54730000 rw-p 00000000 00:00 0\r\n18:51:45     ffff54730000-ffff54740000 ---p 00000000 00:00 0\r\n18:51:45     ffff54740000-ffff54f40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff54f40000-ffff56f40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff56f40000-ffff56f50000 ---p 00000000 00:00 0\r\n18:51:45     ffff56f50000-ffff57750000 rw-p 00000000 00:00 0\r\n18:51:45     ffff57750000-ffff59750000 rw-p 00000000 00:00 0\r\n18:51:45     ffff59750000-ffff59760000 ---p 00000000 00:00 0\r\n18:51:45     ffff59760000-ffff59f60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff59f60000-ffff5bf60000 rw-p 00000000 00:00 0\r\n18:51:45     ffff5bf60000-ffff5bf70000 ---p 00000000 00:00 0\r\n18:51:45     ffff5bf70000-ffff5c770000 rw-p 00000000 00:00 0\r\n18:51:45     ffff5c770000-ffff5e770000 rw-p 00000000 00:00 0\r\n18:51:45     ffff5e770000-ffff5e780000 ---p 00000000 00:00 0\r\n18:51:45     ffff5e780000-ffff5ef80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff5ef80000-ffff60f80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff60f80000-ffff60f90000 ---p 00000000 00:00 0\r\n18:51:45     ffff60f90000-ffff61790000 rw-p 00000000 00:00 0\r\n18:51:45     ffff61790000-ffff63790000 rw-p 00000000 00:00 0\r\n18:51:45     ffff63790000-ffff637a0000 ---p 00000000 00:00 0\r\n18:51:45     ffff637a0000-ffff63fa0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff63fa0000-ffff65fa0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff65fa0000-ffff65fb0000 ---p 00000000 00:00 0\r\n18:51:45     ffff65fb0000-ffff667b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff667b0000-ffff687b0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff687b0000-ffff687c0000 ---p 00000000 00:00 0\r\n18:51:45     ffff687c0000-ffff68fc0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff68fc0000-ffff6afc0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff6afc0000-ffff6afd0000 ---p 00000000 00:00 0\r\n18:51:45     ffff6afd0000-ffff6b7d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff6b7d0000-ffff6d7d0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff6d7d0000-ffff6d7e0000 ---p 00000000 00:00 0\r\n18:51:45     ffff6d7e0000-ffff6dfe0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff6dfe0000-ffff6ffe0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff6ffe0000-ffff6fff0000 ---p 00000000 00:00 0\r\n18:51:45     ffff6fff0000-ffff707f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff707f0000-ffff727f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff727f0000-ffff72800000 ---p 00000000 00:00 0\r\n18:51:45     ffff72800000-ffff73000000 rw-p 00000000 00:00 0\r\n18:51:45     ffff73000000-ffff75000000 rw-p 00000000 00:00 0\r\n18:51:45     ffff75000000-ffff75010000 ---p 00000000 00:00 0\r\n18:51:45     ffff75010000-ffff75810000 rw-p 00000000 00:00 0\r\n18:51:45     ffff75810000-ffff77810000 rw-p 00000000 00:00 0\r\n18:51:45     ffff77810000-ffff77820000 ---p 00000000 00:00 0\r\n18:51:45     ffff77820000-ffff78020000 rw-p 00000000 00:00 0\r\n18:51:45     ffff78020000-ffff7a020000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7a020000-ffff7a030000 ---p 00000000 00:00 0\r\n18:51:45     ffff7a030000-ffff7a830000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7a830000-ffff7c830000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7c830000-ffff7c840000 ---p 00000000 00:00 0\r\n18:51:45     ffff7c840000-ffff7d040000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7d040000-ffff7f040000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7f040000-ffff7f050000 ---p 00000000 00:00 0\r\n18:51:45     ffff7f050000-ffff7f850000 rw-p 00000000 00:00 0\r\n18:51:45     ffff7f850000-ffff81850000 rw-p 00000000 00:00 0\r\n18:51:45     ffff81850000-ffff81860000 ---p 00000000 00:00 0\r\n18:51:45     ffff81860000-ffff82060000 rw-p 00000000 00:00 0\r\n18:51:45     ffff82060000-ffff82070000 ---p 00000000 00:00 0\r\n18:51:45     ffff82070000-ffff82870000 rw-p 00000000 00:00 0\r\n18:51:45     ffff82870000-ffff829c0000 r-xp 00000000 fd:02 7592180                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libgfortran-daac5196.so.5.0.0\r\n18:51:45     ffff829c0000-ffff829d0000 r--p 00140000 fd:02 7592180                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libgfortran-daac5196.so.5.0.0\r\n18:51:45     ffff829d0000-ffff82a00000 rw-p 00150000 fd:02 7592180                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libgfortran-daac5196.so.5.0.0\r\n18:51:45     ffff82a00000-ffff83d40000 r-xp 00000000 fd:02 7592178                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libopenblasp-r0-32ff4d91.3.13.so\r\n18:51:45     ffff83d40000-ffff83d50000 ---p 01340000 fd:02 7592178                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libopenblasp-r0-32ff4d91.3.13.so\r\n18:51:45     ffff83d50000-ffff83d60000 r--p 01340000 fd:02 7592178                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libopenblasp-r0-32ff4d91.3.13.so\r\n18:51:45     ffff83d60000-ffff83d80000 rw-p 01350000 fd:02 7592178                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libopenblasp-r0-32ff4d91.3.13.so\r\n18:51:45     ffff83d80000-ffff83e00000 rw-p 014e0000 fd:02 7592178                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libopenblasp-r0-32ff4d91.3.13.so\r\n18:51:45     ffff83e00000-ffff84190000 r-xp 00000000 fd:02 276318455                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84190000-ffff841a0000 r--p 00380000 fd:02 276318455                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff841a0000-ffff841c0000 rw-p 00390000 fd:02 276318455                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff841c0000-ffff841e0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff841e0000-ffff84200000 rw-p 00400000 fd:02 276318455                  /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84200000-ffff84280000 rw-p 00000000 00:00 0\r\n18:51:45     ffff84280000-ffff84290000 r-xp 00000000 fd:02 270252825                  /usr/lib64/libbz2.so.1.0.6\r\n18:51:45     ffff84290000-ffff842a0000 rw-p 00010000 fd:02 270252825                  /usr/lib64/libbz2.so.1.0.6\r\n18:51:45     ffff842a0000-ffff84380000 rw-p 00000000 00:00 0\r\n18:51:45     ffff84380000-ffff843a0000 r-xp 00000000 fd:02 272114713                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_pickle.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff843a0000-ffff843b0000 r--p 00010000 fd:02 272114713                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_pickle.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff843b0000-ffff843c0000 rw-p 00020000 fd:02 272114713                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_pickle.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff843c0000-ffff843e0000 r-xp 00000000 fd:02 272114699                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_datetime.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff843e0000-ffff843f0000 r--p 00010000 fd:02 272114699                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_datetime.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff843f0000-ffff84400000 rw-p 00020000 fd:02 272114699                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_datetime.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84400000-ffff844c0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff844c0000-ffff844d0000 r-xp 00000000 fd:02 272114714                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff844d0000-ffff844e0000 r--p 00000000 fd:02 272114714                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff844e0000-ffff844f0000 rw-p 00010000 fd:02 272114714                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff844f0000-ffff84510000 r-xp 00000000 fd:02 7592179                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libz-558a5e64.so.1.2.7\r\n18:51:45     ffff84510000-ffff84520000 r--p 00010000 fd:02 7592179                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libz-558a5e64.so.1.2.7\r\n18:51:45     ffff84520000-ffff84540000 rw-p 00020000 fd:02 7592179                    /tmp/workspace/venv-cp37-cp37m/lib/python3.7/site-packages/numpy.libs/libz-558a5e64.so.1.2.7\r\n18:51:45     ffff84540000-ffff84550000 r-xp 00000000 fd:02 272114736                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/fcntl.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84550000-ffff84560000 r--p 00000000 fd:02 272114736                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/fcntl.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84560000-ffff84570000 rw-p 00010000 fd:02 272114736                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/fcntl.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84570000-ffff84580000 r-xp 00000000 fd:02 272114694                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_csv.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84580000-ffff84590000 r--p 00000000 fd:02 272114694                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_csv.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84590000-ffff845a0000 rw-p 00010000 fd:02 272114694                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_csv.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff845a0000-ffff845e0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff845e0000-ffff845f0000 r-xp 00000000 fd:02 272114746                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/select.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff845f0000-ffff84600000 r--p 00000000 fd:02 272114746                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/select.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84600000-ffff84610000 rw-p 00010000 fd:02 272114746                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/select.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84610000-ffff84630000 r-xp 00000000 fd:02 272114721                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_socket.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84630000-ffff84640000 r--p 00010000 fd:02 272114721                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_socket.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84640000-ffff84650000 rw-p 00020000 fd:02 272114721                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_socket.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84650000-ffff84880000 r-xp 00000000 fd:02 272114704                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_hashlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84880000-ffff848b0000 r--p 00220000 fd:02 272114704                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_hashlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff848b0000-ffff848c0000 rw-p 00250000 fd:02 272114704                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_hashlib.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff848c0000-ffff84980000 rw-p 00000000 00:00 0\r\n18:51:45     ffff84990000-ffff849a0000 r-xp 00000000 fd:02 272114749                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/termios.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff849a0000-ffff849b0000 r--p 00000000 fd:02 272114749                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/termios.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff849b0000-ffff849c0000 rw-p 00010000 fd:02 272114749                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/termios.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff849c0000-ffff84a80000 rw-p 00000000 00:00 0\r\n18:51:45     ffff84a90000-ffff84aa0000 r-xp 00000000 fd:02 272114716                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_random.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84aa0000-ffff84ab0000 r--p 00000000 fd:02 272114716                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_random.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84ab0000-ffff84ac0000 rw-p 00010000 fd:02 272114716                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_random.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84ac0000-ffff84ad0000 r-xp 00000000 fd:02 272114681                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bisect.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84ad0000-ffff84ae0000 r--p 00000000 fd:02 272114681                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bisect.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84ae0000-ffff84af0000 rw-p 00010000 fd:02 272114681                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_bisect.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84af0000-ffff84b00000 r-xp 00000000 fd:02 272114719                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_sha3.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b00000-ffff84b10000 r--p 00000000 fd:02 272114719                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_sha3.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b10000-ffff84b20000 rw-p 00010000 fd:02 272114719                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_sha3.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b20000-ffff84b30000 r-xp 00000000 fd:02 272114682                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_blake2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b30000-ffff84b40000 r--p 00000000 fd:02 272114682                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_blake2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b40000-ffff84b50000 rw-p 00010000 fd:02 272114682                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_blake2.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b50000-ffff84b60000 r-xp 00000000 fd:02 272114738                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/math.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b60000-ffff84b70000 r--p 00000000 fd:02 272114738                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/math.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b70000-ffff84b80000 rw-p 00010000 fd:02 272114738                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/math.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff84b80000-ffff84c40000 rw-p 00000000 00:00 0\r\n18:51:45     ffff84c40000-ffff86650000 r-xp 00000000 fd:02 277818305                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_framework.so.2.9.0\r\n18:51:45     ffff86650000-ffff86660000 ---p 01a10000 fd:02 277818305                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_framework.so.2.9.0\r\n18:51:45     ffff86660000-ffff86710000 r--p 01a10000 fd:02 277818305                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_framework.so.2.9.0\r\n18:51:45     ffff86710000-ffff86720000 rw-p 01ac0000 fd:02 277818305                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_framework.so.2.9.0\r\n18:51:45     ffff86720000-ffff86740000 rw-p 00000000 00:00 0\r\n18:51:45     ffff86740000-ffff959d0000 r-xp 00000000 fd:02 409165075                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so\r\n18:51:45     ffff959d0000-ffff95f80000 r--p 0f280000 fd:02 409165075                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so\r\n18:51:45     ffff95f80000-ffff95fc0000 rw-p 0f830000 fd:02 409165075                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so\r\n18:51:45     ffff95fc0000-ffff96040000 rw-p 00000000 00:00 0\r\n18:51:45     ffff96040000-ffff96060000 r-xp 00000000 fd:02 270259739                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n18:51:45     ffff96060000-ffff96070000 r--p 00010000 fd:02 270259739                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n18:51:45     ffff96070000-ffff96080000 rw-p 00020000 fd:02 270259739                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n18:51:45     ffff96080000-ffff96090000 r-xp 00000000 fd:02 405191957                  /usr/lib64/librt-2.17.so\r\n18:51:45     ffff96090000-ffff960a0000 r--p 00000000 fd:02 405191957                  /usr/lib64/librt-2.17.so\r\n18:51:45     ffff960a0000-ffff960b0000 rw-p 00010000 fd:02 405191957                  /usr/lib64/librt-2.17.so\r\n18:51:45     ffff960c0000-ffff96280000 r-xp 00000000 fd:02 282369312                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/platform/_cpu_feature_guard.so\r\n18:51:45     ffff96280000-ffff96290000 ---p 001c0000 fd:02 282369312                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/platform/_cpu_feature_guard.so\r\n18:51:45     ffff96290000-ffff962a0000 r--p 001c0000 fd:02 282369312                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/platform/_cpu_feature_guard.so\r\n18:51:45     ffff962a0000-ffff962b0000 rw-p 001d0000 fd:02 282369312                  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/platform/_cpu_feature_guard.so\r\n18:51:45     ffff962b0000-ffff962f0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff962f0000-ffff96300000 r-xp 00000000 fd:02 272114724                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_struct.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96300000-ffff96310000 r--p 00000000 fd:02 272114724                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_struct.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96310000-ffff96320000 rw-p 00010000 fd:02 272114724                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_struct.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96320000-ffff96330000 r-xp 00000000 fd:02 270259730                  /usr/lib64/libffi.so.6.0.1\r\n18:51:45     ffff96330000-ffff96340000 r--p 00000000 fd:02 270259730                  /usr/lib64/libffi.so.6.0.1\r\n18:51:45     ffff96340000-ffff96350000 rw-p 00010000 fd:02 270259730                  /usr/lib64/libffi.so.6.0.1\r\n18:51:45     ffff96350000-ffff96370000 r-xp 00000000 fd:02 272114695                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_ctypes.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96370000-ffff96380000 r--p 00010000 fd:02 272114695                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_ctypes.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96380000-ffff96390000 rw-p 00020000 fd:02 272114695                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_ctypes.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96390000-ffff964e0000 rw-p 00000000 00:00 0\r\n18:51:45     ffff964e0000-ffff964f0000 r-xp 00000000 fd:02 405191895                  /usr/lib64/libnss_files-2.17.so\r\n18:51:45     ffff964f0000-ffff96500000 r--p 00000000 fd:02 405191895                  /usr/lib64/libnss_files-2.17.so\r\n18:51:45     ffff96500000-ffff96510000 rw-p 00010000 fd:02 405191895                  /usr/lib64/libnss_files-2.17.so\r\n18:51:45     ffff96510000-ffff96520000 r-xp 00000000 fd:02 272114705                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_heapq.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96520000-ffff96530000 r--p 00000000 fd:02 272114705                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_heapq.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96530000-ffff96540000 rw-p 00010000 fd:02 272114705                  /opt/_internal/cpython-3.7.12/lib/python3.7/lib-dynload/_heapq.cpython-37m-aarch64-linux-gnu.so\r\n18:51:45     ffff96540000-ffff96740000 rw-p 00000000 00:00 0\r\n18:51:45     ffff96740000-ffff968d0000 r--p 00000000 fd:02 137409502                  /usr/lib/locale/locale-archive\r\n18:51:45     ffff968d0000-ffff96a40000 r-xp 00000000 fd:02 405191738                  /usr/lib64/libc-2.17.so\r\n18:51:45     ffff96a40000-ffff96a50000 r--p 00160000 fd:02 405191738                  /usr/lib64/libc-2.17.so\r\n18:51:45     ffff96a50000-ffff96a60000 rw-p 00170000 fd:02 405191738                  /usr/lib64/libc-2.17.so\r\n18:51:45     ffff96a60000-ffff96b00000 r-xp 00000000 fd:02 405191856                  /usr/lib64/libm-2.17.so\r\n18:51:45     ffff96b00000-ffff96b10000 r--p 00090000 fd:02 405191856                  /usr/lib64/libm-2.17.so\r\n18:51:45     ffff96b10000-ffff96b20000 rw-p 000a0000 fd:02 405191856                  /usr/lib64/libm-2.17.so\r\n18:51:45     ffff96b20000-ffff96b30000 r-xp 00000000 fd:02 405191997                  /usr/lib64/libutil-2.17.so\r\n18:51:45     ffff96b30000-ffff96b40000 r--p 00000000 fd:02 405191997                  /usr/lib64/libutil-2.17.so\r\n18:51:45     ffff96b40000-ffff96b50000 rw-p 00010000 fd:02 405191997                  /usr/lib64/libutil-2.17.so\r\n18:51:45     ffff96b50000-ffff96b60000 r-xp 00000000 fd:02 405191759                  /usr/lib64/libdl-2.17.so\r\n18:51:45     ffff96b60000-ffff96b70000 r--p 00000000 fd:02 405191759                  /usr/lib64/libdl-2.17.so\r\n18:51:45     ffff96b70000-ffff96b80000 rw-p 00010000 fd:02 405191759                  /usr/lib64/libdl-2.17.so\r\n18:51:45     ffff96b80000-ffff96ba0000 r-xp 00000000 fd:02 405191936                  /usr/lib64/libpthread-2.17.so\r\n18:51:45     ffff96ba0000-ffff96bb0000 r--p 00010000 fd:02 405191936                  /usr/lib64/libpthread-2.17.so\r\n18:51:45     ffff96bb0000-ffff96bc0000 rw-p 00020000 fd:02 405191936                  /usr/lib64/libpthread-2.17.so\r\n18:51:45     ffff96bc0000-ffff96bf0000 r-xp 00000000 fd:02 134274849                  /usr/local/lib/libcrypt.so.2\r\n18:51:45     ffff96bf0000-ffff96c00000 r--p 00020000 fd:02 134274849                  /usr/local/lib/libcrypt.so.2\r\n18:51:45     ffff96c00000-ffff96c10000 rw-p 00000000 00:00 0\r\n18:51:45     ffff96c10000-ffff96c20000 rwxp 00000000 00:00 0\r\n18:51:45     ffff96c20000-ffff96c40000 r--p 00000000 00:00 0                          [vvar]\r\n18:51:45     ffff96c40000-ffff96c50000 r-xp 00000000 00:00 0                          [vdso]\r\n18:51:45     ffff96c50000-ffff96c70000 r-xp 00000000 fd:02 405191638                  /usr/lib64/ld-2.17.so\r\n18:51:45     ffff96c70000-ffff96c80000 r--p 00010000 fd:02 405191638                  /usr/lib64/ld-2.17.so\r\n18:51:45     ffff96c80000-ffff96c90000 rw-p 00020000 fd:02 405191638                  /usr/lib64/ld-2.17.so\r\n18:51:45     ffffc78e0000-ffffc7910000 rw-p 00000000 00:00 0                          [stack]\r\n18:51:45     /bin/bash: line 1: 51393 Aborted \r\n", "comments": ["@hrw @cfRod @nSircombe ", "I have same bug while building in manylinux2014 aarch64 container.", "I'm able to build with Bazel 4.2.2 and Python 3.8 - is this failure restricted to 3.7?\r\n", "@elfringham \r\nCould you please try with python 3.8 and let us know if this is still an issue.", "@Saduf2019 it looks like it is only a problem inside the manylinux2014 docker image but it does fail on Python 3.8 in that environment.", "I used 'git bisect' to try and isolate the issue. This was not straight forward due to two things. First there is a range of commits that will not build in the period of interest which may be affecting the result. Secondly the signature of the problem changes at some point from 'free of invalid pointer and abort' to segfault.\r\nThe result of the bisect was https://github.com/tensorflow/tensorflow/commit/367cf9968c3d14d9d41d1775d8ceeb8e7bf3190f which introduces cpu_feature_guard. However if I remove the call to that .so from the latest git HEAD, the build still fails.", "I used git bisect to isolate the point where the signature of the failure changed from segfault to abort. The result was this commit about protobuf\r\nhttps://github.com/tensorflow/tensorflow/commit/7fbc5be3b5a3cc17c05f1ae5b0577fdca8a0e0e2", "If I go back to https://github.com/tensorflow/tensorflow/commit/367cf9968c3d14d9d41d1775d8ceeb8e7bf3190f where the segfault first appeared and cherry pick https://github.com/tensorflow/tensorflow/commit/7fbc5be3b5a3cc17c05f1ae5b0577fdca8a0e0e2 then the segfault turns into the abort.", "If I go back to https://github.com/tensorflow/tensorflow/commit/098fc5e8c58ed0582cd0121839cddbff0a1c89d5 which is the commit before https://github.com/tensorflow/tensorflow/commit/367cf9968c3d14d9d41d1775d8ceeb8e7bf3190f the build works. But if I then cherry pick https://github.com/tensorflow/tensorflow/commit/7fbc5be3b5a3cc17c05f1ae5b0577fdca8a0e0e2 it results in the abort. So I think this shows that protobuf is definitely implicated in the abort.", "Moving now to git HEAD, if I revert the change from https://github.com/tensorflow/tensorflow/commit/7fbc5be3b5a3cc17c05f1ae5b0577fdca8a0e0e2 the failure changes from abort to segfault.\r\nFurthermore if I remove the call to _cpu_feature_guard.so from tensorflow/python/platform/self_check.py which effectively undoes the change from https://github.com/tensorflow/tensorflow/commit/367cf9968c3d14d9d41d1775d8ceeb8e7bf3190f then the build completes successfully. So the segfault and the abort are two separate issues and both need to be addressed.", "If I understand correctly, if you revert these two old commits you can build on the latest version of master and not encounter any issues?", "Pretty much yes, but not quite so simple as that. There are later commits that build on the use of _cpu_feature_guard.so so simply reverting https://github.com/tensorflow/tensorflow/commit/367cf9968c3d14d9d41d1775d8ceeb8e7bf3190f is not possible which is why I just removed the call from self_check.py. Also https://github.com/tensorflow/tensorflow/commit/7fbc5be3b5a3cc17c05f1ae5b0577fdca8a0e0e2 looks to be a bug fix and probably should not be reverted.\r\nRunning the failure through pdb in both cases the failure happens on this line of python\r\n`from tensorflow.python.tools.api.generator import doc_srcs`\r\nin tensorflow/python/__init__.py\r\nAlso latest version of master is broken in an additional way since this morning. https://github.com/tensorflow/tensorflow/issues/54273", "Tagged the author of the XNNPACK dep on that PR.\r\n\r\nWill try to get some help on this issue too.", "This seems to have been caused by the use of BAZEL_LINKLIBS to add '-l%:stdc++' to the build. This was introduced in our initial CI scripts and has since just been carried forward. I am not sure of the initial need for this usage but it is not needed now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53632\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53632\">No</a>\n"]}, {"number": 53631, "title": "Request for grouped convolutions on CPU", "body": "**System information**\r\n- TensorFlow version (you are using): 2.7\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nGrouped convolutions are not currently supported on CPUs in graph mode. We get the following error when we try to do the same:\r\n```\r\nUnimplementedError:  Fused conv implementation does not support grouped convolutions for now.\r\n\t [[node sequential_2/sequential/conv2d/BiasAdd\r\n (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py:265)\r\n]] [Op:__inference_predict_function_1730]\r\n```\r\nTill date, there have been numerous issues on TF's GitHub repo regarding this. Owing to that, I am requesting the team to look into this.\r\n\r\n**Will this change the current api? How?**\r\n`model.predict()` with a model having grouped convolutions will not result in an error on a CPU.\r\n\r\n**Who will benefit with this feature?**\r\nMany architectures today use grouped convolutions as they are known to be more efficient while maintaining the accuracy. Thus, I believe many TF developers will benefit from this addition. \r\n", "comments": ["Hi @AdityaKane2001 ! \r\nCould you please post this feature request on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thank you!", "@mohantym\r\n\r\nI believe this is a core TF issue and not a Keras one. This is because the aforementioned error is thrown in [tensorflow/core/kernels/conv_ops_fused_impl.h](https://github.com/tensorflow/tensorflow/blob/25d9dd7b1194de41a63e9ddaa68445e64b7f802a/tensorflow/core/kernels/conv_ops_fused_impl.h#L216-L218). As the error says the core library has not implemented this yet, and hence I have raised this issue here itself.\r\n", "Hi @Saduf2019 ! Could you please look at this feature request?", "@AdityaKane2001 \r\nPlease feel free to raise a PR for the same.", "@Saduf2019 \r\n\r\nNot really my piece of cake \ud83d\ude05 That's the reason I opened an issue and not a PR directly.", "@jvishnuvardhan \r\n\r\nCould you please take a look at this one? TIA"]}, {"number": 53630, "title": "Remove meta support for aarch64.", "body": "This patch removes meta support for aarch64 as it's currently no longer maintained and tests `quantized_op_test` and `quantize_bias_add_op_test` fail when it is enabled.", "comments": []}]