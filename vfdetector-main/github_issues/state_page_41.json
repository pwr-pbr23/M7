[{"number": 46062, "title": "Modularize and consolidate the Docker images for downstream usage", "body": "**System information**\r\n- TensorFlow version (you are using): 2.4.0+\r\n- Are you willing to contribute it (Yes/No): I can help, but it needs ownership from TF Dev-Infra team.\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently there are 3 or 4 Dockerfiles which are maintained independently and with different levels of support. This has been a time sink for the TF team, and a headache for downstream consumers. It should be (relatively) easy to refactor these as docker targets that build from one another. Information below is for  GPU containers (though it applies to CPU and TF versions as well):\r\n\r\n*  DockerHub tensorflow/tensorflow:gpu\r\n    * https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/gpu.Dockerfile\r\n    * Builds from nvidia/cuda  \r\n    * Installs TF pip package to base python3\r\n*  DockerHub tensorflow/tensorflow:devel-gpu\r\n    * https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile\r\n    * Builds from nvidia/cuda \r\n    * Installs build tools and bazel\r\n    * Clones TF source code; \r\n    * Installs python deps to base python3\r\n *  DockerHub tensorflow/tensorflow:custom_op_gpu\r\n    * https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.custom_op_ubuntu_16_cuda10.1\r\n    * Builds from nvidia/cuda \r\n    * Installs build tools and bazel\r\n    * Installs devtoolset7 and devtoolset8 for manylinux2010 builds\r\n    * Explicitly installs select python versions\r\n    * Installs python deps to base python3\r\n *  GCR tensorflow-testing/nosla-cuda11.0-cudnn8-ubuntu18.04-manylinux2010-multipython\r\n    * https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.rbe.cuda11.0-cudnn8-ubuntu18.04-manylinux2010-multipython\r\n    * Builds from nvidia/cuda \r\n    * Installs build tools and bazel\r\n    * Installs devtoolset7 and devtoolset8 for manylinux2010 builds\r\n    * A nice modular installation of all support python versions\r\n    * Installs python deps to all python installations\r\n    * **This is currently used by SIG Addons and SIG IO -- though there is no SLA for these images**\r\n\r\nAs you can see there is a ton of duplication, not reusing of modular scripts when they can be, and with these 4 options there is still a ton of bloat in the images that should be refactored.\r\n\r\n**Will this change the current api? How?**\r\nWe should use Docker targets to progressively build the containers and publish their intermediate stages. There would be no need to modify tags or anything. Prototype:\r\n\r\n```\r\nFROM nvidia/cuda${ARCH:+-$ARCH}:${CUDA}-base-ubuntu${UBUNTU_VERSION} as base\r\nRUN apt-get update && apt-get install -y --no-install-recommends \\\r\n        build-essential \\\r\n        cuda-command-line-tools-${CUDA/./-} \\\r\n        libcublas-${CUDA/./-} \\\r\n        ....\r\n\r\nRUN ln -s $(which python3) /usr/local/bin/python\r\n\r\nCOPY install/build_and_install_python.sh /install/\r\nRUN /install/build_and_install_python.sh \"3.6.9\"\r\nRUN /install/build_and_install_python.sh \"3.7.7\"\r\nRUN /install/build_and_install_python.sh \"3.8.2\"\r\n\r\n# Install bazel\r\nARG BAZEL_VERSION=3.7.2\r\nRUN mkdir /bazel && \\\r\n    wget -O /bazel/installer.sh \"https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\" && \\\r\n    wget -O /bazel/LICENSE.txt \"https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE\" && \\\r\n    chmod +x /bazel/installer.sh && \\\r\n    /bazel/installer.sh && \\\r\n    rm -f /bazel/installer.sh\r\n\r\n# -------------------------------------------------------------------\r\nFROM base as tensorflow_gpu\r\nRUN python3 -m pip install --no-cache-dir ${TF_PACKAGE}${TF_PACKAGE_VERSION:+==${TF_PACKAGE_VERSION}}\r\n\r\n# -------------------------------------------------------------------\r\nFROM base as tensorflow_devel_gpu\r\n\r\nRUN apt-get update && apt-get install -y \\\r\n    openjdk-8-jdk \\\r\n    ....\r\n\r\nRUN python3 -m pip --no-cache-dir install \\\r\n    Pillow \\\r\n    h5py \\\r\n    keras_preprocessing \\\r\n    matplotlib \\\r\n    mock \\\r\n    'numpy<1.19.0' \\\r\n    scipy \\\r\n    sklearn \\\r\n    pandas \\\r\n    future \\\r\n    portpicker \\\r\n    enum34\r\n\r\n# -------------------------------------------------------------------\r\nFROM base as tensorflow_custom_op_gpu\r\nADD devtoolset/fixlinks.sh fixlinks.sh\r\nADD devtoolset/build_devtoolset.sh build_devtoolset.sh\r\nADD devtoolset/rpm-patch.sh rpm-patch.sh\r\n\r\n# Set up a sysroot for glibc 2.12 / libstdc++ 4.4 / devtoolset-7 in /dt7.\r\nRUN /build_devtoolset.sh devtoolset-7 /dt7\r\n# Set up a sysroot for glibc 2.12 / libstdc++ 4.4 / devtoolset-8 in /dt8.\r\nRUN /build_devtoolset.sh devtoolset-8 /dt8\r\n\r\nFROM nvidia/cuda:11.0-cudnn8-devel-ubuntu18.04\r\nCOPY --from=devtoolset /dt7 /dt7\r\nCOPY --from=devtoolset /dt8 /dt8\r\n\r\nRUN /install/install_bootstrap_deb_packages.sh\r\nRUN /install/install_deb_packages.sh\r\nRUN /install/install_clang.sh\r\nRUN /install/install_bazel.sh\r\nRUN /install/install_buildifier.sh\r\nRUN /install/install_pip_packages.sh\r\nRUN /install/install_auditwheel.sh\r\n\r\nENV TF_NEED_CUDA=1\r\n\r\n# -------------------------------------------------------------------\r\nFROM tensorflow_custom_op_gpu as tensorflow_build_manylinux2010_multipython\r\n\r\nCOPY install/install_pip_packages_by_version.sh /install/\r\nRUN /install/install_pip_packages_by_version.sh \"/usr/local/bin/pip2.7\"\r\nRUN /install/install_pip_packages_by_version.sh \"/usr/local/bin/pip3.8\"\r\nRUN /install/install_pip_packages_by_version.sh \"/usr/local/bin/pip3.5\"\r\nRUN /install/install_pip_packages_by_version.sh \"/usr/local/bin/pip3.6\"\r\nRUN /install/install_pip_packages_by_version.sh \"/usr/local/bin/pip3.7\"\r\n\r\n# -------------------------------------------------------------------\r\n\r\n```\r\n\r\n**Who will benefit with this feature?**\r\nSIGs, developers, and downstream libraries looking for well managed Docker containers to build from. \r\n\r\nExample benefits:\r\n* Currently the custom_op container has a lot of installations that are not needed see #38352\r\n* Currently the custom_op container gets updated when time permits, this would make it update alongside the rest of the containers\r\n* Currently the manylinux2010_multipython is the most comprehensive build container, but it has no SLA and is also unnecessarily bulky (can remove all the pip package installations for every py version)\r\n* Single Dockerfile to maintain (can have owners for seperate pieces etc.)\r\n\r\n**Any Other info.**\r\nWith this being refactored properly we could close #38352, https://github.com/tensorflow/addons/issues/2326 and https://github.com/tensorflow/build/issues/6\r\n", "comments": ["Tagging some stakeholders to see if we're able to get traction on this issue. I know some team members have left Dev-Infra, but this would be a great way to consolidate work and save time down the line.\r\n\r\ncc \r\nTF team -  @av8ramit @angerson\r\nSIG Build - @perfinion \r\nSIG Addons - @bhack @WindQAQ \r\nSIG IO  - @yongtang \r\n\r\n", "Dockerfile analisys and refactoring was discussed recently in many SIG build meetings also for the cache issue at https://github.com/tensorflow/build/issues/5.\nBut I think that @angerson is no more allocated on this activity.", "First, thanks a lot for writing this up as a clean issue with clear goals. It's a big help for our prioritization and planning.\r\n\r\nDocker has been challenging for us internally because of the maintenance costs and related confusion. A consolidation would be awesome:\r\n\r\n- Save engineering time maintaining the images\r\n- Help other internal teams that use TF's docker images for their own tests\r\n- Give us an opportunity to use containerization in our own tests\r\n- Let us build internally with the same environments as we offer externally\r\n\r\nI don't think we'll be able to prioritize a dedicated project for this because of our team's current constraints (DevInfra is only a few people now, and internal maintenance is prioritized). I'd like to make better Docker support a goal beyond just our team, though, and I have some internal OKRs that would actually benefit a lot from Docker improvements. So what I think I can do for now is work on Docker while doing that, and use the results to encourage prioritization at a higher level than just me.\r\n\r\nOn to implementation: I like your suggested Dockerfile layout. I regret my decision years ago to create a complex assembler for our Dockerfiles and would like to deprecate it for something more normal, like this. I also want to move the Dockerfiles and scripts out of tensorflow/tensorflow because dealing with branches is very annoying; an officially-supported project in SIG Build should work nicely. I'll work on testing out your prototype there.\r\n", "How many Dockerfiles we have in the tree? 67? \n\nhttps://github.com/tensorflow/tensorflow/search?l=Dockerfile&q=rights&type=", "`find  tensorflow/* -iname \"*.Dockerfile\"  | wc -l` currently we have 107 Dockerfiles (including partial)", "Having 107 Dockerfiles create also an overhead when you need to create a PR for update just a python library.", "Also, I think some of the python installations such as 2.7, 3.5 (with heavy customization etc) may not be necessary any more, as 2.7 and 3.5 are deprecated. Some of the customizations in the script may also come from the original Ubuntu 14.04 base where packages were missing. It may be possible to clean up a little now as we moves to Ubuntu 18.04+.", "> This is currently used by SIG Addons and SIG IO -- though there is no SLA for these images\r\n\r\nJust to be clear: what, beyond an environment that is ideal for building TensorFlow, is required for your use case? I've been operating under the assumption that the custom-op container is somehow unique, but I've never known what about it is helpful. Would the multipython image completely deprecate custom-op if we supported it?", "For Addons/IO, one challenges is that the custom kernel ops are based on C++ API which may have subtle differences depending on the compiler and c runtime inside the OS. As a result if the gcc version and C runtime is different from tensorflow's gcc version and c runtime, the kernel ops may see incompatibility (sometimes strange seg fault, etc).\r\n\r\nThis is the biggest challenge as tensorflow uses a gcc version from devtoolset and relies on a Ubuntu 16.04 c/c++ runtime. (devtoolset is not natively built with ubuntu so any mismatch could accompanied with surprises for custom ops). In the end we realized that it is just much easier to built the kernel ops on Addons/IO with the same devtoolset/ubuntu environment.", "Cc: @sub-mod @fatherlinux dont we build TF images based on RHEL/UBI ?", "@seanpmorgan @angerson Is there an interest for centos Images ? PyPI is using centos and we can contribute those images.\r\n", "We have centos for Onednn third_party builds https://github.com/tensorflow/tensorflow/search?l=Dockerfile&q=centos", "Thanks @bhack .\r\nLast time i checked multistaged dicker builds don't work on RHEL. The docker client is different on RHEL and mac.", "@seanpmorgan \r\n> Currently the manylinux2010_multipython is the most comprehensive build container, but it has no SLA and is also unnecessarily bulky (can remove all the pip package installations for every py version)\r\n\r\nI thought having all the pip packages installed in each version was a benefit. Is that incorrect?", "@angerson The manylinux2010 is mostly needed for building `.so` files, so just having one python version will be enough. \r\n\r\nThe packing of pip can be done easily with any thin python container. For example, in IO we use manylinux2010 container to build the `.so` file, then on second step, we use `python:3.6-slim`( and `python:3.7-slim` and `python:3.8-slim`) to built the pip wheels.", "Ah, I see, thank you. But it's still useful to have all of the python versions available, right?", "> Ah, I see, thank you. But it's still useful to have all of the python versions available, right?\n\nWhat Is the size overhead for the Dev images?", "Pretty big. <del>I think Nvidia's devel containers are ~3GB and the nosla ones are ~13GB.</del> See below. It will be difficult to make an everything-included image that's small.\r\n\r\nimage | tag | size                                                                                                                                                                                                  \r\n:-:|:-:|:-:|                                                                                                                                                                                                        \r\ngcr.io/tensorflow-testing/nosla-cuda11.0-cudnn8-ubuntu18.04-manylinux2010-multipython  |latest                           |  13.9GB                                                                                  \r\nnvidia/cuda                                                                            |11.0-base-ubuntu18.04           |  110MB                                                                                    \r\nnvidia/cuda                                                                            |11.0-cudnn8-devel-ubuntu18.04    | 7.41GB                                                                                   \r\nnvidia/cuda                                                                            |11.0-cudnn8-runtime-ubuntu18.04  | 3.6GB  ", "<del>Comparatively, the current official images are pretty small. `devel-gpu` is 3.22GB and `nightly-gpu` is 2.36GB. The non-GPU ones are much smaller.</del>\r\n\r\nDarn. Actually, devel-gpu is 7GB. Docker Hub only reports the compressed size.", "Custom ops images are not published anymore. \r\nWe have temp switched to `cr.io/tensorflow-testing/nosla-cuda11.2-cudnn8.1-ubuntu18.04-manylinux2010-multipython ` with https://github.com/tensorflow/addons/pull/2598 but we don't have a CPU image anymore.\r\n\r\nWe are also trying to use  the new image at https://github.com/tensorflow/addons/pull/2515 but also there we don't have a CPU image anymore.\r\n\r\nWe have a new ticket for disk space issue on small cloud instances with these large GPU image at https://github.com/tensorflow/addons/issues/2613\r\n\r\n", "@angerson perhaps we can bring this issue up in SIG Build, but with the new nightly Docker images would it make sense to support options for CUDA vs other GPUs as well as a CPU-only image?"]}, {"number": 46061, "title": "Error during converting the OpenNMT-tf model to TensorFlow Lite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source): 2.4.0 (have tested on tf-nightly as well)\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nhttps://colab.research.google.com/gist/sayakpaul/b3a06119884e0b0bf9cb7f509e4b341e/scratchpad.ipynb\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nException: <unknown>:0: error: loc(\"transformer_base_1/while@__inference__run_14521\"): 'tf.While' op body result type tensor<?x8x1x64xf32> is incompatible with result type tensor<?x8x0x64xf32> at index 6\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    214       return model_str\r\n    215     except Exception as e:\r\n--> 216       raise ConverterError(str(e))\r\n    217 \r\n    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: <unknown>:0: error: loc(\"transformer_base_1/while@__inference__run_14521\"): 'tf.While' op body result type tensor<?x8x1x64xf32> is incompatible with result type tensor<?x8x0x64xf32> at index 6\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://s3.amazonaws.com/opennmt-models/averaged-ende-export500k-v2.tar.gz\r\n```\r\n\r\n[OpenNMT](https://opennmt.net/) is a pretty well-known open-source project in the area of Neural Machine Translation. It's used across industries and many academic institutions. \r\n\r\nI was trying to convert their latest SavedModel to TensorFlow Lite but currently, it's failing. From the initial error logs, it looks like it's because of the pesky `tf.While` op.  When I switched to `tf-nightly` it gets changed to the following - \r\n\r\n```\r\nConverterError: <unknown>:0: error: loc(callsite(callsite(\"transformer_base_1/TensorArrayV2@__inference__run_14521\" at \"StatefulPartitionedCall@__inference_signature_wrapper_15063\") at \"StatefulPartitionedCall_4\")): requires element_shape to be 1D tensor during TF Lite transformation pass\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall_4\"): called from\r\n<unknown>:0: error: loc(callsite(callsite(\"transformer_base_1/TensorArrayV2@__inference__run_14521\" at \"StatefulPartitionedCall@__inference_signature_wrapper_15063\") at \"StatefulPartitionedCall_4\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall_4\"): called from\r\n```\r\n\r\nI have tried with the flex ops too but that does not help. I was wondering if the TensorFlow Lite team could look into this and share some suggestions to fix this much like https://github.com/TensorSpeech/TensorflowTTS/pull/84. \r\n\r\nPlease note that OpenNMT folks have tried to convert TensorFlow Lite before but they have been unsuccessful so far as per  https://github.com/OpenNMT/OpenNMT-tf/issues/490. \r\n\r\nCc: @abattery ", "comments": ["The conversion failure from the nightly version happened at the TensorList transformation. @haozha111 could you take a look at this?", "> The conversion failure from the nightly version happened at the TensorList transformation. @haozha111 could you take a look at this?\r\n\r\nyes, i can repro the same error with tf-nightly. Taking a look and will post anything i found here. Thanks!", "I took a look at your model, and I think the reason for tensorlist to fail to convert is that, it lacks an element_shape when the model construct the TensorArray. Could you check where in the code the model calls 'tf.TensorArray' and try to pass a element_shape there?", "Thanks for looking into it @haozha111. I don't think passing in an `element_shape` would be possible for this pre-trained model. "]}, {"number": 46052, "title": "Ability to parse non-Example protos without Eager Execution", "body": "**System information**\r\n- TensorFlow version 2.4.0:\r\n- Are you willing to contribute it (No):\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am trying to use the Waymo open dataset in tensorflow, without using eager execution. The data is not formatted as tf.data.examples, but instead as a custom proto that is serialized. The eager-compatible approach is something like this: `example.ParseFromString(raw_record.numpy())`, which relies on the numpy compatibility of eager tensors. I thought this issue could be solved by the introduction of tf.experimental.numpy, but it does not seem to support iterating like normal numpy arrays. Are there any plans to add iteration support to tensorflow numpy, or support for deserializing protos other than tf.Examples?\r\n \r\n**Will this change the current api? How?**\r\nIf the iteration approach is taken, it will not change the api as iteration methods currently exist but throw errors when called. Other approaches may involve additions to the API for proto desierialization.\r\n\r\n**Who will benefit with this feature?**\r\nUsers of the Waymo Open Dataset will benefit, as well as anyone else who would like to format their data as custom protos. Tf.example format can be difficult for structured or hierarchical data.", "comments": []}, {"number": 46035, "title": "map_fn can't generate ragged tensor on arbitrary dimension", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20.04 lts\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nmap_fn can't generate ragged tensor on arbitrary dimension.\r\n\r\n**Describe the expected behavior**\r\n\r\nmap_fn should generate ragged tensor on arbitrary dimension.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\n#!/usr/bin/python3\r\n\r\nimport tensorflow as tf;\r\n\r\nelems = tf.constant([3, 5, 0, 2]);\r\na=tf.map_fn(lambda x: tf.zeros((x)), elems, fn_output_signature = tf.RaggedTensorSpec(shape = (None), dtype = tf.float32, ragged_rank = 0));\r\nprint(a);\r\n# error occurs below\r\nb=tf.map_fn(lambda x: tf.zeros((4,x)), elems, fn_output_signature = tf.RaggedTensorSpec(shape = (4, None), dtype = tf.float32, ragged_rank = 1));\r\nprint(b);\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["i am able to reproduce this issue on[ tf 2.4 ](https://colab.research.google.com/gist/Saduf2019/b72d1339d4186a2387541c5680a8bc94/untitled489.ipynb)and nightly, please find the [gist here.](https://colab.research.google.com/gist/Saduf2019/c0a4fb375a6cc43ac46bb74f54da5fed/untitled488.ipynb)", "thx, this is the error i am talking about", "This is not ovbious, but when the function returns a dense Tensor (`tf.zeros((4, x))`), the `fn_output_signature` must have `ragged_rank=0`, even in the second case.\r\nSee https://www.tensorflow.org/api_docs/python/tf/map_fn#raggedtensors_2", "I tried the following code with tensorflow 2.4.1. the shape of b is not (4,4,None) but (4,4,3). is your solution available on nightly version?\r\n\r\n```python\r\n#!/usr/bin/python3\r\n\r\nimport tensorflow as tf;\r\n\r\nelems = tf.constant([3, 5, 0, 2]);\r\nb=tf.map_fn(lambda x: tf.zeros((4,x)), elems, fn_output_signature = tf.RaggedTensorSpec(shape = (4, None), dtype = tf.float32, ragged_rank = 0));\r\nprint(b);\r\n```", "Yes, and it looks like the result contains some nonzero values so it's definitely a bug.\r\n\r\n@edloper is there a workaround?", "Yes, agreed that this looks like a bug.  A work-around for now is to have the function you pass to `map_fn` convert its output to a ragged tensor before returning it (and update the RaggedTensorSpec accordingly).  I.e., in your example, change the line that defines `b` to:\r\n\r\n```\r\nb=tf.map_fn(lambda x: tf.RaggedTensor.from_tensor(tf.zeros((4,x))), elems, fn_output_signature = tf.RaggedTensorSpec(shape = (4, None), dtype = tf.float32, ragged_rank = 1))\r\n```\r\n\r\nI suspect that the bug is in the RaggedTensorFromVariant op -- I will look into it after the weekend.", "@edloper Should the workaround extend to higher rank outputs?  Consider rank=3 outputs:\r\n```python\r\nimport tensorflow as tf\r\n\r\nelems = tf.constant([3, 5, 0, 2])\r\nb = tf.map_fn(fn=lambda x: tf.RaggedTensor.from_tensor(tf.zeros((6, 7, x))),\r\n              elems=elems,\r\n              fn_output_signature=tf.RaggedTensorSpec(shape=(6, 7, None), ragged_rank=1))\r\nprint('nested_row_splits:')\r\nfor split in b.nested_row_splits:\r\n    print(split.numpy())\r\nprint('shape:', b.shape)\r\nprint('ragged_rank:', b.ragged_rank)\r\nprint('b:', b)\r\n```\r\nwhich in TF 2.5.0 and TF 2.6.0-dev20210601 prints out:\r\n```\r\nnested_row_splits:\r\n[ 0  6 12 18 24]\r\n[  0   7  14  21  28  35  42  49  56  63  70  77  84  91  98 105 112 119\r\n 126 133 140 147 154 161 168]\r\nshape: (4, 6, 7, 3)\r\nragged_rank: 2\r\n```\r\nThe ragged last shape dimension shows 3, not None (the maximum last ragged dimension is 5).  Printing out the ragged tensor `b` (printout not pasted) has wrong shape - the last dimension is always 3 and does not vary according to `elems`.  Some elements of `b` are garbage floats.  Is the above attempt to extend to higher rank outputs incorrect, is this a bug? Cc. @jvishnuvardhan - Thanks", "@mmilosav In this example, you'd need to use `ragged_rank=2` in the `RaggedTensorSpec` when you call `tf.map_fn` (and in the call to `RaggedTensor.from_tensor`):\r\n\r\n```\r\nb = tf.map_fn(fn=lambda x: tf.RaggedTensor.from_tensor(tf.zeros((6, 7, x)), ragged_rank=2),\r\n              elems=elems,\r\n              fn_output_signature=tf.RaggedTensorSpec(shape=(6, 7, None), ragged_rank=2))\r\n``` \r\n\r\nIn the general case, if a shape has ragged dimensions in axes `[a1, a2, ..., aN]`, then `ragged_rank` should be set to `max(a1, a2, ..., aN)`.  In this case, `axis=2` is the (only) ragged axis, so `ragged_rank` needs to be `2`."]}, {"number": 46030, "title": "I need to pass a buffer in the tensorFlow library when the buffer is of the type byteArray", "body": "Please, help me. I trying to use the android demo (https://github.com/tensorflow/examples/tree/master/lite/examples/speech_commands/android) version with speech recognition and i need to pass a buffer in the tensorFlow library when the buffer is of the type byteArray. When sending the buffer of type byteArray, the model stops speech recognition. How to correctly pass the buffer in the tensorFlow library with byteArray type?\r\n\r\n```\r\nclass MainActivity : AppCompatActivity() {\r\n\r\n    companion object {\r\n\r\n        private const val TAG = \"MainActivity\"\r\n        private const val SAMPLE_RATE = 16_000\r\n        private const val BUFFER_SIZE_SECONDS = 0.3F\r\n        private const val DETECTION_THRESHOLD = 0.50F\r\n        private const val SUPPRESSION_MS = 1500\r\n        private const val MINIMUM_COUNT = 3\r\n        private const val MINIMUM_TIME_BETWEEN_SAMPLES_MS = 30L\r\n        private const val AVERAGE_WINDOW_DURATION_MS = 1_000L\r\n        private const val REQUEST_AUDIO_RECORD_PERMISSION = 200\r\n    }\r\n\r\n    private val labels = listOf(\"_silence_\", \"_unknown_\", \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\")\r\n    private val tfLiteOptions = Interpreter.Options()\r\n    private val recordingBufferLock = ReentrantLock()\r\n\r\n    private var recordingOffset = 0\r\n    private var shouldContinue = true\r\n    private var recordingThread: Thread? = null\r\n    private var shouldContinueRecognition = true\r\n    private var recognitionThread: Thread? = null\r\n    private var recordingBuffer = ByteArray(SAMPLE_RATE)\r\n\r\n    private lateinit var tfLite: Interpreter\r\n    private lateinit var tfLiteModel: MappedByteBuffer\r\n    private lateinit var recognizeCommands: RecognizeCommands\r\n\r\n    override fun onCreate(savedInstanceState: Bundle?) {\r\n        super.onCreate(savedInstanceState)\r\n        setContentView(R.layout.activity_main)\r\n\r\n        recognizeCommands = RecognizeCommands(\r\n            labels,\r\n            AVERAGE_WINDOW_DURATION_MS,\r\n            DETECTION_THRESHOLD,\r\n            SUPPRESSION_MS,\r\n            MINIMUM_COUNT,\r\n            MINIMUM_TIME_BETWEEN_SAMPLES_MS\r\n        )\r\n\r\n        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) == PermissionChecker.PERMISSION_GRANTED) {\r\n            initTfLite()\r\n        } else {\r\n            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), REQUEST_AUDIO_RECORD_PERMISSION)\r\n        }\r\n    }\r\n\r\n    private fun initTfLite() {\r\n        try {\r\n            tfLiteModel = loadModelFile()\r\n            tfLite = Interpreter(tfLiteModel, tfLiteOptions)\r\n\r\n            tfLite.resizeInput(0, intArrayOf(SAMPLE_RATE, 1))\r\n            tfLite.resizeInput(1, intArrayOf(1))\r\n\r\n            startRecording()\r\n            startRecognition()\r\n        } catch (exc: IOException) {\r\n            Log.e(TAG, \"Error: ${exc.message}\")\r\n        }\r\n    }\r\n\r\n    private fun startRecording() {\r\n        if (recordingThread == null) {\r\n            shouldContinue = true\r\n            recordingThread = Thread { record() }\r\n            recordingThread?.start()\r\n        }\r\n    }\r\n\r\n    private fun record() {\r\n        Process.setThreadPriority(Process.THREAD_PRIORITY_AUDIO)\r\n\r\n        val bufferSize = (SAMPLE_RATE.toFloat() * BUFFER_SIZE_SECONDS).roundToInt() * 2\r\n        val record = AudioRecord(\r\n            MediaRecorder.AudioSource.DEFAULT,\r\n            SAMPLE_RATE,\r\n            AudioFormat.CHANNEL_IN_MONO,\r\n            AudioFormat.ENCODING_PCM_16BIT,\r\n            bufferSize\r\n        )\r\n\r\n        if (record.state != AudioRecord.STATE_INITIALIZED) {\r\n            Log.e(TAG,\"Audio Record can't initialize!\")\r\n            return\r\n        }\r\n\r\n        record.startRecording()\r\n\r\n        while (shouldContinue) {\r\n            val audioBuffer = ByteArray(bufferSize)\r\n            val numberRead = record.read(audioBuffer, 0, audioBuffer.size)\r\n            val newRecordingOffset = recordingOffset + numberRead\r\n            val secondCopyLength = Math.max(0, newRecordingOffset - recordingBuffer.size)\r\n            val firstCopyLength = numberRead - secondCopyLength\r\n\r\n            recordingBufferLock.lock()\r\n            try {\r\n                System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, firstCopyLength)\r\n                System.arraycopy(audioBuffer, firstCopyLength, recordingBuffer, 0, secondCopyLength)\r\n                recordingOffset = newRecordingOffset % recordingBuffer.size\r\n            } finally {\r\n                recordingBufferLock.unlock()\r\n            }\r\n        }\r\n\r\n        record.stop()\r\n        record.release()\r\n    }\r\n\r\n    private fun startRecognition() {\r\n        if (recognitionThread == null) {\r\n            shouldContinueRecognition = true\r\n            recognitionThread = Thread { recognize() }\r\n            recognitionThread?.start()\r\n        }\r\n    }\r\n\r\n    private fun recognize() {\r\n        val inputBuffer = ByteArray(SAMPLE_RATE)\r\n        val floatInputBuffer = Array(SAMPLE_RATE) { FloatArray(1) }\r\n        val outputScores = Array(1) { FloatArray(labels.size) }\r\n        val sampleRateList = intArrayOf(SAMPLE_RATE)\r\n\r\n        while (shouldContinueRecognition) {\r\n            recordingBufferLock.lock()\r\n\r\n            try {\r\n                val maxLength = recordingBuffer.size\r\n                val firstCopyLength = maxLength - recordingOffset\r\n                val secondCopyLength = recordingOffset\r\n                System.arraycopy(recordingBuffer, recordingOffset, inputBuffer, 0, firstCopyLength)\r\n                System.arraycopy(recordingBuffer, 0, inputBuffer, firstCopyLength, secondCopyLength)\r\n            } finally {\r\n                recordingBufferLock.unlock()\r\n            }\r\n\r\n            for (i in 0 until SAMPLE_RATE) {\r\n                floatInputBuffer[i][0] = inputBuffer[i] / Byte.MAX_VALUE.toFloat()\r\n            }\r\n\r\n            val inputArray = arrayOf<Any>(floatInputBuffer, sampleRateList)\r\n            val outputMap: MutableMap<Int, Any> = HashMap()\r\n            outputMap[0] = outputScores\r\n\r\n            tfLite.runForMultipleInputsOutputs(inputArray, outputMap)\r\n\r\n            val result = recognizeCommands.processLatestResults(outputScores[0], System.currentTimeMillis())\r\n\r\n            if (!result.foundCommand.startsWith(\"_\") && result.isNewCommand) {\r\n                Log.d(TAG, \"Command: ${result.foundCommand} (${result.score})\")\r\n            }\r\n\r\n            try {\r\n                Thread.sleep(MINIMUM_TIME_BETWEEN_SAMPLES_MS)\r\n            } catch (exc: InterruptedException) {\r\n                Log.d(TAG, \"Error: ${exc.message}\")\r\n            }\r\n        }\r\n    }\r\n\r\n    @Throws(IOException::class)\r\n    private fun loadModelFile(): MappedByteBuffer {\r\n        val fileDescriptor = assets.openFd(\"conv_actions_frozen.tflite\")\r\n        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)\r\n        val fileChannel = inputStream.channel\r\n        val startOffset = fileDescriptor.startOffset\r\n        val declaredLength = fileDescriptor.declaredLength\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)\r\n    }\r\n\r\n    override fun onRequestPermissionsResult(\r\n        requestCode: Int,\r\n        permissions: Array<out String>,\r\n        grantResults: IntArray\r\n    ) {\r\n        super.onRequestPermissionsResult(requestCode, permissions, grantResults)\r\n        if (requestCode == REQUEST_AUDIO_RECORD_PERMISSION) {\r\n            initTfLite()\r\n        } else {\r\n            Toast.makeText(this, \"\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0435\", Toast.LENGTH_LONG).show()\r\n            finish()\r\n        }\r\n    }\r\n}\r\n```", "comments": ["Your logic to make input data looks strange to me.\r\nYou're using 16bit sampling for AudioRecord, but you treat it as 8 bit sampling data.\r\nThe original logic is using short[] to keep 16 bit data. You can keep the original logic or you can use 8bit sample for AudioRecord.\r\n\r\n>             for (i in 0 until SAMPLE_RATE) {\r\n>                floatInputBuffer[i][0] = inputBuffer[i] / Byte.MAX_VALUE.toFloat()\r\n>            }"]}, {"number": 46025, "title": "micro: port op DEPTH_TO_SPACE from lite", "body": "@tensorflow/micro\r\n\r\nThis issue tracks my work porting operator DEPTH_TO_SPACE from lite to micro. The port will be submitted in a number of PRs. Here's a rough flight plan:\r\n\r\nPR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver\r\nPR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences\r\nPR 3: Copy operator from lite to micro without making any changes or including in the build\r\nPR 4: Delete extra code from the micro copy of the operator\r\nPR 5: Port micro copy of operator as necessary and add a corresponding test", "comments": []}, {"number": 46007, "title": "Error on TPU V3-8 with XLA: RPC failed with status = \"Unavailable: Socket closed\"", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I am using the XLA example of RoBERTa Pytorch-XLA https://cloud.google.com/tpu/docs/tutorials/roberta-pytorch\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): debian-9-torch-xla-v20201225 (GCP image)\r\n- GCP Machine type: Custom 8vCPUs, 256GB memory\r\n- TensorFlow installed from (source or binary): Provided on GCP image\r\n- TensorFlow version (use command below): torch-xla-1.7\r\n- Python version: Python 3.6.10 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: TPU V3-8\r\n\r\n**Describe the current behavior**\r\n\r\nThe following error is happening after training with Pythorch-XLA  for some time: \r\n\r\n```\r\n2020-12-28 01:56:05.252085: W    1417 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.251970000\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n\r\n\r\n*** Begin stack trace ***\r\n        tensorflow::CurrentStackTrace()\r\n        xla::XrtComputationClient::ReleaseHandles(std::vector<xla::XrtComputationClient::DeviceHandle, std::allocator<xla::XrtComputationClient::DeviceHandle> >*, std::function<xla::XrtSession::CachedNode const& (xla::XrtSession*, tensorflow::Scope const&, std::string const&)> const&, xla::metrics::Metric*, xla::metrics::Counter*)\r\n        xla::XrtComputationClient::HandleReleaser()\r\n        xla::util::TriggeredTask::Runner()\r\n\r\n\r\n        clone\r\n*** End stack trace ***\r\n```\r\n\r\n\r\nI was following the steps described here: https://cloud.google.com/tpu/docs/tutorials/roberta-pytorch with the same network parameters, just a different dataset.  \r\nI encountered an error before, but it was happening due to OOM on the VM after restoring a checkpoint, which reason why I increased VM memory.\r\n\r\nIt seems that the TPU is getting pre-empted somehow, but I don't have access to the runtime log as this happened overnight and it got automatically deleted by TFRC.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe training should continue as expected.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://cloud.google.com/tpu/docs/tutorials/roberta-pytorch\r\n\r\nTraining data was around 40GB.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n| epoch 002 | training on xla:0/1:   4151 / 10099 loss=1.804, nll_loss=1.804, wps=17811, ups=0, wpb=117675.783, bsz=296.068, num_updates=14249, lr=0.000491148, gnorm=0.345, oom=0.000, wall=27948, train_wall=92610, now=01:54:20\r\n| epoch 002 | training on xla:0/7:   4151 / 10099 loss=1.805, nll_loss=1.805, wps=17811, ups=0, wpb=117678.381, bsz=296.074, num_updates=14249, lr=0.000491148, gnorm=0.345, oom=0.000, wall=27948, train_wall=92609, now=01:54:20\r\n| epoch 002 | training on xla:0/3:   4151 / 10099 loss=1.805, nll_loss=1.805, wps=17810, ups=0, wpb=117668.251, bsz=296.137, num_updates=14249, lr=0.000491148, gnorm=0.345, oom=0.000, wall=27949, train_wall=92608, now=01:54:20\r\n2020-12-28 01:56:05.252059: W    1436 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.251908254\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252085: W    1417 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.251970000\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252085: W    1416 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.251940620\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252162: W    1379 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252025037\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252205: W    1438 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252117134\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252251: W    1465 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252143973\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252279: W    1483 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252130522\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252398: W    1464 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252301762\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252431: W    1428 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252333413\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252452: W    1341 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252361631\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252472: W    1400 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252380523\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252456: W    1345 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252299434\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252541: W    1378 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252405772\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252553: W    1423 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252493206\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252618: W    1397 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252489431\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\n2020-12-28 01:56:05.252674: W    1480 tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:160] RPC failed with status = \"Unavailable: Socket closed\" and grpc_error_string = \"{\"created\":\"@1609120565.252561700\",\"description\":\"Error received from peer ipv4:10.180.83.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\", maybe retrying the RPC\r\nterminate called after throwing an instance of 'std::runtime_error'\r\n  what():  tensorflow/compiler/xla/xla_client/xrt_computation_client.cc:1110 : Check failed: session->session()->Run( feed_inputs, {}, {cached_node.operations[0]}, &outputs) == ::tensorflow::Status::OK() (Aborted: Session a57840b79b1bd972 is not found. vs. OK)\r\n*** Begin stack trace ***\r\n        tensorflow::CurrentStackTrace()\r\n        xla::XrtComputationClient::ReleaseHandles(std::vector<xla::XrtComputationClient::DeviceHandle, std::allocator<xla::XrtComputationClient::DeviceHandle> >*, std::function<xla::XrtSession::CachedNode const& (xla::XrtSession*, tensorflow::Scope const&, std::string const&)> const&, xla::metrics::Metric*, xla::metrics::Counter*)\r\n        xla::XrtComputationClient::HandleReleaser()\r\n        xla::util::TriggeredTask::Runner()\r\n\r\n\r\n        clone\r\n*** End stack trace ***\r\n```\r\n  \r\n  \r\n\r\n\r\n\r\nCurrently, I resumed training on another TPU node, but checking the memory usage it seems it is increasing at each training step. Is it possible that OOM happened on the TPU and it got unavailable?\r\n\r\n![image](https://user-images.githubusercontent.com/14294190/103204324-039df800-48ef-11eb-98cb-8feca300d76a.png)\r\n\r\n", "comments": ["Hi soares-f , I'm getting the same issue (though with a custom model), with a similar per-epoch increase in TPU memory.\r\nDid you end up figuring out what the cause was?"]}, {"number": 46002, "title": "TFlite Poor Performance on Pixel 3 CPU when channel not multiple of 4", "body": "**System information**\r\n- Have I written custom code: Only to generate conv2d tflite models\r\n- Host OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: Pixel 3\r\n- TensorFlow installed from (source or binary): [native benchmark binary](https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary) nightly pre-built (no Flex delegate) android_aarch64\r\n- Host TensorFlow version: 2.3.0\r\n- Mobile device TensorFlow version: nightly\r\n- Python version: 3.8.3\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nThe tflite conv2d op performs poorly on Pixel 3 CPU when the input or output channel numbers are not multiples of 4. Selective inference latency measured on Pixel 3 is shown in the following table to support 3 major observations:\r\n\r\n|In/Out Channel|Latency|In/Out Channel|Latency|In/Out Channel|Latency|\r\n|-|-|-|-|-|-|\r\n|16/14|21760.5|30/43|137299.0|4/44|14541.9|\r\n|16/15|24486.5|31/43|166752.0|44/4|38141.8|\r\n|16/16|21479.2|32/43|86515.3|11/43|67771.0|\r\n|16/17|24136.2|33/43|156961.0|43/11|72423.9|\r\n|16/18|26734.9|34/43|152460.0|22/30|66271.4|\r\n|44/37|26193.0|35/43|158265.0|30/22|77171.4|\r\n|44/64|124600.0|36/43|112036.0|\r\n\r\n1. The first two columns show that with a fixed input channel, output channels of no multiples of 4 (no4x) perform even worse than those of more channels but of multiples of 4 (4x). Notably, 44/37 has a larger latency than 44/64.\r\n2. Similarly, the second two columns show that with a fixed output channel, no4x input channels perform worse than 4x input channels. Notably, 30/43 has a larger latency than 36/43.\r\n3. The last two columns show that input and output channels are not created equal. Regardless of 4x or no4x, input channels turn to induce greater latency than output channels.\r\n\r\n**Describe the expected behavior**\r\n[TFlite guide on GPU](https://www.tensorflow.org/lite/performance/gpu_advanced#tips_and_tricks) mentions:\r\n\r\n> On a GPU, tensor data is sliced into 4-channels. Thus, a computation on a tensor of shape [B, H, W, 5] will perform about the same on a tensor of shape [B, H, W, 8], but significantly worse than [B, H, W, 4].\r\n\r\nOur questions:\r\n\r\n1. Should CPU observe the same behavior as the above-described GPU case?\r\n2. The above example seems to indicate that the latency of a no4x channel should perform about the same as when it is rounded up to the next 4x, but in our measurements, it is not the case. no4x can sometimes perform worse than much larger 4x. Is there any reasoning behind this?\r\n3. In our third observation, input channel impacts latency more than output channel. Is there any reasoning behind this?\r\n\r\n**Standalone code to reproduce the issue**\r\nThe conv2d models used for the benchmark are defined with keras and converted to tflite with the following code:\r\n```\r\n# TF model generation\r\nmodel = Sequential()\r\nmodel.add(Conv2D(output_channel, (3, 3), padding=\"same\"))\r\nmodel.build(input_shape=(1, 180, 180, input_channel))\r\nshutil.rmtree(\"./temp\")\r\nsave_model(model, \"./temp\")\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"./temp\", signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\ntf_filename = 'b{}_ic{}_oc{}_ih{}_iw{}_tf.tflite'.format(1, input_channel, output_channel, 180, 180)\r\nwith open(model_dir + tf_filename, 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\nWhere `input_channel` and `output_channel` are variables, batch size is fixed to 1, input shape is fixed to 180x180, kernel size is 3x3, and stride is 1. In this way, the generated tflite models contain only a single conv2d operator with various input and output channel numbers. The models are then loaded to Pixel 3 phones for the benchmark.\r\n\r\n**Other info / logs**\r\nThe inference latency was measured using the [native benchmark binary](https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary) nightly pre-built (no Flex delegate) android_aarch64 with the following command:\r\n`adb shell taskset f0 /data/local/tmp/android_aarch64_benchmark_model --graph=/data/local/tmp/{model}.tflite --num_threads=1 --num_runs=100`\r\nIn the report generated by the benchmark binary, `inference (avg)` is kept as the inference latency of a conv2d model. For example, when the report contains\r\n`Inference timings in us: Init: 8241, First inference: 4084, Warmup (avg): 1584.61, Inference (avg): 1573.36`\r\n1573.36 is kept as the latency for the model.\r\n", "comments": ["I found similar things on my side, not sure if there is any comment from TF?"]}, {"number": 45999, "title": "Bug in Transpose Convolution Padding", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **Binary**\r\n- TensorFlow version (use command below): **2.3.0**\r\n- Python version: **3.7.6**\r\n- Bazel version (if compiling from source): **N/A**\r\n- GCC/Compiler version (if compiling from source): **N/A**\r\n- CUDA/cuDNN version: **10.2**\r\n- GPU model and memory: **Nvidia GeForce GTX 1080 8GB**\r\n\r\n**Describe the current behavior**\r\nPadding for transpose convolutions under certain parameter combinations fails to distribute the padding as expected. This can, in extreme cases, lead to highly skewed outputs. This can happen regardless of whether the filter or signal are even or odd.\r\n\r\nHere, the output is subtly different but quite simple to verify that it must have been generated with a padding of [1, 0] rather than [0, 1]:\r\n```Python\r\nTESTING 2 x 2 INPUT WITH 2 x 2 KERNEL, (1, 1) STRIDE AND \"SAME\" PADDING:\r\nInput:\r\n[[1 1]\r\n [1 1]]\r\n\r\nKernel:\r\n[[1 1]\r\n [1 1]]\r\n\r\n\r\nDilated Input: (=> 2 x 2 array)\r\n[[1 1]\r\n [1 1]]\r\n\r\nDilated Input + Padding: (=> 3 x 3 array)\r\n[[1 1 0]\r\n [1 1 0]\r\n [0 0 0]]\r\n\r\n\r\nManual Result: (=> 2 x 2 array)\r\n[[4 2]\r\n [2 1]]\r\n\r\nStandard Result: (=> 2 x 2 array)\r\n[[1 2]\r\n [2 4]]\r\n```\r\n\r\nHere's an example with an odd kernel and valid padding instead:\r\n```Python\r\nTESTING 2 x 2 INPUT WITH 3 x 3 KERNEL, (5, 5) STRIDE AND \"VALID\" PADDING:\r\nInput:\r\n[[1 1]\r\n [1 1]]\r\n\r\nKernel:\r\n[[1 1 1]\r\n [1 1 1]\r\n [1 1 1]]\r\n\r\n\r\nDilated Input: (=> 6 x 6 array)\r\n[[1 0 0 0 0 1]\r\n [0 0 0 0 0 0]\r\n [0 0 0 0 0 0]\r\n [0 0 0 0 0 0]\r\n [0 0 0 0 0 0]\r\n [1 0 0 0 0 1]]\r\n\r\nDilated Input + Padding: (=> 12 x 12 array)\r\n[[0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 1 0 0 0 0 1 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 1 0 0 0 0 1 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]]\r\n\r\n\r\nManual Result: (=> 10 x 10 array)\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 1 1 1 0 0 1 1 1 0]\r\n [0 0 0 0 0 0 0 0 0 0]]\r\n\r\nStandard Result: (=> 10 x 10 array)\r\n[[1 1 1 0 0 1 1 1 0 0]\r\n [1 1 1 0 0 1 1 1 0 0]\r\n [1 1 1 0 0 1 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 0 0 1 1 1 0 0]\r\n [1 1 1 0 0 1 1 1 0 0]\r\n [1 1 1 0 0 1 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0]]\r\n```\r\n\r\nHere's an example with an odd signal and even kernel:\r\n```Python\r\nTESTING 3 x 3 INPUT WITH 2 x 2 KERNEL, (4, 4) STRIDE AND \"VALID\" PADDING:\r\nInput:\r\n[[1 1 1]\r\n [1 1 1]\r\n [1 1 1]]\r\n\r\nKernel:\r\n[[1 1]\r\n [1 1]]\r\n\r\n\r\nDilated Input: (=> 9 x 9 array)\r\n[[1 0 0 0 1 0 0 0 1]\r\n [0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0]\r\n [1 0 0 0 1 0 0 0 1]\r\n [0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0]\r\n [1 0 0 0 1 0 0 0 1]]\r\n\r\nDilated Input + Padding: (=> 13 x 13 array)\r\n[[0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 1 0 0 0 1 0 0 0 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 1 0 0 0 1 0 0 0 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 1 0 0 0 1 0 0 0 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]]\r\n\r\n\r\nManual Result: (=> 12 x 12 array)\r\n[[0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 1 1 0 0 1 1 0 0 1 1 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]]\r\n\r\nStandard Result: (=> 12 x 12 array)\r\n[[1 1 0 0 1 1 0 0 1 1 0 0]\r\n [1 1 0 0 1 1 0 0 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [1 1 0 0 1 1 0 0 1 1 0 0]\r\n [1 1 0 0 1 1 0 0 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [1 1 0 0 1 1 0 0 1 1 0 0]\r\n [1 1 0 0 1 1 0 0 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]]\r\n```\r\n\r\nFinally, here the skew is quite large and noticeable due to the large amount of padding, which clearly seems like it could only have stemmed from the padding being allocated entirely to the bottom and right only:\r\n```Python\r\nTESTING 2 x 2 INPUT WITH 2 x 2 KERNEL, (6, 6) STRIDE AND \"SAME\" PADDING:\r\nInput:\r\n[[1 1]\r\n [1 1]]\r\n\r\nKernel:\r\n[[1 1]\r\n [1 1]]\r\n\r\n\r\nDilated Input: (=> 7 x 7 array)\r\n[[1 0 0 0 0 0 1]\r\n [0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0]\r\n [1 0 0 0 0 0 1]]\r\n\r\nDilated Input + Padding: (=> 13 x 13 array)\r\n[[0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 1 0 0 0 0 0 1 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 1 0 0 0 0 0 1 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0 0]]\r\n\r\n\r\nManual Result: (=> 12 x 12 array)\r\n[[0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 1 1 0 0 0 0 1 1 0 0]\r\n [0 0 1 1 0 0 0 0 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 1 1 0 0 0 0 1 1 0 0]\r\n [0 0 1 1 0 0 0 0 1 1 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]]\r\n\r\nStandard Result: (=> 12 x 12 array)\r\n[[1 1 0 0 0 0 1 1 0 0 0 0]\r\n [1 1 0 0 0 0 1 1 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [1 1 0 0 0 0 1 1 0 0 0 0]\r\n [1 1 0 0 0 0 1 1 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]\r\n [0 0 0 0 0 0 0 0 0 0 0 0]]\r\n```\r\n\r\n**Describe the expected behavior**\r\nPadding for transpose convolutions should be distributed evenly with at most an extra zero on the right when not evenly divisible by 2. This is TensorFlow convention for regular convolutions, but not here, oddly enough.\r\n\r\nAll of my examples are easy to compute and verify by hand. It is not clear what the exact method of allocating the padding is for transpose convolutions, as the documentation is quite scarce. Just to clarify, my code does actually match up for many parameter combinations I did not show here for brevity, but it disagrees with enough to make me suspicious that something's up. I would love it if someone could explain the algorithm better!\r\n\r\n**Standalone code to reproduce the issue**\r\nI have provided code to replicate the above examples below:\r\n```Python\r\n# Import modules\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose\r\n\r\n# Define convenience functions\r\ndef dilate_array(x, kernel, dilation_rate, padding = 'valid'): # manually dilate array by inserting zeros\r\n    # Get padding for after dilation\r\n    rank = len(x)\r\n    x = x[None, ..., None]\r\n    paddings, _ = get_deconv_padding(x, kernel, strides, padding = padding) # calculate BEFORE dilation\r\n    \r\n    # Create \"upsampled\" array via repetition then cut off extra values by slicing\r\n    shp, strd, slc = (1, ), (slice(None, None, None), ), (slice(None, None, None), )\r\n    dil = inp = Input(x.shape[1:])\r\n    for i in range(rank):\r\n        shp += (dilation_rate[i]*dil.shape[i + 1] - dilation_rate[i] + 1, )\r\n        dil = tf.repeat(dil, dilation_rate[i], axis = i + 1)\r\n        strd += (slice(None, None, dilation_rate[i]), )\r\n        slc += (slice(None, shp[i + 1], None), )\r\n    shp += (1, )\r\n    strd += (slice(None, None, None), )\r\n    slc += (slice(None, None, None), )\r\n    dil = dil[slc]\r\n    \r\n    # Create mask to replace repeats with zeros a la \"proper\" resampling and transpose convolution\r\n    mask = np.zeros(shp)\r\n    mask[strd] = 1.0\r\n    mask = tf.cast(mask, dil.dtype)\r\n    \r\n    # Mask dilated input\r\n    dil = mask*dil\r\n    \r\n    # Pad dilated input\r\n    pad = tf.pad(dil, paddings, mode = 'CONSTANT')\r\n    \r\n    # Execute dilation + padding\r\n    model = Model(inp, [dil, pad])\r\n    xd, xp = model.predict(x)\r\n    xd, xp = xd[0, ..., 0], xp[0, ..., 0]\r\n    \r\n    return xd, xp, paddings\r\ndef deconv_padding_after_dilation(input_length, kernel_length, stride, padding = 'valid'): # adjusted padding for manual dilation (== stride)\r\n    # Compute minimum padding length assuming manually dilated array\r\n    output_length = stride*input_length + (max(kernel_length - stride, 0) if padding == 'valid' else 0)\r\n    dilated_length = stride*input_length - (stride - 1)\r\n    pad_length = output_length - dilated_length + kernel_length - 1\r\n    \r\n    return pad_length, output_length\r\ndef get_deconv_padding(x, kernel, strides, padding = 'valid'):\r\n    # Calculate needed paddings with PRE-DILATED input to apply to DILATED input\r\n    rank = len(x.shape) - 2\r\n    paddings, output_shape = [[0, 0]], (1, )\r\n    for i in range(rank):\r\n        pad_length, output_length = deconv_padding_after_dilation(int(x.shape[i + 1]), kernel.shape[i], strides[i], padding = padding)\r\n        paddings += [[pad_length//2, pad_length//2 + pad_length%2]]\r\n        output_shape += (output_length, )\r\n    paddings += [[0, 0]]\r\n    output_shape += (1, )\r\n    \r\n    return paddings, output_shape\r\ndef execute_manual_transpose_convolution(x, kernel, strides, padding = 'valid'):\r\n    # Manually dilate and pad output then convolve normally\r\n    xd, xp, paddings = dilate_array(x, kernel, strides, padding = padding)\r\n    inp = Input(xp.shape + (1, ))\r\n    conv = Conv2D(1, kernel.shape, padding = 'valid')(inp)\r\n    model = Model(inp, conv)\r\n    model.set_weights([kernel[..., None, None], np.zeros((1, ))])\r\n    y = model.predict(xp[None, ..., None])[0, ..., 0]\r\n    \r\n    return xd, xp, paddings, y\r\ndef execute_standard_transpose_convolution(x, kernel, strides, padding = 'valid'):\r\n    # Use standard transpose convolution\r\n    inp = Input(x.shape + (1, ))\r\n    convT = Conv2DTranspose(1, kernel.shape, strides = strides, padding = padding)(inp)\r\n    model = Model(inp, convT)\r\n    model.set_weights([kernel[..., None, None], np.zeros((1, ))])\r\n    y = model.predict(x[None, ..., None])[0, ..., 0]\r\n    \r\n    return y\r\n```\r\n```Python\r\n# Define inputs\r\nrank = 2\r\nx = np.ones(rank*(2, ), dtype = 'float32') # CHANGE THIS\r\nkernel = np.ones(rank*(2, ), dtype = 'float32') # CHANGE THIS\r\nstrides = rank*(1, ) # CHANGE THIS\r\npadding = 'same' # CHANGE THIS\r\n\r\n# Test transpose convolution\r\nxd, xp, paddings, y_manual = execute_manual_transpose_convolution(x, kernel, strides, padding = padding)\r\ny_standard = execute_standard_transpose_convolution(x, kernel, strides, padding = padding)\r\n\r\n# Show results\r\nprint('TESTING {} INPUT WITH {} KERNEL, {} STRIDE AND \"{}\" PADDING:'.format(' x '.join([str(s) for s in x.shape]),\r\n                                                                            ' x '.join([str(s) for s in kernel.shape]),\r\n                                                                            strides,\r\n                                                                            padding.upper()))\r\nprint('Input:')\r\nprint(x.astype(int))\r\nprint('')\r\nprint('Kernel:')\r\nprint(kernel.astype(int))\r\nprint('\\n')\r\nprint('Dilated Input: (=> {} array)'.format(' x '.join([str(s) for s in xd.shape])))\r\nprint(xd.astype(int))\r\nprint('')\r\nprint('Dilated Input + Padding: (=> {} array)'.format(' x '.join([str(s) for s in xp.shape])))\r\nprint(xp.astype(int))\r\nprint('\\n')\r\nprint('Manual Result: (=> {} array)'.format(' x '.join([str(s) for s in y_manual.shape])))\r\nprint(y_manual.astype(int))\r\nprint('')\r\nprint('Standard Result: (=> {} array)'.format(' x '.join([str(s) for s in y_standard.shape])))\r\nprint(y_standard.astype(int))\r\nprint('')\r\n```\r\n\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1f177e50ce9fe8fdb76c411708dc59a1/45999.ipynb#scrollTo=EOMmFgTLMheP). Thanks!", "Adding the `contributions welcome` label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!", "I want to work on this issue as I am a new contributor and want to solve this issue if possible share some resource so that I can get started with it @nikitamaia ", "Done! There's some info in the [Contribute To TensorFlow guide here](https://www.tensorflow.org/community/contribute/code).", "As this was assigned on 13 Apr:\r\n@carrycooldude Do you have a draft PR, are you still working on this?", "I am still working on this", "@carrycooldude , Any updates on this issue? Please let us know if you are still working on this issue", "How i can contribute\r\nplease guide me\r\nI like to solve this problem"]}, {"number": 45998, "title": " When I use AndroidStudio to import Image Segementation TensorsorflowLite model, there is a problem...", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n-Pixel 2xl  Android 11\r\n\r\n**Describe the problem**\r\nModel:\r\n[ImageSegmentation](https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2)\r\n\r\nDependencies\uff1a\r\n```\r\nimplementation(\"org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly\")\r\nimplementation(\"org.tensorflow:tensorflow-lite-support:0.0.0-nightly\")\r\nimplementation(\"org.tensorflow:tensorflow-lite-metadata:0.0.0-nightly\")\r\n```\r\n\r\nCode:\r\n```\r\n val options = Model.Options.Builder()\r\n            .setDevice(Model.Device.GPU)\r\n            .setNumThreads(4)\r\n            .build()\r\nval inputImage = TensorImage.fromBitmap(originBitmap)\r\nval model = ImageSegmentationModel.newInstance(context, options)\r\nval result = model.process(inputImage)\r\nresult.segmentationMasksAsCategoryList\r\nmodel.close()\r\n```\r\nError: `java.lang.IllegalArgumentException: Label number 21 mismatch the shape on axis 1`", "comments": ["@hotsx \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "thanks for reminding", "This error is caused by the code of `TensorLabel` [here](https://github.com/tensorflow/tflite-support/blob/93616b1d1397b7d910e4890979185daf53dc81e8/tensorflow_lite_support/java/src/java/org/tensorflow/lite/support/label/TensorLabel.java#L89). I guess you are trying to use TensorLabel to parse the label strings. the output tensor is in the size of `[1,257,257,21]` where the label axis is the fourth one. So you should create the TensorLabel by using this [factory creation method](https://github.com/tensorflow/tflite-support/blob/93616b1d1397b7d910e4890979185daf53dc81e8/tensorflow_lite_support/java/src/java/org/tensorflow/lite/support/label/TensorLabel.java#L75-L76), where the first parameter is a map of axis id (3 in this case) and labels.\r\n\r\nHowever, TensorLabel actually won't help you in this case, because there's no method to allow you to get a map of label string and the sliced TensorBuffer value. The [getMapWithTensorBuffer](https://github.com/tensorflow/tflite-support/blob/93616b1d1397b7d910e4890979185daf53dc81e8/tensorflow_lite_support/java/src/java/org/tensorflow/lite/support/label/TensorLabel.java#L108-L113) method only \"allow the mapping on the first axis with size greater than 1\". For example it works with the [image classification model](https://www.tensorflow.org/lite/models/image_classification/overview), where the output is in the size of `[1, n]`. If the output tensor size of the image segmentation model is `[1, 21, 257, 257]`, `getMapWithTensorBuffer` can be used.\r\n\r\nTo parse the labels, you can use [FileUtil.loadLabels](https://github.com/tensorflow/tflite-support/blob/93616b1d1397b7d910e4890979185daf53dc81e8/tensorflow_lite_support/java/src/java/org/tensorflow/lite/support/common/FileUtil.java#L86), such as:\r\n```\r\nlabels = FileUtil.loadLabels(metadataExtractor.getAssociatedFile(classesLabelsFileName));\r\n```\r\n\r\nHope it helps."]}, {"number": 45997, "title": "java.lang.NoClassDefFoundError: Failed resolution of: Lorg/tensorflow/lite/support/image/ColorSpaceType", "body": "Error when using ImageSegmentation in Android\r\n\r\nMaybe my ability is not enough and I am prone to make some low-level mistakes, but this problem has really troubled me for a long time, and there is no problem with using other types of models. Thank you.", "comments": ["Sorry to hear that the issue has been bothered you for a while. This is due to a recent breakage of our bintray to Jcenter pipeline. The Java package on the Jcenter is not updated properly. And we are actively looking into this issue, and trying to fix it.\r\n\r\nAt the mean time, please try the package from [Bintray](https://jcenter.bintray.com/org/tensorflow/tensorflow-lite-support/0.0.0-nightly/). It should be up-to-date."]}, {"number": 45993, "title": "How to access operations of the tf graph from a keras model? (for tf 2.4.0)", "body": "**System information**\r\n- TensorFlow installed from (source or binary): pypi\r\n- TensorFlow version (use command below): 2.4.0\r\n\r\n**Describe the current behavior**\r\nStarting from tensorflow 2.4.0, it seems that the keras model cannot access the operations of the backend tf graph. I am looking at `keras.backend.get_session().graph`, is this the right way to access tf.graph? If I do `keras.backend.get_session().graph.get_operations()`, it returns an empty array.\r\nNote that we can do this successfully for tf 1.x. And for tf 2.3, we can access tf graph by `model.outputs[0].graph`, however, `model.ouputs[0]` does not have `graph` for tf 2.4.\r\nThat is:\r\n```python\r\n# keras == 2.3.1, tensorflow == 2.3.0\r\nfrom tensorflow.python import keras  \r\nmodel = keras.models.Sequential()\r\nmodel.add(keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\r\ntf_operations = model.outputs[0].graph.get_operations()\r\nprint(len(tf_operations))\r\n# result: 8\r\n\r\n# keras == 2.3.1, tensorflow == 1.15.0\r\nfrom tensorflow.python import keras  \r\nmodel = keras.models.Sequential()\r\nmodel.add(keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\r\ntf_operations = keras.backend.get_session().graph.get_operations()\r\nprint(len(tf_operations))\r\n# result: 25\r\n```\r\nbut for tensorflow==2.4.0, if I use:\r\n```python\r\ntf_operations = model.outputs[0].graph.get_operations()\r\n```\r\nthen it throws errors `AttributeError: 'KerasTensor' object has no attribute 'graph'`\r\nand it returns 0 when I `print(len(tf_operations))` for `tf_operations = keras.backend.get_session().graph.get_operations()`", "comments": ["@jiafatom \r\nI ran the code shared and find indentation errors, please provide with complete stand alone code such that we can replicate the issue faced, or if possible share a colab gist with error reported.", "@Saduf2019 Thanks for looking at this. I just updated the code in the description. The code should be straightforward, it works when I just copy-paste to a python file. Please let me know if you still have issues.", "@jiafatom \r\nI ran the code shared and face this error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a03b07436074537c30bd38cf066768f1/untitled489.ipynb).", "@Saduf2019 Yes, you have repro the same error I am talking about in the description, and this is my question.\r\nFrom description, I mentioned:\r\n\r\nbut for tensorflow==2.4.0, if I use:\r\ntf_operations = model.outputs[0].graph.get_operations()\r\nthen it throws errors AttributeError: 'KerasTensor' object has no attribute 'graph'\r\n\r\nThis is because the `graph` attribute is no longer in `model.outputs[0]`. But in tf 2.3, it works successfully.\r\nSo the question is how to access the graph (the tf graph operations) in tf 2.4. -- Is there another way if this is not working?", "@jvishnuvardhan \r\nThe error is producible in nightly as well, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/e9f93c926cd912b3a835fe36b01aed64/untitled488.ipynb)."]}, {"number": 45983, "title": "Unrecognized DataType enum value 68 and crash in malloc", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ArchLinux\r\n- TensorFlow installed from (source or binary): Official repository: `python-tensorflow` (https://archlinux.org/packages/community/x86_64/python-tensorflow/) or `python-tensorflow-opt`\r\n- TensorFlow version (use command below): Tensorflow 2.4.0 with Keras 2.4.3\r\n- Python version: 3.9 (I know this isn't supported yet. Feel free to close this if it's version incompatibility)\r\n- CUDA/cuDNN version: N/A (gpu not enabled)\r\n- GPU model and memory: N/A (not enabled)\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n1. Clone https://github.com/j05t/emnist\r\n2. Run this file \r\n[train.zip](https://github.com/tensorflow/tensorflow/files/5744113/train.zip) in the directory with `gdb`\r\n3. The program crashes with:\r\n\r\n```\r\nStarting program: /usr/bin/python train.py\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/usr/lib/libthread_db.so.1\".\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.summary API due to missing TensorBoard installation.\r\n2.4.3\r\n0.17325132 0.3316614\r\n[New Thread 0x7fff503ee640 (LWP 57446)]\r\n2020-12-27 00:32:00.447866: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-27 00:32:00.448201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[New Thread 0x7fff4fb2d640 (LWP 57447)]\r\n[New Thread 0x7fff4f32c640 (LWP 57448)]\r\n[New Thread 0x7fff4eb2b640 (LWP 57449)]\r\n[New Thread 0x7fff4e32a640 (LWP 57450)]\r\n[New Thread 0x7fff4db29640 (LWP 57451)]\r\n[New Thread 0x7fff4d328640 (LWP 57452)]\r\n[New Thread 0x7fff4cb27640 (LWP 57453)]\r\n[New Thread 0x7fff2ffff640 (LWP 57454)]\r\n2020-12-27 00:32:00.450681: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n[New Thread 0x7fff2f7fe640 (LWP 57455)]\r\n[New Thread 0x7fff2effd640 (LWP 57456)]\r\n2020-12-27 00:32:00.757113: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-12-27 00:32:00.771377: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1996860000 Hz\r\n[New Thread 0x7fff2d7fb640 (LWP 57457)]\r\n[Thread 0x7fff2d7fb640 (LWP 57457) exited]\r\n[New Thread 0x7fff2d7fb640 (LWP 57461)]\r\n[New Thread 0x7fff2cefa640 (LWP 57462)]\r\n[New Thread 0x7fff0bfff640 (LWP 57463)]\r\n[New Thread 0x7fff0b7fd740 (LWP 57465)]\r\n[New Thread 0x7fff0affb7c0 (LWP 57466)]\r\n[New Thread 0x7fff0a7f9840 (LWP 57467)]\r\n[New Thread 0x7fff09ff78c0 (LWP 57468)]\r\n[New Thread 0x7fff097f5940 (LWP 57469)]\r\n[New Thread 0x7fff08ff39c0 (LWP 57470)]\r\n[New Thread 0x7ffeffffda40 (LWP 57471)]\r\n[New Thread 0x7ffeff7fbb40 (LWP 57472)]\r\n[New Thread 0x7ffefeff9bc0 (LWP 57473)]\r\n[New Thread 0x7ffefe7f7c40 (LWP 57474)]\r\n[New Thread 0x7ffefdff5cc0 (LWP 57475)]\r\n[New Thread 0x7ffefd7f3d40 (LWP 57476)]\r\n[New Thread 0x7ffefcff1dc0 (LWP 57477)]\r\n[New Thread 0x7ffed3ffce40 (LWP 57478)]\r\n2020-12-27 00:32:03.193765: E tensorflow/core/framework/types.cc:101] Unrecognized DataType enum value 68\r\nmalloc(): unaligned tcache chunk detected\r\n\r\nThread 12 \"python\" received signal SIGABRT, Aborted.\r\n[Switching to Thread 0x7fff2effd640 (LWP 57456)]\r\n0x00007ffff7a29615 in raise () from /usr/lib/libc.so.6\r\n(gdb) bt\r\n#0  0x00007ffff7a29615 in raise () from /usr/lib/libc.so.6\r\n#1  0x00007ffff7a12862 in abort () from /usr/lib/libc.so.6\r\n#2  0x00007ffff7a6b5e8 in __libc_message () from /usr/lib/libc.so.6\r\n#3  0x00007ffff7a7327a in malloc_printerr () from /usr/lib/libc.so.6\r\n#4  0x00007ffff7a77f8c in malloc () from /usr/lib/libc.so.6\r\n#5  0x00007fffe674a53a in operator new (sz=64) at /build/gcc/src/gcc/libstdc++-v3/libsupc++/new_op.cc:50\r\n#6  0x00007ffff29718ee in tensorflow::Status::Status(tensorflow::error::Code, absl::lts_2020_02_25::string_view, std::vector<tensorflow::StackFrame, std::allocator<tensorflow::StackFrame> >&&) ()\r\n   from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fffe462d157 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#8  0x00007fffe4634daa in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#9  0x00007fffe463b392 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#10 0x00007fffe9add029 in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007fffe9ad9cc8 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007fffe5a59ee1 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#13 0x00007ffff79d33e9 in start_thread () from /usr/lib/libpthread.so.0\r\n#14 0x00007ffff7aec293 in clone () from /usr/lib/libc.so.6\r\n\r\n```\r\n\r\nAlternative corruption message:\r\n\r\n```\r\nNew Thread 0x7fff503ee640 (LWP 58610)]\r\n2020-12-27 00:42:25.626607: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-12-27 00:42:25.626814: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-27 00:42:25.629252: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2020-12-27 00:42:25.901677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-12-27 00:42:25.917771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1996860000 Hz\r\npython: malloc.c:4064: _int_malloc: Assertion `(unsigned long) (size) >= (unsigned long) (nb)' failed.\r\n\r\nThread 12 \"python\" received signal SIGABRT, Aborted.\r\n[Switching to Thread 0x7fff2effd640 (LWP 58620)]\r\n0x00007ffff7a29615 in raise () from /usr/lib/libc.so.6\r\n\r\n// Crashed thread\r\n(gdb) bt\r\n#0  0x00007ffff7a29615 in raise () from /usr/lib/libc.so.6\r\n#1  0x00007ffff7a12862 in abort () from /usr/lib/libc.so.6\r\n#2  0x00007ffff7a73458 in __malloc_assert () from /usr/lib/libc.so.6\r\n#3  0x00007ffff7a76f08 in _int_malloc () from /usr/lib/libc.so.6\r\n#4  0x00007ffff7a77e51 in malloc () from /usr/lib/libc.so.6\r\n#5  0x00007fffe674a53a in operator new (sz=40) at /build/gcc/src/gcc/libstdc++-v3/libsupc++/new_op.cc:50\r\n#6  0x00007fffe452b776 in tensorflow::Tensor::Tensor(tensorflow::Allocator*, tensorflow::DataType, tensorflow::TensorShape const&, tensorflow::AllocationAttributes const&) () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#7  0x00007fffe43986f2 in tensorflow::OpKernelContext::allocate_tensor(tensorflow::DataType, tensorflow::TensorShape const&, tensorflow::Tensor*, tensorflow::AllocatorAttributes, tensorflow::AllocationAttributes const&) ()\r\n   from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#8  0x00007fffe4398ebb in tensorflow::OpKernelContext::allocate_output(int, tensorflow::TensorShape const&, tensorflow::Tensor**, tensorflow::AllocatorAttributes) () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#9  0x00007fffe43992e5 in tensorflow::OpKernelContext::allocate_output(int, tensorflow::TensorShape const&, tensorflow::Tensor**) () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#10 0x00007fffec4eb9e0 in tensorflow::AllocateOutputSetMklShape(tensorflow::OpKernelContext*, int, tensorflow::Tensor**, tensorflow::TensorShape const&, tensorflow::MklDnnShape const&, bool) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007fffec840fff in tensorflow::MklFusedBatchNormOp<Eigen::ThreadPoolDevice, float, float, true, false, false>::Compute(tensorflow::OpKernelContext*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007fffe463c3de in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#13 0x00007fffe9add029 in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#14 0x00007fffe9ad9cc8 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#15 0x00007fffe5a59ee1 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#16 0x00007ffff79d33e9 in start_thread () from /usr/lib/libpthread.so.0\r\n#17 0x00007ffff7aec293 in clone () from /usr/lib/libc.so.6\r\n\r\n// Main Thread\r\n\r\nThread 1 (Thread 0x7ffff7874740 (LWP 58605) \"python\"):\r\n#0  0x00007ffff7ae6d5d in syscall () from /usr/lib/libc.so.6\r\n#1  0x00007ffff29bae09 in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\n#2  0x00007ffff29b7b43 in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007ffff29b8043 in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fffee56824b in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tensorflow::CancellationManager*, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fffe9c59f2b in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_2020_02_25::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::lts_2020_02_25::Span<tensorflow::TensorHandle*>) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fffe9c5ac88 in tensorflow::ExecuteNode::Run() () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fffee564f80 in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fffe9c59107 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fffe9c59820 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007fffe9c4917e in tensorflow::EagerOperation::Execute(absl::lts_2020_02_25::Span<tensorflow::AbstractTensorHandle*>, int*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007fffe9a9d099 in TFE_Execute () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007fffe9a2c2e5 in TFE_Py_ExecuteCancelable(TFE_Context*, char const*, char const*, absl::lts_2020_02_25::InlinedVector<TFE_TensorHandle*, 4ul, std::allocator<TFE_TensorHandle*> >*, _object*, TFE_CancellationManager*, absl::lts_2020_02_25::InlinedVector<TFE_TensorHandle*, 2ul, std::allocator<TFE_TensorHandle*> >*, TF_Status*) () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#13 0x00007fff9d2fe87f in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\r\n#14 0x00007fff9d2fec79 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\r\n#15 0x00007fff9d3227b5 in ?? () from /usr/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\r\n#16 0x00007ffff7d01253 in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#17 0x00007ffff7ce771d in _PyObject_MakeTpCall () from /usr/lib/libpython3.9.so.1.0\r\n#18 0x00007ffff7ce3462 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#19 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#20 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#21 0x00007ffff7cdf577 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#22 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#23 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#24 0x00007ffff7cff8e4 in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#25 0x00007ffff7cdf577 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#26 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#27 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#28 0x00007ffff7cff8e4 in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#29 0x00007ffff7cdf577 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#30 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#31 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#32 0x00007ffff7ce6fe5 in _PyObject_FastCallDictTstate () from /usr/lib/libpython3.9.so.1.0\r\n#33 0x00007ffff7cfc3d9 in _PyObject_Call_Prepend () from /usr/lib/libpython3.9.so.1.0\r\n#34 0x00007ffff7ddaa7a in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#35 0x00007ffff7d001e2 in PyObject_Call () from /usr/lib/libpython3.9.so.1.0\r\n#36 0x00007ffff7ce10c6 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#37 0x00007ffff7cddaaf in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#38 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#39 0x00007ffff7cffae4 in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#40 0x00007ffff7ce10c6 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#41 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#42 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\n#43 0x00007ffff7ce6fe5 in _PyObject_FastCallDictTstate () from /usr/lib/libpython3.9.so.1.0\r\n#44 0x00007ffff7cfc3d9 in _PyObject_Call_Prepend () from /usr/lib/libpython3.9.so.1.0\r\n#45 0x00007ffff7ddaa7a in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#46 0x00007ffff7ce771d in _PyObject_MakeTpCall () from /usr/lib/libpython3.9.so.1.0\r\n#47 0x00007ffff7ce3462 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#48 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#49 0x00007ffff7cef40e in _PyFunction_Vectorcall () from /usr/lib/libpython3.9.so.1.0\r\n#50 0x00007ffff7cff8e4 in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#51 0x00007ffff7cdf577 in _PyEval_EvalFrameDefault () from /usr/lib/libpython3.9.so.1.0\r\n#52 0x00007ffff7cdd28d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#53 0x00007ffff7cdcc51 in _PyEval_EvalCodeWithName () from /usr/lib/libpython3.9.so.1.0\r\n#54 0x00007ffff7d9eb13 in PyEval_EvalCode () from /usr/lib/libpython3.9.so.1.0\r\n#55 0x00007ffff7daeb9d in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#56 0x00007ffff7daa96b in ?? () from /usr/lib/libpython3.9.so.1.0\r\n#57 0x00007ffff7c4c7c4 in PyRun_FileExFlags () from /usr/lib/libpython3.9.so.1.0\r\n#58 0x00007ffff7c4c14c in PyRun_SimpleFileExFlags () from /usr/lib/libpython3.9.so.1.0\r\n#59 0x00007ffff7dc0c99 in Py_RunMain () from /usr/lib/libpython3.9.so.1.0\r\n#60 0x00007ffff7d91ba9 in Py_BytesMain () from /usr/lib/libpython3.9.so.1.0\r\n#61 0x00007ffff7a14152 in __libc_start_main () from /usr/lib/libc.so.6\r\n#62 0x000055555555504e in _start ()\r\n\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe program doesn't crash.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n(Described above)\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@htfy96 \r\nI ran the code shared and face this error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/263aad481c0fea67048b9074a55b938b/untitled488.ipynb).", "Hi,\r\n\r\nThanks for looking into this. I think you need to clone https://github.com/j05t/emnist first and run the train.py inside the cloned repository. Also If you like I can create a Vagrant box (a virtual machine image) so you can replicate it bit-to-bit", "@htfy96 I am facing different error as shown below. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/9c0826815af3aa6b3712cbbf5b026c4c/untitled488.ipynb).\r\n\r\n```\r\n2.5.0\r\n0.17325132 0.3316614\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-17-2cc1d72b736a> in <module>()\r\n    103 num_epochs = 10\r\n    104 h = m.fit(batches, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=0,\r\n--> 105                             validation_data=test_batches, validation_steps=validation_steps)\r\n    106 \r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nInvalidArgumentError:  Conv2DCustomBackpropFilterOp only supports NHWC.\r\n\t [[node gradient_tape/sequential_6/conv2d_27/Conv2D/Conv2DBackpropFilter (defined at <ipython-input-17-2cc1d72b736a>:105) ]] [Op:__inference_train_function_11306]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```", "The above error is weird because it runs without error on my machine. I slightly modified the code to simulate my local setup with `keras==2.4.3` and `tensorflow==2.4.0` and use `import keras` instead of `from tensorflow import keras\r\n` at https://colab.research.google.com/gist/htfy96/67c6e76afb3bdd7965945821e738c920/untitled488.ipynb. Still no luck and it yields the same error. The same code on my machine outputs:\r\n```\r\n2.4.3 # Keras version\r\n2.4.0 # Tensorflow version\r\n0.17325132 0.3316614\r\n2021-01-04 01:20:32.949083: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-04 01:20:32.949366: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-04 01:20:32.950210: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2021-01-04 01:20:33.200021: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-01-04 01:20:33.200450: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1996805000 Hz\r\npython: malloc.c:4064: _int_malloc: Assertion `(unsigned long) (size) >= (unsigned long) (nb)' failed.\r\n\r\n```\r\n\r\nIf you need more information I can create a docker image to simulate my local environment entirely", "Here is archlinux's build script: https://github.com/archlinux/svntogit-community/blob/packages/tensorflow/trunk/PKGBUILD . Perhaps it's something wrong during the build process."]}, {"number": 45974, "title": "TensorflowLite Android OpenCL delegate may produce invalid Conv2D result", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Huawei P30 Lite\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: -\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): Android NDK 21.3.6528147\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: Mali-G51 MP4 as per [gsmarena](https://www.gsmarena.com/huawei_p30_lite-9545.php) on an Android smartphone\r\n\r\nI have been trying to run inference of some CNN model using TFLite 2.4.0 with OpenCL GPU delegate enabled and found that Conv2D operator may produce NaNs, Infs and other invalid values when running on the **Mali-G51 MP4** GPU if precision loss is allowed (I assume that getting NaNs is not considered as a reasonable precision loss) and Cond2D padding is set to `same`. For `valid` padding model produces valid results.\r\nI've created a simple Conv2D-only ([simple_conv.zip](https://github.com/tensorflow/tensorflow/files/5743060/simple_conv.zip), shown on the illustration below) model to test via [inference_diff](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff) util:\r\n\r\n![image](https://user-images.githubusercontent.com/5624568/103150993-e2bc9200-478a-11eb-8a56-11c5566eeb33.png)\r\n\r\nHere are some sample outputs of the `inference_diff/run_eval` util obtained using the described model on the Huawei P30 Lite (Mali-G51 MP4 GPU) smartphone:\r\n\r\n```\r\n$ adb shell /data/local/tmp/run_eval --model_file=/data/local/tmp/simple_conv.tflite --num_runs=1 --delegate=gpu\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nGPU delegate is created.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : tflite_inference_stage.cc:128 \r\nnative : inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 1\r\nReference run latency: avg=55112(us), std_dev=17548(us)\r\nTest run latency: avg=11990(us), std_dev=1488(us)\r\nOutputDiff[0]: avg_error=inf, std_dev=nan\r\n```\r\n\r\nAfter disabling precision loss manually, model seemed to be working fine, but much slower obviously:\r\n\r\n```\r\n$ adb shell /data/local/tmp/run_eval --model_file=/data/local/tmp/simple_conv.tflite --num_runs=1 --delegate=gpu --gpu_precision_loss_allowed=false\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nGPU delegate is created.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : tflite_inference_stage.cc:128 \r\nnative : inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 1\r\nReference run latency: avg=121364(us), std_dev=20829(us)\r\nTest run latency: avg=28716(us), std_dev=1158(us)\r\nOutputDiff[0]: avg_error=0.000120298, std_dev=0\r\n```\r\n\r\nAfter further investigation I found out that this kind of behavior may be fixed by manually commenting the [piece of code](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/delegates/gpu/cl/selectors/operation_selector.cc#L257) responsible for selecting Winograd algorithm kernel as a Conv2D node implementation (i.e. `SelectConvolution` branch is always used). After this fix, model seemed to be working fine:\r\n\r\n```\r\n$ adb shell /data/local/tmp/run_eval --model_file=/data/local/tmp/simple_conv.tflite --num_runs=1 --delegate=gpu\r\nGPU delegate is created.\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : tflite_inference_stage.cc:128 \r\nnative : inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 1\r\nReference run latency: avg=113876(us), std_dev=17465(us)\r\nTest run latency: avg=30590(us), std_dev=3084(us)\r\nOutputDiff[0]: avg_error=0.304206, std_dev=0\r\n```\r\n\r\nThus I assume that Winograd algorithm implementation for OpenCL delegate is the root cause of the issue. To sum up, here is the list of conditions to reproduce the bug, at least on the Mali-G51 MP4 GPU:\r\n1. Create Conv2D node which is suitable for using Winograd algorithm as per [check](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/delegates/gpu/cl/selectors/operation_selector.cc#L43).\r\n2. Use `same` padding in Conv2D node.\r\n3. Use OpenCL backend.\r\n4. Allow precision loss.\r\n\r\nThe same behavior was also observed when running on Samsung Galaxy M31 (Mali-G72 MP3 GPU) and Huawei P20 (Mali-G72 MP12 GPU). However, running default build (i.e. without disabling Winograd manually) on Samsung Galaxy S20+ (Mali-G77 MP11 GPU) was successful. \r\n\r\nPlease let me know, if you need more details/logs/code etc.", "comments": ["@impjdi , could you take a look at this? If its a bug I can help file an internal tracker.", "@dev0x13 \r\n\r\nForwarding the message from our OpenCL specialist.  Due to COVID-19 and restricted office visits, he could only test on a device that he had, Mali T880MP4, but it seems to work correctly and he couldn't reproduce the issue.\r\n\r\nCan you try to run `tensorflow/tensorflow/lite/delegates/gpu/cl/kernels/winograd_test.cc` ?", "@impjdi \r\n\r\nThis test is passing, here is the output just in case:\r\n\r\n```\r\n$ adb shell /data/local/tmp/winograd_test\r\nRunning main() from gmock_main.cc\r\n[==========] Running 2 tests from 1 test suite.\r\n[----------] Global test environment set-up.\r\n[----------] 2 tests from OpenCLOperationTest\r\n[ RUN      ] OpenCLOperationTest.Winograd4x4To36\r\n[       OK ] OpenCLOperationTest.Winograd4x4To36 (2942 ms)\r\n[ RUN      ] OpenCLOperationTest.Winograd36To4x4\r\n[       OK ] OpenCLOperationTest.Winograd36To4x4 (1472 ms)\r\n[----------] 2 tests from OpenCLOperationTest (4415 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 2 tests from 1 test suite ran. (4415 ms total)\r\n[  PASSED  ] 2 tests.\r\n```\r\n\r\nThank you and OpenCL specialist for checking this issue. Too bad that you're not able to reproduce it with available hardware.\r\nI'll try to debug this kernel myself using my hardware and will share results here if there will be any.", "Thank you!", "Well, I managed to find the root cause of this behavior, and it seems to be a serious system problem from my perspective. Description is below.\r\n\r\nIf Conv2D operator is suitable for applying Winograd it's been decomposed to three operators: `Winograd4x4To36` -> `ConvBuffer1x1` (at least at Mali GPU) -> `Winograd36To4x4` in operation selection while applying OpenCL delegate.\r\n\r\nAfter brief inspection of OpenCL code produced by `ConvBuffer1x1` I have noticed that the computation core consists of accumulating multiplication results. However, accumulator type for half-precision computation mode (which is default for OpenCL delegate) is also float16, so it may represent at most 65504 and therefore is very vulnerable for overflow. This may be easily proven by changing bias value in `tensorflow/tensorflow/lite/delegates/gpu/cl/kernels/conv_buffer_1x1.cc` from zero to 65503 (totally valid value even for a half-precision float). Apparently the test will fail, but one may notice that in this case `ConvBuffer1x1` will produce `inf` values for `CalculationsPrecision::F16` case, which are eventually becoming NaNs if used for arithmetic operations in the next operator (e.g. Winograd). If we will increase bias to, say, 10^5 (still valid float value), then we will obtain Infs even for `CalculationsPrecision::F32_F16`.\r\n\r\nI believe that the same behavior can be reproduced using this recipe for Winograd ops as well. I also believe that this is observable only at Mali G51 and a couple other GPUs because of the implementation details, since Inf on float overflow is not guaranteed by the specification.\r\n\r\nI understand that the given example of incorrect behavior is kind of unrealistic, but apparently this may happen in some other cases, e.g. in the one above, which is actually delivered from the real-world production model.\r\n\r\nTo sum up:\r\n\r\n- In my opinion the root cause of this issue is half-precision floating point values overflow which happens in kernels code.\r\n- If so, then this may also happen in other kernels where accumulation is used as well. This is very tricky since there are no overflow checks in the TF Lite GPU delegate code for half-precision computation mode, however for the limit this low (65504) this may happen easily.\r\n\r\nI am not really into production OpenCL coding, so could you clarify whether this is expected or should be considered as a bug? Hope this helps and thank you in advance.", "Thank you very much for your time looking into this issue!  The overflow issue makes sense; it is one of the most frequent reasons why one cannot use FP16.  I'll forward your findings to the person who implemented the Winograd conv2d, maybe we can do something about it.  It may take a bit to hear back as he's on vacation right now.", "Thank you! I will try to make a workaround for my model for now.", "Hi @dev0x13.\r\nI'm currently facing the same issue you've reported. Did you ever find a good workaround or the only way to use FP16 models on Mali GPUs is to manually remove that line of code related to Winograd?", "Hi @AndreaBrg.\r\nNo, I ended up using custom build with Winograd conv commented out. This seems to work for all models I use on many different Android devices, however performance is lower comparing to the vanilla TFLite build.\r\nMe and my colleague also have tried to patch the Winograd OpenCL kernel, but with no success (I guess because we are not really into OpenCL).", "Thanks for the fast reply.\r\nOne last question, did you try using OpenGL instead of OpenCL? I have read here https://github.com/tensorflow/tensorflow/issues/26297#issuecomment-641678944 that one could force to ignore OpenCL.", "I have tried this, and incorrect result issue actually had been gone. However, OpenGL delegate seems to be much slower than OpenCL one, so it barely makes sense to use it instead of CPU for my model.", "Ok, interesting, thanks for the insight.", "Hi @dev0x13 @AndreaBrg \r\nI'm currently facing the similar issue. But instead of having nan for the diff output, output is as follows: \r\nOutputDiff[0]: avg_error=0.334206. \r\n\r\nDo you consider that 0.33 is large enough to cause the different result between CPU & GPU. I want diff error to be less than 0.003. Did you find a good workaround for this issue?", "@misheeltoli Can you specify the command you are using for getting the output diff? For the GPU delegate, there is a `gpu_precision_loss_allowed` flag (see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/delegates/README.md)) that can be set to off with the inference_diff tool. This should improve the diff value. What is considered to be a 'large diff' depends on the model, and what your output tensor means :-)", "@srjoglekar246 Thanks for the reply.\r\nThese are the commands and results for the output diff. As you can see from the result, when I use **gpu_precision_loss_allowed=true**, avg_error is 0.334995. But it is 6.36335e-06 for **gpu_precision_loss_allowed=false**. Can you provide me the details about why the difference between these result values are so large?\r\nAlso as you may already know, precision_loss enabled(fp16) setting is much faster than precision loss disabled(fp32). I need to use precision_loss enabled for the inference. Can you provide me any other workarounds I can try to solve this issue?\r\n```\r\nadb shell /data/local/tmp/run_eval \\\r\n    --model_file=/data/local/tmp/model.tflite \\\r\n    --delegate=gpu \\\r\n    --num_runs=5 \\\r\n    --gpu_precision_loss_allowed=true\r\nGPU delegate created.\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Replacing 622 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : lite/tools/evaluation/stages/tflite_inference_stage.cc:128 \r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 388 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 336 partitions.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 5\r\nReference run latency: avg=399408(us), std_dev=32415(us)\r\nTest run latency: avg=51941.7(us), std_dev=6460(us)\r\nOutputDiff[0]: avg_error=0.334995, std_dev=0.0490164\r\n```\r\n\r\n```\r\n\u279c  ~ adb shell /data/local/tmp/run_eval \\\r\n    --model_file=/data/local/tmp/model.tflite \\\r\n    --delegate=gpu \\\r\n    --num_runs=5 \\\r\n    --gpu_precision_loss_allowed=false  \r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nGPU delegate created.\r\nINFO: Replacing 622 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : lite/tools/evaluation/stages/tflite_inference_stage.cc:128 \r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 388 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 336 partitions.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 5\r\nReference run latency: avg=405939(us), std_dev=40977(us)\r\nTest run latency: avg=112061(us), std_dev=3014(us)\r\nOutputDiff[0]: avg_error=6.36335e-06, std_dev=3.32635e-06\r\n```\r\n", "Thats a tradeoff you must decide on :-). The reason the fp16 mode is so much faster is that it uses half-precision math to execute the model (which decreases latency, but increases diff). Based on your application, you can try tuning some of the other gpu knobs on the [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/delegates/README.md) I provided (like gpu_inference_for_sustained_speed: bool (default=false))."]}, {"number": 45970, "title": "Timeseries example does NOT address the core of prediction", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series\r\n\r\n## Description of issue (what needs changing):\r\nI get the sequential data and the methods to get to next step or multi steps. But with the Time being converted to frequency, why do we have to have again equidistant events record. That beats the purpose of ANY timed series problem. In the example given, converting the time to frequency does not affect the model much because the series is Timed, not any value for the period. The period between records is equal. I still don't see this as a clear example of Time series. You can call this example as Series prediction, not Timed series prediction.\r\n\r\n1) There seems to be some errors too,  In the below function, why do we have Shuffle to TRUE ? I thought timeseries is sequential ? \r\n\r\n```\r\ndef make_dataset(self, data):\r\n  data = np.array(data, dtype=np.float32)\r\n  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n      data=data,\r\n      targets=None,\r\n      sequence_length=self.total_window_size,\r\n      sequence_stride=1,\r\n      shuffle=True,\r\n      batch_size=32,)\r\n  ds = ds.map(self.split_window)\r\n  return ds\r\n```\r\n\r\n2 ) And also, how is the Validation done ? Do we have to window slide the validation data too ?\r\n3)  Do we really need window slide for LSTM ? Seems to be over fitting for a lots of examples.\r\n4)  If some input fields have categorical data (not the output), there is no way this will perform better especially if we use embedding\r\n5) With this function timeseries_dataset_from_array, it is hard to do any embedding layer.\r\n6) Timeseries involves large datasets, unfortunately using BatchNormalization is very confusing, blame it on the documentation.\r\n7) How do we do feature engineered layer (such as mixed with embedding layer) in the first input with 3D tensor.\r\n\r\n\r\n", "comments": ["And also i don't understand this one in the code in make dataset function\r\n\r\n        data = np.array(data, dtype=np.float32)\r\n        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n            data=data,\r\n            targets=None,\r\n            sequence_length=self.total_window_size,\r\n            sequence_stride=sequence_stride,\r\n            shuffle=shuffle,\r\n            batch_size=batch_size, )\r\nIf we have to preserve the dtype from dataframe until we feed this to feature engineered layer, how do we do it ? ", "1) There seems to be some errors too,  In the below function, why do we have Shuffle to TRUE ? I thought timeseries is sequential ? \r\n\r\n```\r\ndef make_dataset(self, data):\r\n  data = np.array(data, dtype=np.float32)\r\n  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n      data=data,\r\n      targets=None,\r\n      sequence_length=self.total_window_size,\r\n      sequence_stride=1,\r\n      shuffle=True,\r\n      batch_size=32,)\r\n  ds = ds.map(self.split_window)\r\n  return ds\r\n```\r\n\r\n2 ) And also, how do the Validation done ? Do we have to window slide the validation data too ?\r\n3)  Do we really need window slide for LSTM ? Seems to be over fitting for a lots of examples.\r\n4)  If some input fields have categorical data (not the output), there is no way this will perform better especially if we use embedding\r\n5) With this function timeseries_dataset_from_array, it is hard to do any embedding layer.\r\n6) Timeseries involves large datasets, unfortunately using BatchNormalization is very confusing, blame it on the documentation.\r\n7) How do we do feature engineered layer in the first input with 3D tensor.\r\n\r\n\r\n"]}, {"number": 45964, "title": "tf.data.Data.as_numpy_iterator() creates unnecessary copies", "body": "Does `tf.data.Data.as_numpy_iterator()` need to copy the data ([here](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/data/ops/dataset_ops.py#L3942)), or can the tensor buffer be used directly? This copy can be avoided by using `x._numpy()` instead, like in this Flax ImageNet example [here](https://github.com/google/flax/blob/master/linen_examples/imagenet/train.py#L169-L170). Or, by using the numpy buffer interface, as shown [here](https://github.com/tensorflow/tensorflow/issues/33254#issuecomment-542379165). ", "comments": ["Hi @n2cholas,\r\n\r\n`as_numpy_iterator` calls `numpy` instead of `_numpy` as a defensive measure to prevent Tensors from being mutated, causing undefined behavior (short demonstration in https://colab.research.google.com/drive/1WLNyazBbY8ZxGsBHKP3TXASjEAUr7VBI). We can't transparently change the behavior to zero-copy because current users may be relying on the copying mechanism already. Perhaps we could add a `copy=True` parameter, and when `copy=False` we could use `_numpy()` and then set the resulting array's [writeable](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) flag to `False`? What are your thoughts on this approach?\r\n\r\nAs a workaround in the short term, you can define a zero-copy as_numpy_iterator as follows:\r\n\r\n```python\r\ndef zero_copy_as_numpy_iterator(dataset):\r\n  return map(lambda elem: tf.nest.map_structure(lambda c: c._numpy(), elem), dataset)\r\n```\r\n\r\n", "Hi @aaudiber, thanks for the response! That makes sense, and I like the idea of adding a `copy=True` parameter. There seems to already be an API to create a zero-copy immutable numpy array from a tensor, that could be used, described [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L1051-L1057). "]}, {"number": 45962, "title": "on_epoch_end() being called multiple times when workers > 0", "body": "**System information**\r\n- Written custom code\r\n- Linux 5.4.0-1034-azure x86_64\r\n- TensorFlow version 2.3.0\r\n- Python version: 3.6.9\r\n- CUDA version:  10.1\r\n\r\n**Current Behavior**\r\nI have implemented a data generator based on the Sequence generator class. At the end of every epoch, I want to update a parameter. This parameter should change the preprocessing of my dataset for the next epoch. However at the end of every epoch the on_epoch_end() function is called multiple times. To better grasp this behavior I implemented a counter in the on_epoch_end() as this:\r\n\r\n```\r\n    def on_epoch_end(self):\r\n        'Updates indices after each epoch'\r\n\r\n        #My parameter should be updated here\r\n\r\n        print(\"counted\", self.counter, self.genMode)\r\n        self.counter += 1\r\n\r\n        self.indexes = np.arange(len(self.imageID))\r\n        if self.shuffle == True:\r\n            np.random.shuffle(self.indexes)\r\n```\r\nWhere it prints the current count aswell as the mode of the generator that's printing this statement (as I have a validation and a training generator). \r\n\r\nself.counter is initiated at self.counter = 1\r\n\r\nThis results in the following output:\r\n\r\n```\r\nEpoch 1/15\r\ncounted 1 train\r\ncounted 1 val\r\ncounted 2 val\r\ncounted 2 train\r\nEpoch 2/15\r\ncounted 3 train\r\ncounted 3 val\r\ncounted 4 train\r\nEpoch 3/15\r\ncounted 5 train\r\ncounted 4 val\r\ncounted 6 train\r\nEpoch 4/15\r\ncounted 7 train\r\ncounted 5 val\r\ncounted 8 train\r\nEpoch 5/15\r\ncounted 9 train\r\ncounted 6 val\r\ncounted 7 val\r\ncounted 10 train\r\nEpoch 6/15\r\ncounted 11 train\r\ncounted 8 val\r\ncounted 12 train\r\nEpoch 7/15\r\ncounted 13 train\r\ncounted 9 val\r\ncounted 14 train\r\nEpoch 8/15\r\ncounted 15 train\r\ncounted 10 val\r\ncounted 11 val\r\ncounted 16 train\r\n\r\n...... etc\r\n```\r\nI currently cannot find a workaround to only update my parameter once at the end of every epoch. The parameter should be updated for both my validation generator and my training generator concurrently. \r\n\r\n**expected behavior**\r\n\r\nExpected behavior would be that the on_epoch_end() function would be called only once at the end of every epoch. \r\n\r\n**Standalone code to reproduce the issue**\r\nThe code I use to create the generators plus my model.fit() function. Where scheduler is just a simple learning rate scheduler. It adjusts the learning rate every fifth epoch (5, 10 15). I have tried my code without the callbacks which produced exactly the same behavior. \r\n```\r\n\r\n    validation_generator = DataGenerator(augParams, genMode = 'val', **params)\r\n    train_generator = DataGenerator(augParams, genMode = 'train', **params)\r\n\r\n    callbacks_list = [scheduler]\r\n    model.fit(train_generator,  \r\n                        validation_data=validation_generator,\r\n                        verbose = 3,\r\n                        max_queue_size=1000,\r\n                        workers=5,\r\n                        epochs=15,\r\n                        callbacks= callbacks_list)\r\n```\r\n\r\nThe generators themselves implement the following thee functions plus some additional functions that are used for preprocessing that are called from __data__generation(). (I left out all functions and initialization that are not connected to the on_epoch_end() function)\r\n\r\n```\r\nfrom tensorflow.keras.utils import Sequence\r\n\r\nclass DataGenerator(Sequence):\r\n    def __init__(self, augParams, genMode, batchSize=32, dim=(360,640), shuffle=True):\r\n          self.genMode = genMode\r\n          self.counter = 1\r\n  \r\n\r\n    def __len__(self):\r\n        'Denotes the number of batches per epoch'\r\n        return int(np.floor(len(self.imageID) / self.batchSize))\r\n\r\n    \r\n    def __getitem__(self, index):\r\n        'Generate one batch of data'\r\n        # Generate indexes of the batch\r\n        indexes = self.indexes[index*self.batchSize:(index+1)*self.batchSize]\r\n\r\n        # Find list of IDs\r\n        imageIDtemp = [self.imageID[k] for k in indexes]\r\n        annoIDtemp = [self.annoID[k] for k in indexes]\r\n\r\n        # Generate data\r\n        X, Y = self.__data_generation(imageIDtemp, annoIDtemp)\r\n        return X, Y\r\n    \r\n    def on_epoch_end(self):\r\n        'Updates indices after each epoch'\r\n        #My parameter should be updated here\r\n\r\n        print(\"counted\", self.counter, self.genMode)\r\n        self.counter += 1\r\n\r\n        self.indexes = np.arange(len(self.imageID))\r\n        if self.shuffle == True:\r\n            np.random.shuffle(self.indexes)\r\n```\r\n\r\non_epoch_end() is not called when the generators are initialized. \r\n\r\n**Other info / logs**\r\n\r\nMy first guess was that the on_epoch_end() function wasn't thread-safe so I tried thread locking it but this had no effect. I have also run the exact same code only this time adjusting my on_epoch_end() to this:\r\n\r\n```\r\n    def on_epoch_end(self):\r\n        'Updates indices after each epoch'\r\n        traceback.print_stack()\r\n        #My parameter should be updated here\r\n\r\n        print(\"counted\", self.counter, self.genMode)\r\n        self.counter += 1\r\n\r\n        self.indexes = np.arange(len(self.imageID))\r\n        if self.shuffle == True:\r\n            np.random.shuffle(self.indexes)\r\n```\r\n\r\nPrinting the stack every time the function is called. This results in the following log for the first 5 epochs.\r\n\r\n**Log with traceback.print_stack()**\r\n\r\n```\r\nEpoch 1/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 1 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 1 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 2 train\r\nEpoch 2/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 3 train\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 2 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 3 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 4 train\r\nEpoch 3/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 5 train\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 4 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 5 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 6 train\r\nEpoch 4/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 7 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 6 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 8 train\r\nEpoch 5/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 9 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 7 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 117, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 110, in main\r\n    callbacks= callbacks_list)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 98, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 10 train\r\n```\r\n\r\n**Log of first 5 epochs with traceback.print_stacks() when no callbacks have been given to the fit function.**\r\n\r\n```\r\nEpoch 1/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 1 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 1 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 2 train\r\nEpoch 2/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 3 train\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 2 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 3 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 4 train\r\nEpoch 3/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 5 train\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 4 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 5 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 6 train\r\nEpoch 4/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 7 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 6 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 8 train\r\nEpoch 5/15\r\n  File \"/usr/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 876, in _run\r\n    self.sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 9 train\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1133, in fit\r\n    return_dict=True)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1373, in evaluate\r\n    for _, iterator in data_handler.enumerate_epochs():  # Single epoch.\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 7 val\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/oddity/code/Train.py\", line 116, in <module>\r\n    main()\r\n  File \"/home/oddity/code/Train.py\", line 109, in main\r\n    epochs=15)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1086, in fit\r\n    for epoch, iterator in data_handler.enumerate_epochs():\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1145, in enumerate_epochs\r\n    self._adapter.on_epoch_end()\r\n  File \"/home/oddity/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 953, in on_epoch_end\r\n    self._keras_sequence.on_epoch_end()\r\n  File \"/home/oddity/code/DataGenFastest.py\", line 99, in on_epoch_end\r\n    traceback.print_stack()\r\ncounted 10 train\r\n``` \r\n\r\n", "comments": ["@WikkAI \r\nCan you please provide complete indented code with dependencies, or if possible share a colab gist with error reported.", "@Saduf2019 \r\nThis google colab has a simple generator that generates random samples and a very simple convolutional model. It shows that the on_epoch_end() function is being called multiple times just as in my examples above. The google colab file is running Tensorflow 2.4.0 but it is producing the same behavior as my example above (which was running 2.3.0). I hope this google colab file is what you had in mind. \r\n\r\nhttps://colab.research.google.com/drive/1GmE0gb8cTTAS5TppiH_uEcjhbiGD48ve?usp=sharing", "@WikkAI \r\nI ran the code shared on nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/9c42a0fbd1adffe56934f889d727895f/untitled488.ipynb), and let us know if it confirms your issue.", "It is calling the on_epoch_end() function twice. However, on tensorflow 2.3.0 and 2.4.0 the validation generator would only sometimes call the function twice and not all of the time like in this version. This unpredictability is the biggest issue for me as it cant be solved by using a counter. The unpredictability of the validation generator does not seem present in the code you shared. I hope this makes sense.", "Still an issue in TF nightly version 2.6 as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/67395c313decb43f28bfedb14655a138/untitled90.ipynb).Thanks!", "Having the exact same issue. Set `workers=1` seems to suppress this behaviour.\r\n\r\n@jvishnuvardhan Any updates? Thank you!"]}, {"number": 45958, "title": "Performance discrepency in an integer quantized model ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am integer quantizing (full-integer) the [EAST model](https://arxiv.org/abs/1704.03155) trained on COCO-text dataset. Results are very inconsistent with the integer quantized model with respect to the other variants such as dynamic-range and float16. I get the following results with both dynamic-range and float16 (which is consistent with the original model too) - \r\n\r\n![image](https://user-images.githubusercontent.com/22957388/103078882-cc7ecc80-45f8-11eb-8392-e2db4cf515cb.png)\r\n\r\nBut with the integer quantized model, I get - \r\n\r\n![download](https://user-images.githubusercontent.com/22957388/103078920-e3bdba00-45f8-11eb-9f15-3b846dbc189b.png)\r\n\r\nDuring inference with the integer quantized model, I have also scaled the input image properly. My question is do I need to scale back the predictions before I post-process them?  \r\n\r\n**Describe the expected behavior**\r\n\r\nThe results of the integer-quantized model should be consistent. \r\n\r\n**Standalone code to reproduce the issue**\r\n \r\nConversion and inference Colab Notebook - https://colab.research.google.com/gist/sayakpaul/0438ad116871cd860d0a25dcc9b21805/east_tflite.ipynb. ", "comments": ["Happens with other images too. Here's an example - \r\n\r\n### Dynamic-range and float16 results\r\n\r\n![image (1)](https://user-images.githubusercontent.com/22957388/103079158-5cbd1180-45f9-11eb-8e27-f1effd391a20.png)\r\n\r\n### Integer results\r\n\r\n![download (1)](https://user-images.githubusercontent.com/22957388/103079185-65154c80-45f9-11eb-8d93-11a5a38e5220.png)\r\n\r\n"]}, {"number": 45949, "title": "TFLiteTransferConverter (tfltransfer) for model personalization cannot convert a model on 'keras_model_head.py': AttributeError: 'list' object has no attribute 'values' line 51", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: 750 ti 2GB\r\n\r\n**Describe the current behavior**\r\nI am following the model personalization post available on the TensorFlow GitHub repository (https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/README.md) to build a custom trainable model on a mobile device. I expect to have the custom (or even the provided example) model for the 'head' can be converted via the following code:\r\n`converter = TFLiteTransferConverter(4,\r\n                                    base,\r\n                                    heads.KerasModelHead(head),\r\n                                    optimizers.SGD(3e-2),\r\n                                    train_batch_size=20)`\r\n\r\nBut the library gets stuck on `heads.KerasModelHead(head)` line and produces the following error:\r\n\r\n```\r\n/tfltransfer/heads/keras_model_head.py in __init__(self, keras_model)\r\n     49     self._predict_signature = loaded_model.signatures['serving_default']\r\n     50 \r\n---> 51     input_def = next(self._predict_signature.inputs.values().__iter__())\r\n     52     self._input_shape = tuple(\r\n     53         dim.size for dim in input_def.tensor_shape.dim[1:])\r\n\r\nAttributeError: 'list' object has no attribute 'values'\r\n```\r\n\r\nI have tried both the provided example and a custom model on different systems including Google Colab. The issue cannot be resolved.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe converter should produce the converted model files to be used on the device. The converter should produce the following file based on a custom base and head models.\r\n```\r\nbottleneck.tflite\r\ninference.tflite\r\ninitialize.tflite\r\noptimizer.tflite\r\ntrain_head.tflite\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nThe following is the example code obtained from the TensorFlow Github tested on Google Colab.\r\n```\r\nimport tensorflow as tf\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive')\r\nnb_path = '/content/drive/MyDrive/ML/converter/'\r\nsys.path.insert(0,nb_path)\r\nfrom tfltransfer import bases\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.regularizers import l2\r\nfrom tfltransfer import bases\r\nfrom tfltransfer import heads\r\nfrom tfltransfer import optimizers\r\nfrom tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\r\nbase = bases.MobileNetV2Base(image_size=224)\r\n\r\nhead = tf.keras.Sequential([\r\nlayers.Flatten(input_shape=(7, 7, 1280)),\r\nlayers.Dense(\r\nunits=32,\r\nactivation='relu',\r\nkernel_regularizer=l2(0.01),\r\nbias_regularizer=l2(0.01)),\r\nlayers.Dense(\r\nunits=4,\r\nactivation='softmax',\r\nkernel_regularizer=l2(0.01),\r\nbias_regularizer=l2(0.01)),\r\n])\r\nhead.compile(loss='categorical_crossentropy', optimizer='sgd')\r\nconverter = TFLiteTransferConverter(4,\r\nbase,\r\nheads.KerasModelHead(head),\r\noptimizers.SGD(3e-2),\r\ntrain_batch_size=20)\r\nconverter.convert_and_save('custom_keras_model')\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n```\r\ntfltransfer/heads/keras_model_head.py\", line 51, in __init__\r\n    input_def = next(self._predict_signature.inputs.values().__iter__())\r\nAttributeError: 'list' object has no attribute 'values'\r\n```\r\n\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/58091b60823af37b3eaaa5c5cb83168c/45949.ipynb). Thanks!", "Yes, I could reproduce it too. It was due to the recent removing experimental.export_saved_model(). Please let me work on it.", "It is due to the latest keras API update (e.g. removed experimental saved model function), so I am working on huge internal upgrade from TFv1 to TFv2 in my model personalization library. Please stay tuned.", "Is there any update as to the timeline of the upgrade?", "> It is due to the latest keras API update (e.g. removed experimental saved model function), so I am working on huge internal upgrade from TFv1 to TFv2 in my model personalization library. Please stay tuned.\r\n\r\nsome issue here,@jaeyoo\r\nis there any useful old tensorflow version or keras version?", "@jaeyoo \r\nHello \r\nis here any update? \r\n", "For temporary workaround, please rollback the PR.\r\n\r\n```\r\ngit clone https://github.com/tensorflow/examples\r\ncd examples; git reset --hard 0e7a63baa06c0afd133a98eee95457533b7f9dc1\r\nsed -i \"s/tf.keras.experimental.export_saved_model/tf.compat.v1.keras.experimental.export_saved_model/g\" examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py\r\n```\r\n", "Was able to reproduce the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/c87052933d0434eecdce861fd2683241/untitled189.ipynb)..Thanks !", "@jaeyoo \r\nHi any update to the fix still?\r\nWas able to reproduce the issue with tfv2.7.0-dev20210919"]}, {"number": 45946, "title": "Tensorflow operations : Invalid data type according to Tensorflow Profiler", "body": "Hi,\r\n\r\nI use Tensorflow 2.5 installed from source with Cuda 11.1 and Cudnn 8 on Ubuntu 20.04. My GPU is a Nvidia Quadro RTX 6000. \r\n\r\nI have got Out of Memory problems with the GPU and the training of a CycleGAN model. In order to track memory leaks in my code, I have run it with [profiler trace](https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/Trace) and I can now see with Tensorboard strange results in the memory breakdown table (memory profile tab). Indeed, some Tensorflow operations have \"INVALID\" data type, no region type and no shape. This suggests there are bugs with some Tensorflow operations.\r\n\r\nAbove I put a minimal code sample which reproduces this kind of error.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport keras\r\n\r\nIMAGE_SHAPE = [256,256,3]\r\n\r\ndef Discriminator():\r\n    return keras.Sequential([\r\n        keras.layers.Flatten(input_shape=IMAGE_SHAPE),\r\n        keras.layers.Dense(1, activation=\"sigmoid\")\r\n    ])\r\n\r\ndef Generator():\r\n    return keras.Sequential([\r\n        keras.layers.Conv2D(filters=IMAGE_SHAPE[-1], kernel_size=3, strides=1, padding=\"same\", use_bias=False,\r\n                           input_shape=IMAGE_SHAPE)\r\n    ])\r\n\r\ngenerator_BtoA = Generator()\r\ndiscriminator_A = Discriminator()\r\n\r\nloss_obj = keras.losses.MeanSquaredError()\r\n\r\ndiscriminator_A_optimizer = keras.optimizers.Adam(0.0002)\r\n\r\nBATCH_SIZE = 32\r\n\r\n@tf.function\r\ndef train_step():\r\n    # training discriminator\r\n    imagesA = tf.random.uniform([BATCH_SIZE]+IMAGE_SHAPE)\r\n    imagesB = tf.random.uniform([BATCH_SIZE]+IMAGE_SHAPE)\r\n    fakesA = generator_BtoA(imagesB, training=False)\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        disc_fakesA = discriminator_A(fakesA, training=True)\r\n        discA_loss = loss_obj(tf.zeros_like(disc_fakesA), disc_fakesA)\r\n    gradients_discA = tape.gradient(discA_loss, discriminator_A.trainable_variables)\r\n    discriminator_A_optimizer.apply_gradients(zip(gradients_discA, discriminator_A.trainable_variables))\r\n\r\n\r\nfrom tensorflow.profiler.experimental import Trace as Trace_profiler, start as start_profiler, stop as stop_profiler\r\n\r\nstart_profiler(\"my_logdir/\")\r\nwith Trace_profiler(\"train\", step_num=1, _r=-1):\r\n    train_step()\r\nstop_profiler()\r\n```\r\n\r\nWith this code, I get the following results in the memory profile tab :\r\n\r\nOp Name | Allocation Size (GiBs) | Requested Size (GiBs) | Occurrences | Region type | Data type | Shape\r\n-- | -- | -- | -- | -- | -- | --\r\nsequential/conv2d/Conv2D | 0.227 | 0.227 | 1 | \u00a0 | INVALID\r\nsequential/conv2d/Conv2D | 0.039 | 0.039 | 1 | \u00a0 | INVALID\r\nsequential/conv2d/Conv2D | 0.023 | 0.023 | 1 | output | float | [32,3,256,256]\r\nsequential/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer | 0.023 | 0.023 | 1 | output | float | [32,3,256,256]\r\n\r\n\r\nHow do you interprete these results ?\r\n", "comments": ["@RocaVincent,\r\n> I have got Out of Memory problems with the GPU and the training of a CycleGAN model.\r\n\r\nTo resolve the out of memory error, please try any one of the methods to limit GPU memory as shown in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth).\r\n\r\n\r\nAlso, please go through these guides for [tensorboard profiling tool](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) and [memory profile summary](https://www.tensorflow.org/guide/profiler#memory_profile_summary) for more information. Thanks!", "@amahendrakar \r\n\r\n> To resolve the out of memory error, please try any one of the methods to limit GPU memory as shown in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth).\r\n\r\nI have already tried to allow memory growthing but there is still the problems.\r\n \r\n> Also, please go through these guides for [tensorboard profiling tool](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) and [memory profile summary](https://www.tensorflow.org/guide/profiler#memory_profile_summary) for more information.\r\n\r\nThat's what I've done and that's what I've explained in the first post with in addition a minimal code sample to reproduce the results with the profiler, you may have missed it.\r\n\r\nI'm curious to know if people get the same results with this code (run the code and access the dir *my_logdir* with the profiler).\r\n", "I did not face any out of memory errors on running the code, however I did get similar results with the memory profiler on TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/efd7fe9f22efd676bf9e08dea1bbc573/45946.ipynb). \r\n\r\n![Screenshot 2020-12-24 at 11 18 40 PM](https://user-images.githubusercontent.com/57165142/103173584-f4349580-4881-11eb-8d57-1b5a63982fc1.png)\r\n\r\nThanks!", "@RocaVincent,\r\nCan you please respond to the above comment? Thanks! ", "@rmothukuru\r\nMy issue is about the strange results that the profiler gives with this convolutions with invalid data type, no shape and no region type. Of course, I haven't OOM errors with this simple code either, but it points out some problems which may cause OOM with bigger models.", "Hi, \r\nI think I replied you regarding this issue in https://github.com/tensorflow/profiler/issues/255\r\nWe are still investigating (delayed due to the holidays).\r\nthanks", "I have this issue with Conv1D also. My model should be using under 200MB, but I have INVALID shape when profiling and the heap usage spikes to 4GB.", "Was able to replicate the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/5c8e82c1710e65a412c03ca82743b06b/untitled188.ipynb)..Thanks !", "> I have this issue with Conv1D also. My model should be using under 200MB, but I have INVALID shape when profiling and the heap usage spikes to 4GB.\r\n\r\nGot almost exactly the same. With Conv2D. It causes that 4go of memory are fried, even if the network need no more than 200Mo to run...\r\n\r\n![image](https://user-images.githubusercontent.com/12199444/133930589-8ee0aeb7-7b7a-4587-98b8-ca8a82250ec8.png)\r\n![image](https://user-images.githubusercontent.com/12199444/133930604-2f90851e-550e-40a6-8594-b35362595b81.png)\r\n\r\nDoes anybody have found a solution or an idea of that ? \r\n", "I am running TensorFlow 2.4.3 and see the same issue. Has anybody found a solution or an idea for this issue?\r\n![image](https://user-images.githubusercontent.com/4673843/138609552-ba266073-0302-4f98-b491-d415135a2152.png)\r\n", "Has similar issue, any update? @ckluk-github "]}, {"number": 45943, "title": "[C++][FATAL]Calling FreezeSavedModel in cc/tools/saved_model.h causes protobuf::FatalException", "body": "**Please fix this one ASAP. A machine learning API that can not properly export the trained model is fatal.**\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): gcc-10\r\n- CUDA/cuDNN version: cuda 11 installed but not used\r\n- GPU model and memory: mx150\r\n- protobuf version: 3.9.2 / 3.10.1 (tried both, former one is the designated version), 3.14.0 simply does not compile\r\n- abseil version: abseil-cpp-20200225 with `absl/bas/option.h` configured as the one attached at the end of the code.\r\n\r\n**Describe the current behavior**\r\nWhenever FreezeSavedModel function is called in the code, tensorflow::ClientSession cannot execute properly.\r\nThings work absolutely fine if FreezeSavedModel function is commented out.\r\nError message shown.\r\n```\r\n2020-12-23 10:10:29.483878: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-23 10:10:29.502660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099940000 Hz\r\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/map.h:1060] CHECK failed: it != end(): key not found: Reciprocal\r\nterminate called after throwing an instance of 'google::protobuf::FatalException'\r\n  what():  CHECK failed: it != end(): key not found: Reciprocal\r\nAborted (core dumped)\r\n```\r\n\r\n**Describe the expected behavior**\r\nExecute without error.\r\n```\r\n2020-12-23 10:01:51.025954: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-23 10:01:51.046594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099940000 Hz\r\nTensor<type: float shape: [1,150,150,3] values: [[[0.34117648 0.313725501 0.24313727]]]...>\r\nTensor<type: float shape: [150,150,3] values: [[0.34117648 0.313725501 0.24313727]]...>\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nHeader file for CatDogCnn\r\n```\r\n/**\r\n * @file CatDogCnn.hpp\r\n * @author Hung-Tien Huang (paperbus72@gmail.com)\r\n * @brief A simplified AlexNet for classifying cats and dogs.\r\n * @version 0.1\r\n * @date 2020-12-16\r\n *\r\n * @copyright Copyright (c) 2020\r\n *\r\n */\r\n#ifndef INCLUDE_TUTORIAL_02_CAT_DOG_CNN_CAT_DOG_CNN_H_\r\n#define INCLUDE_TUTORIAL_02_CAT_DOG_CNN_CAT_DOG_CNN_H_\r\n\r\n#include <tensorflow/cc/client/client_session.h>\r\n#include <tensorflow/cc/framework/gradients.h>\r\n#include <tensorflow/cc/ops/image_ops.h>\r\n#include <tensorflow/cc/ops/standard_ops.h>\r\n#include <tensorflow/cc/ops/state_ops.h>\r\n#include <tensorflow/cc/tools/freeze_saved_model.h>\r\n#include <tensorflow/core/framework/tensor.h>\r\n#include <tensorflow/core/lib/io/path.h>\r\n#include <tensorflow/core/platform/types.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include <tensorflow/core/summary/summary_file_writer.h>\r\n\r\n#include <filesystem>\r\n#include <fstream>\r\n#include <iostream>\r\n#include <map>\r\n#include <memory>\r\n#include <string>\r\n#include <tuple>\r\n#include <unordered_set>\r\n#include <variant>\r\n#include <vector>\r\n\r\nnamespace tensorflow_tutorial {\r\nclass CatDogCnn {\r\n public:\r\n  /**\r\n   * @brief Construct a new Cat Dog Cnn object. Assume images are square.\r\n   *\r\n   * @param image_size the size of image\r\n   * @param num_of_channels number of channels\r\n   */\r\n  CatDogCnn(const int image_size, const int num_of_channels);\r\n  /**\r\n   * @brief Create a Graph for Input Image. If unstack is false, the\r\n   * output_image_tensor_node_ will have shape of [height, width, channel]. If\r\n   * unstack is true, the ouput_image_tensor_node_ will have shape of [batch,\r\n   * height, width, channel]. In addition, only the first element will be stored\r\n   * to output_image_tensor_node_\r\n   *\r\n   * @param unstack unstack or not (set to true if batch mode, false otherwise)\r\n   * @return tensorflow::Status of the current scope\r\n   */\r\n  tensorflow::Status CreateGraphForInputImage(bool unstack);\r\n\r\n  /**\r\n   * @brief Convert an image to a tensor\r\n   *\r\n   * @param path_to_image path to the jpeg file to be converted\r\n   * @param out_tensor pointer to output tensor\r\n   * @return tensorflow::Status of the current scope\r\n   */\r\n  tensorflow::Status ConvertImageToTensor(\r\n      const std::filesystem::path& path_to_image,\r\n      tensorflow::Tensor* out_tensor);\r\n\r\n  /**\r\n   * @brief Load all the image in a directory represented by dataset_root_path.\r\n   * std::vector<std::pair<std::string, float>> folder_label is a vector of\r\n   * [\"string representation of class\", and float representation of the class].\r\n   * std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>\r\n   * image_tensors is [\"tensor representation of an image\", type of class in\r\n   * float, and the path to the actual image file]; its content will get cleared\r\n   * prior to loading\r\n   *\r\n   * @param dataset_root_path path to the dataset's root folder\r\n   * @param folder_label reference to the manually assigned type and each type's\r\n   * numerical representation; label string MUST match the actual folder name\r\n   * @param image_tensors pointer to the vector which images are to be stored\r\n   * @return tensorflow::Status of the current scope\r\n   */\r\n  tensorflow::Status LoadDataset(\r\n      const std::filesystem::path& dataset_root_path,\r\n      const std::vector<std::pair<std::string, float>>& folder_label,\r\n      std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>*\r\n          image_tensors);\r\n\r\n  /**\r\n   * @brief Load entire dataset into memory and chunk them into batches.\r\n   *\r\n   * @param dataset_root_path path to the dataset's root folder\r\n   * @param folder_label reference to the manually assigned type and each type's\r\n   * numerical representation; label string MUST match the actual folder name\r\n   * @param batch_size number of elements per batch\r\n   * @param image_batch pointer to a vector of all image batches\r\n   * @param label_batch pointer to a vector of all label batches\r\n   * @return tensorflow::Status of the current scope\r\n   */\r\n  tensorflow::Status LoadBatach(\r\n      const std::filesystem::path& dataset_root_path,\r\n      const std::vector<std::pair<std::string, float>>& folder_labels,\r\n      const size_t batch_size, std::vector<tensorflow::Tensor>* image_batch,\r\n      std::vector<tensorflow::Tensor>* label_batch);\r\n\r\n  /**\r\n   * @brief returns an input object that performs Gloron/Xavier normal\r\n   * initialization\r\n   *\r\n   * @param scope\r\n   * @param in_chan\r\n   * @param out_chan\r\n   * @param filter_side\r\n   * @return tensorflow::Input  an input node that returns initialized\r\n   * parameters\r\n   */\r\n  tensorflow::Input GlorotUniformInitializer(const tensorflow::Scope& scope,\r\n                                             const int input_channels,\r\n                                             const int output_channels,\r\n                                             const int filter_side = 0);\r\n\r\n  /**\r\n   * @brief Add convolution layer with relu and max pool. Weights are\r\n   * initialized with Glorot/Xavier univorm initialization.\r\n   *\r\n   * @param layer_index\r\n   * @param scope\r\n   * @param input_channels\r\n   * @param output_channels\r\n   * @param filter_side\r\n   * @param input\r\n   * @return tensorflow::Input\r\n   */\r\n  tensorflow::Output AddConvLayer(const std::string& layer_index,\r\n                                  const tensorflow::Scope& scope,\r\n                                  const int input_channels,\r\n                                  const int output_channels,\r\n                                  const int filter_side,\r\n                                  const tensorflow::Input& input);\r\n\r\n  /**\r\n   * @brief Add fully connected layer with or withot activation based on bool\r\n   * need_activation variable.\r\n   *\r\n   * @param layer_index\r\n   * @param scope\r\n   * @param input_channels\r\n   * @param output_channels\r\n   * @param need_activation whether to append additional Relu at the end\r\n   * @param input\r\n   * @return tensorflow::Input\r\n   */\r\n  tensorflow::Output AddDenseLayer(const std::string& layer_index,\r\n                                   const tensorflow::Scope& scope,\r\n                                   const int input_channels,\r\n                                   const int output_channels,\r\n                                   const bool need_activation,\r\n                                   const tensorflow::Input& input);\r\n\r\n  /**\r\n   * @brief Create a CNN Graph\r\n   *\r\n   * @param filter_side\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status CreateGraphForCnn(const int filter_side);\r\n\r\n  /**\r\n   * @brief Create an Optimization(backpropagation) graph.\r\n   *\r\n   * @param learning_rate\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status CreateGraphForOptimization(const float learning_rate);\r\n\r\n  /**\r\n   * @brief Use the image_batch and label_batch to train the neural network.\r\n   *\r\n   * @param image_batch\r\n   * @param label_batch\r\n   * @param results\r\n   * @param loss\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status Train(const tensorflow::Tensor& image_batch,\r\n                           const tensorflow::Tensor& label_batch,\r\n                           std::vector<float>* results, float* loss);\r\n\r\n  /**\r\n   * @brief Use the image_batch and label_batch provided to validate the neural\r\n   * network.\r\n   *\r\n   * @param image_batch\r\n   * @param label_batch\r\n   * @param results\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status Validate(const tensorflow::Tensor& image_batch,\r\n                              const tensorflow::Tensor& label_batch,\r\n                              std::vector<float>* results);\r\n\r\n  /**\r\n   * @brief Executes all the Assgin Variable nodes\r\n   *\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status Initialize();\r\n\r\n  /**\r\n   * @brief Freeze the model\r\n   *\r\n   * @param path\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status FreezeModel(const std::filesystem::path& path);\r\n\r\n  /**\r\n   * @brief Load a frozen model from file.\r\n   *\r\n   * @param path\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status LoadFrozenModel(const std::filesystem::path& path);\r\n\r\n  /**\r\n   * @brief Predict from frozen model\r\n   *\r\n   * @param image\r\n   * @param result\r\n   * @return tensorflow::Status\r\n   */\r\n  tensorflow::Status PredictFromFrozen(const tensorflow::Tensor& image,\r\n                                       int* result);\r\n\r\n private:\r\n  const int kImageSize;      // assume squre picture\r\n  const int kNumOfChannels;  // RGB\r\n  // load image\r\n  tensorflow::Scope load_image_scope_;\r\n  tensorflow::Output input_image_filename_node_;\r\n  tensorflow::Output output_image_tensor_node_;\r\n  // networks\r\n  tensorflow::Scope network_root_scope_;\r\n  std::unique_ptr<tensorflow::ClientSession> train_session_ptr_;\r\n  std::unique_ptr<tensorflow::Session> frozen_session_ptr_;\r\n  std::map<std::string, tensorflow::Output> variables_;\r\n  std::map<std::string, tensorflow::TensorShape> variable_shapes_;\r\n  std::map<std::string, tensorflow::Output> variable_assign_nodes_;\r\n  // cnn variables\r\n  tensorflow::Output input_batch_tensor_node_;\r\n  tensorflow::Output input_labels_tensor_node_;\r\n  tensorflow::Output drop_rate_node_;\r\n  tensorflow::Output skip_drop_node_;\r\n  tensorflow::Output output_classification_;\r\n  tensorflow::Output squared_difference_node_;\r\n  tensorflow::Output output_loss_logits_node_;\r\n  const std::string kInputNodeName;\r\n  const std::string kInputDropRateNodeName;\r\n  const std::string kInputSkipDropNodeName;\r\n  const std::string kOutputClassificationNodeName;\r\n  // back propagation\r\n  std::vector<tensorflow::Operation> adam_operations;\r\n  std::vector<tensorflow::Output> weights_biases_;\r\n\r\n  /**\r\n   * @brief Shuffle the dataset randomly.\r\n   *\r\n   * @param image_tensors\r\n   */\r\n  static void ShuffleSet(\r\n      std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>*\r\n          image_tensors);\r\n};\r\n}  // namespace tensorflow_tutorial\r\n\r\n#endif  // INCLUDE_TUTORIAL_02_CAT_DOG_CNN_CAT_DOG_CNN_H_\r\n```\r\nCatDogCnn.cpp\r\n```\r\n/**\r\n * @file CatDogCnn.cpp\r\n * @author Hung-Tien Huang (paperbus72@gmail.com)\r\n * @brief\r\n * @version 0.1\r\n * @date 2020-12-16\r\n *\r\n * @copyright Copyright (c) 2020\r\n *\r\n */\r\n\r\n#include <tensorflow_tutorial/tutorial_02/CatDogCnn/CatDogCnn.hpp>\r\n\r\nnamespace tensorflow_tutorial {\r\n\r\nCatDogCnn::CatDogCnn(const int image_size, const int num_of_channels)\r\n    : kImageSize{image_size},\r\n      kNumOfChannels{num_of_channels},\r\n      load_image_scope_{tensorflow::Scope::NewRootScope()},\r\n      network_root_scope_{tensorflow::Scope::NewRootScope()},\r\n      kInputNodeName{\"input_batch\"},\r\n      kInputDropRateNodeName{\"drop_rate\"},\r\n      kInputSkipDropNodeName{\"skip_drop\"},\r\n      kOutputClassificationNodeName{\"output_classification\"} { /*empty*/\r\n}\r\n\r\ntensorflow::Status CatDogCnn::CreateGraphForInputImage(bool unstack) {\r\n  input_image_filename_node_ = tensorflow::ops::Placeholder{\r\n      load_image_scope_.NewSubScope(\"input_file_name\"),\r\n      tensorflow::DataType::DT_STRING};\r\n  tensorflow::ops::ReadFile read_file_node{\r\n      load_image_scope_.NewSubScope(\"read_file\"), input_image_filename_node_};\r\n  tensorflow::ops::DecodeJpeg decode_image_node{\r\n      load_image_scope_.NewSubScope(\"decode_image\"), read_file_node};\r\n  // convert each pixel to float\r\n  tensorflow::ops::Cast cast_float_node{\r\n      load_image_scope_.NewSubScope(\"cast_float\"), decode_image_node,\r\n      tensorflow::DataType::DT_FLOAT};\r\n  // [height, width channel] -> [batch, height, width, channel]\r\n  tensorflow::ops::ExpandDims expand_batch_dim_node{\r\n      load_image_scope_.NewSubScope(\"exapnd_batch_dim\"), cast_float_node, 0};\r\n  // resize image to square\r\n  tensorflow::ops::ResizeBilinear resize_image_node(\r\n      load_image_scope_.NewSubScope(\"resize\"), expand_batch_dim_node,\r\n      {kImageSize, kImageSize});\r\n  // divide each pixel by 255 so that each pixel is [0, 1]\r\n  tensorflow::ops::Div normalize_image_node{\r\n      load_image_scope_.NewSubScope(\"normalize_image\"),\r\n      resize_image_node,\r\n      {255.f}};\r\n  if (unstack) {\r\n    /**\r\n     * @todo Unstack has documentation mismach. According to documentation, it\r\n     * should be unstack along 0th axis. However, doing so cause segmentation\r\n     * fault. When unstack along 1st axis, it is the expected behaviour when\r\n     * unstack along 0th axis\r\n     *\r\n     */\r\n    // unstack along batch axis\r\n    // array of [height, width, channel]\r\n    tensorflow::ops::Unstack unstack_image_node{\r\n        load_image_scope_.NewSubScope(\"unstack_image\"), normalize_image_node,\r\n        1};\r\n    output_image_tensor_node_ = unstack_image_node[0];\r\n  } else {\r\n    output_image_tensor_node_ = normalize_image_node;\r\n  }\r\n  return load_image_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::ConvertImageToTensor(\r\n    const std::filesystem::path& path_to_image,\r\n    tensorflow::Tensor* out_tensor) {\r\n  if (load_image_scope_.ok() == false) {\r\n    return load_image_scope_.status();\r\n  }\r\n  if (path_to_image.extension().string() != \".jpg\" &&\r\n      path_to_image.extension().string() != \".jpeg\") {\r\n    std::cerr << path_to_image.string() << \" is NOT *.jpeg\" << std::endl;\r\n    /**\r\n     * @todo cannot create status with error message. change back to\r\n     * tensorflow::errors::InvalidArgument when tensorflow fix the bug\r\n     *\r\n     */\r\n    // return tensorflow::errors::InvalidArgument(\"Image must be jpeg encoded\");\r\n    // return tensorflow::Status{tensorflow::errors::Code::INVALID_ARGUMENT,\r\n    //                           err_msg,};\r\n    return tensorflow::Status::OK();\r\n  }\r\n  std::vector<tensorflow::Tensor> out_tensors;\r\n  tensorflow::ClientSession client_session{load_image_scope_};\r\n  TF_CHECK_OK(\r\n      client_session.Run({{input_image_filename_node_, path_to_image.string()}},\r\n                         {output_image_tensor_node_}, &out_tensors));\r\n  (*out_tensor) = std::move(out_tensors[0]);\r\n  return load_image_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::LoadDataset(\r\n    const std::filesystem::path& dataset_root_path,\r\n    const std::vector<std::pair<std::string, float>>& folder_labels,\r\n    std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>*\r\n        image_tensors) {\r\n  image_tensors->clear();\r\n  // for each class\r\n  for (const std::pair<std::string, float>& current_class : folder_labels) {\r\n    // create path to the curren class directory\r\n    const std::filesystem::path current_class_path =\r\n        dataset_root_path / current_class.first;\r\n    // if the current class directory exists\r\n    if (std::filesystem::exists(current_class_path)) {\r\n      // for each file inside the current class directory\r\n      for (const std::filesystem::directory_entry& p :\r\n           std::filesystem::directory_iterator{current_class_path}) {\r\n        const std::filesystem::path& current_image_path = p.path();\r\n        // continue if not a jpeg file\r\n        if (current_image_path.extension().string() != \".jpeg\" &&\r\n            current_image_path.extension().string() != \".jpg\") {\r\n          std::cerr << current_image_path << \" is NOT a jpeg\" << std::endl;\r\n          continue;\r\n        }\r\n        tensorflow::Tensor current_image_tensor;\r\n        TF_RETURN_IF_ERROR(\r\n            ConvertImageToTensor(current_image_path, &current_image_tensor));\r\n        image_tensors->emplace_back(\r\n            std::tuple<tensorflow::Tensor, float, std::filesystem::path>{\r\n                std::move(current_image_tensor), current_class.second,\r\n                std::move(current_image_path)});\r\n      }\r\n      ShuffleSet(image_tensors);\r\n      image_tensors->shrink_to_fit();\r\n    } else {\r\n      std::cerr << current_class_path << \" does NOT exists\" << std::endl;\r\n      /**\r\n       * @todo status is not ok!!\r\n       *\r\n       */\r\n      return tensorflow::Status::OK();\r\n    }\r\n  }\r\n  return load_image_scope_.status();\r\n}\r\nvoid CatDogCnn::ShuffleSet(\r\n    std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>*\r\n        image_tensors) {\r\n  uint_fast32_t seed = static_cast<uint_fast32_t>(\r\n      std::chrono::system_clock::now().time_since_epoch().count());\r\n  std::shuffle(image_tensors->begin(), image_tensors->end(),\r\n               std::mt19937{seed});\r\n}\r\n\r\ntensorflow::Status CatDogCnn::LoadBatach(\r\n    const std::filesystem::path& dataset_root_path,\r\n    const std::vector<std::pair<std::string, float>>& folder_labels,\r\n    const size_t batch_size, std::vector<tensorflow::Tensor>* image_batch,\r\n    std::vector<tensorflow::Tensor>* label_batch) {\r\n  // clear batch prior to begin\r\n  image_batch->clear();\r\n  label_batch->clear();\r\n  // load entire dataset in\r\n  std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>\r\n      entire_dataset;\r\n  TF_RETURN_IF_ERROR(\r\n      LoadDataset(dataset_root_path, folder_labels, &entire_dataset));\r\n  // start to chunk batch\r\n  auto begin = entire_dataset.begin();\r\n  auto end = entire_dataset.begin() + batch_size;\r\n  size_t num_of_batches = entire_dataset.size() / batch_size;\r\n  if (num_of_batches * batch_size < entire_dataset.size()) {\r\n    num_of_batches = num_of_batches + 1;\r\n  }\r\n  for (size_t i = 0; i < num_of_batches; ++i) {\r\n    // if end exceeds the entire_dataset.end()\r\n    if (end > entire_dataset.end()) {\r\n      end = entire_dataset.end();\r\n    }\r\n    // break Tensor and label into two std::vector\r\n    std::vector<tensorflow::Input> current_batch_image_v{};\r\n    std::vector<tensorflow::Input> current_batch_label_v{};\r\n    for (auto curr = begin; curr < end; ++curr) {\r\n      current_batch_image_v.emplace_back(std::move(std::get<0>(*curr)));\r\n      tensorflow::Tensor tmp{tensorflow::DataType::DT_FLOAT, {1}};\r\n      tmp.scalar<float>()(0) = std::get<1>(*curr);\r\n      current_batch_label_v.emplace_back(std::move(tmp));\r\n    }\r\n    // convert std::vector to tensorflow::InputList\r\n    tensorflow::InputList current_batch_image{current_batch_image_v};\r\n    tensorflow::InputList current_batch_label{current_batch_label_v};\r\n    // stack all the image in current batch into one big tensor\r\n    tensorflow::Scope root = tensorflow::Scope::NewRootScope();\r\n    tensorflow::ops::Stack stack_current_image_batch_node{root,\r\n                                                          current_batch_image};\r\n    tensorflow::ops::Stack stack_current_label_batch_node{root,\r\n                                                          current_batch_label};\r\n    TF_CHECK_OK(root.status());\r\n    tensorflow::ClientSession client_session{root};\r\n    std::vector<tensorflow::Tensor> current_batch;\r\n    TF_CHECK_OK(client_session.Run(\r\n        {stack_current_image_batch_node, stack_current_label_batch_node},\r\n        &current_batch));\r\n    image_batch->emplace_back(std::move(current_batch[0]));\r\n    label_batch->emplace_back(std::move(current_batch[1]));\r\n    // increment the entire_dataset being processed\r\n    begin = end;\r\n    // break if begin reaches the end\r\n    if (begin == entire_dataset.end()) {\r\n      break;\r\n    }\r\n    end = end + batch_size;\r\n  }\r\n  return tensorflow::Status::OK();\r\n}\r\n\r\ntensorflow::Input CatDogCnn::GlorotUniformInitializer(\r\n    const tensorflow::Scope& scope, const int input_channels,\r\n    const int output_channels, const int filter_side) {\r\n  float std = 0.0f;\r\n  tensorflow::Tensor tensor_shape;\r\n  if (filter_side == 0) {  // dense\r\n    std = std::sqrt(6.0f / (input_channels + output_channels));\r\n    tensor_shape = tensorflow::Tensor{tensorflow::DT_INT64, {2}};\r\n    auto v = tensor_shape.vec<tensorflow::int64>();\r\n    v(0) = input_channels;\r\n    v(1) = output_channels;\r\n  } else {  // conv\r\n    std = std::sqrt(6.0f / (filter_side * filter_side *\r\n                            (input_channels + output_channels)));\r\n    tensor_shape = tensorflow::Tensor{tensorflow::DT_INT64, {4}};\r\n    auto v = tensor_shape.vec<tensorflow::int64>();\r\n    v(0) = filter_side;\r\n    v(1) = filter_side;\r\n    v(2) = input_channels;\r\n    v(3) = output_channels;\r\n  }\r\n  // std::cout << tensor_shape.DebugString() << std::endl;\r\n  // rand_node returns tensor with value [0,1]\r\n  tensorflow::ops::RandomUniform rand_node{scope, tensor_shape,\r\n                                           tensorflow::DT_FLOAT};\r\n  // ([0, 1] - [.5, .5]) * 2.0f = [-1, 1]\r\n  return tensorflow::ops::Multiply{\r\n      scope, tensorflow::ops::Sub{scope, rand_node, 0.5f}, std * 2.0f};\r\n}\r\n\r\ntensorflow::Output CatDogCnn::AddConvLayer(const std::string& layer_index,\r\n                                           const tensorflow::Scope& scope,\r\n                                           const int input_channels,\r\n                                           const int output_channels,\r\n                                           const int filter_side,\r\n                                           const tensorflow::Input& input) {\r\n  const std::string kCurrWeightStr{\"weight_\" + layer_index};\r\n  const std::string kCurrBiasStr{\"bias_\" + layer_index};\r\n  // conv2d weights\r\n  tensorflow::TensorShape shape{filter_side, filter_side, input_channels,\r\n                                output_channels};\r\n  variables_[kCurrWeightStr] =\r\n      tensorflow::ops::Variable{scope.NewSubScope(kCurrWeightStr + \"_var\"),\r\n                                shape, tensorflow::DataType::DT_FLOAT};\r\n  variable_shapes_[kCurrWeightStr] = shape;\r\n  variable_assign_nodes_[kCurrWeightStr] = tensorflow::ops::Assign{\r\n      scope.NewSubScope(kCurrWeightStr + \"_assign\"), variables_[kCurrWeightStr],\r\n      GlorotUniformInitializer(scope, input_channels, output_channels,\r\n                               filter_side)};\r\n  // bias after conv2d\r\n  shape = {output_channels};\r\n  variables_[kCurrBiasStr] =\r\n      tensorflow::ops::Variable{scope.NewSubScope(kCurrBiasStr + \"_var\"), shape,\r\n                                tensorflow::DataType::DT_FLOAT};\r\n  variable_shapes_[kCurrBiasStr] = shape;\r\n  variable_assign_nodes_[kCurrBiasStr] = tensorflow::ops::Assign{\r\n      scope.NewSubScope(kCurrBiasStr + \"_assign\"), variables_[kCurrBiasStr],\r\n      tensorflow::Input::Initializer{0.0f, shape}};\r\n  /**\r\n   * @todo tensorflow::StringPiece is using absl::string_view, which is being\r\n   * redirected to std::string_view and causes error.\r\n   *\r\n   */\r\n  // here have to use assign node as input, otherwise the variables will be\r\n  // uninitialized\r\n  tensorflow::ops::Conv2D conv_2d_node{scope.WithOpName(\"Conv\"),\r\n                                       input,\r\n                                       variables_[kCurrWeightStr],\r\n                                       {1, 1, 1, 1},\r\n                                       \"SAME\"};\r\n  tensorflow::ops::BiasAdd bias_add_node{\r\n      scope.WithOpName(\"bias_add\"), conv_2d_node, variables_[kCurrBiasStr]};\r\n  tensorflow::ops::Relu relu_node{scope.WithOpName(\"relu\"), bias_add_node};\r\n  return tensorflow::ops::MaxPoolV2{scope.WithOpName(\"max_pool\"),\r\n                                    relu_node,\r\n                                    {1, 2, 2, 1},\r\n                                    {1, 2, 2, 1},\r\n                                    \"SAME\"};\r\n}\r\n\r\ntensorflow::Output CatDogCnn::AddDenseLayer(const std::string& layer_index,\r\n                                            const tensorflow::Scope& scope,\r\n                                            const int input_channels,\r\n                                            const int output_channels,\r\n                                            const bool need_activation,\r\n                                            const tensorflow::Input& input) {\r\n  const std::string kCurrWeightStr{\"weight_\" + layer_index};\r\n  const std::string kCurrBiasStr{\"bias_\" + layer_index};\r\n  tensorflow::TensorShape shape{input_channels, output_channels};\r\n  variables_[kCurrWeightStr] =\r\n      tensorflow::ops::Variable{scope.NewSubScope(kCurrWeightStr + \"_var\"),\r\n                                shape, tensorflow::DataType::DT_FLOAT};\r\n  variable_shapes_[kCurrWeightStr] = shape;\r\n  variable_assign_nodes_[kCurrWeightStr] = tensorflow::ops::Assign{\r\n      scope.NewSubScope(kCurrWeightStr + \"_assign\"), variables_[kCurrWeightStr],\r\n      GlorotUniformInitializer(scope, input_channels, output_channels)};\r\n  shape = {output_channels};\r\n  variables_[kCurrBiasStr] =\r\n      tensorflow::ops::Variable{scope.NewSubScope(kCurrBiasStr + \"_var\"), shape,\r\n                                tensorflow::DataType::DT_FLOAT};\r\n  variable_shapes_[kCurrBiasStr] = shape;\r\n  variable_assign_nodes_[kCurrBiasStr] = tensorflow::ops::Assign{\r\n      scope.NewSubScope(kCurrBiasStr + \"_assign\"), variables_[kCurrBiasStr],\r\n      tensorflow::Input::Initializer{0.0f, shape}};\r\n  // here have to use variable assign node as input, otherwise variables will be\r\n  // uninitialized\r\n  tensorflow::ops::MatMul multiply_weight_node{\r\n      scope.WithOpName(\"multiply_weight\"), input, variables_[kCurrWeightStr]};\r\n  tensorflow::ops::Add add_bias_node{scope.WithOpName(\"add_bais\"),\r\n                                     multiply_weight_node,\r\n                                     variables_[kCurrBiasStr]};\r\n  if (need_activation) {\r\n    return tensorflow::ops::Relu{scope.WithOpName(\"relu\"), add_bias_node};\r\n  }\r\n  return add_bias_node;\r\n}\r\n\r\ntensorflow::Status CatDogCnn::CreateGraphForCnn(const int filter_side) {\r\n  input_batch_tensor_node_ = tensorflow::ops::Placeholder(\r\n      network_root_scope_.WithOpName(kInputNodeName),\r\n      tensorflow::DataType::DT_FLOAT);\r\n  drop_rate_node_ = tensorflow::ops::Placeholder{\r\n      network_root_scope_.WithOpName(kInputDropRateNodeName),\r\n      tensorflow::DataType::DT_FLOAT};\r\n  skip_drop_node_ = tensorflow::ops::Placeholder{\r\n      network_root_scope_.WithOpName(kInputSkipDropNodeName),\r\n      tensorflow::DataType::DT_FLOAT};\r\n  // conv 1\r\n  tensorflow::Scope scope_conv1 = network_root_scope_.NewSubScope(\"conv1\");\r\n  int input_channels = kNumOfChannels;\r\n  int output_channels = 32;\r\n  tensorflow::Output pool1_node =\r\n      AddConvLayer(\"1\", scope_conv1, input_channels, output_channels,\r\n                   filter_side, input_batch_tensor_node_);\r\n  int new_side = std::ceil(kImageSize / 2.0f);\r\n\r\n  // conv 2\r\n  tensorflow::Scope scope_conv2 = network_root_scope_.NewSubScope(\"conv2\");\r\n  input_channels = output_channels;\r\n  output_channels = 64;\r\n  tensorflow::Output pool2_node =\r\n      AddConvLayer(\"2\", scope_conv2, input_channels, output_channels,\r\n                   filter_side, pool1_node);\r\n  new_side = std::ceil(new_side / 2.0f);\r\n\r\n  // conv_3\r\n  tensorflow::Scope scope_conv3 = network_root_scope_.NewSubScope(\"conv3\");\r\n  input_channels = output_channels;\r\n  output_channels = 128;\r\n  tensorflow::Output pool3_node =\r\n      AddConvLayer(\"3\", scope_conv3, input_channels, output_channels,\r\n                   filter_side, pool2_node);\r\n  new_side = std::ceil(new_side / 2.0f);\r\n\r\n  // conv_4\r\n  tensorflow::Scope scope_conv4 = network_root_scope_.NewSubScope(\"conv4\");\r\n  input_channels = output_channels;\r\n  output_channels = 128;\r\n  tensorflow::Output pool4_node =\r\n      AddConvLayer(\"4\", scope_conv4, input_channels, output_channels,\r\n                   filter_side, pool3_node);\r\n  new_side = std::ceil(new_side / 2.0f);\r\n\r\n  // flatten\r\n  tensorflow::Scope scope_flatten = network_root_scope_.NewSubScope(\"flatten\");\r\n  int flat_length = new_side * new_side * output_channels;\r\n  tensorflow::ops::Reshape flat_node{\r\n      scope_flatten, pool4_node, {-1, flat_length}};\r\n\r\n  // dropout\r\n  tensorflow::Scope scope_dropout = network_root_scope_.NewSubScope(\"dropout\");\r\n  // [0,1)\r\n  tensorflow::ops::RandomUniform rand_node{\r\n      scope_dropout, tensorflow::ops::Shape{scope_dropout, flat_node},\r\n      tensorflow::DataType::DT_FLOAT};\r\n  // binary = floor(rand + (1 - drop_rate) + skip_drop)\r\n  tensorflow::ops::Floor drop_out_binary_node{\r\n      scope_dropout,\r\n      tensorflow::ops::Add{\r\n          scope_dropout, rand_node,\r\n          tensorflow::ops::Add{\r\n              scope_dropout,\r\n              tensorflow::ops::Sub{scope_dropout, 1.0f, drop_rate_node_},\r\n              skip_drop_node_}}};\r\n  // multiply elementwise\r\n  tensorflow::ops::Multiply apply_drop_out_node{\r\n      scope_dropout.WithOpName(\"apply_drop_out\"),\r\n      tensorflow::ops::Div{scope_dropout, flat_node, drop_rate_node_},\r\n      drop_out_binary_node};\r\n\r\n  // dense1\r\n  input_channels = flat_length;\r\n  output_channels = 512;\r\n  tensorflow::Scope scope_dense1 = network_root_scope_.NewSubScope(\"dense1\");\r\n  tensorflow::Output relu5 =\r\n      AddDenseLayer(\"dense1\", scope_dense1, input_channels, output_channels,\r\n                    false, apply_drop_out_node);\r\n  // dense2\r\n  input_channels = output_channels;\r\n  output_channels = 256;\r\n  tensorflow::Scope scope_dense2 = network_root_scope_.NewSubScope(\"dense2\");\r\n  tensorflow::Output relu6 = AddDenseLayer(\r\n      \"dense2\", scope_dense2, input_channels, output_channels, false, relu5);\r\n  // desne3\r\n  input_channels = output_channels;\r\n  output_channels = 1;\r\n  tensorflow::Scope scope_dense3 = network_root_scope_.NewSubScope(\"dense3\");\r\n  tensorflow::Output relu7 = AddDenseLayer(\r\n      \"dense3\", scope_dense3, input_channels, output_channels, false, relu6);\r\n\r\n  output_classification_ = tensorflow::ops::Sigmoid{\r\n      network_root_scope_.WithOpName(kOutputClassificationNodeName), relu7};\r\n\r\n  return network_root_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::CreateGraphForOptimization(\r\n    const float learning_rate) {\r\n  input_labels_tensor_node_ = tensorflow::ops::Placeholder{\r\n      network_root_scope_.WithOpName(\"input_labels_tensor\"),\r\n      tensorflow::DataType::DT_FLOAT};\r\n  tensorflow::Scope scope_loss = network_root_scope_.NewSubScope(\"loss\");\r\n  TF_CHECK_OK(scope_loss.status());\r\n  // calculate loos\r\n  squared_difference_node_ = tensorflow::ops::SquaredDifference{\r\n      scope_loss, output_classification_, input_labels_tensor_node_};\r\n  output_loss_logits_node_ =\r\n      tensorflow::ops::Mean{scope_loss.WithOpName(\"output_loss_logits\"),\r\n                            squared_difference_node_,\r\n                            {0}};\r\n  TF_CHECK_OK(scope_loss.status());\r\n  for (std::pair<std::string, tensorflow::Output> v : variables_) {\r\n    weights_biases_.push_back(v.second);\r\n  }\r\n  std::vector<tensorflow::Output> grad_outputs{};\r\n  TF_CHECK_OK(tensorflow::AddSymbolicGradients(network_root_scope_,\r\n                                               {output_loss_logits_node_},\r\n                                               weights_biases_, &grad_outputs));\r\n  int index = 0;\r\n  for (std::pair<std::string, tensorflow::Output> v : variables_) {\r\n    std::string index_str = std::to_string(index);\r\n    // m and v are described in API documentation\r\n    tensorflow::ops::Variable m_var{network_root_scope_,\r\n                                    variable_shapes_[v.first],\r\n                                    tensorflow::DataType::DT_FLOAT};\r\n    tensorflow::ops::Variable v_var{network_root_scope_,\r\n                                    variable_shapes_[v.first],\r\n                                    tensorflow::DataType::DT_FLOAT};\r\n    variable_assign_nodes_[\"m_\" + index_str] = tensorflow::ops::Assign{\r\n        network_root_scope_, m_var,\r\n        tensorflow::Input::Initializer{0.f, variable_shapes_[v.first]}};\r\n    variable_assign_nodes_[\"v_\" + index_str] = tensorflow::ops::Assign{\r\n        network_root_scope_, v_var,\r\n        tensorflow::Input::Initializer{0.0f, variable_shapes_[v.first]}};\r\n    tensorflow::ops::ApplyAdam apply_adam{network_root_scope_,\r\n                                          v.second,\r\n                                          m_var,\r\n                                          v_var,\r\n                                          0.0f,\r\n                                          0.0f,\r\n                                          learning_rate,\r\n                                          0.9f,\r\n                                          0.999f,\r\n                                          0.00000001f,\r\n                                          {grad_outputs[index]}};\r\n    adam_operations.emplace_back(std::move(apply_adam.operation));\r\n    ++index;\r\n  }\r\n  return network_root_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::Initialize() {\r\n  if (network_root_scope_.ok() == false) {\r\n    return network_root_scope_.status();\r\n  }\r\n  std::vector<tensorflow::Output> assign_operations{};\r\n  for (std::pair<std::string, tensorflow::Output> i : variable_assign_nodes_) {\r\n    assign_operations.emplace_back(i.second);\r\n  }\r\n  train_session_ptr_.reset(new tensorflow::ClientSession{network_root_scope_});\r\n  TF_CHECK_OK(train_session_ptr_->Run(assign_operations, nullptr));\r\n  return network_root_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::Train(const tensorflow::Tensor& image_batch,\r\n                                    const tensorflow::Tensor& label_batch,\r\n                                    std::vector<float>* results, float* loss) {\r\n  if (network_root_scope_.ok() == false) {\r\n    return network_root_scope_.status();\r\n  }\r\n  std::vector<tensorflow::Tensor> output_tensors{};\r\n  TF_CHECK_OK(train_session_ptr_->Run(\r\n      {\r\n          {input_batch_tensor_node_, image_batch},\r\n          {input_labels_tensor_node_, label_batch},\r\n          {drop_rate_node_, 0.5f},\r\n          {skip_drop_node_, 0.0f},\r\n      },\r\n      {output_loss_logits_node_, output_classification_}, adam_operations,\r\n      &output_tensors));\r\n\r\n  *loss = output_tensors[0].scalar<float>()(0);\r\n  auto label_mat = label_batch.matrix<float>();\r\n  auto classification_mat = output_tensors[1].matrix<float>();\r\n  for (size_t i = 0; i < label_mat.dimension(0); ++i) {\r\n    results->push_back(\r\n        (std::fabs(classification_mat(i, 0) - label_mat(i, 0)) > 0.5f) ? 0 : 1);\r\n  }\r\n  return network_root_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::Validate(const tensorflow::Tensor& image_batch,\r\n                                       const tensorflow::Tensor& label_batch,\r\n                                       std::vector<float>* results) {\r\n  if (network_root_scope_.ok() == false) {\r\n    return network_root_scope_.status();\r\n  }\r\n  std::vector<tensorflow::Tensor> output_tensors;\r\n  TF_CHECK_OK(train_session_ptr_->Run(\r\n      {\r\n          {input_batch_tensor_node_, image_batch},\r\n          {input_labels_tensor_node_, label_batch},\r\n          {drop_rate_node_, 1.0f},\r\n          {skip_drop_node_, 1.0f},\r\n      },\r\n      {output_classification_}, &output_tensors));\r\n  auto label_mat = label_batch.matrix<float>();\r\n  auto classification_mat = output_tensors[0].matrix<float>();\r\n  for (size_t i = 0; i < label_mat.dimension(0); ++i) {\r\n    results->push_back(\r\n        (std::fabs(classification_mat(i, 0) - label_mat(i, 0)) > 0.5f) ? 0 : 1);\r\n  }\r\n  return network_root_scope_.status();\r\n}\r\n\r\ntensorflow::Status CatDogCnn::FreezeModel(const std::filesystem::path& path) {\r\n  std::vector<tensorflow::Tensor> output_tensors{};\r\n  TF_CHECK_OK(train_session_ptr_->Run(weights_biases_, &output_tensors));\r\n  std::unordered_map<std::string, tensorflow::Tensor> name_variable_map;\r\n  for (size_t i = 0; i < weights_biases_.size(); ++i) {\r\n    name_variable_map[weights_biases_[i].node()->name()] = output_tensors[i];\r\n  }\r\n  tensorflow::GraphDef graph_def{};\r\n  TF_CHECK_OK(network_root_scope_.ToGraphDef(&graph_def));\r\n  tensorflow::SavedModelBundle saved_model_bundle{};\r\n  tensorflow::SignatureDef signature_def{};\r\n  (*(signature_def.mutable_inputs()))[input_batch_tensor_node_.name()].set_name(\r\n      input_batch_tensor_node_.name());\r\n  (*(signature_def.mutable_inputs()))[output_classification_.name()].set_name(\r\n      output_classification_.name());\r\n  tensorflow::MetaGraphDef* meta_graph_def =\r\n      &(saved_model_bundle.meta_graph_def);\r\n  (*(meta_graph_def->mutable_signature_def()))[\"signature_def\"] = signature_def;\r\n  *(meta_graph_def->mutable_graph_def()) = graph_def;\r\n  tensorflow::SessionOptions options{};\r\n  saved_model_bundle.session.reset(tensorflow::NewSession(options));\r\n  tensorflow::GraphDef frozen_graph_def{};\r\n  std::unordered_set<std::string> inputs;\r\n  std::unordered_set<std::string> outputs;\r\n  // <---------------- uncomment following causes runtime exception start ---------------->\r\n  TF_CHECK_OK(tensorflow::FreezeSavedModel(saved_model_bundle, &frozen_graph_def, &inputs, &outputs));\r\n  // <--------------- uncomment following causes runtime exception end ---------------->\r\n  return tensorflow::WriteBinaryProto(tensorflow::Env::Default(), path.string(),\r\n                                      frozen_graph_def);\r\n}\r\n\r\ntensorflow::Status CatDogCnn::LoadFrozenModel(\r\n    const std::filesystem::path& path) {\r\n  // std::unique_ptr<tensorflow::GraphDef> graph_def_ptr;\r\n  // tensorflow::SessionOptions options{};\r\n  // frozen_session_ptr_.reset(tensorflow::NewSession(options));\r\n  // graph_def_ptr.reset(new tensorflow::GraphDef{});\r\n  // TF_CHECK_OK(tensorflow::ReadBinaryProto(tensorflow::Env::Default(),\r\n  //                                         path.string(),\r\n  //                                         graph_def_ptr.get()));\r\n  // return frozen_session_ptr_->Create(*graph_def_ptr.get());\r\n}\r\n\r\ntensorflow::Status CatDogCnn::PredictFromFrozen(const tensorflow::Tensor& image,\r\n                                                int* result) {\r\n  // std::vector<tensorflow::Tensor> output_tensors{};\r\n  // tensorflow::Tensor t{tensorflow::DataType::DT_FLOAT,\r\n  //                      tensorflow::TensorShape{{1}}};\r\n  // t.scalar<float>()(0) = 1.0f;\r\n  // // drop rate and skip drop rate both set to 1\r\n  // TF_RETURN_IF_ERROR(frozen_session_ptr_->Run(\r\n  //     {\r\n  //         {kInputNodeName, image},\r\n  //         {kInputDropRateNodeName, t},\r\n  //         {kInputSkipDropNodeName, t},\r\n  //     },\r\n  //     {kOutputClassificationNodeName}, {}, &output_tensors));\r\n  // auto mat = output_tensors[0].matrix<float>();\r\n  // *result = (mat(0, 0) > 0.5f) ? 1 : 0;\r\n  // return tensorflow::Status::OK();\r\n}\r\n\r\n}  // namespace tensorflow_tutorial\r\n\r\n```\r\nhearder file for entry point (main.hpp)\r\n```\r\n/**\r\n * @file tutorial_02.hpp\r\n * @author your name (you@domain.com)\r\n * @brief\r\n * @version 0.1\r\n * @date 2020-12-16\r\n *\r\n * @copyright Copyright (c) 2020\r\n *\r\n */\r\n#ifndef INCLUDE_TENSORFLOW_TUTORIAL_TUTORIAL_02_HPP_\r\n#define INCLUDE_TENSORFLOW_TUTORIAL_TUTORIAL_02_HPP_\r\n\r\n#include <tensorflow/core/framework/tensor.h>\r\n#include <tensorflow/core/summary/summary_file_writer.h>\r\n\r\n#include <chrono>\r\n#include <iostream>\r\n#include <map>\r\n#include <tensorflow_tutorial/tutorial_02/CatDogCnn/CatDogCnn.hpp>\r\n#include <tuple>\r\n#include <vector>\r\n\r\nvoid TestCnn(const int argc, char** argv);\r\n\r\nvoid TestConvertImageToTensor(const int argc, char** argv);\r\nvoid TestLoadDataset(const int argc, char** argv);\r\nvoid TestLoadBatch(const int argc, char** argv);\r\nvoid TestAddConvLayer(const int argc, char** argv);\r\nvoid TestAddDenseLayer(const int argc, char** argv);\r\n\r\nvoid AssignVariable(const tensorflow::ClientSession& session,\r\n                    const tensorflow::ops::Assign& variable_assign_node);\r\nvoid ProperAssignVariableExample(const int argc, char** argv);\r\n\r\n#endif  // INCLUDE_TENSORFLOW_TUTORIAL_TUTORIAL_02_HPP_\r\n\r\n```\r\n\r\nentry point to cause the exception (main.cpp)\r\n```\r\n/**\r\n * @file tutorial_02.cpp\r\n * @author Hung-Tien Huang (paperbus72@gmail.com)\r\n * @brief\r\n * @version 0.1\r\n * @date 2020-12-16\r\n *\r\n * @copyright Copyright (c) 2020\r\n *\r\n */\r\n\r\n#include <tensorflow_tutorial/tutorial_02/tutorial_02.hpp>\r\n\r\nint main(int argc, char** argv) {\r\n  // TestCnn(argc, argv);\r\n\r\n  TestConvertImageToTensor(argc, argv);\r\n  // TestLoadDataset(argc, argv);\r\n  // TestLoadBatch(argc, argv);\r\n  // TestAddConvLayer(argc, argv);\r\n  // TestAddDenseLayer(argc, argv);\r\n  // ProperAssignVariableExample(argc, argv);\r\n  return 0;\r\n}\r\n\r\nvoid TestCnn(const int argc, char** argv) {\r\n  if (argc != 3) {\r\n    std::cerr << \"./tutorial_2 /path/to/base/folder \"\r\n                 \"/path/to/export/filename/without/extension\"\r\n              << std::endl;\r\n    exit(EXIT_FAILURE);\r\n  }\r\n  const std::filesystem::path kBaseFolder{argv[1]};\r\n  const std::filesystem::path kTrainFolder = kBaseFolder / \"train\";\r\n  const std::filesystem::path kValidateFolder = kBaseFolder / \"validation\";\r\n  const std::filesystem::path kExportPath =\r\n      std::filesystem::path{argv[2]}.replace_extension(\".pb\");\r\n  std::filesystem::create_directories(kExportPath.parent_path());\r\n  const size_t kImageSide = 150;\r\n  const size_t kImageChannels = 3;\r\n  const size_t kBatchSize = 20;\r\n  const size_t kFilterSide = 3;\r\n\r\n  tensorflow_tutorial::CatDogCnn model{150, 3};\r\n  // load dataset\r\n  TF_CHECK_OK(model.CreateGraphForInputImage(true));\r\n  std::vector<tensorflow::Tensor> train_image_batch;\r\n  std::vector<tensorflow::Tensor> train_label_batch;\r\n  std::vector<tensorflow::Tensor> validate_image_batch;\r\n  std::vector<tensorflow::Tensor> validate_label_batch;\r\n  TF_CHECK_OK(model.LoadBatach(\r\n      kTrainFolder, {std::make_pair(\"cats\", 0), std::make_pair(\"dogs\", 1)},\r\n      kBatchSize, &train_image_batch, &train_label_batch));\r\n  TF_CHECK_OK(model.LoadBatach(\r\n      kValidateFolder, {std::make_pair(\"cats\", 0), std::make_pair(\"dogs\", 1)},\r\n      kBatchSize, &validate_image_batch, &validate_label_batch));\r\n  // check data length\r\n  assert(train_image_batch.size() == train_label_batch.size());\r\n  assert(validate_image_batch.size() == validate_label_batch.size());\r\n  const size_t num_epochs = 30;\r\n  const size_t kNumTrainBatches = train_label_batch.size();\r\n  const size_t kNumValidateBatches = validate_label_batch.size();\r\n\r\n  // std::cout << kNumTrainBatches << \" \" << kNumValidateBatches << std::endl;\r\n  // std::cout << train_image_batch[0].DebugString() << std::endl;\r\n  // std::cout << train_image_batch[20].DebugString() << std::endl;\r\n  // std::cout << train_label_batch[0].DebugString() << std::endl;\r\n  // std::cout << train_label_batch[20].DebugString() << std::endl;\r\n\r\n  // build cnn graph\r\n  TF_CHECK_OK(model.CreateGraphForCnn(kFilterSide));\r\n  TF_CHECK_OK(model.CreateGraphForOptimization(0.0002f));\r\n  TF_CHECK_OK(model.Initialize());\r\n  // Epoch / Step loops\r\n  for (int epoch = 0; epoch < num_epochs; epoch++) {\r\n    std::cout << \"Epoch \" << epoch + 1 << \"/\" << num_epochs << \":\";\r\n    auto t1 = std::chrono::high_resolution_clock::now();\r\n    float loss_sum = 0;\r\n    float accuracy_sum = 0;\r\n    for (int b = 0; b < kNumTrainBatches; b++) {\r\n      std::vector<float> results;\r\n      float loss;\r\n      TF_CHECK_OK(model.Train(train_image_batch[b], train_label_batch[b],\r\n                              &results, &loss));\r\n      loss_sum += loss;\r\n      accuracy_sum +=\r\n          accumulate(results.begin(), results.end(), 0.f) / results.size();\r\n      std::cout << \".\";\r\n    }\r\n    std::cout << std::endl << \"Validation:\";\r\n    float validation_sum = 0;\r\n    for (int c = 0; c < kNumValidateBatches; c++) {\r\n      std::vector<float> results;\r\n      TF_CHECK_OK(model.Validate(validate_image_batch[c],\r\n                                 validate_label_batch[c], &results));\r\n      validation_sum +=\r\n          accumulate(results.begin(), results.end(), 0.f) / results.size();\r\n      std::cout << \".\";\r\n    }\r\n    std::cout << std::endl;\r\n    auto t2 = std::chrono::high_resolution_clock::now();\r\n    std::cout\r\n        << \"Time: \"\r\n        << std::chrono::duration_cast<std::chrono::seconds>(t2 - t1).count()\r\n        << \" seconds \";\r\n    std::cout << \"Loss: \" << loss_sum / kNumTrainBatches\r\n              << \" Results accuracy: \" << accuracy_sum / kNumTrainBatches\r\n              << \" Validation accuracy: \"\r\n              << validation_sum / kNumValidateBatches << std::endl;\r\n    // TF_CHECK_OK(model.FreezeModel(kExportPath.string()));\r\n  }\r\n}\r\n\r\nvoid TestConvertImageToTensor(const int argc, char** argv) {\r\n  if (argc != 2) {\r\n    std::cerr << \"./tutorial_02 /path/to/image\" << std::endl;\r\n    exit(EXIT_FAILURE);\r\n  }\r\n  const std::filesystem::path path_to_image{argv[1]};\r\n  tensorflow_tutorial::CatDogCnn cat_dog_model{150, 3};\r\n  tensorflow::Tensor image_tensor;\r\n  cat_dog_model.CreateGraphForInputImage(false);\r\n  cat_dog_model.ConvertImageToTensor(path_to_image, &image_tensor);\r\n  std::cout << image_tensor.DebugString() << std::endl;\r\n  cat_dog_model.CreateGraphForInputImage(true);\r\n  cat_dog_model.ConvertImageToTensor(path_to_image, &image_tensor);\r\n  std::cout << image_tensor.DebugString() << std::endl;\r\n}\r\n\r\nvoid TestLoadDataset(const int argc, char** argv) {\r\n  if (argc != 2) {\r\n    std::cerr << \"./tutorial_02 /path/to/root/folder\" << std::endl;\r\n    exit(EXIT_FAILURE);\r\n  }\r\n  const std::filesystem::path path_to_root_dir{argv[1]};\r\n  tensorflow_tutorial::CatDogCnn cat_dog_model{150, 3};\r\n  std::vector<std::pair<std::string, float>> label = {std::pair{\"cats\", 0},\r\n                                                      std::pair{\"dogs\", 1}};\r\n  std::cout << \"Remain Stacked:\" << std::endl;\r\n  cat_dog_model.CreateGraphForInputImage(false);\r\n  std::vector<std::tuple<tensorflow::Tensor, float, std::filesystem::path>>\r\n      image_tensors;\r\n  cat_dog_model.LoadDataset(path_to_root_dir, label, &image_tensors);\r\n  std::cout << \"Number of Samples: \" << image_tensors.size() << std::endl;\r\n  std::cout << \"Shape of 0th element: \"\r\n            << std::get<0>(image_tensors[0]).DebugString()\r\n            << \"\\nclass of 0th element (float): \"\r\n            << std::get<1>(image_tensors[0])\r\n            << \"\\npath to 0th element: \" << std::get<2>(image_tensors[0])\r\n            << std::endl;\r\n  std::cout << \"dataset size: \" << image_tensors.size() << std::endl;\r\n  std::cout << \"Unstacked:\" << std::endl;\r\n  image_tensors.clear();\r\n  cat_dog_model.CreateGraphForInputImage(true);\r\n  cat_dog_model.LoadDataset(path_to_root_dir, label, &image_tensors);\r\n  std::cout << \"Number of Samples: \" << image_tensors.size() << std::endl;\r\n  std::cout << \"Shape of 0th element: \"\r\n            << std::get<0>(image_tensors[0]).DebugString()\r\n            << \"\\nclass of 0th element (float): \"\r\n            << std::get<1>(image_tensors[0])\r\n            << \"\\npath to 0th element: \" << std::get<2>(image_tensors[0])\r\n            << std::endl;\r\n  std::cout << \"dataset size: \" << image_tensors.size() << std::endl;\r\n}\r\n\r\nvoid TestLoadBatch(const int argc, char** argv) {\r\n  if (argc != 3) {\r\n    std::cerr << \"./tutorial_02 /path/to/root/folder number_of_batches\"\r\n              << std::endl;\r\n    exit(EXIT_FAILURE);\r\n  }\r\n  const std::filesystem::path path_to_root_dir{argv[1]};\r\n  const size_t kNumOfBatches = std::stoul(argv[2]);\r\n  std::vector<std::pair<std::string, float>> label = {std::pair{\"cats\", 0},\r\n                                                      std::pair{\"dogs\", 1}};\r\n  tensorflow_tutorial::CatDogCnn cat_dog_model{150, 3};\r\n  cat_dog_model.CreateGraphForInputImage(true);\r\n  std::vector<tensorflow::Tensor> image_batches;\r\n  std::vector<tensorflow::Tensor> label_batches;\r\n  cat_dog_model.LoadBatach(path_to_root_dir, label, kNumOfBatches,\r\n                           &image_batches, &label_batches);\r\n  std::cout << \"image_batches: \\nLength : \" << image_batches.size()\r\n            << std::endl;\r\n  std::cout << image_batches[0].DebugString() << std::endl;\r\n  std::cout << \"label_batches: \\nLength : \" << label_batches.size()\r\n            << std::endl;\r\n  std::cout << label_batches[0].DebugString() << std::endl;\r\n}\r\n\r\nvoid TestAddConvLayer(const int argc, char** argv) {\r\n  std::cout << \"test add conv layer\" << std::endl;\r\n  std::vector<tensorflow::Tensor> output_tensors{};\r\n  tensorflow_tutorial::CatDogCnn cat_dog_model{150, 3};\r\n  tensorflow::Scope scope = tensorflow::Scope::NewRootScope();\r\n  tensorflow::TensorShape shape{1, 150, 150, 3};\r\n  tensorflow::Output input_variable = tensorflow::ops::Variable{\r\n      scope.NewSubScope(\"input\"), shape, tensorflow::DataType::DT_FLOAT};\r\n  tensorflow::ops::Assign assign_input_var{\r\n      scope.NewSubScope(\"assign_input\"), input_variable,\r\n      tensorflow::Input::Initializer{0.3f, shape}};\r\n  tensorflow::Output conv = cat_dog_model.AddConvLayer(\r\n      \"conv_test\", scope.NewSubScope(\"conv_test\"), 3, 32, 3, assign_input_var);\r\n  tensorflow::ClientSession client{scope};\r\n\r\n  TF_CHECK_OK(client.Run({conv}, &output_tensors));\r\n  std::cout << output_tensors.size() << std::endl;\r\n\r\n  tensorflow::GraphDef graph;\r\n  TF_CHECK_OK(scope.ToGraphDef(&graph));\r\n  tensorflow::SummaryWriterInterface* w;\r\n  TF_CHECK_OK(tensorflow::CreateSummaryFileWriter(\r\n      1, 0, \".\", \".img-graph\", tensorflow::Env::Default(), &w));\r\n  TF_CHECK_OK(w->WriteGraph(0, std::make_unique<tensorflow::GraphDef>(graph)));\r\n\r\n  if (!scope.ok()) {\r\n    std::cerr << \"ERROR\" << scope.status().error_message() << std::endl;\r\n    exit(EXIT_FAILURE);\r\n  }\r\n  std::cout << output_tensors[0].DebugString() << std::endl;\r\n}\r\n\r\nvoid TestAddDenseLayer(const int argc, char** argv) {\r\n  std::cout << \"test add dense layer\" << std::endl;\r\n\r\n  // initialize input variables\r\n  tensorflow::Scope scope = tensorflow::Scope::NewRootScope();\r\n  tensorflow::TensorShape shape{1, 30};\r\n  tensorflow::ops::Variable input_variable{scope.NewSubScope(\"input\"), shape,\r\n                                           tensorflow::DataType::DT_FLOAT};\r\n  tensorflow::ops::Assign assign_input_var{\r\n      scope.NewSubScope(\"assign_input\"), input_variable,\r\n      tensorflow::Input::Initializer{0.3f, shape}};\r\n  tensorflow::ClientSession client{scope};\r\n  AssignVariable(client, assign_input_var);\r\n\r\n  // add dense layer\r\n  tensorflow_tutorial::CatDogCnn cat_dog_model{10, 3};\r\n  tensorflow::Output dense = cat_dog_model.AddDenseLayer(\r\n      \"dense_layer\", scope.NewSubScope(\"dense_layer\"), 30, 5, false,\r\n      input_variable);\r\n\r\n  // execute the graph\r\n  std::vector<tensorflow::Tensor> output_tensors{};\r\n  TF_CHECK_OK(client.Run({dense}, &output_tensors));\r\n  std::cout << output_tensors.size() << std::endl;\r\n\r\n  // output graph\r\n  tensorflow::GraphDef graph;\r\n  TF_CHECK_OK(scope.ToGraphDef(&graph));\r\n  tensorflow::SummaryWriterInterface* w;\r\n  TF_CHECK_OK(tensorflow::CreateSummaryFileWriter(\r\n      1, 0, \".\", \".img-graph\", tensorflow::Env::Default(), &w));\r\n  TF_CHECK_OK(w->WriteGraph(0, std::make_unique<tensorflow::GraphDef>(graph)));\r\n\r\n  // print string\r\n  std::cout << output_tensors[0].DebugString() << std::endl;\r\n}\r\n\r\nvoid AssignVariable(const tensorflow::ClientSession& session,\r\n                    const tensorflow::ops::Assign& variable_assign_node) {\r\n  std::vector<tensorflow::Tensor> output{};\r\n  TF_CHECK_OK(session.Run(\r\n      {}, {}, {tensorflow::Operation{variable_assign_node.node()}}, &output));\r\n}\r\n\r\nvoid ProperAssignVariableExample(const int argc, char** argv) {\r\n  std::vector<tensorflow::Tensor> output_tensors{};\r\n  tensorflow::Scope scope = tensorflow::Scope::NewRootScope();\r\n  tensorflow::TensorShape shape{1, 150, 150, 3};\r\n  tensorflow::ops::Variable input_variable{scope.NewSubScope(\"input\"), shape,\r\n                                           tensorflow::DataType::DT_FLOAT};\r\n  tensorflow::ops::Assign assign_input_var{\r\n      scope.NewSubScope(\"assign_input\"), input_variable,\r\n      tensorflow::Input::Initializer{0.3f, shape}};\r\n  // have to execute the assign input node first prior to using the variable\r\n  tensorflow::ClientSession client{scope};\r\n  TF_CHECK_OK(client.Run({}, {},\r\n                         {tensorflow::Operation{assign_input_var.node()}},\r\n                         &output_tensors));\r\n  std::cout << output_tensors.size() << std::endl;\r\n  TF_CHECK_OK(client.Run({input_variable}, &output_tensors));\r\n  std::cout << output_tensors.size() << std::endl;\r\n  std::cout << output_tensors[0].DebugString() << std::endl;\r\n}\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\n2020-12-23 09:32:00.026726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099940000 Hz\r\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/map.h:1060] CHECK failed: it != end(): key not found: Reciprocal\r\nterminate called after throwing an instance of 'google::protobuf::FatalException'\r\n  what():  CHECK failed: it != end(): key not found: Reciprocal\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\n\r\nThread 1 \"main\" received signal SIGABRT, Aborted.\r\n__GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50\r\n50      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n(gdb) backtrace \r\n#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50\r\n#1  0x00007fffe8603859 in __GI_abort () at abort.c:79\r\n#2  0x00007fffe89d8951 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#3  0x00007fffe89e447c in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#4  0x00007fffe89e44e7 in std::terminate() () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007fffe89e4799 in __cxa_throw () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#6  0x00007fffeb44aed5 in google::protobuf::internal::LogMessage::Finish() [clone .cold] () from /usr/local/lib/libtensorflow_cc.so.2\r\n#7  0x00007ffff50353cd in tensorflow::grappler::NumOutputs(tensorflow::NodeDef const&, tensorflow::GraphDef*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#8  0x00007ffff4bd25f6 in tensorflow::grappler::ConstantFolding::RunOptimizationPass(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/libtensorflow_cc.so.2\r\n#9  0x00007ffff4bd3175 in tensorflow::grappler::ConstantFolding::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/libtensorflow_cc.so.2\r\n#10 0x00007ffff4aa40fa in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\n#11 0x00007ffff4aa556d in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem&&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/libtensorflow_cc.so.2\r\n#12 0x00007ffff4aa69a9 in tensorflow::grappler::MetaOptimizer::OptimizeConsumeItem(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem&&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/libtensorflow_cc.so.2\r\n#13 0x00007ffff4aa88eb in tensorflow::grappler::RunMetaOptimizer(tensorflow::grappler::GrapplerItem&&, tensorflow::ConfigProto const&, tensorflow::DeviceBase*, tensorflow::grappler::Cluster*, tensorflow::GraphDef*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#14 0x00007ffff4a95b11 in tensorflow::GraphExecutionState::OptimizeGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#15 0x00007ffff4a9675b in tensorflow::GraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::ClientGraph, std::default_delete<tensorflow::ClientGraph> >*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#16 0x00007ffff4a41250 in tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> > > > >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*,--Type <RET> for more, q to quit, c to continue without paging--\r\n tensorflow::DirectSession::RunStateArgs*, absl::lts_2020_02_25::InlinedVector<tensorflow::DataType, 4ul, std::allocator<tensorflow::DataType> >*, absl::lts_2020_02_25::InlinedVector<tensorflow::DataType, 4ul, std::allocator<tensorflow::DataType> >*, long long*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#17 0x00007ffff4a42b53 in tensorflow::DirectSession::CreateExecutors(tensorflow::CallableOptions const&, std::unique_ptr<tensorflow::DirectSession::ExecutorsAndKeys, std::default_delete<tensorflow::DirectSession::ExecutorsAndKeys> >*, std::unique_ptr<tensorflow::DirectSession::FunctionInfo, std::default_delete<tensorflow::DirectSession::FunctionInfo> >*, tensorflow::DirectSession::RunStateArgs*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#18 0x00007ffff4a45418 in tensorflow::DirectSession::GetOrCreateExecutors(absl::lts_2020_02_25::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, absl::lts_2020_02_25::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, absl::lts_2020_02_25::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#19 0x00007ffff4a496d6 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*, tensorflow::thread::ThreadPoolOptions const&) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#20 0x00007ffff4a33d08 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tenso--Type <RET> for more, q to quit, c to continue without paging--\r\nrflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /usr/local/lib/libtensorflow_cc.so.2\r\n#21 0x00007fffeb81640a in tensorflow::ClientSession::Run(tensorflow::RunOptions const&, std::unordered_map<tensorflow::Output, tensorflow::Input::Initializer, tensorflow::OutputHash, std::equal_to<tensorflow::Output>, std::allocator<std::pair<tensorflow::Output const, tensorflow::Input::Initializer> > > const&, std::vector<tensorflow::Output, std::allocator<tensorflow::Output> > const&, std::vector<tensorflow::Operation, std::allocator<tensorflow::Operation> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) const ()\r\n   from /usr/local/lib/libtensorflow_cc.so.2\r\n#22 0x00007fffeb816547 in tensorflow::ClientSession::Run(std::unordered_map<tensorflow::Output, tensorflow::Input::Initializer, tensorflow::OutputHash, std::equal_to<tensorflow::Output>, std::allocator<std::pair<tensorflow::Output const, tensorflow::Input::Initializer> > > const&, std::vector<tensorflow::Output, std::allocator<tensorflow::Output> > const&, std::vector<tensorflow::Operation, std::allocator<tensorflow::Operation> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const () from /usr/local/lib/libtensorflow_cc.so.2\r\n#23 0x00007fffeb816788 in tensorflow::ClientSession::Run(std::unordered_map<tensorflow::Output, tensorflow::Input::Initializer, tensorflow::OutputHash, std::equal_to<tensorflow::Output>, std::allocator<std::pair<tensorflow::Output const, tensorflow::Input::Initializer> > > const&, std::vector<tensorflow::Output, std::allocator<tensorflow::Output> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const () from /usr/local/lib/libtensorflow_cc.so.2\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\n#24 0x000055555556df6a in CatDogCNN::ReadTensorFromImageFile (this=0x7fffffffd390, file_name=\"../../data/cats_and_dogs_small/train/cats/cat.470.jpg\", outTensor=...) at ../CatDogCNN.cpp:38\r\n#25 0x000055555556e565 in CatDogCNN::ReadFileTensors (this=0x7fffffffd390, base_folder_name=\"../../data/cats_and_dogs_small/train\", v_folder_label=std::vector of length 2, capacity 2 = {...}, \r\n    file_tensors=std::vector of length 0, capacity 0) at ../CatDogCNN.cpp:60\r\n#26 0x000055555556e972 in CatDogCNN::ReadBatches (this=0x7fffffffd390, base_folder_name=\"../../data/cats_and_dogs_small/train\", v_folder_label=std::vector of length 2, capacity 2 = {...}, \r\n    batch_size=20, image_batches=std::vector of length 0, capacity 0, label_batches=std::vector of length 0, capacity 0) at ../CatDogCNN.cpp:79\r\n#27 0x000055555556307a in main (argc=1, argv=0x7fffffffd7e8) at ../main.cpp:39\r\n\r\n```\r\nabsl/base/option.h has to be configured this way, otherwise there will be linker error. Absolutely not a good idea to append version number before class name. Slight version change will cause endless error.\r\n```\r\n#ifndef ABSL_BASE_OPTIONS_H_\r\n#define ABSL_BASE_OPTIONS_H_\r\n\r\n// Copyright 2019 The Abseil Authors.\r\n//\r\n// Licensed under the Apache License, Version 2.0 (the \"License\");\r\n// you may not use this file except in compliance with the License.\r\n// You may obtain a copy of the License at\r\n//\r\n//      https://www.apache.org/licenses/LICENSE-2.0\r\n//\r\n// Unless required by applicable law or agreed to in writing, software\r\n// distributed under the License is distributed on an \"AS IS\" BASIS,\r\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n// See the License for the specific language governing permissions and\r\n// limitations under the License.\r\n//\r\n// -----------------------------------------------------------------------------\r\n// File: options.h\r\n// -----------------------------------------------------------------------------\r\n//\r\n// This file contains Abseil configuration options for setting specific\r\n// implementations instead of letting Abseil determine which implementation to\r\n// use at compile-time. Setting these options may be useful for package or build\r\n// managers who wish to guarantee ABI stability within binary builds (which are\r\n// otherwise difficult to enforce).\r\n//\r\n// *** IMPORTANT NOTICE FOR PACKAGE MANAGERS:  It is important that\r\n// maintainers of package managers who wish to package Abseil read and\r\n// understand this file! ***\r\n//\r\n// Abseil contains a number of possible configuration endpoints, based on\r\n// parameters such as the detected platform, language version, or command-line\r\n// flags used to invoke the underlying binary. As is the case with all\r\n// libraries, binaries which contain Abseil code must ensure that separate\r\n// packages use the same compiled copy of Abseil to avoid a diamond dependency\r\n// problem, which can occur if two packages built with different Abseil\r\n// configuration settings are linked together. Diamond dependency problems in\r\n// C++ may manifest as violations to the One Definition Rule (ODR) (resulting in\r\n// linker errors), or undefined behavior (resulting in crashes).\r\n//\r\n// Diamond dependency problems can be avoided if all packages utilize the same\r\n// exact version of Abseil. Building from source code with the same compilation\r\n// parameters is the easiest way to avoid such dependency problems. However, for\r\n// package managers who cannot control such compilation parameters, we are\r\n// providing the file to allow you to inject ABI (Application Binary Interface)\r\n// stability across builds. Settings options in this file will neither change\r\n// API nor ABI, providing a stable copy of Abseil between packages.\r\n//\r\n// Care must be taken to keep options within these configurations isolated\r\n// from any other dynamic settings, such as command-line flags which could alter\r\n// these options. This file is provided specifically to help build and package\r\n// managers provide a stable copy of Abseil within their libraries and binaries;\r\n// other developers should not have need to alter the contents of this file.\r\n//\r\n// -----------------------------------------------------------------------------\r\n// Usage\r\n// -----------------------------------------------------------------------------\r\n//\r\n// For any particular package release, set the appropriate definitions within\r\n// this file to whatever value makes the most sense for your package(s). Note\r\n// that, by default, most of these options, at the moment, affect the\r\n// implementation of types; future options may affect other implementation\r\n// details.\r\n//\r\n// NOTE: the defaults within this file all assume that Abseil can select the\r\n// proper Abseil implementation at compile-time, which will not be sufficient\r\n// to guarantee ABI stability to package managers.\r\n\r\n// Include a standard library header to allow configuration based on the\r\n// standard library in use.\r\n#ifdef __cplusplus\r\n#include <ciso646>\r\n#endif\r\n\r\n// -----------------------------------------------------------------------------\r\n// Type Compatibility Options\r\n// -----------------------------------------------------------------------------\r\n//\r\n// ABSL_OPTION_USE_STD_ANY\r\n//\r\n// This option controls whether absl::any is implemented as an alias to\r\n// std::any, or as an independent implementation.\r\n//\r\n// A value of 0 means to use Abseil's implementation.  This requires only C++11\r\n// support, and is expected to work on every toolchain we support.\r\n//\r\n// A value of 1 means to use an alias to std::any.  This requires that all code\r\n// using Abseil is built in C++17 mode or later.\r\n//\r\n// A value of 2 means to detect the C++ version being used to compile Abseil,\r\n// and use an alias only if a working std::any is available.  This option is\r\n// useful when you are building your entire program, including all of its\r\n// dependencies, from source.  It should not be used otherwise -- for example,\r\n// if you are distributing Abseil in a binary package manager -- since in\r\n// mode 2, absl::any will name a different type, with a different mangled name\r\n// and binary layout, depending on the compiler flags passed by the end user.\r\n// For more info, see https://abseil.io/about/design/dropin-types.\r\n//\r\n// User code should not inspect this macro.  To check in the preprocessor if\r\n// absl::any is a typedef of std::any, use the feature macro ABSL_USES_STD_ANY.\r\n\r\n#define ABSL_OPTION_USE_STD_ANY 0\r\n\r\n\r\n// ABSL_OPTION_USE_STD_OPTIONAL\r\n//\r\n// This option controls whether absl::optional is implemented as an alias to\r\n// std::optional, or as an independent implementation.\r\n//\r\n// A value of 0 means to use Abseil's implementation.  This requires only C++11\r\n// support, and is expected to work on every toolchain we support.\r\n//\r\n// A value of 1 means to use an alias to std::optional.  This requires that all\r\n// code using Abseil is built in C++17 mode or later.\r\n//\r\n// A value of 2 means to detect the C++ version being used to compile Abseil,\r\n// and use an alias only if a working std::optional is available.  This option\r\n// is useful when you are building your program from source.  It should not be\r\n// used otherwise -- for example, if you are distributing Abseil in a binary\r\n// package manager -- since in mode 2, absl::optional will name a different\r\n// type, with a different mangled name and binary layout, depending on the\r\n// compiler flags passed by the end user.  For more info, see\r\n// https://abseil.io/about/design/dropin-types.\r\n\r\n// User code should not inspect this macro.  To check in the preprocessor if\r\n// absl::optional is a typedef of std::optional, use the feature macro\r\n// ABSL_USES_STD_OPTIONAL.\r\n\r\n#define ABSL_OPTION_USE_STD_OPTIONAL 0\r\n\r\n\r\n// ABSL_OPTION_USE_STD_STRING_VIEW\r\n//\r\n// This option controls whether absl::string_view is implemented as an alias to\r\n// std::string_view, or as an independent implementation.\r\n//\r\n// A value of 0 means to use Abseil's implementation.  This requires only C++11\r\n// support, and is expected to work on every toolchain we support.\r\n//\r\n// A value of 1 means to use an alias to std::string_view.  This requires that\r\n// all code using Abseil is built in C++17 mode or later.\r\n//\r\n// A value of 2 means to detect the C++ version being used to compile Abseil,\r\n// and use an alias only if a working std::string_view is available.  This\r\n// option is useful when you are building your program from source.  It should\r\n// not be used otherwise -- for example, if you are distributing Abseil in a\r\n// binary package manager -- since in mode 2, absl::string_view will name a\r\n// different type, with a different mangled name and binary layout, depending on\r\n// the compiler flags passed by the end user.  For more info, see\r\n// https://abseil.io/about/design/dropin-types.\r\n//\r\n// User code should not inspect this macro.  To check in the preprocessor if\r\n// absl::string_view is a typedef of std::string_view, use the feature macro\r\n// ABSL_USES_STD_STRING_VIEW.\r\n\r\n#define ABSL_OPTION_USE_STD_STRING_VIEW 0\r\n\r\n// ABSL_OPTION_USE_STD_VARIANT\r\n//\r\n// This option controls whether absl::variant is implemented as an alias to\r\n// std::variant, or as an independent implementation.\r\n//\r\n// A value of 0 means to use Abseil's implementation.  This requires only C++11\r\n// support, and is expected to work on every toolchain we support.\r\n//\r\n// A value of 1 means to use an alias to std::variant.  This requires that all\r\n// code using Abseil is built in C++17 mode or later.\r\n//\r\n// A value of 2 means to detect the C++ version being used to compile Abseil,\r\n// and use an alias only if a working std::variant is available.  This option\r\n// is useful when you are building your program from source.  It should not be\r\n// used otherwise -- for example, if you are distributing Abseil in a binary\r\n// package manager -- since in mode 2, absl::variant will name a different\r\n// type, with a different mangled name and binary layout, depending on the\r\n// compiler flags passed by the end user.  For more info, see\r\n// https://abseil.io/about/design/dropin-types.\r\n//\r\n// User code should not inspect this macro.  To check in the preprocessor if\r\n// absl::variant is a typedef of std::variant, use the feature macro\r\n// ABSL_USES_STD_VARIANT.\r\n\r\n#define ABSL_OPTION_USE_STD_VARIANT 0\r\n\r\n\r\n// ABSL_OPTION_USE_INLINE_NAMESPACE\r\n// ABSL_OPTION_INLINE_NAMESPACE_NAME\r\n//\r\n// These options controls whether all entities in the absl namespace are\r\n// contained within an inner inline namespace.  This does not affect the\r\n// user-visible API of Abseil, but it changes the mangled names of all symbols.\r\n//\r\n// This can be useful as a version tag if you are distributing Abseil in\r\n// precompiled form.  This will prevent a binary library build of Abseil with\r\n// one inline namespace being used with headers configured with a different\r\n// inline namespace name.  Binary packagers are reminded that Abseil does not\r\n// guarantee any ABI stability in Abseil, so any update of Abseil or\r\n// configuration change in such a binary package should be combined with a\r\n// new, unique value for the inline namespace name.\r\n//\r\n// A value of 0 means not to use inline namespaces.\r\n//\r\n// A value of 1 means to use an inline namespace with the given name inside\r\n// namespace absl.  If this is set, ABSL_OPTION_INLINE_NAMESPACE_NAME must also\r\n// be changed to a new, unique identifier name.  In particular \"head\" is not\r\n// allowed.\r\n\r\n#define ABSL_OPTION_USE_INLINE_NAMESPACE 1\r\n#define ABSL_OPTION_INLINE_NAMESPACE_NAME lts_2020_02_25\r\n\r\n#endif  // ABSL_BASE_OPTIONS_H_\r\n```", "comments": ["Hello I wanted to ask if you managed to solve this and how you were able to build TF 2.4 in order to see that function. I am still getting the Linker error symbol not found on \"class tensorflow::Status __cdecl tensorflow::FreezeSavedModel\" even after modifying the BUILD file to include it. Thank you", "The problem is never resolved. I haven't touch this project for quite awhile and I have forgot how I get it. But I think it was a lot of gdb backtrace that leads me to the file."]}, {"number": 45942, "title": "standalone pip package for tf.io.gfile.GFile", "body": "\r\nIs there a chance to somehow split the `io.gfile` into a standalone pip package? This would be great!\r\n\r\nThe current `tf.io.gfile.GFile` API is very handy for transparently accessing local or GCS bucket files.\r\nIt is so great, I wish I could use it even in projects where I don't have tensorflow. As far as I'm aware the only/main alternative is to use the `google-cloud-storage` pip package (`google.cloud.storage.Client`), but it does not provide a python ideomatic API and cannot transparently handle local files.\r\n\r\nI'm not sure where and what would be the best way to handle this, therefore I posted a related issue at googleapis/python-storage#354.", "comments": ["@kpe Do you mean something like this https://github.com/dask/gcsfs ?", "@vnvo2409 - thank you, I've missed `dask/gcsfs`, but it seems to be what I need! Thank you!\r\n\r\n(I still like the way how `tf.io.gfile.GFile` can also open local files, something that seems to not be the case with `dask/gcsfs`, but it will do)", "I think it is possible to compile a pip package for gfile without tensorflow but it will require a lot of efforts.", "After conversion to modular filesystems fully lands, we might revisit this, as it becomes possible.", "+1  gfile is a beautiful tool which is not only for GCS but also other file systems like HDFS.  It will be great we can have it as a standalone package.", "+1 for a standalone package. HDFS access through GFile is nice to have independently of TF ", "+1"]}, {"number": 45941, "title": "Index used for OOV 'UNK' token from Tokenizer has a breaking change from 2.1.4 to 2.3.0.", "body": "In Keras 2.1.4, the OOV token added to [Tokenizer](https://faroit.com/keras-docs/2.1.4/preprocessing/text/#tokenizer) will create a new vocabularly index that is 1 unit larger than the largest actual word index. Overall, in 2.1.4, you have index 0 as a reserved token index, index 1 through N as word indexes for actual words in a vocabulary, and index N + 1 as the 'UNK' OOV index.\r\n\r\nIn Keras 2.3.0, the OOV token uses index 1 instead of N + 1. This affects any pass through use of the tokenizer as well, such as when using `texts_to_sequences`.\r\n\r\nThis is a breaking change that makes Keras code written for 2.1.4 incompatible with 2.3.0 (for example, tests validating the existence of the 'UNK' token will fail, and re-training some models will leads to wrong word indices in applications that take e.g. an embedding vector learned for the UNK token and use it for other types of processing. Such code will now incorrectly be taking an embedding vector for a real word at index N + 1. Fine-tuning or transfer learning of a model with an Embedding layer that relies on this OOV behavior will also fail, since any new usage of `keras.preprocessing.text.Tokenizer` (such as `texts_to_sequences`) to process inputs into the embedding layer will have swapped the meaning of index N + 1 (previously learned weights for OOV) into index position 1 - and any auxiliary code users have written to extract word embeddings or to do feature importance studies at the level of individual word vectors will be wrong). \r\n\r\nThere's currently no API support to always access into the embedding layer via some other mechanism that abstracts away the position of the OOV index, especially since users can provide their own custom token string to use - so unfortunately the actual index position itself is an exposed part of the API of Tokenizer.\r\n\r\nI'm curious why this breaking change didn't require updating Keras to 3.0.0 at the time, given that it is breaking the version contracts of semver.\r\n\r\nAre there any configuration options to restore the old OOV index behavior (N + 1 instead of 1) when using keras 2.3.0?\r\n\r\nTracking this down through code history, you can see the original version of the preprocessing handling here (using N + 1 as the index):\r\n\r\n- https://github.com/keras-team/keras-preprocessing/blame/ea4b8e16d48e2522e6b497d7df9c04aedc63fc7b/keras_preprocessing/text.py#L238\r\n\r\nand then you can see the new implementation here, specifically setting the OOV index to 1 instead of N + 1:\r\n\r\n- https://github.com/keras-team/keras-preprocessing/commit/878a605a6418c8105ac4c9226945a18ce9e3bf57#diff-45a6438ee723ad37ca89a89ab8d76a4b3e645c3f70d7ec16a5a35fd80a6379c5R230\r\n\r\nThe way it manifests as a breaking change seems to affect both `keras_preprocessing` as a separate package and transitively `keras` according to the way `keras` sets version pins on `keras_preprocessing`.\r\n", "comments": ["@espears1,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@amahendrakar Can you elaborate on what kind of example you'll need? I linked all the source code in my original post which shows the explicit code change creating the bug. Essentially, _any possible_ use of `keras.preprocessing.text.Tokenizer` (particularly `texts_to_sequences`) will have a logically breaking difference between 2.1.4 and 2.3.0 if you examine which position of the Tokenizer's vocabulary houses the OOV token, as described above.", "I'm not sure the TF2.3 label applies - this is about the jump from Keras 2.1.4 to 2.3.0\r\nUpdate: This behavior change actually occurs between Keras 2.2.0 and Keras 2.2.1 (and they're associated required versions of Keras-Preprocessing)", "Here's a minimal sample:\r\n```\r\nfrom keras.preprocessing.text import Tokenizer\r\ntokenizer = Tokenizer(50, oov_token=\"Unknown\")\r\ntokenizer.fit_on_texts([\"I am a sequence of words\", \"I am another sequence\"])\r\nprint(tokenizer.texts_to_sequences([\"I am a sequence of characters\"]))\r\n```\r\n\r\nWith Keras 2.2.0 it outputs `[[1, 2, 4, 3, 5, 8]]`\r\nWith Keras 2.2.1 it outputs `[[2, 3, 5, 4, 6, 1]]`\r\n\r\n", "@rossmessing Thank you - great example!\r\n\r\n@jvishnuvardhan @amahendrakar consider the above example and what happens if you use this tokenization scheme to fine-tune a model with an Embedding layer. Suppose the model was originally trained in keras 2.2.0. Within the Embedding layer, index `8` is for out-of-vocabulary words, and the embedding weights for that token index are learned for that purpose. Meanwhile, index `1` weights are learned for `'I'`. Now later if you come back and try to fine-tune in keras 2.2.1, the OOV words will be causing modifications to weights originally learned for `'I'` in index position 1.\r\n\r\nThis is just one use case. There are many others where you must actually look at the index positions of the output of `texts_to_sequences` and then use them to index into other companion arrays of metadata, pre-trained word vectors, etc.\r\n\r\nWhat it means is that within the output of `texts_to_sequences`, the position of `N + 1` (where `N` is the vocabulary size) has a semantic meaning for the user in 2.2.0 and earlier. It's functionally a part of the API because a user may be required to depend on that specific indexing choice, and this example above shows that the API \"breaks\" from 2.2.0 to 2.2.1 because of the new treatment of the OOV token's index.", "@espears1 \r\nIs this still an issue, can you please check in the latest tf and let us know.", "@Saduf2019 Yep, it's still an issue. It's a backward-compatibility-breaking issue so it affects all TF after the break from 2.2.0 to 2.2.1. Ideally even non-latest published minor versions should receive a new patch bump for it to be fixed, though that might be intractable.\r\n\r\nModels trained with 2.2.0 can't have their vocab loaded for fine-tuning in 2.2.1 or onward, because the token index positions won't correspond to the same underlying words of the vocab (due to the 'unknown' token shifting its index).", "tf.keras.preprocessing.text.Tokenizer will be deprecated in future version since it does not operate on Tensors, and is most unlikely to get any update.\r\nWe recommend you to use tf.keras.layers.TextVectorization which has similar functionality which operate on Tensors.\r\nFor details see [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer?version=nightly). Thanks! "]}, {"number": 45936, "title": "Modular filesystem inconsistent rename_file behaviour", "body": "This is not a contribution.\r\n\r\nThe new modular filesystem includes a [rename_file](https://github.com/tensorflow/tensorflow/blob/67b4154b7dff78b1a2f1d0cd1ae6bbf6cea90673/tensorflow/c/experimental/filesystem/filesystem_interface.h#L485) operation. The docstring states that the implementation must throw a TF_FAILED_PRECONDITION error if either of the src or dst paths are directories. This is also part of the [test suite](https://github.com/tensorflow/tensorflow/blob/67b4154b7dff78b1a2f1d0cd1ae6bbf6cea90673/tensorflow/c/experimental/filesystem/modular_filesystem_test.cc#L859-L882). However the [gfile rename api description](https://github.com/tensorflow/tensorflow/blob/2800f688ffcce464054e41dbb09a83815dc3810d/tensorflow/python/lib/io/file_io.py#L537) says 'Rename or move a file / __directory__.'. Current implementations of the filesystem interface follow the latter description and will happily rename a directory, eg. [s3](https://github.com/tensorflow/tensorflow/blob/67b4154b7dff78b1a2f1d0cd1ae6bbf6cea90673/tensorflow/c/experimental/filesystem/plugins/s3/s3_filesystem.cc#L1109-L1151), [gcs](https://github.com/tensorflow/tensorflow/blob/67b4154b7dff78b1a2f1d0cd1ae6bbf6cea90673/tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc#L1011-L1024).\r\n\r\nShould we follow the existing implementations or the interface documentation?\r\n", "comments": ["Thank you for pointing this out !\r\n\r\nIn fact, I am fully aware of this inconsistent. However, given that \"directory\" isn't supported by [s3](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/using-folders.html), I decided to follow the existing implementations: [s3](https://github.com/tensorflow/tensorflow/blob/9489702e35b16a40a1accf3b8b5ed557efae10c7/tensorflow/core/platform/s3/s3_file_system.cc#L1133) because it saves a lot of resources ( and less flakiness ).\r\n\r\nI am working on documentations for the new modular filesystem plugins and it will be done around TF 2.5. Please let me know if you have any question left !\r\n\r\n/cc @yongtang @mihaimaruseac ", "Wondering if we should change to `rename_path` and support the newer API", "I think it is a good idea. But it won't solve all the misunderstandings we are having. In my opinion, we just need a better document ( which I am working on )."]}, {"number": 45929, "title": "TanhExp activation function", "body": "Please add the new TanhExp activation function, it\u2019s faster to compute and converge better than Mish and Swish.\r\n\r\nLink for the paper: https://arxiv.org/pdf/2003.09855.pdf", "comments": ["@left-brain , We will work on the new feature addition and submit the code soon", "@left-brain, me and @anilkumarKanasani  have added the TanhExp activation functionality and pull request #47472 has been created for the same.", "Over to @miaout17 for follow-up."]}, {"number": 45921, "title": "FullyConnected reference_integer_ops miscalculate output data due to endianness issue on s390x", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nThe Test case `//tensorflow/lite/micro/examples/hello_world:hello_world_test` failed on s390x with error:\r\n\r\n```\r\nTesting LoadModelAndPerformInference\r\n0. (1.0*2^-127) near value (-1.1018541*2^0) failed at tensorflow/lite/micro/examples/hello_world/hello_world_test.cc:103\r\n0.841 (1.6819992*2^-1) near value (-1.1018541*2^0) failed at tensorflow/lite/micro/examples/hello_world/hello_world_test.cc:111\r\n0.141 (1.1279996*2^-3) near value (-1.1018541*2^0) failed at tensorflow/lite/micro/examples/hello_world/hello_world_test.cc:118\r\n-0.959 (-1.9179993*2^-1) near value (-1.1018541*2^0) failed at tensorflow/lite/micro/examples/hello_world/hello_world_test.cc:125\r\n0/1 tests passed\r\n~~~SOME TESTS FAILED~~~\r\n```\r\n\r\nOn debugging, I found that `GetTensorData<int32_t>(bias)` returns tensor data in LE format, where bias is an Optional Input Tensor being populated in `Eval` as ```const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);```\r\n\r\nThis tensor data of bias is used in reference_integer_ops FullyConnected in calculation of `acc`. \r\nI tried a solution of byte-swapping this data while populating `acc` which fixed the test case. The solution looked like this:\r\n```\r\nif (bias_data) {\r\n#if FLATBUFFERS_LITTLEENDIAN\r\n        acc += bias_data[out_c];\r\n#else\r\n        acc += __bswap_32(bias_data[out_c]);\r\n#endif\r\n``` \r\nin [fully_connected.h](https://github.com/tensorflow/tensorflow/blob/bba12d0401800fbf873ea35f34517a8c47a54272/tensorflow/lite/kernels/internal/reference/integer_ops/fully_connected.h#L54)\r\n\r\nSince, I do not have a view of the reach and use of this optional tensor, can you please suggest if there is another way that you would like me to try or if I should PR this solution?\r\n\r\n**Describe the expected behavior**\r\nThe tensor data on BE systems must be in correct format and the test case should pass.\r\n\r\n**Standalone code to reproduce the issue**\r\nTo reproduce the issue, please run this test case:\r\n```\r\nbazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" test --host_javabase=\"@local_jdk//:jdk\" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only -c dbg --copt=-O -c opt --copt=-g --strip never --color=yes --curses=yes --test_output=errors --verbose_failures  -- //tensorflow/lite/micro/examples/hello_world:hello_world_test\r\n```\r\n\r\n**Other info / logs**", "comments": ["I found that a similar fix is also required for `micro_speech_binary_mock_test` and `micro_speech_test` test cases to pass on s390x. The changes are required in [depthwise_conv.h](https://github.com/tensorflow/tensorflow/blob/60b9283c9e5308bae6fe19d2db531a6c230baffd/tensorflow/lite/kernels/internal/reference/integer_ops/depthwise_conv.h#L105). Here also, the bias data needs to be byte-swapped before populating `acc`. ", "Hi @advaitjain , just posting an update here.. \r\nIn tensorflow release 2.4.1, this solution causes regression to `//tensorflow/lite/micro/kernels:fully_connected_test` and similarly, fix in  `depthwise_conv.h` causes `//tensorflow/lite/micro/kernels:depthwise_conv_test` test case to fail. \r\nIt seems that these tests require `bias_data` to be in Little Endian format and is handling data accordingly while for `hello_world_test` and micro_speech_tests, `bias_data` is being used in calculation assuming that it's in BE format and hence, it's messing up the calculation of `acc`.", "Any updates from the community for this issue? Thanks!", "Hi @advaitjain , hope all is well.\r\n\r\nWonder if you have any updates reg this issue? Thanks!"]}, {"number": 45902, "title": "Number of Delegated Nodes", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Ubunto 18\r\n- TensorFlow installed from (source or binary):\r\n- source \r\n- Tensorflow version (commit SHA if source):\r\n- 2.4 nigthly\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nWhen I run my NN tflite quantized model on mobile device's DSP. I get the following message:\r\n\r\nINFO: Hexagon delegate: 44 nodes delegated out of 67 nodes with 7 partitions.\r\n\r\nWhen visualizing the tflite model, I see that the whole model was successfully quantized (FFQ or IOQ - w/ or w/o inputs/outputs) \r\nSo, why only part of the model was delegated?\r\nIs there a way to control or optimize this? how to make all the NN to go through the DSP?\r\n\r\n(Model Attached)\r\n[myModel2.zip](https://github.com/tensorflow/tensorflow/files/5724126/myModel2.zip)\r\n\r\n", "comments": ["because not all valid TfLite ops are supported by Hexagon delegate. you may want to check its [supported ops and constraints](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/hexagon/README.md)", "Thanks,\r\nI followed the supported ops in the link you sent and replaced all suspecios ops with supported ones.\r\nYet, nothing changed and I still get one third of my ops not delegated.\r\nis there a way to know which ops specifically were not delegated? could you have a look in the model I've attached?\r\n[myModel_ffq2.zip](https://github.com/tensorflow/tensorflow/files/5724934/myModel_ffq2.zip)\r\n\r\nThanks\r\n", "Unsupported nodes in the model:\r\n\r\nUnsupported node 0 QUANTIZE\r\nUnsupported node 1 QUANTIZE\r\nUnsupported node 5 CONV_2D\r\nUnsupported node 13 CONV_2D\r\nUnsupported node 16 CONV_2D\r\nUnsupported node 20 CONV_2D\r\nUnsupported node 34 CONV_2D\r\nUnsupported node 40 CONV_2D\r\nUnsupported node 47 CONV_2D\r\nUnsupported node 63 TRANSPOSE_CONV\r\nUnsupported node 65 DEQUANTIZE\r\n\r\nFor Quantize/Dequantize they are from/to float which we don't run on the DSP. If you changed your model to have inputs and outputs as int8 they will be gone.\r\n\r\nFor Conv2D, we currently only supports \r\ndilation_height_factor/dilation_weight_factor  == 1 and stride_height/stride_width <= 3\r\nIn your case dilation is the reason it is not delegated.\r\n\r\nFor TransposeConv, we currently don't handle bias - it was added in TFLite recently.\r\nIf it is blocker for your case, we are happy to add support to the bias for you.\r\n", "Thank you!\r\nI'm afraid dilation rate > 1 is much more crucial for me, since it enables you to enlarge your features space per conv operation.\r\nDo you plan to support this any time soon?\r\n", "BTW, I could replace conv dilation with AveragePooling(dilationFactor) -> conv2d(dilation =1)  -> Upsampling(dilationFactor) but unfortunately other 2 operations are not supported as well.", "I also tried to remove all unsupported ops (besides quantization of float inputs) and yet I get  \r\nINFO: Hexagon delegate: 33 nodes delegated out of 39 nodes with 3 partitions.\r\nSeems like some of the conv ops are still not delegated (dilation=1, stride<=3).\r\nAttached is the model.\r\n[myModelV3_fullDSP.zip](https://github.com/tensorflow/tensorflow/files/5729993/myModelV3_fullDSP.zip)\r\n", "For the last model shared, the unsupported ops are\r\n- Quantize/Dequantize: Same comment as my previous comment to get rid of them.\r\n- TransposeConv: In this model it is different than the previous one. I have a fix will send it shortly and will look in adding the bias later.\r\n- -ResizeBilinear: We support size < 66 at the moment, the reason is because we noticed that in some cases Hexagon NN implementation loses a lot of accuracy, so we disabled it. If you're building from source, i can point you how to enable it for testing if it doesn't cause a lot of accuracy issue for you.\r\n\r\nFor dilated conv, sure we can look in adding support to dilated conv2d. If i recall correctly Hexagon NN limits to strides 1 for dilated version.\r\n\r\nWill update the issue here when changes lands.\r\n\r\nThanks", "The TransposeConv issue in the last model should be fixed now. Wait for the latest nightly if you're relying on nightly or build from master again.\r\nWill update when other changes land.\r\n\r\nThanks", "Thanks, I will check and update.", "Update:\r\nTransposeConv with bias support was merged. Please try it and let us know if you're having issues.\r\n\r\nNext, add support for the dilated conv support. Will update when it is also added.\r\n\r\nThanks", "> Update:\r\n> TransposeConv with bias support was merged. Please try it and let us know if you're having issues.\r\n> \r\n> Next, add support for the dilated conv support. Will update when it is also added.\r\n> \r\n> Thanks\r\n\r\nHi,\r\n\r\nThanks for supporting bias now!\r\n\r\nI kindly report you that I have found an issue in TransponseConv with bias.\r\n\r\nI've just filled a new issue: #51093 \r\n\r\nBest,\r\n", "Thanks @twkx for reporting this. Will follow on the other issue.\r\nThank again.", "is there any tools and ways  to know which ops is support or not in dsp", "We have them listed here\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/hexagon/README.md"]}, {"number": 45898, "title": "Fix #45839: tf.distribute.CollectiveAllReduceStrategy can't load model from checkpoint", "body": "This code has been tested on Tensorflow v2.3, but when I tested on v2.4\uff0c\r\n\r\na new bug, not caused by the code I submitted,  was encountered.", "comments": ["Please change worker_context.should_checkpoint instead of duplicating multi_worker_util.is_chief. Evaluator should not be considered as chief, but it makes sense to enable checkpoint loading on evaluator.", "@crccw \r\nThank you for your advisement, I have modified it according to your suggestion. Please check it again and point out the \r\n\r\ndeficiencies.\r\n\r\nThanks a lot.", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@UrmsOne  Any update on this PR? Please. Thanks!", "@gbaned Sorry for my delayed reply. As @crccw said, there is no problem if use NFS, but my datasets are all above 1TB, using NFS will brings additional storage overhead. So I suggest that a switch should be reserved, when using local storage, the checkpoint file can be written by themselves. This also needs to consider the issue of backward compatibility.", "I'm not sure the reason that the size of the dataset matters. You only need to put your checkpoint files on NFS.", "@UrmsOne  Can you please check @crccw's comments and keep us posted ? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@gbaned \r\n\r\n> @UrmsOne Can you please check @crccw's comments and keep us posted ? Thanks!\r\n\r\nYes, I can.  But I want to use local storage instead of NFS for distributed training. Can I implement a custom CollectiveAllReduceStrategy to support local storage for distributed training and achieve the backward compatibility of CollectiveAllReduceStrategy? And then  PR again?\r\n", "@crccw  Can you please assist on above comments from @UrmsOne. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!", "@crccw Any update on this PR? Please. Thanks!"]}, {"number": 45879, "title": "Feature request - testing_split in ImageDataGenerator", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): `2.3.1`\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently `ImageDataGenerator` API has a parameter `validation_split` to split data-set _training_ and _validation_ split purpose.\r\n\r\n**Will this change the current api? How?**\r\n\r\nWhat about _testing_ ?\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone, I guess.\r\n\r\n**Any Other info.**\r\n\r\nAfter implementing, code may look something like this, way more simpler :\r\n```\r\nimage_datagen = ImageDataGenerator(\r\n    validation_split = 0.2\r\n    testing_split = 0.1\r\n)\r\n\r\ntrain_generator = image_datagen.flow_from_directory(\r\n        subset=\"training\",)\r\n\r\nvalid_generator = image_datagen.flow_from_directory(\r\n        subset=\"validation\",)\r\n\r\ntest_generator = image_datagen.flow_from_directory(\r\n        subset=\"testing\",)\r\n```", "comments": ["Won't this be reinitializing your train and val sets each time you run it.", "@maifeeulasad,\r\nCan you please respond to the above comment. Thanks! ", "@shrikumaran , @rmothukuru \r\n>>> Won't this be reinitializing your train and val sets each time you run it.\r\n\r\n__Won't that make code more readable and clean.__ Making code readable by a huge portion is an important criteria.", "This will be good feature we won't need to setup individual directories for the different sets we have, but when like this each time we run we will be training on a different train and val set. This may lead to overfitting if we use the pretrained model from previous epochs to continue training. So, maybe we could create a way to have a permanent record of what all images are val and train set, so that we don't mix up. Let me know what you guys think.", "We can set make that `shuffle` parameter only work for **train** and **validation** set. And forcing **test** set to take the last `n` elements. \r\n\r\nAnother way is passing a `.csv` file."]}, {"number": 45857, "title": "Changing kBufferAlignment to 8 from 16 for SIMD extensions fixes TfLite micro_allocator_test", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nWhile testing ```//tensorflow/lite/micro:micro_allocator_test``` on s390x, a segmentation fault was observed.\r\nOn debugging, I found an issue with SSE alignment. There were multiple warnings in the logs: ```8 bytes lost due to alignment. To avoid this loss, please make sure the tensor_arena is 16 bytes aligned.``` The TC was failing further when assigning the buffers but it seemed that on working on the warnings and changing `kBufferAlignment` from `16` to `8` fixed the issue.\r\n\r\nTo debug, I compared the results of this TC on Intel and s390x.\r\nIn ```MicroAllocator::Create```, with `kBufferAlignment = 16` ,  and everything else same on Intel and s390x ```uint8_t* aligned_result = reinterpret_cast<uint8_t*>(((data_as_uintptr_t + (alignment - 1)) / alignment) * alignment);``` returns `aligned_result` as ```(uint8_t *) 0x3ffffffe1e0``` where tensor_arena was ```(uint8_t *) 0x3ffffffe1d8```  while on Intel, same returns ```(uint8_t *) 0x7fffffffd2b0``` which is equal to address of tensor_arena or data_as_uintptr_t . If the value of ```kBufferAlignment``` is 8 , then aligned_arena is same as tensor_arena.\r\nAlthough, I could not find if for s390x tensor buffers should be aligned to 8 bytes or 16 bytes for SIMD extensions, but changing the value to 8 helped in passing the TCs. This value effects a multiple TfLite Micro related test cases.\r\n\r\nTo our understanding,  s390x can handle any byte alignment. It would be great if we can identify the real cause of this issue and someone can look into this issue from SIMD perspective. \r\n\r\n**Describe the expected behavior**\r\nThe tensor arena should not lose any bytes of data due to alignment.\r\n\r\n**Standalone code to reproduce the issue**\r\nTo reproduce this issue, you can simply run the test case using:\r\n```bazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" test --host_javabase=\"@local_jdk//:jdk\" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial  -k --test_timeout 300,450,1200,3600 --build_tests_only --test_output=errors -- //tensorflow/lite/micro:micro_allocator_test```\r\n\r\n**Other info / logs** \r\nA PR was raised with this change and other arena size related fixes. That PR is rejected and closed and I was asked to raise a github issue to discuss this further. PR reference: #45790 . It would be great if we can find out the real cause behind this problem. @advaitjain Can you please help tag someone who would be able to help here. Thanks!", "comments": ["Hi! Some thoughts from my side. \r\n\r\nHW architectures vary a lot and may rely on larger bus bandwidths (e.g. 128bits) to communicate efficiently with the memory. On a related note, Ethos-U55 would require the tensor arena start address (obs: the arena itself, not individual tensors) to be 16 byte aligned. Today that is handled by the micro allocator. The tensor arena and individual tensor alignment depends on the same parameter (kBufferAlignment), so they'd need to split up. A small change, but it may add to the complexity. In the case of SIMD instructions for Arm Cortex-M, the 16 byte tensor alignment does not affect on the SIMD operations, word alignment is fine. \r\n\r\nOn the topic of memory savings. If I understand the issue correctly, we may loose up to a worst case of 15 bytes per runtime tensor (and on average 7.5 bytes per runtime tensor) due to alignment. The default greedy memory planner re-uses runtime tensors. Hence, _the size of the arena is dimensioned by the largest combined size of any simultaneously used tensors_, plus \"house keeping\" dynamic memory allocations. Therefore, the worst case loss due to alignment would be 15 bytes per runtime tensor for this specific simultaneously used tensor combination.\r\n\r\nIt's quite complex to describe this in words, so I'll add a usecase:\r\n\r\nIf we use the person detection demo as an example, the a) input and b) output tensor of layer 3 represent that largest combination. The worst case alignment loss would be 30 bytes, 15 bytes for a) + 15bytes for b). That results in only about 0.02% (30/136000) memory increase of the total 136kB arena. Therefore, I think the gain of changing this alignment would be very small. Let me know what you think.\r\n\r\nRegarding the issue you ran into, I unfortunately don't have any input.", "Thanks @freddan80 for making this easier to understand. I completely agree with you that in this case gain of changing this alignment would be very small. In the case of s390x, to my understanding, the architecture can handle any byte alignment. Although with the TC failure, I started to doubt the effect of changing kBufferAlignment. \r\n\r\nMaybe, as you mentioned, splitting up kBufferAlignment for Tensor arena and individual tensor alignment is what we need here. I noticed that to populate the output arena tensor, allocation was done from tail but because flatbuffer vectors are in LE format, the tensor was first read in BE format(from tail) and then populated. This process seemed very complicated and seemed like adding into the problem of byte-alignment. Is there maybe an underlying problem here for Big Endian systems? \r\n\r\nJust an additional info, To get a successful result, I did have to increase arena_size as well for the Test case.", "@skribm9 Interesting observation regarding BE system. @advaitjain, do you know if the tests have been ran on a BE system previously?", "Hi @advaitjain do you have some time to look at this issue? ", "Apologies for the long delay @skribm9. Yes, I would guess that there is something specific to BE systems here. Unfortunately, we currently do not have the cycles to look into BE support which has been ad-hoc and untested.\r\n\r\nIn a departure from the way the code is currently implemented, my preference here would be:\r\n * The TFLM inference code should only support flatbuffers and runtime have the same endianness (without any endian transformations in the code itself).\r\n * There should be external tooling to convert a LE flatbuffer into a BE flatbuffer (which can then be used with the TFLM interpreter on a BE processor). I'd be ok with having a micro/tools/big_endian folder for such tooling.\r\n\r\n@skribm9, let me know if this direction sounds reasonable to you and if this something that you would be interested in contributing.", "Thank you for your response @advaitjain. I agree with you, flatbuffers only support Little-endian and has been causing issues in several other test cases as well. We had a discussion for Tensorflow serving code where the community kindly agreed to make changes in flatbuffer related code to make sure that it supports all potential permutations of little/big endian conversion and deployment. This is being tracked under [45009](https://github.com/tensorflow/tensorflow/issues/45009)\r\n\r\nIf you feel that the flatbuffer related changes can help with this TFLM issue as well, we can certainly wait for that issue to be closed."]}]