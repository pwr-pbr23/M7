[{"number": 8390, "title": "How can I use BatchNorm in a multi-GPU model", "body": "I want to use batch normalization in the [cifar10 example](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py) in a multi-GPU structure. All variables are stored in CPU, I build 2 Queues one for training batch and one for testing batch;  5 models( 4 for training and another for testing),\r\n\r\n GPU_tower codes like this\r\n![image](https://cloud.githubusercontent.com/assets/5405385/23892678/8d4c4e10-08d6-11e7-8d67-50d3bc32aec0.png)\r\n\r\n****Problem is**: when I add tf.contrib.batch_norm layers in my NN model . How can I  reuse those batchnorm variables ? I set reuse = True and pass namescope but get valueError. Is there a simple way to make it work? I don't want to modify a lot.**\r\n\r\nI know there are some high level framework such as [slim with the inception](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L253) model with a built-in batch-norm \r\nbut I can hardly do personal implementations (I need to add many instructions in slim.conv2d and tf.contrib.conv2d, so it's more convenient to use tf.nn.conv2d), \r\n\r\n**Could I just follow the inception Sync method but without high level frame like slim ?**\r\nThanks a lot!\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Great @boluoweifenda: I have same problem as you. Did you solve it? ", "Do not always ask us to ask on StackOverflow."]}, {"number": 8389, "title": "ArgumentError: argument --train_dir: conflicting option string: --train_dir", "body": "I met this question,when I run \"cifar10_train.py\" in jupyter.\r\n\r\n---------------------------------------------------------------------------\r\nArgumentError                             Traceback (most recent call last)\r\n/root/.jupyter/workspace/littlefish/cifar10/cifar10_train.py in <module>()\r\n     50 \r\n     51 tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\r\n---> 52                            \"\"\"Directory where to write event logs \"\"\"\r\n     53                            \"\"\"and checkpoint.\"\"\")\r\n     54 tf.app.flags.DEFINE_integer('max_steps', 1000000,\r\n\r\n/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/flags.py in DEFINE_string(flag_name, default_value, docstring)\r\n     78     docstring: A helpful message explaining the use of the flag.\r\n     79   \"\"\"\r\n---> 80   _define_helper(flag_name, default_value, docstring, str)\r\n     81 \r\n     82 \r\n\r\n/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/flags.py in _define_helper(flag_name, default_value, docstring, flagtype)\r\n     63                               default=default_value,\r\n     64                               help=docstring,\r\n---> 65                               type=flagtype)\r\n     66 \r\n     67 \r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in add_argument(self, *args, **kwargs)\r\n   1342                 raise ValueError(\"length of metavar tuple does not match nargs\")\r\n   1343 \r\n-> 1344         return self._add_action(action)\r\n   1345 \r\n   1346     def add_argument_group(self, *args, **kwargs):\r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in _add_action(self, action)\r\n   1705     def _add_action(self, action):\r\n   1706         if action.option_strings:\r\n-> 1707             self._optionals._add_action(action)\r\n   1708         else:\r\n   1709             self._positionals._add_action(action)\r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in _add_action(self, action)\r\n   1546 \r\n   1547     def _add_action(self, action):\r\n-> 1548         action = super(_ArgumentGroup, self)._add_action(action)\r\n   1549         self._group_actions.append(action)\r\n   1550         return action\r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in _add_action(self, action)\r\n   1356     def _add_action(self, action):\r\n   1357         # resolve any conflicts\r\n-> 1358         self._check_conflict(action)\r\n   1359 \r\n   1360         # add to actions list\r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in _check_conflict(self, action)\r\n   1495         if confl_optionals:\r\n   1496             conflict_handler = self._get_handler()\r\n-> 1497             conflict_handler(action, confl_optionals)\r\n   1498 \r\n   1499     def _handle_conflict_error(self, action, conflicting_actions):\r\n\r\n/root/anaconda3/lib/python3.5/argparse.py in _handle_conflict_error(self, action, conflicting_actions)\r\n   1504                                      for option_string, action\r\n   1505                                      in conflicting_actions])\r\n-> 1506         raise ArgumentError(action, message % conflict_string)\r\n   1507 \r\n   1508     def _handle_conflict_resolve(self, action, conflicting_actions):\r\n\r\nArgumentError: argument --train_dir: conflicting option string: --train_dir", "comments": ["Did you run this twice? Can you try with normal python?", "I was getting the same error and it was exactly because I ran the code more than once. Restart the kernel and the code cell once. Done!", "Nice!", "I wonder if there is any way to clear all predefined argument, since restarting the kernel each time is annoying", "The short answer is probably no. The `flags` code is based on `argparse`, which doesn't appear to support removal. You could try to reload the tensorflow module `reload(tensorflow)` or its flag module.\r\n\r\nI imagine it's possible to reset the args if you import argparse, then do: `tf.flags._global_parser = argparse.ArgumentParser()`. This is subject to change but probably won't change very frequently.", "I'm having this problem too where I've defined my learning rate in flags.py and I'm getting the error \"argparse.ArgumentError: argument --learning_rate: conflicting option string(s): --learning_rate\". However, learning_rate is only mentioned in the flags.py file (below) and the config.yaml file (both specified as floats).\r\n\r\nI've never had this error before... my code was working perfectly until I reorganized my files into subdirectories in preparation for tuning hyperparameters with Google ML Cloud engine. \r\n\r\n```\r\nimport tensorflow as tf\r\nimport sys\r\n\r\nflags = tf.app.flags\r\nflags.DEFINE_float('learning_rate', 1e-3, 'Initial learning rate')\r\nflags.DEFINE_integer('batch_size', 4, 'Batch size')\r\nflags.DEFINE_integer('input_rows', 144, 'Number of rows in input images')\r\nflags.DEFINE_integer('input_cols', 160, 'Number of columns in input images')\r\nflags.DEFINE_integer('input_filters', 3, 'Number of filters in input images')\r\nflags.DEFINE_integer('num_train_samples', 42096, 'Number of training examples')\r\nflags.DEFINE_integer('n_z', 2200, 'Size of bottleneck layer')\r\nflags.DEFINE_integer('C1', 64, 'Number of feature maps in first conv layer')\r\nflags.DEFINE_integer('C2', 32, 'Number of feature maps in second conv layer')\r\nflags.DEFINE_integer('C3', 16, 'Number of feature maps in third conv layer')\r\nflags.DEFINE_integer('FC4', 1024, 'Number of feature maps in first fully connected layer')\r\nflags.DEFINE_integer('FC5', 512, 'Number of feature maps in second fully connected layer')\r\nflags.DEFINE_integer('FC6', 256, 'Number of feature maps in third fully connected layer')\r\nflags.DEFINE_integer('kernel_size', 3, 'Kernel size for all convolutions')\r\nflags.DEFINE_integer('stride_size', 1, 'Stride size for all convolutions')\r\nflags.DEFINE_string('log_dir', './log', 'Directory to store training checkpoints')\r\nflags.DEFINE_string('train_dir', '/Users/hannahrae/data/mcam_vae/train', 'Directory containing training images')\r\nflags.DEFINE_string('test_dir', '/Users/hannahrae/data/mcam_vae/test', 'Directory containing test images')\r\nflags.DEFINE_string('val_dir', '/Users/hannahrae/data/mcam_vae/validation', 'Directory containing validation images')\r\nflags.DEFINE_integer('max_steps', 800, 'Maximum number of times to run trainer')\r\nflags.DEFINE_integer('num_epochs', 10, 'Number of times to go through all the training data')\r\nflags.DEFINE_float('l2_beta', 0.01, 'Beta term in L2 regularization of weights')\r\nflags.DEFINE_string('tmp_dir', './tmp/data', 'Directory to download data files and write the converted result')\r\n\r\nFLAGS = flags.FLAGS\r\n```\r\n\r\n<img width=\"237\" alt=\"screen shot 2017-10-02 at 4 38 01 pm\" src=\"https://user-images.githubusercontent.com/6354180/31104142-1b59b686-a790-11e7-8f9f-39855255d2f1.png\">\r\n", "If there is a module called within `cifar10_train.py`, in which a flag of the same name exists, this error may appear. Make sure to set a unique name for the flag."]}, {"number": 8388, "title": "the mnist data downloading statement always fail in tensorflow/examples/tutorials/mnist/mnist_softmax.py", "body": "Hi, \r\nIn the example code of mnist_softmax.py\r\nI always fail on:\r\nmnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\r\nThe error logs are like this:\r\n>>> mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/clock/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 211, in read_data_sets\r\n    SOURCE_URL + TRAIN_IMAGES)\r\n  File \"/home/clock/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \"/home/clock/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/home/clock/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 98, in urlretrieve\r\n    return opener.retrieve(url, filename, reporthook, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 245, in retrieve\r\n    fp = self.open(url, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 213, in open\r\n    return getattr(self, name)(url)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 350, in open_http\r\n    h.endheaders(data)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 1053, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 897, in _send_output\r\n    self.send(msg)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 859, in send\r\n    self.connect()\r\n  File \"/usr/lib/python2.7/httplib.py\", line 836, in connect\r\n    self.timeout, self.source_address)\r\n  File \"/usr/lib/python2.7/socket.py\", line 575, in create_connection\r\n    raise err\r\nIOError: [Errno socket error] [Errno 110] Connection timed out\r\n\r\n\r\nAnd I found it'll download the dataset from http://yann.lecun.com/exdb/mnist/, but Yann Lecunn's website already disappear these days. Can you choose another more stable website to download the dataset?\r\nThanks very much in advance.", "comments": ["This issue is already solved. #8171 \r\n\r\nNext TF release will have the fix.", "Thanks! Micael! It seems it's not included into PIP package yet. But I could manually change it in the library directly. I really appreciate your help.", "Close it, since it's duplicated with #8171.", "Hello,\r\nI am having following issues in sample code of mnist_softmax.py\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n\r\n>>> mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 240, in read_data_sets\r\n    source_url + TRAIN_IMAGES)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 98, in urlretrieve\r\n    return opener.retrieve(url, filename, reporthook, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 245, in retrieve\r\n    fp = self.open(url, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 213, in open\r\n    return getattr(self, name)(url)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 443, in open_https\r\n    h.endheaders(data)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 1053, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 897, in _send_output\r\n    self.send(msg)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 859, in send\r\n    self.connect()\r\n  File \"/usr/lib/python2.7/httplib.py\", line 1278, in connect\r\n    server_hostname=server_hostname)\r\n  File \"/usr/lib/python2.7/ssl.py\", line 353, in wrap_socket\r\n    _context=self)\r\n  File \"/usr/lib/python2.7/ssl.py\", line 601, in __init__\r\n    self.do_handshake()\r\n  File \"/usr/lib/python2.7/ssl.py\", line 830, in do_handshake\r\n    self._sslobj.do_handshake()\r\nIOError: [Errno socket error] [SSL: UNKNOWN_PROTOCOL] unknown protocol (_ssl.c:590)\r\n\r\n", "amanbeniwal,\r\n\r\nIt seems your issue relates to https protocal, can you make some debgging work in you environment, and if confirm it's a issue in tensorflow, and then report it as another new bug here? This bug's root cause is located to the wrong downloading  URL in tensorflow source tree, and they already fixed it, and it's closed. \r\nAnd it seems your issue relates to the SSL&HTTPS, it should be a new issue with another root cause.\r\n\r\nThanks!\r\n\r\nClock", "WARNING:tensorflow:From /home/sunil/PycharmProjects/test/testFile.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\r\nExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nWARNING:tensorflow:From /home/sunil/anaconda3/envs/condaEnvTest/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease write your own downloading logic.\r\nWARNING:tensorflow:From /home/sunil/anaconda3/envs/condaEnvTest/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use tf.data to implement this functionality.\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nWARNING:tensorflow:From /home/sunil/anaconda3/envs/condaEnvTest/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use tf.data to implement this functionality.\r\nWARNING:tensorflow:From /home/sunil/anaconda3/envs/condaEnvTest/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use tf.one_hot on tensors.\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nWARNING:tensorflow:From /home/sunil/anaconda3/envs/condaEnvTest/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\r\n\r\n**can you please help me...\r\ni'm using fedora as operating system**"]}, {"number": 8387, "title": "Tensorboard Summaries in Re-entered Scopes", "body": "Tensorboard creates a new unique scope for summaries every time existing variable scope is re-entered leading to summaries being split to different groups in the Tensorboard. This might be due to summaries using name scopes internally and re-entered variable scopes having unique `original_name_scope`.\r\n\r\n```python\r\ndef print_scope(scope):\r\n    print('               scope.name: {}'.format(scope.name))\r\n    print('scope.original_name_scope: {}'.format(scope.original_name_scope))\r\n\r\nwith tf.variable_scope('parent') as parent_scope:\r\n    print_scope(parent_scope)\r\n    with tf.variable_scope('childA') as childA_scope:\r\n        print_scope(childA_scope)\r\nprint()\r\nwith tf.variable_scope(parent_scope):\r\n    print_scope(parent_scope)\r\n    with tf.variable_scope('childB') as childB_scope:\r\n        print_scope(childB_scope)\r\n```\r\noutputs\r\n```\r\n               scope.name: parent\r\nscope.original_name_scope: parent/\r\n               scope.name: parent/childA\r\nscope.original_name_scope: parent/childA/\r\n\r\n               scope.name: parent\r\nscope.original_name_scope: parent/\r\n               scope.name: parent/childB\r\nscope.original_name_scope: parent_1/childB/\r\n```\r\nChild B is created in re-entered parent scope and has prefix for parent in the `original_name_scope`. I believe parent prefix is what confuses name scope in Tensorboard summaries. I think re-entering existing variable scope should not have these unique prefixes for parent scope.\r\n\r\nI have lemmatizer wrapped in Python class and Tensorboard summaries are created in different stages of graph build with re-entered variable scopes. Tensorboard splits graphs like so: [Screenshot](http://i.imgur.com/KRDt3wj.png)\r\n\r\nTested on Tensorflow 1.0.1\r\n", "comments": ["I also observed this same behavior with Tensorflow 1.0.1\r\n\r\nIt was quite confusing when I looked at my graph in Tensorboard. I thought I had defined my graph incorrectly. Turns out my graph was fine, and Tensorboard was just being weird.", "I have the same problem. I use helper something like\r\n\r\n```\r\ndef _variable_summaries(var, name):\r\n    with tf.name_scope(\"stats\"):\r\n        with tf.name_scope('mean'):\r\n            mean = tf.reduce_mean(var)\r\n            tf.summary.scalar(name, mean)\r\n        with tf.name_scope('sttdev'):\r\n            tf.summary.scalar(name, tf.sqrt(tf.reduce_sum(tf.square(var - mean))))\r\n        with tf.name_scope('max'):\r\n            tf.summary.scalar(name, tf.reduce_max(var))\r\n        with tf.name_scope('min'):\r\n            tf.summary.scalar(name, tf.reduce_min(var))\r\n    tf.summary.histogram(name, var)\r\n```\r\n\r\nwhich I call with \r\n\r\n```\r\n_variable_summaries(weights, layer_name + '/weights')\r\n_variable_summaries(biases, layer_name + '/biases')\r\n```\r\n\r\nfor each layer as it is created.\r\n\r\nThis used to create a collection of stats for each layer (one panel/scope per layer, containing all the collected stats). But now I get two `stats_X` layers for each layer. I also get a mess when trying to track anything that iterates and attempts to \"accumulate\" values in a single scope over time, [like the global step](https://stackoverflow.com/q/44249086/656912) or the elapsed time taken by an epoch.\r\n\r\nIs there a workaround I'm missing? Is this the intended behavior now?\r\n\r\n(I think I actually found `_variable_summaries` in older Tensorflow docs.)", "I migrated this issue to tensorflow/tensorboard#93 because TensorBoard has moved out of the TensorFlow repository and into the new tensorflow/tensorboard repository. Lets continue discussion there."]}, {"number": 8386, "title": "RegisterGradient for TF 1.0.x", "body": "Hello guys,\r\n\r\nWhat is the equivalent of `@ops.RegisterGradient('Mod')` for Tensorflow 1.0.x?\r\n\r\nIt works for 0.12 but I have this error for 1.0.1:\r\n\r\n`LookupError: No gradient defined for operation 'rnn/while/PhasedLSTMCell/FloorMod_1' (op type: FloorMod)`\r\n\r\nSource code is:\r\n\r\n```\r\n@ops.RegisterGradient('Mod')\r\ndef _mod_grad(op, grad):\r\n    x, y = op.inputs\r\n    gz = grad\r\n    x_grad = gz\r\n    y_grad = tf.reduce_mean(-(x // y) * gz, axis=[0], keep_dims=True)[0]\r\n    return x_grad, y_grad\r\n```\r\n\r\nThanks!", "comments": ["Ok my bad `Mod` was renamed to `FloorMod`. So that's why it was not registered. The interface is still the same."]}, {"number": 8385, "title": "ImportError: No module named '_pywrap_tensorflow'   Failed to load the native TensorFlow runtime.", "body": "Apologies  for the inappropriate description i am actually very new to Machine learning  my\r\n\r\nTF version is 1.0.1\r\nPython version is 3.5.2 \r\nOS windows 8 64bit and \r\n**Native pip**  \r\nas recommended on tensor flow.org\r\nhttps://www.python.org/downloads/release/python-352/\r\n\r\nThe problem ocured  at this simple import command  \r\n\r\n**import tensorflow as tf**\r\n\r\n### What other attempted solutions have you tried?\r\nNone\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n\r\n\r\n\r\nC:\\Users\\test\\Desktop>>python firstp.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__ini\r\nt__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__ini\r\nt__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\test\\Desktop\\firstp.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__ini\r\nt__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\t\r\nensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__ini\r\nt__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_st\r\narted/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["Please fill the template for new issues, with information about OS, TF version, python version etc. It is very hard to diagnose a problem without the information required on the template (made to be filled, not erased). And check your installation of tensorflow, these errors look like a bad installation.", "@WahabZia Sorry you faced issues trying to run TF. If you installed for GPU support I need you to:\r\n1. Check if your `%CUDA_HOME%` is properly set and CUDA and cuDNN DLLs directories are in your `PATH`. \r\n2. After that if the issue persists install the [Visual C++ Redistributable 2015 x64](https://www.microsoft.com/en-us/download/details.aspx?id=53587) as `MSVCP140.DLL` may be missing in your system. \r\n\r\nThanks for filling the issue and feel free to ask any questions or doubts you may still have about TensorFlow.", "Thanks @Carmezim for your kind reply i am using the  CPU-only version of TensorFlow . What should i do", "@WahabZia If you are using Python.org distribution and receiving this error is very likely `MSVCP140.DLL` is not installed in your system. \r\nSo as I provided on step 2, please try installing Visual C++ Redistributable linked above, uninstall then install TF again and let us know if you had progress on it.", "Thanks @Carmezim for the help i have found the dll from the DLLFiles.com \r\nhttps://www.dll-files.com/msvcp140.dll.html \r\nThe import issue is resolved \r\n\r\nI also used this command \r\n\r\nC:\\> pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_amd64.whl \r\n\r\nFrom this thread\r\nhttp://stackoverflow.com/questions/42011070/on-windows-running-import-tensorflow-generates-no-module-named-pywrap-tenso\r\n\r\nbefore placing the DLL in System32\r\n\r\nAnd now i am facing this issue  when i am sort of trying  to  validate my installation. \r\n\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\n\r\nMicrosoft Windows [Version 6.3.9600]\r\n(c) 2013 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\Windows\\system32>python\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AM\r\nD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') fo\r\nr unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_t\r\nype: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"')\r\n for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for\r\nunknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_ty\r\npe: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"')\r\nfor unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"'\r\n) for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') fo\r\nr unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') fo\r\nr unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"\r\n') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"C\r\nPU\"') for unknown op: UpdateFertileSlots\r\nb'Hello, TensorFlow!'\r\n>>>\r\n\r\n\r\n**Thanks alot for the help**\r\n", "Both of the problems are resolved . Thanks gentelmen for the help . The issue was occurring because of  missing MSVCP140.DLL  which was found on https://www.dll-files.com/msvcp140.dll.html \r\nor by installing   Visual C++ Redistributable as recomeded by fellows . \r\n**Thanks @Carmezim and @MicaelCarvalho for the help**", "I am also facing the same problem(2nd one). I have installed  Visual C++ Redistributable but still facing this issue. Please help me out. ", "@WahabZia  plz help", "Hello @imamol555  sorry for the late reply can you please share the logs .  So  that i  can the reason for the problem .  Sorry  again for the late reply i didn't check git account for a couple of days .", "@WahabZia plz help. You mentioned that you also faced issue 2nd, but probably forgot to mention how you addressed it. As you requested the logs are as shown below. This is same as you mentioned before\r\n\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>>\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\nb'Hello, TensorFlow!'\r\n>>>\r\n\r\nappreciate if you can help to resolve this.", "@krishnaputhran If you look up the comments you'll see his issue was due missing the `MSVCP140.DLL`. You can solve it by downloading the [Visual C++ Redistributable](https://www.microsoft.com/en-us/download/details.aspx?id=53587).\r\n\r\nBut some users had this problem after install with `pip install tensorflow` because of a bug on the wheel and not the missing DLL mentioned. To solve it uninstall TensorFlow, download this [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/124/) choosing the right version, CPU or GPU, and install with this wheel.", "@Carmezim thanks for your immediate response and I appreciate that. Yes my issue is solved now. I had to do the following as mentioned above.\r\n1. The \"import tensorflow as tf\" is solved my installing the [Visual C++ Redistributable.](https://www.microsoft.com/en-us/download/details.aspx?id=53587). Make sure in your System32 or C:\\Windows\\SysWOW64 has the msvcp140.dll \r\n2. To get rid off the second issue as mentioned above, upgrade your Tensorflow to the latest nightly build [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/124/). As the fix is not yet promoted to the release and available in the nightly builds.\r\n", "Indeed, `pip3 install --upgrade tensorflow-gpu` seems to be causing the issue (tested on Win 10), despite installing the Visual C++ Redistributable. Installing via the following command solves the problem: pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_amd64.whl", "That solved it for me, too. Thanks.", "@Carmezim   Hi, I\"m having the same error as above **(Windows 7, pip3.6, tensorflow1.2 rc,)** .  I seem to have  MS Visual c++ compiler,  Visual c++ build tools, and Visual Studio 2015 installed and If search files (in the search bar) , Windows is able to find  msvcp140.dll. \r\n\r\nAs for CUDA Path I see\r\n\r\n\r\n```\r\nSystem variables\r\n------------------\r\n\r\nvariable\r\n------------\r\n CUDA_PATH     C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\r\n CUDA_PATH_V8_0   C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\r\n```\r\n\r\n\r\nIs my CUDA_PATH okay? \r\n\r\nThank you. ", "@Moondra Which error specifically, could you please provide the log? How did you install TensorFlow 1.2?\r\nIf `MSVCP140.DLL` is in your `%PATH%` and you're getting `missing DLL` error this [script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) may be useful. Just download and run it and it will help you assess the culprit. Make sure cuDNN is also properly installed (the cuDNN files directory is in your `%PATH%`)\r\n.", "@Carmezim\r\n\r\nI installed the rc version of Tensorflow like this:\r\n\r\n`pip3.6 install tensorflow-gpu==1.2.0rc2`\r\n\r\n Here is my traceback error:\r\n\r\n```\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 18,\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\nline 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], p\r\n  File \"<frozen importlib._bootstrap>\", line 978,\r\n  File \"<frozen importlib._bootstrap>\", line 961,\r\n  File \"<frozen importlib._bootstrap>\", line 950,\r\n  File \"<frozen importlib._bootstrap>\", line 648,\r\n  File \"<frozen importlib._bootstrap>\", line 560,\r\n  File \"<frozen importlib._bootstrap_external>\",\r\n  File \"<frozen importlib._bootstrap>\", line 205,\r\nImportError: DLL load failed: The specified modul\r\n\r\nDuring handling of the above exception, another e\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow.py\", line 41, in <modul\r\n    from tensorflow.python.pywrap_tensorflow_inte\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 21,\r\n    _pywrap_tensorflow_internal = swig_import_hel\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 20,\r\n    return importlib.import_module('_pywrap_tenso\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\nline 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], p\r\nModuleNotFoundError: No module named '_pywrap_ten\r\n\r\nDuring handling of the above exception, another e\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorfl\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow.py\", line 52, in <modul\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 18,\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\nline 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], p\r\n  File \"<frozen importlib._bootstrap>\", line 978,\r\n  File \"<frozen importlib._bootstrap>\", line 961,\r\n  File \"<frozen importlib._bootstrap>\", line 950,\r\n  File \"<frozen importlib._bootstrap>\", line 648,\r\n  File \"<frozen importlib._bootstrap>\", line 560,\r\n  File \"<frozen importlib._bootstrap_external>\",\r\n  File \"<frozen importlib._bootstrap>\", line 205,\r\nImportError: DLL load failed: The specified modul\r\n\r\nDuring handling of the above exception, another e\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow.py\", line 41, in <modul\r\n    from tensorflow.python.pywrap_tensorflow_inte\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 21,\r\n    _pywrap_tensorflow_internal = swig_import_hel\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\n\\python\\pywrap_tensorflow_internal.py\", line 20,\r\n    return importlib.import_module('_pywrap_tenso\r\n  File \"C:\\Users\\Moondra\\AppData\\Local\\Programs\\P\r\nline 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], p\r\nModuleNotFoundError: No module named '_pywrap_ten\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_so\r\n\r\nfor some common reasons and solutions.  Include t\r\nabove this error message when asking for help.\r\n```\r\n\r\n\r\n\r\n\r\nMy Path variable looks like this:\r\n\r\n`C:\\Program Files  (x86)\\Tesseract-OCR\\;C:\\Users\\Moondra\\Anaconda_related\\Anaconda\\geckodriver.exe;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python36;C:\\Users\\Moondra\\Cygwin\\bin;C:\\Users\\Moondra\\Anaconda_related\\Anaconda;C:\\Users\\Moondra\\Anaconda_related\\Anaconda\\Scripts;C:\\Users\\Moondra\\Anaconda_related\\Anaconda\\Library\\bin;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python35\\;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python36\\;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Python35\\Scripts;C:\\Users\\Moondra\\AppData\\Local\\Programs\\Python\\Launcher\\`\r\n\r\n\r\n\r\n\r\n\"Make sure cuDNN is also properly installed (the cuDNN files directory is in your %PATH%)\"\r\n\r\n\r\nI don't think I have this installed. I'm assuming this is separate from CUDA? I've installed NVDIA CUDA but is this a separate install? Thank you. ", "@Moondra that's most likely the problem. cuDNN is a separate library required to run TensorFlow with GPU support. Until next release cuDNN 5.1 is the compatible version on Windows (on next release it will be 6.0).", "@Carmezim  Okay, so I've downloaded cuDNN 5.1 (Version 8.0), and unzipped. There seems to be no exe file, so I just put the folder somewhere and created a path to the `cudnn64_5.dll`  file located within the folder. \r\n\r\n `C:\\Nvidia_CUDL\\cuda\\bin\\cudnn64_5.dll`    (This is the path I've created in the path variable)\r\nIs the file I'm supposed to create a path to?\r\nHowever,  I still seem to be presented with the error. \r\n\r\nThank you.", "@Moondra You can find the instructions to install cuDNN on NVIDIA's website. cuDNN is not an executable file but library files. \r\nUsually the content of the cuDNN zip matches the folders inside CUDA's directory (include, lib64 etc), so you could basically extract/copy them there. \r\n\r\nTry downloading the script I provided above made by @mrry and run it locally. You will have a better assessment of the reason why you're receiving these errors. If it's CUDA/cuDNN related then you haven't installed them properly. ", "@Carmezim  I finally got it! Yeah you are supposed to insert the contents into the CUDA directory.\r\n(I was also missing a third path variable)\r\n\r\nThis blog was REALLY useful in showing how to install to install all the necessary drivers for tensorflow. \r\nhttps://nitishmutha.github.io/tensorflow/2017/01/22/TensorFlow-with-gpu-for-windows.html\r\n\r\nI  suggest you guys add it your docs or official website as I think it will save you guys a lot of time from dealing with newcomers like me.\r\n\r\n\r\nThank you so much for all of your help.", "Why not create a test case for it? It will be great for future releases. :)", "@Moondra Nice you got it working. Thanks for the feedback, TF team will appreciate. I think in this case though it does not make sense to provide instructions for third party libraries/software as is supposed for users to take care of that themselves e.g. follow official docs already available from NVIDIA, and kind of out of TF range to make sure third party libraries are installed properly by users, so IMO it's out of TF's responsibility. For instance you also notice they don't teach you how to install Python or which dist. etc. But if they decided to to that would certainly save some time for first time users.", "@Carmezim   Yeah I suppose you are right. Nvidia's docs were pretty confusing though;\r\n\r\nThe whole Visual Studio project and linker etc were instructions were really confusing.  Maybe I should email them. \r\n\r\n`WINDOWS\r\n\r\n    Add <installpath> to the PATH environment variable.\r\n\r\n    In your Visual Studio project properties, add <installpath> to the Include Directories \r\n    and Library Directories lists and add cudnn.lib to Linker->Input->Additional Dependencies.`\r\n\r\n\r\nAnyway, thank you so much for working with me until I got it working.  I really appreciate it. ", "@Moondra yeah, NVIDIA docs can be a bit confusing for a beginner but again, IMO their docs are not up to TF. Glad you got it working! ", "Hi Caremzim,\r\n\r\nthank you for providing your script. I used it, got the following response:\r\n![image](https://user-images.githubusercontent.com/29492654/27243811-3c6b626e-52d3-11e7-87f3-cf724085a2d1.png)\r\n\r\nIf I just try to import, I get this\r\n![image](https://user-images.githubusercontent.com/29492654/27243853-6f699122-52d3-11e7-95a4-121bc7908c40.png)\r\n\r\nI have intalled cuda 7.5 with cudnn 5 on windows server 2012 r2. MS redistributable 2015 also installed.\r\nThanks a lot,\r\n\r\nBlg\r\n", "@hadamschek Hi, glad it was helpful although that is not my script, you can thank @mrry for kindly create and provide it though :) \r\nYour error is likely due your CUDA version. If you refer to TensorFlow docs you will notice only CUDA 8.0 is supported on Windows. If you install it with cuDNN 5.1 for CUDA 8.0 you might solve this issue. Also I don't really know about Windows Server but you OS needs to be 64-bit as well as Python. Let me know if you face any further issues.\r\n\r\n \r\n", "@hadamschek Just curious, how did you install the gpu version? e.g via standard pip install or using the nightly build? If you are using the standard pip install for gpu, it is not stable. If you have not tried the nightly build, perhaps you can install it with its latest stable version. ", "@Carmezim @krishnaputhran  hi guys i have read through each of your guys comments and followed yet i am having an issues while doing import tensorflow as tf i am trying to do this on window 10 below is log \r\nPython 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3.5\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nPlease hELP\r\ntHANK yOU", "@abhigoku10 Please try running the script again and it will point you what may be causing this. It may be you didn't install CUDA and cuDNN correctly adding their directories to your `%PATH%` but as you are using a Python Anaconda distribution a common cause is  a missing `MSVC140.DLL`  in your system which you can get downloading the [Microsoft Visual C++ 2015 Redistributable Update 3](https://www.microsoft.com/en-us/download/details.aspx?id=53587).\r\n\r\nNext time going through TensorFlow's installation guide [under common problems](https://www.tensorflow.org/install/install_windows#common_installation_problems) may save you some time.", "@Carmezim  Thanks for the tips, i uninstalled everything and followed the steps again, then i found out the cudnn dlls i have downloaded was of different, now everything is working fine i am able to import and run the code. Appreciate the help tq ", "@Carmezim  just installed tensorflow-gpu version from pip.The specs are as follows:\r\ncuda v8.0\r\ncudnn 7.0\r\nalso MSVCP140.DLL is in the path\r\n\r\nthe following error is occurring when importing tensorflow\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"F:\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\nline 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"F:\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <mod\r\nule>\r\n    from tensorflow.python import *\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49,\r\nin <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\nline 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"F:\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\nline 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inter\r\nnal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"F:\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\n\r\n\r\n\r\n", "@Carmezim Any help would be appreciated", "@furyjack could you try running this [script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) to see what can be going wrong? I'm not following TF on Windows it's been a while but one thing stands out to me which is your cuDNN version. Isn't the latest supported according to the docs v6.1?", "@Carmezim i ran the script this was the output of it\r\n\r\n(root) C:\\Users\\Admin\\Desktop>python tensorflow_self_check.py\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.5.\r\n\r\n- TensorFlow is installed at: F:\\Anaconda3\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Download and install CUDA 8.0 from\r\n  this URL: https://developer.nvidia.com/cuda-toolkit\r\n\r\n- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Note that installing cuDNN is a\r\n  separate step from installing CUDA, and it is often found in a\r\n  different directory from the CUDA DLLs. You may install the\r\n  necessary DLL by downloading cuDNN 5.1 from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\n- Could not find cuDNN.\r\n\r\nMy path variables\r\nCUDA_HOME : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\r\nCUDA_PATH : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\r\nCUDA_PATH_V8_0: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\r\n\r\nand in my path variable i have\r\n1)C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\extras\\CUPTI\\libx64\r\n2)C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\x64\r\n\r\n\r\n", "@Carmezim Thanks i found out the problems \r\n1)path variables should have a extra \\bin at the end\r\n2)the cuda version should have been 6\r\n3)in path variable there should be have been and extra C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\cuda\\bin", "- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: C:\\python36\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that\r\n  this DLL be installed in a directory that is named in your %PATH%\r\n  environment variable. Typically it is installed in 'C:\\Windows\\System32'.\r\n  If it is not present, ensure that you have a CUDA-capable GPU with the\r\n  correct driver installed.\r\n\r\n- Could not find cuDNN 6.\r\n\r\n  The GPU version of TensorFlow requires that the correct cuDNN DLL be installed\r\n  in a directory that is named in your %PATH% environment variable. Note that\r\n  installing cuDNN is a separate step from installing CUDA, and it is often\r\n  found in a different directory from the CUDA DLLs. The correct version of\r\n  cuDNN depends on your version of TensorFlow:\r\n  \r\n  * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll')\r\n  * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll')\r\n    \r\n  You may install the necessary DLL by downloading cuDNN from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\nwhat to do", "what is the matter here\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: C:\\python36\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that\r\n  this DLL be installed in a directory that is named in your %PATH%\r\n  environment variable. Typically it is installed in 'C:\\Windows\\System32'.\r\n  If it is not present, ensure that you have a CUDA-capable GPU with the\r\n  correct driver installed.", "@viveky444 \r\nI wrote an article about this.\r\n[Link to article](https://medium.com/@lakshaytaneja26/https-medium-com-lakshaytaneja26-installing-tensorflow-on-windows-e577edfacade).Hope this helps.", "@Carmezim Your script helped me fix my problem (not posted here), thank you very much!", "@bottino happy you fixed your problem :)\r\njust for the record though the script is by @mrry so kudos to him \ud83d\ude04, and indeed it's a very handy tool", "Maybe there is another solution if you have tried such solutions above and still not config like me, you can install a older vision of tensorflow since the latest vision of it may have some problems, and i used : \"pip install https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.2.0-cp35-cp35m-win_amd64.whl \" and solve it.", "@Carmezim \r\nOS: CentOS 7.3\r\nAnaconda Version: 4.3.30\r\n\r\nI have built tensorflow v1.4-rc1 from source. It looks like all is well until I run the TensorFlow python scripts. I checked the directory `site-packages/tensorflow/python/` and found that there is no `_pywrap_tensorflow.so` file. \r\n\r\nWhat makes me confused is that the whl package built from source works on another machine.", "@DjangoPeng I've never really dealt with TF on \r\nCentOS but if you could provide the logs if I cannot, others may help. What scripts do you refer?", "Somebody please help me with this problem:\r\n\r\nPython 3.6.3 (v3.6.3:2c5fed8, Oct  3 2017, 18:11:49) [MSC v.1900 64 bit (AMD64)]\r\n on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helpe\r\nr\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__i\r\nnit__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helpe\r\nr\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__i\r\nnit__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\r\n\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helpe\r\nr\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Neeraj\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__i\r\nnit__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\nDuring handling of the above exception, another exception occurred:", "@narendra-7638 Hi, could you try running [this script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) locally and see what it indicates?\r\nThere's clearly a missing or misplaced DLL TensorFlow isn't able to locate in your system so it will help pointing that out.", "Hi @Carmezim and @WahabZia , I m facing the same issue for installing TF for CPU-only version. I guess i don't need to install CUDA for CPU-only version. I tried using the following\r\n`pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu /tensorflow-1.6.0-cp35-cp35m-win_amd64.whl`\r\n\r\nBut getting the following error\r\n\r\n`tensorflow-1.6.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.`\r\n\r\nPlease help. I have downloaded CUDNN-9.1 but i still feel that i don't need it for CPU-only version, SO haven't installed it yet.\r\nI have the MSVC140.DLL in System32 folder. Also added it in PATH environmental variable.\r\n\r\nAlso I was working on the previous version of tensorflow i.e 1.5.0 and everything worked fine. This problem started wen I upgraded to the latest version 1.6.0 just to avoid warnings\r\n\r\nPython : 3.6.4 installed from python.org for 64bit executable\r\nTensorflow : 1.6.0 using command  \"pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.6.0-cp36-cp36m-win_amd64.whl\"\r\nSystem Windows 7 64-bit\r\nNative pip\r\n\r\nPlease revert asap.. Thanking you in anticipation\r\n\r\nhere is the trace stack\r\n\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  ImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Software-Installations\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>> \r\n\r\n", "Hi Ive got the same problem and ive tried all the solutions i can find but i still get the same result  \r\n\r\nD:\\Avinaash\\Downloads\\models-master\\models\\research>python object_detection/builders/model_builder_test.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"object_detection/builders/model_builder_test.py\", line 18, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Avinaash\\AppData\\Local\\Programs\\Python\\Python35\\lib\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n\r\n", "Use python3.5 version it solves all the problems. I spent almost weeks on these errors.", "> @WahabZia Sorry you faced issues trying to run TF. If you installed for GPU support I need you to:\r\n> \r\n> 1. Check if your `%CUDA_HOME%` is properly set and CUDA and cuDNN DLLs directories are in your `PATH`.\r\n> 2. After that if the issue persists install the [Visual C++ Redistributable 2015 x64](https://www.microsoft.com/en-us/download/details.aspx?id=53587) as `MSVCP140.DLL` may be missing in your system.\r\n> \r\n> Thanks for filling the issue and feel free to ask any questions or doubts you may still have about TensorFlow.\r\n\r\nWhen I try to install using [this install](https://download.microsoft.com/download/9/3/F/93FCF1E7-E6A4-478B-96E7-D4B285925B00/vc_redist.x64.exe) it gives me error that  \r\n\r\n> `Another versionof this product is already installed. Installation of this version can not continue. To configure ....bla bla bla`\r\n\r\nPlease Help", "Hello,\r\n\r\ni have the Visual C++ Redistributable 2015 x64 as well as DLL (msvp..) file too....\r\ni am using tensorflow for the first time on windows 10\r\nwhen i m running the following statement in python \r\nimport tensorflow as tf \r\n==============================================================\r\nit gives the following error\r\n==============================================================\r\nimport tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Gaurav Shimpi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n======================================================\r\nPlease assist :(", "I have the same issue as @hemangjoshi37a . I seem to have `Visual C++ Redistributable 2017 x64` installed. I do not wish to uninstall it but there is no way to install 2015 without uninstalling it as far as I can see. Please advise on what should be done here.", "@TomMaullin okay bro. Thank for the help.", "I am also facing the same error.\r\n\r\npython --version gave\r\n`Python 3.7.0`\r\n\r\nTensorflow version is \r\n\r\n(0.12.0)\r\n\r\nI have already installed Microsoft Visual C++ Redistribution (x64) 9.0.30729.17/.6161 / .21022 /(x86) 30729.17/ (x86) 30729.6161\r\n\r\n Microsoft Visual C++ Redistribution2015-2019  (x64)  14.25.28508\r\n Microsoft Visual C++ Redistribution2015-2019  (x64)  14.31.31103\r\n\r\nI have included path to all dlls  to environment variable path.\r\n\r\nOS is Win 7 Ultimate.\r\n\r\nWhen I do \r\n`import tensorflow as tf`\r\n\r\n I get following error\r\n`---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in swig_import_helper()\r\n     17         try:\r\n---> 18             fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n     19         except ImportError:\r\n\r\nh:\\python installed\\lib\\imp.py in find_module(name, path)\r\n    296     else:\r\n--> 297         raise ImportError(_ERR_MSG.format(name), name=name)\r\n    298 \r\n\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     53     # use `dlopen()` for dynamic loading.\r\n---> 54     from tensorflow.python import pywrap_tensorflow\r\n     55 except ImportError:\r\n\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in swig_import_helper()\r\n     19         except ImportError:\r\n---> 20             import _pywrap_tensorflow\r\n     21             return _pywrap_tensorflow\r\n\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-4234dfe0332e> in <module>\r\n----> 1 import tensorflow as tf\r\n      2 from tensorflow.keras.utils import to_categorical\r\n\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\nh:\\python installed\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     58 please exit the tensorflow source tree, and relaunch your python interpreter\r\n     59 from there.\"\"\" % traceback.format_exc()\r\n---> 60   raise ImportError(msg)\r\n     61 \r\n     62 # Protocol buffers\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"h:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"h:\\python installed\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"h:\\python installed\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"h:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"h:\\python installed\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.`"]}, {"number": 8384, "title": "_pywrap_tensorflow_internal.so: ELF file OS ABI invalid", "body": "improt tensorflow as tf\r\nErrorinfo:\r\n imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: $PATH/tensorflow/python/_pywrap_tensorflow_internal.so: ELF file OS ABI invalid\r\n\r\nthere is _pywrap_tensorflow_internal.so in path. how can i solve this \u201cELF file OS ABI invalid\u201d\r\ninstall with pip\r\ntensorflow version\uff1ahttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.1-cp27-none-linux_x86_64.whl\r\n\r\nOS info\uff1aLinux NAME #1 SMP TIME x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nfile _pywrap_tensorflow_internal.so\uff1a _pywrap_tensorflow.so: ELF 64-bit LSB shared object, AMD x86-64, version 1 (GNU/Linux), not stripped\r\n\r\n### Environment info\uff1a\r\nLinux NAME #1 SMP TIME x86_64 x86_64 x86_64 GNU/Linux\r\nLinux version 2.6.32_1-12-0-0 (scmpf@dbl-sat-dev01.dbl01.baidu.com) (gcc version 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) ) #1 SMP Mon Aug 12 17:59:52 CST 2013\r\nCentOS release 4.3 (Final)\r\nKernel \\r on an \\m\r\nLSB Version:    :core-3.0-amd64:core-3.0-ia32:core-3.0-noarch:graphics-3.0-amd64:graphics-3.0-ia32:graphics-3.0-noarch\r\nDistributor ID: CentOS\r\nDescription:    CentOS release 4.3 (Final)\r\nRelease:        4.3\r\nCodename:       Fina\r\n\r\n###The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`\uff1a\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\nImportError: /home/users/caoshiwei/.jumbo/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: ELF file OS ABI invalid\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help\r\n", "comments": ["Please provide all the information asked for in the \"New Issue\" template (which includes version, OS, architecture etc.).", "I have add some infos about this Issue", "Please do provide _all_ the information asked for in the \"New Issue\" template, without which it is hard to diagnose (for example, which distribution/version of Linux are you using)\r\n\r\nFrom Googling the error message, it seems that this might have to do with the fact that your machine/Linux distribution might have a very old loader?", "updated Issue\r\nthat\u2018s all INFO about this Issue\r\nthe  machine/Linux distribution is old loader as Environment info shown", "As @asimshankar said, this is CentOS 4.4, which was released about 10 years ago apparently. Linux used to have SystemV formatted binaries, I think.\r\n\r\nAccording to this, if you use `od` you should be able to see which format you have.\r\nhttps://en.wikipedia.org/wiki/Executable_and_Linkable_Format\r\n\r\nThe only route is to build from source, but you need `gcc-4.x` with `C++11` support for that. You might be able to cross-compile.", "thx~"]}, {"number": 8383, "title": "Importing graph with control flow using TF_GraphImportGraphDef crashes", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/8284\r\nhttps://github.com/tensorflow/tensorflow/issues/5406\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nmacOS 10.12.3\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nCPU only\r\n\r\n1. The commit hash (`git rev-parse HEAD`) e895d5ca395c2362df4f5c8\r\n2. The output of `bazel version`\r\n\r\n```\r\nBuild label: 0.4.4-homebrew\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 2 01:05:15 2017 (1485997515)\r\nBuild timestamp: 1485997515\r\nBuild timestamp as int: 1485997515\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework.graph_util import convert_variables_to_constants\r\n\r\nx = tf.placeholder(tf.float32, shape=(None), name=\"x\")\r\n\r\ndef add_one(x):\r\n  return tf.add(x, 1)\r\n\r\ny = tf.map_fn(add_one, x)\r\n\r\ny = tf.identity(y, name=\"y\")\r\n\r\nwith tf.Session() as sess:\r\n  print(tf.get_default_graph().as_graph_def().node)\r\n  minimal_graph = convert_variables_to_constants(sess, sess.graph.as_graph_def(add_shapes=True), [\"y\"])\r\n  tf.train.write_graph(minimal_graph, '.', 'minimal_graph.proto', as_text=False)\r\n```\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n  tf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n  \"io/ioutil\"\r\n)\r\n\r\nfunc main() {\r\n  modelPath := \"cond_test/minimal_graph.proto\"\r\n  graphDef, _ := ioutil.ReadFile(modelPath)\r\n  graph := tf.NewGraph()\r\n  graph.Import(graphDef, \"\")\r\n}\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n- Loading the graph without the `map_fn` works as expected. (`y = add_one(x)`)\r\n- Originally encountered problem using prebuild tensorflow for python: `pip install tensorflow`\r\n- Same issue when saving / restoring using SavedModel routines.\r\n\r\n### Logs or other output that would be helpful\r\n\r\n```\r\nfatal error: unexpected signal during runtime execution\r\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x5de318c]\r\n\r\nruntime stack:\r\nruntime.throw(0x40cdc29, 0x2a)\r\n\t/usr/local/go/src/runtime/panic.go:596 +0x95\r\nruntime.sigpanic()\r\n\t/usr/local/go/src/runtime/signal_unix.go:274 +0x2db\r\n\r\ngoroutine 1 [syscall, locked to thread]:\r\nruntime.cgocall(0x40973d0, 0xc42004de60, 0x40b34e0)\r\n\t/usr/local/go/src/runtime/cgocall.go:131 +0xe2 fp=0xc42004de30 sp=0xc42004ddf0\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_GraphImportGraphDef(0xbf00020, 0xd0be3f0, 0xd0bee20, 0xd0bd5a0)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:386 +0x45 fp=0xc42004de60 sp=0xc42004de30\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Graph).Import.func7(0xbf00020, 0xd0be3f0, 0xd0bee20, 0xd0bd5a0)\r\n\t/Users/olav/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:96 +0x121 fp=0xc42004de98 sp=0xc42004de60\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Graph).Import(0xc42000e038, 0xc42008a000, 0x1ae9, 0x1ce9, 0x0, 0x0, 0x0, 0x0)\r\n\t/Users/olav/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:96 +0x1ef fp=0xc42004df00 sp=0xc42004de98\r\nmain.main()\r\n\t/Users/olav/go/src/github.com/olavhn/infer/test.go:14 +0x112 fp=0xc42004df88 sp=0xc42004df00\r\nruntime.main()\r\n\t/usr/local/go/src/runtime/proc.go:185 +0x20a fp=0xc42004dfe0 sp=0xc42004df88\r\nruntime.goexit()\r\n\t/usr/local/go/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc42004dfe8 sp=0xc42004dfe0\r\n\r\ngoroutine 17 [syscall, locked to thread]:\r\nruntime.goexit()\r\n\t/usr/local/go/src/runtime/asm_amd64.s:2197 +0x1\r\n```\r\n", "comments": ["Thanks very much for the detailed bug report and instructions to reproduce, this is very helpful.\r\n\r\nUpon investigation, I believe the cause here is exactly the same as #8284, so I'm closing this out as a duplicate. The fix should be in shortly."]}, {"number": 8382, "title": "How can I modify RNN cell weight during each training epoch?", "body": "I want to binarize the weights of RNN-GRU cell during each training epoch, in order to reduce the model size and increase the performance. Instead of binarizing the weights after freezing the graph, I wonder how can I get access to and modify the weights during each training epoch, or more specifically, before computing gradients and updating weights? It seems no API is provided to let RNN cell weight exposed to users.\r\nThank you so much.\r\n", "comments": ["Your question can be better addressed on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). The GitHub \"Issues\" section is mainly for bug reporting and feature requests.\r\n\r\nOn the topic: take a look at `tf.get_variable`, it may help you.", "As @MicaelCarvalho this is best answered on StackOverflow where we monitor all questions with the tag `tensorflow`. All optimizers have the `compute_gradients` method. You will get the variables and gradients back, then you can modify them at your leisure, before calling `apply_gradients`."]}, {"number": 8381, "title": "DropoutWrapper in rnn_cell", "body": "DropoutWrapper in rnn_cell do not have a state for training or testing.  Although the keep_prob can be passed as a tensor conditioned on training/testing, would it be possible to add a state argument like in  tf.nn.dropout?", "comments": ["Thanks for your interest @caiqi !\r\n\r\nThis is a question best asked on stackoverflow, where we monitor all issues with the tag `tensorflow`.\r\n\r\nWe keep this channel for actual tensorflow bugs."]}, {"number": 8380, "title": "Tensorflow works, but cannot import tensorflow.python", "body": "Operating System: Ubuntu 16.04\r\nTensorflow version: tensorflow-gpu 1.0.1 on python3.6\r\n\r\n---------------------------------------------------------\r\njiexun@jiexun-XPS-15-9560:~/Desktop$ python3\r\nPython 3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 12:22:00) \r\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n>>> tf.__version__\r\n'1.0.1'\r\n>>> import tensorflow.python\r\n>>> import tensorflow.python as py\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'python'\r\n>>> \r\n---\r\n\r\nI also tested importing the other tensorflow folders, with the below results:\r\n>>> import tensorflow.contrib as con\r\n>>> import tensorflow.core as core\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'core'\r\n>>> import tensorflow.examples as examples\r\n>>> import tensorflow.include as include\r\n>>> import tensorflow.models as models\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.models'\r\n>>> import tensorflow.tensorboard as tb\r\n>>> import tensorflow.tools as tools\r\n>>> \r\n\r\nFor me, it seems like I can't import tensorflow.core, tensorflow.models, and tensorflow.python. Tensorflow.python in particular is the module that I am trying to use. \r\n\r\nAny idea why this is happening? I may be missing something obvious.\r\n\r\nThanks so much for the help!\r\n", "comments": ["There is no `tensorflow.python` module, the directory structure in the source tree may not map to the module names in the installed version. The set of all symbols/modules etc. can be found in the [Python API documentation](https://www.tensorflow.org/api_docs/python/)\r\n\r\nHope that helps.", "I am able to import when using `from tensorflow.python.ops import functional_ops as fn_ops` instead of `import tensorflow.python.ops.functional_ops as fn_ops`\r\n\r\nThanks! @asimshankar ", "I am to able to import and use it import when I am using the updated version 1.13.0-rc2 and do the following: \r\nimport tensorflow as tf\r\ntf.python_io.control_flow_ops = tf    instead of tensorflow.python.control_flow_ops = tf   "]}, {"number": 8379, "title": "RuntimeError: Attempted to use a closed Session.", "body": "Hello every one, I am getting a stack error while testing new unique data to the model I have trained. The error says \" RuntimeError: Attempted to use a closed Session.\". I am not much expert with tensorflow. Some may help me to figure out why?. Thanks! @alextp @MicaelCarvalho @jfsantos \r\n\r\nprint (\"Now, Testing the unlabel data and writing the results\")\r\nYPredByNNForUnlabeledData = sess.run(tf.argmax(yPredbyNN,1),feed_dict={X: testing_features})\r\nprint (YPredByNNForUnlabeledData)\r\nfor i in xrange (len(YPredByNNForUnlabeledData)):\r\n    \r\n    if YPredByNNForUnlabeledData[i] == 0:\r\n        ClassLabelFinal.append('classical')\r\n        \r\n    else:\r\n        ClassLabelFinal.append('blues')\r\n\r\ncwd = os.getcwd()\r\nTest_dataset_path = (\"/Users/MA/Desktop/BluesTest\")%cwd\r\nTest_dataset, Total_Instances = load_instances(Test_dataset_path)\r\n\r\ntimestamps = load_timestamps(Test_dataset)\r\n\r\nwrite_results(timestamps, ClassLabelFinal, 'Result.csv')\r\n****************************************************************************\r\nNow, Testing the unlabel data and writing the results\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-9-dd19a8c04012> in <module>()\r\n      1 print (\"Now, Testing the unlabel data and writing the results\")\r\n----> 2 YPredByNNForUnlabeledData = sess.run(tf.argmax(yPredbyNN,1),feed_dict={X: testing_features})\r\n      3 print (YPredByNNForUnlabeledData)\r\n      4 for i in xrange (len(YPredByNNForUnlabeledData)):\r\n      5 \r\n\r\nC:\\Users\\MA\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    764     try:\r\n    765       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 766                          run_metadata_ptr)\r\n    767       if run_metadata:\r\n    768         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nC:\\Users\\MA\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    900     # Check session.\r\n    901     if self._closed:\r\n--> 902       raise RuntimeError('Attempted to use a closed Session.')\r\n    903     if self.graph.version == 0:\r\n    904       raise RuntimeError('The Session graph is empty.  Add operations to the '\r\n\r\nRuntimeError: Attempted to use a closed Session. \r\n", "comments": ["This type of question is better asked at [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow), the GitHub page is mostly used for bug reports, and this is clearly not the case. Also, when bug reporting, please fill the template (it is the default text on the \"New issue\" screen, you just have to fill the gaps). Enclosing your codes/outputs with the code tags also helps, so we can read the logs without much effort.\r\n\r\nYour problem is on line 2, when you run `sess.run`. But `sess` seems to be an invalid/closed session. Either you're calling this outside a `with tf.Session() as session:` block or you have closed your session before running `sess.run`."]}, {"number": 8378, "title": "Issue running LabelImage.java demo. ", "body": "Below is the error:\r\n\r\nException in thread \"main\" java.lang.UnsupportedOperationException: Op BatchNormWithGlobalNormalization is not available in GraphDef version 21. It has been removed in version 9. Use tf.nn.batch_normalization().\r\n\tat org.tensorflow.Graph.importGraphDef(Native Method)\r\n\tat org.tensorflow.Graph.importGraphDef(Graph.java:113)\r\n\tat org.tensorflow.Graph.importGraphDef(Graph.java:97)\r\n\tat org.tensorflow.examples.LabelImage.executeInceptionGraph(LabelImage.java:110)\r\n\tat org.tensorflow.examples.LabelImage.main(LabelImage.java:65)\r\n\r\nI can't find the source file in which to use tf.nn.batch_normalization\r\nAre the Java libraries using older versions of Tensorflow?", "comments": ["Could you provide some more detail (ideally the set of commands used to reproduce the problem)? Following the instructions in [java/README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md), I was unable to reproduce the error. Are you using a custom graph perhaps?\r\n\r\nFor example, the following does not reproduce the problem:\r\n```sh\r\n# Download and unzip the model\r\nwget \"https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\"\r\nunzip inception5h.zip\r\n\r\n# Download a sample image\r\nwget \"https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/label_image/data/grace_hopper.jpg\"\r\n\r\n# Run the example as per instructions in README.md\r\njava \\\r\n  -Djava.library.path=./jni \\\r\n  -cp libtensorflow-1.0.0-PREVIEW1.jar:./src/main/java \\\r\n  org.tensorflow.examples.LabelImage . ./grace_hopper.jpg\r\n```", "I get same error while train own model and [followed codelab ](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0) instruction.", "Ah, thanks for the update @kinDSa \r\nI think this is because the codelab is using a very old graph with deprecated operations. I'm going to close this as a duplicate of #8396 (since that has more information) and follow up there.", "Ahhh, thankyou @asimshankar, downloading that version of inception fixed it. \r\nI was using the version from here:\r\nhttps://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\r\n\r\nfrom the image recognition tutorial:\r\nhttps://www.tensorflow.org/tutorials/image_recognition\r\n\r\nWhat is the difference between the two versions? It seems the one I downloaded is more recent. \r\nI'm using the bazel command in the readme\r\n"]}, {"number": 8377, "title": "Enable type_index on Windows", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 8376, "title": "tf.exp() cannot handle large negative numbers correctly", "body": "This issue is mistakenly filed. Please delete..", "comments": []}, {"number": 8375, "title": "Streaming accuracy and recall aren't working as expected", "body": "### Environment info\r\nUbuntu 16.04\r\nCuda 8.0\r\nCudnn 5.1\r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\nc56c873fbaf976d26d487ad57c8efbc87f05331c\r\n2. The output of `bazel version`\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\nHere is my code:\r\n```\r\nweights = {'first': tf.Variable(tf.random_normal([1, 3, 1, 10])),\r\n           'iterated': tf.Variable(tf.random_normal([1, 3, 10, 10])),\r\n           'out': tf.Variable(tf.random_normal([embedding_dim*10, n_classes]))}\r\n\r\nbiases = {'first': tf.Variable(tf.random_normal([10])),\r\n          'iterated': tf.Variable(tf.random_normal([10])),\r\n          'out': tf.Variable(tf.random_normal([n_classes]))}\r\n\r\npreds, cost = model(x, y, weights, biases, dropout, depth_tensor)\r\n\r\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\r\n\r\naccuracy, update_accuracy = streaming_accuracy(y, preds)\r\nrecall, update_recall = streaming_recall(y, preds)\r\n\r\ninit = tf.global_variables_initializer()\r\ninit2 = tf.local_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    i = 1\r\n    \r\n    for batch_x, batch_y in data_processor(data, train_inds, embedding, label_processor, n_iter):\r\n        sess.run(optimizer, \r\n                 feed_dict={x: batch_x, y: batch_y, \r\n                            dropout: dropout_prob})\r\n        \r\n        if i % display_step == 0:\r\n            loss = sess.run(cost, \r\n                            feed_dict={x: batch_x, y: batch_y, dropout: dropout_prob})\r\n            \r\n            print(\"Iter:{}, Minibatch Loss:{:.6f}\".format(i,loss))\r\n        i += 1\r\n    \r\n    sess.run(init2)\r\n    for batch_x, batch_y in data_processor(data, val_inds, embedding, label_processor, n_iter):\r\n        recall, accuracy = sess.run([update_recall, update_accuracy], \r\n                                    feed_dict={x:batch_x, y: batch_y, dropout: 1})\r\n        \r\n        f1 = 2 * recall * accuracy / (recall + accuracy)\r\n    \r\n    print(\"Testing Accuracy:\", accuracy,\"Testing Recall:\", recall, \"Testing F1 Score:\", f1) \r\n```\r\n\r\nOutput:\r\n```\r\nIter:100, Minibatch Loss:18038.144531\r\nIter:200, Minibatch Loss:11628.046875\r\nIter:300, Minibatch Loss:9288.974609\r\nIter:400, Minibatch Loss:4583.474121\r\nIter:500, Minibatch Loss:6600.524902\r\n...\r\nIter:11700, Minibatch Loss:4.203137\r\nIter:11800, Minibatch Loss:3.623320\r\nIter:11900, Minibatch Loss:4.883300\r\nIter:12000, Minibatch Loss:3.045975\r\nTesting Accuracy: 0.0 Testing Recall: 0.00211863 Testing F1 Score: 0.0\r\n```\r\n", "comments": ["It looks like this is more of a usage question. The best venue is to ask on stackoverflow, where we monitor all questions with the tag `tensorflow`. From the output, it looks like your model is still not working well. You should probably continue to train, and perhaps make your model smaller.\r\n\r\nClosing here, feel free to post a cross-link to stack overflow.", "I also get strangely small recall for multi-class problem. Here's a comparison between the metrics I get via scikit-learn and via Tensorflow:\r\n**Scikit-learn code**\r\n```\r\n        all_true = []\r\n        all_predicted = []\r\n        for i in tqdm(range(0, EPOCHS * test.data_size // BATCH_SIZE)):\r\n            entities_sample, predictions_sample, _, __ = sess.run([test.entities, predictions, precision_op, recall_op])\r\n\r\n            all_true.extend(entities_sample.flatten())\r\n            all_predicted.extend(predictions_sample.flatten())\r\n\r\n        s_prec = metrics.precision_score(all_true, all_predicted, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9], average='micro')\r\n        s_rec = metrics.recall_score(all_true, all_predicted, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9], average='micro')\r\n        s_f1 = metrics.f1_score(all_true, all_predicted, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9], average='micro')\r\n        s_confusion = metrics.confusion_matrix(all_true, all_predicted)\r\n\r\n        print(s_prec)\r\n        print(s_rec)\r\n        print(s_f1)\r\n```\r\n\r\n**Scikit-learn output**\r\n\r\n```\r\n0.875761847506\r\n0.875743692863\r\n0.87575277009\r\n```\r\n\r\n**Tensorflow code**\r\n\r\n```\r\n        for i in tqdm(range(0, EPOCHS * test.data_size // BATCH_SIZE)):\r\n            entities_sample, predictions_sample, _, __ = sess.run([test.entities, predictions, precision_op, recall_op])\r\n\r\n            all_true.extend(entities_sample.flatten())\r\n            all_predicted.extend(predictions_sample.flatten())\r\n\r\n\r\n        f1_score = (2 * (precision * recall)) / (precision + recall)\r\n\r\n        final_precision, final_recall, final_f1 = sess.run([precision, recall, f1_score])\r\n        print('Precision:{}'.format(final_precision))\r\n        print('Recall:{}'.format(final_recall))\r\n        print('f-1 score:{}'.format(final_f1))\r\n```\r\n\r\n**Tensorflow output**\r\n\r\n```\r\nPrecision:0.8595223781587512\r\nRecall:0.4297611890793756\r\nf-1 score:0.5730149187725008\r\n```\r\n\r\nAs you can see the difference between scikit's recall and tensorflow is quite drastic. Not sure if this is a bug or a difference in the implementation. ", "From what I see, tensorflow's recall and precision do not mean what they are supposed to mean\r\n\r\nmodified from this example from [here](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py)\r\n\r\n```\r\n    predictions = tf.argmax(logits, 1)\r\n    labels = tf.squeeze(labels)\r\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\r\n        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),\r\n        'Precision': slim.metrics.streaming_precision(predictions, labels),\r\n        'Recall': slim.metrics.streaming_recall(predictions, labels),\r\n        'Recall_5': slim.metrics.streaming_recall_at_k(logits, labels, 5),\r\n        'Recall_3': slim.metrics.streaming_recall_at_k(logits, labels, 3),\r\n        'Recall_1': slim.metrics.streaming_recall_at_k(logits, labels, 1),\r\n        })\r\n```\r\n\r\n```\r\n2018-03-06 12:45:43.520961: I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall_1[0.664843738]\r\n2018-03-06 12:45:43.521368: I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall[0.990521312]\r\n2018-03-06 12:45:43.521429: I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall_5[0.857031226]\r\n2018-03-06 12:45:43.521487: I tensorflow/core/kernels/logging_ops.cc:79] eval/Precision[0.996820331]\r\n2018-03-06 12:45:43.521537: I tensorflow/core/kernels/logging_ops.cc:79] eval/Accuracy[0.664843738]\r\n2018-03-06 12:45:43.521584: I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall_3[0.809375]\r\n```\r\n\r\nhow come both streaming_recall and streaming_precision are 99% while accuracy and top 1 recall are 66%.\r\n\r\nsomething seriously is different than the known meaning of [recall and precision](https://en.wikipedia.org/wiki/Precision_and_recall)\r\nwe know.  and why accuracy is same as recall_1 and why recall and recall_1 are different?\r\n", "here is the stackoverflow link\r\n\r\nhttps://stackoverflow.com/questions/49131436/tensorflows-recall-and-precision-do-not-mean-what-they-are-supposed-to-mean", "related question\r\n\r\nhttps://stackoverflow.com/questions/43618608/tensorflow-streaming-metrics-are-not-working?rq=1"]}, {"number": 8374, "title": "How to visualize local dataset  on TensorBoard ?", "body": "Hello, I would like to know how we can visualize dataset on TensorBoard locally. I have Wine dataset taken from UCI Machine Learning repository and wonder what procedure I should follow to display on TensorBoard. Unfortunately I could not find about this on google. Could you help me with this, please ? ", "comments": ["Your question can be better addressed on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). The GitHub \"Issues\" section is mainly for bug reporting and feature requests.", "I have asked there, but unfortunately no any answer came.The link is here:\r\n\r\nhttp://stackoverflow.com/questions/42774670/visualizing-dataset-on-tensorboard", "I believe you're looking for [tf.summary.image](https://www.tensorflow.org/api_docs/python/tf/summary/image). If you need examples, you can look for `tf.image_summary` (the old, deprecated version of this function), like these: [StackOverflow 1](http://stackoverflow.com/questions/38543850/tensorflow-how-to-display-custom-images-in-tensorboard-e-g-matplotlib-plots), [StackOverflow 2](http://stackoverflow.com/questions/34696845/how-to-see-multiple-images-through-tf-image-summary). ;-)", "Thank you for your help! @MicaelCarvalho "]}, {"number": 8373, "title": "Switch back to Ubuntu 14.04 for our releases.", "body": "Haven't tested this yet. Letting Jenkins do the work.\r\n\r\n@caisq fyi. Note that we should keep our Docker Hub images on Ubuntu 16.04 because that fixes the bugs users encounter.\r\n\r\nNote for others looking at this change: we're downgrading to Ubuntu 14.04 for official releases so that it links against the older version of glibc and allows for wider compatibility.", "comments": ["@gunan this is mostly a revert plus some minor version changes and edits.", "I'm expecting you'll see some jemalloc caused SEGFAULTS on process shutdown, since that happens in 14.04 but not 16.04", "We're using the other fix here: reinstalling numpy without OpenBLAS support.", "@jhseu Thanks for cc'ing me. +1 for keeping the Docker Hub and gcr.io images at 16.04.", "Thank you very much for the change!"]}, {"number": 8372, "title": "Fix CameraActivity typo", "body": "Fix crash when activity paused", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "When I open popup activity (e.g., PreferenceActivity), onPause is called and \"Activity has leaked window that was originally added ...\" error occurs.\r\nThis is because the code wrote as !isFinishing(), activity call finish() even though it is not actually finishing.\r\nNew activity works, but cannot go back to previous activity since it's already finished.", "ping @andrewharp ", "So to clarify, it's when you modify the demo to create new windows that you have issues? Does this finish() line actually ever get called for you with this change?", "@andrewharp Exactly. To be able to return to the Camera Activity, finish() should not be called when creating a new window. Sorry for late response.", "@seano314 Ok, so what I am trying to understand is why it would ever make sense to call finish() if the app is already finishing. It seems that there is no typo here that I can see, just a use-case that the demos don't currently need to account for.\r\n\r\nIf we remove the explicit finish() call, the I worry that confusing behavior may occur when users switch quickly between different demo activities. Adding finish() here was a quick stop-gap solution that worked, but if you would like to add a real fix that does things the Android way that would be appreciated. Otherwise I think we should keep it as-is, or find another way to make your modifications work with the version of TF in the repo that doesn't break the existing demos.", "@seonho Mind taking a look at @andrewharp comment above? Looks like his question is for you? :) \r\n\r\n", "@seano314 Closing as this is intended behavior. I think I understand the issue you're seeing, but it needs to be handled differently, as simply reversing the check actually introduces a bug."]}, {"number": 8371, "title": "Problem with missing kernel registration in contrib/makefile build", "body": "## Problem with missing kernel registration in contrib/makefile build\r\n\r\nWhen reading a graph (through saved_model) I get the error message:\r\n\r\nStatus: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\nwhen trying to link the application using the tensorflow-core library generated in tensorflow/contrib/makefile\r\n\r\nWhen using bazel, the same application runs without errors.\r\n\r\nI have verified that the file \"tensorflow/core/ops/random_ops.cc\" containing the operation is already present in \"tf_op_files.txt\".\r\n\r\nThe library is linked with -all_load option.\r\n\r\n### Environment info\r\nThe tensorflow version used is branch r1.0 on macOS 10.12.3 (no CUDA support). Hash e895d5ca395c2362df4f5c8f08b68501b41f8a98\r\nBazel Version is 0.4.4", "comments": ["Did you possibly produce the saved model with a different version of tensorflow as you are trying to run it?\r\n@petewarden, do you have any makefile tips?", "2017-03-31 18:22:40: E /Users/a54/tf_files/projects/tensorswift-ios/tensorswift/tensorflow_utils.mm:152] Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: truncated_normal_3/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](truncated_normal_3/shape)]]\r\n2017-03-31 18:22:40: F /Users/a54/tf_files/projects/tensorswift-ios/tensorswift/TensorBridge.mm:75] Couldn't load model: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: truncated_normal_3/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](truncated_normal_3/shape)]]\r\nwarning: could not execute support code to read Objective-C class data in the process. This may reduce the quality of type information available.", "@a54 @tokoduck Excuse me, could you tell me your problem solved?I met a similar problem. Thank you\r\n![snip20170613_6](https://user-images.githubusercontent.com/8908244/27210034-30192b64-5282-11e7-95b2-d456da5357b2.png)\r\n", "@StarRain-L: Only the float kernel is registered for Maximum, you are creating a int32 version. \r\n\r\n@tokoduck: Is this the full error message? \r\n\r\n@petewarden, would this be expected given the makefile build has a restricted set of kernels?", "This is expected, but it should be possible to override this by defining the __ANDROID_TYPES_FULL__ macro:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_ops_common.h#L476", "@martinwicke yes, that was the full error message\r\n\r\n@StarRain-L from my knowledge, it is not resolved, but I have not checked the newer releases 1.1 and 1.2 yet.\r\n\r\nAs a work around, I got my program working when linking with the dynamic library, that can be created using bazel. When linking the same program with the static library, it fails.", "hi,\n\nno, I am on MacOS (and ubuntu). So I have the workaround to produce a\ndynamic library using bazel, linking with this library works, but linking\nwith the static library from the makefile project produces the error\nmessage.\n\nOn Sat, Jun 17, 2017 at 8:58 AM, Sunny <notifications@github.com> wrote:\n\n> @tokoduck <https://github.com/tokoduck> I'm in iOS, and you?Your problem\n> solved?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8371#issuecomment-309197996>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AZK8vf0hsOjaELocBdpElrUv3OxlN3RQks5sE3j8gaJpZM4Mb5aO>\n> .\n>\n", "My problem has been solved temporarily, thank you for your reply!!!!!!This is my reference information.\r\nhttps://github.com/tensorflow/tensorflow/search?l=C%2B%2B&q=TruncatedNormal&type=&utf8=\u2713", "Since the makefile build is primarily intended for mobile use cases, and there's a workaround using the bazel version here instead, closing this bug. Please reopen with more information if this is incorrect."]}, {"number": 8370, "title": "Add SingleImageRandomDotStereogramsOp to Contrib", "body": "This add an Op to convert 3D data into a 2D image SIRDS (Single Image Random Dot Stereogram) for scientific data review.\r\n\r\nIt is related to this concussion:\r\nhttps://github.com/tensorflow/tensorflow/issues/8022", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "I have installed and run the google formatting tools as well as cleaned up the MD and docstring.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@martinwicke ,\r\n\r\nThe changes look fine to me, is there anything I need to do?  I think the CLA issue is due to your edits?", "Yeah, don't worry about CLAbot, it gets confused. ", "@martinwicke Let me fix what you have indicated above, I would like to keep the \"generation_mode\" in the params if that is okay, I can stop the attribute command and simply ignore the value of this attribute.  I think this will be handy in the future.\r\n\r\nDo I need to issue a git command to pull back your updates or can I just update my current repository and pull again with the updates or does this loose your fixes?", "Go ahead and update current and fix the things i missed as you need to. It actually pulled my main file, but i have everything wrote down. I added a few specs extra for VM for tensorflow & cudnn to use than i really need. Was trying to visualize the behaviour. Thought it would be useful support from some of the comments. Stereograms looks good. No need for border -> border. Doubles was extra  not needed. Wanted it to be an asset for the future. Are there any other offsets that need fixing? I think most everything was accounted for except a few fft maybe to deal with n%. Probably need to know how to reverse the sequence to correct anythimg still being offset. Probably just a few more calculations to complete the math lib, but you may have already account for that issue. But think this pr will be good. Std:: should already cover everything else. Let me know if there are any other pr i need to close out or any questions. Dont think i opened any other pr myself. Lost track as this ended up covering a lot of more than i expected. Thank You for allowing me to be a part of this.", "@martinwicke ,\r\n\r\nI have addressed the latest change requests.  Let me know if there is anything else (or something I broke) that needs updating.\r\n\r\nI did leave the 'generation_mode' parameter to define the future interface, but the Op will ignore any values passed for now.\r\n\r\nI have also updated the demo page, if needed, I can create a brief version for the tensorflow tutorials.\r\nhttps://github.com/Mazecreator/TensorFlow-SIRDS/blob/master/single_image_random_dot_stereograms/SIRDS%20Demo.ipynb\r\n\r\nThanks for the help and patients, I haven't used git before and it sometimes does things a little faster than expected.  Also, it seems like you have edited the docs to ~78 character line lengths, I am not sure this is documented [here](https://www.tensorflow.org/community/documentation), it might be worth adding this formatting restriction as I only saw reference to \"short\" not a line length for the different document parts.", "Ignore the read me update if you wish. I shortened it to be less explicit. That way you can choose what to pass. I don't know if it is an issue or not. Let me know if I need to revert it.", "I don't see any update, but if you are talking about removing the specifics in the \"generation_mode\" for SIRDS, I am okay with that change.", "Just noticed one thing that was mentioned. I am curious if 1d was over looked as they are not listed seperately from the string arg. I didnt think about it before. 1d attributes? An oversight on my part.  Unneccessary ?  sirds returns values for 1d attributes. Already fixed @ lines 243 - 244 ?", "@RealTimeDeployment I am getting a little lost with your questions, is this @martinwicke 's repository?  I am not sure the connection to this review.  I see the lines 243 - 244 are STD::ROUND statements and not sure about the 1D reference and strings?   I am sure you can put in a [1,X] shape but haven't testing it for a 1D display, but then in my mind it would be clearer to use a simple X,Y plot rather than a SIRDS for evaluation.", "@Mazecreator The updates you make to this branch of your repository will be reflected in this PR. \r\n\r\nI would like you to remove the unused arguments. Arguments are easy to add, but hard to remove, so we should be careful about adding them. And please do fix the boarder issue.", "@martinwicke all your update requests have been completed.", "Jenkins, test this please!", "Jenkins, test this please.", "this makes the image ops test fail:\r\n```\r\nFAIL: //tensorflow/contrib/image:image_ops_test (see /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/testlogs/tensorflow/contrib/image/image_ops_test/test.log).\r\nINFO: From Testing //tensorflow/contrib/image:image_ops_test:\r\n==================== Test output for //tensorflow/contrib/image:image_ops_test:\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/contrib/image/python/kernel_tests/image_ops_test.py\", line 23, in <module>\r\n    from tensorflow.contrib.image.python.ops import image_ops\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/contrib/image/__init__.py\", line 39, in <module>\r\n    from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms\r\nImportError: No module named 'tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms'\r\n```", "//tensorflow/contrib/image:image_ops_test was an existing Op & Test in the contrib/image directory.  I am not sure if it is supported, bu this shouldn't be related to my addition of the SIRDS Op.", "If you read the error message, it does say:\r\n```\r\nImportError: No module named 'tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms'\r\n```", "Hmmm... Okay, I will need help, I don't understand how the Testing works.  I didn't touch that test and don't  see where it references \"single_image_random_dot_stereograms\".  I seem to be able to compile the source locally and run the SIRDS, so not sure what would cause this problem.\r\n", "You can run tests yourself by using `bazel build --config=opt //tensorflow/contrib/image/...`. In that case, you have modified `__init__.py`, but did not change the build rule: \r\nhttps://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/image/BUILD#L73\r\nYou need to add `\":single_image_random_dot_stereograms\"` to the dependencies.", "Hi @drpngx ,\r\n\r\nSorry, I added the dependency but now I am in deeper.  I ran this command as it seems to run the tests:\r\nbazel test --config=opt --config=cuda //tensorflow/contrib/image/...\r\nI even tried this without cuda & opt, but I am getting a different error now.\r\n\r\n    ERROR: /home/greg/tensorflow/tensorflow/contrib/image/BUILD:59:1: in deps attribute of py_test rule //tensorflow/contrib/image:image_ops_test: rule '//tensorflow/contrib/image:single_image_random_dot_stereograms' does not exist. Since this rule was created by the macro 'cuda_py_test', the error might have been caused by the macro implementation in /home/greg/tensorflow/tensorflow/tensorflow.bzl:863:12.\r\n    ERROR: Analysis of target '//tensorflow/contrib/image:image_ops_test' failed; build aborted.\r\n    INFO: Elapsed time: 2.839s\r\n    ERROR: Couldn't start the build. Unable to run tests.\r\n\r\nSorry, I just don't understand what is going on under the hood with the tests.  I rand the command you had put in the message, but that only seemed to build and not run the tests.", "Yes, you are right, you need `bazel test`. Also, the correct dependency is `\":single_image_random_dot_stereograms_py\"`, not `\":single_image_random_dot_stereograms\"` as I had previously indicated.", "Jenkins, test this please.", "Could you possibly rebase instead of merge? That confuses googlebot. Thanks!", "Hi @drpngx ,\r\n\r\nThank you, that took care of the problem.  Now it tests okay.  Not sure why it had to be added or where to find that information, might be good to capture documentation like this for the Add Op help.  seems like indents are critical as well.", "@drpngx ,\r\n\r\nI am not sure how to do that, should I pull a new tensorflow/master and add these files back in or can I somehow rebase my mazecreator/master?\r\n\r\nI am new to git as well...\r\n\r\nSorry for the hassle.\r\n", "@drpngx the CLAbot is confused because I fixed some indent in order to get past sanity. It can be ignored. All commits are from me or @mazecreator and we are in CLA. \r\n\r\nI'm assuming you'll squash it anyway so it's good to go I think. ", "Sounds good. Thaanks!"]}, {"number": 8369, "title": "Add argument axis in tf.TensorArray method concat()?", "body": "Hi, TF development team,\r\n\r\nWould it possible to add an argument axis in tf.TensorArray method concat(), defined in file tensorflow/tensorflow/python/ops/tensor_array_ops.py?\r\n\r\nThe reason is that there could be use cases when concat on the last axis make sense. Of course, the requirement would also need to be changed to \r\n\r\n\"\"\"\r\nAll of the values must have been written, their ranks must match, and\r\n    and their shapes must all match for all dimensions except the **dimension specified as axis**.\r\n\"\"\"\r\n\r\nBTW, or, would tf.concat() accept tf.TensorArray as input? - I tried, but didn't find a way.\r\n\r\nThanks.\r\n", "comments": ["An integrated axis argument might make sense (also for `.stack()`), but one simple work around is to use `TensorArray.stack` and then concatenate along the desired axis.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Thank you, @shoyer, @asimshankar and @concretevitamin ! I am ok with the workaround method.\r\n\r\nAlthough an integrated axis argument is preferred, and make sense?\r\n\r\nBTW, how much efficiency gain would be for an integrated axis (if implemented) compared to the work around method (stack then concatenate)?\r\n\r\nThank you.", "The cost here is one extra copy of the data, which is usually negligible (though it depends on the application).", "Ok, I see. Thank you, @shoyer !", "@shoyer, could you please provide an example of this workaround? It is not clear for me how to perform `tf.concat()` on a single stacked tensor.\r\n\r\nTo be precise, I've tried:\r\n> probs = output_ta.stack()  # (num_slices, D1, D2, D3)\r\n> probs = tf.concat((probs,), axis=2)  # still (num_slices, D1, D2, D3)\r\n\r\nBut I need the output of `tf.concat()` to be `(D1, D2, D3)`, concatenated by axis D2.", "I think I meant `tf.stack`, not `tf.concat`, e.g., `tf.stack(probs, axis=2)`", "@shoyer probably I don't understand something about how this works. =)\r\n\r\n`TensorArray.stack()` will return values stacked along new zero dimension. `tf.stack()` over its output makes no sense for me as `tf.stack(probs)` is complaining about `Expected list for 'values' argument to 'pack' Op`. So I'm a bit lost.\r\n\r\nI've solved that case by doing `tf.transpose()` inside the body which fills `TensorArray` and then transpose it back after `TensorArray.concat()`. But this seems to be a bit off as we introduce another memory copy for back transpose.\r\n", "Okay, I forgot stack needs a sequence, not a Tensor. So nevermind, transpose is your best bet.", "I would also agree that  adding and axis argument to TensorArray.stack() would be useful. Current workaround  is to just transpose the first dimension to the back", "I am facing the same issue myself. Are there plans to add the axis argument? @asimshankar [asimshankar](https://github.com/asimshankar)", "I think this is a needed feature, stacking and transposing makes the code ugly and hard to read, where you can just say `concat(axis=1)`."]}, {"number": 8368, "title": "Reuse some parameters of a Variable", "body": "I know how to reuse complete variables Tensorflow in two different operations as explained in the documentation: [https://www.tensorflow.org/programmers_guide/variable_scope]\r\n\r\nBut, is it possible to reuse parameters in more complex ways? In particular, is it possible to specify that two variables of different shapes share some parameters in common? \r\n\r\nA small example of what I am trying to do: I would like to have a model with 25 parameters. I would like to use these parameters in three variables X, Y, and Z so that X uses all parameters in a 5x5 tensor:\r\nX = \r\nw11, w12, ... , w15\r\nw21, w22, ... , w25\r\n...\r\nw51, w52, ... , w55\r\n\r\nwhile Y uses 9 of the parameters in a 3x3 tensor, for example the middle 3x3 block of X. That is:\r\nY = \r\nw22, w23, w24\r\nw32, w33, w34\r\nw42, w43, w44\r\n\r\nwhile Z uses the same nine weights as Y and also in a 3x3 tensor, but transposed with respect to Y, that is:\r\nZ =\r\nw22, w32, w42\r\nw23, w33, w43\r\nw24, w34, w44\r\n\r\nIf this is not possible, are there plans in the Tensorflow development community to support this capability?\r\n", "comments": ["This question is probably better asked on [stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow) as we try to keep the Github issues focused on bugs and feature requests.", "Thank you. I just reposted in stackoverflow (https://stackoverflow.com/questions/42797103/how-to-reuse-some-parameters-of-a-variable-in-tensorflow). I posted here before thinking that of it as a feature request."]}, {"number": 8367, "title": " the files are available but inspection result No event files found within logdir", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#my-tensorboard-isnt-showing-any-data-whats-wrong\r\n\r\n### Environment info\r\nOperating System: mac\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\ninspecting directory\r\n\r\n### Logs or other output that would be helpful\r\n\r\n\r\n(mlp) earthhouse86:cifar10 ikibozu$ tensorboard --inspect --logdir==$OUTPUT_DIR 0\r\n======================================================================\r\nProcessing event files... (this can take a few minutes)\r\n======================================================================\r\n\r\nNo event files found within logdir =/Users/ikibozu/mlpractical/notebooks/cw4/result\r\n(mlp) earthhouse86:cifar10 ikibozu$ find $OUTPUT_DIR | grep tfevent\r\n/Users/ikibozu/mlpractical/notebooks/cw4/result/C10_10_tf.nn.relu_2017-03-13_14-47-18/train-summaries/events.out.tfevents.1489416439.earthhouse86.hw147.homewurk.nl\r\n/Users/ikibozu/mlpractical/notebooks/cw4/result/C10_10_tf.nn.relu_2017-03-13_14-47-18/valid-summaries/events.out.tfevents.1489416669.earthhouse86.hw147.homewurk.nl\r\n", "comments": ["Your logs are inside another folder. You're passing `/Users/ikibozu/mlpractical/notebooks/cw4/result` as path, but the files are inside `/Users/ikibozu/mlpractical/notebooks/cw4/result/C10_10_tf.nn.relu_2017-03-13_14-47-18/train-summaries/`.\r\n\r\nAnd next time, please fill the fields of the issue template. ;-)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8366, "title": "Fixed TF Stylize crash after reaching the end", "body": "[Video of the bug in action](https://youtu.be/XUCEO6H8Q-E)\r\n[Video of the fixed version](https://youtu.be/b1QS4i4o9Wg)", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins Test this, please."]}, {"number": 8365, "title": "R0.7", "body": "", "comments": ["Can one of the admins verify this patch?", "We don't plan to make updates to the r0.7 branch anymore."]}, {"number": 8364, "title": "Documentation formatting broken", "body": "See https://www.tensorflow.org/api_docs/python/tf/contrib/copy_graph/copy_op_to_graph (source code formatting leaks into general text)\r\nor https://www.tensorflow.org/api_docs/python/tf/contrib/graph_editor/copy (Returns: and Raises: get folded into parameters).\r\n\r\nEither the doc generator needs to understand python doc comments better or the doc comments need to be updated to work better with markdown (extra newlines etc). What do you think?\r\n\r\nThanks,\r\n Andreas\r\n", "comments": ["@josh11b @martinwicke for docs"]}, {"number": 8363, "title": "Tensorboard smoothing 1st order lag filter", "body": "@dandelionmane  This is an alternative to [PR7891](https://github.com/tensorflow/tensorflow/pull/7891), since you mentioned you are considering alternative ways forward. \r\n\r\nIt replaces the use of a moving average window with a simple first-order lag filter. It has a few advantages: 1) A bit less code. 2) It doesn't require visiting a potentially large number of values in the window to be averaged when computing each smoothed value. 3) The degree of smoothing doesn't change when you get near the end of the curve.\r\n\r\nI left the changes in the html file so you could just run it without having to rebuild.\r\n\r\nHere's what it does on the same data shown in the other PR.\r\n![p_alt](https://cloud.githubusercontent.com/assets/2138320/23866631/64b05b3a-07e7-11e7-9fe8-24cd4668011c.png)\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "There is another reason I think this kind of filtering is superior. The moving-average window filter currently implemented averages over a window centered on the current point, and so in general the \"kernel radius\" stretches forward to include future data, making it non-causal. In the common use case where you've got a training loss curve, you make a hyper-param or other change, and restart training, and then you want to compare how training progresses relative to the previous iteration. The previous iteration's loss curve you are comparing to stretches out into the future, which is reflected in its curve. However for the currently-executing training, the future loss values don't exist yet so you can't directly compare the latest smoothed curve values of the currently-executing training loss to that of the previous iterations. \r\n\r\nThat problem doesn't apply with this kind of smoothing. In the case of this PR, the smoothed curves are always causal, so you can compare previous iterations' curves to the current iteration's curve at every point, right up to the most recent data. Sure, it has some lag, but the lag is the same for all the curves.\r\n\r\nHope that makes sense.", "@dandelionmane what's the plan with this and #7891? ", "LGTM. Please fix the conflicts (you can just port the changes into the new tf-tensorboard.html) and then we'll merge.", "Or you can just revert the conflicting file and wait for us to update it. ", "OK thanks; I reverted html file. I think it's better to be generated by tool chain than manually-hacked.", "Jenkins, test this please.", "(I am on 1.1rc1) Not sure if this \"issue\" was introduced by this PR, but this seems odd to me:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24732034/1a9ebe26-1a3c-11e7-9399-f85c8cfea9ac.png)\r\nThe smoothed line (dark purple is not defined for the last N steps). If the implication is that smoothing cannot be calculated for these values, then I would argue the same should apply for the first N steps as well. \r\n\r\nRather I would prefer smoothing to be defined all the way to the left and right with a reduced window (which is what I assume happens initially) on both sides.", "@cancan101 I checked and tf-tensorboard.html in 1.1 does not yet reflect the changes made in this PR (as of this writing), and that's the file that determines the behaviour one sees when running tensorboard. It would show up in the `resmoothDataset` method in tf-tensorboard.html which needs to be regenerated from the underlying .ts file that was changed as a part of this PR. There are instructions on how to do that somewhere under the tensorboard source subtree. \r\n\r\nThe problem you show (I think) is one of the things this PR was meant to correct. \r\n\r\nA simple hack that may be easier than regenerating the `tf-tensorboard.html` properly, is to replace the `resmoothDataset` function in `tf-tensorboard.html` with the version of the function that's in  `tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.ts `. At least I think that worked for me.\r\n"]}, {"number": 8362, "title": "Memory Allocation at each call to Frozen Graph?", "body": "Operating System: Linux, CPU\r\nTF: 0.11.0\r\n\r\nIt looks like a memory allocation is occurring during each call to my frozen graph.\r\nI suspect I'm using the code incorrectly rather than this is a bug.\r\nPlease delete if this does not belong here. \r\nI posted on [StackOverflow](http://stackoverflow.com/questions/42769464/bad-memory-allocation-when-using-frozen-graph).\r\n\r\n-------\r\n\r\nMy model was running too slow doing inference.\r\nI froze the graph and converted variables to constants to improve the speed. \r\n\r\nNormally I load the graph and weights (which runs OK):\r\n```\r\nwith tf.Graph().as_default(), tf.Session() as session:\r\n\t...\r\n\tsaver.restore(session, ckpt_path)\r\n\tfor i in range(5):\r\n\t    result = session.run(...)\r\n```\r\n\r\nHowever, when I load the frozen graph:\t\r\n```\r\n# Save the graph\r\n\r\n# output_node_names - equivalent to the results that are requested in the session.run() calls\r\noutput_node_names = [...] \r\nsaver = tf.train.import_meta_graph(ckpt + '.meta')\r\ngraph = tf.get_default_graph()\r\ninput_graph_def = graph.as_graph_def()\r\n\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, ckpt)\r\n    output_graph_def = graph_util.convert_variables_to_constants(\r\n        sess, input_graph_def, output_node_names) \r\n\r\n     with tf.gfile.GFile(output_graph, \"wb\") as f:\r\n         f.write(output_graph_def.SerializeToString())\r\n\r\n\r\n# Load the graph\r\n\r\ndef load_graph(filename):\r\n\twith tf.gfile.GFile(filename, \"rb\") as f:\r\n\t       graph_def = tf.GraphDef()\r\n\t       graph_def.ParseFromString(f.read())\r\n\r\n\t with tf.Graph().as_default() as graph:\r\n\t        tf.import_graph_def(graph_def, input_map=None, \r\n\t        \treturn_elements=None, name=\"prefix\", op_dict=None, \r\n                        producer_op_list=None)\r\n\treturn graph \r\n\r\ngraph = load_graph(\"model.pb\")\r\nsession = tf.Session(graph=graph)\r\n\t\r\nfor i in range(5):\r\n\tresult = session.run(...)\r\n```\r\n\r\nAfter loading the full graph, inference takes ~1 second.\r\nAfter loading the frozen graph, inference takes ~4 seconds.\r\nSo it seems like something may not be loaded entirely in my frozen graph?\r\nThe first call to session.run() successfully produces a result (although very slow), but **the second call to run() throws an error**.\r\n\r\n**`W tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[300,100000]`**\r\n\r\nSince the graph internally has an embedding table (this is not what is being returned by session.run()), it seems this is what is being re-allocated:\r\n\t```embedding = tf.get_variable(\"embedding\", [300, 100000])```\r\n\r\nAlso the error message printed 3 times, hopefully that means 3 allocation attempts, and not 3 instances being allocated? \r\nBut why is this allocation on every call to session.run()?\r\n\r\n\r\nEdit:\r\n@MicaelCarvalho \r\nHere is the format of my input for Session.run():\r\n```\r\nx = [0.0]\r\nx_placeholder = graph.get_tensor_by_name('prefix/x_placeholder:0')\r\ny = graph.get_tensor_by_name('prefix/y:0')\r\nfeed_dict = {x_placeholder: x}\r\nto_return = [y]\r\nresult = sess.run(to_return, feed_dict=feed_dict)\r\n```\r\n\r\n", "comments": ["Check this out:\r\n```\r\ndef test():\r\n  a = 1\r\n  with a as b:\r\n    return b\r\n\r\ntest()\r\n```\r\n\r\nThe `with` statement closes/destroys the object after using it. And you are returning the destroyed object, just like the example I gave you. By itself your function is already a bug, but please also provide what parameters you are giving to `session.run(...)`.", "@MicaelCarvalho  I understand your point; but it actually works. The code below successfully prints the operations from my loaded graph outside of the \"with\" block. \r\n```\r\nwith tf.Graph().as_default() as graph:\r\n     tf.import_graph(...)\r\n\r\nfor op in graph.get_operations():\r\n     print(op)\r\n\r\nreturn graph\r\n```\r\n", "I would still change that:\r\n```\r\ndef load_graph(filename):\r\n  with tf.gfile.GFile(...):\r\n    (...)\r\n  graph = tf.Graph()\r\n  with graph.as_default():\r\n    tf.import_graph_def(...)\r\n  return graph\r\n```\r\n\r\nComing back to the issue: Who built the graph? It is possible some nodes inside it, when executed, create new operations/nodes. Put this function inside your source:\r\n```\r\nimport numpy as np\r\ndef print_num_params(graph):\r\n  vvars = 0\r\n  for v in tf.global_variables():\r\n    vvars += np.prod(v.get_shape().as_list())\r\n  total_parameters = 0\r\n  for v in tf.trainable_variables():\r\n    total_parameters += np.prod(v.get_shape().as_list())\r\n  print('Total params = %i' % (total_parameters))\r\n  print('Total vars = %i' % (vvars))\r\n  print('Total ops = %i' % (len(graph.get_operations())))\r\n```\r\n\r\nAnd before each call to `sess.run`, run this code and report back the results:\r\n`print_num_params(graph)`", "It prints the safe after each session.run() call.\r\n```\r\nTotal params = 0\r\nTotal vars = 0\r\nTotal ops = 10242\r\n```", "Before `for i in range(5):`, add `with graph.as_default():`, and report back if anything changed.\r\n\r\n====\r\n\r\nAs for the debug info : Does these numbers change between subsequent runs of `session.run`? I.e. in the 5 times the `for` calls `session.run`, does the value of \"Total ops\" change? If yes, your graph is increasing at each iteration and that's a graph construction problem.\r\n\r\nIf no, please put the same debug code on your original architecture and print its parameters to check if they match.", "The printout is the same for each iteration of session.run(), and the same while using graph.as_default().", "Since this doesn't seem to be a bug, closing here. I added a comment on stackoverflow.", "I'm not fully convinced we have enough information to assume this isn't a bug... The behavior is rather strange and if the data @richfwebb reported back are correct, I am clueless as well. Maybe someone could point other possible causes that would create these \"symptoms\", other than the things I investigated with him. :-)"]}, {"number": 8361, "title": "Add parameter to monitors to allow execution every_n_epochs", "body": "Many of the Monitors used for monitoring the training with an Estimator allow to specify the number of training steps after which they will be executed. Additionally it would be nice to be able to specify the number of epochs after which the monitor should be executed. This would make it very easy to validate the training after all training data has been learned for example one (or two...) more times. \r\n\r\nFrom looking at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/monitors.py, I saw that all the monitors allowing to specify the `every_n_steps` parameter are extending the EveryN class. In order to also allow a parameter like `every_n_epochs`, this class could be extended to count the number of epochs by listening to the `def epoch_begin(self, epoch)` method.", "comments": ["@ispirmustafa - do we have a plan to add this?  If not, we can mark this as contributions welcome.", "No. This is not in our plan. Epoch doesn't work in distributed settings.\r\nBTW, monitores are deprecated. Please use tf.train.SessionRunHook", "@ispirmustafa I know, this is drifting slightly from the specific issue at hand here, however... If, as you pointed out, the monitors API is deprecated, is there any effort on the way to update the core tutorial to reflect best practices in using `tf.train.SessionRunHook`? I saw related discussions in #7669.\r\n\r\nAlso, I did not see readily see an indication in the Release Notes. Thx, in advance for an indication.", "Hi @tomwanzek,\r\nYes updating tutorials is in our plan."]}]