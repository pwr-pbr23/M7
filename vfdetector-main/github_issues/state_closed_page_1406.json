[{"number": 10804, "title": "Not possible to use tf.contrib.training.stratified_sample with a SparseTensor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: - \r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\n**Context**:\r\nI set up an input pipeline that reads `tf.train.SequenceExample`. My dataset is quite unbalanced, so I used `tf.contrib.training.stratified_sample` to resample examples. \r\n\r\n**Problem**:\r\n`tf.contrib.training.stratified_sample` works well with `tf.FixedLenFeature` (context_features) but it raises a `TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. ...` when applied to `tf.VarLenFeature` of sequence_features. \r\nUsing `tf.sparse_tensor_to_dense()` is not applicable either, as it raises `ValueError: All shapes must be fully defined: ...`\r\n\r\n**Statement**:\r\nIf it is not an intended behaviour, then I'd like to report a bug, as I don't see why `tf.SparseTensor` shouldn't be supported.\r\nIf `tf.contrib.training.stratified_sample` works as intended, then I'd like to request a feature of `tf.SparseTensor` support in online data resampling ops.\r\n", "comments": ["@MtDersvan, unfortunately SparseTensor is supported only is rather limited contexts. One of the reasons is because the sparse format is based on unordered sparsity which makes some operations slower. I'm not  sure that stratified sampling would be easy or hard, but @zongheng, do you have any suggestions, or should we mark this contributions welcome?", "Any success @aselle? I'd be willing to contribute.", "@Zongheng, could you take a look?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I got the same problem, it can be solved by update tf to >1.5, but I need to run it on tf1.4. And I solved by use tf.sparse_to_dense() and specify the output_shape\u3002This is not elegant but useful. ", "I think this is a stale issue. Based on the above comments, looks like this was resolved. Also, `tf.contrib` was deprecated in the recent versions.\r\n\r\nI am closing this issue. Please feel free to reopen if the issue persists with recent TF versions. Thanks!"]}, {"number": 10803, "title": "TensorBoard Histogram Dashboard link broken", "body": "The link (https://www.tensorflow.org/get_started/tensorboard_histograms) to the \"TensorBoard Histogram Dashboard\" documentation is broken (404). If that section is currently in the process of being written perhaps add a dummy page saying so.", "comments": ["PTAL @wolffg. Thanks!\r\n", "This is now fixed."]}, {"number": 10802, "title": "Decoding images in a given shape from TF records", "body": "I am trying to read images from TFrecords file. The images vary in shapes. After reading, I want to preserve their shape which is why I pass the height, width and depth parameters appropriately. But the code just doesn't print anything after the set_shape command. The sess.run() calls do not respond. I initialized the session in the main function and passed the object. Is there a way to get the values of height,w,d tensors so that I can pass it to set_shape? How do I fix this? Any suggestions are welcome. Thanks in advance\r\n\r\n`def read_and_decode(sess,filename_queue):\r\n  reader = tf.TFRecordReader()\r\n  _, serialized_example = reader.read(filename_queue)\r\n  features = tf.parse_single_example(\r\n      serialized_example,\r\n      # Defaults are not specified since both keys are required.\r\n      features={\r\n          'height': tf.FixedLenFeature([], tf.int64),\r\n          'width': tf.FixedLenFeature([], tf.int64),\r\n          'depth': tf.FixedLenFeature([], tf.int64),\r\n          'image_raw': tf.FixedLenFeature([], tf.string),\r\n          'label': tf.FixedLenFeature([], tf.int64),\r\n      })\r\n\r\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n  image.set_shape([sess.run(features['height']),sess.run(features['width']),sess.run(features['depth'])])`\r\n\r\n", "comments": ["@Peri044 see https://stackoverflow.com/questions/41921746/tensorflow-varlenfeature-vs-fixedlenfeature for a solution", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nBut your code looks like a usage error to me. Why not use tf.reshape... set_shape is used for hinting shape inference (setting a fixed shape when you know there is one).", "Thank you @zakizhou  That worked.\r\n@aselle Sorry for the post but I did ask on Stack overflow and couldn't get a response. I tried the reshape thing too but the sess.run calls didn't work. Turns out it was usage error like you pointed out. I was confused as to how to input the height value of tensor into another tensor (reshape). \r\n\r\n`height = tf.cast(features['height'], tf.int32)\r\n  width = tf.cast(features['width'], tf.int32)\r\n  depth = tf.cast(features['depth'], tf.int32)\r\n  label_str = tf.cast(features['label_str'], tf.string)\r\n  len_label = tf.cast(features['len_label'], tf.int32)\r\n\r\n  image_shape = tf.stack([height, width, depth])\r\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n  image = tf.reshape(image, image_shape)`\r\n\r\nThis worked. Thanks for the help. "]}, {"number": 10801, "title": "tf.reshape fails for Tensor with valid shape parameter", "body": "I don't know if my problem is truly a bug with TensorFlow, but I think it is. My problem is that `tf.reshape(x, shape=(sequence_length, 4))` fails even when `x` is a tensor and the shape provided is valid. Reshape returns the following error: `TypeError: List of Tensors when single Tensor expected`\r\n\r\nSome background: I have a number of CSVs that I converted to `SequenceExample`s and stored as `TFRecord`s to use to train dynamic RNNs. The length of each sequence can vary. I can successfully read the `SequenceExamples` using `parse_single_sequence_example`, which returns a tensor of shape `(?,)` for each of my four feature tensors and each of my four label tensors. I then stack the four feature tensors to create `x` with shape `(?, 4)` and type `<class 'tensorflow.python.framework.ops.Tensor'>`. I create a similar tensor of labels `y` with shape `(?, 4)` and type `<class 'tensorflow.python.framework.ops.Tensor'>`. Everything is good.\r\n\r\nThen, I'd like to create minibatches based on similar length sequences using `tf.contrib.training.bucket_by_sequence_length`, but if I pass in `input_length=x.shape[0]`, I receive the following error: `ValueError: Cannot convert an unknown Dimension to a Tensor: ?`. Since I know the sequence length when creating the `SequenceExample`s, I modified my code to add the sequence length (an integer) as a context feature. Then, when I read my features and labels, I try to reshape them as follows:\r\n\r\n```\r\n        sequence_length = context_parsed['length']\r\n        tf.reshape(x, shape=(sequence_length, 4))\r\n```\r\n\r\nwhere `sequence_length` has type `<class 'tensorflow.python.framework.ops.Tensor'>` and shape `()`. This raises the following error: `TypeError: List of Tensors when single Tensor expected`. However, `x` is a Tensor, not a list of Tensors. This is why I think there may be a bug in TensorFlow's `tf.reshape()` function.\r\n\r\nMy TensorFlow version: TensorFlow version: v1.2.0-rc0-24-g94484aa 1.2.0-rc1\r\n\r\nIf it helps, I could post one of my .tfrecord files and the code necessary to create this error.\r\n", "comments": ["I'd suggest first asking on StackOverflow, because I strongly suspect you are constructing things with a small mistake. I'd suggest posting full code of a reproducible example, and try to make it as small of an example as possible. Can you reproduce it without tfrecord to remove that variable. Breaking the problem into smaller pieces like this will likely make it clearer.  Please use the template in the future. Closing for now, thank you."]}, {"number": 10800, "title": "tf.cond should be evaluated lazily", "body": "It should be possible to statically analyze the following graph such that the execution of the one branch is stopped early if the other branch is determined to be chosen. Am I missing some different function in TensorFlow that allows to do this? Perhaps using control dependencies?\r\n\r\nIn the following code the identity matrix is multiplied many times and a placeholder threshold determines whether the second multiplication or the last is chosen as output of the graph.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport timeit\r\n\r\nN = 2048\r\n\r\nx = tf.placeholder(tf.float32, [N,N])\r\nt = tf.placeholder(tf.float32)\r\nnet = x\r\nstop = None\r\nfor i in range(300):\r\n  net = tf.matmul(net, net)\r\n  if i == 1:\r\n    stop = net\r\n\r\nnet = tf.cond(tf.reduce_sum(stop) < t, lambda: stop * 0., lambda: net)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n\r\nr = None\r\n\r\nstart_time = timeit.default_timer()\r\nfor i in range(10):\r\n  r = sess.run(net, feed_dict={x: np.eye(N), t: N})\r\nprint(r)\r\nprint(timeit.default_timer() - start_time)\r\n\r\nstart_time = timeit.default_timer()\r\nfor i in range(10):\r\n  r = sess.run(net, feed_dict={x: np.eye(N), t: N + 1})\r\nprint(r)\r\nprint(timeit.default_timer() - start_time)\r\n```\r\n\r\nBoth runs take roughly the same time even though the second run only depend on the first two matrix multiplications (at least if one accounts for the warm-up phase which give the first run a slight disadvantage).\r\n\r\nI hope I am not missing something obvious. Thanks.", "comments": ["See #3287 #8168 and https://stackoverflow.com/questions/34401714/is-tensorflow-lazy for background info.\r\n", "Only #3287 is related (the others don't use `tf.cond`). There you get a more detailed answer. Short answer: The creation of all the operations which should be executed lazily must be done inside the function call. In your case, you create them and inside the function call just refer to them.\r\n\r\nThis is not a bug what you see, you are using it wrong. Maybe the documentation in TF could be improved.", "Thank you. I guess this solves my problem. Still, wouldn't it be possible to statically analyze the dependencies of a `tf.cond` node? I mean isn't the feasibility of such optimizations the advantage of defining computations symbolically/declaratively in TensorFlow?", "It's this way because TF was designed to be this way. It certainly could have been different, if dependencies of ops would be handled different in TF. But right now, when an op is going to be evaluated, all tensors which go into it must also be evaluated.\r\n\r\nNote that it is quite interesting to check out the code of `tf.cond`. Internally, `tf.cond` is implemented via `switch`/`merge` and control flow contexts.\r\n", "@3rd3 it's possible to do this by modifying the graph on the client level. Lazy evaluation is implemented using `switch/merge` statements, and `tf.cond` inserts those statements around the tensors created in `tf.cond` call. If you want to add laziness to tensors that have already been created, you can use `graph_editor` to modify the graph with the proper structure.\r\n\r\nFor instance, here's an example of modifying the graph to run variable initializer lazily -- https://gist.github.com/yaroslavvb/d67410e240369736fc4ba0267250ef27", "@yaroslavvb Thanks, very interesting gist. Wouldn't it make sense to make these kinds of optimizations part of TensorFlow?", "@3rd3\r\n\r\nNote that reason for current semantics is that it matches what you would expect from other programming languages:\r\n\r\nIE consider\r\n\r\n```\r\n1+2 if False else 2+3\r\n```\r\nvs\r\n\r\n```\r\na=1+2\r\na if False else b\r\n```\r\n\r\nLike in your case with `tf.cond`, computation `a` is getting evaluated despite `if` being lazy. The way to make it truely lazy both in Python and TensorFlow case, is to move the actual computation inside `if`.\r\n\r\nChanging existing `tf.cond` to work lazily on computation previously defined, would change the semantics. IE, suppose you have `tf.cond(a,b,c)`. Tensors `b` and `c` may have side-effects such as triggering variable assignments, and if you optimize it out, it'll change behavior/break existing TF scripts.\r\n\r\nIt might be useful to have something like `lazycond(a,b,c)` construct which has semantics you want. It could be done purely on Python level by analyzing graph and inserting appropriate switch/merge statements.", "I am wondering why you use imperative semantics here when static analysis and optimization is exactly the strong suit of declarative programming.\r\n\r\nIt also seems that TensorFlow is already lazy in some regards because in the following case `y` is not computed since it is not queried.\r\n\r\n    x = tf.no_op()\r\n    y = tf.no_op()\r\n    sess.run(x)\r\n\r\nQuery laziness, but no branching laziness? This seems to me like an odd mix of different paradigms.", "@3rd3 indeed, this is a common pitfall. In retrospect I think it would be less confusion if your example usage was explicitly forbidden. You have a mix -- some Tensors are created inside tf.cond, while others are created outside of tf.cond. To ensure laziness, all computation must be defined by the lambda called by `tf.cond`, that enables the construct to insert proper merge/switch calls", "But that would still not resolve the paradigm discrepancy between query laziness and branching non-laziness.", "I would say this is Python API issue, rather than core TensorFlow issue,\nsince there's no \"cond\" in TF API, only Switch/Merge. Changing tf.cond to\nbe fully lazy will change behavior\u200b of existing programs, so it can't be\ndone for backward compatibility reasons. You could write your own version\nof tf.cond which inserts Switch/Merge in a more intuitive way\n\nOn Jul 1, 2017 2:29 PM, \"3rd3\" <notifications@github.com> wrote:\n\nBut that would still not resolve the paradigm discrepancy between query\nlaziness and branching non-laziness.\n\n\u2014\nYou are receiving this because you were mentioned.\n\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/issues/10800#issuecomment-312429571>,\nor mute the thread\n<https://github.com/notifications/unsubscribe-auth/AABaHOQVanyfGay_1DHuSEmXpIBBKRYKks5sJjvDgaJpZM4N9VuH>\n.\n"]}, {"number": 10799, "title": "Compiler is out of heap space", "body": "I am compiling tensorflow on windows 10 laptop, i7 6700hq 16GB ram with Visual Studio 2015 and all dependencies are ok as it is explained on readme. However at the end of compilation I get the following error:\r\n\r\n```\r\n\"D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\" (default target) (3) ->\r\n\"D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj\" (default target) (4) ->\r\n\"D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.vcxproj\" (default target) (105) ->\r\n(ClCompile target) ->\r\n  d:\\prj\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBase\r\n.h(832): fatal error C1060: compiler is out of heap space (compiling source file D:\\PRJ\\tensorflow\\tensorflow\\core\\kern\r\nels\\reverse_op.cc) [D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.vcxproj]\r\n  d:\\prj\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src\\core\\../plugins/MatrixCwiseBinaryOp\r\ns.h(116): fatal error C1060: compiler is out of heap space (compiling source file D:\\PRJ\\tensorflow\\tensorflow\\core\\ker\r\nnels\\self_adjoint_eig_v2_op.cc) [D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.vcxproj]\r\n  d:\\prj\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src/Core/CoreEvaluators.h(599): fatal e\r\nrror C1060: compiler is out of heap space (compiling source file D:\\PRJ\\tensorflow\\tensorflow\\core\\kernels\\svd_op_doubl\r\ne.cc) [D:\\PRJ\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.vcxproj]\r\n```\r\nHow can I solve this problem?", "comments": ["This seems to be a compiler bug... try following advice here.\r\nhttps://stackoverflow.com/questions/43140529/compiler-is-out-of-heap-space\r\n", "I increased the maximum number of concurrent processes and it did the job with no errors. Also with the huge decrease in compilation time: from ~60 mins to 5 mins !! I compiled with the following code by increasing the concurrent processes to 4 (where the default was 1)\r\n\r\n`D:\\...\\build> MSBuild /m:4 /p:Configuration=Release tf_python_build_pip_package.vcxproj`\r\n\r\nAlso I want to mention as a side note that I tested both pre-compiled version of tensorflow-gpu and the version that I compiled on training a simple cnn. The speedup is very noticable. Totally worth it!", "for the ones who are still suffering, take a look [here](http://twonightmare.blogspot.com/2017/08/tensorflow-gpu-build-for-windows-for.html).", "@borablanca how did you manage to build tensor-gpu? I am consistently failing...", "I just leave it here https://twitter.com/Evl_Spirit/status/993777818294276096"]}, {"number": 10798, "title": "TF Detect to work with the new Object Detection API model", "body": "Hi there, if I replace the current TF Detect model with the new Object Detection API model, will it still work?", "comments": ["@bryancresswell  - are you referring to the Android Detection demo?", "@jch1 yup!", "It currently won't work (it was actually trained using an older version of the API) - I plan to update it to use the new models over the next couple of weeks.", "Alright, sounds great! Looking forward to the updates! Thanks for the quick response.", "@bryancresswell I added an Android example using the Object Detection API (MobileNet w/ SSD) here: https://github.com/bmount/tensorflow/tree/android-demo-mobilenet-ssd (patch: https://github.com/bmount/tensorflow/commit/24b59a4a7797623a9da9311ee1214ac334478ed3 ). You can download the model graphs and labels from the links in the comments in the configuration section of the SSD_ variables. Curious to see how it works for you, I've only tested on 1 high-end phone, latency is not ideal but the quality of detection and tracking is pretty great.\r\n\r\n@jch1 I gather you are working on a fuller update to the detection examples -- really looking forward to that. The Object Detection API is so nicely ergonomic (thank you!) that something simple like the above link may be enough to get people started, if it's useful for the demo I could make it PR-able. General feedback toward the other update effort is just: the Single Shot + MobileNet model (from the zoo) with the current tracker is pretty great and would be a reasonable default for the detector activity and build-time downloads, if it performs reasonably on enough devices. An example of feeding RGB inputs with fewer intermediate steps than the examples that assume FP32 inputs would also be helpful for demo code (if that's possible.) ", "hey @bmount ,\r\n\r\nI want to try your project and get your project start on my smartphone (Samsung S7).\r\nI dont have any idea how i can get your finished work  (https://github.com/bmount/tensorflow/tree/android-demo-mobilenet-ssd) on my smartphone. Please can you help me an upload your work as a finished android app ??\r\n\r\nbest wishes\r\nSavash", "Hi @Savash2016, here's a large \"everything\" apk: https://storage.googleapis.com/bmount/ssd-mobilenet-v1-coco/tensorflow_demo.apk . If you have trouble installing, steps to build are: 1) check out https://github.com/bmount/tensorflow/tree/android-demo-mobilenet-ssd 2) run `bazel build -c opt //tensorflow/examples/android:tensorflow_demo` 3) run `adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk` to install on device. Curious how this runs on your phone, have heard some decent results from people who landed on this thread.", "Niceeeeeee! Hi @bmount,\r\nthank you! I can work with both ways without any problems! \r\nPreviously I worked with darkflow/yolo to make an app in android and it was quite the same.\r\n\r\nAgain, thank you and keep doing!\r\n", "Hi,\r\n\r\n@Savash2016  @bmount  I tried compiling and got the following error..\r\n\r\n`No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                     device='GPU'; T in [DT_STRING]\r\n                                                                     device='GPU'; T in [DT_BOOL]\r\n                                                                     device='GPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_INT32]\r\n[[Node: Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/cond/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater, Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater)]]\r\n                                                                       at org.tensorflow.Session.run(Native Method)\r\n                                                                       at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                       at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                       at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)\r\n                                                                       at org.tensorflow.demo.TensorFlowSingleShotDetector.recognizeImage(TensorFlowSingleShotDetector.java:105)\r\n                                                                       at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:337)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:739)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:148)\r\n                                                                       at android.os.HandlerThread.run(HandlerThread.java:61)`\r\n\r\nCan you help me out?\r\n\r\nSince I am on Windows, I am using Gradle and using the prebuilt Tensorflow .so and .aar files.", "Hi,\r\n@anandcu3 sorry I dont have an solution for this.\r\n\r\nBut I would advise you to do your work in linux (ubuntu).\r\nPreviously I worked with windows  too and after a lot of problems (with bazel and tensorflow) I switched to Ubuntu.\r\n\r\n", "@anandcu3 I think I hit the Switch kernel registration issue too and the workaround was this little change in register_types.h:  https://github.com/bmount/tensorflow/commit/24b59a4a7797623a9da9311ee1214ac334478ed3#diff-76e272a58ca1535b3e0ec93499779a14 which I believe I found here: https://github.com/tensorflow/tensorflow/issues/2680 . That patch is part of the commit with the ssd demo, so you should be able to build from that commit, any additional errors would be Windows and I probably wouldn't be helpful debugging.", "@bmount  @Savash2016 I took time and got a VM setup with Ubuntu 16 64bit. and used the tensorflow repo from your fork. Now the  Switch kernel registration issue is solved but i get this error.\r\n\r\n`ERROR: /home/anand/TensorflowAndroidPort/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:4539:1: Linking of rule '//tensorflow/core/kernels:android_tensorflow_kernels' failed (Exit 1): arm-linux-androideabi-ar failed: error executing command `\r\n`Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 1515.142s, Critical Path: 54.58s\r\nFAILED: Build did NOT complete successfully`\r\n\r\n Edit: I updated the error to make it more readable\r\n\r\nCould you please help me debug this? And provide more information about the Bazel and NDK api versions used.", "@anandcu3 The required toolchain is the one in NDK 12b (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#install-bazel-and-android-prerequisites), IIRC I initially tried with a more recent release too and had a similar problem.", "@bmount I'm using NDK12b as well.. Posted an issue regarding this separately as well..\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/12109\r\n", "Thanks @bmount ! Tested your apk on a Moto G5 Plus, detection takes ~2-3 seconds but quality is pretty good. Will try to build your detection class and test different quantizations to see if it improves the detection speed.", "@jch1 thanks for your work first. and I wonder when the updated API can be released. ", "@bmount I want to make the .pkt for the object detection on the mobile. And I want to make the the label to be chinese, so I want to know the label of the mobilenet on the tensorflow, but I can't find the label file by downloading the model from the tensorflow model zoo. Maybe can you tell me where to find the label file for the mobilenet? thank you so much! hope your message!", "@lugq1990 the TensorFlow team has pushed a full update a few days ago that includes MobileNet + Single Shot detector by default, and references to and automatic downloading of models and label files: https://github.com/tensorflow/tensorflow/commit/53aabd5cb0ffcc1fd33cbd00eb468dd8d8353df2\r\n\r\nYou can download them separately here: http://storage.googleapis.com/download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_android_export.zip -- in COCO a number of classes were removed after labeling had begun, so there are gaps represented by \"???\", otherwise you should be able to replace each English label with the Chinese equivalent in that word list.", "@bmount that's what I want. Really thank you !!! wish you a good day!", "@bmount When I apply the  TensorFlow team pushed android demo, in the object detection, in my mobilephone can't get any boundingbox,I don't know what it occurs?", "@wm901115nwpu please open a new issue and fill out the template form with all relevant details, including a full description of what you're seeing on the screen and trying to recognize. This will make the problem much easier to diagnose, thanks.", "@wm901115nwpu @andrewharp \r\n\r\nFaced the same issue. I got around that by setting \r\n\r\n`useCamera2API = true`\r\n\r\ninstead of \r\n\r\n`useCamera2API = isHardwareLevelSupported(characteristics,\r\n            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_FULL);`\r\n\r\nat https://github.com/tensorflow/tensorflow/blob/3686ef0d51047d2806df3e2ff6c1aac727456c1d/tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java#L300\r\n ", "@anandcu3 it works well, thank you.", "@wm901115nwpu @anandcu3 can you please provide details about your devices so that we can further tailor the Camera API selection?\r\n\r\nIt should still draw boxes on detections using API 1, so if it doesn't then that is also an issue.", "@andrewharp \r\n\r\nI'm on OnePlus X with Marshmallow 6.0.1 (API 23) . ", "@andrewharp I'm on HongMi Note4 with MIUI8.5.", "Huawei P9 Lite: \"useCamera2API = true\" also made the detection demo work.  No boxes before that.", "Same issue with a Motorola G5 Plus, got it working with useCamera2API = true", "Do you know How to use direct camera to detect object?"]}, {"number": 10797, "title": "Tutorial: Pass train_file.name instead of train_file", "body": "Change read_csv argument from train_file to train_file.name in tutorial\r\nfor Linear model.\r\n\r\nPassing train_file to read_csv doesn't load any data into dataframe\r\nand the dataframe remains empty. It works when changed to file name.", "comments": ["Can one of the admins verify this patch?", "Thanks @sahildua2305!"]}, {"number": 10796, "title": "Merge pull request #1 from tensorflow/master", "body": "merge from master", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Sorry, I try to update fork"]}, {"number": 10795, "title": "How to update the variable list for which the optimizer need to train in tensorflow?", "body": "How to update the list of variables for the optimizer to train in tensorflow? In other words, if we have the following optimizer:\r\n\r\n`optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_scalar, var_list=my_var_list)`\r\n\r\nI need to update my_var_list for example while fine tuning the network. That is, I am going to remove the variable which I no longer need to train and keep the others. Example, fine tuning the dense layer in a convolutional neural network.\r\n\r\nAny help is much appreciated!!", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nHowever, one thing you could do is just make a new optimizer op that contains a changed set of var_list. i.e. nothing says you can't have more than one. Obviously this is not efficient if you need to do this too often."]}, {"number": 10794, "title": "Failed to load the native TensorFlow runtime.", "body": "## I tried #10026 but I won't work for me . \r\n-------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-21-32e52670ef8f> in <module>()\r\n      6 import pattern\r\n      7 from bs4 import BeautifulSoup as bs\r\n----> 8 import tensorflow as tf\r\n```\r\n/root/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\n/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     50 for some common reasons and solutions.  Include the entire stack trace\r\n     51 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 52   raise ImportError(msg)\r\n     53 \r\n     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /root/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n```\r\n\r\n## Failed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 10793, "title": "Arbitrary dim for tile", "body": "Add arbitrary dim support for Tile Op. https://github.com/tensorflow/tensorflow/issues/8873", "comments": ["Can one of the admins verify this patch?", "@girving could you take a look? Thanks!", "@girving python unit test added", "Jenkins, test this please.", "@yanchen036 Can you fix the buildifier errors mentioned in https://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/4904/console?", "@girving Sorry, I'm confused by the error info. I haven't seen the difference.\r\n```\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n725d724\r\n<     prefix = \"tile_ops\",\r\n731a731\r\n>     prefix = \"tile_ops\",\r\n4136a4137\r\n>         \"tile_functor.h\",\r\n4139d4139\r\n<         \"tile_functor.h\",\r\n4274a4275\r\n>         \"tile_functor_cpu.cc\",\r\n4283d4283\r\n<         \"tile_functor_cpu.cc\",\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```", "It wants you to reorder some lines.  This is so internal tools that parse and print the file don't change it.", "@girving I'm not sure. Like this? \r\n```\r\n tf_kernel_library(\r\n     name = \"tile_ops\",\r\n-    prefix = \"tile_ops\",\r\n     srcs = [\"tile_functor_cpu.cc\"],\r\n     hdrs = [\"tile_functor.h\"],\r\n     gpu_srcs = [\r\n-        \"tile_functor_gpu.cu.cc\",\r\n         \"tile_functor.h\",\r\n+        \"tile_functor_gpu.cu.cc\",\r\n     ],\r\n+    prefix = \"tile_ops\",\r\n     deps = ARRAY_DEPS,\r\n )\r\n```", "Jenkins, test this please.", "@girving Aha, I understand, please test again, thanks", "Jenkins, test this please.", "Can you fix the `Makefile` breakage?  Look in `tensorflow/contrib/makefile` and make sure your new files are referenced where the current tile files are.", "added tile_functor_cpu.cc to makefile.", "Jenkins, test this please.", "Woohoo!  Thank you for the contribution @yanchen036!  No one using TensorFlow will ever realize you did this, because their code will just silently do the right thing rather than breaking in a surprising and unnecessary manner. :)", "Thanks for the review, @girving ,I'll continue to refactor other binary operators which not support arbitrary dimension.", "@drpngx Ready to merge.", "Thanks!", "@yanchen036 and/or @girving , I was recently having some build issues related to this when we started to need the tile kernels and I added the `tile_*.cc` files to our kernel list. (Note: this is a modified version based of the CMake in `contrib/cmake`.) It turned out that I was forgetting to also build with `tile_functor.cc` and thus I was getting `undefined reference to tensorflow::functor::Tile` errors. It seems that outside of this thread, the only place this dependency is explicit is [the makefile](https://github.com/tensorflow/tensorflow/pull/10793/commits/e640d75bc6dd1f9a3990c4e199d36f67c5f98bcd) and the bazel `BUILD` file. I haven't had the time to understand how all the kernel code is structured to make sense of it, but should there be some kind of explicit dependency among the `tile_*.h` files or `tile_*.cc` files (e.g., `tile_ops_impl.h` includes `tile_functor.h`)?\r\n\r\nThanks!", "Yes it's probably missing [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/BUILD#L833). PR welcome. Thanks!", "@drpngx , I don't understand what you mean. [tile_functor_cpu.cc already includes tile_functor.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tile_functor_cpu.cc#L18https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tile_functor_cpu.cc#L18), so I was thinking somewhere (like [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tile_ops.cc#L38)) to connect the `tile_ops_*` to the `tile_functor_*` files.", "I was talking about the build files. They should be connected. If there is a missing include, then we should also add it."]}, {"number": 10792, "title": "Enable sparse_matmul(a,b) when a and b are sparse, conformable", "body": "Current tf.sparse_matmul(a,b) requires both a and b to be dense, apparently.\r\n\r\n```\r\nn = 500000\r\nk = 5000\r\nwith tf.Session() as sess:\r\n    rep = 1.0\r\n    sparse1 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])\r\n    sparse2 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])\r\n    sparse1 = tf.cast(sparse1, tf.float32)\r\n    sparse2 = tf.cast(sparse2, tf.float32)\r\n\r\n    sq = tf.sparse_matmul(\r\n            tf.sparse_tensor_to_dense(sparse1, 0.0)\r\n            , tf.sparse_tensor_to_dense(sparse2, 0.0)\r\n            , a_is_sparse=True\r\n            , b_is_sparse=True\r\n)\r\n```\r\n\r\nThe cast of `sparse_tensor_to_dense()` seem inappropriate.  Please enable\r\n\r\n```\r\nn = 500000\r\nk = 5000\r\nwith tf.Session() as sess:\r\n    rep = 1.0\r\n    sparse1 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])\r\n    sparse2 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])\r\n    sparse1 = tf.cast(sparse1, tf.float32)\r\n    sparse2 = tf.cast(sparse2, tf.float32)\r\n\r\n    sq = tf.sparse_matmul(\r\n            sparse1\r\n            , sparse2\r\n            , a_is_sparse=True\r\n            , b_is_sparse=True\r\n)\r\n```", "comments": ["Related issue: https://github.com/tensorflow/tensorflow/issues/10003", "@lakshayg, yes this is a dupe of #10003, closing for now. thanks!"]}, {"number": 10791, "title": "[Docs] Clarify Python requirement ", "body": " Explicitly state Python target arch on Windows.\r\nReference: https://github.com/tensorflow/tensorflow/issues/10786#issuecomment-309187925", "comments": ["Can one of the admins verify this patch?"]}, {"number": 10790, "title": "conv1d not in tf.contrib.layers", "body": "As of tensorflow 1.2, conv1d can be found under `tf.layers`, and not `tf.contrib.layers`, where you find conv2d. Shouldn't it be available under the contrib namespace? By the way, what's the conceptual difference between both submodules?", "comments": ["tf.contrib.* should be considered temporary. We make no guarantees about the stability of the modules and symbols in there. They may change behavior (even in not backwards-compatible ways) at any time. \r\n\r\nThe symbols in core (anything in the tensorflow module that is not in contrib) are subject to semver guarantees, meaning they will not change behavior in backwards-incompatible ways between minor releases. Backwards incompatible changes are only allowed between major releases.\r\n\r\nWe use contrib as a staging ground where we try out and test ideas. When those ideas mature and stabilize, we move them out of contrib, and in the process remove deprecated parts or fix problems that we may have identified while working with them for a while.\r\n\r\nOnce we have a core module we don't really want to maintain the contrib versions. The only reason to not delete them is in order to avoid unnecessarily breaking users of the contrib versions. For layers, the contrib versions (of layers already in core) should be considered deprecated and subject to eventual removal. If we make improvements to the core version (such as adding conv1d) we may not also backport these improvements to the contrib modules."]}, {"number": 10789, "title": "quantize_graph error in simple graph", "body": "\r\nwhen my graph is as follows, it will fail to quantize, the error info is **AssertionError: Failed to quantized constant ones_1 of type**\r\n`x = tf.ones((1000,1),'int32')\r\n**ones = tf.ones((1, 100), \"int32\")**\r\nx = tf.reshape(x, shape=(-1,1))`\r\n\r\nwhen i change graph to the following, it works:\r\n`x = tf.ones((1000,1),'int32')\r\n**ones = tf.ones((1, 100), \"int32\")\r\nones = tf.reshape(ones, shape=(1,-1))**\r\nx = tf.reshape(x, shape=(-1,1))`\r\n\r\nis there anyone can help me to find out the reason, because even i change my code and successfully generated quantized graph, the graph is wrong when importing, BTW my graph is much more complex than the code above.", "comments": ["BTW, what the meaning of parameter \"mode\" can take, such as round, quantize, eightbit, weights, or weights_rounded", "if i use tf.fill instead fo tf.ones, then can quantize the graph, but when importing graph, it reports an error that can not change from int32 to float32. the reason why it should  change to float32 is beacuse the variable will matrix multiply with another float variable", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 10788, "title": "Where is ios_examples?", "body": "Hi,\r\n\r\nI'm trying to follow your iOS guide in the README, which tells me to use: tensorflow/contrib/ios_examples. \r\n\r\nBut this folder is completely missing.\r\n\r\nCan anyone advise? ", "comments": ["Just found ios_examples was moved to tensorflow/examples/ios. You may want to update your README as it contains broken links to the old location.\r\n\r\nAdditionally the broken links are used elsewhere in the repo. E.g.: the README for https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios still refers to ios_examples.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 10787, "title": "quantize_graph", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 10786, "title": " Unable to install tenser flow  on python 3.6.1 on windows 10 x64", "body": "![pip](https://user-images.githubusercontent.com/29494774/27248510-24b7f1f6-5322-11e7-9067-1ba4dfb700ac.PNG)\r\n\r\n\r\nUnable to install tenserflow ", "comments": ["@Vishurao06 You're installing a wheel for Python 3.5. `tensorflow-1.0.0cp35-cpm35` where **cp35** is the version it was compiled to. \r\nYou need the corresponding wheel for Python 3.6 that you can download [here](http://ci.tensorflow.org/view/Nightly/job/nightly-win/M=windows,PY=36/lastSuccessfulBuild/artifact/cmake_build/tf_python/dist/tensorflow-1.2.0rc2-cp36-cp36m-win_amd64.whl)", "Thanks , but the issue is still the same\r\n\r\n![pip](https://user-images.githubusercontent.com/29494774/27249079-a02954d0-532a-11e7-8d6d-e869d0568ebd.PNG)\r\n", "@yifeif looks like we're not stripping the amd64 suffix, but we should?", "thanks i fixed it , actually the pip scripts were default at 32 bit as in the below image \r\n![pip2](https://user-images.githubusercontent.com/29494774/27249257-8f990634-532e-11e7-99fb-1d66191ee5f0.PNG)\r\n\r\nso i changed both path and script path to python36  instead of default python 36-32", "@Vishurao06 glad you solved. TensorFlow requires Python 64-bit on Windows.\r\n\r\nBTW this info could be a good addition to Windows installation guide. One can infer that but it's actually not explicitly stated which could be helpful for beginners or folks without much tech grasp (seen it happen a few times with researchers/academics that are not so technically proficient for instance).\r\ncc @mrry "]}, {"number": 10784, "title": "build fails for r1.2 on linux", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n\r\nOS: Ubuntu 16.04.2 LTS\r\nI have cloned tensorflow from github.\r\nchecked out release r1.2\r\n\r\nI have rune the configure script:\r\n$ ./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.5/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n/usr/lib/python3/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N] N\r\nNo MKL support will be enabled for TensorFlow\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: -march=native\r\nDo you wish to use jemalloc as the malloc implementation? [Y/n] Y\r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] N\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] N\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] N\r\nNo XLA JIT support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N] N\r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] N\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] N\r\nNo CUDA support will be enabled for TensorFlow\r\n..................................................\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nConfiguration finished\r\nshaeffer@ip-10-164-47-27:/srv/projects/c++/tfgit1.2$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nERROR: /srv/projects/c++/tfgit1.2/third_party/py/python_configure.bzl:285:20: unexpected keyword 'environ' in call to repository_rule(implementation: function, *, attrs: dict or NoneType = None, local: bool = False).\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension file 'third_party/py/python_configure.bzl' has errors.\r\nINFO: Elapsed time: 3.281s\r\n\r\nThe tensorflow r1.2 build fails as described directly above.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**: GitHub clone of source code\r\n- **TensorFlow version (use command below)**: r1.2\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\n$ bazel version\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\n- **Exact command to reproduce**:\r\n\r\n$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package", "comments": ["Try upgrading bazel to at least 0.4.5.\r\n", "Ok, upgraded bazel\r\n\r\n$ bazel version\r\nBuild label: 0.5.1\r\n\r\nThis has resolved the build failure.\r\nThank you."]}, {"number": 10783, "title": "Update performance_guide.md", "body": "", "comments": ["Can one of the admins verify this patch?", "fixes #7551", "Jenkins, test this please."]}, {"number": 10782, "title": "Fix #9392", "body": "", "comments": []}, {"number": 10781, "title": "Update performance_guide.md", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "fixes #7776"]}, {"number": 10780, "title": "1.2 release python pip version is incorrect", "body": "The python pip package still has the version label 1.2.0-rc2 even though 1.2.0 was released proper today. Can you change please.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L32\r\n", "comments": ["@apcode, the master branch hasn't been updated yet. The release is generated from the r1.2 branch, which is in the process of being merged back to the master branch. Once the merge is done, master will be at 1.2.0 as well.", "That usually happens when we remerge the 1.2.0 branch back into master. This is normal. Thanks for the comment."]}, {"number": 10779, "title": "Mac + Python 3.6.1: Attempting to download mnist data results in CERTIFICATE_VERIFY_FAILED error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n$ python3 --version\r\nPython 3.6.1\r\n\r\n$ python3 -m virtualenv venv\r\nUsing base prefix '/Library/Frameworks/Python.framework/Versions/3.6'\r\nNew python executable in .../venv/bin/python3\r\nAlso creating executable in .../venv/bin/python\r\nInstalling setuptools, pip, wheel...done.\r\n\r\n$ source venv/bin/activate\r\n$ pip install tensorflow\r\nCollecting tensorflow\r\n  Using cached tensorflow-1.2.0-cp36-cp36m-macosx_10_11_x86_64.whl\r\n  ....\r\n\r\n$ python\r\nPython 3.6.1 (v3.6.1:69c0db5050, Mar 21 2017, 01:21:04) \r\n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.examples.tutorials.mnist import input_data\r\n>>> mnist = input_data.read_data_sets(\"/tmp/data/\")\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1318, in do_open\r\n    encode_chunked=req.has_header('Transfer-encoding'))\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1239, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1285, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1234, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1026, in _send_output\r\n    self.send(msg)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 964, in send\r\n    self.connect()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1400, in connect\r\n    server_hostname=server_hostname)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 401, in wrap_socket\r\n    _context=self, _session=session)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 808, in __init__\r\n    self.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 1061, in do_handshake\r\n    self._sslobj.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 683, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 235, in read_data_sets\r\n    SOURCE_URL + TRAIN_IMAGES)\r\n  File \".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 248, in urlretrieve\r\n    with contextlib.closing(urlopen(url, data)) as fp:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 223, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 526, in open\r\n    response = self._open(req, data)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 544, in _open\r\n    '_open', req)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 504, in _call_chain\r\n    result = func(*args)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1361, in https_open\r\n    context=self._context, check_hostname=self._check_hostname)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1320, in do_open\r\n    raise URLError(err)\r\nurllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749)>\r\n```\r\n\r\nThis doesn't reproduce with TensorFlow 1.1.\r\n", "comments": ["Could you try with python2 (default system install of py)? Also,  how did you install with brew or macports (we use brew for our testing so that's more likely to work).", "I installed Python 3.6 using the dmg installer from the Python website (not through brew or macports).\r\n\r\nIt seems to work with Python 2.7.10. I had thought that in Python 2.x urlretrieve didn't validate the server certificate, but apparently it does as of 2.7.9: https://docs.python.org/2/library/urllib.html", "It works me on python 3.4 on Linux. I'd try installing python3.6 using brew. It could be the python3 distrib you are using has out of data certificates.", "This might have also been because I recently switched to a new machine and it's still only partially installed :)\r\n\r\nFor future reference: if you want to use the Python dmg installer, you also have to read Python 3's ReadMe and run the `/Applications/Python 3.6/Install Certificates.command` bash script to install newer certs.\r\n\r\nThanks for the quick response, @aselle!\r\n", "If you want to just copy paste into Terminal:\r\n`/Applications/Python\\ 3.6/Install\\ Certificates.command\r\n`", "I'm getting exactly this same issue on MacOSX 10.11.6\r\n\r\nI first followed exactly the steps here for the `virtualenv` setup for Python 3.n: https://www.tensorflow.org/install/install_mac\r\n\r\nThen, following the first 2 steps in this tutorial https://www.tensorflow.org/get_started/mnist/beginners I see the following; any suggestions for working-around this (e.g. could I download this from somewhere else?) would be greatly appreciated.\r\n\r\n```\r\n(tensorflow) ~/tensorflow  $ python\r\nPython 3.6.2 (v3.6.2:5fd33b5926, Jul 16 2017, 20:11:06) \r\n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.examples.tutorials.mnist import input_data\r\n>>> mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1318, in do_open\r\n    encode_chunked=req.has_header('Transfer-encoding'))\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1239, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1285, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1234, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1026, in _send_output\r\n    self.send(msg)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 964, in send\r\n    self.connect()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 1400, in connect\r\n    server_hostname=server_hostname)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 401, in wrap_socket\r\n    _context=self, _session=session)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 808, in __init__\r\n    self.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 1061, in do_handshake\r\n    self._sslobj.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 683, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/aaron/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 235, in read_data_sets\r\n    SOURCE_URL + TRAIN_IMAGES)\r\n  File \"/Users/aaron/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \"/Users/aaron/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/aaron/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 248, in urlretrieve\r\n    with contextlib.closing(urlopen(url, data)) as fp:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 223, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 526, in open\r\n    response = self._open(req, data)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 544, in _open\r\n    '_open', req)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 504, in _call_chain\r\n    result = func(*args)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1361, in https_open\r\n    context=self._context, check_hostname=self._check_hostname)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\", line 1320, in do_open\r\n    raise URLError(err)\r\nurllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>\r\n```\r\n\r\n", "@brightbytes-dude Did you run the command listed here: https://github.com/tensorflow/tensorflow/issues/10779#issuecomment-309134512\r\n\r\n`/Applications/Python\\ 3.6/Install\\ Certificates.command`\r\n", "That did the trick, thanks!!  (I stupidly assumed that was only relevant for the `dmg` installation.)", "Could you please change the MNIST download URL in contrib/learn/python/learn/datasets/mnist.py to not use https ? That will help people who are having this problem. In tried in a browser and the http download link works.\r\n\r\nline to change:\r\nSOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\nnew line:\r\nSOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'", "Hello, \r\nI'm new to python and tensorflow. Trying the MNIST example and receive the about the same error messages as paulcwatts (above) \r\n>>> from tensorflow.examples.tutorials.mnist import input_data\r\n>>> mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 1318, in do_open\r\n    encode_chunked=req.has_header('Transfer-encoding'))\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 1239, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 1285, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 1234, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 1026, in _send_output\r\n    self.send(msg)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 964, in send\r\n    self.connect()\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\http\\client.py\", line 1400, in connect\r\n    server_hostname=server_hostname)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\ssl.py\", line 401, in wrap_socket\r\n    _context=self, _session=session)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\ssl.py\", line 808, in __init__\r\n    self.do_handshake()\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\ssl.py\", line 1061, in do_handshake\r\n    self._sslobj.do_handshake()\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\ssl.py\", line 683, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#4>\", line 1, in <module>\r\n    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py\", line 240, in read_data_sets\r\n    source_url + TRAIN_IMAGES)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 248, in urlretrieve\r\n    with contextlib.closing(urlopen(url, data)) as fp:\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 223, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 526, in open\r\n    response = self._open(req, data)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 544, in _open\r\n    '_open', req)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 504, in _call_chain\r\n    result = func(*args)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 1361, in https_open\r\n    context=self._context, check_hostname=self._check_hostname)\r\n  File \"C:\\Users\\Andreas\\Documents\\Python\\lib\\urllib\\request.py\", line 1320, in do_open\r\n    raise URLError(err)\r\nurllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>\r\n\r\n\r\n\r\nThe main difference is that I'm on WINDOWS 10 and I cannot find the certificates command. \r\nSorry for maybe asking \"stupid questions\" but those errors do not \"go away\"\r\n", "I have same problem with ssl  and this line fix it,\r\n/Applications/Python\\ 3.6/Install\\ Certificates.command\r\n thanks @EthanAI @aselle @paulcwatts ", "If there's anyone stumbling across this page but looking for the answer to permit Tensorflow Hub in Ubuntu, I made it work like this:\r\n\r\n```\r\n# Directory where user certs can be stored\r\ncd /usr/local/share/ca-certificates\r\n# Below may require elevated permissions, such as sudo su\r\npip3 install --upgrade certifi  # Installs a certificate file\r\n# Move the installed cert to the place Ubuntu expects it\r\ncp /home/ubuntu/.local/lib/python3.5/site-packages/certifi/cacert.pem .\r\n# Convert it into the format Ubuntu expects\r\nopenssl x509 -in cacert.pem -inform pem -outform der -out cacert.crt\r\n# Actually load the new cert into the OS\r\nupdate-ca-certificates\r\n```\r\n\r\nOn top of this, some magical combination of configuration of my corporate proxy, restarting the Jupyter notebook kernel, and running TF Hub from a script on the terminal rather than from a notebook eventually caused TF Hub to work both on the terminal and in the notebook.", "running that command also failed. \r\n./Install\\ Certificates.command \r\n -- pip install --upgrade certifi\r\nCollecting certifi\r\n  Cache entry deserialization failed, entry ignored\r\n  Could not fetch URL https://pypi.python.org/simple/certifi/: There was a problem confirming the ssl certificate: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) - skipping\r\n  Could not find a version that satisfies the requirement certifi (from versions: )\r\nNo matching distribution found for certifi\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 44, in <module>\r\n  File \"<stdin>\", line 25, in main\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\", line 291, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6', '-E', '-s', '-m', 'pip', 'install', '--upgrade', 'certifi']' returned non-zero exit status 1.", "on MacOS `/Applications/Python\\ 3.6/Install\\ Certificates.command` command works for me", "`/Applications/Python\\ 3.6/Install\\ Certificates.command` did the magic on MacOSX High Sierra. Thx", "What is the solution for those using a virtual environment?\r\n\r\nUpdate: It looks like running that same system command pointed out above \ud83d\udc46 does the trick when in an active venv as well. Good to know!", "> If you want to just copy paste into Terminal:\r\n> `/Applications/Python\\ 3.6/Install\\ Certificates.command `\r\n\r\nthank u!", "> This might have also been because I recently switched to a new machine and it's still only partially installed :)\r\n> \r\n> For future reference: if you want to use the Python dmg installer, you also have to read Python 3's ReadMe and run the `/Applications/Python 3.6/Install Certificates.command` bash script to install newer certs.\r\n> \r\n> Thanks for the quick response, @aselle!\r\n\r\nThanks! It worked! :D", "Thanks", "> Could you please change the MNIST download URL in contrib/learn/python/learn/datasets/mnist.py to not use https ? That will help people who are having this problem. In tried in a browser and the http download link works.\r\n> \r\n> line to change:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n> new line:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n\r\nI see both the urls are same.", "> Could you please change the MNIST download URL in contrib/learn/python/learn/datasets/mnist.py to not use https ? That will help people who are having this problem. In tried in a browser and the http download link works.\r\n> \r\n> line to change:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n> new line:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n\r\nIt worked for me. ", "We only need input at the Terminal\r\n`\r\nopen \"/Applications/Python 3.6/Install Certificates.command\"\r\n`", "> > Could you please change the MNIST download URL in contrib/learn/python/learn/datasets/mnist.py to not use https ? That will help people who are having this problem. In tried in a browser and the http download link works.\r\n> > line to change:\r\n> > SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n> > new line:\r\n> > SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n> \r\n> I see both the urls are same.\r\n\r\nchange 'https://...' to 'http://...'", "/Applications/Python 3.7/Install Certificates.command\r\nWork for me", "How to do it in Manjaro Linux? I have Python3.7 tensorflow.", "> If you want to just copy paste into Terminal:\r\n> `/Applications/Python\\ 3.6/Install\\ Certificates.command `\r\n\r\nThanks man! It works for me! \r\nI just run the code in jupyter notebook:\r\n`!/Applications/Python\\ 3.6/Install\\ Certificates.command`", "# Incase of linux...\r\ngo to **.local/python3.X/lib/python3.6/site-packages/keras/utils/data_utils.py**  \r\n\r\n## and below import statements add these----\r\n\r\n```import requests\r\nrequests.packages.urllib3.disable_warnings()\r\nimport ssl\r\n\r\ntry:\r\n    _create_unverified_https_context = ssl._create_unverified_context\r\nexcept AttributeError:\r\n    # Legacy Python that doesn't verify HTTPS certificates by default\r\n    pass\r\nelse:\r\n    # Handle target environment that doesn't support HTTPS verification\r\n    ssl._create_default_https_context = _create_unverified_https_context\r\n```\r\n\r\n> now try new instance of python and ..hopefully it works  :smile_cat: ", "> This might have also been because I recently switched to a new machine and it's still only partially installed :)\r\n> \r\n> For future reference: if you want to use the Python dmg installer, you also have to read Python 3's ReadMe and run the `/Applications/Python 3.6/Install Certificates.command` bash script to install newer certs.\r\n> \r\n> Thanks for the quick response, @aselle!\r\n\r\nYou saved my life with this comment! <3", "> Could you please change the MNIST download URL in contrib/learn/python/learn/datasets/mnist.py to not use https ? That will help people who are having this problem. In tried in a browser and the http download link works.\r\n> \r\n> line to change:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n> new line:\r\n> SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\r\n\r\nThis works for me on ubuntu\r\nby changing `~/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/keras/datasets/mnist.py`\r\n\r\n**New Line**\r\n`origin_folder = 'http://storage.googleapis.com/tensorflow/tf-keras-datasets/'`\r\n", "Here's what worked for me:\r\n\r\n1. Download the mnist dataset file by hand (the url is given in the error message)\r\n2. Copy that file into ~/.keras/datasets/\r\n\r\nThat's all.  The keras download utility looks in that folder for cached data before going over the network.\r\n\r\n(Python 3.7.3, tensorflow 2.1.0)", "/Applications/Python\\ 3.6/Install\\ Certificates.command does this work for virtual environment as well? "]}, {"number": 10778, "title": "Merging r1.2 back into master.", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "In other words, omit 323d40fce604e9e31975714197ce4a7064b55dc2", "yes please.\u200b\n"]}, {"number": 10777, "title": "Error: map_fn = tf.python.functional_ops.map_fn AttributeError: module 'tensorflow' has no attribute 'python'", "body": "Error on System: py3.5, win7, tf 1.2 cpu version.\r\n\r\nmap_fn = tf.python.functional_ops.map_fn\r\nAttributeError: module 'tensorflow' has no attribute 'python'\r\n", "comments": ["How do I reproduce this? Command line? just `python -c \"import tensorflow\"`?", "just these two lines:\r\n```\r\nimport tensorflow as tf\r\nmap_fn = tf.python.functional_ops.map_fn\r\n```\r\nanyway looks like old code which might be changed to \r\n`map_fn = tf.map_fn` ?\r\n\r\nI am closing this issue, because it works. Thanks"]}, {"number": 10776, "title": "Docker build issues -- libcuda.so.1 cannot be found", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I'm using baidu's warp-ctc which has custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A, using docker\r\n- **TensorFlow installed from (source or binary)**: provided docker image\r\n- **TensorFlow version (use command below)**: 1.2.0\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Provided\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nUnable to install warp-ctc with tensorflow in version 1.2, while it works in version 1.0.0\r\n\r\nThis is screenshot of dockerfile for version 1.0: http://i.imgur.com/Zl9ikYT.png\r\nFor newer tensorflow versions (e.g. 1.1 and 1.2 have the same issue) problems occur: http://i.imgur.com/UEcCkOm.png\r\n\r\nThat is libcuda.so.1 cannot be found. \r\n\r\nI've opened similar issue on nvidia-docker https://github.com/NVIDIA/nvidia-docker/issues/374 since I've used their images and installed tensorflow via pip with same exact issues. Only change is tensorflow verions while everything else remains the same.\r\n\r\nI'm unable to test this outside docker contained due to machine permissions (or lack thereof, no admin and cannot install newer CUDA/cuDNN/etc.)\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nHere is dockerfile used in the reproduction:\r\n```\r\nFROM tensorflow/tensorflow:1.2.0-devel-gpu-py3\r\n \r\nRUN apt-get update && apt-get install -y --no-install-recommends \\\r\n        build-essential \\\r\n        python3-setuptools \\\r\n        python3-dev \\\r\n        python3-pip \\\r\n        python3-numpy \\\r\n        python3-scipy \\\r\n        software-properties-common \\\r\n        libhdf5-serial-dev \\\r\n        cmake \\\r\n        git \\\r\n        && \\\r\n    apt-get clean && \\\r\n    rm -rf /var/lib/apt/lists/*\r\n \r\nWORKDIR /opt\r\nENV TENSORFLOW_SRC_PATH=/opt/tensorflow\r\nENV WARP_CTC_PATH=/opt/warp-ctc/build\r\nENV CUDA_HOME=/usr/local/cuda\r\n \r\nRUN git clone https://github.com/tensorflow/tensorflow.git tensorflow\r\nRUN git clone https://github.com/nmiculinic/warp-ctc.git warp-ctc\r\n \r\nWORKDIR $TENSORFLOW_SRC_PATH\r\nRUN git checkout tags/v1.2.0\r\n \r\nWORKDIR /opt/warp-ctc\r\nRUN git checkout 4875195a4444991b5c8c6027ffd4bd485e2aac3a\r\n \r\nRUN mkdir build\r\nWORKDIR /opt/warp-ctc/build\r\nRUN cmake .. && make\r\nWORKDIR /opt/warp-ctc/tensorflow_binding\r\nRUN python3 setup.py install\r\n```", "comments": ["What is the docker command you used to start your docker container?", "This is build error, not run. Thus: ```docker build -t tag .```", "Could you try running `nvidia-docker build -t tag`?", "I just did. Same error, nothing's changed.", "Our CI continuously build our docker images using our docker files without any issues.\r\n\r\nSo let's try something simpler to verify if your machine is setup correctly.\r\nCould you try using the docker image checked into dockerhub tf repository? This is to verify if you have correct docker setup:\r\n\r\n```\r\nnvidia-docker run -it tensorflow/tensorflow:latest-gpu bash\r\npython\r\nimport tensorflow as tf\r\ntf.test.is_gpu_available()\r\n```\r\n\r\nIf the above works, then probably there is some issues with the environment variables.", "It responds with True. It found the correct GPU device.", "Then it looks to me like nvidia-docker and TF are clear in this issue.\r\none thing you can try to debug is this, remove the last line (the failing command) from your dockerfile.\r\nStart a container with the image you build with the rest of the dockerfile, using nvidia-docker.\r\nLocate libcuda.so.1 in this container, and try adding the path to your LD_LIBRARY_PATH, then running the last line manually in the container.", "Ok I solved it.\r\n\r\nI added this two lines and modified problematic one:\r\n\r\n```\r\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1\r\nRUN LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:$LD_LIBRARY_PATH python3 setup.py install \r\nRUN rm /usr/local/cuda/lib64/stubs/libcuda.so.1\r\n```\r\n\r\nand that solved the issue. I guess tensorflow changed from implicit libcuda.so to explicit libcuda.so.1 dependency, but I tried without explicit LD_LIBRARY_PATH and it fails. I guess that's needed.\r\n"]}, {"number": 10775, "title": "Link to TensorBoard repo in ISSUES_TEMPLATE.md", "body": "Any new TensorBoard issues should be filed against the TensorBoard repository, not on core TensorFlow.", "comments": ["Done, ptal", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 10774, "title": "Update docker rebuilding instructions", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/7885", "comments": []}]