[{"number": 7906, "title": "Erroneous number of channels in the Guide to TF Layers tutorial.", "body": "The tutorial _[A Guide to TF Layers: Building a Convolutional Neural Network](https://www.tensorflow.org/tutorials/layers)_ seems to have the wrong number of channels in the tensor dimensions given at the end of the paragraph _Convolutional Layer #1_:\r\n\r\n> Our output tensor produced by conv2d() has a shape of [batch_size, 28, 28, 1]: the same width and height dimensions as the input, but now with 32 channels holding the output from each of the filters.\r\n\r\nTo be consistent with the rest of the tutorial, it should probably say _\"shape of [batch_size, 28, 28, 32]\"_, since the rightmost dimension denotes the number of channels.", "comments": ["@karltk Good point, thanks for filing this issue!  I'll get it fixed up."]}, {"number": 7905, "title": "pi_examples: Building label_image shows missing graph.pb.h then graph.pb.h version error", "body": "When building the label_image example in pi_examples:\r\n\r\n./tensorflow/core/framework/graph.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n./tensorflow/core/framework/graph.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nNone, the mentions of graph.pb.h were all for that file simply being missing. \r\n\r\nIn my case, moving graph.pb.h to the location the compiler expects resulted in the version error message, above.\r\n\r\nAlso, the issue reports seemed to be pre- TF v.1.0.0, and likely not relevant.\r\n\r\n### Environment info\r\nOperating System:\r\nRaspbian Jessie, version \"Jan 2017\", release date \"2017-01-11\"\r\nhttps://www.raspberrypi.org/downloads/raspbian/\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\nN/A\r\n\r\nIf installed from binary pip package, provide:\r\nN/A\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n321d38ee0ff76d749a8578f37128b02bf033ce76\r\n\r\n2. The output of `bazel version`\r\nBuild label: 0.4.3- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Feb 24 03:14:34 2017 (1487906074)\r\nBuild timestamp: 1487906074\r\nBuild timestamp as int: 1487906074\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nBuild tensorflow from source, exactly as at:\r\nhttps://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md\r\n\r\nAttempt tp build label_image example, exactly as at:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples/\r\n\r\nCorrected error caused by missing graph.pb.h by copying graph.pb.h from:\r\n/home/pi/tensorflow/bazel-tensorflow/tensorflow/core/framework/graph.pb.h\r\nto\r\n/home/pi/tensorflow/tensorflow/core/framework/node_def.pb.h\r\n\r\nand ran the label_image make again. Error shown below.\r\n\r\n### What other attempted solutions have you tried?\r\nNone, not very familiar w/Bazel and TF building yet... after all, the pi_examples are for newbies to get started with and learn TF, right? \r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\npi@raspberrypi:~/tensorflow $ make -f tensorflow/contrib/pi_examples/label_image/Makefile\r\ngcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen/ -I/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto/ -I/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o\r\nIn file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:32:0:\r\n./tensorflow/core/framework/graph.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n #error This file was generated by a newer version of protoc which is\r\n  ^\r\n./tensorflow/core/framework/graph.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n #error incompatible with your Protocol Buffer headers.  Please update\r\n  ^\r\n./tensorflow/core/framework/graph.pb.h:14:2: error: #error your headers.\r\n #error your headers.\r\n  ^\r\nIn file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:32:0:\r\n./tensorflow/core/framework/graph.pb.h:31:51: fatal error: tensorflow/core/framework/node_def.pb.h: No such file or directory\r\n #include \"tensorflow/core/framework/node_def.pb.h\"\r\n                                                   ^\r\ncompilation terminated.\r\ntensorflow/contrib/pi_examples/label_image/Makefile:79: recipe for target '/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o' failed\r\nmake: *** [/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o] Error 1", "comments": ["Note: The original problem is that these files were reported by the compiler as missing from \r\n./tensorflow/core/framework\r\n\r\ngraph.pb.h\r\nnode_def.pb.h\r\nattr_value.pb.h\r\ntensor.pb.h\r\nresource_handle.pb.h\r\ntensor_shape.pb.h\r\ntypes.pb.h\r\nfunction.pb.h\r\nop_def.pb.h\r\nversions.pb.h\r\n\r\nI read that these files are generated (and then placed in tensorflow/core/framework, i assume), but apparently that didn't happen while building TF.\r\n\r\nRebuilding TF showed that all files were current. \r\n\r\nRunning configure (to clean) and make will take over 10 hours (and recovering from numerous Pi \"hangs\"!), so I haven't done that again yet. \r\n\r\nHowever, I did get a good build of the TF 1.0.0 Python .whl file, it installed OK, and reports version OK in Python. So, the TF (and Bazel?) build appears to be partially successful.\r\n", "@avantol Have you tried following the instructions here to build TF on your pi:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi\r\n\r\nNote that *.pb.h files are generated by the protocol buffer compiler.  That's where to start looking wrt problems with your install.", "@tatatodd: THANKS!!! Using make (instead of Bazel) to build tensorflow:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi\r\n\r\nworked....  and label_image builds correctly now.\r\n\r\nI also had to update protobuf to 3.2.0, others should take note.\r\n\r\nMy conclusion is that Bazel on Raspberry Pi is a *huge waste of time*, it just doesn't work, likely a problem with defining the build for Raspberry Pi. Also, it crashed Pi frequently (yes, I used the memory tips).  \r\n\r\n\"make\" is 8 hours faster and works correctly.\r\n\r\nAlso, others should note that the statement\r\n\"The recommended way to build TensorFlow from source is using the Bazel open-source build system\" at:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi\r\n\r\ndoes NOT necessarily apply to Raspberry Pi!\r\n\r\nThis advice took me down completely the wrong road for a week. Beware!"]}, {"number": 7904, "title": "add_summary won't accept the tensor returned by tensor_summary ", "body": "### Related Problem\r\nhttps://github.com/tensorflow/tensorflow/issues/6778\r\n\r\n### Environment Info\r\nOperating System: Kubuntu 16.04 LTS\r\n\r\nInstalled TensorFlow version:\r\nNo CUDA acceleration. Compiled from source.\r\n\r\ncommit hash: \r\n`4ac9c09d5ca57a03b8daa5fb9e295947b1619854`\r\n\r\nbazel version:\r\n```\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```\r\n\r\n### Example\r\n\r\nI restored a graph from a checkpoint and get the variables. Then I tried to write the summary to the log but got an error.\r\n\r\n```\r\nsess = tf.Session()\r\nsaver = tf.train.import_meta_graph('my-model.meta')\r\nsaver.restore(sess, tf.train.latest_checkpoint('./'))\r\nall_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\nwriter = tf.summary.FileWriter('./many/log',sess.graph)\r\nwriter.add_summary(tf.summary.tensor_summary(\"conv\", all_vars[0]))\r\n```\r\n\r\n```\r\n>>> writer.add_summary(tf.summary.tensor_summary('conv',all_vars[0]))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/summary/writer/writer.py\", line 107, in add_summary\r\n    event = event_pb2.Event(summary=summary)\r\nTypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.Summary got Tensor.\r\n```\r\n### Official API Description\r\n\r\nAccording to the official API (https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter), \r\n\r\n`tf.summary.tensor_summary` \r\n\r\n> Returns:\r\nA scalar Tensor of type string. The serialized Summary protocol buffer.\r\n\r\n `add_summary(summary, global_step=None)`\r\n\r\n> You can pass the result of evaluating any summary op, using tf.Session.run or tf.Tensor.eval, to this function. Alternatively, you can pass a tf.Summary protocol buffer that you populate with your own data. The latter is commonly done to report evaluation results in event files.\r\n\r\nSo I believe this is a bug.", "comments": ["Also https://github.com/tensorflow/models/issues/764", "Sorry I realized this issue is not about the functions but my understanding of tensorflow. In order to manipulate I have to have the graph run by a session.", "@KaraRyougi can you please provide your solution since I'm stuck on the same problem :(", "@KaraRyougi @IdoHakimi - were you able to resolve this problem ?"]}, {"number": 7903, "title": "Deleted unused private field.", "body": "", "comments": ["Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 7902, "title": "Periodically evaluating on a validation set", "body": "A common training pattern is to run an epoch, or a few epochs, of training and then evaluate on a development set. As far as I can tell, there does not seem to be an easy way to do this while also using the TFRecords format. While it is possible to run through a data split by setting the num_epochs parameter in the functions to read in single examples, doing so would require the computation graph to be rebuilt before every validation phase. Instead, it would be preferable to have a symbolic example that could be reset to the beginning of the dataset using a related operation.\r\n\r\nI feel that the above pattern is sufficiently widely used to make a new feature worthwhile. Further, having control over the number of epochs also becomes important when trying to replicate the performance numbers of other implementations.\r\n\r\n####\r\nThe same training-validation pattern using feed dicts:\r\nfor epoch in num_epochs:\r\n  for batch in get_batches(train, epoch):\r\n    sess.run(train_op, feed_dict={\"batch\": batch)\r\n  num_correct, total = 0, 0\r\n  for batch in get_batches(val, epoch):\r\n    acc = sess.run(acc_op, feed_dict={\"batch\", batch)\r\n    total += batch.shape[0]\r\n    num_correct += batch.shape[0] * acc\r\n  print \"Dev accuracy after %s epochs: %s\" % (epoch + 1, num_correct / total)", "comments": ["Have you looked at [Validation Monitors](https://www.tensorflow.org/get_started/monitors#configuring_a_validationmonitor_for_streaming_evaluation)? I have not tried to use this yet. I'm not sure how much it will require you to rework your code to fit the tf.learn format. My understand is that the validation monitor would take an input function. That input function would provide data via whatever method you want to use, including reading TFRecord examples.", "Thanks for the suggestion. However, I don't think switching to tf.learn would really solve the issue. The hooks allow you to run a validation phase after a certain number of steps, which I can do well enough in my own code, but still rely on underlying queues to determine when the data is over. As a result, the limitation in the io utilities applies equally to them. (i.e. the lack of a method to read an epoch of data multiple times without rebuilding the graph).", "@varunkumar3618 In my understanding, if you use queues as the input source, it's kind of \"built in\" to the computation graph. So I would like to use a `tf.cond` which read a boolean and determine which function to be used. Then, you can change the value of the boolean on the go.", "That makes sense, I'll try it out.", "@varunkumar3618 \r\n\r\nPlease check out #7951 , which acknowledges the deficiency here and proposes an enhancement moving forwards.  Please add any use-cases onto that issue, so we can collect them in one place!\r\n\r\nSince I believe this issue was intended as a feature request, I'm closing it out so that we can focus on the other one.  If I've made a mistake in this regard, feel free to ping this issue and I'll re-open it.  Thanks!", "Yes, thank you. That's exactly what I was requesting.", "have you found any adhoc way to solve this problem? If you have, please let me know. thx!", "The new tf.data API should suit your needs. https://www.tensorflow.org/api_docs/python/tf/data"]}, {"number": 7901, "title": "Catch PermissionError to raise RuntimeError", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Jenkins, test this please."]}, {"number": 7900, "title": "Segmenttation fault tensorflow 1.0 osx", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/issues/3263\r\nhttps://github.com/tensorflow/tensorflow/issues/2278\r\n\r\nNote, I already set the link to \r\n`sudo ln -s /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib`\r\n\r\n### Environment info\r\nOperating System:\r\nosx 10.12.3\r\n\r\nInstalled version of CUDA and cuDNN:  8.0.63 / 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\nlrwxr-xr-x  1 root  wheel     33 26 Feb 15:35 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib\r\n-rwxr-xr-x  1 root  wheel  13504 24 Jan 20:58 /usr/local/cuda/lib/libcuda.dylib\r\nlrwxr-xr-x  1 root  wheel     45 12 Jan 02:33 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a\r\nlrwxr-xr-x  1 root  wheel     50 12 Jan 02:33 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib\r\nlrwxr-xr-x  1 root  wheel     46 12 Jan 02:33 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib\r\nlrwxr-xr-x  1 root  wheel     49 12 Jan 02:33 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nstart python shell\r\nimport tensorflow\r\n\r\noutput is\r\n```\r\nPython 3.6.0 |Anaconda custom (x86_64)| (default, Dec 23 2016, 13:19:00)\r\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.8.0.dylib locally\r\nSegmentation fault: 11\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nsetting the link as outlined above in the linked issues\r\n\r\nChecking the CUDA sample projects works fine so the library seems to be installed correctly.", "comments": ["after libcublas, AFAICR libcudnn is loaded.\r\nAre you sure you have cudnn installed?", "Yes. Copied into both include and lib directory\ngunan <notifications@github.com> schrieb am Mo. 27. Feb. 2017 um 12:15:\n\n> after libcublas, AFAICR libcudnn is loaded.\n> Are you sure you have cudnn installed?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7900#issuecomment-282692798>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABnc9MoIpPHZFy7hV6yS62FUORdkY_DYks5rgrAygaJpZM4MMbIm>\n> .\n>\n", "Which lib directory?\r\nyour cuda lib directory contents do not list libcudnn.", "@gunan indeed. you were correct. I messed up some paths. Thank you.", "Hey @geoHeil , could you show me what paths you've got? I'm getting the exact same error as you, but I also have cudnn downloaded and installed. \r\n\r\n`$ ls -l /usr/local/cuda/lib/`\r\n`admin        33 Mar  3 17:36 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib`\r\n`wheel     13504 Jan 11 20:31 /usr/local/cuda/lib/libcuda.dylib`\r\n`wheel        45 Jan 11 20:33 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a`\r\n`wheel        50 Jan 11 20:33 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib`\r\n`wheel        46 Jan 11 20:33 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib`\r\n`wheel        49 Jan 11 20:33 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a`\r\n`admin        36 Mar  3 17:37 /usr/local/cuda/lib/libcudnn.5 -> /usr/local/cuda/lib/libcudnn.5.dylib`\r\n`admin  76280680 Feb 24 16:32 /usr/local/cuda/lib/libcudnn.5.dylib`\r\n`admin  76280680 Feb 24 16:32 /usr/local/cuda/lib/libcudnn.dylib`\r\n`admin  64702864 Feb 24 16:32 /usr/local/cuda/lib/libcudnn_static.a`\r\n\r\n\r\n", "What is your os? On a first glance that looks rather fine but you can look\nat https://github.com/geoHeil/dev-env/blob/master/osx-setup.sh\nsbatir <notifications@github.com> schrieb am Mi. 29. M\u00e4rz 2017 um 18:12:\n\n> Hey @geoHeil <https://github.com/geoHeil> , could you show me what paths\n> you've got? I'm getting the exact same error as you, but I also have cudnn\n> downloaded and installed.\n> dyn-160-39-142-202:lib sbatir$ ls -l /usr/local/cuda/lib/libcud*\n> lrwxr-xr-x 1 sbatir admin 33 Mar 3 17:36\n> /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib\n> -rwxr-xr-x 1 sbatir wheel 13504 Jan 11 20:31\n> /usr/local/cuda/lib/libcuda.dylib lrwxr-xr-x 1 sbatir wheel 45 Jan 11 20:33\n> /usr/local/cuda/lib/libcudadevrt.a ->\n> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a lrwxr-xr-x 1 sbatir wheel 50\n> Jan 11 20:33 /usr/local/cuda/lib/libcudart.8.0.dylib ->\n> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib lrwxr-xr-x 1 sbatir\n> wheel 46 Jan 11 20:33 /usr/local/cuda/lib/libcudart.dylib ->\n> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib lrwxr-xr-x 1 sbatir wheel 49\n> Jan 11 20:33 /usr/local/cuda/lib/libcudart_static.a ->\n> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a lrwxr-xr-x 1 sbatir admin\n> 36 Mar 3 17:37 /usr/local/cuda/lib/libcudnn.5 ->\n> /usr/local/cuda/lib/libcudnn.5.dylib -rwxr-xr-x@ 1 sbatir admin 76280680\n> Feb 24 16:32 /usr/local/cuda/lib/libcudnn.5.dylib -rwxr-xr-x@ 1 sbatir\n> admin 76280680 Feb 24 16:32 /usr/local/cuda/lib/libcudnn.dylib -rw-r--r--@\n> 1 sbatir admin 64702864 Feb 24 16:32 /usr/local/cuda/lib/libcudnn_static.a\n>\n> \u2014\n> You are receiving this because you were mentioned.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7900#issuecomment-290139398>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABnc9PizTPHRid_U8enOzFbkCm7heia3ks5rqoLGgaJpZM4MMbIm>\n> .\n>\n"]}, {"number": 7898, "title": "when i use tf.train.SyncReplicasOptimizer ,find worker1 run step 150,but worker0 run step 120,is right??", "body": "when i use tf.train.SyncReplicasOptimizer ,find worker1 run step 150,but worker0 run step 120,is right??\r\n\r\nopt = tf.SyncReplicasOptimizer(opt, replicas_to_aggregate=number_workers,\r\n                               total_num_replicas=number_workers)\r\n\r\nis it right??,find worker1 run step 150,but worker0 run step 120,is right??\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7897, "title": "Missing input file zipaling or aapt while building android example", "body": "### Environment info\r\nOperating System: Windows 10 Pro\r\n\r\nIf installed from source, provide \r\nThe output of `bazel version`:\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:18 2017 (1485975258)\r\nBuild timestamp: 1485975258\r\nBuild timestamp as int: 1485975258\r\n\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nIt throw 'missing input file zipaling' or 'missing input file aapt'.\r\n\r\n`ERROR: missing input file '@androidsdk//:build-tools/25.0.2/zipalign'.\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1: declared output 'external/androidsdk/zipalign_runner.sh' was not created by genrule. This is probably because the genrule actually didn't create this output, or because the output was a directory and the genrule was run remotely (note that only the contents of declared file outputs are copied from genrules run remotely).\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1: not all outputs were created or valid.\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1: @androidsdk//:zipalign_binary: missing input file '@androidsdk//:build-tools/25.0.2/zipalign'.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1 1 input file(s) do not exist.\r\n`\r\n\r\n`ERROR: missing input file '@androidsdk//:build-tools/25.0.2/aapt'.\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1: @androidsdk//:aapt_binary: missing input file '@androidsdk//:build-tools/25.0.2/aapt'.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: C:/tools/msys64/tmp/_bazel_Kornel/i4o1VGAg/external/androidsdk/BUILD.bazel:5:1 1 input file(s) do not exist.\r\n`\r\n\r\n### What other attempted solutions have you tried?\r\nI tried chaning sdk versions to lower.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n[http://pastebin.com/6HQ4cVMS](url) - Pastebin zipaling log\r\n[http://pastebin.com/VJrmxLSv](url) - Pastebin aapt log\r\n\r\n[http://pastebin.com/mqCyPBhp](url) - Pastebin WORKSPACE file", "comments": ["Bazel doesn't support Android on Windows yet; see #6385 for more details and alternatives."]}, {"number": 7896, "title": "Issue with while_loop in tf.scan", "body": "Hello,\r\n\r\nI have recently updated to the newest version of tensorflow (v1.0) and am suddenly having some trouble when I use tf.scan.\r\n\r\nI have already tried setting shapes for all of the variables. Which didn't work! Don't really know what else i could do since that is the solution that is recommended for the error in tf.while_loop...\r\n\r\nHere is the code snippet:\r\n\r\n`\r\nh, z = tf.scan(\r\n                    self.sample,\r\n                    x,\r\n                    initializer = [ h0, tf.expand_dims(z0, 1 )]\r\n                    )\r\n`\r\n\r\nWhere h0 is [256, 90], z0 is expanded to [256, 1] and x is [None, 256, 400]. It worked in the previous version so I am assuming the trouble is related to the tf.scan code.\r\n\r\n\r\nValueError: The shape for scan/while/Merge_2:0 is not an invariant for the loop. It enters the loop with shape (256, 1), but has shape (256,) after one iteration. Provide shape invariants using either the `shape_invariants` argument of tf.while_loop or set_shape() on the loop variables.\r\n", "comments": ["I have fixed my problem by adding an additional expand_dims and an additional squeeze at the end. However I find it curious that it still produced this error in the new version, whereas it didn't in the previous one.", "@yuanbyu, any ideas?\r\n", "I am facing the exact same error. Relevant code below:\r\n\r\n```\r\ndef _mem_read(self, e):\r\n        # e : B x R x C, self.memory : B x N x R x Dr\r\n        N = tf.shape(self.memory)[1] # length of the sequence + 1\r\n        eshuf = tf.transpose(e, perm=(2,0,1)) # C x B x R\r\n        e1hot = tf.one_hot(eshuf, N, axis=2) # C x B x N x R\r\n\r\n        # accumulate across C\r\n        def _accum(acc, x):\r\n            # x : B x N x R\r\n            # acc : B x N x R x Dr\r\n            return acc + tf.expand_dims(x, axis=3)*self.memory\r\n\r\n        out = tf.scan(_accum, e1hot,\r\n                initializer=tf.zeros((tf.shape(e)[0], N, self.num_relations, self.rdims),\r\n                    dtype=tf.float32)) # B x N x R x Dr\r\n        out = tf.reduce_sum(out, axis=1) # B x R x Dr\r\n        return out\r\n```\r\nThe error i receive is:\r\n\r\n> ValueError: The shape for scan/while/scan/while/Merge_1:0 is not an invariant for the loop. It enters the loop with shape (?, ?, 2, 2), but has shape \\<unknown\\> after one iteration. Provide shape invariants using either the `shape_invariants` argument of tf.while_loop or set_shape() on the loop variables.\r\n\r\n@RiaanZoetmulder could you please elaborate exactly where you added the additional expand_dims and squeeze to resolve the error?\r\n\r\nThanks,\r\nBhuwan", "@bdhingra @RiaanZoetmulder I met the same question exactly as you described. Could you give me some advice about how to fix this problem?"]}, {"number": 7895, "title": "Running on Microsoft Server 2012 r2", "body": "Hello Everyone,\r\n\r\nJust tried installing on server 2012 and I get the following notifications:\r\n\r\n\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"')\r\n for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for\r\nunknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"')\r\nfor unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"'\r\n) for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') fo\r\nr unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"\r\n') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\n\r\n\r\nI assume this is due to the server using 2 processors. \r\nBtw i did uninstall and reinstalled the nightly build.", "comments": ["This is a duplicate of #7500 , which describes the problem and the fix."]}, {"number": 7894, "title": "Unable to use Tensorflow on Android Studio", "body": "I have opened the Android part into android studio from examples/contrib/Android and the project opened.\r\nAfter that I added the pre compiled jar file libandroid_tensorflow_inference_java from the nightly mode added it as module then added module dependency from the project structure .\r\nAfter that I get error on bazel location. I have also build bazel-0.40 at the following path def bazel_location = 'C:\\\\Users\\\\ANMOL\\\\Downloads\\\\bazel-0.4.0\\\\bazel-0.4.0\\\\output\\\\bazel.exe' and when I copy this path into Android Studio it doesnt seem to work .\r\nAny Ideas how to make it work\r\n![android studio bazel error](https://cloud.githubusercontent.com/assets/23556208/23337762/f6ce0df8-fc1d-11e6-89e4-291a5625ec23.jpg)\r\n", "comments": ["Bazel doesn't support Android on Windows yet; see #6385 for more details and alternatives."]}, {"number": 7893, "title": "Add MNIST dataset loader in Go binding", "body": "As well as python examples, MNIST dataset is good resource for tutorial and examples in Go API. \r\n\r\nIn addition to this, it might be better to write examples using MNIST like logistic regression or CNN but Go binding API (wrappers.go) looks so different from python API. Could you let me know if there is good resource to write MNIST example in Go?", "comments": ["Can one of the admins verify this patch?", "@Lewuathe : This a wonderful, though I'd suggest that you keep this example in your repository rather than putting it in the TensorFlow repository for now. \r\n\r\nRegarding construction of the CNN: `wrappers.go` provides only the low level TensorFlow ops, while Python has richer APIs in `tf.layers` (other other frameworks like Keras) for constructing models. To reproduce that in Go, for now, the choices would be to, either:\r\n\r\n- Construct the model in Python and then export/import into Go (which is what I did in this [word2vec example](https://github.com/asimshankar/go-tensorflow/tree/master/word2vec), OR\r\n- Follow the codepath for model construction in python to figure out the primitive TensorFlow ops being use and reconstruct with that (perhaps adding a \"layers\" like API for Go).\r\n\r\nHope that helps.\r\n", "@asimshankar Thanks for letting me know. \r\nJust one question. So the main purpose of Go binding is not training but embedding Tensorflow model into each respective applications? For example, we train model with Python API and export. Go binding is used in Go application to read and run the model. Is this assumption correct?\r\nTraining with Go API is not recommended in current status?", "Thanks for understanding, I'll close this pull request for now.\r\n\r\nTo answer your question: As of today, the Go API is well suited for importing and executing a trained model. It is also suited, but a little less so, for importing models constructed in Python and training them from within Go (e.g. the word2vec example I alluded to above) as it lacks the more convenient higher level APIs (like [Estimator](https://www.youtube.com/watch?v=t64ortpgS-E&index=6&list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv)) that are implemented in Python. A little work is needed to duplicate that convenience. For model construction, it is possible in Go since it implements the lowest level of graph construction, but this is where you're likely to miss the higher level constructs like [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers) and a little more work is needed to develop those.\r\n\r\nIf there are folks in the community who want to develop their own APIs on top of the primitives of this `tensorflow` package in Go, we encourage that."]}, {"number": 7892, "title": "how to aggregate gradients by weight", "body": "`tf.gradients` has a parameter` aggregation_method`. As default, it will sum up all the gradients. What should I do if I want to sum up all the gradients by weight? To be more specific, I want to apply a weight to each gradient, then sum them up. This weight may also comes from a tensorflow variable. I asked a question about this in stackoverflow and attached a minimal code snippet.\r\nhttp://stackoverflow.com/questions/42464742/how-to-weight-gradient-in-different-examples", "comments": ["Stack overflow is the correct place for that question."]}, {"number": 7891, "title": "Improve tensorboard smoothing", "body": "The smoothing of training loss in Tensorboard was frustrating; it would seemingly select a random set of unfiltered points near the end of the loss history leaving one unable to see the most recent trend.\r\n\r\nI see that at least one other person was annoyed at this, as a change has been committed to master that changes the behavior. I think the change in this PR is superior. The previous one appears to have just truncated the smoothed curve, whereas this one will smooth all the way up until the end. When I'm 400K training iterations in, I find myself really wanting to see how the trend has gone in those last 20K iterations.\r\n\r\nI also notice that the previous commit didn't update `dist/tf-tensorboard.html`, which I think is the only thing that affects most people running latest master.", "comments": ["Maybe not updating `tf-tensorboard.html` was a better idea. Should it be updated in sync with the .ts, or should I leave it unchanged?\r\n\r\n[Edit] BTW, I should point out I didn't machine-generate `tf-tensorboard.html` from `vz-line-chart.ts` using gulp. I tried following the instructions in the DEVELOPMENT.md file in the tensorboard directory, but ran into a problem with npm, which apparently hanged. So I just manually hacked the javascript changes directly into `tf-tensorboard.html`, and that worked. I _think_ they're equivalent. But I've never actually touched any js before. It looked kind of C-like, so I went with it. So if you are tempted to accept this PR, I trust that whoever you are at the GOOG will run gulp or whatever and check that this change actually works when the html file is generated from the assets. Or perhaps give me a pointer and I could have another go at it. Thanks.\r\n", "Can one of the admins verify this patch?", "And just to make things more concrete, here are images showing the different behaviors on the same wavenet training loss data.\r\n\r\nThe previous behavior with the \"noisy\" end section was like this:\r\n![p_old](https://cloud.githubusercontent.com/assets/2138320/23343680/48d9d818-fc35-11e6-9860-cb1bc90cc9e5.png)\r\n\r\nThe behavior currently in master (or what you would get in master if tf-tensorboard.html were updated) is this:\r\n![p_prev](https://cloud.githubusercontent.com/assets/2138320/23343695/5f9a3552-fc35-11e6-929d-d47c7a954954.png)\r\n\r\nIt does remove the noisy bit at the end, but leaves one unable to see the most recent trend.\r\n\r\nAnd the behavior with the change in this PR preserves the smoothed line all the way to the end:\r\n![p_thispr](https://cloud.githubusercontent.com/assets/2138320/23343701/7aacde80-fc35-11e6-9ddd-57a4da7233e3.png)\r\n\r\n", "@dandelionmane Can you check in on the changes? Thanks!", "Let's take #8363 instead.", "The new smoothing is nice. But we lost the ability of being able to peek at values in the non-smoothed region. It would be good to let the tooltip show up when mousing in that region (and perhaps show blank under the \"smoothed\" column)."]}, {"number": 7890, "title": "I can successfully open CUDA library cupti64_80.dll\uff0c but it stop on this step and can't forward. what should I do?  what's the problem? help", "body": "\r\n![image](https://cloud.githubusercontent.com/assets/16426261/23336757/11a08ce6-fc14-11e6-82da-97d77e20da5c.png)\r\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["The issues template above asks for information you haven't provided, such as the OS and CUDA installation.  It's difficult to guess what might be wrong without more information.", "I will close this issue in favor of other one. This issue has very little information, and your screenshot only shows some benign information messages."]}, {"number": 7889, "title": "Bug in code for new TF Layer tutorial \"A Guide to TF Layers: Building a Convolutional Neural Network\"", "body": "The code provided for the new TF Layer API tutorial (see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py) does not work if any filter size other than 5x5 is specified, or if color images are used. No matter what other filter size is specified, an error is generated indicating a shape mismatch between the specified filter (3x3 in the error message shown below) and another seemingly hard-coded 5x5 filter buried somewhere in the estimator. The tensor referred to below as \"rhs\" ALWAYS reports as [5,5,1,32] no matter what the actual filter size is set to within the python code OR if a color/3 channel image is used (e.g., lhs reports as 5x5x3x32 while rhs is 5x5x1x32).\r\n\r\nHere's a sample code snippet wherein the filter size is set to 3x3 instead of 5x5 for the first convolution layer:\r\n\r\n conv1 = tf.layers.conv2d(\r\n      inputs=input_layer,\r\n      filters=32,\r\n      kernel_size=[3, 3],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n\r\nand here's the error message:\r\n\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,1,32] rhs shape= [5,5,1,32]\r\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](conv2d/kernel, save/RestoreV2_2)]]\r\n\r\n\r\n\r\n\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nNone found - this seems to be a new problem related to the new TF Layer API\r\n\r\n### Environment info\r\nOperating System: Windows 10, Anaconda3, Python 3.5.2, TensorFlow 1.0\r\n\r\n", "comments": ["It is not a bug with `tf.layer`. Instead, I tried and got the same error after I first ran with the original code and then changed a bit. It loaded the old checkpoint and checked for its shape.", "The answer suggested by @inflation looks correct to me.\r\n\r\nClosing due to lack of activity.  Please reopen if necessary.", "@jtopor and @inflation \r\nI have same problem. I want to add one more layer, change kernel-size from 5x5 to 3x3 but It gives me same error. I just can change batch-size, learning-rate and dropout.\r\nCould you figure out how we can change parameters base on our data set? or just leave this code and work on other code? \r\nAny help would be greatly appreciate.   \r\n", "I faced the same problem too. The problem is once the model is created for first time, there is a copy of the structure stored in this location \"/tmp/mnist_convnet_model\". This is line where it gets created # #Create the Estimator\r\nmnist_classifier = learn.Estimator(\r\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\r\nDelete this folder and change the filter size and rerun your program. Hopefully this should solve it."]}, {"number": 7888, "title": "Added missing defines for AVX512 packets", "body": "", "comments": ["Jenkins, test this please.\n\nOn Feb 25, 2017 2:27 PM, \"Benoit Steiner\" <notifications@github.com> wrote:\n\n> @benoitsteiner <https://github.com/benoitsteiner> requested your review\n> on: tensorflow/tensorflow#7888\n> <https://github.com/tensorflow/tensorflow/pull/7888> Added missing\n> defines for AVX512 packets.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7888#event-977230701>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_Sbd_6RLMffEY0bOGNdRGk_WB11tWUks5rgKq1gaJpZM4MMKQk>\n> .\n>\n"]}, {"number": 7887, "title": "Anaconda's release is now 3.6 and it breaks the install", "body": "I am trying to install tensorflow on windows 10 Enterprise Edition.\r\nI followed the instructions to download Anaconda, but the web-site has been upgraded to Python 3.6. \r\nI tried to download a new whl from the nightly build but it does not work with the latest Anaconda release.  \r\nI get:\r\n\r\nC:\\>pip install --upgrade C:\\Temp\\tensorflow-1.0.0rc2-cp35-cp35m-win_amd64.whl\r\ntensorflow-1.0.0rc2-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\r\n\r\nAny plans to upgrade tensorflow to the latest version of Anaconda Python?\r\n\r\nCharles\r\n\r\n", "comments": ["It's a work in progress #6999. To use Python 3.6 currently only by building TensorFlow from source.", "@CBrauer It should be possible to use the latest Anaconda installer. I am using `Anaconda3-4.3.0.1-Windows-x86_64` on a Windows 10 machine.\r\n\r\nWhile it by default uses Python 3.6 as you pointed out, you can simply create a conda environment based on Python 3.5 and then install TensorFlow into it.\r\n\r\nThe only issue I ran into, is the one already opened #7873.\r\n\r\n", "Closing this issue to unify all python 3.6 discussion on #6999 "]}, {"number": 7886, "title": "How could I get the weights from the checkpoint file saved using tensorflow-slim?", "body": "I know that if I knew the variable names or graph I could restore the graph or the variables in the checkpoint files.\r\nBut if I don't know the actual variable names  like w1,w2,b1,b2...in conv1,conv2,.... \r\nHow could I get the variable values?\r\nFor example, I get the checkpoint file of alexnet in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/alexnet.py\r\nHow could I get the variable values in these checkpoint files?\r\n", "comments": ["If you use the new version of checkpoints, you can import the metagraph with variable collections. Check out `tf.train.import_meta_graph` and `tf.get_collection`.", "@inflation Actually I tried these before, the code is as below\r\n```\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n\r\nnew_saver = tf.train.import_meta_graph('/home/scw4750/Liuhongkun/tfrecord/zooscan/Alexnet/Modal/model20170226041552612/mymodel.meta')\r\n#print( tf.train.latest_checkpoint('./'))\r\nwhat=new_saver.restore(sess, '/home/scw4750/Liuhongkun/tfrecord/zooscan/Alexnet/Modal/model20170226041552612/mymodel')\r\n#print(what)\r\nall_vars = tf.get_collection('alexnet_v2')\r\nprint(all_vars)\r\nfor v in all_vars:\r\n    v_ = sess.run(v)\r\n    print(v_)\r\n```\r\nThe function tf.get_collection() at least has the key for the collection, I tried the scope name defined in alexnet.py , print(all_vars) shows nothing but [ ]. So I don't know how could I get the key.\r\n\r\n```\r\ntf.get_collection(key, scope=None) {#get_collection}\r\n\r\nWrapper for Graph.get_collection() using the default graph.\r\n\r\nSee Graph.get_collection() for more details.\r\nArgs:\r\n\r\n    key: The key for the collection. For example, the GraphKeys class contains many standard names for collections.\r\n    scope: (Optional.) If supplied, the resulting list is filtered to include only items whose name attribute matches using re.match. Items without a name attribute are never returned if a scope is supplied and the choice or re.match means that a scope without special tokens filters by prefix.\r\n\r\nReturns:\r\n\r\nThe list of values in the collection with the given name, or an empty list if no value has been added to that collection. The list contains the values in the order under which they were collected.\r\n```", "Well, `variable_scope` is not quite the same with `collection`. You can see the default collections from `tf.GraphKeys`. Any other collections are defined manually.", "@inflation It worked, I use \r\n`all_vars = tf.get_collection(ops.GraphKeys.GLOBAL_VARIABLES)`\r\nthen I could get the variables' value.\r\nThank you!"]}, {"number": 7885, "title": "Dockerfile version error", "body": "Version of TensorFlow was incorrectly updated in the Dockerfile\r\ntensorflow/blob/master/tensorflow/tools/docker/Dockerfile \r\n\r\n` http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl`\r\n\r\nIt should probably be the 1.0.0 release not the 0.0.0 release\r\n` http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl`", "comments": ["Please note that this invalid version string (0.0.0) is intentional. The Dockerfiles in tools/docker are not meant to be used for direct `docker build` calls. Instead, they are meant to be called from the script [tools/docker/parameterized_docker_build.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/parameterized_docker_build.sh). The doc string of the script contains use instructions.", "The Readme.md file says to use this command:\r\n\r\n$ docker build --pull -t $USER/tensorflow-suffix -f Dockerfile.suffix .", "@sveesible Good point. I'll make a note to update the README.md file. Re-opening this issue.", "@caisq What's the status here?", "Working on a PR. Sorry for the delay."]}, {"number": 7884, "title": "add links to nightly builds for Microsoft Windows", "body": "", "comments": ["Can one of the admins verify this patch?", "PR Merged. Thanks, @Franck-Dernoncourt !"]}, {"number": 7883, "title": "Changed inconsistent conv1d docs to use 'input' param instead of 'value'", "body": "Fixed inconsistency in documentation for conv1d.  Partial fix for issue #6379\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 7882, "title": "Update DetectorActivity.java", "body": "Set default detector in DetectorActivity.java back to MultiBox", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "@qzw331 be518926cd4bd5535a6b44c5542b605c5470e1a6 was committed to master back on Jan 11, I just hadn't deleted the andrewharp-patch-1 branch. I think we can close this, unless I'm missing something?"]}, {"number": 7881, "title": "Branch 148552367", "body": "", "comments": ["Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 7880, "title": "Peek operation for queues", "body": "Peeking queues would be a useful addition for multi threaded TensorFlow applications. Right now there is no way to look at the first element without affecting the queue. We could empty a `tf.FIFOQueue`, look at the first element, and enqueue all elements in order. But that is not safe when other threads operate on the queue at the same time (see locking mechanisms #6360).\r\n\r\nExample use case is an environment class in reinforcement learning, that buffers the next few time steps in a queue. The agent should be able to look at the current observation and reward at any time. Executing a step operation should remove the current time step so the next one becomes visible to the agent.", "comments": ["There was an internal discussion with @suharshs / @mrry about this (to mitigate the unexpected behavior of summary ops consuming training data). I'm hazy on details, maybe @mrry remembers, there were some design/implementation difficulties in supporting peek", "Do you think it's possible to build a workaround from existing TensorFlow operations?", "1. Work-around is possible by having all accesses to a queue go through buffer. Your would have a \"queue\" object which consists of tf.FIFOQueue and tf.Variable, and the top object of the \"queue\" is stored in the tf.Variable. You can then implement \"peek\" that returns value of the variable, then and \"dequeue\" which overwrites it with value from the FIFOQueue\r\n\r\n2. Native support could be useful since `.peek` is a common abstraction", "Thanks, I will use that. Similarly, having a `clear()` operation would be useful instead of checking for non emptiness and using `dequeue_up_to()` with the queue capacity.", "@yaroslavvb Actually, I implemented your idea of holding the first element in a variable. Unfortunately, it doesn't seem to work. The problem might be that, unlike the queue, the variable is not safe against concurrent access. Here is [an example gist](https://gist.github.com/danijar/fe98e758700865124b109bd1ee85f5aa).", "@danijar your gist is non-deterministic because different valid execution orders produce different reuslts. Consider following block\r\n\r\n```\r\n    dummy = tf.cond(tf.equal(self._size, 0), first, other)\r\n    with tf.control_dependencies([self._size.assign_add(1)]):\r\n      return tf.identity(dummy)\r\n```\r\n\r\nSince `dummy=tf.cond` is created outside of the `control_dependencies` block, `cond` can run either before or after `assign_add`. You can make it deterministic by moving it inside the block\r\n\r\n```\r\n    with tf.control_dependencies([self._size.assign_add(1)]):\r\n      dummy = tf.cond(tf.equal(self._size, 0), first, other)\r\n      return tf.identity(dummy)\r\n```", "possibly relevant -- https://github.com/tensorflow/tensorflow/issues/7951", "Thank you. However, then the condition changes. I'd either need to compare the size to 1 instead which makes the code confusing, or add a second `tf.control_dependencies()` around everything to ensure that `dummy` was gets executed before. In any way, it would be quite helpful to have an existing `.peek()` on queues.", "I will also greatly appreciate a peek() method on queues.", "Hi all,\r\nA peek operation on concurrent queues is inherently racy since there can be multiple consumers (one consumer peeks while the other consumer takes). It seems ill-advised to add a method to queues that only works in the single consumer case.\r\nAdditionally, peek may be defined differently (or add a lot of complexity) for non FIFO queues.\r\nIf you share your use cases, we may be able to try to find more workarounds.\r\nThanks!", "@suharshs The use case is reinforcement learning with the environment ticking a few time steps ahead of the agent to allow to parallelize the two. Both environment and agent fully live in graph and communicate via queues. The agent sends actions with a queue to the environment, which gets consumed by a queue runner that steps the environment. Moreover, the environment provides queues containing observations, rewards, and done flags that the agent should `peek()` at.", "@suharshs Do you have a solution for in-graph reinforcement learning?", "I do not, but this is definitely something that people are interested in and we plan to look into. I will close this issue though for now, and keep you posted on in-graph RL solutions"]}, {"number": 7879, "title": "Errory in summary writer tensorflow v1.0", "body": "I have the below error when trying to run my code\r\n\r\n**Error**\r\nTraceback (most recent call last):\r\n  File \"fer2013_train.py\", line 102, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"fer2013_train.py\", line 98, in main\r\n    train()\r\n  File \"fer2013_train.py\", line 64, in train\r\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\r\nAttributeError: module 'tensorflow.python.training.training' has no attribute 'SummaryWriter'\r\n\r\n**Code:**\r\n\r\n    # Build the summary operation based on the TF collection of Summaries.\r\n    summary_op = tf.summary.merge_all()\r\n\r\n    # Build an initialization operation to run below.\r\n    init = tf.global_variables_initializer()\r\n\r\n    # Start running operations on the Graph.\r\n    sess = tf.Session(config=tf.ConfigProto(\r\n        log_device_placement=FLAGS.log_device_placement))\r\n    sess.run(init)\r\n\r\n    # Start the queue runners.\r\n    tf.train.start_queue_runners(sess=sess)\r\n\r\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\r\n                                            graph_def=sess.graph_def)\r\n\r\n**tensorflow version**\r\n>>> tf.__version__\r\n'1.0.0'\r\n", "comments": ["This is because SummaryWriter is no longer exported into the train module, as it was deprecated, but now FileWriter uses the same interface (see [here](https://github.com/tensorflow/tensorflow/blob/34df7ee6f5a8f931d2433dc7e6e739bc880a35ea/tensorflow/python/training/summary_io.py#L31))\r\n\r\nUse tf.summary.FileWriter instead.", "Thanks it works :)", "Now it just says 'module 'tensorflow.train' has no attribute 'summary''\u2026\u2026\r\nWhat can I do?", "> Now it just says 'module 'tensorflow.train' has no attribute 'summary''\u2026\u2026\r\n> What can I do?\r\n\r\nProblem has been solved.Thanks.", "> Now it just says 'module 'tensorflow.train' has no attribute 'summary''\u2026\u2026\r\n> What can I do?\r\n\r\nsome problem how can i solve it \r\nAttributeError: 'MY_Model' object has no attribute 'summary'\r\n"]}, {"number": 7878, "title": "GAN", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": []}, {"number": 7877, "title": "Native Windows libraries for Java?", "body": "Looking at the java directory, the README only provides links for MacOS and Linux. Do we have to build from source for Windows or are those libraries provided somewhere else? Am I missing something?", "comments": ["Yes, for now you need to build from source, we haven't gotten around to packaging or testing on Windows yet. ", "@poxvoculi or @asimshankar - Is there an issue that can be watched to track the progress?", "No, there isn't. Reopening this one for tracking."]}, {"number": 7876, "title": "Import meta graph followed by save overwrites the previous checkpoints", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Ubuntu 14.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): using CPU version of tensorflow 1.0.0\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: pip install tensorflow\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. 1.0.0\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```python\r\nimport tensorflow as tf\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    initializer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5, seed=42, dtype=tf.float32)\r\n    var1 = tf.get_variable('var1', shape=(1,), dtype=tf.float32, initializer=initializer)\r\n    saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=20)\r\n    init_op = tf.global_variables_initializer()\r\n    graph.finalize()\r\n\r\nwith tf.Session(graph=graph) as sess:\r\n    sess.run(init_op)\r\n    saver.save(sess, 'sample_graph', global_step=0)\r\n\r\ngraph = tf.Graph()\r\nwith tf.Session(graph=graph) as sess:\r\n    saver = tf.train.import_meta_graph('sample_graph-0.meta')\r\n    saver.restore(sess, './sample_graph-0')\r\n    saver.save(sess, 'sample_graph', global_step=1)\r\n    print(saver.last_checkpoints) # lists only ['sample_graph-1'] does not preserve the previous checkpoint sample_graph-0\r\n```\r\nEssentially I am checkpointing a graph and then importing it. On trying to save the next checkpoint, the saver overwrites the previous checkpoint in the checkpoint file (the actual meta, index and data files are not overwritten) and only the last saved checkpoint is present in the `checkpoint` file. Is this the intended behavior? Is there any way to preserve the checkpoints across multiple saves of the graph.\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Thanks for a clear issue report.", "@sherrym is this intended? Is the checkpoint still there but the checkpoint list is cleared since it's a new saver/graph?", "Nagging Assignee @sherrym: It has been 273 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Is this still an issue ?\r\n@sherrym - Could you please look into this ?", "Reassigning to Allen, Sherry has left the team. \r\n\r\nI think what is happening is that the list of checkpoints is reset by import_meta_graph. The old checkpoints still exist on disk, but the index structure is overwritten by import_meta_graph.\r\n\r\nWe won't do any work on this before 2.0, and I'm concerned that we won't be able to really fix this since it would be a behavior change (and it's not clear that this is a bug -- import_meta_graph often does invalidate old checkpoints since you may add new variables). \r\n\r\nI will close this issue. This should be much less of a problem in 2.0.", "There is a `write_state` Boolean argument to `Saver.save`, so you can prevent it from updating the Checkpoint file. And there is also `Saver.set_last_checkpoints_with_time`, which you can use along with `tf.train.get_checkpoint_mtimes` so that the `Saver` writes a correct-ish Checkpoint file instead of just not overwriting.\r\n\r\nI do think the 2.x story will be better here. Still working out the details, but there should be a design review soon for importing SavedModels. I'll include an import-and-train workflow there."]}]