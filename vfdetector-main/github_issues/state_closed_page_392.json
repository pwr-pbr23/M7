[{"number": 42205, "title": "tf.nn.avg_pool3d crashes(floating point exception) when `input` contain large value and stride=0", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.nn.avg_pool3d` crashes(floating point exception) when `input` contain large value and `stride=0`. Related #42206\r\n\r\n**Describe the expected behavior**\r\n\r\nExpect no crashes\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ninput = tf.constant( [[[[[1e+40]]]]], dtype=np.float64)\r\ntf.nn.avg_pool3d(input=input,ksize=1,strides=0,padding='SAME')\r\n~~~\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nFloating point exception (core dumped)\r\n~~~\r\nRelated #42206", "comments": ["Check the [gist](https://colab.research.google.com/drive/1RP1JkN2nuGmLI1_dsAqZSrA8SajEzjhO?usp=sharing)", "@DNXie \r\nPlease provide access to the link shared.", "@Saduf2019  Done. And you can also reproduce it with the code I provided in the post.", "I am able to reproduce this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/64733016a242ed3e261b72b57e0f8347/untitled367.ipynb)", "This is fixed with latest tf-nightly. It requires that strides to pooling ops be non-zero and that its length match the tensor rank.\r\nSee the [gist](https://colab.research.google.com/gist/ymodak/b4c7e1bab69b573628740d3b244fecbc/untitled367.ipynb)\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42205\">No</a>\n"]}, {"number": 42203, "title": "tf.nn.space_to_depth and tf.nn.depth_to_space crashes (segfault) in `NCHW_VECT_C ` mode with certain input", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.nn.space_to_depth ` and `tf.nn.depth_to_space` crashes (segfault) in when `input` is of length EXACTLY 4, `block_size>1` and `data_format=NCHW_VECT_C`.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpect no segfault\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n~~~python\r\nimport tensorflow as tf\r\ntf.nn.space_to_depth(input=tf.zeros((4)), block_size = 2, data_format ='NCHW_VECT_C')\r\ntf.nn.depth_to_space(input=tf.zeros((4)), block_size = 2, data_format ='NCHW_VECT_C')\r\n~~~\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~", "comments": ["Was able to reproduce the issue with TF v2.1, TF v2.3 and TF-nightly. \r\n\r\nSession crashes on running the code, never reaches the print statement.  Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/473b0b7e56de406bdf4e5da95898c7c1/42203.ipynb). Thanks!\r\n", "I ran the code on nightly and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/5b068248c0aba40244fbaa1db5f56d2c/untitled499.ipynb)", "Those API only support NHWC today.\r\n- https://github.com/tensorflow/tensorflow/blob/8cc5a3a/tensorflow/core/kernels/spacetodepth_op.cc#L76\r\n- https://github.com/tensorflow/tensorflow/blob/8cc5a3a/tensorflow/core/kernels/depthtospace_op.cc#L61\r\n\r\nAdding contribution welcome tag.", "Was able to replicate the issue in TF 2.6.0-dev20210529,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/bca7a1f300d75a6d5acaed1fbce1b615/untitled97.ipynb#scrollTo=EKi5jI-ZQrnf)..Thanks !", "@DNXie Thanks for creating this issue. It was crashing with `TF2.3`. With recent `tf-nightly`, it doesn't crash anymore and throws an error as expected. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/60575c690ea58dd5f55092cf80b1fa0c/untitled499.ipynb) with `tf-nightly`. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42203\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42203\">No</a>\n"]}, {"number": 42202, "title": "Added support for noisy dense layer", "body": "Added support for noisy dense layers which are just dense layers with some random noise (decayed through gradient descent) added to the weights matrix to help with exploration in reinforcement learning environments.\r\n\r\nPaper on noisy nets: https://arxiv.org/pdf/1706.10295.pdf", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42202) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42202) for more info**.\n\n<!-- ok -->", "@pavithrasv Please let me know if there are any problems or if you have any questions. Thanks!", "Should we add this to TF add ons? https://github.com/tensorflow/addons/tree/master/tensorflow_addons/layers", "I just assumed that because this was so similar to the traditional dense layer and because it is very commonly used in RL that it should be added to TensorFlow, but if you think it would fit TF add ons better then I can submit a PR there.", "Yes, I think this will be a better fit for the addons repo. This layer is similar to having Dense + Dropout. What we recommend for new layers is that, they be added to the addons repo and if we see a lot of requests for the layer to be in the core APIs, we can move them to core.", "Ok then. I'll submit a PR to TF add ons.", "Thank you!"]}, {"number": 42201, "title": "Confusing error in gradient of assign_add + while_loop + gather", "body": "**Describe the current behavior**\r\nAutograph produces a static graph with the wrong number of inputs when a trainable variable is in a separate class. I also get a warning about converting a sparse op to a dense one, which seems to be related (while to gather, problem goes away when removed).\r\n\r\n**Describe the expected behavior**\r\nThe function should execute without errors.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1x36cCyKsSxsOCw1Z4mnR4AzbwDSuXzTY#scrollTo=O6GzPt2gZiPF", "comments": ["Turns out it was unrelated to the secondary class and the sparse to dense op warning, I've updated the colab accordingly", "Interestingly, the error actually seems to go away if you switch to gather_nd\r\n\r\nhttps://colab.research.google.com/drive/1Pa8g79qxnzlzf0oUM0cEtDoJrOUZSICd#scrollTo=cJDdoS6OR_Fc", "I am able to replicate this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/73b647d45206ec4167c0672b817a3b2d/untitled358.ipynb)", "It looks like certain inputs are indeed mismatched in the graph, but the error happens in the gradient ops. The error message about incorrect number of inputs looks like a red herring. Will update the bug title a bit.", "Actually, I think assign_add is unrelated, it seems to fail with any graph op that requires the variable, eg\r\nhttps://colab.research.google.com/drive/11MZorVrToy1bng_GfgmSWwum4z6kUvEL#scrollTo=wGyr_8aK0iv5", "I think [this commit](https://github.com/tensorflow/tensorflow/commit/2d1e9501e391c4588be68dabef039112b6643f2a) fixes the bug ([colab](https://colab.research.google.com/drive/19BMMQsnMc8sMZGEuXL7lGu0YyNWjUniz?usp=sharing#scrollTo=O6GzPt2gZiPF)), should I close the issue @mdanatg?", "Yep looks like the issue is resolved and can be closed. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42201\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42201\">No</a>\n"]}, {"number": 42200, "title": "GPUs idle between batches during multi-worker training with Keras ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7 (Core)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Tesla K40 11441MiB\r\n \r\n**Describe the current behavior**\r\nI have a setup of two workers in a cluster, and each worker has 4 GPUs. I have slightly changed the network in \"Mnist Multi-worker training with Keras\" tutorial to a deeper network. The training progress is way slower than just training on a single machine using tf.distribute.MirroredStrategy. Looking at GPU loads using nvidia-smi, I see that the GPUs are Idle for about 2 seconds before the load goes to 99%.  I also ran profiling on the workers between batch 10 and 11 using Tensorboard, and I can see that the majority of time is spent on colelctive_ops.\r\n\r\n**Describe the expected behavior**\r\nI was expecting 2X speed up on training with two workers(Total 8 GPUS) than training on a single machine(4 GPUs) using MirroredStrategy.\r\n\r\n**Standalone code to reproduce the issue**\r\n**Worker 1:** \r\n```\r\nfrom datetime import datetime\r\nfrom packaging import version\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport json\r\nimport tensorflow as  tf\r\n\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': [\"node72:12345\", \"node67:23456\"]\r\n    },\r\n    'task': {'type': 'worker', 'index': 0}\r\n})\r\n\r\n# Create a TensorBoard callback\r\nlogs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n\r\ntboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\r\n                                                 histogram_freq = 1,\r\n                                                 profile_batch = '10,11')\r\n\r\ndef mnist_dataset(batch_size):\r\n    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\r\n    # The `x` arrays are in uint8 and have values in the range [0, 255].\r\n    # We need to convert them to float32 with values in the range [0, 1]\r\n    x_train = x_train / np.float32(255)\r\n    y_train = y_train.astype(np.int64)\r\n    train_dataset = tf.data.Dataset.from_tensor_slices(\r\n      (x_train, y_train)).shuffle(60000).cache().repeat().batch(batch_size)\r\n    return train_dataset\r\n\r\n\r\ndef build_and_compile_cnn_model():\r\n    model = tf.keras.Sequential([\r\n      tf.keras.Input(shape=(28, 28)),\r\n      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\r\n      tf.keras.layers.Conv2D(256, 2, activation='relu'),\r\n      tf.keras.layers.Conv2D(128, 2, activation='relu'),\r\n      tf.keras.layers.Conv2D(32, 1, activation='relu'),  \r\n      tf.keras.layers.Conv2D(32, 2, activation='relu'),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(2048, activation='relu'),        \r\n      tf.keras.layers.Dense(1024, activation='relu'),        \r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dense(10)\r\n    ])\r\n    model.compile(\r\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n    return model\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\nnum_workers = 2\r\nper_worker_batch_size = 2048\r\n# Here the batch size scales up by number of workers since \r\n# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \r\n# and now this becomes 128.\r\nglobal_batch_size = per_worker_batch_size * num_workers\r\nmulti_worker_dataset = mnist_dataset(global_batch_size)\r\n\r\nwith strategy.scope():\r\n  # Model building/compiling need to be within `strategy.scope()`.\r\n  multi_worker_model = build_and_compile_cnn_model()\r\n\r\n# Keras' `model.fit()` trains the model with specified number of epochs and\r\n# number of steps per epoch. Note that the numbers here are for demonstration\r\n# purposes only and may not sufficiently produce a model with good quality.\r\nmulti_worker_model.fit(multi_worker_dataset, epochs=20, steps_per_epoch=20,callbacks = [tboard_callback])\r\n\r\n```\r\n\r\n\r\n**Worker 2:** \r\n\r\n```\r\nfrom datetime import datetime\r\nfrom packaging import version\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport json\r\nimport tensorflow as  tf\r\n\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': [\"node72:12345\", \"node67:23456\"]\r\n    },\r\n    'task': {'type': 'worker', 'index': 1}\r\n})\r\n\r\n# Create a TensorBoard callback\r\nlogs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n\r\ntboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\r\n                                                 histogram_freq = 1,\r\n                                                 profile_batch = '10,11')\r\n\r\ndef mnist_dataset(batch_size):\r\n    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\r\n    # The `x` arrays are in uint8 and have values in the range [0, 255].\r\n    # We need to convert them to float32 with values in the range [0, 1]\r\n    x_train = x_train / np.float32(255)\r\n    y_train = y_train.astype(np.int64)\r\n    train_dataset = tf.data.Dataset.from_tensor_slices(\r\n      (x_train, y_train)).shuffle(60000).cache().repeat().batch(batch_size)\r\n    return train_dataset\r\n\r\n\r\ndef build_and_compile_cnn_model():\r\n    model = tf.keras.Sequential([\r\n      tf.keras.Input(shape=(28, 28)),\r\n      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\r\n      tf.keras.layers.Conv2D(256, 2, activation='relu'),\r\n      tf.keras.layers.Conv2D(128, 2, activation='relu'),\r\n      tf.keras.layers.Conv2D(32, 1, activation='relu'),  \r\n      tf.keras.layers.Conv2D(32, 2, activation='relu'),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(2048, activation='relu'),        \r\n      tf.keras.layers.Dense(1024, activation='relu'),        \r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dense(10)\r\n    ])\r\n    model.compile(\r\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n    return model\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\nnum_workers = 2\r\nper_worker_batch_size = 2048\r\n# Here the batch size scales up by number of workers since \r\n# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \r\n# and now this becomes 128.\r\nglobal_batch_size = per_worker_batch_size * num_workers\r\nmulti_worker_dataset = mnist_dataset(global_batch_size)\r\n\r\nwith strategy.scope():\r\n  # Model building/compiling need to be within `strategy.scope()`.\r\n  multi_worker_model = build_and_compile_cnn_model()\r\n\r\n# Keras' `model.fit()` trains the model with specified number of epochs and\r\n# number of steps per epoch. Note that the numbers here are for demonstration\r\n# purposes only and may not sufficiently produce a model with good quality.\r\nmulti_worker_model.fit(multi_worker_dataset, epochs=20, steps_per_epoch=20,callbacks = [tboard_callback])\r\n\r\n\r\n```\r\n\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n<img width=\"987\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3833065/89832661-a9fa8400-db2d-11ea-848b-fa34ef9c26a6.png\">\r\n<img width=\"966\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3833065/89832872-01005900-db2e-11ea-984e-a4a264508080.png\">", "comments": ["Communicating over network has significant overhead compared to communicating within one host, so it won't be 2X. Being said, >1s collective time is long for this model, what's your network condition?\r\n\r\nCould you set communicaiton to NCCL when creating MultiWorkerMirroredStrategy. Maybe also run https://github.com/NVIDIA/nccl-tests to confirm to bandwidth", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42199, "title": "Cannot find libcudnn.so.7 ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 10.1/8.0.2.39\r\n- GPU model and memory: NVIDIA GeForce GTX 1050 Mobile\r\n\r\n**Describe the current behavior**\r\n\r\nI get the following error when I check my GPU with tensorflow:\r\n`W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory`\r\n\r\nI found this forum thread and it was suggest to create symlinks as follows:\r\nhttps://github.com/tensorflow/tensorflow/issues/20271\r\n`cd /usr/local/cuda-10.1/lib64\r\nsudo ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5 libcudnn.so.7\r\nsudo ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5 libcudnn.so`\r\n\r\nI tried this but I'm still getting an error. I should note that I linked `libcudnn.so.8` and `libcudnn.so.8.0.2` instead of 7.6.5. (7.6.5 and .so.7 were not included in my installation). Do I need to download libcudnn.so.7 separately?\r\n\r\nAny advice is appreciated\r\n\r\n\r\n**Describe the expected behavior**\r\nI assume that this error should not appear. \r\n\r\n**Standalone code to reproduce the issue**\r\nI get this issue after checking the status of my GPU with: `tf.config.list_physical_devices('GPU')` \r\n\r\n**Other info / logs** \r\nThis is the full message that I get when I check the status of my GPU:\r\n`2020-08-10 14:40:36.820491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-10 14:40:36.821735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\r\ncoreClock: 1.493GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-08-10 14:40:36.821834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-10 14:40:36.821900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-10 14:40:36.821953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-10 14:40:36.822004: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-10 14:40:36.822054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-10 14:40:36.822103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-10 14:40:36.822367: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n2020-08-10 14:40:36.822401: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...`\r\n\r\n\r\n**EDIT:** I'm not sure if this constitutes a \"bug\", happy to repost as a request for support if necessary.", "comments": ["@ajayp1,\r\nAs per the [tested build configurations](https://www.tensorflow.org/install/source#gpu), please try installing TensorFlow with CUDA v10.1 and cuDNN v7.6 and let us know if it resolves the issue. Thanks!", "This worked - thanks!"]}, {"number": 42198, "title": "How to load onnx model in Keras", "body": "Hello!\r\nKeras version: 2.4.3\r\nTensorflow version: 2.2.0\r\nPython version:  3.7.7\r\nOS: Windows 10 x64\r\n\r\nI want to load onnx model [(this yolov3 model)](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3) in keras.\r\nI download this model and run command to convert onnx to pb file, like this:\r\n**nnx-tf convert -i yolov3.onnx -o saved_model.pb**\r\nthis command was taken from [link](https://github.com/onnx/onnx-tensorflow)\r\nCommand finished with success!\r\nThen i try to load pb file like this:\r\n` from tensorflow import keras\r\n  model = keras.models.load_model('my path to folder with saved_model.pb file')`\r\n\r\nAnd result is error:\r\n **String field 'tensorflow.MetaGraphDef.MetaInfoDef.meta_graph_version' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes.**\r\n\r\nPlease help", "comments": ["@Aleksey1555 `keras.models.load_model` cannot be used to load *.pb file. I think this is more related to `onnx` repo. Can you please post your issue in [`onnx` repo here](https://github.com/onnx/onnx-tensorflow/issues).  Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42197, "title": "After updtae Anaconda, tf is not working", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["After update Anaconda with:\r\n conda update --all\r\n\r\ntf is not working.\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n I receive this message:\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed: No se puede encontrar el m\u00f3dulo especificado.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-2-8b76bb972d70> in <module>\r\n      1 # And the tf and keras framework, thanks to Google\r\n----> 2 import tensorflow as tf\r\n      3 from tensorflow import keras\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n     39 \r\n---> 40 from tensorflow.python.eager import context\r\n     41 \r\n     42 # pylint: enable=wildcard-import\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py in <module>\r\n     33 from tensorflow.core.protobuf import config_pb2\r\n     34 from tensorflow.core.protobuf import rewriter_config_pb2\r\n---> 35 from tensorflow.python import pywrap_tfe\r\n     36 from tensorflow.python import tf2\r\n     37 from tensorflow.python.client import pywrap_tf_session\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py in <module>\r\n     26 \r\n     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\r\n---> 28 from tensorflow.python import pywrap_tensorflow\r\n     29 from tensorflow.python._pywrap_tfe import *\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: No se puede encontrar el m\u00f3dulo especificado.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nI would appreciate your help to solve my issue.", "@Libardo1 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nDid you try with [tested build configuration](https://www.tensorflow.org/install/source_windows#gpu) from here and see if you are facing the issue.\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Please, refer similar issues #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nThis issue is more suitable on Continuum [Anaconda repo](https://github.com/ContinuumIO/anaconda-issues/issues) since its related to TF installation with Anaconda.\r\nPlease post it on [Continuum Anaconda.](https://github.com/ContinuumIO/anaconda-issues/issues)\r\nThanks!", "(base) PS C:\\Users\\Libardo> conda info\r\n\r\n     active environment : base\r\n    active env location : C:\\ProgramData\\Anaconda3\r\n            shell level : 1\r\n       user config file : C:\\Users\\Libardo\\.condarc\r\n populated config files : C:\\Users\\Libardo\\.condarc\r\n          conda version : 4.8.4\r\n    conda-build version : 3.19.2\r\n         python version : 3.7.8.final.0\r\n       virtual packages :\r\n       base environment : C:\\ProgramData\\Anaconda3  (writable)\r\n           channel URLs : https://conda.anaconda.org/conda-forge/win-64\r\n                          https://conda.anaconda.org/conda-forge/noarch\r\n                          https://conda.anaconda.org/anaconda-fusion/win-64\r\n                          https://conda.anaconda.org/anaconda-fusion/noarch\r\n                          https://repo.anaconda.com/pkgs/main/win-64\r\n                          https://repo.anaconda.com/pkgs/main/noarch\r\n                          https://repo.anaconda.com/pkgs/r/win-64\r\n                          https://repo.anaconda.com/pkgs/r/noarch\r\n                          https://repo.anaconda.com/pkgs/msys2/win-64\r\n                          https://repo.anaconda.com/pkgs/msys2/noarch\r\n          package cache : C:\\ProgramData\\Anaconda3\\pkgs\r\n                          C:\\Users\\Libardo\\.conda\\pkgs\r\n                          C:\\Users\\Libardo\\AppData\\Local\\conda\\conda\\pkgs\r\n       envs directories : C:\\ProgramData\\Anaconda3\\envs\r\n                          C:\\Users\\Libardo\\.conda\\envs\r\n                          C:\\Users\\Libardo\\AppData\\Local\\conda\\conda\\envs\r\n               platform : win-64\r\n             user-agent : conda/4.8.4 requests/2.24.0 CPython/3.7.8 Windows/10 Windows/10.0.19041\r\n          administrator : False\r\n             netrc file : None\r\n           offline mode : False", "(base) PS C:\\Users\\Libardo> conda list --show-channel-urls\r\n# packages in environment at C:\\ProgramData\\Anaconda3:\r\n#\r\n# Name                    Version                   Build  Channel\r\n_anaconda_depends         2019.03                  py37_0    anaconda\r\n_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0    defaults\r\n_tflow_select             2.1.0                       gpu    anaconda\r\nabseil-cpp                20200225.2           ha925a31_2    conda-forge\r\nabsl-py                   0.8.1                    pypi_0    pypi\r\naffine                    2.3.0                      py_0    conda-forge\r\nalabaster                 0.7.12                     py_0    conda-forge\r\nanaconda                  custom                   py37_1    defaults\r\nanaconda-client           1.7.2                      py_0    conda-forge\r\nanaconda-navigator        1.9.12                   py37_0    defaults\r\nanaconda-project          0.8.3                      py_0    conda-forge\r\nanalytics-python          1.2.9                    pypi_0    pypi\r\naniso8601                 8.0.0                    pypi_0    pypi\r\nappdirs                   1.4.3                    pypi_0    pypi\r\narchspec                  0.1.1              pyh9f0ad1d_0    conda-forge\r\narctic                    1.79.2                   pypi_0    pypi\r\nargh                      0.26.2          pyh9f0ad1d_1002    conda-forge\r\nargon2-cffi               20.1.0           py37h4ab8f01_1    conda-forge\r\narrow-cpp                 1.0.0           py37h1234567_1_cpu    conda-forge\r\narviz                     0.6.1                    pypi_0    pypi\r\nasn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge\r\nastor                     0.8.0                    pypi_0    pypi\r\nastroid                   2.4.2            py37hc8dfbb8_0    conda-forge\r\nastropy                   4.0.1.post1      py37h8055547_0    conda-forge\r\nastunparse                1.6.3                    pypi_0    pypi\r\natomicwrites              1.4.0              pyh9f0ad1d_0    conda-forge\r\nattrs                     19.3.0                     py_0    conda-forge\r\nautoimpute                0.11.6                   pypi_0    pypi\r\nautokeras                 1.0.2                    pypi_0    pypi\r\nautopep8                  1.5.4              pyh9f0ad1d_0    conda-forge\r\naws-sdk-cpp               1.7.164          vc14h84f8083_2    conda-forge\r\nbabel                     2.8.0                      py_0    conda-forge\r\nbackcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\nbackports                 1.0                        py_2    conda-forge\r\nbackports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\nbackports.os              0.1.1           py37hc8dfbb8_1002    conda-forge\r\nbackports.shutil_get_terminal_size 1.0.0                      py_3    conda-forge\r\nbamboolib                 0.1.1                    pypi_0    pypi\r\nbcrypt                    3.1.7            py37h8055547_1    conda-forge\r\nbeautifulsoup4            4.9.1            py37hc8dfbb8_0    conda-forge\r\nbert-for-tf2              0.13.5                   pypi_0    pypi\r\nbitarray                  1.4.2            py37h4ab8f01_0    conda-forge\r\nbkcharts                  0.2                      py37_0    defaults\r\nblas                      1.0                         mkl    defaults\r\nbleach                    3.1.5              pyh9f0ad1d_0    conda-forge\r\nblinker                   1.4                        py_1    conda-forge\r\nblosc                     1.20.0               ha925a31_0    conda-forge\r\nbokeh                     2.1.1            py37hc8dfbb8_0    conda-forge\r\nboost-cpp                 1.72.0               h89d28cc_2    conda-forge\r\nboto                      2.49.0                     py_0    conda-forge\r\nboto3                     1.10.34                  pypi_0    pypi\r\nbotocore                  1.13.34                  pypi_0    pypi\r\nbottleneck                1.3.2            py37hbc2f12b_1    conda-forge\r\nbranca                    0.3.1                      py_0    conda-forge\r\nbrotli                    1.0.7             ha925a31_1004    conda-forge\r\nbrotlipy                  0.7.0           py37h4ab8f01_1000    conda-forge\r\nbs4                       0.0.1                    pypi_0    pypi\r\nbzip2                     1.0.8                hfa6e2cd_2    conda-forge\r\nc-ares                    1.16.1               h62dcd97_0    conda-forge\r\nca-certificates           2020.6.24                     0    anaconda\r\ncachetools                4.1.1                      py_0    conda-forge\r\ncausalgraphicalmodels     0.0.4                    pypi_0    pypi\r\ncausalimpact              0.1.6                    pypi_0    pypi\r\ncausalinference           0.1.2                    pypi_0    pypi\r\ncertifi                   2020.6.20                py37_0    anaconda\r\ncffi                      1.14.1           py37h26f1ce3_0    conda-forge\r\ncfitsio                   3.470                hbbe6aef_6    conda-forge\r\ncftime                    1.0.4.2                  pypi_0    pypi\r\nchardet                   3.0.4           py37hc8dfbb8_1006    conda-forge\r\ncharls                    2.1.0                h33f27b4_2    conda-forge\r\nchart-studio              1.1.0              pyh9f0ad1d_0    conda-forge\r\nclick                     7.1.2              pyh9f0ad1d_0    conda-forge\r\nclick-plugins             1.1.1                      py_0    conda-forge\r\ncligj                     0.5.0                      py_0    conda-forge\r\ncloudpickle               1.5.0                      py_0    conda-forge\r\nclyent                    1.2.2                      py_1    conda-forge\r\ncmdstanpy                 0.4.0                    pypi_0    pypi\r\ncolorama                  0.4.3                      py_0    conda-forge\r\ncomtypes                  1.1.7           py37hc8dfbb8_1001    conda-forge\r\nconda                     4.8.4            py37hc8dfbb8_2    conda-forge\r\nconda-build               3.19.2           py37hc8dfbb8_3    conda-forge\r\nconda-env                 2.6.0                         1    conda-forge\r\nconda-package-handling    1.6.0            py37h702c6c1_2    conda-forge\r\nconda-verify              3.1.1           py37hc8dfbb8_1001    conda-forge\r\nconfound-prediction       0.0.1a1                  pypi_0    pypi\r\nconsole_shortcut          0.1.1                         4    defaults\r\ncontextlib2               0.6.0.post1                py_0    conda-forge\r\nconv                      0.2                      pypi_0    pypi\r\nconvertdate               2.2.1              pyh9f0ad1d_0    conda-forge\r\ncryptography              3.0              py37h26f1ce3_0    conda-forge\r\ncudatoolkit               10.1.243             h74a9793_0    defaults\r\ncudnn                     7.6.5                cuda10.1_0    anaconda\r\ncurl                      7.71.1               h4b64cdc_4    conda-forge\r\ncvxpy                     1.0.25                   pypi_0    pypi\r\ncycler                    0.10.0                     py_2    conda-forge\r\ncython                    0.29.21          py37h1834ac0_0    conda-forge\r\ncytoolz                   0.10.1           py37hfa6e2cd_0    conda-forge\r\ndask                      2.22.0                     py_0    conda-forge\r\ndask-core                 2.22.0                     py_0    conda-forge\r\ndatetime                  4.3                      pypi_0    pypi\r\ndecorator                 4.4.2                      py_0    conda-forge\r\ndefusedxml                0.6.0                      py_0    conda-forge\r\ndeprecation               2.0.7                    pypi_0    pypi\r\ndiff-match-patch          20200713           pyh9f0ad1d_0    conda-forge\r\ndill                      0.3.1.1                  pypi_0    pypi\r\ndistributed               2.22.0           py37hc8dfbb8_0    conda-forge\r\ndocutils                  0.16             py37hc8dfbb8_1    conda-forge\r\ndowhy                     0.1.1                    pypi_0    pypi\r\ndtale                     1.5.0                    pypi_0    pypi\r\neconml                    0.5                      pypi_0    pypi\r\necos                      2.0.7.post1              pypi_0    pypi\r\neikon                     1.0.1                    pypi_0    pypi\r\nentrypoints               0.3             py37hc8dfbb8_1001    conda-forge\r\nenum-compat               0.0.3                    pypi_0    pypi\r\nephem                     3.7.7.1          py37hfa6e2cd_0    conda-forge\r\net_xmlfile                1.0.1                   py_1001    conda-forge\r\nexpat                     2.2.9                he025d50_2    conda-forge\r\nfancyimpute               0.5.4                    pypi_0    pypi\r\nfastcache                 1.1.0            py37h8055547_1    conda-forge\r\nfbprophet                 0.6              py37h6538335_0    conda-forge\r\nfilelock                  3.0.12             pyh9f0ad1d_0    conda-forge\r\nfindspark                 1.3.0                      py_1    conda-forge\r\nfiona                     1.8.13           py37hef9e828_1    conda-forge\r\nflake8                    3.8.3                      py_1    conda-forge\r\nflask                     1.1.2              pyh9f0ad1d_0    conda-forge\r\nflask-compress            1.4.0                    pypi_0    pypi\r\nflask-restful             0.3.8                    pypi_0    pypi\r\nfreetype                  2.10.2               hd328e21_0    conda-forge\r\nfreexl                    1.0.5             hd288d7e_1002    conda-forge\r\nfsspec                    0.8.0                      py_0    conda-forge\r\nfuture                    0.18.2           py37hc8dfbb8_1    conda-forge\r\ngast                      0.3.3                    pypi_0    pypi\r\ngdal                      3.0.4            py37hd44be9e_7    conda-forge\r\ngeojson                   2.5.0                      py_0    conda-forge\r\ngeopandas                 0.8.1                      py_0    conda-forge\r\ngeos                      3.8.1                he025d50_0    conda-forge\r\ngeotiff                   1.5.1               h3d29ae3_10    conda-forge\r\nget_terminal_size         1.0.0                h38e98db_0    defaults\r\ngettext                   0.19.8.1          hb01d8f6_1002    conda-forge\r\ngevent                    20.6.2           py37h4ab8f01_0    conda-forge\r\ngflags                    2.2.2             ha925a31_1004    conda-forge\r\ngiflib                    5.2.1                h2fa13f4_2    conda-forge\r\nglib                      2.65.0               he4de6d7_0    conda-forge\r\nglob2                     0.7                        py_0    conda-forge\r\nglog                      0.4.0                h0174b99_3    conda-forge\r\ngmaps                     0.9.0                      py_0    conda-forge\r\ngoogle-auth               1.7.1                    pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.1                      py_2    conda-forge\r\ngoogle-pasta              0.1.8                    pypi_0    pypi\r\ngreenlet                  0.4.16           py37h4ab8f01_0    conda-forge\r\ngrpc-cpp                  1.30.1               h45b88af_1    conda-forge\r\ngrpcio                    1.25.0                   pypi_0    pypi\r\nh5py                      2.10.0          nompi_py37hde23a51_104    conda-forge\r\nhdf4                      4.2.13            hf8e6fe8_1003    conda-forge\r\nhdf5                      1.10.6          nompi_he0bbb20_101    conda-forge\r\nheapdict                  1.0.1                      py_0    conda-forge\r\nhiplot                    0.1.1                    pypi_0    pypi\r\nholidays                  0.10.3             pyh9f0ad1d_0    conda-forge\r\nhtml5lib                  1.1                pyh9f0ad1d_0    conda-forge\r\nhummingbird-ml            0.0.2                    pypi_0    pypi\r\nhupper                    1.10.2                     py_0    conda-forge\r\nhypothesis                5.24.0                     py_0    conda-forge\r\nicc_rt                    2019.0.0             h0cc432a_1    defaults\r\nicu                       64.2                 he025d50_1    conda-forge\r\nidna                      2.10               pyh9f0ad1d_0    conda-forge\r\nimagecodecs               2020.5.30        py37h92c78e3_2    conda-forge\r\nimageio                   2.9.0                      py_0    conda-forge\r\nimagesize                 1.2.0                      py_0    conda-forge\r\nimportlib-metadata        1.7.0            py37hc8dfbb8_0    conda-forge\r\nimportlib_metadata        1.7.0                         0    conda-forge\r\ninflection                0.4.0                    pypi_0    pypi\r\niniconfig                 1.0.1              pyh9f0ad1d_0    conda-forge\r\nintel-openmp              2019.4                      245    defaults\r\nintervaltree              3.0.2                      py_0    conda-forge\r\nipykernel                 5.3.4            py37h5ca1d4c_0    conda-forge\r\nipyleaflet                0.13.3             pyh9f0ad1d_0    conda-forge\r\nipython                   7.17.0           py37hc6149b9_0    conda-forge\r\nipython_genutils          0.2.0                      py_1    conda-forge\r\nipywidgets                7.5.1                      py_0    conda-forge\r\nisort                     4.3.21           py37hc8dfbb8_1    conda-forge\r\nitsdangerous              1.1.0                      py_0    conda-forge\r\njdcal                     1.4.1                      py_0    conda-forge\r\njedi                      0.15.2                   py37_0    conda-forge\r\njinja2                    2.11.2             pyh9f0ad1d_0    conda-forge\r\njmespath                  0.9.4                    pypi_0    pypi\r\njoblib                    0.16.0                     py_0    conda-forge\r\njpeg                      9d                   he774522_0    conda-forge\r\njson5                     0.9.4              pyh9f0ad1d_0    conda-forge\r\njsonschema                3.2.0            py37hc8dfbb8_1    conda-forge\r\njupyter                   1.0.0                      py_2    conda-forge\r\njupyter_client            6.1.6                      py_0    conda-forge\r\njupyter_console           6.1.0                      py_1    conda-forge\r\njupyter_core              4.6.3            py37hc8dfbb8_1    conda-forge\r\njupyterlab                2.2.4                      py_0    conda-forge\r\njupyterlab_server         1.2.0                      py_0    conda-forge\r\njxrlib                    1.1                  hfa6e2cd_2    conda-forge\r\nkealib                    1.4.13               h3b59ab9_1    conda-forge\r\nkeras                     2.3.1            py37h21ff451_0    conda-forge\r\nkeras-applications        1.0.8                      py_1    conda-forge\r\nkeras-preprocessing       1.1.2                    pypi_0    pypi\r\nkeras-tuner               1.0.1                    pypi_0    pypi\r\nkeyring                   21.3.0           py37hc8dfbb8_0    conda-forge\r\nkiwisolver                1.2.0            py37heaa310e_0    conda-forge\r\nkmeans1d                  0.2.0                    pypi_0    pypi\r\nknnimpute                 0.1.0                    pypi_0    pypi\r\nkorean_lunar_calendar     0.2.1              pyh9f0ad1d_0    conda-forge\r\nkrb5                      1.17.1               hc04afaa_2    conda-forge\r\nlazy-object-proxy         1.4.3            py37h8055547_2    conda-forge\r\nlcms2                     2.11                 he1115b7_0    conda-forge\r\nlerc                      2.2                  ha925a31_0    conda-forge\r\nlibaec                    1.0.4                he025d50_1    conda-forge\r\nlibarchive                3.3.3             h0c0e0cf_1008    conda-forge\r\nlibblas                   3.8.0                    14_mkl    conda-forge\r\nlibcblas                  3.8.0                    14_mkl    conda-forge\r\nlibclang                  9.0.1           default_hf44288c_0    conda-forge\r\nlibcurl                   7.71.1               h4b64cdc_4    conda-forge\r\nlibffi                    3.2.1             h6538335_1007    conda-forge\r\nlibgdal                   3.0.4                hf164de3_7    conda-forge\r\nlibgpuarray               0.7.6             hfa6e2cd_1003    conda-forge\r\nlibiconv                  1.15              hfa6e2cd_1006    conda-forge\r\nlibkml                    1.3.0             h7e985d0_1011    conda-forge\r\nliblapack                 3.8.0                    14_mkl    conda-forge\r\nliblief                   0.10.1               ha925a31_0    defaults\r\nlibnetcdf                 4.7.4           nompi_h256d12c_105    conda-forge\r\nlibpng                    1.6.37               hfe6a214_1    conda-forge\r\nlibpq                     12.3                 hd9aa61d_0    conda-forge\r\nlibprotobuf               3.12.4               h200bbdf_0    conda-forge\r\nlibpython                 2.0              py37hc8dfbb8_0    conda-forge\r\nlibsodium                 1.0.17               h2fa13f4_0    conda-forge\r\nlibspatialindex           1.9.3                he025d50_3    conda-forge\r\nlibspatialite             4.3.0a            h51df0ed_1038    conda-forge\r\nlibssh2                   1.9.0                hb06d900_5    conda-forge\r\nlibtiff                   4.1.0                h885aae3_6    conda-forge\r\nlibutf8proc               2.5.0                h9e6e254_2    conda-forge\r\nlibwebp-base              1.1.0                hfa6e2cd_3    conda-forge\r\nlibxml2                   2.9.10               h5d81f1c_2    conda-forge\r\nlibxslt                   1.1.33               h579f668_1    conda-forge\r\nlibzopfli                 1.0.3                ha925a31_0    conda-forge\r\nlightgbm                  2.3.1                    pypi_0    pypi\r\nllvm-meta                 9.0.1                         0    conda-forge\r\nllvmlite                  0.33.0           py37h8b575af_1    conda-forge\r\nlmu                       0.1                       dev_0    <develop>\r\nlocket                    0.2.0                      py_2    conda-forge\r\nlunarcalendar             0.0.9                      py_0    conda-forge\r\nlxml                      4.5.2            py37h8ba8a40_0    conda-forge\r\nlz4                       2.2.1                    pypi_0    pypi\r\nlz4-c                     1.9.2                h62dcd97_1    conda-forge\r\nlzo                       2.10              hfa6e2cd_1000    conda-forge\r\nm2-msys2-runtime          2.5.0.17080.65c939c               3    defaults\r\nm2-patch                  2.7.5                         2    defaults\r\nm2w64-binutils            2.25.1                        5    defaults\r\nm2w64-bzip2               1.0.6                         6    defaults\r\nm2w64-crt-git             5.0.0.4636.2595836               2    defaults\r\nm2w64-expat               2.1.1                         2    defaults\r\nm2w64-gcc                 5.3.0                         6    defaults\r\nm2w64-gcc-ada             5.3.0                         6    defaults\r\nm2w64-gcc-fortran         5.3.0                         6    defaults\r\nm2w64-gcc-libgfortran     5.3.0                         6    defaults\r\nm2w64-gcc-libs            5.3.0                         7    defaults\r\nm2w64-gcc-libs-core       5.3.0                         7    defaults\r\nm2w64-gcc-objc            5.3.0                         6    defaults\r\nm2w64-gettext             0.19.7                        2    defaults\r\nm2w64-gmp                 6.1.0                         2    defaults\r\nm2w64-headers-git         5.0.0.4636.c0ad18a               2    defaults\r\nm2w64-isl                 0.16.1                        2    defaults\r\nm2w64-libiconv            1.14                          6    defaults\r\nm2w64-libmangle-git       5.0.0.4509.2e5a9a2               2    defaults\r\nm2w64-libwinpthread-git   5.0.0.4634.697f757               2    defaults\r\nm2w64-make                4.1.2351.a80a8b8               2    defaults\r\nm2w64-mpc                 1.0.3                         3    defaults\r\nm2w64-mpfr                3.1.4                         4    defaults\r\nm2w64-pkg-config          0.29.1                        2    defaults\r\nm2w64-toolchain           5.3.0                         7    defaults\r\nm2w64-tools-git           5.0.0.4592.90b8472               2    defaults\r\nm2w64-windows-default-manifest 6.4                           3    defaults\r\nm2w64-winpthreads-git     5.0.0.4634.697f757               2    defaults\r\nm2w64-xz                  5.2.2                         2    defaults\r\nm2w64-zlib                1.2.8                        10    defaults\r\nmako                      1.1.3              pyh9f0ad1d_0    conda-forge\r\nmarkdown                  3.1.1                    pypi_0    pypi\r\nmarkupsafe                1.1.1            py37h8055547_1    conda-forge\r\nmatplotlib                3.3.0                         1    conda-forge\r\nmatplotlib-base           3.3.0            py37h35e8a6e_1    conda-forge\r\nmccabe                    0.6.1                      py_1    conda-forge\r\nmenuinst                  1.4.16                   py37_0    conda-forge\r\nmetaflow                  2.0.0                    pypi_0    pypi\r\nmissingno                 0.4.2                    pypi_0    pypi\r\nmistune                   0.8.4           py37h8055547_1001    conda-forge\r\nmkl                       2019.4                      245    defaults\r\nmkl-service               2.3.0            py37hfa6e2cd_0    conda-forge\r\nmkl_fft                   1.1.0            py37hc8d92b1_1    conda-forge\r\nmkl_random                1.1.0            py37he350917_0    conda-forge\r\nmlxtend                   0.17.2                   pypi_0    pypi\r\nmock                      4.0.2            py37hc8dfbb8_0    conda-forge\r\nmockextras                1.0.2                    pypi_0    pypi\r\nmore-itertools            8.4.0                      py_0    conda-forge\r\nmpmath                    1.1.0                      py_0    conda-forge\r\nmsgpack-python            1.0.0            py37heaa310e_1    conda-forge\r\nmsys2-conda-epoch         20160418                      1    defaults\r\nmultipledispatch          0.6.0                      py_0    conda-forge\r\nmultiprocess              0.70.9                   pypi_0    pypi\r\nmunch                     2.5.0                      py_0    conda-forge\r\nnavigator-updater         0.2.1                    py37_0    defaults\r\nnbconvert                 5.6.1            py37hc8dfbb8_1    conda-forge\r\nnbformat                  5.0.7                      py_0    conda-forge\r\nnengo                     2.8.0                    pypi_0    pypi\r\nnengo-gui                 0.4.6                    pypi_0    pypi\r\nnengolib                  0.5.2                    pypi_0    pypi\r\nnetworkx                  2.4                        py_1    conda-forge\r\nneuraxle                  0.3.4                    pypi_0    pypi\r\nninja                     1.10.0               h1ad3211_0    conda-forge\r\nnltk                      3.4.4                      py_0    conda-forge\r\nnose                      1.3.7           py37hc8dfbb8_1004    conda-forge\r\nnotebook                  6.1.1            py37hc8dfbb8_0    conda-forge\r\nnumba                     0.50.1           py37h3bbf574_1    conda-forge\r\nnumexpr                   2.7.1            py37h1834ac0_1    conda-forge\r\nnumpy                     1.18.1                   pypi_0    pypi\r\nnumpy-base                1.18.5           py37hc3f5095_0    defaults\r\nnumpydoc                  1.1.0              pyh9f0ad1d_0    conda-forge\r\noauthlib                  3.1.0                    pypi_0    pypi\r\nolefile                   0.46                       py_0    conda-forge\r\nonnx                      1.7.0                    pypi_0    pypi\r\nonnxconverter-common      1.7.0                    pypi_0    pypi\r\nopenjpeg                  2.3.1                h57dd2e7_3    conda-forge\r\nopenpyxl                  3.0.4                      py_0    conda-forge\r\nopenssl                   1.1.1g               he774522_0    anaconda\r\nopt-einsum                3.1.0                    pypi_0    pypi\r\nopt_einsum                3.3.0                      py_0    conda-forge\r\nosqp                      0.6.1                    pypi_0    pypi\r\npackaging                 20.4               pyh9f0ad1d_0    conda-forge\r\npandas                    1.1.0            py37h1834ac0_0    conda-forge\r\npandas-datareader         0.8.1                    pypi_0    pypi\r\npandoc                    2.10.1               he774522_0    conda-forge\r\npandocfilters             1.4.2                      py_1    conda-forge\r\nparamiko                  2.7.1              pyh9f0ad1d_1    conda-forge\r\nparams-flow               0.7.4                    pypi_0    pypi\r\nparquet-cpp               1.5.1                         2    conda-forge\r\nparso                     0.5.2                      py_0    defaults\r\npartd                     1.1.0                      py_0    conda-forge\r\npastedeploy               2.1.0              pyh9f0ad1d_0    conda-forge\r\npath                      15.0.0           py37hc8dfbb8_0    conda-forge\r\npath.py                   12.5.0                        0    conda-forge\r\npathlib2                  2.3.5            py37hc8dfbb8_1    conda-forge\r\npathtools                 0.1.2                      py_1    conda-forge\r\npatsy                     0.5.1                      py_0    conda-forge\r\npcre                      8.44                 h6538335_0    conda-forge\r\npep8                      1.7.1                      py_0    conda-forge\r\npexpect                   4.8.0            py37hc8dfbb8_1    conda-forge\r\nphased-lstm-keras         1.0.2                    pypi_0    pypi\r\npickleshare               0.7.5           py37hc8dfbb8_1001    conda-forge\r\npillow                    7.2.0            py37hc826c6e_1    conda-forge\r\npip                       20.0.2                   pypi_0    pypi\r\npkginfo                   1.5.0.1                    py_0    conda-forge\r\nplaster                   1.0                        py_0    conda-forge\r\nplaster_pastedeploy       0.7                        py_0    conda-forge\r\nplotly                    4.3.0                    pypi_0    pypi\r\npluggy                    0.13.1           py37hc8dfbb8_2    conda-forge\r\nply                       3.11                       py_1    conda-forge\r\npmdarima                  0.0.0                    pypi_0    pypi\r\npoppler                   0.67.0               h1707e21_8    conda-forge/label/cf202003\r\npoppler-data              0.4.9                         1    conda-forge\r\npostgresql                12.3                 he14cc48_0    conda-forge\r\npowershell_shortcut       0.0.1                         3    defaults\r\nppscore                   0.0.2                    pypi_0    pypi\r\nproj                      7.0.0                haa36216_5    conda-forge\r\nprometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge\r\nprompt-toolkit            3.0.6                      py_0    conda-forge\r\nprompt_toolkit            3.0.6                         0    conda-forge\r\nprotobuf                  3.10.0                   pypi_0    pypi\r\npsutil                    5.7.2            py37h4ab8f01_0    conda-forge\r\npy                        1.9.0              pyh9f0ad1d_0    conda-forge\r\npy-lief                   0.10.1           py37ha925a31_0    defaults\r\npy-params                 0.9.4                    pypi_0    pypi\r\npy4j                      0.10.9             pyh9f0ad1d_0    conda-forge\r\npyarrow                   1.0.0           py37h1234567_1_cpu    conda-forge\r\npyasn1                    0.4.8                      py_0    conda-forge\r\npyasn1-modules            0.2.7                    pypi_0    pypi\r\npycodestyle               2.6.0              pyh9f0ad1d_0    conda-forge\r\npycosat                   0.6.3           py37h8055547_1004    conda-forge\r\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\r\npycrypto                  2.6.1           py37h8055547_1004    conda-forge\r\npycurl                    7.43.0.5         py37h24bd3af_2    conda-forge\r\npydocstyle                5.0.2                      py_0    conda-forge\r\npydot                     1.4.1                    pypi_0    pypi\r\npyflakes                  2.2.0              pyh9f0ad1d_0    conda-forge\r\npygments                  2.6.1                      py_0    conda-forge\r\npygpu                     0.7.6           py37h44b1f71_1001    conda-forge\r\npyjwt                     1.7.1                      py_0    conda-forge\r\npylint                    2.5.3            py37hc8dfbb8_0    conda-forge\r\npylops                    1.9.0                    pypi_0    pypi\r\npymc3                     3.8                      pypi_0    pypi\r\npymeeus                   0.3.7              pyh9f0ad1d_0    conda-forge\r\npymongo                   3.9.0                    pypi_0    pypi\r\npymrio                    0.4.1                    pypi_0    pypi\r\npynacl                    1.3.0           py37h2fa13f4_1001    conda-forge\r\npyodbc                    4.0.30           py37h6538335_0    conda-forge\r\npyopenssl                 19.1.0                     py_1    conda-forge\r\npyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\npyproj                    2.6.1.post1      py37h1d8b288_0    conda-forge\r\npyqt                      5.12.3           py37h6538335_1    conda-forge\r\npyqt5-sip                 4.19.18                  pypi_0    pypi\r\npyqtwebengine             5.12.1                   pypi_0    pypi\r\npyramid                   1.10.1                     py_0    conda-forge\r\npyreadline                2.1                   py37_1001    conda-forge\r\npyrsistent                0.16.0           py37h8055547_0    conda-forge\r\npysocks                   1.7.1            py37hc8dfbb8_1    conda-forge\r\npyspark                   3.0.0                      py_0    conda-forge\r\npystan                    2.19.1.1                 pypi_0    pypi\r\npytables                  3.6.1            py37h2d87964_2    conda-forge\r\npytesseract               0.3.2                    pypi_0    pypi\r\npytest                    6.0.1            py37hc8dfbb8_0    conda-forge\r\npytest-arraydiff          0.3                        py_0    conda-forge\r\npytest-astropy            0.7.0                      py_0    conda-forge\r\npytest-astropy-header     0.1.2                      py_0    conda-forge\r\npytest-doctestplus        0.8.0                      py_0    conda-forge\r\npytest-openfiles          0.5.0                      py_0    conda-forge\r\npytest-remotedata         0.3.1                      py_0    conda-forge\r\npython                    3.7.8           h60c2a47_1_cpython    conda-forge\r\npython-dateutil           2.8.1                      py_0    conda-forge\r\npython-graphviz           0.13.2                   pypi_0    pypi\r\npython-jsonrpc-server     0.3.4              pyh9f0ad1d_1    conda-forge\r\npython-language-server    0.31.9           py37hc8dfbb8_0    conda-forge\r\npython-libarchive-c       2.9                      py37_0    conda-forge\r\npython_abi                3.7                     1_cp37m    conda-forge\r\npytorch                   1.4.0           py3.7_cuda101_cudnn7_0    pytorch\r\npytrends                  4.7.3                    pypi_0    pypi\r\npytz                      2020.1             pyh9f0ad1d_0    conda-forge\r\npywavelets                1.1.1            py37h44b1f71_1    conda-forge\r\npywin32                   227              py37hfa6e2cd_0    conda-forge\r\npywin32-ctypes            0.2.0           py37hc8dfbb8_1001    conda-forge\r\npywinpty                  0.5.7                    py37_0    conda-forge\r\npyyaml                    5.3.1            py37h8055547_0    conda-forge\r\npyzmq                     19.0.2           py37h453f00a_0    conda-forge\r\nqdarkstyle                2.8.1              pyh9f0ad1d_0    conda-forge\r\nqgrid                     1.1.1                    pypi_0    pypi\r\nqt                        5.12.5               h7ef1ec2_0    conda-forge\r\nqtawesome                 0.7.2              pyh9f0ad1d_0    conda-forge\r\nqtconsole                 4.7.5              pyh9f0ad1d_0    conda-forge\r\nqtpy                      1.9.0                      py_0    conda-forge\r\nquandl                    3.5.0                    pypi_0    pypi\r\nquantecon                 0.4.6                    pypi_0    pypi\r\nrasterio                  1.1.5            py37h02db82b_1    conda-forge\r\nre2                       2020.08.01           ha925a31_0    conda-forge\r\nrequests                  2.24.0             pyh9f0ad1d_0    conda-forge\r\nrequests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge\r\nretrying                  1.3.3                    pypi_0    pypi\r\nripgrep                   12.1.1               h301d43c_0    conda-forge\r\nrope                      0.17.0             pyh9f0ad1d_0    conda-forge\r\nrpy2                      2.9.5                    pypi_0    pypi\r\nrsa                       4.6                pyh9f0ad1d_0    conda-forge\r\nrtree                     0.9.4            py37h804a536_1    conda-forge\r\nruamel_yaml               0.15.80         py37h8055547_1001    conda-forge\r\ns3transfer                0.2.1                    pypi_0    pypi\r\nscikit-image              0.17.2           py37h3bbf574_1    conda-forge\r\nscikit-learn              0.23.2           py37hdc70db3_0    conda-forge\r\nscipy                     1.3.1                    pypi_0    pypi\r\nscs                       2.1.1-2                  pypi_0    pypi\r\nseaborn                   0.10.1                        1    conda-forge\r\nseaborn-base              0.10.1                     py_1    conda-forge\r\nselenium                  3.141.0                  pypi_0    pypi\r\nsend2trash                1.5.0                      py_0    conda-forge\r\nsetuptools                49.3.1           py37hc8dfbb8_0    conda-forge\r\nsetuptools-git            1.2                      pypi_0    pypi\r\nshapely                   1.7.0            py37he1cf020_3    conda-forge\r\nsimplegeneric             0.8.1                      py_1    conda-forge\r\nsingledispatch            3.4.0.3               py37_1000    conda-forge\r\nsip                       4.19.20          py37h6538335_0    conda-forge\r\nsix                       1.15.0             pyh9f0ad1d_0    conda-forge\r\nsklearn                   0.0                      pypi_0    pypi\r\nsklearn-contrib-py-earth  0.1.0+1.gdde5f89           dev_0    <develop>\r\nsnappy                    1.1.8                ha925a31_3    conda-forge\r\nsnowballstemmer           2.0.0                      py_0    conda-forge\r\nsnuggs                    1.4.7                      py_0    conda-forge\r\nsortedcollections         1.2.1              pyh9f0ad1d_0    conda-forge\r\nsortedcontainers          2.2.2              pyh9f0ad1d_0    conda-forge\r\nsoupsieve                 2.0.1            py37hc8dfbb8_0    conda-forge\r\nsparse                    0.8.0                    pypi_0    pypi\r\nsphinx                    3.2.0                      py_0    conda-forge\r\nsphinxcontrib             1.0                      py37_1    defaults\r\nsphinxcontrib-applehelp   1.0.2                      py_0    conda-forge\r\nsphinxcontrib-devhelp     1.0.2                      py_0    conda-forge\r\nsphinxcontrib-htmlhelp    1.0.3                      py_0    conda-forge\r\nsphinxcontrib-jsmath      1.0.1                      py_0    conda-forge\r\nsphinxcontrib-qthelp      1.0.3                      py_0    conda-forge\r\nsphinxcontrib-serializinghtml 1.1.4                      py_0    conda-forge\r\nsphinxcontrib-websupport  1.2.4              pyh9f0ad1d_0    conda-forge\r\nspyder                    4.1.2            py37hc8dfbb8_0    conda-forge\r\nspyder-kernels            1.9.3            py37hc8dfbb8_0    conda-forge\r\nsqlalchemy                1.3.18           py37h4ab8f01_0    conda-forge\r\nsqlite                    3.32.3               he774522_1    conda-forge\r\nstatsmodels               0.11.0                   pypi_0    pypi\r\nstocker                   0.1.5                    pypi_0    pypi\r\nsympy                     1.6.2            py37hc8dfbb8_0    conda-forge\r\ntabulate                  0.8.7                    pypi_0    pypi\r\ntb-nightly                1.14.0a20190603          pypi_0    pypi\r\ntbats                     1.0.9                    pypi_0    pypi\r\ntbb                       2020.1               he980bc4_0    conda-forge\r\ntblib                     1.6.0                      py_0    conda-forge\r\ntensorboard               2.0.2                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.7.0                    pypi_0    pypi\r\ntensorflow                2.3.0                    pypi_0    pypi\r\ntensorflow-addons         0.9.1                    pypi_0    pypi\r\ntensorflow-estimator      2.0.1                    pypi_0    pypi\r\ntensorflow-gpu            2.0.0                    pypi_0    pypi\r\ntensorflow-gpu-estimator  2.1.0                    pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nterminado                 0.8.3            py37hc8dfbb8_1    conda-forge\r\nterminaltables            3.1.0                    pypi_0    pypi\r\ntestpath                  0.4.4                      py_0    conda-forge\r\ntf-estimator-nightly      1.14.0.dev2019060501          pypi_0    pypi\r\ntheano                    1.0.4                    pypi_0    pypi\r\nthemis                    0.1.0                    pypi_0    pypi\r\nthreadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\nthrift-cpp                0.13.0               h1907cbf_2    conda-forge\r\ntifffile                  2020.7.24                  py_0    conda-forge\r\ntigramite                 4.1.0                    pypi_0    pypi\r\ntiledb                    1.7.7                h0b90766_3    conda-forge\r\ntk                        8.6.10               hfa6e2cd_0    conda-forge\r\ntoml                      0.10.1             pyh9f0ad1d_0    conda-forge\r\ntoolz                     0.10.0                     py_0    conda-forge\r\ntornado                   6.0.4            py37hfa6e2cd_0    conda-forge\r\ntqdm                      4.48.2             pyh9f0ad1d_0    conda-forge\r\ntraitlets                 4.3.3            py37hc8dfbb8_1    conda-forge\r\ntraittypes                0.2.1                      py_1    conda-forge\r\ntranslationstring         1.3                        py_0    conda-forge\r\ntyped-ast                 1.4.1            py37hfa6e2cd_0    conda-forge\r\ntypeguard                 2.7.1                    pypi_0    pypi\r\ntyping_extensions         3.7.4.2                    py_0    conda-forge\r\ntzlocal                   2.0.0                    pypi_0    pypi\r\nujson                     1.35            py37h63f7a3c_1002    conda-forge\r\nunicodecsv                0.14.1                     py_1    conda-forge\r\nurllib3                   1.25.10                    py_0    conda-forge\r\nvc                        14.1                 h869be7e_1    conda-forge\r\nvenusian                  3.0.0                      py_0    conda-forge\r\nvs2015_runtime            14.16.27012          h30e32a0_2    conda-forge\r\nvs2017_win-64             19.16.27038          h2e3bad8_2    conda-forge\r\nvswhere                   2.7.1                h21ff451_0    defaults\r\nwatchdog                  0.10.3           py37hc8dfbb8_1    conda-forge\r\nwcwidth                   0.2.5              pyh9f0ad1d_1    conda-forge\r\nweather                   1.4.0                      py_0    itk\r\nwebencodings              0.5.1                      py_1    conda-forge\r\nwebob                     1.8.6                      py_0    conda-forge\r\nwebsocket-client          0.56.0                   pypi_0    pypi\r\nwerkzeug                  0.16.1                     py_0    conda-forge\r\nwheel                     0.34.2                     py_1    conda-forge\r\nwidgetsnbextension        3.5.1            py37hc8dfbb8_1    conda-forge\r\nwin_inet_pton             1.1.0                    py37_0    conda-forge\r\nwin_unicode_console       0.5                   py37_1000    conda-forge\r\nwincertstore              0.2                   py37_1003    conda-forge\r\nwinpty                    0.4.3                         4    conda-forge\r\nwrapt                     1.11.2           py37h8055547_0    conda-forge\r\nxarray                    0.14.1                   pypi_0    pypi\r\nxerces-c                  3.2.2             h6538335_1004    conda-forge\r\nxgboost                   0.90                     pypi_0    pypi\r\nxlrd                      1.2.0              pyh9f0ad1d_1    conda-forge\r\nxlsxwriter                1.3.2              pyh9f0ad1d_0    conda-forge\r\nxlwings                   0.20.1           py37hc8dfbb8_0    conda-forge\r\nxlwt                      1.3.0                      py_1    conda-forge\r\nxmltodict                 0.12.0                     py_0    conda-forge\r\nxz                        5.2.5                h62dcd97_1    conda-forge\r\nyaml                      0.2.5                he774522_0    conda-forge\r\nyapf                      0.30.0             pyh9f0ad1d_0    conda-forge\r\nzeromq                    4.3.2                ha925a31_3    conda-forge\r\nzfp                       0.5.5                ha925a31_1    conda-forge\r\nzict                      2.0.0                      py_0    conda-forge\r\nzipp                      3.1.0                      py_0    conda-forge\r\nzlib                      1.2.11            h62dcd97_1007    conda-forge\r\nzope-interface            4.7.1                    pypi_0    pypi\r\nzope.deprecation          4.4.0                      py_0    conda-forge\r\nzope.event                4.4                pyh9f0ad1d_0    conda-forge\r\nzope.interface            5.1.0            py37h8055547_0    conda-forge\r\nzstd                      1.4.5                h1f3a1b7_2    conda-forge", "@Libardo1 \r\n\r\nSorry, but we don't provide support for issues with the conda environment.\r\nThis issue is more suitable on Continuum [Anaconda repo](https://github.com/ContinuumIO/anaconda-issues/issues) since its related to TF installation with Anaconda.\r\nPlease post the issue on [Continuum Anaconda.](https://github.com/ContinuumIO/anaconda-issues/issues).Thanks!", "OK, TIA", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42197\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42197\">No</a>\n"]}, {"number": 42196, "title": "[ROCm] Explicitly specifying dtype=np.float32 for *ExpandedBatch subtests in conv_ops_3d_test", "body": "The following commit adds the *ExpandedBatch subtests in the unit test `conv_ops_3d_test`\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/549e69ca1316cd6bc54cbbe28dd9340fdd7b8e76\r\n\r\nThose unit tests currently fail on the ROCm platform, because the dtype is not explicitly specified in the capp to `np.asarray` within the `_CreateNumpyTensor`. This defaults the datatype for the data/filter tensors to `double/float64` and ROCm does not have support for it, wich leads to those subtests failing.\r\n\r\nThis PR/commit adds an explicit `dtype=np.float32` argument to above mentioned call to `np.asarray`, thus making the data/filter tensors to be of `float32` type, which makes those subtests pass on the ROCm platform.\r\n\r\nChanging the dtype from `float64` to `float32` does change what the subtests are testing, so this change should be ok.\r\n\r\n----------------------\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": ["@gbaned gente ping.  this PR seems to have gotten stuck in the merge pipeline"]}, {"number": 42195, "title": "[TF:MLIR] Canonicalize ShapeNOp with partial static input shape", "body": "Canonicalize ShapeNOp by replacing corresponding output with static input shape.", "comments": ["/cc @smit-hinsu for visibility."]}, {"number": 42194, "title": "Added TF_ForwardInputOrAllocateOutput to Kernel C API ", "body": "Extended C API with OpKernel method. Also added tests to test input forwarding. \r\n\r\n@annarev @bmzhao ", "comments": []}, {"number": 42193, "title": "Keras RNNs do not respect get_initial_state if stateful=True", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nRNNs created with `stateful=True` always start with all-zero initial state, even if there is a `get_initial_state` function defined.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe state variables should be initialized with the values returned by `get_initial_state`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass TestCell(tf.keras.layers.Layer):\r\n    state_size = 1\r\n    output_size = 1\r\n\r\n    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n        return tf.ones((batch_size, 1), dtype=dtype)\r\n\r\n    def call(self, inputs, states):\r\n        tf.assert_equal(states, 1.0)\r\n        return inputs, states\r\n\r\n\r\nlayer = tf.keras.layers.RNN(TestCell(), stateful=True)\r\n\r\nx = np.ones((1, 10, 1), dtype=np.float32)\r\n\r\nlayer(x)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Condition x == y did not hold.\r\nFirst 1 elements of x:\r\n[0.]\r\nFirst 1 elements of y:\r\n[1.]\r\n```\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/9f76798b4dc0a8c77468dfe9ff58b31d/42193-tf-nightly.ipynb). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42193\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42193\">No</a>\n"]}, {"number": 42192, "title": "DLL load failed for Tensorflow-GPU==1.14, with CUDA 10.0", "body": "**System information**\r\nCUDA Version: 10.0\r\nCUDNN Version: 7\r\nOS: Windows 10\r\nPython version: 3.6\r\nGPU: Geforce mx150\r\n\r\nI cloned a github repository that requires tensorflow 1.13-1.14, so I just made a new virtual environment and installed tensorflow-gpu==1.14, which installed without any problems.\r\n\r\nThen I tried to run a session in order to see that things were working:\r\n\r\n```\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n\r\n```\r\nHowever, when I run the above, I get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\alyfl\\.virtualenvs\\trRosetta_gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\alyfl\\.virtualenvs\\trRosetta_gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\alyfl\\.virtualenvs\\trRosetta_gpu\\lib\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\alyfl\\.virtualenvs\\trRosetta_gpu\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 48, in <module>\r\n    from google.protobuf.pyext import _message\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\nImportError: DLL load failed: The specified procedure could not be found.\r\n```\r\nI just installed CUDA 10.0, since I realized that this old version of tensorflow would require that version (and restarted afterwards). I have confirmed that CUDA 10.0 is in my path environment, and that it seems to be the version linked in python as shown below:\r\n\r\n```\r\nfrom tensorflow.python.platform import build_info as tf_build_info\r\nprint(tf_build_info.cuda_version_number)\r\n>10.0\r\nprint(tf_build_info.cudnn_version_number)\r\n>7\r\n\r\n```\r\n\r\nI'm not really sure what exactly is going wrong here, and the error messages aren't much help either at this point", "comments": ["@tueboesen \r\nCan you please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/42186#issuecomment-671321222) for the cuda version and compatibility.\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nsimilar issues #21719 #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204 #40804\r\nThanks!\r\n", "> @tueboesen\r\n> Can you please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/42186#issuecomment-671321222) for the cuda version and compatibility.\r\n> \r\n> Please, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\n> similar issues #21719 #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204 #40804\r\n> Thanks!\r\n\r\nI have the right cuda version and compatibility, and my system is definitely 64 bit, including python. (I have managed to run tensorflow==1.4 just fine, so the problem seems to be with the gpu/cuda part of the setup. \r\nI have an intel core i7 cpu, which can run AVX instructions (see CPU info below).\r\nI haven't found anything else in there that suggests what my problem might be.\r\n\r\n```\r\nCoreinfo v3.5 - Dump information on system CPU and memory topology\r\nCopyright (C) 2008-2020 Mark Russinovich\r\nSysinternals - www.sysinternals.com\r\n\r\n\r\nIntel(R) Core(TM) i7-8550U CPU @ 1.80GHz\r\nIntel64 Family 6 Model 142 Stepping 10, GenuineIntel\r\nMicrocode signature: 00000096\r\nHTT             *       Hyperthreading enabled\r\nHYPERVISOR      -       Hypervisor is present\r\nVMX             *       Supports Intel hardware-assisted virtualization\r\nSVM             -       Supports AMD hardware-assisted virtualization\r\nX64             *       Supports 64-bit mode\r\n\r\nSMX             -       Supports Intel trusted execution\r\nSKINIT          -       Supports AMD SKINIT\r\n\r\nNX              *       Supports no-execute page protection\r\nSMEP            *       Supports Supervisor Mode Execution Prevention\r\nSMAP            *       Supports Supervisor Mode Access Prevention\r\nPAGE1GB         *       Supports 1 GB large pages\r\nPAE             *       Supports > 32-bit physical addresses\r\nPAT             *       Supports Page Attribute Table\r\nPSE             *       Supports 4 MB pages\r\nPSE36           *       Supports > 32-bit address 4 MB pages\r\nPGE             *       Supports global bit in page tables\r\nSS              *       Supports bus snooping for cache operations\r\nVME             *       Supports Virtual-8086 mode\r\nRDWRFSGSBASE    *       Supports direct GS/FS base access\r\n\r\nFPU             *       Implements i387 floating point instructions\r\nMMX             *       Supports MMX instruction set\r\nMMXEXT          -       Implements AMD MMX extensions\r\n3DNOW           -       Supports 3DNow! instructions\r\n3DNOWEXT        -       Supports 3DNow! extension instructions\r\nSSE             *       Supports Streaming SIMD Extensions\r\nSSE2            *       Supports Streaming SIMD Extensions 2\r\nSSE3            *       Supports Streaming SIMD Extensions 3\r\nSSSE3           *       Supports Supplemental SIMD Extensions 3\r\nSSE4a           -       Supports Streaming SIMDR Extensions 4a\r\nSSE4.1          *       Supports Streaming SIMD Extensions 4.1\r\nSSE4.2          *       Supports Streaming SIMD Extensions 4.2\r\n\r\nAES             *       Supports AES extensions\r\nAVX             *       Supports AVX instruction extensions\r\nFMA             *       Supports FMA extensions using YMM state\r\nMSR             *       Implements RDMSR/WRMSR instructions\r\nMTRR            *       Supports Memory Type Range Registers\r\nXSAVE           *       Supports XSAVE/XRSTOR instructions\r\nOSXSAVE         *       Supports XSETBV/XGETBV instructions\r\nRDRAND          *       Supports RDRAND instruction\r\nRDSEED          *       Supports RDSEED instruction\r\n\r\nCMOV            *       Supports CMOVcc instruction\r\nCLFSH           *       Supports CLFLUSH instruction\r\nCX8             *       Supports compare and exchange 8-byte instructions\r\nCX16            *       Supports CMPXCHG16B instruction\r\nBMI1            *       Supports bit manipulation extensions 1\r\nBMI2            *       Supports bit manipulation extensions 2\r\nADX             *       Supports ADCX/ADOX instructions\r\nDCA             -       Supports prefetch from memory-mapped device\r\nF16C            *       Supports half-precision instruction\r\nFXSR            *       Supports FXSAVE/FXSTOR instructions\r\nFFXSR           -       Supports optimized FXSAVE/FSRSTOR instruction\r\nMONITOR         *       Supports MONITOR and MWAIT instructions\r\nMOVBE           *       Supports MOVBE instruction\r\nERMSB           *       Supports Enhanced REP MOVSB/STOSB\r\nPCLMULDQ        *       Supports PCLMULDQ instruction\r\nPOPCNT          *       Supports POPCNT instruction\r\nLZCNT           *       Supports LZCNT instruction\r\nSEP             *       Supports fast system call instructions\r\nLAHF-SAHF       *       Supports LAHF/SAHF instructions in 64-bit mode\r\nHLE             -       Supports Hardware Lock Elision instructions\r\nRTM             -       Supports Restricted Transactional Memory instructions\r\n\r\nDE              *       Supports I/O breakpoints including CR4.DE\r\nDTES64          *       Can write history of 64-bit branch addresses\r\nDS              *       Implements memory-resident debug buffer\r\nDS-CPL          *       Supports Debug Store feature with CPL\r\nPCID            *       Supports PCIDs and settable CR4.PCIDE\r\nINVPCID         *       Supports INVPCID instruction\r\nPDCM            *       Supports Performance Capabilities MSR\r\nRDTSCP          *       Supports RDTSCP instruction\r\nTSC             *       Supports RDTSC instruction\r\nTSC-DEADLINE    *       Local APIC supports one-shot deadline timer\r\nTSC-INVARIANT   *       TSC runs at constant rate\r\nxTPR            *       Supports disabling task priority messages\r\n\r\nEIST            *       Supports Enhanced Intel Speedstep\r\nACPI            *       Implements MSR for power management\r\nTM              *       Implements thermal monitor circuitry\r\nTM2             *       Implements Thermal Monitor 2 control\r\nAPIC            *       Implements software-accessible local APIC\r\nx2APIC          *       Supports x2APIC\r\n\r\nCNXT-ID         -       L1 data cache mode adaptive or BIOS\r\n\r\nMCE             *       Supports Machine Check, INT18 and CR4.MCE\r\nMCA             *       Implements Machine Check Architecture\r\nPBE             *       Supports use of FERR#/PBE# pin\r\n\r\nPSN             -       Implements 96-bit processor serial number\r\n\r\nPREFETCHW       *       Supports PREFETCHW instruction\r\n\r\nMaximum implemented CPUID leaves: 00000016 (Basic), 80000008 (Extended).\r\nMaximum implemented address width: 48 bits (virtual), 39 bits (physical).\r\n\r\nProcessor signature: 000806EA\r\n\r\nLogical to Physical Processor Map:\r\n**------  Physical Processor 0 (Hyperthreaded)\r\n--**----  Physical Processor 1 (Hyperthreaded)\r\n----**--  Physical Processor 2 (Hyperthreaded)\r\n------**  Physical Processor 3 (Hyperthreaded)\r\n\r\nLogical Processor to Socket Map:\r\n********  Socket 0\r\n\r\nLogical Processor to NUMA Node Map:\r\n********  NUMA Node 0\r\n\r\nNo NUMA nodes.\r\n\r\nLogical Processor to Cache Map:\r\n**------  Data Cache          0, Level 1,   32 KB, Assoc   8, LineSize  64\r\n**------  Instruction Cache   0, Level 1,   32 KB, Assoc   8, LineSize  64\r\n**------  Unified Cache       0, Level 2,  256 KB, Assoc   4, LineSize  64\r\n********  Unified Cache       1, Level 3,    8 MB, Assoc  16, LineSize  64\r\n--**----  Data Cache          1, Level 1,   32 KB, Assoc   8, LineSize  64\r\n--**----  Instruction Cache   1, Level 1,   32 KB, Assoc   8, LineSize  64\r\n--**----  Unified Cache       2, Level 2,  256 KB, Assoc   4, LineSize  64\r\n----**--  Data Cache          2, Level 1,   32 KB, Assoc   8, LineSize  64\r\n----**--  Instruction Cache   2, Level 1,   32 KB, Assoc   8, LineSize  64\r\n----**--  Unified Cache       3, Level 2,  256 KB, Assoc   4, LineSize  64\r\n------**  Data Cache          3, Level 1,   32 KB, Assoc   8, LineSize  64\r\n------**  Instruction Cache   3, Level 1,   32 KB, Assoc   8, LineSize  64\r\n------**  Unified Cache       4, Level 2,  256 KB, Assoc   4, LineSize  64\r\n\r\n```\r\n\r\n", "@tueboesen Everything seems rights. Can you please share the commands you have used to install TF and GPU inside an environment. Thanks!", "> @tueboesen Everything seems rights. Can you please share the commands you have used to install TF and GPU inside an environment. Thanks!\r\n\r\nI just went through the process once again, on my desktop computer dedicated for deep learning, just to verify the problem and I ended up with the same issue there.\r\n\r\nI know this is a rather old version of tensorflow, and I wish I could just use a newer version but unfortunately, I need either version 1.13 or 1.14 in order to run the following code from a research article:\r\nhttps://github.com/gjoni/trRosetta\r\n\r\n\r\nMy process was the following:\r\n\r\n1. Install python 3.6.0 (python-3.6.0-amd64.exe)\r\n2. Spin up a new virtual environment with python 3.6.0 \r\n3. pip install tensorflow-gpu==1.14\r\n4. try to run: sess = tf.Session(), and get told that I'm missing a DLL, and to install CUDA 10.0\r\n5. Install CUDA 10.0 (cuda_10.0.130_411.31_win10.exe)\r\n6. try to run: sess = tf.Session(), and get told that I'm missing another DLL, related to cuDNN 7.\r\n7. Install cudnn 7 (download cudnn-10.0-windows10-x64-v7.6.5.32.zip, extract it, and move it to the CUDA 10.0 folder) \r\n8. try to run: sess = tf.Session(), and get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\Tue\\PycharmProjects\\trRosetta\\venv_36\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\Tue\\PycharmProjects\\trRosetta\\venv_36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\Tue\\PycharmProjects\\trRosetta\\venv_36\\lib\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\Tue\\PycharmProjects\\trRosetta\\venv_36\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 48, in <module>\r\n    from google.protobuf.pyext import _message\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\nImportError: DLL load failed: The specified procedure could not be found.\r\n``` \r\n\r\n\r\nAdditional info on this desktop system:\r\n\r\n```\r\nCoreinfo v3.5 - Dump information on system CPU and memory topology\r\nCopyright (C) 2008-2020 Mark Russinovich\r\nSysinternals - www.sysinternals.com\r\n\r\n\r\nAMD Ryzen 7 2700X Eight-Core Processor\r\nAMD64 Family 23 Model 8 Stepping 2, AuthenticAMD\r\nMicrocode signature: 00000000\r\nHTT             *       Multicore\r\nHYPERVISOR      *       Hypervisor is present\r\nVMX             -       Supports Intel hardware-assisted virtualization\r\nSVM             -       Supports AMD hardware-assisted virtualization\r\nX64             *       Supports 64-bit mode\r\n\r\nSMX             -       Supports Intel trusted execution\r\nSKINIT          -       Supports AMD SKINIT\r\n\r\nNX              *       Supports no-execute page protection\r\nSMEP            *       Supports Supervisor Mode Execution Prevention\r\nSMAP            *       Supports Supervisor Mode Access Prevention\r\nPAGE1GB         *       Supports 1 GB large pages\r\nPAE             *       Supports > 32-bit physical addresses\r\nPAT             *       Supports Page Attribute Table\r\nPSE             *       Supports 4 MB pages\r\nPSE36           *       Supports > 32-bit address 4 MB pages\r\nPGE             *       Supports global bit in page tables\r\nSS              -       Supports bus snooping for cache operations\r\nVME             *       Supports Virtual-8086 mode\r\nRDWRFSGSBASE    *       Supports direct GS/FS base access\r\n\r\nFPU             *       Implements i387 floating point instructions\r\nMMX             *       Supports MMX instruction set\r\nMMXEXT          *       Implements AMD MMX extensions\r\n3DNOW           -       Supports 3DNow! instructions\r\n3DNOWEXT        -       Supports 3DNow! extension instructions\r\nSSE             *       Supports Streaming SIMD Extensions\r\nSSE2            *       Supports Streaming SIMD Extensions 2\r\nSSE3            *       Supports Streaming SIMD Extensions 3\r\nSSSE3           *       Supports Supplemental SIMD Extensions 3\r\nSSE4a           *       Supports Streaming SIMDR Extensions 4a\r\nSSE4.1          *       Supports Streaming SIMD Extensions 4.1\r\nSSE4.2          *       Supports Streaming SIMD Extensions 4.2\r\n\r\nAES             *       Supports AES extensions\r\nAVX             *       Supports AVX instruction extensions\r\nFMA             *       Supports FMA extensions using YMM state\r\nMSR             *       Implements RDMSR/WRMSR instructions\r\nMTRR            *       Supports Memory Type Range Registers\r\nXSAVE           *       Supports XSAVE/XRSTOR instructions\r\nOSXSAVE         *       Supports XSETBV/XGETBV instructions\r\nRDRAND          *       Supports RDRAND instruction\r\nRDSEED          *       Supports RDSEED instruction\r\n\r\nCMOV            *       Supports CMOVcc instruction\r\nCLFSH           *       Supports CLFLUSH instruction\r\nCX8             *       Supports compare and exchange 8-byte instructions\r\nCX16            *       Supports CMPXCHG16B instruction\r\nBMI1            *       Supports bit manipulation extensions 1\r\nBMI2            *       Supports bit manipulation extensions 2\r\nADX             *       Supports ADCX/ADOX instructions\r\nDCA             -       Supports prefetch from memory-mapped device\r\nF16C            *       Supports half-precision instruction\r\nFXSR            *       Supports FXSAVE/FXSTOR instructions\r\nFFXSR           *       Supports optimized FXSAVE/FSRSTOR instruction\r\nMONITOR         -       Supports MONITOR and MWAIT instructions\r\nMOVBE           *       Supports MOVBE instruction\r\nERMSB           -       Supports Enhanced REP MOVSB/STOSB\r\nPCLMULDQ        *       Supports PCLMULDQ instruction\r\nPOPCNT          *       Supports POPCNT instruction\r\nLZCNT           *       Supports LZCNT instruction\r\nSEP             *       Supports fast system call instructions\r\nLAHF-SAHF       *       Supports LAHF/SAHF instructions in 64-bit mode\r\nHLE             -       Supports Hardware Lock Elision instructions\r\nRTM             -       Supports Restricted Transactional Memory instructions\r\n\r\nDE              *       Supports I/O breakpoints including CR4.DE\r\nDTES64          -       Can write history of 64-bit branch addresses\r\nDS              -       Implements memory-resident debug buffer\r\nDS-CPL          -       Supports Debug Store feature with CPL\r\nPCID            -       Supports PCIDs and settable CR4.PCIDE\r\nINVPCID         -       Supports INVPCID instruction\r\nPDCM            -       Supports Performance Capabilities MSR\r\nRDTSCP          *       Supports RDTSCP instruction\r\nTSC             *       Supports RDTSC instruction\r\nTSC-DEADLINE    -       Local APIC supports one-shot deadline timer\r\nTSC-INVARIANT   *       TSC runs at constant rate\r\nxTPR            -       Supports disabling task priority messages\r\n\r\nEIST            -       Supports Enhanced Intel Speedstep\r\nACPI            -       Implements MSR for power management\r\nTM              -       Implements thermal monitor circuitry\r\nTM2             -       Implements Thermal Monitor 2 control\r\nAPIC            *       Implements software-accessible local APIC\r\nx2APIC          -       Supports x2APIC\r\n\r\nCNXT-ID         -       L1 data cache mode adaptive or BIOS\r\n\r\nMCE             *       Supports Machine Check, INT18 and CR4.MCE\r\nMCA             *       Implements Machine Check Architecture\r\nPBE             -       Supports use of FERR#/PBE# pin\r\n\r\nPSN             -       Implements 96-bit processor serial number\r\n\r\nPREFETCHW       *       Supports PREFETCHW instruction\r\n\r\nMaximum implemented CPUID leaves: 0000000D (Basic), 8000001E (Extended).\r\nMaximum implemented address width: 48 bits (virtual), 48 bits (physical).\r\n\r\nProcessor signature: 00800F82\r\n```\r\n\r\nGPU: Nvidia Geforce RTX 2080 Ti\r\n\r\nA quick pip list on the system gives the following:\r\n\r\n```\r\nMicrosoft Windows [Version 10.0.18362.900]\r\n(c) 2019 Microsoft Corporation. All rights reserved.\r\n\r\n(venv_36) C:\\Users\\Tue\\PycharmProjects\\trRosetta>pip list\r\nPackage              Version\r\n-------------------- -------\r\nabsl-py              0.9.0\r\nastor                0.8.1\r\ngast                 0.4.0\r\ngoogle-pasta         0.2.0\r\ngrpcio               1.31.0\r\nh5py                 2.10.0\r\nimportlib-metadata   1.7.0\r\nKeras-Applications   1.0.8\r\nKeras-Preprocessing  1.1.2\r\nMarkdown             3.2.2\r\nnumpy                1.19.1\r\npip                  20.2.2\r\nprotobuf             3.12.4\r\nsetuptools           49.3.1\r\nsix                  1.15.0\r\ntensorboard          1.14.0\r\ntensorflow-estimator 1.14.0\r\ntensorflow-gpu       1.14.0\r\ntermcolor            1.1.0\r\nWerkzeug             1.0.1\r\nwheel                0.34.2\r\nwrapt                1.12.1\r\nzipp                 3.1.0\r\n\r\n(venv_36) C:\\Users\\Tue\\PycharmProjects\\trRosetta>\r\n```\r\n\r\nFinally it should be noted that I am able to run deep learning codes on both these computers, although they use newer versions of these libraries. I have both cuda 10.1 and 10.0 install right now, but 10.0 is the default in the $PATH environment at the moment due to this.", "There may be various reasons, like your python may be 32 bit, or on windows, we saw that anything downloaded from windows store has issues due to sandboxing, or missing visual studio redistributable.\r\nHowever, 1.14 is well outside our support windows, so I will mark this as community support.", "@tueboesen \r\nWe see that this issue is for 1.x which is not currently supported, could you please upgrade to 2.x and let us know.\r\nPlease refer to [this guide](https://www.tensorflow.org/install/source_windows#gpu) for the compatibility.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42192\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42192\">No</a>\n"]}, {"number": 42191, "title": "Gcs refactor part 2", "body": "@mihaimaruseac \r\nNow all 3 filesystems are usable now. We will need more testing of course.", "comments": ["This is awesome.\r\n\r\nWant to write a blog post for TensorFlow blog about these filesystems?", "I would love to. But I don't know how to do it ? I haven't written any blog yet.", "Let me look up the requierements and everything and then I'll share a Google Doc with you by email to prepare a draft."]}, {"number": 42190, "title": "[TFlite]: Failed to instantiate the interpreter with a StyleGAN2 generator model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel4, Samsung Galaxy S9+\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version on desktop (use command below): tensorflow 2.2.0 + tensorflow-gpu 2.2.0\r\n- TensorFlow lite version on mobile: tensorflow-lite:0.0.0-nightly + tensorflow-lite-gpu:0.0.0-nightly\r\n- Python version: 3.6.10\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: V10.2.89\r\n- GPU model and memory: 4* TITAN RTX 24GB\r\n\r\n**Describe the current behavior**\r\nI used `tf.compat.v1.lite.TFLiteConverter.from_session` to convert StyleGAN2 generator in Tensorflow lite format. the conversion  gives no error and no warning.\r\nThe option used for the conversion are as follow:\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]`\r\nOn phone, the interpreter instanciation fails when running on CPU: `tflite = new Interpreter(tfliteModel, tfliteOptions);` gives the following error:\r\n`Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.\r\n    Node number 239 (PAD) failed to prepare.`\r\nWhen trying to use GPU or NNAPI delegates, i have the same kind of error:\r\n`java.lang.RuntimeException: Unable to start activity ComponentInfo{org.pytorch.helloworld/org.pytorch.helloworld.MainActivity}: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.\r\n    Node number 239 (PAD) failed to prepare.`\r\n\r\n**Describe the expected behavior**\r\nI expect the model to be able to execute whatever target (CPU/GPU/NNAPI) is used, but most likely on NNAPI or GPU to get the best performances.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs**\r\nI tried several things to cope with this issue. When using the following option:\r\n`converter.target_ops=SELECT_TF_OPS`\r\nIt is working on CPU, but fails with another error on GPU: \r\n`ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`\r\nI guess this is because these target ops are not compatible with GPU and NNAPI delegates.\r\n\r\nI also tried to use converter v2 using the following method:\r\n`converter =  tf.lite.TFLiteConverter.from_concrete_functions([func])`\r\nBut the model size is very huge (624MB instead of 110MB for converter.v1) and i faced the same error when running on mobile: \r\n` Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.\r\n    Node number 221 (PAD) failed to prepare.`\r\n\r\n", "comments": ["Same thing happaned to me. During converting Pytorch model 'ir_csn_152' pretrained on 'ig_ft_kinetics_32frms' to Onnx, then to TF pb frozen graph, that is loaded and converted by TFLiteConverter sucessfully. But running  'interpreter.allocate_tensors()' gives 'RuntimeError: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.Node number 0 (PAD) failed to prepare.' error.", "@ntreepoint @denieboy Looks like some tensors in the graph have >4 dimensions, which isn't well-supported by TFLite yet. Can you share the tflite file? Even untrained works fine, as long as I can inspect the converter output file.", "Hi @srjoglekar246 I can't share the model because of company restrictions. Anyway i have checked the model and i confirm that i have tensors which have more than 4 dimensions (up to 6). Do you know when this will be available in TFLite?", "Can you provide the ops you need >4 dim support for, apart from PAD?\r\nYou can use the [visualization tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/visualize.py) on the TFLite graph for this.", "Could you try TF 2.3 or the latest version for the conversion? We've added a lot of sanity checks in the conversion in the TF 2.3 version. The converter is able to assign the TF ops to appropriate op set, TFLite builtin op or Flex op based on the input restriction unless the shape is undecided.", "@srjoglekar246 , here is the list of ops that need dim >4:\r\n```\r\nMUL\r\nSTRIDED_SLICE\r\nSQUARE\r\nSUM\r\nRESHAPE\r\nTRANSPOSE\r\nPAD\r\n```\r\n", "@abattery , i have tried using TF 2.3\r\nThe conversion fails. It generates a huge trace file (2.6G), it looks like you are dumping big data at the end such as model weight, perhaps you could reconsider the level of traces.\r\nI don't have any error related to tensor dimensions. The error i got is the following:\r\n`note: see current operation: %579 = \"tf.Pad\"(%578, %cst_72) {device = \"\"} : (tensor<3x16x1x16x1x1xf32>, tensor<6x2xi32>) -> tensor<3x16x2x16x2x1xf32>\r\nerror: 'tf.Pad' op is neither a custom op nor a flex op`\r\nI didn't get such error on 2.2. Where could it come from?\r\nHere are the truncated logs:\r\n[res.txt](https://github.com/tensorflow/tensorflow/files/5136840/res.txt)\r\n", "Since your graph contains operators, that are not supported in TFLite builtin operators, the conversion failure is an intended behavior. I would suggest conversion with Select TF ops in order to cover unsupported TF operators via Flex delegate.\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\nSee also https://www.tensorflow.org/lite/guide/reduce_binary_size", "@abattery i confirm that this is working on CPU using TF operators. What is not clear to me is why it was stated that tf.Pad is not a flex op and at the end it is working. Any insight on this?\r\nAlso this is not working on neither GPU nor NNAPI. I have the following warning message:\r\n`Ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`\r\nWhen inspecting the model i don't see any dynamic size.Here is the model details from visualize tool:\r\n[generator.zip](https://github.com/tensorflow/tensorflow/files/5149531/generator.zip)\r\nCan you pinpoint where this error come from? Does it mean that model using TF operators are not compatible with GPU and NNAPI?\r\n", "@ntreepoint That is indeed the case. Also, looks like *all* ops in your graph are turning out to be TF operators (hence the name 'CUSTOM' in the op names.) That isn't compatible with TFLite, so NNAPI/GPU delegation won't work.", "@abattery ,\r\nComing back to the conversion issue i have using TF 2.3:\r\n`note: see current operation: %579 = \"tf.Pad\"(%578, %cst_72) {device = \"\"} : (tensor<3x16x1x16x1x1xf32>, tensor<6x2xi32>) -> tensor<3x16x2x16x2x1xf32> error: 'tf.Pad' op is neither a custom op nor a flex op`\r\nThe error message is confusing. It states that the operator is not supported whereas i think it is supported by Tensorflow Lite. Does this message can be more likely triggered by the issue we raised before, which is that the input/output tensors dimensions are too big?\r\nIf so do you have a rough estimation on when it could be supported for the following ops i already mentioned:\r\n```\r\nMUL\r\nSTRIDED_SLICE\r\nSQUARE\r\nSUM\r\nRESHAPE\r\nTRANSPOSE\r\nPAD\r\n```", "FYI, Flex + GPU combination is now working at tf-nightly version if the graph has only static shapes.", "Thanks for the information @abattery. I confirm that Flex + GPU is working with the Python interpreter. However, I'm trying to run the same StyleGAN2 model on iOS and I run into this error: TensorFlow Lite Error: \"tensorflow/lite/kernels/strided_slice.cc new_axis_mask is not implemented yet. TensorFlow Lite Error: Node number 76 (STRIDED_SLICE) failed to prepare\".  I tried different TF versions but it did not help. By the way, this error occurs when I convert the model with \"TFLITE_BUILTINS\" option. I know that I can use \"SELECT_TF_OPS\" but since iOS does not support a selective TF_OPS conversion, I have memory issues on iOS devices as it loads all of the TF ops and the model is very large. So TFLITE_BUILTINS seems to be the only option for me. Also, I have implemented a custom OP for RandomStandardNormal as it's not supported by TFLITE. Here is the link to the tflite model: https://bucket-mert.s3.us-east-2.amazonaws.com/StyleGAN2+Tflite/synthesis_tflite_build.tflite\r\n\r\nThanks for your help,\r\nRegards ", "@thaink could you take a look at this? It looks like the strided slice operator has an issue with the new_axis_mask attribute.", "@sailor002 could you make sure that the TensorFlow Lite conversion is done with the recent TensorFlow version? You can use the different TensorFlow versions for training a model and exporting the model to the corresponding TensorFlow Lite model. For example, you can export the saved model from TensorFlow 2.2 and convert the saved model in TensorFlow 2.4 or beyonds.", "> @thaink could you take a look at this? It looks like the strided slice operator has an issue with the new_axis_mask attribute.\r\n\r\nNew axis mask and ellipsis_mask are not yet supported in our strided_slice kernel.", "Thanks for the quick reply. @abattery I also tried to convert the model with the latest nightly version but this time I get \"Encountered unresolved custom op: Pad.\" on the device. Pad seems to be another custom op that needs to be implemented but I think that even if I find a way to implement it, I'll still get the new_axis_mask error afterward. @thaink are there any plans for new_axis_mask and ellipsis_mask to be supported in the near future. If not, is there an easy way that I can find a workaround or manually support it with a bazel-built custom library on the device? Thanks...", "@sailor002 could you convert your model with the select TF op option instead of using custom ops? I would confirm that the new_axis_mask error can be resolved by the Flex delegate in the recent version.", "@abattery I've converted the model with TF op. It works with the python API (on a GPU cloud instance, with approx 10-seconds inference time). However, when I run the model on an iOS device (iPad 5th gen), I get a memory error: \"* malloc: can't allocate region\r\n:*** mach_vm_map(size=2437758976, flags: 100) failed (error code=3)\r\nTfLite Test(5619,0x10d18b880) malloc: *** set a breakpoint in malloc_error_break to debug\r\nlibc++abi.dylib: terminating with uncaught exception of type std::bad_alloc: std::bad_alloc\"\r\n\r\nI googled it and tried out an answer saying that increasing the thread number could help, but unfortunately the error persists. By the way, I converted the model with the \"tf.lite.Optimize.DEFAULT\" optimization option. Any ideas what else could be done?", "I managed to get the 256x256 version of the model (the original is 1024x1024) working on iPhone 11. On the iPad however, the issue still persists. So now it's all about memory. I think it's a handicap right now not being able to run the model without TF op (because of the new_axis_mask error). If we could, then we would definitely save a lot of memory. Plus, I am not able to use the Metal GPU and CoreML delegates as they are not supported by TF op. This seems to prolong prediction times which are around 3 secs on iPhone 11.", "I am not sure that the memory issue is coming from the TF library for the iOS platform or the heavy model itself. You can build your own slim TF library based on https://www.tensorflow.org/lite/guide/reduce_binary_size\r\n\r\n@yyoon @thaink could you take a look?", "@sailor002 How big is the model in megabytes, and on which exact iPad model are you seeing that error?\r\n\r\nIIUC, TFLite reads the `.tflite` file as a memory-mapped file, so the entire model will be in read into memory.\r\nI've never seen that particular memory allocation error before, but if the model file itself is too big to be read into memory, it could fail at the interpreter initialization step. (@srjoglekar246 @abattery please correct me if I'm wrong here.)\r\n\r\nWould be good to try some memory profiling with the iPhone 11 on which you managed to run the model. Then you'd get a better idea of how much memory is used at runtime and if it's a reasonable amount of memory to be used in other devices.", "@yyoon Here are the profiling results with iPad 5th Gen with [this](https://drive.google.com/file/d/1dbJQ1q-16J7kxdQBWqtdfjBxb1C0Bcf7/view?usp=sharing) model. The model is a tflite conversion of StyleGAN2 (applied Post-training float16 quantization). Normally, StyleGAN is trained to produce 1024x1024 images but I have downgraded it to be 128x128 for this model (because of the memory issue). As you see, RAM usage after the tensor allocation is around 20 MB which is quite normal. However, when I invoke the first inference, it rises up to 700 MB. After the 2nd inference, it rises up to about 800 MB and remains stable for every following inference.\r\n\r\nThe issue is that 128x128 is a low resolution for this project. I at least hope for 256x256 or more preferably 512x512 which causes an immediate memory crash when the inference is invoked. I don't know, maybe StyleGAN is not so suitable for mobile but I'm pushing the limits.\r\n\r\n@abattery I considered using a custom slim library, but as far as I understand, it's not supported on iOS. The doc says \"Selective Build for C API and iOS version is not supported currently\". Correct me if I'm wrong.\r\n\r\nAnd, one more interesting issue :) I managed to convert the model with \"Post-training float16 quantization\" obtaining a half-sized model which is expected. But when I used the OPTIMIZE_FOR_SIZE option (Post-training dynamic range quantization), the model size is almost unchanged compared to the original one, which is contrary to the expected quarter-sized binary. I also tried with \"Post-training integer quantization\", but again the model size is almost unchanged. Maybe if I could manage to convert the model to quarter size with these options, the memory issue may be resolved.\r\n\r\n![1_after_tensor_alloc](https://user-images.githubusercontent.com/32747250/103737871-1e195500-5004-11eb-96bc-60ed0ae384ad.jpg)\r\n![2_after_first_inference](https://user-images.githubusercontent.com/32747250/103737876-1fe31880-5004-11eb-9ddc-10160c5e981d.jpg)\r\n![3_after_n_inference_stable](https://user-images.githubusercontent.com/32747250/103737879-207baf00-5004-11eb-9396-60f2cd949925.jpg)\r\n\r\n\r\n", "@sailor002 GAN models are usually tricky to get working well on mobile, I am afraid. One of our previous projects involved ESRGAN, and we had to distill it to a smaller model for efficient on-device performance (See [this repo](https://github.com/captain-pool/GSOC/tree/master/E3_Distill_ESRGAN)). Using a distilled model will probably reduce your model-size (by simplifying hidden layers) while still retaining a high input size.\r\n\r\nIn this case, there is only so much we can do on the inference side :-). On that note, have you tried 8-bit quantization-aware training for this? Might help reduce the memory overhead.", "@srjoglekar246 thanks for the hints. I'll give the distillation method a try. I actually have not tried 8-bit quantization-aware training because I did not try to retrain the model (official weights are quite good). But maybe when I retrain the model for smaller sizes, I use 8-bit quantization-aware training in the process. But it's interesting that \"Post-training dynamic range quantization\" and \"Post-training integer quantization\" did not reduce the size at all. I remember the console logs saying something like \"skipping quantization of {foo} because it has fewer than 1024 elements\". Maybe this is the cause. Any ideas on that?", "That is strange. Most models contains weights etc that should be quantizable. Can you share your quantized conversion code?\r\n\r\nAlso, for the inference stats above, did you run on CPU or GPU?", "@srjoglekar246  [Here](https://drive.google.com/file/d/1P87Nv0zxdxTm0ddtRlazRYrY2AUG8oik/view?usp=sharing) is the dynamic quantization model. And [here](https://drive.google.com/file/d/1CRdDzNBdVZqir57cPyFBrm7SVFLdEWcT/view?usp=sharing) is the integer quantization model.\r\n\r\nI run on CPU because when I run on GPU, I get several other errors:\r\n\"\r\n2021-01-05 13:55:14.157800+0300 TfLite Test[5624:2088575] TfLiteFlexDelegate delegate: 33 nodes delegated out of 700 nodes with 9 partitions.\r\nTensorFlow Lite Error: Following operations are not supported by GPU delegate:\r\nBROADCAST_TO: Operation is not supported.\r\nDELEGATE TfLiteFlexDelegate: Operation is not supported.\r\nSTRIDED_SLICE: STRIDED_SLICE supports for 3 or 4 dimensional tensors only.\r\nSTRIDED_SLICE: Slice does not support shrink_axis_mask parameter. \r\n129 operations will run on the GPU, and the remaining 547 operations will run on the CPU.\r\nTensorFlow Lite Error: TfLiteMetalDelegate Prepare: Tensor \"model/Synthesis_network/4x4/Conv1/Mul_3\" has bad input dims size: 5.\r\nTensorFlow Lite Error: Node number 709 (TfLiteMetalDelegate) failed to prepare.\r\nTensorFlow Lite Error: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\nTensorFlow Lite Error: Node number 0 (FlexRandomStandardNormal) failed to prepare.\r\n\"\r\n\r\nBy the way, I'm working on the distillation method. I try to retrain a student model (both the same depth and a simplified version of the original model) but I guess there is something wrong because the model is not learning at all. Then I tried to use a standard DCGAN as the student model. This time it creates some face silhouettes but no more than that. It's strange that the original model performs worse than the standard DCGAN architecture. I've also studied the repo you've mentioned and it really helped. Do you have some best practices on this topic from your past experience like which student model architectures work best?. Thanks..\r\n", "@sailor002 Looks like you are trying to use 5-dim tensors, which are not well-supported on the GPU delegate. You will probably need to use different ops or reshape or something like that. Also, your model contains [TF Select ops](https://www.tensorflow.org/lite/guide/ops_select) for which you need to add some BUILD dependencies. See the linked docs for details.\r\n\r\nUsually, simple Convolutional architectures (like the MobileNets) work best for on-device inference. Looks like your original model contains a lot of tricky architecture that won't perform the best on device. So distillation will certainly help. Most of the best-practices we learnt in that project are encoded in the repo I linked you too, so going over the code should help :-).\r\n\r\n> It's strange that the original model performs worse than the standard DCGAN architecture. \r\n\r\nDo you mean the teacher performs *worse* than the student (the simpler model)?", "@srjoglekar246 thanks for the tips. I appreciate your help. No, I mean I'm comparing a shallow version of StyleGAN2 (as the student) and a regular DCGAN architecture (also as the student). DCGAN student can produce face silhouettes wheres the shallow StyleGAN2 student can not produce anything. Maybe this is related to using a wrong training process on my side because StyleGAN2 training is also somewhat complex due to Progressively Growing architecture and some other details. But of course, this is out of the scope of this thread. Anyway, thanks for the support. I hope I can find a way to create a mobile-friendly tflite model :)", "@sailor002 You should be able to gauge on-device performance without training the model. Simply try converting & running an untrained model (just benchmark for latency using [our tool](https://www.tensorflow.org/lite/performance/measurement)). This will save wasted time on training student models.", "Thanks, I'll definitely use it.", "@ntreepoint It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version  2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42190\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42190\">No</a>\n"]}, {"number": 42189, "title": "No gradient defined for operation RaggedTensorFromVariant", "body": "hello , \r\n\r\nI having an issue with training a simple model with RaggedTensors and Tendorflow is throwing the below error :\r\n`\"No gradient defined for operation RaggedTensorFromVariant\"`\r\n**System information**\r\n-Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n-OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n-Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n-TensorFlow installed from (source or binary): Binary\r\n-TensorFlow version (use command below): '2.3.0'\r\n-Python version: 3.7\r\n-Bazel version (if compiling from source): NA\r\n-GCC/Compiler version (if compiling from source): NA\r\n-CUDA/cuDNN version: 10.1\r\n-GPU model and memory: RTX 2080 TI\r\nYou can collect some of this information using our environment capture\r\n\r\n**Describe the current behavior**\r\nI'm unable to calculate the gradient of the dense values of a Ragged Tensor when RaggedTensors has been  used inside tf.map_fn.  below is the error that i get when running my code : \r\n`LookupError: No gradient defined for operation 'map_16/RaggedFromVariant/RaggedTensorFromVariant' (op type: RaggedTensorFromVariant)`\r\n\r\n**Describe the expected behavior**\r\nI believe that tensorflow should be able to handle such operations and be able to calculate the gradient especially that the values component of a raggedTensor is normal dense Tensor.  \r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.compat.v1.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\nimport numpy as np \r\nmyTensor = tf.ragged.placeholder(dtype=tf.float32 , ragged_rank=1)\r\ndef matmul_ragged( a) : \r\n    tens= a \r\n    con5 = tf.Variable([[0.1 , 2.11 , 11.2 ] ,[5.0 , 0.0 , 15.11 ] ])\r\n    mat=tf.matmul(tens,con5)\r\n    return mat\r\n \r\nstruct = tf.RaggedTensorSpec(shape=[None,None] , ragged_rank=0 ,dtype=tf.float32)\r\nfinal_answer = tf.map_fn(matmul_ragged ,myTensor, fn_output_signature=struct)\r\nprint(final_answer)\r\nloss = tf.reduce_mean(final_answer.values)\r\noptimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer\r\nopt_op = optimizer.minimize(loss)\r\n\r\nwith tf.Session() as sess : \r\n    sess.run(tf.global_variables_initializer())\r\n    vals =tf.ragged.RaggedTensorValue(np.array([[1.0, 2.2 ]  , [4.0, 5.0]  , [6.0, 7.0] ,  [8.0, 9.0] , [10.11, 10.11]]) , np.array([0, 2, 5]))\r\n    re    = sess.run([final_answer  ] , feed_dict={myTensor:vals} )\r\n    print(re)\r\n```\r\n\r\nBelow is a error stack that I get \r\n\r\n```\r\nLookupError                               Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    606           try:\r\n--> 607             grad_fn = ops.get_gradient_function(op)\r\n    608           except LookupError:\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in get_gradient_function(op)\r\n   2654     op_type = op.type\r\n-> 2655   return _gradient_registry.lookup(op_type)\r\n   2656 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py in lookup(self, name)\r\n     96       raise LookupError(\r\n---> 97           \"%s registry has no entry for: %s\" % (self._name, name))\r\n\r\nLookupError: gradient registry has no entry for: RaggedTensorFromVariant\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-17-8c10c3f6b529> in <module>\r\n     23 loss = tf.reduce_mean(final_answer.values)\r\n     24 optimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer\r\n---> 25 opt_op = optimizer.minimize(loss)\r\n     26 \r\n     27 with tf.Session() as sess :\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\r\n    401         aggregation_method=aggregation_method,\r\n    402         colocate_gradients_with_ops=colocate_gradients_with_ops,\r\n--> 403         grad_loss=grad_loss)\r\n    404 \r\n    405     vars_with_grad = [v for g, v in grads_and_vars if g is not None]\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\r\n    510         gate_gradients=(gate_gradients == Optimizer.GATE_OP),\r\n    511         aggregation_method=aggregation_method,\r\n--> 512         colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n    513     if gate_gradients == Optimizer.GATE_GRAPH:\r\n    514       grads = control_flow_ops.tuple(grads)\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\r\n    170         ys, xs, grad_ys, name, colocate_gradients_with_ops,\r\n    171         gate_gradients, aggregation_method, stop_gradients,\r\n--> 172         unconnected_gradients)\r\n    173   # pylint: enable=protected-access\r\n    174 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    621               raise LookupError(\r\n    622                   \"No gradient defined for operation '%s' (op type: %s)\" %\r\n--> 623                   (op.name, op.type))\r\n    624         if loop_state:\r\n    625           loop_state.EnterGradWhileContext(op, before=False)\r\n\r\nLookupError: No gradient defined for operation 'map_16/RaggedFromVariant/RaggedTensorFromVariant' (op type: RaggedTensorFromVariant)`\r\n\r\n```\r\nI would appreciate your help to fix this bug or if possible guide me on a work around. \r\n\r\nThanks \r\n", "comments": ["@malsulaimi,\r\nI was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5a14e109b1f1862309ea7947a64c23d4/42189-tf-nightly.ipynb). \r\n\r\nAlso, please take a look at [this workaround](https://groups.google.com/a/tensorflow.org/d/msg/discuss/P63KdpGGwvA/1ks-INGBAwAJ)  and let us know if it helps. Thanks!", "@amahendrakar Thank you very much for the fast response . I tried to apply the work around , but I'm getting a gradient related error : \r\n\r\nThis is my new code : \r\n```\r\n\r\n@tf.RegisterGradient(\"RaggedTensorFromVariant\")\r\ndef _RaggedTensorFromVariantGrad(op,grad,foo): \r\n    return [tf.cast(tf.zeros_like(foo), tf.variant)]\r\n\r\nmyTensor = tf.ragged.placeholder(dtype=tf.float32 , ragged_rank=1)\r\n         \r\ndef matmul_ragged( a) : \r\n    tens= a \r\n    con5 = tf.Variable([[0.1 , 2.11 , 11.2 ] ,[5.0 , 0.0 , 15.11 ] ])\r\n    mat=tf.matmul(tens,con5)\r\n    return mat\r\n \r\n\r\n\r\n\r\nfinal_answer =tf.map_fn(matmul_ragged,myTensor)\r\n\r\nprint(final_answer)\r\nloss = tf.reduce_mean(final_answer)\r\noptimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer\r\nopt_op = optimizer.minimize(loss)\r\n\r\nwith tf.Session() as sess : \r\n    sess.run(tf.global_variables_initializer())\r\n    vals =tf.ragged.RaggedTensorValue(np.array([[1.0, 2.2 ]  , [4.0, 5.0]  , [6.0, 7.0] ,  [8.0, 9.0]]) , np.array([0, 2, 4]))\r\n    re , re1, re2    = sess.run([opt_op   ] , feed_dict={myTensor:vals} )\r\n    print(re)\r\n    print(re1)\r\n    print(re2)\r\n\r\n```\r\n\r\n\r\nbelow is the error stack : \r\n\r\n```\r\n\r\ntf.RaggedTensor(values=Tensor(\"map/RaggedFromVariant/RaggedTensorFromVariant:1\", dtype=float32), row_splits=Tensor(\"map/RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(?,), dtype=int64))\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-2-2073a7dbe0e4> in <module>\r\n     30 loss = tf.reduce_mean(final_answer)\r\n     31 optimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer\r\n---> 32 opt_op = optimizer.minimize(loss)\r\n     33 \r\n     34 with tf.Session() as sess :\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\r\n    408           \"No gradients provided for any variable, check your graph for ops\"\r\n    409           \" that do not support gradients, between variables %s and loss %s.\" %\r\n--> 410           ([str(v) for _, v in grads_and_vars], loss))\r\n    411 \r\n    412     return self.apply_gradients(grads_and_vars, global_step=global_step,\r\n\r\nValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'map/while/Variable:0' shape=(2, 3) dtype=float32_ref>\"] and loss Tensor(\"RaggedReduceMean/truediv:0\", shape=(), dtype=float32).\r\n```", "I think this code is closer to what you want (2 arg version necessary for `tf.function`):\r\n```python\r\nfrom tensorflow.raw_ops import RaggedTensorToVariant\r\n\r\n@tf.RegisterGradient(\"RaggedTensorFromVariant\")\r\ndef _RaggedTensorFromVariantGrad(*args):\r\n    if len(args) == 2:\r\n        op, grad = args\r\n        res = [RaggedTensorToVariant(rt_nested_splits=[], rt_dense_values=grad,\r\n                                      batched_input=False)]\r\n    else:\r\n        op, empty, grad = args\r\n        res = [RaggedTensorToVariant(rt_nested_splits=[op.outputs[0]], rt_dense_values=grad,\r\n                                    batched_input=True)]\r\n```\r\nIt seems to sort of work in eager mode (for a few hundred steps in the model I'm trying to get working), but I get the same error you do in your colab, making me think there's another op in that graph that doesn't support gradients. It breaks immediately if you put `tf.function` around it though, with this error, potentially related to the no gradients problem:\r\n```\r\nOP_REQUIRES failed at constant_op.cc:288 : Internal: No unary variant unary_op function found for unary variant op enum: 1 Variant type_name: tensorflow::Tensor for device type: CPU\r\n```", "@malsulaimi,\r\nCould you please check @kentslaney's comment and let us know if it helps. Thanks!", "I'd be surprised if that fixed it on its own, I had to write some C++ to register the zeros unary op for a tensor type variant\r\n```cpp\r\n#include \"tensorflow/core/util/tensor_ops_util.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nusing CPUDevice = Eigen::ThreadPoolDevice;\r\n\r\nREGISTER_UNARY_VARIANT_UNARY_OP_FUNCTION(ZEROS_LIKE_VARIANT_UNARY_OP, DEVICE_CPU, Tensor, ZerosLikeTensor<CPUDevice>);\r\n```\r\n```cpp\r\n#if GOOGLE_CUDA\r\n#define EIGEN_USE_GPU\r\n\r\n#include \"tensorflow/core/util/tensor_ops_util.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nusing GPUDevice = Eigen::GpuDevice;\r\n\r\nREGISTER_UNARY_VARIANT_UNARY_OP_FUNCTION(ZEROS_LIKE_VARIANT_UNARY_OP, DEVICE_GPU, Tensor, ZerosLikeTensor<GPUDevice>);\r\n#endif\r\n```\r\nI'm now getting\r\n```\r\n2020-08-18 04:07:16.182610: F tensorflow/core/framework/tensor.cc:673] Check failed: 1 == NumElements() (1 vs. 4)Must have a one element tensor\r\n```\r\nI'll have to build from source with debugging mode later this week to get the stack trace and hopefully figure out what went wrong. I suspect it has to do with the wrapper variant that `RaggedTensorToVariant` puts around the output based on the numbers. As far as I can tell `RaggedTensor`s don't have a separate `tf.variant` class like `TensorList`s do in the unary op registry, but I'm not sure why. Let me know if you have any ideas on the error or see something wrong with my code @amahendrakar", "Actually, it turns out it was a separate problem, after compiling and loading the above I got it to run in static graph", "> @malsulaimi,\r\n> Could you please check @kentslaney's comment and let us know if it helps. Thanks!\r\n\r\n@malsulaimi,\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "> Actually, it turns out it was a separate problem, after compiling and loading the above I got it to run in static graph\r\n\r\n@kentslaney,\r\nIf you still need help with the problem, please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 42188, "title": "Tflite convertor inserted additional 1x1 conv layers", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Windows 10\r\n- pip install tensorflow==2.1.0\r\n\r\n**Describe the problem**\r\nI made a model with tf.keras, converted it using TensorflowLite and got strange redundant layers 4 1x1 conv layers.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nThis is my script\r\n\r\n`\r\nimport tensorflow as tf\r\nfrom tflite_runtime.interpreter import Interpreter\r\nimport numpy as np\r\nimport os\r\nunixToolsPaths=r'C:\\ARC_2019_12\\tools\\make;C:\\ARC_2019_12\\tools\\cmake\\bin;C:\\ARC_2019_12\\tools\\usr\\x86_64-pc-msys\\bin;C:\\ARC_2019_12\\tools\\usr\\bin;'\r\nos.environ['PATH'] += unixToolsPaths\r\nimport subprocess\r\n\r\ndef makeModel():\r\n    inputs = tf.keras.Input(shape=(49, 10, 1))\r\n    x = tf.keras.layers.Conv2D( 64, (10,4), (2, 2), padding='same', activation='relu')(inputs)\r\n    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)\r\n    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)\r\n    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)\r\n    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)\r\n    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)\r\n    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)\r\n    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)\r\n    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)\r\n    x = tf.keras.layers.AveragePooling2D((25, 5))(x)\r\n    x = tf.keras.layers.Flatten()(x)\r\n    x = tf.keras.layers.Dense(2)(x)\r\n    x = tf.keras.layers.Softmax()(x)\r\n    model = tf.keras.Model(inputs=inputs, outputs=x)\r\n    return model\r\n\r\n\r\ndef quantizationDataGenerator():\r\n    for i in range(10):\r\n        yield [ np.random.rand(1, 49, 10, 1).astype(np.float32)]\r\n\r\ndef convertTFL(name, model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.representative_dataset = quantizationDataGenerator\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.inference_input_type = tf.int8\r\n    converter.inference_output_type = tf.int8\r\n    quantModel = converter.convert()\r\n\r\n    with open(\"{}.tflite\".format(name), \"wb\") as f:\r\n        f.write(quantModel)\r\n\r\ndef convertToCC(file, ccFile):\r\n    subprocess.run(r'xxd -i {} > {}'.format(file, ccFile), shell=True, check=True)\r\n    \r\n    with open(ccFile, 'r') as f:\r\n        linesOrig = f.readlines()\r\n    lines = [\r\n        'unsigned char modelBuffer[] DATA_ALIGN_ATTRIBUTE = {\\n'\r\n    ]\r\n    lines.extend(linesOrig[1:-1])\r\n                \r\n    with open(ccFile, 'w') as f:\r\n        f.writelines(lines)\r\n        \r\n\r\nif __name__ == '__main__':\r\n    name = 'kws'\r\n    model = makeModel()\r\n    model.summary() \r\n    convertTFL(name, model)\r\n`\r\n\r\n", "comments": ["@yadonskov \r\nI ran the code shared it is not indented, please provide with complete indented code such that we can replicate the issue faced or if possible share a colab gist with the error faced.", "@Saduf2019 \r\nhttps://gist.github.com/yadonskov/5eba06542c9e83329d9a10b84ea5233f#file-tf_issue-ipynb\r\n", "I reproduced same behaviour in 2.3 version too", "@yadonskov \r\nI ran the code shared please find the [gist here](https://colab.research.google.com/gist/Saduf2019/28f84982b95bb046d9b510c667af2e9b/untitled367.ipynb), can you please point out the extra layer you are referring to the model summary and code both lead to 14 layers as expected.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "When I see in Netron - I see additional like double 1x1 convolutions \r\n![image](https://user-images.githubusercontent.com/17152311/91968848-efb9ff00-ed1d-11ea-9544-7a5485fed1df.png)\r\nmaybe Netron visualization is incorrect?\r\n"]}, {"number": 42187, "title": "Make ./configure work with Ubuntu's nvidia-cuda-toolkit package", "body": "This PR is a work-in-progress. I'm raising it now to get the CI build to run. Not sure if they run for draft PRs or not.\r\n\r\nCloses #40202.", "comments": ["@DoxasticFox This PR is in draft, any update on this? Please. Thanks!", "Thanks for asking, @gbaned. I think this PR is near completion. I think so because I was able to build and install a python3 package which executed code on my GPU. What's currently slowing me down is that I'm not sure how to run the CI tests locally. Many seem to fail, even on the master branch. I'm not sure if that's expected, given that some of the tests seem to be designed for TPUs, for example, which I don't have on my machine. Other inadequacies in my hardware could also play a role, like how much (G)RAM I have. Or I could just be running the wrong set of tests. I haven't had the time to investigate because of current work/life commitments, but I intend to pick this PR up again soon. What would expedite this work a lot is either: if pushing to this PR branch would trigger a build; or if someone could give me more explicit instructions about how to run the tests locally than those in [`CONTRIBUTING.md`](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests) and the related documentation.", "@gbaned Is it possible to run the CI build, please?", "@DoxasticFox  Can you please resolve conflicts? Thanks!", "Thanks for running the build, @gbaned. Looks like \"Windows Bazel GPU\" is failing. I've resolved the conflict, but it looks like I'll also need to revise my work.", "Can you please explain a bit what is different with nvidia-cuda-toolkit package from Ubuntu? Does it have a different directory structure, so no \"bin\" directory?\r\nI fear the changes you are doing will make the open source build diverge from our internal build, which makes things a bit messy. I have added Christian as reviewer who is more familiar with these things.", "@akuegel You can see the list of files installed by `nvidia-cuda-toolkit` [here](https://packages.ubuntu.com/focal/amd64/nvidia-cuda-toolkit/filelist). That mostly installs binaries. Headers are provided by [`nvidia-cuda-dev`](https://packages.ubuntu.com/focal/amd64/nvidia-cuda-dev/filelist) and [`libcupti-dev`](https://packages.ubuntu.com/focal/amd64/libcupti-dev/filelist). Ubuntu doesn't provide cuDNN, so that needs to be installed by following [Nvidia's instructions](https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux).\r\n\r\nYou can compare that to the locations of files in the `tensorflow/tensorflow:devel-gpu` Docker image by running this script inside the container:\r\n\r\n<details>\r\n  <summary>(Click to show script)</summary>\r\n\r\n```bash\r\n#!/usr/bin/env bash\r\n\r\nfiles=(\r\n        # Binaries\r\n        bin2c\r\n        fatbinary\r\n        nvcc\r\n        nvlink\r\n        ptxas\r\n\r\n        # Includes\r\n        cublas_api.h\r\n        cuda.h\r\n        cudnn.h\r\n        cudnn_version.h\r\n        cufft.h\r\n        cupti.h\r\n        cusolver_common.h\r\n        cusparse.h\r\n\r\n        # Others\r\n        link.stub\r\n)\r\n\r\nfunction _find {\r\n        2>/dev/null find -L / -xdev -name \"$1\" | tr '\\n' ' '\r\n}\r\n\r\nfor f in \"${files[@]}\"\r\ndo\r\n        printf \"%-20s%s\\n\" \"$f\" \"$(_find \"$f\")\"\r\ndone\r\n```\r\n\r\n</details>\r\n\r\nScript output:\r\n\r\n```\r\nbin2c               /usr/local/cuda-10.1/bin/bin2c /usr/local/cuda/bin/bin2c\r\nfatbinary           /usr/local/cuda-10.1/bin/fatbinary /usr/local/cuda/bin/fatbinary\r\nnvcc                /usr/local/cuda-10.1/bin/nvcc /usr/local/cuda/bin/nvcc\r\nnvlink              /usr/local/cuda-10.1/bin/nvlink /usr/local/cuda/bin/nvlink\r\nptxas               /usr/local/cuda-10.1/bin/ptxas /usr/local/cuda/bin/ptxas\r\ncublas_api.h        /usr/include/cublas_api.h\r\ncuda.h              /usr/local/cuda-10.1/include/cuda.h /usr/local/cuda-10.1/targets/x86_64-linux/include/cuda.h /usr/local/cuda/include/cuda.h /usr/local/cuda/targets/x86_64-linux/include/cuda.h /usr/include/linux/cuda.h /tensorflow_src/tensorflow/core/platform/cuda.h\r\ncudnn.h             /usr/include/cudnn.h\r\ncudnn_version.h     /tensorflow_src/tensorflow/stream_executor/cuda/cudnn_version.h\r\ncufft.h             /usr/local/cuda-10.1/include/cufft.h /usr/local/cuda-10.1/targets/x86_64-linux/include/cufft.h /usr/local/cuda/include/cufft.h /usr/local/cuda/targets/x86_64-linux/include/cufft.h\r\ncupti.h             /usr/local/cuda-10.1/extras/CUPTI/include/cupti.h /usr/local/cuda/extras/CUPTI/include/cupti.h\r\ncusolver_common.h   /usr/local/cuda-10.1/include/cusolver_common.h /usr/local/cuda-10.1/targets/x86_64-linux/include/cusolver_common.h /usr/local/cuda/include/cusolver_common.h /usr/local/cuda/targets/x86_64-linux/include/cusolver_common.h\r\ncusparse.h          /usr/local/cuda-10.1/include/cusparse.h /usr/local/cuda-10.1/targets/x86_64-linux/include/cusparse.h /usr/local/cuda/include/cusparse.h /usr/local/cuda/targets/x86_64-linux/include/cusparse.h\r\nlink.stub           /usr/local/cuda-10.1/bin/crt/link.stub /usr/local/cuda/bin/crt/link.stub\r\n```\r\n\r\nCurrently Tensorflow assumes that certain files exist in the same directory as each other. For example `link.stub` and `nvlink` are assumed to both be in `cuda_config.cuda_toolkit_path` [here](https://github.com/tensorflow/tensorflow/pull/42187/files#diff-27368da6eb4c2514a27a4d9733bc9b57L1073-L1074). But `nvidia-cuda-toolkit` has them at `/usr/bin/nvlink` and `/usr/lib/nvidia-cuda-toolkit/bin/crt/link.stub`.\r\n", "So how I can I remove myself from the review? I am not the right person to review this, I don't work on tensorflow infrastructure and am not really familiar with the configure scripts.", "Hi Christian, thanks for trying to fix this. I know the setup is quite brittle, and we do not really support all CUDA distro installations.\r\n\r\nWe are actually moving in the opposite direction, requiring CUDA to be installed in a single directory without trying to find all the necessary bits scattered across various paths. This is similar to what clang requires from the CUDA installation.", "@chsigg Understandable. It's easy to see how many issues would come with supporting many driver installation methods.\r\n\r\nThis raises a question for me: If TensorFlow should require CUDA to be installed in one directory, does anything even need to be done to address [third_party/gpus/find_cuda_config.py:286](https://github.com/tensorflow/tensorflow/blob/255f590ab64e637f49288883013d35efa0633b35/third_party/gpus/find_cuda_config.py#L286)? TensorFlow supports single-directory CUDA installations just fine. AFAIK this PR and #40202 should be closed.\r\n"]}, {"number": 42186, "title": "Failed to load the native TensorFlow runtime.", "body": "**System information**\r\n- OS Platform and Distribution windows 10\r\n- TensorFlow installed from source\r\n- TensorFlow 2.3\r\n- Python 3.8\r\n- Installed using conda\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am just trying to a run a code that i downloaded from github if someone can help this is my first time using tensorflow.\r\n\r\n**Any other info / logs**\r\n[Running] python -u \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\MNIST\\HelloTensor.py\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\MNIST\\HelloTensor.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n[Done] exited with code=1 in 145.607 seconds\r\n\r\n[Running] python -u \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\EmotionDetection\\EmotionDetector.py\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\EmotionDetection\\EmotionDetector.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n[Done] exited with code=1 in 366.04 seconds\r\n\r\n[Running] python -u \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\EmotionDetection\\EmotionDetector.py\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\projects\\Desktop\\Machine and  Deep learning\\TensorflowProjects-master\\TensorflowProjects-master\\EmotionDetection\\EmotionDetector.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\projects\\.conda\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n[Done] exited with code=1 in 196.316 seconds\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@Abdallah-isa \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Please, refer similar issues #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42186\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42186\">No</a>\n"]}, {"number": 42185, "title": "Node number 241 (TfLiteFlexDelegate) failed to invoke.", "body": "**System information**\r\n- OS Platform  : TFlite C++ API on Android Platform\r\n- TensorFlow version : tf-nightly 2.4.0\r\n\r\n**I have build tflite C library with Flex Op module.\r\n\r\nBut when I test it with a Tflite model which contain flex ops, I have got a error while invoke\uff1a**\r\n\r\n op_kernel.cc:1772 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)\r\nContainer __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)\r\n    \t (while executing 'TensorArrayScatterV3' via Eager)\r\nNode number 241 (TfLiteFlexDelegate) failed to invoke.\r\n\r\nHas anyone encountered such a problem?\r\n", "comments": ["@MannyKai,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "> @MannyKai,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!\r\n\r\nYes, I have re submitted the question and described it in more detail\uff0c[https://github.com/tensorflow/tensorflow/issues/42214](url)", "@MannyKai,\r\nCan we please close this issue since it is already being tracked there? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 42184, "title": "Get error during converting ResizeNearestNeighbor to tflite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux\r\n- TensorFlow installed from (source or binary):  package manager\r\n- TensorFlow version (or github SHA if from source):  2.2.0 - 1\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_model_quant = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n2020-08-10 18:10:20.777385: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nloc(callsite(\"sequential/up_sampling2d/resize/ResizeNearestNeighbor\"(\"/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":865:0) at callsite(\"/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":959:0 at callsite(\"/usr/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\":435:0 at \"test.py\":51:0)))): error: 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor.\r\nTraceback (most recent call last):\r\n  File \"/usr/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/lib/python3.8/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/lib/python3.8/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 50, in execute\r\n    output_str = _pywrap_toco_api.TocoConvert(\r\nException: /usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:865:9: error: 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op\r\n        self._initialize(args, kwargs, add_initializers_to=initializers)\r\n        ^\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:959:5: note: called from\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n    ^\r\n/usr/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:435:5: note: called from\r\n    concrete_func = func.get_concrete_function()\r\n    ^\r\ntest.py:51:1: note: called from\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n^\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor.\r\n\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nConversion fails.\r\n\r\nIn the attachment zip file, there is a .py file that you can run and reproduce the error. The code is originally from this tutorial:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb\r\n\r\nThe cause of the failure is that I added a UpSampling2D layer with \"nearest neighbor\" in the model and do \"Convert using integer-only quantization\".  Everything is ok if I delete UpSampling2D, or use UpSampling2D with \"bilinear\".\r\n\r\n[test.zip](https://github.com/tensorflow/tensorflow/files/5050250/test.zip)\r\n\r\n\r\n", "comments": ["@neesetifa \r\nI ran the .py file shared and do not face any issues on tf nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/2e92a6fddd0d149ca0b9a34683bbf4ba/untitled337.ipynb)\r\nWith respect to the error reported please refer to below issues:\r\n#36517 #41085 [link](https://github.com/google-coral/edgetpu/issues/152) #35590 ", "@Saduf2019  Thank you for the quick reply. I ran the gist and everything seems fine on tf nightly.\r\nActually this problem happened when I tried to convert a mobilenet yolo v3 model in my office. I will try it again with tf nightly when I get back to the office tomorrow. ", "Could you try conversion with tf select ops?\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select", "@neesetifa \r\nCould you please update.", "@Saduf2019  I'm so sorry for the delay.  \r\nYesterday, I successfully convert the model using tf nightly, but got following problems:\r\n1. If I use tf 2.2 to do inference, we get error \"Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3' \", which is same as the one you mentioned before [link](https://github.com/google-coral/edgetpu/issues/152)\r\n\r\n2. If I use tf nightly to do inference, we get new error:\r\n> 2020-08-12 02:29:00.559305: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5459220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-12 02:29:00.559335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"test_on_single_image_tflite_ver.py\", line 63, in <module>\r\n    interpreter_quant.set_tensor(input_index_quant, resized_image)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\", line 408, in set_tensor\r\n    self._interpreter.SetTensor(tensor_index, value)\r\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type INT8 for input 0, name: input_1 \r\n\r\nattachment is the model converted by tf nightly\r\n[tflite.zip](https://github.com/tensorflow/tensorflow/files/5060321/tflite.zip)\r\n\r\nfollowing is my conversion code\r\n\r\n```\r\ndef process_single_image_with_opencv(image):\r\n    image_shape = image.shape[:2]\r\n    image = cv2.resize(image, (416, 416))  \r\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\r\n    image = image / 255.0\r\n    return image, image_shape\r\n\r\n# load model\r\nmodel_yolo = get_model()\r\nmodel_yolo.load_weights(filepath = SAVE_MODEL_DIR + \"final_weights.h5\")\r\n\r\ntxt_dataset = tf.data.TextLineDataset(filenames=TRAIN_TXT_DIR)\r\ndef representative_data_gen():\r\n      for txt in txt_dataset.take(1000):\r\n            image_name, _, _ = ReadTxt(txt.numpy()).parse_line()\r\n            image = cv2.imread(image_name)\r\n            image, _ = process_single_image_with_opencv(image)\r\n            image = tf.expand_dims(image, axis = 0)\r\n            yield [image]\r\n            \r\ntflite_models_dir = pathlib.Path(TFLite_MODEL_DIR)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_yolo)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8\r\nconverter.inference_output_type = tf.int8\r\n    \r\ntflite_model_quant = converter.convert()\r\ntflite_model_quant_file = tflite_models_dir/\"mobilenet_yolo_v3_fixed_size_416_alpha_50_int8.tflite\"\r\ntflite_model_quant_file.write_bytes(tflite_model_quant)\r\n```\r\n\r\n\r\nfollowing is my inference code\r\n\r\n```\r\ntest_image = cv2.imread( \"xxxxx.jpg\" ) # just use any image\r\nresized_image,  _ = process_single_image_with_opencv(test_image)\r\nresized_image = np.expand_dims(resized_image, axis = 0)\r\n\r\ninterpreter_quant = tf.lite.Interpreter(model_path = 'mobilenet_yolo_v3_fixed_size_416_alpha_50_int8.tflite')\r\ninterpreter_quant.allocate_tensors()\r\n\r\ninput_index_quant  = interpreter_quant.get_input_details()[0][\"index\"]\r\noutput_index_quant = interpreter_quant.get_output_details()[0][\"index\"]\r\n\r\ninterpreter_quant.set_tensor(input_index_quant, resized_image)\r\ninterpreter_quant.invoke()\r\noutput_data = interpreter_quant.get_tensor(output_index_quant) \r\n\r\n# then use output_data to get best boxes\r\n```\r\n\r\n\r\n", "@abattery   Thanks for the reply. I tried that one before, and I get \"segmentation fault\" during conversion with no other information.", "For the quantization problem after conversion, it is related to the model optimization toolkit.", "@neesetifa You are using `process_single_image_with_opencv()`, but it seems to output float image. It is not compatible with your quantized integer model. Could you check with integer images again?", "@jaeyoo  Thank you for your reply. I double checked `process_single_image_with_opencv()`, this used to work in 2.2.  I read the latest tutorial and it seems that I need to manually convert the image back to integer in 2.3 or nightly before doing invoke(). Now everything works perfect. \r\nThis issue can be closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42184\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42184\">No</a>\n"]}, {"number": 42183, "title": "Adam optimizer - ValueError: tf.function-decorated function tried to create variables on non-first call", "body": "I am using tensorflow 2.3\r\n\r\nThe code below \r\n\r\n\r\n\r\n    import  tensorflow as tf\r\n    \r\n    y_N= tf.Variable([1., 2., 3.],name=\"dd\")\r\n    \r\n    @tf.function\r\n    def loss():\r\n        return -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))\r\n    \r\n    @tf.function\r\n    def run():\r\n        tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])\r\n    \r\n    run()\r\n\r\ngives exception\r\n\r\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\r\n\r\nProblem looks like `tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])` creates new variable on > first call, while using `@tf.function`. If I must wrap adam_optimizer under `@tf.function`, is it possible? looks like a bug?", "comments": ["I have tried in colab with TF version 2.3, nightly version(`2.4.0-dev20200810`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/b8abbdd5f974a0f189fe36cb6c34a421/untitled234.ipynb).Thanks!", "I found out that  after calling `minimize` function, it will create an `iter` variable, by calling `self.iterations` once. \r\n(This happens in `tensorflow/python/keras/optimizer_v2/optimizer_v2.py`)\r\n\r\nSubsequent call of the `self.iterations` will not create new variable - \r\nas `iter` has already been created.\r\n\r\nTherefore, by calling it earlier outside the tf.function solve the issue, here's the code that works:\r\n\r\n    import  tensorflow as tf\r\n    \r\n    y_N= tf.Variable([1., 2., 3.],name=\"dd\")\r\n    \r\n    @tf.function\r\n    def loss():\r\n        return -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))\r\n    \r\n    @tf.function\r\n    def run(adam):\r\n        adam.minimize(loss, var_list=[y_N])\r\n    \r\n    \r\n    adam=tf.keras.optimizers.Adam(0.5)\r\n    run(adam)\r\n\r\nThough I think the `minimize` of Adam function could be improved so that we don't need this hack.", "Hi @tianhuat, you've run into a fairly common scenario due to some slightly confusing behavior with Keras and tf.function. The [Variables section of the tf.function guide](https://www.tensorflow.org/guide/function#variables) explains the error message you've seen as guarding against behavior divergence on repeated calls. In eager mode, a function creates a new variable with each call, but with graph mode a new variable may not be created due to trace reuse. This is essentially what you've noted in your above comment, and the suggested solution is to pass in the optimizer. And for reference, you'll likely run into a similar error message if you try to create the model inside your tf.function, instead of passing it in.\r\n\r\nI'll close this issue now as you've found a solution, and there is also an open issue around this error message (with a lot of comments if you're interested in reading more on the details) #27120", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42183\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42183\">No</a>\n"]}, {"number": 42182, "title": "Not every keras.metrics.* accept from_logits=True", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.3\r\n- TensorFlow installed from: binary (Docker Image tensorflow:2.3.0-gpu)\r\n- TensorFlow version: v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: 3.6.9 \r\n- CUDA/cuDNN version: CUDA10.2\r\n- GPU model and memory: RTX 2080 8GB\r\n\r\n\r\n**Describe the current behavior**\r\nThe issue is the same as described by MeghnaNatraj in ticket [37103](https://github.com/tensorflow/tensorflow/issues/37103). The mentioned ticket states the problem has been solved. I was requested to open a new ticket.\r\n\r\nIf I have a model with an output layer of one neuron and 'sigmoid' activation function and using BinaryCrossentropy(from_logits=False), then the model.fit() function accepts any metrics (e.g. Precision)\r\nIf I have the same model as before but without activation function and BinaryCrossentropy(from_logits=True), then model.fit() function will return an error.\r\n\r\n**Describe the expected behavior**\r\n- Having a model, which has an output layer without an activation function: keras.layers.Dense(1) # Output range is [-inf, +inf]\r\n- Loss function of the model working with logits: BinaryCrossentropy(from_logits=True)\r\n- Accepting metrics during fitting like keras.metrics.Precision\r\n\r\n**Standalone code to reproduce the issue**\r\nI have copied the same test code by MeghnaNatraj in ticket [37103](https://github.com/tensorflow/tensorflow/issues/37103) \r\n\r\n```\r\n# INITIALIZE\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n# define dataset\r\ndataset = np.array([[6,148,72,35,0,33.6,0.627,50,1],\r\n[1,85,66,29,0,26.6,0.351,31,0],\r\n[8,183,64,0,0,23.3,0.672,32,1],\r\n[1,89,66,23,94,28.1,0.167,21,0],\r\n[0,137,40,35,168,43.1,2.288,33,1]])\r\n# split into input (X) and output (y) variables\r\nX = dataset[:,0:8]\r\ny = dataset[:,8]\r\n```\r\n\r\n```\r\n# WORKS: Model output is in range [0, 1]\r\n# define the keras model\r\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),\r\n                                    tf.keras.layers.Dense(1, activation='sigmoid')])\r\n# compile the keras model\r\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(),\r\n              optimizer=tf.keras.optimizers.RMSprop(),\r\n              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),\r\n                       tf.keras.metrics.Precision(name='precision'),\r\n                       tf.keras.metrics.TruePositives(name='tp')])\r\n# fit the keras model on the dataset\r\nmodel.fit(X, y, epochs=10, batch_size=10, verbose=0)\r\n```\r\n\r\n```\r\n# DOES NOT WORK: Model output is in range [-inf, inf]\r\n# define the keras model\r\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),\r\n                                    tf.keras.layers.Dense(1)])\r\n# compile the keras model\r\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n              optimizer=tf.keras.optimizers.RMSprop(),\r\n              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),\r\n                       tf.keras.metrics.Precision(name='precision'),\r\n                       tf.keras.metrics.TruePositives(name='tp')])\r\n# fit the keras model on the dataset\r\nmodel.fit(X, y, epochs=10, batch_size=10, verbose=0)\r\n\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]\r\n\t [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]\r\n\t [[metrics/tp/assert_greater_equal/Assert/AssertGuard/pivot_f/_31/_61]]\r\n  (1) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]\r\n\t [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_function_12253]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 840, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\r\n    cancellation_manager=cancellation_manager)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential/dense_1/BiasAdd:0) = ] [[28.8497276][37.4658966][48.6209221]...] [y (Cast_5/x:0) = ] [1]\r\n         [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]]\r\n         [[assert_less_equal_1/Assert/AssertGuard/pivot_f/_41/_81]]\r\n  (1) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential/dense_1/BiasAdd:0) = ] [[28.8497276][37.4658966][48.6209221]...] [y (Cast_5/x:0) = ] [1]\r\n         [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_1165]\r\n```\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/a935a6152c181e3dc41a634fbb0014f7/42182-2-2.ipynb#scrollTo=JpJKOKSJLXea), [TF v2.3](https://colab.research.google.com/gist/amahendrakar/3b2889c03a765d80bab6b5b444920d73/42182.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/ff1cbac265479597dde7294de7547a4d/42182-tf-nightly.ipynb). Please find the attached gist. Thanks!", "any one is working on this? ", "Would also like to know if there is any progress on this issue.", "Looking at the source code for `tf.keras.metrics.Precision`, one can see that there is an assertion that thresholds are between 0 and 1. See trail of links below:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4ef28c5f287cd0a96daad3e7634b570de7e1f496/tensorflow/python/keras/metrics.py#L1256\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4ef28c5f287cd0a96daad3e7634b570de7e1f496/tensorflow/python/keras/utils/metrics_utils.py#L178\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4ef28c5f287cd0a96daad3e7634b570de7e1f496/tensorflow/python/keras/utils/metrics_utils.py#L169\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4ef28c5f287cd0a96daad3e7634b570de7e1f496/tensorflow/python/keras/utils/metrics_utils.py#L171\r\n\r\nFurther to change this, it seems like there has to be made a change here: https://github.com/tensorflow/tensorflow/blob/4ef28c5f287cd0a96daad3e7634b570de7e1f496/tensorflow/python/keras/utils/metrics_utils.py#L336-L345", "would like some resolution on this!", "Also running into this problem at the moment. ", "run into this problem for a combination use of `tf.keras.losses.BinaryCrossentropy(from_logits=True)` (for a numerically stable loss computation) and `tf.keras.metrics.AUC`", "This issue also arises when trying to add metrics to [classify text with bert tutorial](https://www.tensorflow.org/tutorials/text/classify_text_with_bert)", "As a stupid and simple workaround, I simply created this wrapper module. Anyone else encountering this issue, feel free to use the following code as you please.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras.metrics as tfm\r\n\r\n\r\nclass AUC(tfm.AUC):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(AUC, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(AUC, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass BinaryAccuracy(tfm.BinaryAccuracy):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(BinaryAccuracy, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(BinaryAccuracy, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass TruePositives(tfm.TruePositives):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(TruePositives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(TruePositives, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass FalsePositives(tfm.FalsePositives):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(FalsePositives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(FalsePositives, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass TrueNegatives(tfm.TrueNegatives):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(TrueNegatives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(TrueNegatives, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass FalseNegatives(tfm.FalseNegatives):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(FalseNegatives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(FalseNegatives, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass Precision(tfm.Precision):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(Precision, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(Precision, self).update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass Recall(tfm.Recall):\r\n    def __init__(self, from_logits=False, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._from_logits = from_logits\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        if self._from_logits:\r\n            super(Recall, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n        else:\r\n            super(Recall, self).update_state(y_true, y_pred, sample_weight)\r\n```", "Thank you very much, @barskern. It works perfectly!\r\nI did find a more compact way to express your solution. Thought Id share it:\r\n\r\n```py\r\nclass FromLogitsMixin:\r\n  def __init__(self, from_logits=False, *args, **kwargs):\r\n    super().__init__(*args, **kwargs)\r\n    self.from_logits = from_logits\r\n\r\n  def update_state(self, y_true, y_pred, sample_weight=None):\r\n    if self.from_logits:\r\n      y_pred = tf.nn.sigmoid(y_pred)\r\n    return super().update_state(y_true, y_pred, sample_weight)\r\n\r\n\r\nclass AUC(FromLogitsMixin, tf.metrics.AUC):\r\n  ...\r\n\r\nclass BinaryAccuracy(FromLogitsMixin, tf.metrics.BinaryAccuracy):\r\n  ...\r\n\r\nclass TruePositives(FromLogitsMixin, tf.metrics.TruePositives):\r\n  ...\r\n\r\nclass FalsePositives(FromLogitsMixin, tf.metrics.FalsePositives):\r\n  ...\r\n\r\nclass TrueNegatives(FromLogitsMixin, tf.metrics.TrueNegatives):\r\n  ...\r\n\r\nclass FalseNegatives(FromLogitsMixin, tf.metrics.FalseNegatives):\r\n  ...\r\n\r\nclass Precision(FromLogitsMixin, tf.metrics.Precision):\r\n  ...\r\n\r\nclass Recall(FromLogitsMixin, tf.metrics.Recall):\r\n  ...\r\n\r\nclass F1Score(FromLogitsMixin, tfa.metrics.F1Score):\r\n  ...\r\n```", "@lucasdavid That looks a lot cleaner! Thank you for the improvements \ud83d\ude01", "I tried the code in colab with TF nightly & didn't face the issue reported ,please check the gist [here](https://colab.research.google.com/gist/sushreebarsa/0b8aa23e900fb3c195eb5a393db985ff/untitled131.ipynb?authuser=1) ..Thanks !", "F1Score based on @barskern's code:\r\n\r\n```python\r\nclass F1Score(tf.keras.metrics.Metric):\r\n    def __init__(self, name=\"f1\", from_logits=False, **kwargs):\r\n        super(F1Score, self).__init__(name=name, **kwargs)\r\n        self.precision = Precision(from_logits)\r\n        self.recall = Recall(from_logits)\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        self.precision.update_state(y_true, y_pred, sample_weight)\r\n        self.recall.update_state(y_true, y_pred, sample_weight)\r\n\r\n    def result(self):\r\n        p = self.precision.result()\r\n        r = self.recall.result()\r\n        return (2 * p * r) / (p + r + tf.keras.backend.epsilon())\r\n\r\n    def reset_states(self):\r\n        self.precision.reset_states()\r\n        self.recall.reset_states()\r\n```", "Closing this issue as it is fixed in latest version of TensorFlow. Please feel free to reopen the issue if you still have a concern. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42182\">No</a>\n", "> Closing this issue as it is fixed in latest version of TensorFlow. Please feel free to reopen the issue if you still have a concern. Thanks!\r\n\r\nHi @sushreebarsa, I believe this issue is not solved yet, at least not completely. Please see my post in the TensorFlow forum below.\r\nhttps://discuss.tensorflow.org/t/metrics-related-predictions-must-be-1-error/6144\r\n\r\nWould you reopen the issue or should I create a new one?", "Hi @raftAtGit , \r\nPlease create a new issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!\r\n ", "> ```python\r\n> f self._from_logits:\r\n>             super(FalseNegatives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n>         else:\r\n>             super(FalseNegatives, self).update_state(y_true, y_pred, sample_weight)\r\n> \r\n> \r\n> class Precision(tfm.Precision):\r\n>     def __init__(self, from_logits=False, *args, **kwargs):\r\n>         super().__init__(*args, **kwargs)\r\n>         self._from_logits = from_logits\r\n> \r\n>     def update_state(self, y_true, y_pred, sample_weight=None):\r\n>         if self._from_logits:\r\n>             super(Precision, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n>         else:\r\n>             super(Precision, self).update_state(y_true, y_pred, sample_weight)\r\n> \r\n> \r\n> class Recall(tfm.Recall):\r\n>     def __init__(self, from_logits=False, *args, **kwargs):\r\n>         super().__init__(*args, **kwargs)\r\n>         self._from_logits = from_logits\r\n> \r\n>     def update_state(self, y_true, y_pred, sample_weight=None):\r\n>         if self._from_logits:\r\n>             super(Recall, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\r\n>         else:\r\n>             super(Recall, self).update_state(y_true, y_pred, sample_weight)\r\n> ```\r\n\r\n@lucasdavid can you explicitly write out what `...`mean under each class? an example will be helpful. Thanks\r\n"]}, {"number": 42181, "title": "TensorArray cannot be converted with TFLiteConverter", "body": "I want to use a `tf.TensorArray` in a decoding-loop in order to collect predicted ids from the model (for later conversion to text. However, it seems that `tf.TensorArray` makes issues when trying to convert it with `TFLiteConverter`.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.8 (Conda)\r\n- CUDA/cuDNN version: 10.1\r\n\r\n**Describe the current behavior**\r\n\r\nConverting a function which uses `tf.TensorArray` throws an exception saying\r\n\r\n```none\r\nerror: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nConvert the model without errors.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\n@tf.function\r\ndef tensor_array():\r\n    outputs = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True)\r\n    outputs = outputs.write(0, 1)\r\n    outputs = outputs.write(1, 2)\r\n    outputs = outputs.write(2, 3)\r\n    return outputs.gather(tf.range(outputs.size()))\r\n\r\n\r\ndef main():\r\n    concrete_fn = tensor_array.get_concrete_function()\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_fn])\r\n    converter.experimental_new_converter = True\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n    tflite_model = converter.convert()\r\n\r\n    with open('model.tflite', 'wb') as f:\r\n        f.write(tflite_model)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Other info / logs** \r\n\r\n```none\r\n2020-08-10 10:28:45.806093: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-08-10 10:28:45.809971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-10 10:28:45.809981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.004ms.\r\n2020-08-10 10:28:45.809988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-10 10:28:45.822697: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-08-10 10:28:45.822721: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nloc(callsite(\"TensorArrayV2\"(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":464:0) at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":1071:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/bin/tensor_array.py\":6:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":962:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":600:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":986:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3065:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3213:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":2855:0 at \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":696:0)))))))))): error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\nloc(callsite(\"TensorArrayV2\"(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":464:0) at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":1071:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/bin/tensor_array.py\":6:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":962:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":600:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":986:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3065:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3213:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":2855:0 at \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":696:0)))))))))): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n```\r\n", "comments": ["\r\nI ran the code and i am able to replicate the issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/98690c98039b4d3864e05368c107c5fb/untitled351.ipynb)", "TensorArray is not supported natively in TFLite. TensorArray is one of TF v1.x stuffs and TFLite currently supports TF v2 control flow ops. Could you try using a TensorList or enabling the following option?\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2", "@abattery I am now just using `tf.concat` to return the predicted ids. This seems to work. \ud83d\udc4d \r\n", "Closing this issue now since it's solved. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42181\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42181\">No</a>\n"]}, {"number": 42179, "title": "[EXT-SYSLIB] Add runtime_py for external flatbuffer.", "body": "Fix proper build when ```flatbuffer``` is external ```LOCAL_LIBS```.\r\n\r\n```\r\nERROR: /home/cbalint/rpmbuild/BUILD/tensorflow/tensorflow/tensorflow/lite/python/BUILD:206:11: no such target '@flatbuffers//:runtime_py': target 'runtime_py' not declared in package '' (did you mean 'runtime_cc'?) defined by /home/cbalint/rpmbuild/BUILD/tensorflow/_bazel_cbalint/4c79ce0d14678d18eb8640cac68aaf03/external/flatbuffers/BUILD.bazel and referenced by '//tensorflow/lite/python:util'\r\n```\r\n\r\nCc @perfinion, @mihaimaruseac \r\n\r\nThank You !", "comments": []}, {"number": 42178, "title": "Capability to get probabilities for each tag in crf_decode", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.15\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am talking about this specific repository.\r\n[https://github.com/tensorflow/addons/blob/v0.10.0/tensorflow_addons/text/crf.py](url)\r\n\r\nFor now crf_decode function returns the tag indices with highest probability and a viterbi score for the whole sequence.\r\nBut the crf_decode do not returns the probabilities for every tag for each token in sequence like we get in softmax.\r\nSo I request to please add this capability because probabilities of tags help us know the confidence score and many more things.\r\n\r\n\r\n**Will this change the current api? How?**\r\nYes, it will support more capabilities.\r\n\r\n**Who will benefit with this feature?**\r\nI believe many developers around the globe are looking for this feature.\r\n\r\n**Any Other info.**\r\nPlease add it as soon as possible.", "comments": ["@agarwalishan,\r\nCould you please submit a new issue in the Addons repo using [this link](https://github.com/tensorflow/addons/issues/new/choose), so that we can track the issue there. Thanks!", "@amahendrakar,\r\nHey thanks for reply I have opened issue on the given link, you may close it here."]}, {"number": 42177, "title": "Fused conv implementation does not support grouped convolutions for now", "body": "\r\n![image](https://user-images.githubusercontent.com/12997948/89756964-837d1e80-db16-11ea-98a9-262719e3bc72.png)\r\n\r\n`Fused conv implementation does not support grouped convolutions for now`\r\n\r\nWhat should i do \uff1f", "comments": ["@yangshengdong \r\nplease update the template, we cannot find the tensorflow version, steps followed before you faced the error and error logs for us to analyze the issue.\r\nAlso please paste the error message (using makrdown formatting around it) instead of screenshotting. Screenshots are not searchable so they don't help in looking for the issue and also don't help other people having the same error from finding about the issue.", "thanks\uff0cThis problem solved\r\n\r\nThe problem was due to the difference in the number of channels in the image and the model"]}, {"number": 42176, "title": "TF Lite version for examples/lite/examples/image_classification", "body": "I tried to run image classification demo on Android based on the following link. It can work successfully.\r\nhttps://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/README.md\r\n\r\nI have a question about the version number for this TF Lite. I want to know weather this demo is using libtflite.so in my Android OS or some other TF Lite version?\r\n\r\nThanks.", "comments": ["According to my understanding, the libraries as below are just for JNI support. libtflite.so is still needed. Well, who provides libtflite.so? My Android OS or others?\r\n\r\nimplementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\nimplementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\nimplementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'", "The example pulls the native TFLite binaries from the nightly builds. Generally, the nightly builds have a newer \"true\" version than the last publicly released TFLite builds (in this case, 2.3). That is, `org.tensorflow:tensorflow-lite:0.0.0-nightly` corresponds to an AAR package that has both the Java and C++ code (libtensorflowlite_jni.so) that contains the TFLite implementation. That library gets statically linked into your app, so it won't be using libtflite.so from your OS (which isn't a true Android platform library).", "I see now. Thank you very much for your detailed explanation. "]}, {"number": 42175, "title": "ValueError: Data cardinality is ambiguous. No issue in version 2.0.0 but fails with 2.2.0/2.3.0", "body": "### Functional API Multi input/output model works correctly in TF 2.0.0 but fails with TF 2.2.0 and 2.3.0\r\n\r\n**Describe the current behavior**\r\nCreated a Multi Input/Output model using the functional api.\r\nmodel.fit fails with the following error:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-20532c7b88ab> in <module>()\r\n     11 print('x',np.asarray(x).shape)\r\n     12 print('y',y.shape)\r\n---> 13 model.fit(x,y,epochs=1)\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\r\n    280             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\r\n    281       msg += \"Please provide data which shares the same first dimension.\"\r\n--> 282       raise ValueError(msg)\r\n    283     num_samples = num_samples.pop()\r\n    284 \r\n\r\nValueError: Data cardinality is ambiguous:\r\n  x sizes: 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224\r\n  y sizes: 2\r\nPlease provide data which shares the same first dimension.\r\n```\r\nColab Github Gist: https://colab.research.google.com/gist/sramakrishnan247/0897350c315280935b1617e325665c08/tf2-3-issue.ipynb\r\n\r\n**Describe the expected behavior**\r\nmodel.fit should work successfully (similar to tensorflow 2.0.0)\r\n```\r\nx (10, 2, 224, 224, 20)\r\ny (2, 3)\r\nTrain on 2 samples\r\n14/2 [==================================================================================================================================================================================================================] - 34s 2s/sample - loss: 1.4392\r\n<tensorflow.python.keras.callbacks.History at 0x7f444928b048>\r\n```\r\nColab Github gist: https://colab.research.google.com/gist/sramakrishnan247/08becc3e024ad21a2b90fa2ebabcfe76/tf2-0-sample.ipynb", "comments": ["@sramakrishnan247,\r\nIn order to expedite the trouble-shooting process, please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!\r\n", "@amahendrakar \r\nCreated Colab sample files for 2.0.0 and 2.3.0 for reproducibility. Please check.", "@sramakrishnan247,\r\nI do not have the permission to view the files. Please try saving the Gist using the following method 'File' -> 'Save a copy as Github Gist', and share the link of the new window. Thanks!", "@amahendrakar Fixed it!\r\nPlease check. Thanks!", "Was able to reproduce the issue. \r\n\r\nCode works fine with [TF v2.0](https://colab.research.google.com/gist/amahendrakar/671050dc6cd79a0ca135757a208f4c74/42175-2-0.ipynb). Facing a `ValueError` on running with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/d549faa23c1d6c4f599379696ff27b40/42175.ipynb#scrollTo=R4ExMVpez7S3) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/87aac4f378f62d74ea766f8e3223145d/42175-tf-nightly.ipynb). \r\n\r\nPlease find the attached gist. Thanks!", "@sramakrishnan247 Thanks for the issue!\r\n\r\nThe issue you're running into is bc you're passing a list-of-lists for `x`. We dropped support for treating inner lists as `Tensor`s bc it's ambiguous as to whether a list should be interpreted as a `Tensor` or as a Python list (as this example shows). Instead, you can pass a list of `np.array`s like this:\r\n\r\n```python\r\nx = []\r\nfor i in range(10):\r\n  x.append([])\r\ndata = np.random.rand(2,10,224, 224, 20)\r\nfor data_vector in data:\r\n  for index in range(10):\r\n    x[index].append(data_vector[index]) \r\n\r\nfor i in range(10):\r\n  x[i] = np.asarray(x[i]) \r\n   \r\ny = np.random.rand(2,3)\r\nprint('x',np.asarray(x).shape)\r\nprint('y',y.shape)\r\nmodel.fit(x,y,epochs=1)\r\n```\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42175\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42175\">No</a>\n", "@omalleyt12 \r\nThanks! "]}, {"number": 42174, "title": "some question about grpc+verbs and grpc+gdr", "body": "when i use gdr, but the server_protocol can be use grpc+gdr or grpc+verbs.\r\ni followed this script, and nv_peer_mem is loaded.\r\n[gdr](https://github.com/tensorflow/tensorflow/tree/v1.8.0/tensorflow/contrib/gdr)\r\nbut the performance of grpc+gdr is worse, why?", "comments": ["@DeruiLiu \r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!"]}]