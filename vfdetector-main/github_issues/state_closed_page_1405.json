[{"number": 10835, "title": "Gradient of reduce_prod does not support negative axis", "body": "The gradient of `reduce_prod` does not support negative axis unlike `reduce_prod` itself.\r\nIt is apparently caused by `gather` not supporting negative axes.\r\nThis code illustrates the problem.\r\n```python\r\nimport tensorflow as tf\r\n\r\nvars = tf.Variable([[1., 2.], [3., 4.]])\r\nprod = tf.reduce_prod(vars, -1) # Negative axis here\r\n\r\ntf.InteractiveSession()\r\ntf.global_variables_initializer().run()\r\nprint(prod.eval()) # Works fine\r\nprint(tf.gradients(prod, vars)[0].eval()) # Crashes\r\n```", "comments": ["Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks (e.g. platform, version, etc). Thank you.", "I have had this bug using Tensorflow 1.2.0 (CPU) both installed using pip3 and from source.\r\nI am running MacOS 10.12.5.", "Thanks for the bug report @pvanhaes.  I've reproduced the issue, and agree with your analysis.\r\n\r\nI think there are two ways to fix this; we can either:\r\n1. Ensure that `tf.reduce_*` resolves negative axis arguments into positive (in-range) arguments (see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L1190), or\r\n2. Change `tf.gather` to allow negative indices\r\n\r\nI think (2) sounds reasonable.  Assigning to @ebrevdo, who seems to have some familiarity with `tf.gather`.", "Option 2 does sound reasonable.  Not sure when I'll get to this though.\nWant to try submitting a PR that converts negative values within the proper\nrange to valid positive values?\n\nOn Jun 20, 2017 10:02 AM, \"Todd Wang\" <notifications@github.com> wrote:\n\n> Thanks for the bug report @pvanhaes <https://github.com/pvanhaes>. I've\n> reproduced the issue, and agree with your analysis.\n>\n> I think there are two ways to fix this; we can either:\n>\n>    1. Ensure that tf.reduce_* resolves negative axis arguments into\n>    positive (in-range) arguments (see https://github.com/tensorflow/\n>    tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L1190\n>    <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L1190>),\n>    or\n>    2. Change tf.gather to allow negative indices\n>\n> I think (2) sounds reasonable. Assigning to @ebrevdo\n> <https://github.com/ebrevdo>, who seems to have some familiarity with\n> tf.gather.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10835#issuecomment-309822625>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim2nKJ6AIIyuEbF-Nela4x6KhFrasks5sF_regaJpZM4N-xOO>\n> .\n>\n", "Cool, thanks for the comment @ebrevdo!\r\n\r\n@pvanhaes, would you like to submit a PR?  I'm marking this as \"contributions welcome\", so that others who are interested may also find this issue.", "Can I work on this?", "Yes sounds good.\n\nOn Jun 23, 2017 7:26 AM, \"Anish Shah\" <notifications@github.com> wrote:\n\n> Can I work on this?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10835#issuecomment-310679439>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzGPLkpXpKytv7-dnGeD4sDzv86-ks5sG8sLgaJpZM4N-xOO>\n> .\n>\n", "After I added negative axis support for `tf.gather`, it throws error because `tf.invert_permutation` doesn't support negative axis. Should I do the same for `tf.invert_permutation`?", "The main problem is in [_ProdGrad function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L127)\r\n\r\nThis is the snippet of _ProdGrad. In the comment, I have added an example where this fails.\r\n```\r\nreduced = math_ops.cast(reduction_indices, dtypes.int32) # [-1]\r\nidx = math_ops.range(0, array_ops.rank(op.inputs[0])) # if rank is 2, then [0, 1]\r\nother, _ = array_ops.setdiff1d(idx, reduced)  # others = [0, 1]\r\nperm = array_ops.concat([reduced, other], 0) # [-1, 0, 1] (size is 3, which is greater than rank. throws error in transpose)\r\n```\r\n`tf.setdiff1d` is getting a list of `range(0, rank(input))` and list of reduction indices which contains negative axis. So, `perm` list contains `range(0, rank(input))` and negative indices. This is used to `tf.transpose` and it throws error because the dimensions don't match. \r\n\r\nI hope I make sense.\r\n\r\nI think, the best way to solve this would be in this function itself.", "This output is from tensorflow `master` branch. Except `reduce_prod`, all `reduce_*` & its gradient op work perfectly for negative axis.\r\n\r\n```\r\nIn [1]: import tensorflow as tf\r\n\r\nIn [2]: vars = tf.Variable([[1., 2.], [3., 4.]])\r\n\r\nIn [3]: tf.InteractiveSession()\r\n2017-06-24 00:12:38.861801: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-24 00:12:38.861832: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-24 00:12:38.861845: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-24 00:12:38.861854: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-24 00:12:38.861864: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nOut[3]: <tensorflow.python.client.session.InteractiveSession at 0x7f4145d54510>\r\n\r\nIn [4]: tf.global_variables_initializer().run()\r\n\r\nIn [5]: print(tf.gradients(tf.reduce_max(vars, -1), vars)[0].eval())\r\n[[ 0.  1.]\r\n [ 0.  1.]]\r\n\r\nIn [6]: print(tf.gradients(tf.reduce_min(vars, -1), vars)[0].eval())\r\n[[ 1.  0.]\r\n [ 1.  0.]]\r\n\r\nIn [7]: print(tf.gradients(tf.reduce_mean(vars, -1), vars)[0].eval())\r\n[[ 0.5  0.5]\r\n [ 0.5  0.5]]\r\n\r\nIn [8]: print(tf.gradients(tf.reduce_sum(vars, -1), vars)[0].eval())\r\n[[ 1.  1.]\r\n [ 1.  1.]]\r\n\r\nIn [9]: print(tf.gradients(tf.reduce_logsumexp(vars, -1), vars)[0].eval())\r\n[[ 0.26894143  0.7310586 ]\r\n [ 0.26894143  0.7310586 ]]\r\n\r\n```"]}, {"number": 10834, "title": "I am New To Tensorflow How To learn can anyone Provide Step by Step Process", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["https://www.tensorflow.org/get_started/\r\nFor more targeted questions on how to use TensorFlow, use Stackoverflow.\r\nGood luck!"]}, {"number": 10833, "title": "Remove TensorBoard codebase from TensorFlow.", "body": "TensorBoard can now be found in its own repo:\r\nhttps://github.com/tensorflow/tensorboard", "comments": []}, {"number": 10832, "title": "Error compiling in Linux Mint ", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18\r\n- **TensorFlow installed from (source or binary)**: Installed from Source\r\n- **TensorFlow version (use command below)**: Error generated when running below command\r\n- **Bazel version (if compiling from source)**: Bazel 0.5.1\r\n- **CUDA/cuDNN version**: Unknown\r\n- **GPU model and memory**: No GPU\r\n- **Exact command to reproduce**: sudo bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\n### Describe the problem\r\nError when trying to build from source with Bazel.  Following error code generated:\r\nWARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/BUILD:48:1: error executing shell command: 'JAR='external/local_jdk/bin/jar' OUTPUT='bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar' PROTO_COMPILER='exter...' failed: bash failed: error executing command\r\n(cd /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/execroot/tensorflow && \r\nexec env - \r\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \r\n/bin/bash -c 'JAR='''external/local_jdk/bin/jar''' OUTPUT='''bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar''' PROTO_COMPILER='''external/com_google_protobuf_protoc/bin/protoc''' SOURCE='''external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/build_info.proto''' INCLUDES='''-I. -Iexternal/io_bazel_rules_closure''' bazel-out/host/bin/external/io_bazel_rules_closure/closure/private/gensrcjar'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nexternal/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: cannot create \ufffd\ufffd/@@\ufffd\ufffd: Directory nonexistent\r\nexternal/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: \ufffdELF\ufffd\ufffd\ufffd\ufffd\ufffd: not found\r\nexternal/com_google_protobuf_protoc/bin/protoc: 2: external/com_google_protobuf_protoc/bin/protoc: Syntax error: \")\" unexpected\r\ngensrcjar: proto_compiler failed\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 339.557s, Critical Path: 54.04s\r\n\r\n### Source code / logs\r\nLog/Error above.\r\n\r\nLet me know if you need more information.", "comments": ["Hi, I'm experiencing the same issue. Did you make any progress on this problem?\r\nHowever, the 1.2.0 version compiles just fine for me.", "What branch version did you use to compile this? Also did switching to the 1.2 branch help?", "I believe I am already on 1.2.0, but correct me if I'm wrong?\r\n\r\ngit describe --tags:\r\nv1.2.0-rc0-872-gbbb81bd\r\n\r\nThanks", "When I am on master (today) I see v1.2.0-1392-g8bfbc12e1 which is 8bfbc12e19f7e98ec3525eacf06a2cb75b4fc482\r\nCould you update to a version newer than that and see if it is a still problem.\r\n\r\n\r\n", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 10831, "title": "Documentation fix: Referencing correct pip in installation examples", "body": "The examples are supposed to be for Python2.7 so it makes sense that they refer to the correct pip (pip instead of pip3) to avoid any potential confusion.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 10830, "title": "Performance improvements for hessians.", "body": "This PR improves the performance of `hessians` by using `while_loop` instead of using a `for` loop in python. This improves both the build time (to create the graph) and the evaluation time. Full details are [here](https://gist.github.com/tillahoffmann/003f3bcb9639a18253ec7854abcbea01).\r\n\r\n![image](https://user-images.githubusercontent.com/966348/27299092-06e6dc52-5523-11e7-84ff-5972d7490a89.png)\r\n", "comments": ["@alextp do you remind reviewing this change? Thanks!", "Jenkins, test this please."]}, {"number": 10829, "title": "Java API does not include quantize operations", "body": "When trying to run a quantized model with the Tensorflow Java API in version 1.2-rc0, I get the following exception in Java:\r\n\r\n```\r\njava.lang.IllegalArgumentException: No OpKernel was registered to support Op 'QuantizeV2' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: encoder/encoder_layer_0/Conv2D_eightbit_quantize_normalize/sub = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\"](normalize/sub, encoder/encoder_layer_0/Conv2D_eightbit_min_normalize/sub, encoder/encoder_layer_0/Conv2D_eightbit_max_normalize/sub)]]\r\n\r\n\tat org.tensorflow.Session.run(Native Method)\r\n\tat org.tensorflow.Session.access$100(Session.java:48)\r\n\tat org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n\tat org.tensorflow.Session$Runner.run(Session.java:245)\r\n\t...\r\n```\r\n\r\nIt seams the kernels for quantized graphs are not included in the Java API binary of tensorflow. Can you add these kernels?\r\n\r\nNote: The frozen model I used to create the quantized model runs perfect with the same code.\r\nNote2: I quantized the graph with the current r1.2 branch of tensorflow.", "comments": ["@asimshankar, could you comment?", "@andreas-eberle : The `QuantizeV2` op should be linked in with the Java JNI distribution. Is it possible that you're somehow using an older version of the TensorFlow Java native library?\r\n\r\nTo validate and simulate the environment you're in, I tried the following:\r\n\r\n1. Construct a graph in Python\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.placeholder(tf.float32, name='input')\r\nq, mn, mx = tf.quantize_v2(x, 0., 100., tf.quint8)\r\ny = tf.dequantize(q, mn, mx, name='output')\r\nwith open('/tmp/graph.pb', 'w') as f:\r\n  f.write(tf.get_default_graph().as_graph_def().SerializeToString())\r\n```\r\n\r\n2. Load and execute this graph in a Java program:\r\n\r\n```java\r\nimport org.tensorflow.*;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Paths;\r\n\r\npublic class HelloTF {\r\n  public static void main(String[] args) throws Exception {\r\n    try (Graph g = new Graph()) {\r\n      g.importGraphDef(Files.readAllBytes(Paths.get(\"/tmp/graph.pb\")), \"\");\r\n      try (Session s = new Session(g);\r\n          Tensor input = Tensor.create(50.0f);\r\n          Tensor output = s.runner().feed(\"input\", input).fetch(\"output\").run().get(0)) {\r\n        System.out.println(output.floatValue());\r\n        System.out.println(\"TensorFlow Version: \" + TensorFlow.version());\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nExecuting the Java program seemed to work out fine, executing the quantize and dequantize operations and printing:\r\n\r\n```\r\n50.19608\r\nTensorFlow Version: 1.2.0\r\n```\r\n\r\nCould you try the same in your setup? If you get the same error as you do now, is there some instructions to reproduce that you can share?\r\n\r\nThanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 10828, "title": "add log_softmax c++ gradient", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@andydavis1 mind taking a look? Thanks!", "Thanks for the contribution!", "@tensorflow-jenkins test this please", "@andydavis1 Sorry, this is failing - I am not exactly sure why, as the gradient computation looks correct (comparing to the python [version](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_grad.py#L217)). I am fairly new to c++ so it's very possible there is something I haven't considered in how these ops are applied. If you have any ideas, happy to poke around!", "It looks like tensorflow/cc:gradients_nn_grad_test is failing. Can you run that locally and see what the error is?", "```\r\n[       OK ] NNGradTest.SoftmaxGrad (98 ms) \r\n[ RUN      ] NNGradTest.LogSoftmaxGrad \r\ntensorflow/cc/gradients/nn_grad_test.cc:39: Failure \r\nExpected: (max_error) < (1e-4), actual: 0.000244878 vs 0.0001 \r\n[  FAILED  ] NNGradTest.LogSoftmaxGrad (90 ms) \r\n[ RUN      ] NNGradTest.ReluGrad \r\n[       OK ] NNGradTest.ReluGrad (8 ms) \r\n[ RUN      ] NNGradTest.Relu6Grad \r\n[       OK ] NNGradTest.Relu6Grad (7 ms) \r\n[ RUN      ] NNGradTest.EluGrad \r\n[       OK ] NNGradTest.EluGrad (8 ms) \r\n[----------] 5 tests from NNGradTest (211 ms total)\r\n```\r\nHmm, looks like just a finite differences error. \r\n", "Maybe try reducing the size of the dimension that gets reduced for your unit test case.  Also, some gradients can be sensitive to initial value when the gradient check is used, so you play with 'x_init_value' (see ReluGrad for an example). ", "@andydavis1 Thanks, that fixed it, tests passing locally.", "@tensorflow-jenkins test this please."]}, {"number": 10827, "title": "version 1.2 doesn't show CUDA and cuDNN information", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 5.1\r\n- **GPU model and memory**: GTX 970M, 3GB\r\n\r\n### Describe the problem\r\nIn previous version, after importing tensorflow like `import tensorflow as tf` following output will be shown:\r\n```\r\n>>> import tensorflow as tf;\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally\r\n```\r\nHowever, after I installed CUDA and cuDNN, and then installed Tensorflow v1.2, I found there is NO output for `import tensorflow as tf` in python. And I cannot check whether gpu successfully uses CUDA or cuDNN.\r\nI have checked my GPU as follows and GPU works well. I have tried the method in #566 to adjust `TF_CPP_MIN_LOG_LEVEL`, but it seems have no effect.\r\nI suggest it would be great to include CUDA and cuDNN info when importing tensorflow.\r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> sess = tf.Session()\r\n2017-06-20 00:24:38.111017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-20 00:24:38.111060: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-20 00:24:38.111074: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-20 00:24:38.111086: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-20 00:24:38.111097: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-20 00:24:38.215890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-06-20 00:24:38.216159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \r\nname: GeForce GTX 970M\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.038\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.95GiB\r\nFree memory: 2.63GiB\r\n2017-06-20 00:24:38.216174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \r\n2017-06-20 00:24:38.216180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \r\n2017-06-20 00:24:38.216191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)\r\n```\r\n", "comments": ["@TengdaHan I've reproduced your issue on TF 1.2.0.\r\n\r\nThis is odd, since the code to dump the \"successfully opened CUDA library ...\" code still seems to exist:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/dso_loader.cc#L139\r\n\r\n@zheng-xq might know more about why these log messages aren't showing up.  I'm suspecting that either the dso_loader.cc code isn't actually being used anymore, or there's some weird interaction with the logging system at the time the shared libraries are being loaded.", "I got the same question with you,since I installed tensorflow-gpu yestarday.The tf version is 1.2,and my gpu card is gtx1060. Although the CUDA and cuDNN info is not shown,  it seems that the GPU is  still working , my demo is running much faster then before.\r\nHowever, I just want to make sure too.", "Facing this as well in 1.2, I have a GTX 1080. I get no output on `import tensorflow as tf`, but when I put `log_device_placement=True` I get the CPU-can-be-sped-up instructions (SSE etc) and device mappings. It does look like GPU is being used though from my mappings, but still, I don't get the 'opened CUDA' logs.", "@liangxiao05 Yes, I also feel GPU is working well, but just prefer to have the info.", "hi @puneith do you know of this?", "same problem here! with tensorflow 1.2.0", "Same problem on tensorflow-gpu==1.3.0rc0", "I'm facing the same issue too tensorflow-gpu==1.2.1", "I'm faceing the same issue when i update tensorflow-gpu to the version of 1.3.0. Also, it produces an error which shows the version of 1.3.0 need cudnn 6. So i updated the cudnn to the version of 6.0.21 and it produced this issue. After that, i reinstall ubuntu and install anaconda in order to install the old version of tensorflow. But it doesn't work. Now i'm not sure if the gpu is running.", "I am also facing the same issue, as we end up in a confusion whether it is using CUDA or not.", "same issue", "i have same issue   \r\ntensorflow - 1.4.0\r\ntensorflow-gpu - 1.4.0\r\nGeForce GTX 980 TI \r\ncuda_8.0 \r\ncudnn-8.0 -v6\r\n", "same issue in 1.4.0", "Any thoughts on this @zheng-xq, or suggestions for who might know more?", "Adding @jlebar, the owner of stream_executor", "Hi, folks.\r\n\r\nLoading the CUDA shared libraries is fraught, and complex.  Sometimes we go through this DSO loader, sometimes we can get the shared library through more normal means, sometimes we have to use static libraries.  Frankly I have trouble keeping it all straight.\r\n\r\nI don't know offhand what changed back in June, but I don't think relying on these log messages from the DSO loader is the right way for you all to tell whether CUDA support is working, since, as you've observed, we can load the libraries *without* going through the DSO loader.\r\n\r\nIt seems reasonable to me that TF might want to print a log message indicating that CUDA support is enabled and working.  That's a question for someone higher up in the stack than myself, so, back to XQ to figure that out.  Or, I suppose, someone here could just send a patch.  :)", "I think that a reasonable approach would be to expose APIs to get versions and if these libraries were loaded or not, it would be the cleaner option here in my opinion, instead of just dumping log messages. If someone wants to print something, he can get all the info from API.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I agree with @jlebar on not relying on the log messages from the DSO loader. It seems that there are two possible solutions to this issue: either adding a log message indicating CUDA support is enabled at a higher level or providing an API for users to retrieve these info. Both solutions would require poking around with stream executor code. Please refer to comments in https://github.com/tensorflow/tensorflow/issues/4090 to find out why currently in TensorFlow there is not an API for retrieving CUDA related library info. I will add  \"contributions welcome\" label for this issue as I do not have any cycle to work on this in the near future.", "same issue, and the training process seems really slow", "@XingyuGuUCSD I think the slow training process is probably another issue. When you say slow, what are you comparing to? Also, could you verify that you have correctly set the GPU support during the configuration and have put nodes on the GPU when building the graph? If you believe the slow training process is an issue, please search for other similar ones or open a new one with more detailed logging info, so that we can take a look. Thank you!", "@yzhwang I just update tensorflow and cuda. The GPU-util is high, while the training process is slower, compared with the previous same training program. And the log shows no info for cudnn and  gpu. Thus, I think it may be the problem with the cudnn", "@XingyuGuUCSD Since this issue is about cuda/cudnn logging, it has nothing to do with performance regression. Please do feel free to open up a new issue for others to investigate. Thank you.", "A quick hack that might be useful:\r\n`python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib() + \"/python/_pywrap_tensorflow_internal.so\")' | xargs ldd`", "> A quick hack that might be useful:\r\n> `python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib() + \"/python/_pywrap_tensorflow_internal.so\")' | xargs ldd`\r\n\r\nThanks a lot! Unfortunately, (as with many hacks) this stops working for TF 2.x.  I have not found another hack yet; all .so I found in the TF libs directory (which are also fewer than with 1.13.1) do not link against libcudnn.so; maybe it is now dynamically dlopened.", "for ubuntu 16.04 this worked:\r\n```\r\ndef get_cudnn_version():\r\n    S = check_output(\r\n        'cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2', shell=True)\r\n    N = [int(s) for s in S.split() if s.isdigit()]\r\n    V = f'{N[0]}.{N[1]}.{N[2]}'\r\n    print(V)\r\n    return V\r\n```\r\n\r\n> 7.6.3\r\n\r\nmight need to use `/usr/local/cuda/include/cudnn.h`", "Closing as TF 1.2 is old and no longer supported."]}, {"number": 10826, "title": "ResourceExhaustedError : OOM when allocating tensor with shape", "body": "### The problem\r\n\r\nI try to compute a very costly loss function using FFT2D, rolling of the tensor and neural network with 3 layers. \r\nYou can find the Python script here : [TestFFT2D_2.py](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D_2.py)\r\n\r\nMy loss function is the sum of 448 terms. Each of this term is computed with a rolling of the initial tensor, FFT2D, a multiply of two tensor and a IFFT2D. That is why it is very costly and why it needs a lot of memory. \r\n \r\nYou can find the end of the error message here : \r\n[MemoryError.txt](https://github.com/tensorflow/tensorflow/files/1084875/MemoryError.txt)\r\n\r\nDo you know why the GPU is not able to deal with a memory demanding code ? Do you know a way to avoid this error message even if we need to pay a computing time cost ?\r\n\r\nDo you think I need to do a feature request for a better management of the GPU memory ? \r\n\r\n### System information\r\n- **Have I written custom code **: TestFFT2D.py\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: Source\r\n- **TensorFlow version**: 1.2\r\n- **CUDA/cuDNN version**:\r\nCuda compilation tools, release 7.5, V7.5.17 and  cuDNN  5 with the GeForce GTX 680\r\n- **GPU model and memory**: Tested on GeForce GTX 680 with 2Go\r\n- ** Python version**: Python 3.6.1 |Anaconda 4.4.0 (64-bit)|\r\n- **Exact command to reproduce**: python TestFFT2D_2.py\r\n\r\n", "comments": ["_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nHaving a quick look at your code and your hardware I think that it's down to not having enough GPU memory. 2GB is really not very much. Can you please run nvidia-smi alongside your code to see whether anything else has a lock on your GPU memory? Perhaps something else is using it?\r\nIf you run on CPU only do you run out of memory?\r\nAs far as I know, Tensorflow smartly manages the GPU memory and has ways of dealing with these kind of issues. However in my experience I have found that I will get an OOM error when something else is using the GPU and there isn't enough memory to even get started/initialised. Unfortunately I think that the answer is you need more memory or check that it's free. You'll probably get more luck on Stack Overflow. ", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 10825, "title": "Variable name typo", "body": "In the \"Working example: Tracking Multiple Metrics\", the variable name \"name_to_updates\" --> \"names_to_updates\"", "comments": ["Can one of the admins verify this patch?", "Thank you @callofdutyops!"]}, {"number": 10824, "title": "Constant operator is not appropriate for variable initialize", "body": "Tensorflow uses const tensor to initialize variables(for example ones_initializer, zeros_initializer and some optimizer slot creation), this will prevent `AssignOp `to transfer ownership from rhs to lhs and waster a lot of memory when variable shape is very large(for example sparse model). see #9823 #9742", "comments": ["I don't understand the problem. Ones_initializer and zeros_initializer don't store a constant with a bunch of zeros or ones in them. What alternative are you suggesting?\r\n", "@aselle I saw ones_initializer and zeros_initializer have been changed in latest version, I haven't read the latest code carefully. But for v1.0.1, https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/python/ops/init_ops.py#L62, ones_initializer and zeros_initializer calls constant_op.constant to create constant tensors storing a bunch of ones and zeros inside them. Constant tensors prevent assign op to transfer buffer ownership from input tensor to input variable.\r\n\r\n`a = tf.get_variable(\"BigVar\", [1024 * 1024 * 1024], dtype=tf.float32, initializer=tf.zeros_initializer(dtype=tf.float32))` will first create one constant tensor with shape [1024 * 1024 * 1024], then assign it to variable \"BigVar\", assign op can't transfer buffer ownership from the constant tensor to \"BigVar\" even it's only used for creating \"BigVar\" because constant tensor reference count is always greater than 1. This wastes a lot of memory when creating very large variables.\r\nMy suggestion is adding operators creating non-constant tensors for one_initializer and zeros_intializer, then assign op could try it's best to avoid memory copy.", "You are right unfortunately that the initializer is making a large constant. @jhseu I see you have been making changes here recently: any thoughts of how to e.g. make it broadcast from a scalar instead?", "Yeah, I don't think there's a way to avoid the extra memory usage right now.\r\n\r\nIt's probably worth updating AssignOp to have an attr option that allows broadcasting, matching [XLA's broadcasting semantics](https://www.tensorflow.org/performance/xla/broadcasting). Then the initializer can use a scalar constant.\r\n\r\nI'll mark this as contributions welcome.", "#9823 was already solved by the general solution. I will first create non-const ones/zeros initilizer to leverage assign op memory reuse; then implement the broadcasting if still have time.", "Hi, Is your issue resolved? If yes, can you close this issue. Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/10824\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/10824\">No</a>\n"]}, {"number": 10823, "title": "Excessive chatter in VLOG(1)", "body": "IMO:  tensorflow/core/framework/op.cc:82 is rather a chatty and specific output to be included at VLOG(1).\r\n\r\nCould it be changed to VLOG(2) or better still VLOG(3)\r\n\r\none person's useful output is 100's of peoples noise.\r\n", "comments": ["Not in TF team, but I guess there's a reason to name VLOG differently from LOG :)\n\nJokes aside, you should consider writing some scripts to analyze the VLOG. It's really not for looking into with you bare eyes.", "I would expect a PR moving it to higher VLOG levels to be swiftly approved."]}, {"number": 10822, "title": "py_func returning string leaks memory", "body": "TF version: 1.2.0\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.InteractiveSession()\r\ns = b' '*1000000\r\nx = tf.py_func(lambda: s[1:], [], tf.string) # leaks\r\n# x = tf.py_func(lambda: s, [], tf.string) # does not leak\r\n# x = tf.py_func(lambda: len(s[1:]), [], tf.int64) # does not leak\r\nwhile True:\r\n    x.op.run()\r\n```", "comments": ["cc @alextp \r\n\r\nThis is fixed in the master branch by \r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/27f1b80c22115f134fd959a7c0fe013a21784795\r\n\r\nBut the fix is not in 1.2. So please either use the nightly builds (see home README.md for download addresses) or wait for 1.3."]}, {"number": 10821, "title": "Fixed XLA for integration as submodule", "body": "This PR incorporates some of the known workarounds like str(Label(...)) to enable the integration as a git submodule when using XLA.\r\n\r\nThis was only tested on a macOS environment with a project using tf_library.\r\nMaybe someone with his/her own xla project could cross check this.", "comments": ["Can one of the admins verify this patch?", "@hawkinsp mind taking a look? Thanks!", "@fwinnen could you sync and push again?", "synced", "Sorry, could you sync yet again?", "@jart do you know anything about the `str.Label` trick? Is that something we'd like to integrate?", "@fwinnen it's still out sync. Could you push again?", "Sorry, was working on something else and pushed first file to wrong branch", "Jenkins, test this please.\n\nOn Jul 6, 2017 2:36 AM, \"fwinnen\" <notifications@github.com> wrote:\n\n> Sorry, was working on something else and pushed first file to wrong branch\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10821#issuecomment-313346637>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbZSZkiCHkDxKpm-SB5olCaCKvWo8ks5sLKqsgaJpZM4N-FKm>\n> .\n>\n", "Jenkins, test this please.", "@fwinnen \r\n\r\n```ERROR: /workspace/tensorflow/compiler/aot/tfcompile.bzl:282:47: syntax error at ':': expected ,\r\nERROR: error loading package 'tensorflow/compiler/aot': Extension 'tensorflow/compiler/aot/tfcompile.bzl' has errors.\r\nINFO: Elapsed time: 1.908s\r\nERROR: Couldn't start the build. Unable to run tests.```", "Basically this PR introduces two changes:\r\n\r\n1) use str(Label(...)) to fix problem with //tensorflow... not found when in submodule. This was not invented by me. I just applied the idea from #8606 (which is in master already) to xla.\r\n\r\n2) fix the import path for llvm.", "Jenkins, test this please.", "Sorry, there appears to be a conflict, can you take a look @fwinnen ?", "@fwinnen can you rebase your PR and address the comments?", "I am on vacations, will have a look at this next week. Thx", "Since the changes for llvm are already in upstream, its only a smaller change now.", "@rmlarsen @vrv @hawkinsp small ping to let you know it should be ready to be merged.", "@rmlarsen @vrv @hawkinsp resolved conflicts", "Jenkins, test this please."]}, {"number": 10820, "title": "how to compile tensorflow for sse4.1 sse 4.2, avx, and sycl?", "body": "how can i compile tensorflow for sse4.1 sse 4.2, avx, and sycl?\r\nis there some guide available online?", "comments": ["For SSE and AVX, just add ` -copt=-msse4.1 -copt=-mavx` to your `bazel build` options. SYCL I believe requires you to manually set the `OpenCL` switch when running `./configure`, but I could be wrong.", "Also `-copt=-msse4.2`, but you get the idea.", "thank you @byronyi ", "The following guide will help for SYCL. \r\nhttps://www.codeplay.com/products/computesuite/computecpp/guides/how-to-setup-tensorflow-with-computecpp"]}, {"number": 10819, "title": "Tensorflow Android API version 1.2 not in JCenter", "body": "The freshly released version 1.2 of the tensorflow APIs is not yet fully available in JCenter ( https://bintray.com/google/tensorflow/tensorflow-android/1.2.0). There is a version 1.2.0 but it does not contain any files. \r\n\r\nCan you push these files to the repository?", "comments": ["@petewarden, I have no idea if we support this or about JCenter in general. Could you point me to the right direction or right person?", "Shawn has created the listing\n<https://bintray.com/google/tensorflow/tensorflow-android/1.2.0> for it, so\nI believe he just needs to upload the AAR and pull the switch to make it\nthe latest version now.\n\nOn Jun 19, 2017 12:51 PM, \"Andrew Selle\" <notifications@github.com> wrote:\n\n> @petewarden <https://github.com/petewarden>, I have no idea if we support\n> this or about JCenter in general. Could you point me to the right direction\n> or right person?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10819#issuecomment-309499784>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADOGsRvLhxtp_0jvY6A5LAPKuyVmIcOtks5sFqcdgaJpZM4N-BBe>\n> .\n>\n", "1.2.0 files for TF Android are now available on JCenter!"]}, {"number": 10818, "title": "Implemented selu activation #10612", "body": "This pull request implements the SELU activation function. The activation function works properly when training a simple MLP for digit recognition. But, the following test fails: `//tensorflow/python/kernel_tests:relu_op_test`. This happens due to large error when checking the gradient of gradient. The log is show below:\r\n\r\n```\r\n======================================================================\r\nFAIL: testGradGradFloat32 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 375, in testGradGradFloat32\r\n    self.assertLess(err, 1e-4)\r\nAssertionError: 0.080660700798034668 not less than 0.0001\r\n\r\n======================================================================\r\nFAIL: testGradGradFloat64 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 393, in testGradGradFloat64\r\n    self.assertLess(err, 1e-6)\r\nAssertionError: 0.080654564805808127 not less than 1e-06\r\n\r\n----------------------------------------------------------------------\r\nRan 30 tests in 0.377s\r\n\r\nFAILED (failures=2)\r\nelu (float32) gradient of gradient err =  1.90436840057e-05\r\nelu (float64) gradient of gradient err =  1.50806227728e-07\r\nelu (float32) gradient err =  1.90436840057e-05\r\nelu (float64) gradient err =  1.50806227728e-07\r\nrelu6 (float32) gradient err =  0.0\r\nrelu6 (float64) gradient err =  0.0\r\nrelu (float32) gradient of gradient err =  0.0\r\nrelu (float64) gradient of gradient err =  0.0\r\nrelu (float32) gradient err =  1.29342079163e-05\r\nrelu (float64) gradient err =  8.881784197e-16\r\nselu (float32) gradient of gradient err =  0.080660700798\r\nselu (float64) gradient of gradient err =  0.0806545648058\r\nselu (float32) gradient err =  4.69088554382e-05\r\nselu (float64) gradient err =  2.65132328758e-07\r\n```\r\nAny help in resolving this issue is appreciated.", "comments": ["Can one of the admins verify this patch?", "@josh11b would you be available to review this PR? Thanks!", "Jenkins, test this please.", "This would require an API change.\r\n\r\n@ebrevdo what do you think? This is adding a \"SELU\" activation.", "@drpngx  Not sure why this test fails `//bazel_pip/tensorflow/python/kernel_tests:sparse_reshape_op_test`.\r\n\r\n`//bazel_pip/tensorflow/python/kernel_tests:relu_op_test` This test is failing as I reported in the PR comment. I haven't been able to fix this problem. Any hints / suggestions will be very helpful.", "Are you sure it's correct? The error on the gradient seems rather large.\r\n\r\n```\r\n======================================================================\r\nFAIL: testGradGradFloat32 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 375, in testGradGradFloat32\r\n    self.assertLess(err, 1e-4)\r\nAssertionError: 0.080660700798034668 not less than 0.0001\r\n\r\n======================================================================\r\nFAIL: testGradGradFloat64 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 393, in testGradGradFloat64\r\n    self.assertLess(err, 1e-6)\r\nAssertionError: 0.080654564805808349 not less than 1e-06\r\n\r\n-------\r\n```", "@drpngx I reckon that the error is large but I believe that the derivatives are correct. I will take a look again. On the other hand, a network for the MNIST dataset converges successfully using this activation function.", "This gives large errors when computing gradient of gradient. I looked into the file containing `_SeluGradGrad` (tensorflow/python/ops/nn_grad.py) and it looks alright. Does the failing test function use this to compute the gradient of gradient?", "Approval for api-review", "Jenkins, test this please.", "The failure in 'Linux CPU Tests' is due to `//tensorflow/tools/api/tests:api_compatibility_test`. This test passes on my machine, not sure why this is failing.\r\n\r\nI followed the steps from the console log but it does not seem to change anything\r\n```\r\nERROR:tensorflow:TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nERROR:tensorflow:Issue 1\t: Change detected in python object: tensorflow.nn.\r\nF.\r\n```\r\n\r\nThis is the error in `Linux XLA`:\r\n```\r\nERROR: /workspace/tensorflow/core/BUILD:1428:1: Couldn't build file tensorflow/core/_objs/framework_internal/tensorflow/core/util/port.o: undeclared inclusion(s) in rule '//tensorflow/core:framework_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/util/port.cc':\r\n  'bazel-out/host/genfiles/external/local_config_cuda/cuda/include/cuda.h'.\r\n```\r\nI am not sure what is causing these failure.\r\n\r\nAny help is appreciated. @drpngx ", "It's an API change. You have to follow the instructions and update the\ngolden files\n\nOn Jul 19, 2017 12:54 AM, \"Lakshay Garg\" <notifications@github.com> wrote:\n\n> The failure in 'Linux CPU Tests' is due to //tensorflow/tools/api/tests:\n> api_compatibility_test. This test passes on my machine, not sure why this\n> is failing.\n>\n> I followed the steps from the console log but it does not seem to change\n> anything\n>\n> ERROR:tensorflow:TensorFlow API backwards compatibility test\n> This test ensures all changes to the public API of TensorFlow are intended.\n>\n> If this test fails, it means a change has been made to the public API. Backwards\n> incompatible changes are not allowed. You can run the test as follows to update\n> test goldens and package them with your change.\n>\n>     $ bazel build tensorflow/tools/api/tests:api_compatibility_test\n>     $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\n>           --update_goldens True\n>\n> You will need an API approval to make changes to the public TensorFlow API. This\n> includes additions to the API.\n>\n> ERROR:tensorflow:1 differences found between API and golden.\n> ERROR:tensorflow:Issue 1\t: Change detected in python object: tensorflow.nn.\n> F.\n>\n> This is the error in Linux XLA:\n>\n> ERROR: /workspace/tensorflow/core/BUILD:1428:1: Couldn't build file tensorflow/core/_objs/framework_internal/tensorflow/core/util/port.o: undeclared inclusion(s) in rule '//tensorflow/core:framework_internal':\n> this rule is missing dependency declarations for the following files included by 'tensorflow/core/util/port.cc':\n>   'bazel-out/host/genfiles/external/local_config_cuda/cuda/include/cuda.h'.\n>\n> I am not sure what is causing these failure.\n>\n> Any help is appreciated. @drpngx <https://github.com/drpngx>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10818#issuecomment-316301974>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbT4zRWpxhhdafhgvuv2ufTmU9bG3ks5sPbYbgaJpZM4N9_SW>\n> .\n>\n", "\r\nIt's an API change. You have to follow the instructions and update the\r\ngolden files\r\n\r\n>\r\n> $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n> $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n> --update_goldens True\r\n>\r\n\r\nIf you meant these instructions then I have already tried them but they do not seem to change anything :(\r\n", "@gunan any clue?", "I think this is a Python 3 vs. 2 issue -- I believe it only works with Python 2.\r\n", "Correct, api compatibility test should be run with python 2.7 on a linux system.\r\nI recommend using docker to update goldens.\r\nWe should update test instructions to include this information.", "@tensorflow-jenkins test this please", "```\r\nTIMEOUT: //tensorflow/contrib/signal:spectral_ops_test (see /var/lib/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local_linux-opt/testlogs/tensorflow/contrib/signal/spectral_ops_test/test.log).\r\n```\r\n\r\nThis is the error message from GPU. Is this related to the changes made in this PR? @vrv ", "Probably transient.\n\nJenkins, test this please.\n\nOn Jul 25, 2017 2:30 PM, \"Lakshay Garg\" <notifications@github.com> wrote:\n\n> TIMEOUT: //tensorflow/contrib/signal:spectral_ops_test (see /var/lib/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local_linux-opt/testlogs/tensorflow/contrib/signal/spectral_ops_test/test.log).\n>\n> This is the error message from GPU. Is this related to the changes made in\n> this PR?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10818#issuecomment-317721795>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbfOzJuia9XEIuT6hDC626YzuUgI0ks5sRd_UgaJpZM4N9_SW>\n> .\n>\n", "I have added the missing kernel. Please retest.", "I think the issue is you are missing this:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/elu_op.cc#L61\r\n\r\nI took a quick look into the PR and I cannot see REGISTER_XLA_OP for selu op.", "Just saw your update.\r\nJenkins, test this please.", "All tests have passed. This can now be merged.", "Is this working for anyone? tf.nn.selu, seems to be missing. ", "@thesuperzapper I just checked the 1.3.0 release and I could not find selu in there. May be it isn't a part of the official release yet. Here are some things you can try:\r\n\r\n* Clone the repo itself and build the master branch which contains this function\r\n* Try using keras, it seems to have selu available (contrib/keras/python/keras/activations.py)\r\n* I have some builds of master from a few days ago (which I think have selu available). You can get them from https://github.com/lakshayg/tensorflow-build (Look for tf version 1.3.0rc2)\r\n* Implement selu yourself! https://www.tensorflow.org/api_docs/python/tf/py_func\r\n\r\nAll the best!", "Ok, I just pulled the nightly docker image, and tf.nn.selu was there. It looks like it didn't fully make it into 1.3 for some reason. "]}, {"number": 10817, "title": "TensorFlow C library now available for Windows?", "body": "Does anyone know where  to find the available TensorFlow C library for Windows?\r\nI only get the information about C library on Linux and MacOs.", "comments": ["You can download this from:\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.2.0.zip\r\n\r\nWe haven't yet updated the website, but as of the 1.2 release are producing the C library binary artifacts for Windows.\r\n\r\nHope that helps!", "many thanks! @asimshankar ", "Where can I find the .lib file for this dll?", "@sebesbal try to create a .lib file from .dll, \r\nreferences: https://adrianhenke.wordpress.com/2008/12/05/create-lib-file-from-dll/\r\nyou will need to use lib  /MACHINE:X86 or X64 params for different platform.\r\neg. lib /MACHINE:X86  /def:C:\\mypath\\mylib.def /OUT:C:\\mypath\\mylib.lib", "@sebesbal I compiled GPU version tensorflow lib and dll on windows7 with CUDA8.0 and cudnn5.1, may it help you https://github.com/BowieHsu/Tensorflow-windows-dll", "Can anyone please tell how to compile and run the code that uses windows C tensorflow library? I have MinGW g++ compiler and VS2015 cl compiler. But nothing I try works. Maybe @asimshankar  or @BowieHsu can help? I only need CPU version, simple", "https://github.com/BowieHsu/Tensorflow-windows-dll/issues/5 check it out.", "@BowieHsu thanks for your response!\r\n\r\nI have no problem downloading the library, but I don't understand how to COMPILE with this library using CL VS2015 compiler. Can you please help me with the compilation?", "@nikita-astronaut [here examples](https://github.com/Neargye/hello_tf_win_c_api) TensorFlow C API on Windows."]}, {"number": 10816, "title": "Training LSTM RNN  model after restoration starting again with high loss", "body": "I have an LSTM based RNN language model where in after the initial training for 1000 iterations, the model is saved as follows\r\nsaver = tf.train.Saver()\r\nsaver.save(sess,'rnn_model.ckpt',global_step=1000)\r\n\r\nI've restored the model by\r\n\r\n            saver = tf.train.import_meta_graph(\"rnn_model.ckpt-1000.meta\")\r\n            saver.restore(self.sess, tf.train.latest_checkpoint('./'))\r\n            graph = tf.get_default_graph()\r\n            # restore the operations and placeholder as required from the graph\r\n            # perform retraining\r\n\r\nso far everything looks good, the model is restored, but however, when I plot the loss summary while training with the same input data as previous training, the loss again starts with high value as if it is training from start again freshly. I've tried to search all means to find the relevant forums but could not find a proper solution. please advise on the corrective steps\r\n\r\n (related links\r\nhttps://github.com/tensorflow/tensorflow/issues/6683\r\nhttps://github.com/fchollet/keras/issues/4875\r\nhttps://stackoverflow.com/questions/41328769/tensorflow-loss-resets-after-successfully-restored-checkpoint\r\n\r\n)\r\n\r\n\r\n\r\n", "comments": ["The input data vectors are modeled differently across each execution due to some issue in the data modeling part. Otherwise, no issue in tensor flow graph after restoration found. After fixing the input data model, I could able to retrain from the last checkpoint properly", "I ran into the same problem, I have no idea how to solve it. Can you explain your solution in detail? Thank you.", "@amadupu I am having the same issue as you, any tips on how to solve it? Does it have to do with how I am building the tfrecords from the png? Or is it after that", "I think [this link](https://stackoverflow.com/a/43670684/5634636) might be helpful."]}, {"number": 10815, "title": "Feature request: Add a subclass of seq2seq.Decoder to support regression", "body": "Currently, seq2seq decoder class only supports classification which uses 1D softmax with embedding. The library is very good for this particular task. However, seq2seq is also extremely useful in regression tasks by replacing embedding with a dense layer.\r\n\r\nAs of 1.2, the current architecture only allows 1D sequence data by supplying a Dense layer as _embedding_fn to TrainingHelper. Currently, training is working(loss decreases) but I have yet to find a way to decode.\r\n\r\nI have tried to modify these following pieces to support 2D regression:\r\n`TrainingHelper`\r\n`BasicDecoder`\r\n`dynamic_decode`\r\n`GreedyEmbeddingHelper`(used during decoding, not working)\r\n\r\nI had to change a lot of seq2seq internals, but here is more or less my code:\r\n```python\r\n            self.decoder_cell, self.decoder_initial_state = self.build_decoder_cell()\r\n\r\n            # Input projection layer to feed embedded inputs to the cell\r\n            # ** Essential when use_residual=True to match input/output dims\r\n            input_layer = Dense(self.hidden_units, dtype=self.dtype, name='input_projection')\r\n\r\n            # Output projection layer to convert cell_outputs to actual values\r\n            output_layer = Dense(self.dimension, name='output_projection')\r\n\r\n```\r\n```python\r\n\r\nif self.mode == 'train':\r\n    # decoder_inputs_train :: [batch_size , max_time_steps + 1]\r\n    # Decoder inputs having gone through input projection layer\r\n    self.decoder_inputs_proj = input_layer(self.decoder_inputs_train)\r\n\r\n    # Helper to feed inputs for training: read inputs from dense ground truth vectors\r\n    training_helper = seq2seq.TrainingHelper(inputs=self.decoder_inputs_proj,\r\n                                       sequence_length=self.decoder_inputs_length_train,\r\n                                       time_major=False,\r\n                                       name='training_helper')\r\n\r\n    training_decoder = seq2seq.BasicDecoder(cell=self.decoder_cell,\r\n                                       helper=training_helper,\r\n                                       initial_state=self.decoder_initial_state,\r\n                                       output_layer=output_layer)\r\n                                       #output_layer=None)\r\n\r\n    # Maximum decoder time_steps in current batch\r\n    max_decoder_length = tf.reduce_max(self.decoder_inputs_length_train)\r\n\r\n    # decoder_outputs_train: BasicDecoderOutput\r\n    #                        namedtuple(rnn_outputs, sample_id)\r\n    # decoder_outputs_train.rnn_output: [batch_size, max_time_step + 1, dimension] if output_time_major=False\r\n    #                                   [max_time_step + 1, batch_size, dimension] if output_time_major=True\r\n    # decoder_outputs_train.sample_id: [batch_size], tf.int32\r\n    (self.decoder_outputs_train, self.decoder_last_state_train,\r\n     self.decoder_outputs_length_train) = (seq2seq.dynamic_decode(\r\n        decoder=training_decoder,\r\n        output_time_major=False,\r\n        impute_finished=True,\r\n        maximum_iterations=max_decoder_length))\r\n\r\n    # More efficient to do the projection on the batch-time-concatenated tensor\r\n    # logits_train: [batch_size, max_time_step + 1, dimension]\r\n    self.decoder_logits_train = tf.identity(self.decoder_outputs_train.rnn_output)\r\n\r\n    # RMSE\r\n    self.loss = tf.reduce_mean(tf.sqrt(\r\n          tf.abs(tf.subtract(self.decoder_logits_train, self.decoder_targets_train))\r\n        ), axis=2)\r\n    self.loss = tf.reduce_sum(self.loss)\r\n\r\n    # Contruct graphs for minimizing loss\r\n    self.init_optimizer()\r\n```\r\nAnd here is the code for `decoding` and this is where I get all sorts of errors:\r\n\r\n```\r\n\r\nelif self.mode == 'decode':\r\n\r\n    # Start_tokens: [batch_size,] `int32` vector\r\n    start_tokens = tf.ones([self.batch_size, self.dimension], tf.float32) * 0.1337\r\n    end_token = 0.1337\r\n\r\n    def project_inputs(inputs):\r\n        print \"INPUT SHAPE\", inputs.shape\r\n        return input_layer(inputs)\r\n\r\n    if not self.use_beamsearch_decode:\r\n        # Helper to feed inputs for greedy decoding: uses the argmax of the output\r\n        decoding_helper = seq2seq.GreedyEmbeddingHelper(start_tokens=start_tokens,\r\n                                                        end_token=end_token,\r\n                                                        embedding=project_inputs)\r\n        # Basic decoder performs greedy decoding at each time step\r\n        print(\"building greedy decoder..\")\r\n        inference_decoder = seq2seq.BasicDecoder(cell=self.decoder_cell,\r\n                                                 helper=decoding_helper,\r\n                                                 initial_state=self.decoder_initial_state,\r\n                                                 output_layer=output_layer)\r\n    # For GreedyDecoder, return\r\n    # decoder_outputs_decode: BasicDecoderOutput instance\r\n    #                         namedtuple(rnn_outputs, sample_id)\r\n    # decoder_outputs_decode.rnn_output: [batch_size, max_time_step, num_decoder_symbols]   if output_time_major=False\r\n    #                                    [max_time_step, batch_size, num_decoder_symbols]   if output_time_major=True\r\n    # decoder_outputs_decode.sample_id: [batch_size, max_time_step], tf.int32       if output_time_major=False\r\n    #                                   [max_time_step, batch_size], tf.int32               if output_time_major=True\r\n\r\n    (self.decoder_outputs_decode, self.decoder_last_state_decode,\r\n     self.decoder_outputs_length_decode) = (seq2seq.dynamic_decode(\r\n        decoder=inference_decoder,\r\n        output_time_major=False,\r\n        #impute_finished=True,  # error occurs\r\n        maximum_iterations=self.max_decode_step))\r\n\r\n    if not self.use_beamsearch_decode:\r\n        # decoder_outputs_decode.sample_id: [batch_size, max_time_step]\r\n        # Or use argmax to find decoder symbols to emit:\r\n        # self.decoder_pred_decode = tf.argmax(self.decoder_outputs_decode.rnn_output,\r\n        #                                      axis=-1, name='decoder_pred_decode')\r\n\r\n        # Here, we use expand_dims to be compatible with the result of the beamsearch decoder\r\n        # decoder_pred_decode: [batch_size, max_time_step, 1] (output_major=False)\r\n        self.decoder_pred_decode = tf.expand_dims(self.decoder_outputs_decode.sample_id, -1)\r\n```\r\n\r\nIt would be great if someone could sort it out and streamline the process.", "comments": ["[Related paper](http://www.ijcaonline.org/archives/volume143/number11/zaytar-2016-ijca-910497.pdf)\r\n\r\nGraph on page 2", "@lukaszkaiser might have an opinion on whether this is feasible.", "I'm not sure, I'll defer to @ebrevdo to decide on that.", "I am also running into this exact issue, a more streamlined approach would be very much appreciated. ", "There is already class for this, it's called ScheduledOutputTrainingHelper.  You can get regression by creating this helper with sampling_probability=0 and then putting an l2 loss on the output.  Alternatively you can use a higher sampling probability to get scheduled sampling.  Rui is currently fixing #10736 which should remove any blockers.\r\n\r\nWe may need a [Regression/Feedback]OutputTrainingHelper which doesn't require training inputs, for inference mode; but for training the current class should be sufficient.", "Ricky, is your question about tf.contrib.seq2seq?  Looks like you've rolled\nyour own\n\nOn Jun 20, 2017 11:01 AM, \"Ricky Han\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> here is my toy example for decoder.\n> It's still WIP:\n>\n>\n>     enc_inp = tf.placeholder(tf.float32, shape=(batch_size, seq_length_in, input_dim))\n>\n>     dec_target = tf.placeholder(tf.float32,\n>         shape=(batch_size, seq_length_out, output_dim))\n>\n>     with tf.variable_scope(\"ENCODE\"):\n>         # enc_cells = []\n>         # for i in range(0, encoder_depth):\n>         #     with tf.variable_scope('enc_RNN_{}'.format(i)):\n>         #         cell = tf.contrib.rnn.GRUCell(hidden_dim)  # Or LSTMCell(hidden_dim)\n>         #         cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)\n>         #         enc_cells.append(cell)\n>         # enc_cell = tf.contrib.rnn.MultiRNNCell(enc_cells)\n>         enc_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n>\n>         enc_inp_len = np.array([seq_length_in for _ in range(batch_size)])\n>\n>         ((encoder_fw_outputs,\n>           encoder_bw_outputs),\n>          (encoder_fw_final_state,\n>           encoder_bw_final_state)) = (\n>             tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell,\n>                                             cell_bw=enc_cell,\n>                                             inputs=enc_inp,\n>                                             sequence_length=enc_inp_len,\n>                                             dtype=tf.float32)\n>             )\n>         encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n>\n>         encoder_final_state_c = tf.concat(\n>             (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n>\n>         encoder_final_state_h = tf.concat(\n>             (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n>\n>         encoder_final_state = tf.contrib.rnn.LSTMStateTuple(\n>             c=encoder_final_state_c,\n>             h=encoder_final_state_h\n>         )\n>\n>     W = tf.Variable(tf.random_uniform([hidden_dim, output_dim], -1, 1), dtype=tf.float32)\n>     b = tf.Variable(tf.zeros([output_dim]), dtype=tf.float32)\n>     decoder_lengths = seq_length_out + 10\n>     dec_inp_initial = tf.zeros([batch_size, hidden_dim], dtype=np.float32, name=\"GO\") # BUG:\n>\n>\n>     def loop_fn_initial():\n>         initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n>         initial_input = dec_inp_initial\n>         initial_cell_state = encoder_final_state\n>         initial_cell_output = None\n>         initial_loop_state = None  # we don't need to pass any additional information\n>         return (initial_elements_finished,\n>                 initial_input,\n>                 initial_cell_state,\n>                 initial_cell_output,\n>                 initial_loop_state)\n>\n>     def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n>         def get_next_input():\n>             output_logits = tf.add(tf.matmul(previous_output, W), b) # time x output_dim\n>             prediction = tf.argmax(output_logits, axis=1)\n>             next_input = tf.nn.embedding_lookup(embeddings, prediction)\n>             return next_input\n>         elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n>                                                       # defining if corresponding sequence has ended\n>         finished = tf.reduce_all(elements_finished) # -> boolean scalar\n>         input = tf.cond(finished, lambda: dec_inp_initial, lambda: dec_inp_initial)\n>         state = previous_state\n>         output = previous_output\n>         loop_state = None\n>         return (elements_finished,\n>                 input,\n>                 state,\n>                 output,\n>                 loop_state)\n>     def loop_fn(time, previous_output, previous_state, previous_loop_state):\n>         if previous_state is None:    # time == 0\n>             assert previous_output is None and previous_state is None\n>             return loop_fn_initial()\n>         else:\n>             return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n>\n>\n>     with tf.variable_scope(\"DECODE\"):\n>         # dec_cells = []\n>         # # name=\"dec_cell_{}\".format(i)\n>         # for i in range(0, decoder_depth):\n>         #     with tf.variable_scope('dec_RNN_{}'.format(i)):\n>         #         cell = tf.contrib.rnn.GRUCell(hidden_dim)\n>         #         cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)\n>         #         dec_cells.append(cell)\n>         # dec_cell = tf.contrib.rnn.MultiRNNCell(dec_cells)\n>         decoder_cell = tf.contrib.rnn.LSTMCell(hidden_dim*2) # BUG:\n>\n>         decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n>         decoder_outputs = decoder_outputs_ta.stack()\n>\n>\n>\n>\n>     with tf.Session() as sess:\n>         init = tf.global_variables_initializer()\n>         sess.run(init)\n>\n>         print sess.run(decoder_outputs, feed_dict={\n>             enc_inp: sample_x,\n>             dec_target: sample_y\n>         })\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10815#issuecomment-309839091>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9F4U0Yl1JYEoDlzR_N1hYC00yf_ks5sGAjigaJpZM4N911G>\n> .\n>\n", "@ebrevdo \r\nhello, I noticed something strange about your comment on ScheduledOutputTrainingHelper. Shouldn't the sampling_probability be 1 during the inference phase? The API documentation says that the sampling_probability is the probability of sampling from the outputs instead of reading directly from the inputs. ", "@ebrevdo \r\nhello, I also have a question about ScheduledOutputTrainingHelper. I'm currently doing regression using ScheduledOutputTrainingHelper. But, in the inference stage, is it right to set the sampling probability to 1 and use an arbitrary input to target? For the classification case, GreedyEmbeddingHelper can be used, but for regression there is no Greedy'Output'Helper.\r\n\r\nsampling_probability: the probability of sampling from the outputs instead of reading directly from the inputs.\r\n\r\nmy decoder_input is like Start_value(zeros) + y_target[:-1]\r\n\r\n```\r\nx_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_1])\r\nx_2 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_2])\r\ny_target = tf.placeholder(dtype=tf.float32, shape=[None, n_step, 1])\r\n\r\nphase = tf.placeholder(tf.bool) # if True: training / if False: inference\r\nlength = tf.placeholder(dtype=tf.int32, shape=[None,])\r\ntf_batch_size = tf.placeholder(dtype=tf.int32, shape = [])\r\n\r\nencoder_input = tf.concat([x_1,x_2], axis=2)\r\n\r\n# like Start_token + target[:-1]\r\ndecoder_input = tf.concat([tf.fill([tf_batch_size,1,1], 0.0), # Start by Zeros\r\n                           y_target[:,:-1,:]], #targets[:-1]\r\n                           axis=1) \r\n```\r\n\r\nthen my decoder is like this\r\n\r\n```\r\ndef decoder(decoder_input, encoder_output, decoder_initial_state, decoder_dimension, phase):    \r\n    cell = LayerNormBasicLSTMCell(decoder_dimension)\r\n    \r\n    cell = AttentionWrapper(cell, \r\n                            attention_mechanism=BahdanauAttention(decoder_dimension, encoder_output), \r\n                            initial_cell_state = (LSTMStateTuple(decoder_initial_state, decoder_initial_state)),\r\n                            alignment_history = True) \r\n\r\n    output_cell = OutputProjectionWrapper(cell, output_size=1)\r\n    \r\n    sampling_prob = tf.cond(phase,\r\n                            \r\n                            #training\r\n                            lambda :tf.constant(1.0) - tf.train.inverse_time_decay(learning_rate=1.0,\r\n                                                                                   global_step=global_step,\r\n                                                                                   decay_steps=1000,\r\n                                                                                   decay_rate=0.9),\r\n                            \r\n                            #inference\r\n                            lambda : tf.constant(1.0))\r\n\r\n    helper = ScheduledOutputTrainingHelper(decoder_input, \r\n                                           sequence_length=length, \r\n                                           sampling_probability=sampling_prob)    \r\n    \r\n    my_decoder = BasicDecoder(cell=output_cell, \r\n                              helper=helper, \r\n                              initial_state=output_cell.zero_state(batch_size=tf_batch_size, dtype=tf.float32))\r\n    \r\n    final_outputs, final_state, final_sequence_length = dynamic_decode(my_decoder, maximum_iterations=24)\r\n        \r\n    return final_outputs.rnn_output\r\n```\r\n\r\nIn the inference stage, if i feed zero values(or any arbitrary value) to y_target and set sampling_probabilty to 1.0, i think result has to be same as the case when I feed ground truth values to y_target, because sampling_prob=1 means model always sample from the previous outputs, not ground truth value. So what I'm saying is that if the sampling_probability is set to 1.0, it should not matter what value I feed to y_target in the inference stage\r\n\r\nHowever, result is slightly different like below(but almost same) / phase: False means inference\r\n![image](https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png)\r\n\r\nis this a precision(float32) issue of python? or problem of ScheduledOutputTrainingHelper?", "I think it's just setting the seed to get consistent samples.  Your\nrandomness is different between the two runs.\n\nAdam Roberts added two new inference helpers for this exact case, but they\nare only in the nightlies, not in tf 1.3.  look for InferenceHelper, which\nyou can use to implement sample-only decoding.\n\nOn Aug 31, 2017 2:28 AM, \"chococig\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo>\n> hello, I also have a question about ScheduledOutputTrainingHelper. I'm\n> currently doing regression using ScheduledOutputTrainingHelper. But, in the\n> inference stage, is it right to set the sampling probability to 1 and use\n> an arbitrary input? For the classification case, GreedyEmbeddingHelper can\n> be used, but for regression there is no Greedy'Output'Helper.\n>\n>    - sampling_probability: the probability of sampling from the outputs\n>    instead of reading directly from the inputs.\n>\n> my decoder_input is like Start_value(zeros) + y_target[:-1]\n> '''\n> x_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_1])\n> x_2 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_2])\n> y_target = tf.placeholder(dtype=tf.float32, shape=[None, n_step, 1])\n>\n> phase = tf.placeholder(tf.bool) # if True: training / if False: inference\n> length = tf.placeholder(dtype=tf.int32, shape=[None,])\n> tf_batch_size = tf.placeholder(dtype=tf.int32, shape = [])\n>\n> encoder_input = tf.concat([x_1,x_2], axis=2)\n> like Start_token + target[:-1]\n>\n> decoder_input = tf.concat([tf.fill([tf_batch_size,1,1], 0.0), # Start by\n> Zeros\n> y_target[:,:-1,:]], #targets[:-1]\n> axis=1)\n> '''\n> then my decoder is like this\n>\n> def decoder(encoder_output, decoder_initial_state, decoder_dimension, phase):\n>     cell = LayerNormBasicLSTMCell(decoder_dimension)\n>\n>     cell = AttentionWrapper(cell,\n>                             attention_mechanism=BahdanauAttention(decoder_dimension, encoder_output),\n>                             initial_cell_state = (LSTMStateTuple(decoder_initial_state, decoder_initial_state)),\n>                             alignment_history = True)\n>\n>     output_cell = OutputProjectionWrapper(cell, output_size=1)\n>\n>     sampling_prob = tf.cond(phase,\n>\n>                             #training\n>                             lambda :tf.constant(1.0) - tf.train.inverse_time_decay(learning_rate=1.0,\n>                                                                                    global_step=global_step,\n>                                                                                    decay_steps=1000,\n>                                                                                    decay_rate=0.9),\n>\n>                             #inference\n>                             lambda : tf.constant(1.0))\n>\n>     helper = ScheduledOutputTrainingHelper(decoder_input,\n>                                            sequence_length=length,\n>                                            sampling_probability=sampling_prob)\n>\n>     my_decoder = BasicDecoder(cell=output_cell,\n>                               helper=helper,\n>                               initial_state=output_cell.zero_state(batch_size=tf_batch_size, dtype=tf.float32))\n>\n>     final_outputs, final_state, final_sequence_length = dynamic_decode(my_decoder, maximum_iterations=24)\n>\n>     return final_outputs.rnn_output\n> ...\n>\n> In the inference stage, if i feed zero values(or any arbitrary value) to y_target and set sampling_probabilty to 1.0, i think result has to be same as the case when I feed ground truth values to y_target, because sampling_prob=1 means model always sample from the previous outputs, not ground truth value. So what I'm saying is that if the sampling_probability is set to 1.0, is should not matter what value I feed to y_target.\n>\n> However, result is slightly different like below(but almost same)\n> ![image](https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png)\n>\n> is this a precision(float32) issue of python? or problem of ScheduledOutputTrainingHelper?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10815#issuecomment-326241575>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9Yc_knnYT_CPG4aWgHY8VfPGgfPks5sdnyggaJpZM4N911G>\n> .\n>\n", "Hi, I'm doing similar decoder, but the decoder inputs is conditioned by the encoder final hidden states (context vector), [Related Paper](https://arxiv.org/pdf/1702.05538.pdf) see picture a in page 3. The decoder is trying to fully inference during training with feeding previous outputs and context vector as inputs at each step.\r\n\r\n`class RNNEncoder_Decoder(object):\r\n\r\n    def __init__(self,input_dim,\r\n                 context_dim,output_dim,hidden_dim,\r\n                 layers_stacked_count,learning_rate):\r\n        \r\n        self.graph = tf.get_default_graph()\r\n        self.input_dim = input_dim\r\n        self.output_dim = output_dim\r\n        self.context_dim = context_dim\r\n        self.hidden_dim = hidden_dim\r\n        self.layers_stacked_count = layers_stacked_count\r\n        self.learning_rate = learning_rate\r\n        self.sampling_probability = tf.constant(dtype=tf.float32,value=1.0)\r\n        \r\n        # [batch_size,sequence_length,input_dimension]\r\n        self.enc_inp = tf.placeholder(tf.float32, [None,None,self.input_dim], name='encoder_inputs')\r\n        self.expected_out = tf.placeholder(tf.float32, [None,None,self.output_dim], name='expected_outs')\r\n        # fullly inference during trianing\r\n        self.dec_inp = tf.zeros_like(self.expected_out,dtype=tf.float32,name='decoder_inputs')\r\n                \r\n        seq_length = tf.reduce_sum(tf.sign(tf.reduce_max(tf.abs(self.enc_inp), 2)), 1)\r\n        self.seq_length = tf.cast(seq_length, tf.int32)\r\n        \r\n        with tf.variable_scope('RNNEncoderDecoder'):\r\n            with tf.variable_scope(\"Enocder\") as encoder_varscope:\r\n                # create encoder LSTM cell\r\n                encoder_cells = []\r\n                for i in range(self.layers_stacked_count):\r\n                    with tf.variable_scope('EncoderCell_{}'.format(i)):\r\n                        encoder_cells.append(tf.nn.rnn_cell.LSTMCell(self.hidden_dim,\r\n                                                             use_peepholes=True))\r\n                self.encoder_cell = tf.nn.rnn_cell.MultiRNNCell(encoder_cells)\r\n\r\n                # ruuning dynamic rnn encoder                \r\n                _, enc_state = tf.nn.dynamic_rnn(cell = self.encoder_cell,\r\n                                                 initial_state=None,\r\n                                                 dtype=tf.float32,\r\n                                                 inputs = self.enc_inp,\r\n                                                 sequence_length = self.seq_length\r\n                                                )\r\n \r\n                # extract top layer hidden state as feature representation\r\n                self.context_vector = enc_state[-1].h\r\n                \r\n                cell_state0 = tf.zeros_like(enc_state[0].c,dtype=tf.float32)\r\n                hidden_state0 = tf.zeros_like(enc_state[0].h,dtype=tf.float32)\r\n\r\n                dec_init_state = (enc_state[1], # pass the top layer state of enocder to the bottom layer of decoder\r\n                                  tf.nn.rnn_cell.LSTMStateTuple(cell_state0, hidden_state0))\r\n                \r\n                # condition extracted features on decoder inputs\r\n                # with a shape that matches decoder inputs in all but (potentially) the final dimension. \r\n                # tile context vector from [batch_size,context_dim] to [batch_size,decoder_sequence_length,context_dim]\r\n                context_vector_shape = tf.shape(self.context_vector)\r\n                context_vector_reshaped = tf.reshape(self.context_vector, \r\n                                                     [context_vector_shape[0], 1, context_vector_shape[1]]\r\n                                                    )\r\n                enc_inp_shape = tf.shape(self.enc_inp)\r\n                self.auxiliary_inputs = tf.tile(context_vector_reshaped,\r\n                                           multiples=[1,enc_inp_shape[1],1]\r\n                                          )\r\n                \r\n            with tf.variable_scope(\"Deocder\") as decoder_varscope:\r\n                # create decoder LSTM cell\r\n                decoder_cells = []\r\n                for i in range(self.layers_stacked_count):\r\n                    with tf.variable_scope('DecoderCell_{}'.format(i)):\r\n                        decoder_cells.append(tf.nn.rnn_cell.LSTMCell(self.hidden_dim,\r\n                                                             use_peepholes=True))\r\n                self.decoder_cell = tf.nn.rnn_cell.MultiRNNCell(decoder_cells)\r\n\r\n                dec_out_dense = Dense(units = self.output_dim,\r\n                                      activation = None,\r\n                                      use_bias = False,\r\n                                      kernel_initializer = tf.truncated_normal_initializer(\r\n                                          dtype=tf.float32,\r\n                                          stddev = 1.0 / math.sqrt(float(self.hidden_dim))\r\n                                      ),\r\n                                      name = 'dec_outp_linear_projection'\r\n                                     )\r\n                \r\n                training_helper = tf.contrib.seq2seq.ScheduledOutputTrainingHelper(\r\n                    inputs = self.dec_inp,\r\n                    sequence_length = self.seq_length,\r\n                    auxiliary_inputs = self.auxiliary_inputs, # condtional on inputs\r\n                    sampling_probability = 1.0, # for fullly inference\r\n                    name = 'feeding_conditional_input'\r\n                )\r\n                \r\n                decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                    cell = self.decoder_cell,\r\n                    helper = training_helper,\r\n                    initial_state = dec_init_state,\r\n                    output_layer = dec_out_dense\r\n                )\r\n                \r\n                outputs, _ , final_seq_lengths = tf.contrib.seq2seq.dynamic_decode(decoder=decoder,\r\n                                                                                   impute_finished = True\r\n                                                                                  )\r\n            self.outputs = outputs\r\n            \r\n    ### optimize loss part\r\n    \r\n    def get_decoder_prediction(self,X,session):\r\n        feed_dict = {\r\n            self.enc_inp:X\r\n        }\r\n        feed_dict.update({self.expected_out:X})\r\n        run = [self.outputs]\r\n        return session.run(run,feed_dict=feed_dict)\r\nRNN_test = RNNEncoder_Decoder(input_dim=1,context_dim=32,output_dim=1,hidden_dim=32,layers_stacked_count=2,learning_rate=0.01)`\r\n\r\nWithout \"auxiliary_inputs = self.auxiliary_inputs\", it running successfully,\r\nbut with auxiliary_inputs = self.auxiliary_inputs\r\nAnd I got following:\r\n\r\n`---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-02522a01f0d8> in <module>()\r\n      9                           hidden_dim=hidden_dim,\r\n     10                           layers_stacked_count=layers_stacked_count,\r\n---> 11                           learning_rate=learning_rate\r\n     12                          )\r\n\r\n<ipython-input-2-86494b8d99fa> in __init__(self, input_dim, context_dim, output_dim, hidden_dim, layers_stacked_count, learning_rate)\r\n     98 \r\n     99                 outputs, _ , final_seq_lengths = tf.contrib.seq2seq.dynamic_decode(decoder=decoder,\r\n--> 100                                                                                    impute_finished = True\r\n    101                                                                                   )\r\n    102             self.outputs = outputs\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\r\n    284         ],\r\n    285         parallel_iterations=parallel_iterations,\r\n--> 286         swap_memory=swap_memory)\r\n    287 \r\n    288     final_outputs_ta = res[1]\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\r\n   2773     context = WhileContext(parallel_iterations, back_prop, swap_memory, name)\r\n   2774     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, context)\r\n-> 2775     result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n   2776     return result\r\n   2777 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\r\n   2602       self.Enter()\r\n   2603       original_body_result, exit_vars = self._BuildLoop(\r\n-> 2604           pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2605     finally:\r\n   2606       self.Exit()\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2552         structure=original_loop_vars,\r\n   2553         flat_sequence=vars_for_body_with_tensor_arrays)\r\n-> 2554     body_result = body(*packed_vars_for_body)\r\n   2555     if not nest.is_sequence(body_result):\r\n   2556       body_result = [body_result]\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\r\n    232       \"\"\"\r\n    233       (next_outputs, decoder_state, next_inputs,\r\n--> 234        decoder_finished) = decoder.step(time, inputs, state)\r\n    235       next_finished = math_ops.logical_or(decoder_finished, finished)\r\n    236       if maximum_iterations is not None:\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py in step(self, time, inputs, state, name)\r\n    137     \"\"\"\r\n    138     with ops.name_scope(name, \"BasicDecoderStep\", (time, inputs, state)):\r\n--> 139       cell_outputs, cell_state = self._cell(inputs, state)\r\n    140       if self._output_layer is not None:\r\n    141         cell_outputs = self._output_layer(cell_outputs)\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    178       with vs.variable_scope(vs.get_variable_scope(),\r\n    179                              custom_getter=self._rnn_get_variable):\r\n--> 180         return super(RNNCell, self).__call__(inputs, state)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    448         # Check input assumptions set after layer building, e.g. input shape.\r\n    449         self._assert_input_compatibility(inputs)\r\n--> 450         outputs = self.call(inputs, *args, **kwargs)\r\n    451 \r\n    452         # Apply activity regularization.\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)\r\n    936                                       [-1, cell.state_size])\r\n    937           cur_state_pos += cell.state_size\r\n--> 938         cur_inp, new_state = cell(cur_inp, cur_state)\r\n    939         new_states.append(new_state)\r\n    940 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    178       with vs.variable_scope(vs.get_variable_scope(),\r\n    179                              custom_getter=self._rnn_get_variable):\r\n--> 180         return super(RNNCell, self).__call__(inputs, state)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    448         # Check input assumptions set after layer building, e.g. input shape.\r\n    449         self._assert_input_compatibility(inputs)\r\n--> 450         outputs = self.call(inputs, *args, **kwargs)\r\n    451 \r\n    452         # Apply activity regularization.\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)\r\n    554     input_size = inputs.get_shape().with_rank(2)[1]\r\n    555     if input_size.value is None:\r\n--> 556       raise ValueError(\"Could not infer input size from inputs.get_shape()[-1]\")\r\n    557     scope = vs.get_variable_scope()\r\n    558     with vs.variable_scope(scope, initializer=self._initializer) as unit_scope:\r\n\r\nValueError: Could not infer input size from inputs.get_shape()[-1]`\r\n\r\nCould anyone help me with:\r\nIs this a correct way to condition the last hidden state of encoder on the inputs of decoder?\r\nand why the inputs of decoder become None after I feed the auxiliary_inputs as the error?\r\n@ebrevdo ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "At inference time, there is now a `InferenceHelper` class to which you provide your sampling function, end_function, and an optional `next_inputs` function.  That should allow you to avoid having to use the scheduled output helper.", "@ggaemo ^^ that should help you.", "@wangshang19911011 looks like you may need to call .set_shape() on your auxiliary inputs to ensure their depth is statically known at graph build time?", "Thank you this seems to solve the problem. Is there some example code that I could use to use this? Because I can not just use it as a helper function, can I?", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Has someone managed to get the new InferenceHelper to work with floating point regression tasks?\r\nI am feeding the encoder a tensor [batch, 100 time steps, 4 features], decoder input and decoder expected output are of shape [batch, 10 time steps, 1 feature]. Training works nicely with the TrainingHelper and converges to an okay loss, but I am stuck with getting the inference part to work. The data itself is being fed by using tf's generators.", "@ebrevdo perhaps you can summarize the state of this issue?  I.e. should it be closed, or are there remaining tasks to complete? ", "I think we can close this, InferenceHelper essentially solved the problem.  For remaining how-do-i-do-X type questions, stackoverflow is a better venue."]}, {"number": 10814, "title": "load_csv_with_header", "body": "When I run iris_monitors.py file, It has an error :\r\nFile \"C:\\software\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py\", line 47, in load_csv_with_header\r\nheader = next(data_file)\r\nStopIteration", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, what platform you are using, and what versions it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.\r\n\r\nI did just try it on my Linux machine, and it worked fine. Make sure you are in the right current directory.\r\n", "I got the same problem, have you solved it?\r\n"]}, {"number": 10812, "title": "`tf.Summary` comparison operator overloading?", "body": "So I was trying to use a comparison operation (`>`) with a `tf.Summary` object. It does not throw an error, but the results are incorrect. I couldn't find any help for this on the [official documentation](https://www.tensorflow.org/api_docs/python/tf/Summary/Value).\r\nHere are my logs --> \r\n```\r\n(Pdb) type(losses[0])\r\n<class 'tensorflow.core.framework.summary_pb2.Summary'>\r\n(Pdb) type(losses[1])\r\n<class 'tensorflow.core.framework.summary_pb2.Summary'>\r\n(Pdb) losses\r\n[value {\r\n  tag: \"CTC Loss\"\r\n  simple_value: 40.2547607422\r\n}\r\n, value {\r\n  tag: \"CTC Loss\"\r\n  simple_value: 42.1486358643\r\n}\r\n]\r\n(Pdb) losses[0] > losses[1]\r\nTrue\r\n```\r\nThe objects were created using `tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])`. What do you think? @dandelionmane ?\r\n", "comments": ["These are protocol buffer objects. I have no expectation that the Python protocol buffer implementation will have a > operator defined in a way that is aware of the semantic meaning of summary values. It might be doing a byte string comparison or something else.\r\n\r\nIt may be that you can find some documentation on the protobuf site that explains how this operator works, if you're really curious. https://developers.google.com/protocol-buffers/docs/reference/python-generated"]}, {"number": 10811, "title": "ImportError: cannot import name bayesflow", "body": "**I am trying to use the command:\r\n`cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)`\r\n\r\nHowever, it keeps telling me:  ImportError: cannot import name bayesflow **. Detail is shown as below:\r\n\r\n> ImportError                               Traceback (most recent call last)\r\n> <ipython-input-47-316021e54a93> in <module>()\r\n>       4 labels_series = [tf.reshape(x, [batch_size,1]) for x in labels_series]\r\n>       5 # Forward passes\r\n> ----> 6 cell = tf.contrib.rnn.BasicLSTMCell(state_size)\r\n>       7 states_series, current_state = tf.contrib.rnn(cell, inputs_series, init_state)\r\n>       8 \r\n> \r\n> //anaconda/lib/python2.7/site-packages/tensorflow/python/util/lazy_loader.pyc in __getattr__(self, item)\r\n>      51 \r\n>      52   def __getattr__(self, item):\r\n> ---> 53     module = self._load()\r\n>      54     return getattr(module, item)\r\n>      55 \r\n> \r\n> //anaconda/lib/python2.7/site-packages/tensorflow/python/util/lazy_loader.pyc in _load(self)\r\n>      40   def _load(self):\r\n>      41     # Import the target module and insert it into the parent's namespace\r\n> ---> 42     module = importlib.import_module(self.__name__)\r\n>      43     self._parent_module_globals[self._local_name] = module\r\n>      44 \r\n> \r\n> //anaconda/lib/python2.7/importlib/__init__.pyc in import_module(name, package)\r\n>      35             level += 1\r\n>      36         name = _resolve_name(name[level:], package, level)\r\n> ---> 37     __import__(name)\r\n>      38     return sys.modules[name]\r\n> \r\n> //anaconda/lib/python2.7/site-packages/tensorflow/contrib/__init__.py in <module>()\r\n>      20 \r\n>      21 # Add projects here, they will show up under tf.contrib.\r\n> ---> 22 from tensorflow.contrib import bayesflow\r\n>      23 from tensorflow.contrib import cloud\r\n>      24 from tensorflow.contrib import compiler\r\n> \r\n> ImportError: cannot import name bayesflow\r\n\r\nAnybody know how to fix it? Much appreciated in advance!\r\n\r\nXin", "comments": ["Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks (e.g. TF version, etc). Thank you.", "Update dask\r\n`conda update dask`", "Fixed it for me", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "@pbamotra That does not work for me. "]}, {"number": 10810, "title": "seq2seq for dynamic length sequences", "body": "The seq2seq model is based on the static_rnn, what should I do if my sequence lengths is not known?", "comments": ["You use padding tokens after the end token. Please close this issue because it's a general question", "Thanks but padding causes the context (c) to change.\n\n \n\nFrom: Ricky Han [mailto:notifications@github.com] \nSent: Monday, June 19, 2017 3:03 AM\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: hassanzadeh <ha.hassanzadeh@gmail.com>; Author <author@noreply.github.com>\nSubject: Re: [tensorflow/tensorflow] seq2seq for dynamic length sequences (#10810)\n\n \n\nYou use padding tokens after the end token. Please close this issue because it's a general question\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/10810#issuecomment-309355328> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ANTlnVPS-jA_dkrFDnLG8eQZFkdwwBHcks5sFh0RgaJpZM4N9omP> .  <https://github.com/notifications/beacon/ANTlnTCv7ZB02AWsCSukyQMcxkXSQZPCks5sFh0RgaJpZM4N9omP.gif> \n\n", "@hassanzadeh I have recently release [dynamic seq2seq model](https://github.com/Scitator/YATS2S), you can try it out.", "Thanks", "I believe the 1.0 version seq2seq is based on dynamic_rnn. It uses `raw_rnn` and a symbolic tf.while loop. For more information watch [this talk at TF summit](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=video&cd=6&ved=0ahUKEwjKv8bP_czUAhWGPT4KHSAqCPkQtwIINjAF&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DRIR_-Xlbp7s&usg=AFQjCNFW6bVrYXBNmMCYCN0rkgh22dD44g&sig2=a3n-hbpEk74jet27OJsa2A)", "It's not you can find the code here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py", "Unless this is not the latest code.", "You are right it doesn't use raw_rnn because it implements the symbolic while loop here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/decoder.py#L278", "You should use the new API instead of legacy_seq2seq.", "Thanks, that was what I was missing.", "Looks like it is resolved, but generally speaking, this would have been a good question for StackOverflow. Thanks!", "Thanks."]}, {"number": 10809, "title": "New changes in tf 1.2 and the seq2seq model", "body": "In the change log it reads: \"The strictness described\r\nin the TensorFlow 1.1 release is gone: The first time an RNNCell is used,\r\nit caches its scope. All future uses of the RNNCell will reuse variables from\r\nthat same scope.\"\r\n\r\nBased on which the seq2seq model (with UNtied decoder weights) no longer remain untied. Can you confirm that this is addressed? I don't see anywhere in the seq2seq model that this is addressed.", "comments": ["@hassanzadeh Can you clarify the exact issue you're running into?  E.g. it would help if you could provide a short code example describing your problem.", "Thanks, I think I figured out what I was missing. I did not notice that the encoder cell is deeply copied  ( through copy.deepcopy) before being fed into the decoder.", "Cool, glad you figured things out.  I'll close this out."]}, {"number": 10808, "title": "Original error was: DLL load failed: The specified procedure could not be found.", "body": "Hello. I've been getting 'Original error was: DLL load failed: The specified procedure could not be found' error when attempting to import tensorflow. I'm on Windows 10 with python 3.6.00. I've checked some issues like mine but I already have visual studio c++ 2017. I attempted to download 2015 however I was told I already have it.  I installed tensorflow with:\r\n\r\n\r\n    Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?:\r\n    No\r\n    TensorFlow installed from (source or binary)?:\r\n    binary\r\n    TensorFlow version:\r\n    Can't do version because I the error when importing\r\n    Bazel version (if compiling from source):\r\n    NA\r\n    CUDA/cuDNN version:\r\n    8.0 I think\r\n    GPU Model and Memory:\r\n    Nvidia 1080 4gb\r\n    Exact command to reproduce:\r\n    pip3 install --upgrade tensorflow-gpu\r\n\r\nHere is the full error:\r\n\r\n> Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\__init__.py\", line 142, in <module>\r\n    from . import add_newdocs\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\add_newdocs.py\", line 13, in <module>\r\n    from numpy.lib import add_newdoc\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\lib\\__init__.py\", line 8, in <module>\r\n    from .type_check import *\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\lib\\type_check.py\", line 11, in <module>\r\n    import numpy.core.numeric as _nx\r\n  File \"C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\core\\__init__.py\", line 26, in <module>\r\n    raise ImportError(msg)\r\nImportError:\r\nImporting the multiarray numpy extension module failed.  Most\r\nlikely you are trying to import a failed build of numpy.\r\nIf you're working with a numpy git repo, try `git clean -xdf` (removes all\r\nfiles not under version control).  Otherwise reinstall numpy.\r\nOriginal error was: DLL load failed: The specified procedure could not be found.\r\n\r\nI tried reinstalling numpy too, same error. \r\n\r\n\r\n", "comments": ["I just ran into a similar issue.\r\n\r\nI installed python 3.5.3 ([\"Tensorflow only supports python 3.5.x on Windows\"](https://www.tensorflow.org/install/install_windows#installing_with_native_pip) ) and followed solutions provided in [this](https://stackoverflow.com/a/43566341) stackoverflow answer.\r\n\r\nFor me this turned out to be an issue with my PATH variable for the cuDNN dll.", "Works @timo92 , thanks. ", "I installed python 3.6 and Windows 8.1 x64.\r\nI have similar issue with numpy:\r\n\r\nImportError: \r\nImporting the multiarray numpy extension module failed.  Most\r\nlikely you are trying to import a failed build of numpy.\r\nIf you're working with a numpy git repo, try `git clean -xdf` (removes all\r\nfiles not under version control).  Otherwise reinstall numpy.\r\n\r\nOriginal error was: DLL load failed: The specified procedure could not be found.", "I got the same problem and i am still looking for a solution", "Same here.", "I had the same error with numpy. I tried using Anaconda prompt instead of cmd. I installed numpy with typing \"conda install numpy\" and then the problem was gone."]}, {"number": 10807, "title": "Could a 3.7 alpha wheel of tensorflow be provided on pip?", "body": "Python 3.7 alpha exists, I would like to be able to install a wheel. Any idea when tensorflow could be added on pypi for 3.7?", "comments": ["This is currently unsupported. You can just try renaming the wheel (which is how we generate our python 3.6 binary). Until Python 3.7 is an actual release (not beta, alpha) we will not support it. You can of course build for it .from source, but you may run into problems you need to fix. Is there a compelling reason to use Python 3.7 instead of 3.6?", "We will not release a 3.7 binary until Python 3.7 is officially released.\r\nUntil then, as @aselle suggested you can just rename 3.6 wheel file and install it (except for windows).", "@gunan @aselle Thanks, that worked! I would have never thought python would use a file naming convention to throw an error!"]}, {"number": 10806, "title": "Error compiling in Linux Mint", "body": "I am trying to compile this from source, but currently getting the following issue:\r\n\r\nsudo bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n....................................................................................\r\nWARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/BUILD:48:1: error executing shell command: 'JAR='external/local_jdk/bin/jar' OUTPUT='bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar' PROTO_COMPILER='exter...' failed: bash failed: error executing command \r\n  (cd /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/execroot/tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n  /bin/bash -c 'JAR='\\''external/local_jdk/bin/jar'\\'' OUTPUT='\\''bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar'\\'' PROTO_COMPILER='\\''external/com_google_protobuf_protoc/bin/protoc'\\'' SOURCE='\\''external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/build_info.proto'\\'' INCLUDES='\\''-I. -Iexternal/io_bazel_rules_closure'\\'' bazel-out/host/bin/external/io_bazel_rules_closure/closure/private/gensrcjar'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nexternal/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: cannot create \u0001\ufffd/@@\ufffd\ufffd: Directory nonexistent\r\nexternal/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: \u007fELF\u0002\u0001\u0001\u0003\u0002: not found\r\nexternal/com_google_protobuf_protoc/bin/protoc: 2: external/com_google_protobuf_protoc/bin/protoc: Syntax error: \")\" unexpected\r\ngensrcjar: proto_compiler failed\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 339.557s, Critical Path: 54.04s\r\nCan anyone help on this?\r\n\r\nThanks.\r\n", "comments": ["Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 10805, "title": "Make `tf.contrib.seq2seq._BaseAttentionMechanism` public", "body": "Currently, if users want to write their own attention mechanisms, they have to do so from scratch by extending the `tf.contrib.seq2seq.AttentionMechanism` class (which has nothing) or import the `_BaseAttentionMechanism` from [attention_wrapper.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py) with the following, inconvenient import statement:\r\n\r\n    from tensorflow.contrib.seq2seq.python.ops.attention_wrapper import _BaseAttentionMechanism\r\n\r\nIt's worth including this class directly accessible from `tf.contrib.seq2seq`, considering that it adds good defaults and that both forms of attention currently available, Bahdanau and Luong, inherit this class.\r\n\r\nMy proposal is to simply rename the class to `BaseAttentionMechanism` without an underscore (or perhaps a more meaningful name such as `BasicAttentionMechanism`to differentiate it from the parent class `AttentionMechanism`), and add the class to the `__all__` array in [attention_wrapper.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py).", "comments": ["@ebrevdo, could you evaluate these feature request. Thanks!\r\n", "The `AttentionMechanism` class is also expected to have certain attributes by other methods, like `batch_size`, `values`, `num_units`, and `alignments_size`. These should at least appear in some way in the parent class and be documented so that users can create their own attention mechanisms if they are not to use all the functionality of `_BaseAttentionMechanism `.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "We want to reserve the right to modify the base class without breaking\nexternal users.  You are welcome to copy/paste this class into your own\ncode and subclass it!\n\nOn Thu, Jan 4, 2018 at 11:29 AM, Alfred <notifications@github.com> wrote:\n\n> It has been 14 days with no activity and this issue has an assignee.Please\n> update the label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10805#issuecomment-355374162>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim-od0NQhy2X948B8hPkju3F6BOnPks5tHSWBgaJpZM4N9bqR>\n> .\n>\n", "I also need to write a custom attention mechanism and ran into this issue. @ebrevdo, I'm unclear how copy/pasting the implementation will break external users any less than simply exposing the implementation publicly.\r\n\r\nIf you add a new method/property to `_BaseAttentionMechanism` and make use of it in `AttentionWrapper`, all external users who followed the advice to copy the implementation will be broken. Worse yet, if you changed the semantics of an existing method, users who copied the code could be broken silently. In such cases, subclassing the original `_BaseAttentionMechanism` would have been a much better solution for everyone involved.\r\n\r\nThat said, I understand if you're not prepared to define a public-facing interface to plug in custom attention mechanisms. A comment to that effect in [AttentionMechanism](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionMechanism) would be much appreciated.", "I think the most important thing is to update and document the set of\nunimplemented methods and properties in AttentionMechanism so authors of\nnew mechanisms know exactly what needs to be included. I don't expect to\nchange the API anymore so you should feel safe to a copy the existing base\nclass.\n\nWould you like to send a PR with the updated abstract class an docstrings?\n\nOn Fri, Jul 27, 2018, 10:03 PM Sharvil Nanavati <notifications@github.com>\nwrote:\n\n> I also need to write a custom attention mechanism and ran into this issue.\n> @ebrevdo <https://github.com/ebrevdo>, I'm unclear how copy/pasting the\n> implementation will break external users any less than simply exposing the\n> implementation publicly.\n>\n> If you add a new method/property to _BaseAttentionMechanism and make use\n> of it in AttentionWrapper, all external users who followed the advice to\n> copy the implementation will be broken. Worse yet, if you changed the\n> semantics of an existing method, users who copied the code could be broken\n> silently. In such cases, subclassing the original _BaseAttentionMechanism\n> would have been a much better solution for everyone involved.\n>\n> That said, I understand if you're not prepared to define a public-facing\n> interface to plug in custom attention mechanisms. A comment to that effect\n> in AttentionMechanism\n> <https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionMechanism>\n> would be much appreciated.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10805#issuecomment-408583055>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim7ZgObjnzO0coVFjoRVr7bpzqag8ks5uK_CugaJpZM4N9bqR>\n> .\n>\n"]}]