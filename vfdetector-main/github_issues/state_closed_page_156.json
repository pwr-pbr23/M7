[{"number": 50140, "title": "[PluggableDevice] Add TF_OpKernelConstruction_GetAttrTensor and TF_OpKernelConstruction_GetAttrTensorList", "body": "Add TF_OpKernelConstruction_GetAttrTensor and TF_OpKernelConstruction_GetAttrTensorList to the Pluggable Device C API.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50140) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it."]}, {"number": 50139, "title": "What is the reason for very low GPU utilization?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n```\r\n$ lsb_release -a\r\nLSB Version:\t:core-4.1-amd64:core-4.1-noarch\r\nDistributor ID:\tCentOS\r\nDescription:\tCentOS Linux release 7.9.2009 (Core)\r\nRelease:\t7.9.2009\r\nCodename:\tCore\r\n```\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):\r\n```\r\n$ pip freeze | grep tensorflow\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gpu==2.2.0\r\n \r\n```\r\n- Python version:\r\n```\r\n$ python\r\nPython 3.8.5 (default, Mar 31 2021, 02:37:07) \r\n[GCC 7.3.1 20180303 (Red Hat 7.3.1-5)] on linux\r\n```\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n```\r\n$ gcc --version\r\ngcc (GCC) 7.3.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\n```\r\n- CUDA/cuDNN version:\r\n```\r\nstat /usr/local/cuda\r\n  File: \u2018/usr/local/cuda\u2019 -> \u2018/usr/local/cuda-10.2\u2019\r\n  Size: 20          Blocks: 0          IO Block: 4096   symbolic link\r\nDevice: fd00h/64768d    Inode: 67157410    Links: 1\r\nAccess: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:usr_t:s0\r\nAccess: 2021-05-20 10:43:06.864530636 -0400\r\nModify: 2020-09-21 09:39:18.559883390 -0400\r\nChange: 2020-09-21 09:39:18.559883390 -0400\r\n Birth: -\r\n```\r\n\r\n- GPU model and memory:\r\n```\r\n$ sudo lshw -C display\r\n[sudo] password for jalal: \r\n  *-display                 \r\n       description: VGA compatible controller\r\n       product: GP102 [GeForce GTX 1080 Ti]\r\n       vendor: NVIDIA Corporation\r\n       physical id: 0\r\n       bus info: pci@0000:06:00.0\r\n       version: a1\r\n       width: 64 bits\r\n       clock: 33MHz\r\n       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom\r\n       configuration: driver=nvidia latency=0\r\n       resources: irq:89 memory:f8000000-f8ffffff memory:a0000000-afffffff memory:b0000000-b1ffffff ioport:d000(size=128) memory:f9000000-f907ffff\r\n  *-display\r\n       description: VGA compatible controller\r\n       product: GP102 [GeForce GTX 1080 Ti]\r\n       vendor: NVIDIA Corporation\r\n       physical id: 0\r\n       bus info: pci@0000:05:00.0\r\n       version: a1\r\n       width: 64 bits\r\n       clock: 33MHz\r\n       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom\r\n       configuration: driver=nvidia latency=0\r\n       resources: irq:88 memory:fa000000-faffffff memory:c0000000-cfffffff memory:d0000000-d1ffffff ioport:e000(size=128) memory:fb000000-fb07ffff\r\n\r\n```\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n```\r\n>>> import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\nv2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n\r\n```\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\nI am not sure why this code is barely using GPU memory and why the GPU utilization is very low? It shows it is using both of my GPUs indeed. How can I fix this? Also, for 1000 images, how long does this step take approximately?\r\n\r\n`$ python Feature_extraction.py --input_list ../vertex_path_GT.txt --model pointnet_hico --model_path ../Feature_extraction/model_10000.ckpt`\r\n\r\nI run the code from this directory:\r\n`/scratch3/research/code/DJ-RN-dawnlight/pointnet`\r\n\r\n\r\n![Screenshot from 2021-06-08 02-13-21](https://user-images.githubusercontent.com/76495162/121132783-8fea0a80-c7ff-11eb-83c6-980227676076.png)\r\n![Screenshot from 2021-06-08 02-13-26](https://user-images.githubusercontent.com/76495162/121132785-8fea0a80-c7ff-11eb-81ff-672f69a94151.png)\r\n\r\n\r\nHere's a copy of your code:\r\n\r\n```\r\nimport argparse\r\nimport math\r\nimport h5py\r\nimport numpy as np\r\n#import tensorflow as tf\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nimport socket\r\nimport importlib\r\nimport os\r\nimport sys\r\n#import cPickle as pickle\r\nimport pickle\r\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\r\nsys.path.append(BASE_DIR)\r\nsys.path.append(os.path.join(BASE_DIR, 'models'))\r\nsys.path.append(os.path.join(BASE_DIR, 'utils'))\r\nimport tf_util\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')\r\nparser.add_argument('--model', default='pointnet_hico', help='Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]')\r\nparser.add_argument('--num_point', type=int, default=1228, help='Point Number [256/512/1024/2048] [default: 1024]')\r\nparser.add_argument('--model_path', default='log/model.ckpt', help='model checkpoint file path [default: log/model.ckpt]')\r\nparser.add_argument('--input_list', default='./', help='Path list of your point cloud files [default: ./pc_list.txt]')\r\nFLAGS = parser.parse_args()\r\n\r\n\r\nNUM_POINT = FLAGS.num_point\r\n#GPU_INDEX = FLAGS.gpu\r\nGPU_INDEX = 1\r\nprint(\"GPU_INDEX: \", GPU_INDEX)\r\nMODEL_PATH = FLAGS.model_path\r\nBATCH_SIZE = 1\r\nMODEL = importlib.import_module(FLAGS.model) # import network module\r\nMODEL_FILE = os.path.join(BASE_DIR, 'models', FLAGS.model+'.py')\r\n\r\nMAX_NUM_POINT = 1228\r\nNUM_CLASSES = 600\r\n\r\nHOSTNAME = socket.gethostname()\r\nprint('HOSTNAME: ', HOSTNAME)\r\n\r\ndef evaluate():\r\n    #with tf.device('/gpu:'+str(GPU_INDEX)):\r\n    with tf.device('/device:gpu:1'):\r\n        pointclouds_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\r\n        is_training_pl = tf.placeholder(tf.bool, shape=())\r\n\r\n\r\n        # simple model\r\n        feat = MODEL.get_model(pointclouds_pl, is_training_pl)\r\n        \r\n        # Add ops to save and restore all the variables.\r\n        saver = tf.train.Saver()\r\n        \r\n    # Create a session\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    config.allow_soft_placement = True\r\n    config.log_device_placement = True\r\n    sess = tf.Session(config=config)\r\n\r\n    # Restore variables from disk.\r\n    saver.restore(sess, MODEL_PATH)\r\n\r\n    ops = {'pointclouds_pl': pointclouds_pl,\r\n           'is_training_pl': is_training_pl,\r\n           'feat': feat}\r\n\r\n    eval_one_epoch(sess, ops)\r\n\r\n   \r\ndef eval_one_epoch(sess, ops):\r\n    is_training = False\r\n    input_list = None\r\n    with open(FLAGS.input_list, 'r') as f:\r\n        input_list = f.readlines()\r\n    \r\n    for fn in range(len(input_list)):\r\n        current_data = pickle.load(open(fn, 'rb'))\r\n        current_data = current_data[None, :NUM_POINT, :]\r\n        \r\n            \r\n        feed_dict = {ops['pointclouds_pl']: current_data,\r\n                     ops['is_training_pl']: is_training}\r\n        feat = sess.run([ops['feat']], feed_dict=feed_dict)\r\n        print('filename: ', fn)\r\n        pickle.dump(feat, open(fn[:-4] + '_feature.pkl', 'wb'))\r\n\r\nwith tf.Graph().as_default():\r\n    evaluate()\r\n```\r\n\r\nhere's `nvtop` output:\r\n![Screenshot from 2021-06-08 02-24-06](https://user-images.githubusercontent.com/76495162/121133688-a6449600-c800-11eb-9893-b2763ebbbaca.png)\r\n\r\nhttps://github.com/DirtyHarryLYL/DJ-RN/issues/64\r\n", "comments": ["@monacv ,\r\n\r\nCould you please run the below code snippet and share the results.\r\n\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n\r\nAlso, take a look at the TensorFlow profiling tool [link #1](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras), [link #2](https://www.tensorflow.org/guide/profiler#gpu_kernel_stats) ,[Link](https://github.com/tensorflow/tensorflow/issues/47001#issuecomment-780457956) and let us know if it helps. Thanks!", "@tilakrayal \r\n\r\nThanks for your response.\r\n\r\nHere's the result that you requested:\r\n\r\n```\r\n(djrn) [jalal@goku ~]$ python\r\nPython 3.8.5 (default, Mar 31 2021, 02:37:07) \r\n[GCC 7.3.1 20180303 (Red Hat 7.3.1-5)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n2021-06-09 02:09:07.837418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2021-06-09 02:09:07.893068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-06-09 02:09:07.894680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\npciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-06-09 02:09:07.895123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-09 02:09:07.898138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2021-06-09 02:09:07.901479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2021-06-09 02:09:07.902020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2021-06-09 02:09:07.905551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2021-06-09 02:09:07.907255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2021-06-09 02:09:07.913275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2021-06-09 02:09:07.918778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\nNum GPUs Available:  2\r\n```", "@tilakrayal could you please have a look at here (it kind of gets stuck here):\r\n\r\nhttps://pastebin.com/raw/ke8FK3pT\r\n\r\nexample lines (cannot copy whole thing here):\r\n```\r\n(djrn) [jalal@goku ~]$ cd /scratch3/research/code/DJ-RN-dawnlight/pointnet/\r\n(djrn) [jalal@goku pointnet]$ python Feature_extraction.py --input_list ../vertex_path_GT.txt --model pointnet_hico --model_path ../Feature_extraction/model_10000.ckpt\r\nWARNING:tensorflow:From /scratch3/venv/djrn/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\nGPU_INDEX:  1\r\nHOSTNAME:  goku.bu.edu\r\nWARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\r\nWARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\r\n2021-06-09 02:11:40.272649: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2021-06-09 02:11:40.278565: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3597875000 Hz\r\n2021-06-09 02:11:40.279186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4639580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-06-09 02:11:40.279212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-06-09 02:11:40.281451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2021-06-09 02:11:40.992891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x469faa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2021-06-09 02:11:40.992980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2021-06-09 02:11:40.993014: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2021-06-09 02:11:41.002244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-06-09 02:11:41.003897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\npciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-06-09 02:11:41.004425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-09 02:11:41.009093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2021-06-09 02:11:41.012839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2021-06-09 02:11:41.013441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2021-06-09 02:11:41.017564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2021-06-09 02:11:41.019963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2021-06-09 02:11:41.027162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2021-06-09 02:11:41.034845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\n2021-06-09 02:11:41.034924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-09 02:11:41.039735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-06-09 02:11:41.039784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 \r\n2021-06-09 02:11:41.039810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y \r\n2021-06-09 02:11:41.039834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N \r\n2021-06-09 02:11:41.043792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2021-06-09 02:11:41.045616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10376 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\r\n/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\r\n2021-06-09 02:11:41.046866: I tensorflow/core/common_runtime/direct_session.cc:359] Device mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\r\n/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\r\n\r\ntransform_net1/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.086675: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/weights/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086731: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086758: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086793: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086822: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086856: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086878: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/weights/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.086904: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weights/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.086933: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/weight_loss: (Mul): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.086957: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/weight_loss: (Mul): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.086980: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/biases: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.087004: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/biases: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/biases/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.087032: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/biases/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/biases/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-06-09 02:11:41.087056: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/biases/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\ntransform_net1/tconv1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087080: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/beta: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087109: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/beta: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/beta/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087135: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/beta/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/beta/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087158: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/beta/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/gamma: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087184: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/gamma: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/gamma/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087210: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/gamma/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/gamma/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087234: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/gamma/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/moments/mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087257: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/moments/mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:1\r\ntransform_net1/tconv1/bn/moments/StopGradient: (StopGradient): /job:localhost/replica:0/task:0/device:GPU:1\r\n2021-06-09 02:11:41.087281: I tensorflow/core/common_runtime/placer.cc:114] transform_net1/tconv1/bn/moments/StopGradient: (StopGradient): /job:localhost/replica:0/task:0/device:GPU:1\r\n```\r\n\r\nAs for profiler, unfortunately I never used the Tensorflow profiler and I am not even sure how to incorporate it to this code (which isn't mine) :( ", "Another thing that is pretty much confusing me is that if we are setting TF to use GPU 1, why is it also using GPU 0 as shown below that PID 11680 is using both GPU 0 and GPU 1? Yet, both have a near-zero GPU utilization.\r\n![Screenshot from 2021-06-09 02-18-07](https://user-images.githubusercontent.com/76495162/121303462-1b7b9e00-c8c9-11eb-8520-74f0ff77ba5f.png)\r\n", "also, when I CTL+ c that, I see the below. Does it get stuck in some sort of IO?\r\n```\r\n\r\nt/replica:0/task:0/device:CPU:0\r\n^T^C^XTraceback (most recent call last):\r\n  File \"Feature_extraction.py\", line 92, in <module>\r\n    evaluate()\r\n  File \"Feature_extraction.py\", line 71, in evaluate\r\n    eval_one_epoch(sess, ops)\r\n  File \"Feature_extraction.py\", line 81, in eval_one_epoch\r\n    current_data = pickle.load(open(fn, 'rb'))\r\nKeyboardInterrupt\r\n```\r\n", "There was an error in the original code by the authors. They should have written\r\n`\r\n    for fn in input_list:`\r\n\r\ninstead of\r\n\r\n`    for fn in range(len(input_list)):`\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50139\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50139\">No</a>\n"]}, {"number": 50138, "title": "Need to fetch version from TFLite Model", "body": "https://github.com/tensorflow/tensorflow/issues/47176 \r\n\r\nI have downloaded / created tfLite Model.\r\n\r\nHow do i know the version of the tfLite Model from just the flatbuffer model(*.tflite ) file..\r\nCan i fetch the version information from this model ?\r\n\r\nDuring automation, I was trying to fetch the TFLite Models and running inference over them. Currently , I am using TFLite 2.4.1 library. The models created above this versions which has unsupported operations, need to error out.\r\n\r\nWhat is the best way of handling ? How to get TFLite version from the model.", "comments": ["The \"min_runtime_version\" model metadata in the TFLite mode file contains the information that describes the minimal runtime version capable of running the given model.\r\n\r\nThe above value in the TFLite flatbuffer schema can be read by the existing C++ and Python schema libraries. For example,\r\n\r\n```\r\nfrom tensorflow.lite.python import schema_py_generated as schema_fb\r\n\r\ntflite_model = schema_fb.Model.GetRootAsModel(model_buf, 0)\r\n\r\n# Gets metadata from the model file.\r\nfor i in range(tflite_model.MetadataLength()):\r\n  meta = tflite_model.Metadata(i)\r\n  if meta.Name().decode(\"utf-8\") == \"min_runtime_version\":\r\n    buffer_index = meta.Buffer()\r\n    metadata = tflite_model.Buffers(buffer_index)\r\n    min_runtime_version_bytes = metadata.DataAsNumpy().tobytes()\r\n```\r\n\r\nReferences:\r\n[Model metadata table in TFLite flatbuffer schema](https://github.com/tensorflow/tensorflow/blob/8ad56264b31e0ae8c984f3c2f2ef0dc18cd6540b/tensorflow/lite/schema/schema.fbs#L1156)\r\n", "Does this meta data available for all models ? Does it work ?\r\nHow to add the meta data to the model if it does not have?\r\nIs there any validation to check if meta data exists or not ?", "At least, converted models using TF 2.4 version always contains the metadata.", "How to add the meta data to the model if it does not have?\r\nIs there any validation to check if meta data exists or not ?\r\n\r\nI am using TF version 2.1. Do i need to manually add ?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50137, "title": "custom op: how to delete variables in private", "body": "For `OpKernel`, the example shows OpKernelConstruction and Compute. Which function can we override to delete and free pointer variables defined in `private`?  \r\nFor example, pytorch custom op can do \r\n```\r\nprivate:\r\n   SpecialVariable<T> *vector_variables;\r\n\r\n~CustomOp() override {\r\n  delete [] vector_variables\r\n}\r\n```\r\n\r\ntensorflow example: https://www.tensorflow.org/guide/create_op", "comments": []}, {"number": 50136, "title": "How to get any tensorflow version to work with CUDA 10.2 in CentOS 7?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n\r\nHow should I fix this in CentOS 7?\r\n\r\n    [jalal@goku ~]$ pip freeze | grep tensorflow\r\n    tensorflow-estimator==2.2.0\r\n    tensorflow-gpu==2.2.0\r\n    [jalal@goku ~]$ python\r\n    Python 3.8.5 (default, Mar 31 2021, 02:37:07) \r\n    [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)] on linux\r\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n    >>> import tensorflow as tf\r\n    >>> print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n    2021-06-07 23:50:07.811271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n    2021-06-07 23:50:07.867796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\n    pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\n    coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n    2021-06-07 23:50:07.869403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\n    pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\n    coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n    2021-06-07 23:50:07.870136: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:\r\n    2021-06-07 23:50:07.874249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n    2021-06-07 23:50:07.877819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n    2021-06-07 23:50:07.878745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n    2021-06-07 23:50:07.882687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n    2021-06-07 23:50:07.884788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n    2021-06-07 23:50:07.890952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n    2021-06-07 23:50:07.891011: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\n    Skipping registering GPU devices...\r\n    Num GPUs Available:  0\r\n\r\nThis is despite having two GPUs:\r\n[![enter image description here][1]][1]\r\n\r\n    [jalal@goku ~]$ lsb_release -a\r\n    LSB Version:\t:core-4.1-amd64:core-4.1-noarch\r\n    Distributor ID:\tCentOS\r\n    Description:\tCentOS Linux release 7.9.2009 (Core)\r\n    Release:\t7.9.2009\r\n    Codename:\tCore\r\n\r\n\r\nalso, \r\n\r\n    $ nvcc --version\r\n    nvcc: NVIDIA (R) Cuda compiler driver\r\n    Copyright (c) 2005-2018 NVIDIA Corporation\r\n    Built on Sat_Aug_25_21:08:01_CDT_2018\r\n    Cuda compilation tools, release 10.0, V10.0.130\r\n\r\nI tried the following as suggested by https://github.com/tensorflow/tensorflow/issues/38194#issuecomment-629801937 and didn't work:\r\n\r\n    [jalal@goku djrn]$ ls /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2\r\n    lrwxrwxrwx. 1 root root 20 Sep 21  2020 /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2 -> libcudart.so.10.2.89\r\n    [jalal@goku djrn]$ sudo ln -s /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2 /usr/lib/x86_64-linux-gnu/libcudart.so.10.1\r\n    [sudo] password for jalal: \r\n    ln: failed to create symbolic link \u2018/usr/lib/x86_64-linux-gnu/libcudart.so.10.1\u2019: No such file or directory\r\n\r\n\r\n\r\nTo be specific, I need tensforflow to work with CUDA 10.2, I am fine with any version of tensorflow (preference is tensorflow 2+), however couldn't find a version that works with CUDA 10.2. https://www.tensorflow.org/install/source#tested_build_configurations \r\n\r\nAlso, based on this, my `CUDA` version is `10.2` which is different from both `nvidia-smi` and `nvcc --version` versions: \r\n\r\n    $ stat /usr/local/cuda\r\n      File: \u2018/usr/local/cuda\u2019 -> \u2018/usr/local/cuda-10.2\u2019\r\n      Size: 20        \tBlocks: 0          IO Block: 4096   symbolic link\r\n    Device: fd00h/64768d\tInode: 67157410    Links: 1\r\n    Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)\r\n    Context: unconfined_u:object_r:usr_t:s0\r\n    Access: 2021-05-20 10:43:06.864530636 -0400\r\n    Modify: 2020-09-21 09:39:18.559883390 -0400\r\n    Change: 2020-09-21 09:39:18.559883390 -0400\r\n     Birth: -\r\n\r\n\r\nP.S.: I have made my virtual environment using `python venv` command and don't want to use `conda` or `pyenv`.\r\n  [1]: https://i.stack.imgur.com/g2CFZ.png\r\n\r\n", "comments": ["```\r\n$ sudo ln -s /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2 /usr/lib/x86_64-linux-gnu/libcudart.so.10.1\r\n$ export LD_LIBRARY_PATH=/usr/lib\r\n```\r\n\r\nhttps://stackoverflow.com/a/67882048/2414957", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50136\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50136\">No</a>\n"]}, {"number": 50135, "title": "[determinism] Factor core/kernels RequireDeterminism() into library", "body": "This PR performs a few housekeeping tasks related to GPU-determinism, the most significant of which is factoring various instances of the `RequireDeterminism` function in `core/kernels` into (the previously-implemented) `core/kernels/util/determinism.cc/.h` (as `OpDeterminismRequired`), a follow-up to [this conversation](https://github.com/tensorflow/tensorflow/pull/47772#discussion_r594847461) with @sanjoy on PR [47772](https://github.com/tensorflow/tensorflow/pull/47772).\r\n\r\ncc @reedwm @nluehr", "comments": []}, {"number": 50133, "title": "Create pylint-presubmit.yml", "body": "This is a non-blocking check that runs `pylint` if a PR changes Python files. It's based on the [TensorFlow code style guide](https://www.tensorflow.org/community/contribute/code_style) instructions for running Pylint.\r\n\r\nThis should be a more useful result than the `ci_sanity` Pylint job, since it's consistent. I don't think we can really know if it aligns exactly with the internal pylint, since the configuration is different: while we look into that, this should be a useful check for users.", "comments": ["I'm having trouble getting this to run so that:\r\n\r\n- If there are no changed Python files, succeed.\r\n- If there are changed Python files, run pylint.\r\n\r\nJust getting stuck on bash.", "This is nice, I have just an extra idea.\r\nAs we have already `pylint` and `clang-format` pre-commit hooks in https://github.com/tensorflow/tensorflow/pull/48371 can we use the docker image that we publish for contributors and developers in this Action?\r\n\r\nSo we are quite sure to be aligned between the git Action we run here and the local linting that the developer run locally in the environment that we distribute.", "> As we have already pylint and clang-format pre-commit hooks in #48371 can we use the docker image that we publish for contributors and developers in this Action?\r\n\r\nI think it'll be good to synchronize the environment when the newer Docker images are available.", "> when the newer Docker images are available.\r\n\r\nWhat is blocking https://github.com/tensorflow/tensorflow/pull/48371? \r\nOr do you mean when we will upstream https://github.com/tensorflow/build/tree/dockerfiles/experimental_official_dockerfiles?", "I mean the upstream ones, yes. I don't want to integrate the `devel` containers while working on those other new containers.", "> I mean the upstream ones, yes. I don't want to integrate the `devel` containers while working on those other new containers.\n\nIf we have enought resources for the new images  we could cherry pick the pre-commit hooks in my PR and push in your images instead of the official `devel`.", "Just for the record:\r\nWe already have a Github Action for pylint in model garden https://github.com/tensorflow/models/blob/master/.github/workflows/ci.yml\r\n\r\n"]}, {"number": 50131, "title": "Update bot_config.yml", "body": "Removed whitepsace since the compatibility table was rendering as a plain text.", "comments": []}, {"number": 50129, "title": "Update sparse_cross_op.cc", "body": " Fix Build issue error: extraneous ')' before ';'", "comments": []}, {"number": 50128, "title": "Update sparse_cross_op.cc", "body": " Fix Build issue error: extraneous ')' before ';'", "comments": []}, {"number": 50127, "title": "GPU and NNAPI not working in Tensorflow Classify", "body": "I am using this android aplication : https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification\r\n\r\n In this when I am selecting GPU or NNAPI along with Float_EfficientNet or Float_MobileNet, I am getting the following error: \"Manipulating the hardware accelerators is not allowed in the task library. Only CPU is allowed\". I am using K20 Pro mobile which is equipped with Adreno 640 GPU. I have added all the dependencies which were asked.", "comments": ["@ANTASGUPTA \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]Thanks\r\n", "I believe that the Java version of the task library doesn't support hardware acceleration yet, and the error you're seeing is expected. See:\r\n\r\nhttps://www.tensorflow.org/lite/inference_with_metadata/task_library/overview\r\n\r\nYou'll be able to use the GPU / NNAPI option when running the example with `lib_support` version.\r\n\r\n@lu-wang-g @xunkai55 to confirm. ", "Thanks @yyoon. Indeed Task Library currently doesn't has acceleration support (but it will come soon!)\r\n\r\nAn other option: Please try use support library module instead of task api module. We provide both in that example app for users to find a fit. Move the default from \"taskApi\" to \"support\": https://github.com/tensorflow/examples/blob/2c3b90942fc9b4458140a197f02c31285f172d4c/lite/examples/image_classification/android/app/build.gradle#L38", "@xunkai55 \r\nAs mentioned in line #38 \r\ntaskApi {           getIsDefault().set(true)           dimension \"tfliteInference\"       }.\r\nI have done the same thing, i.e. set taskApi to True but then also, there is no change in the output.\r\nCan you please tell me, what I should do now?\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@ANTASGUPTA Sorry for not saying that clear. I suggest that to move the default to `support` (move line 38 to line 34, particularly) and then retry. Please do let us know if that still not works.", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50126, "title": " ' ValueError: `to_quantize` can only either be a tf.keras Sequential or Functional model.", "body": "I've tried QAT implementation in my model training script. I'm using functional API for the model creation. \r\nSteps that I followed to implement QAT API:\r\n\r\n1. Build the model acrhitecture\r\n2. Inserted the appropriate quantize_model function\r\n3. Train the model\r\nLet me provide you the code snippet for more clearance\r\n         \r\n        words_input = Input(shape=(None,),dtype='int32',name='words_input')\r\n        words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)    \r\n        ............\r\n        convd_output= SeparableConv1D(kernel_size=4, filters=128, padding='same', activation='relu', strides=1, depth_multiplier=3, bias_regularizer=regularizers.l2(0.0001), kernel_constraint =min_max_norm(0.4,0.9))(output)\r\n        #convd_output=tfmot.quantization.keras.quantize_annotate_layer(AveragePooling1D(pool_size=2, strides=1, padding='same')(convd_output)\r\n        convd_output=AveragePooling1D(pool_size=2, strides=1, padding='same')(convd_output)\r\n        convd_output=Dropout(0.1)(convd_output)\t\r\n        ...................\r\n        flatten_output=TimeDistributed(Flatten())(pool_output)          \r\n        \r\n        output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(flatten_output)\r\n\r\n        inputs_list=[words_input, casing_input,newline_input]\r\n        model = Model(*inputs_list, output)\r\n        q_aware_model = tfmot.quantization.keras.quantize_model(model)\r\n        opt = Nadam(lr=0.0005)       \r\n        q_aware_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics = ['sparse_categorical_accuracy'])\r\n        print(q_aware_model.summary())\r\n\r\n**Version details**\r\ntensorflow==1.15.3\r\ntensorflow-model-optimization==0.5.0\r\n\r\n\r\n**Issue :** I'm using functional API which i supported in QAT API, but still I'm getting a value error\r\n\r\n quantize_model     '`to_quantize` can only either be a tf.keras Sequential or\r\n**ValueError:** `to_quantize` can only either be a tf.keras Sequential or Functional model.\r\n\r\nCouldn't able to figure out the issue. It will be helpful if someone help to get over this. \r\nThanks in advance", "comments": ["@Raisa06 ,\r\n\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the version 2.x  and check if you are facing the same issue. Thanks!", "Yes @tilakrayal  I've upgraded tensorflow to 2.3.0 and tensorflow_model_optimization == 0.5.0\r\nBut still facing the same issue.", "Keras quantization API:\r\nVersion to be used \r\nReference : https://github.com/tensorflow/model-optimization/releases\r\n", "@Raisa06 ,\r\n\r\nIn order to expedite the trouble-shooting process, can you please provide the complete updated code or gist to reproduce the issue.Thanks!", "Let me provide you the model architecture\r\n\r\n    def create_model(self, input1Embeddings,input2Embeddings,char2Idx, label2Idx,input3Embeddings):\r\n\r\n        input_1= Input(shape=(None,),dtype='int32',name='input_1')\r\n        text_1 = Embedding(input_dim=input1Embeddings.shape[0], output_dim=input1Embeddings.shape[1],  weights=[input1Embeddings], trainable=False)(input_1)\r\n        input_2= Input(shape=(None,), dtype='int32', name='input_2')\r\n        text_2= Embedding(output_dim=input2Embeddings.shape[1], input_dim=input2Embeddings.shape[0], weights=[input2Embeddings], trainable=False)(input_2)\r\n        input_3= Input(shape=(None,), dtype='int32', name='input_3')\r\n        text_3= Embedding(output_dim=input3Embeddings.shape[1], input_dim=input3Embeddings.shape[0], weights=[input3Embeddings], trainable=False)(input_3)        \r\n\r\n        output = concatenate([text_1, text_2,text_3])\r\n\r\n        convd_output= SeparableConv1D(kernel_size=4, filters=128, padding='same', activation='relu', strides=1, depth_multiplier=3, bias_regularizer=regularizers.l2(0.0001), kernel_constraint =min_max_norm(0.4,0.9))(output)\r\n        convd_output=AveragePooling1D(pool_size=2, strides=1, padding='same')(convd_output)\r\n        convd_output=Dropout(0.1)(convd_output)\r\n\t\t\r\n        convd_output_1= SeparableConv1D(kernel_size=64, filters=128, padding='same', activation='relu', strides=1, depth_multiplier=3, bias_regularizer=regularizers.l2(0.0001), kernel_constraint =min_max_norm(0.4,0.9))(convd_output)\r\n        pool_output1=AveragePooling1D(pool_size=5, strides=1, padding='same')(convd_output_1)\r\n        pool_output1=Dropout(0.1)(pool_output1)\r\n\t\t\r\n        convd_output_2= SeparableConv1D(kernel_size=32, filters=128, padding='same', activation='relu', strides=1, depth_multiplier=3, bias_regularizer=regularizers.l2(0.0001), kernel_constraint =min_max_norm(0.4,0.9))(pool_output1)\r\n        pool_output=AveragePooling1D(pool_size=3, strides=1, padding='same')(convd_output_2) \r\n        pool_output=Dropout(0.3)(pool_output)\r\n        flatten_output=TimeDistributed(Flatten())(output)          \r\n        \r\n        output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(flatten_output)\r\n\r\n        inputs_list=[input_1, input_2,input_3]\r\n        model = Model(*inputs_list, output)\r\n\r\n        opt = Nadam(lr=0.0005)\r\n        quant_aware_model = tfmot.quantization.keras.quantize_model(model)\r\n        \r\n        quant_aware_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics = ['sparse_categorical_accuracy'])\r\n\r\n        print(quant_aware_model.summary())\r\n        return quant_aware_model", "@Raisa06 ,\r\n\r\nLooks like code is incomplete. Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/b47865ade16c250d554506a338b1b63b/untitled50126.ipynb). Request you to provide complete code or colab link to reproduce the issue  in our environment. It helps us in localizing the issue faster.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50125, "title": "tf.case evaluates all operations", "body": "Hi:\r\n\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/case\r\n\r\nFrom this official link, The tensors returned by the first pair whose predicate evaluated to True, or those returned by default if none does. If exclusive==False, execution stops at the first predicate which evaluates to True. But it seems that the tf.case still tries to run all operations although it should stop at the first one.\r\n\r\nMy code:\r\n~~~~~~~~~~~~~~~~~~~~~\r\nimport tensorflow as tf\r\nsess = tf.InteractiveSession()\r\nx = 1.0\r\nf1 = lambda: tf.constant(10.)\r\nf2 = lambda: tf.constant(x/(x-1.0))\r\nr = tf.case([(tf.less(x, 100.), f1)], default=f2, exclusive=False)\r\n~~~~~~~~~~~~~~~~~~~~~~~\r\nIt produces error. r is supposed to return the value of f1, but it still tries to run f2 and produces error as follows: ZeroDivisionError: float division by zero.\r\n\r\nAny suggestion what function I should use so the function can avoid run function f2 so it does not produce error? I have a more complex situation with this same issue. Thanks! I also tried tf.cond, it also produces error.  Thanks! \r\n\r\n**System information**\r\n- OS Platform and Distribution: linux\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.7.6", "comments": ["hi @saikumarchalla , could you please look at my issue at your convenience? Thanks. ", "hi @google-admin  Nobody started to look at my issue yet, could you please help? Thanks!", "@shangh1  Could you please upgrade to TF 2.x version since 1.x version is no more actively supported. Aplogize for the delay.Thanks!", "hi @saikumarchalla, thanks! Sorry for the late reply, I was camping last few days with bad signal. Upgrading to TF 2. version will involve the change for the whole framework, and our production model currently uses TF 1. if this tf.case is not actively supported in TF1. Is there any other functions you know in TF 1 that can overcome this issue? Thanks! \r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50125\">No</a>\n", "@shangh1,\r\nWe recommend the Developers to switch to **`Tensorflow Version, 2.x`**.  Please refer the [Migration Guide](https://www.tensorflow.org/guide/migrate) and [Upgrade Guide](https://www.tensorflow.org/guide/upgrade) which makes migration from **`Tensorflow Version 1.x`** to **`Tensorflow Version 2.x`** easier. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50125\">No</a>\n"]}, {"number": 50122, "title": "Fix systemlib rule to support gRPC", "body": "Systemlib rules currently can't handle the systemlib build file appearing in the system link dictionary.\r\n\r\nThis occurs in the gRPC target here:\r\nhttps://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/workspace2.bzl#L639\r\n\r\nGentoo (the primary client of systemlib) only packages TF 2.4.0,\r\npotentially explaining why the new systemlib logic hasn't been exercised\r\nfor gRPC.\r\n\r\nThis change fixes the issue with the systemlib logic.", "comments": ["@perfinion what do you think of this approach?"]}, {"number": 50121, "title": "No module named 'compat'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.x\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ni install conda env(include tensorflow, slim, object-detection etc)\r\nNo module named 'compat'\r\n\r\n![\u4f01\u4e1a\u5fae\u4fe1\u622a\u56fe_16230466543453](https://user-images.githubusercontent.com/50159788/120968328-4ff13c00-c79b-11eb-83b6-73bed46b9ac9.png)\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@pedro-abundio-wang \r\nCan you verify if:\r\n\r\nimport tensorflow as tf\r\nprint(tf.__version__)  works fine, \r\nWe see that you have not filled in the issue template, please let us know the python version,tf version used, what os are you on is it 64 bit.\r\nYou may also refer to similar issues #38800.", "> @pedro-abundio-wang\r\n> Can you verify if:\r\n> \r\n> import tensorflow as tf\r\n> print(tf.**version**) works fine,\r\n> We see that you have not filled in the issue template, please let us know the python version,tf version used, what os are you on is it 64 bit.\r\n> You may also refer to similar issues #38800.\r\n\r\nprint(tf.version) \r\noutput:\r\n<module 'tensorflow._api.v2.version' from 'H:\\\\Miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\r\n\r\n(base) H:\\models>python --version\r\nPython 3.8.5\r\n\r\nos: windows 64bit\r\n", "@pedro-abundio-wang \r\nCan you install with PIP as follows,\r\npip install tensorflow==2.4\r\nLet us know if issue still persists. \r\nAlso,\r\nPlease try on venv and let us know if you still face the issue,Thanks!", "> @pedro-abundio-wang\r\n> Please try on venv and let us know if you still face the issue.\r\n\r\nYes I am able to import tensorflow and all the other functionalities are working fine and I see only .compat.v1 issue for now.\r\nAnd i met the same problem, on ubuntu-16.04 x64 and conda env, or ubuntu-18.04 x64 tensorflow 2.2 or tf 2.4. or tf 2.5 and conda env", "this is my conda env, after i install tensorflow 2.4, .compat.v1 issue have the same problem.\r\n\r\n(base) H:\\models>conda env export\r\nname: base\r\nchannels:\r\n  - defaults\r\ndependencies:\r\n  - brotlipy=0.7.0=py38h2bbff1b_1003\r\n  - ca-certificates=2020.10.14=0\r\n  - certifi=2020.6.20=pyhd3eb1b0_3\r\n  - cffi=1.14.3=py38hcd4344a_2\r\n  - chardet=3.0.4=py38haa95532_1003\r\n  - conda=4.9.2=py38haa95532_0\r\n  - conda-package-handling=1.7.2=py38h76e460a_0\r\n  - console_shortcut=0.1.1=4\r\n  - cryptography=3.2.1=py38hcd4344a_1\r\n  - idna=2.10=py_0\r\n  - menuinst=1.4.16=py38he774522_1\r\n  - openssl=1.1.1h=he774522_0\r\n  - pip=20.2.4=py38haa95532_0\r\n  - powershell_shortcut=0.0.1=3\r\n  - pycosat=0.6.3=py38h2bbff1b_0\r\n  - pycparser=2.20=py_2\r\n  - pyopenssl=19.1.0=pyhd3eb1b0_1\r\n  - pysocks=1.7.1=py38haa95532_0\r\n  - python=3.8.5=h5fd99cc_1\r\n  - pywin32=227=py38he774522_1\r\n  - requests=2.24.0=py_0\r\n  - ruamel_yaml=0.15.87=py38he774522_1\r\n  - setuptools=50.3.1=py38haa95532_1\r\n  - six=1.15.0=py38haa95532_0\r\n  - sqlite=3.33.0=h2a8f88b_0\r\n  - tqdm=4.51.0=pyhd3eb1b0_0\r\n  - urllib3=1.25.11=py_0\r\n  - vc=14.1=h0510ff6_4\r\n  - vs2015_runtime=14.16.27012=hf0eaf9b_3\r\n  - wheel=0.35.1=pyhd3eb1b0_0\r\n  - win_inet_pton=1.1.0=py38haa95532_0\r\n  - wincertstore=0.2=py38_0\r\n  - yaml=0.2.5=he774522_0\r\n  - zlib=1.2.11=h62dcd97_4\r\n  - pip:\r\n    - absl-py==0.12.0\r\n    - argon2-cffi==20.1.0\r\n    - astunparse==1.6.3\r\n    - async-generator==1.10\r\n    - attrs==21.2.0\r\n    - backcall==0.2.0\r\n    - bleach==3.3.0\r\n    - cachetools==4.2.2\r\n    - colorama==0.4.4\r\n    - cycler==0.10.0\r\n    - decorator==5.0.9\r\n    - defusedxml==0.7.1\r\n    - entrypoints==0.3\r\n    - flatbuffers==1.12\r\n    - gast==0.3.3\r\n    - google-auth==1.30.1\r\n    - google-auth-oauthlib==0.4.4\r\n    - google-pasta==0.2.0\r\n    - grpcio==1.32.0\r\n    - h5py==2.10.0\r\n    - ipykernel==5.5.5\r\n    - ipython==7.24.1\r\n    - ipython-genutils==0.2.0\r\n    - ipywidgets==7.6.3\r\n    - jedi==0.18.0\r\n    - jinja2==3.0.1\r\n    - jsonschema==3.2.0\r\n    - jupyter==1.0.0\r\n    - jupyter-client==6.1.12\r\n    - jupyter-console==6.4.0\r\n    - jupyter-core==4.7.1\r\n    - jupyterlab-pygments==0.1.2\r\n    - jupyterlab-widgets==1.0.0\r\n    - keras-nightly==2.5.0.dev2021032900\r\n    - keras-preprocessing==1.1.2\r\n    - kiwisolver==1.3.1\r\n    - markdown==3.3.4\r\n    - markupsafe==2.0.1\r\n    - matplotlib==3.4.2\r\n    - matplotlib-inline==0.1.2\r\n    - mistune==0.8.4\r\n    - nbclient==0.5.3\r\n    - nbconvert==6.0.7\r\n    - nbformat==5.1.3\r\n    - nest-asyncio==1.5.1\r\n    - notebook==6.4.0\r\n    - numpy==1.19.5\r\n    - oauthlib==3.1.1\r\n    - opt-einsum==3.3.0\r\n    - packaging==20.9\r\n    - pandocfilters==1.4.3\r\n    - parso==0.8.2\r\n    - pickleshare==0.7.5\r\n    - pillow==8.2.0\r\n    - prometheus-client==0.11.0\r\n    - prompt-toolkit==3.0.18\r\n    - protobuf==3.17.2\r\n    - pyasn1==0.4.8\r\n    - pyasn1-modules==0.2.8\r\n    - pygments==2.9.0\r\n    - pyparsing==2.4.7\r\n    - pyrsistent==0.17.3\r\n    - python-dateutil==2.8.1\r\n    - pywinpty==1.1.1\r\n    - pyzmq==22.1.0\r\n    - qtconsole==5.1.0\r\n    - qtpy==1.9.0\r\n    - requests-oauthlib==1.3.0\r\n    - rsa==4.7.2\r\n    - send2trash==1.5.0\r\n    - tensorboard==2.5.0\r\n    - tensorboard-data-server==0.6.1\r\n    - tensorboard-plugin-wit==1.8.0\r\n    - tensorflow==2.4.0\r\n    - tensorflow-estimator==2.4.0\r\n    - termcolor==1.1.0\r\n    - terminado==0.10.0\r\n    - testpath==0.5.0\r\n    - tornado==6.1\r\n    - traitlets==5.0.5\r\n    - typing-extensions==3.7.4.3\r\n    - wcwidth==0.2.5\r\n    - webencodings==0.5.1\r\n    - werkzeug==2.0.1\r\n    - widgetsnbextension==3.5.1\r\n    - wrapt==1.12.1\r\nprefix: H:\\Miniconda3\r\n", "it is very strange. the following code can run, and i try both intelliJ and pycharm ide, both have compat.v1 issue.\r\n\r\n![16231146173809](https://user-images.githubusercontent.com/50159788/121106844-68179880-c839-11eb-8971-462ddafbbcb2.png)\r\n\r\n\r\nimport tensorflow.compat.v1 as tf\r\na = tf.random_normal((10, 3))\r\nb = tf.random_normal((10, 3))\r\nc = tf.reduce_sum(tf.square(a - b))\r\nd = tf.square(tf.norm(a - b))\r\nprint(c)\r\nprint(d)\r\n\r\n--------------------------------------------------------------------------------\r\n\r\noutput: \r\n2021-06-08 09:04:16.053279: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-06-08 09:04:16.053740: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-06-08 09:04:19.423823: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-06-08 09:04:19.425956: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n2021-06-08 09:04:19.426321: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-06-08 09:04:19.429629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: WIN-IPP8JANJS7E\r\n2021-06-08 09:04:19.430092: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: WIN-IPP8JANJS7E\r\n2021-06-08 09:04:19.431193: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-06-08 09:04:19.432110: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\ntf.Tensor(60.59104, shape=(), dtype=float32)\r\ntf.Tensor(60.59104, shape=(), dtype=float32)\r\n\r\n\r\n\r\n", "@pedro-abundio-wang \r\nfrom the error log above, can you verify the cuda path, and verify \"os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\") before importing tensorflow\"\r\nand ensure Cuda 11.0 and cudnn 8.0 is present.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @pedro-abundio-wang\r\n> from the error log above, can you verify the cuda path, and verify \"os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\") before importing tensorflow\"\r\n> and ensure Cuda 11.0 and cudnn 8.0 is present.\r\n\r\nsorry for delay response.\r\nI retry this problem on linux system(ubuntu), and after i install gpu-driver, cuda-11.2 and cudnn 8.0, the environment information as following.\r\n\r\n### **gpu-driver works fine.**\r\n\r\n![Screenshot from 2021-06-19 15-20-10](https://user-images.githubusercontent.com/50159788/122634648-e6b1e700-d111-11eb-81ac-229c2a99f368.png)\r\n\r\n### **cuda works fine.**\r\n\r\n![Screenshot from 2021-06-19 15-22-14](https://user-images.githubusercontent.com/50159788/122634682-27a9fb80-d112-11eb-9a39-2c5b997283e3.png)\r\n\r\n### **cudnn works fine.**\r\n\r\n(models) pedro@Pedro-Abundio-Wang:~/cudnn_samples_v8/mnistCUDNN$ ./mnistCUDNN \r\nExecuting: mnistCUDNN\r\ncudnnGetVersion() : 8100 , CUDNN_VERSION from cudnn.h : 8100 (8.1.0)\r\nHost compiler version : GCC 5.4.0\r\n\r\nThere are 1 CUDA capable devices on your machine :\r\ndevice 0 : sms 10  Capabilities 6.1, SmClock 1784.5 Mhz, MemSize (Mb) 6075, MemClock 4004.0 Mhz, Ecc=0, boardGroupID=0\r\nUsing device 0\r\n\r\nTesting single precision\r\nLoading binary file data/conv1.bin\r\nLoading binary file data/conv1.bias.bin\r\nLoading binary file data/conv2.bin\r\nLoading binary file data/conv2.bias.bin\r\nLoading binary file data/ip1.bin\r\nLoading binary file data/ip1.bias.bin\r\nLoading binary file data/ip2.bin\r\nLoading binary file data/ip2.bias.bin\r\nLoading image data/one_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 57600 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.045056 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.047872 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.119104 time requiring 57600 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.213280 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 3.618592 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 71.100418 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 128000 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.083968 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.154624 time requiring 128000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.174944 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.245760 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.702464 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 1.304576 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nResulting weights from Softmax:\r\n0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 \r\nLoading image data/three_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 57600 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.045760 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.046432 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.088064 time requiring 57600 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.198720 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.215072 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.223232 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 128000 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.059360 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.072704 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.074752 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.116736 time requiring 128000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.129664 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.169984 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nResulting weights from Softmax:\r\n0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 \r\nLoading image data/five_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 \r\n\r\nResult of classification: 1 3 5\r\n\r\nTest passed!\r\n\r\nTesting half precision (math in single precision)\r\nLoading binary file data/conv1.bin\r\nLoading binary file data/conv1.bias.bin\r\nLoading binary file data/conv2.bin\r\nLoading binary file data/conv2.bias.bin\r\nLoading binary file data/ip1.bin\r\nLoading binary file data/ip1.bias.bin\r\nLoading binary file data/ip2.bin\r\nLoading binary file data/ip2.bias.bin\r\nLoading image data/one_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 28800 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 100 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.061440 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.090720 time requiring 100 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.178272 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.183968 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.408576 time requiring 28800 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.441984 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 64000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.109472 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.127744 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.143360 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.166912 time requiring 64000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.192512 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.263168 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nResulting weights from Softmax:\r\n0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 \r\nLoading image data/three_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 28800 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 100 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.049152 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.076672 time requiring 28800 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.087680 time requiring 100 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.135520 time requiring 178432 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.150144 time requiring 184784 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.182272 time requiring 2057744 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnGetConvolutionForwardAlgorithm_v7 ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: -1.000000 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: -1.000000 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: -1.000000 time requiring 64000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: -1.000000 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: -1.000000 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.089088 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.102400 time requiring 2000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.150496 time requiring 64000 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.159584 time requiring 2450080 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.177152 time requiring 1433120 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 0.237120 time requiring 4656640 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 6: -1.000000 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_NOT_SUPPORTED for Algo 3: -1.000000 time requiring 0 memory\r\nResulting weights from Softmax:\r\n0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 \r\nLoading image data/five_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 \r\n\r\nResult of classification: 1 3 5\r\n\r\nTest passed!\r\n\r\n### **nvcc check**\r\n\r\n(models) pedro@Pedro-Abundio-Wang:~/cudnn_samples_v8/mnistCUDNN$ nvcc -V\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2020 NVIDIA Corporation\r\nBuilt on Mon_Nov_30_19:08:53_PST_2020\r\nCuda compilation tools, release 11.2, V11.2.67\r\nBuild cuda_11.2.r11.2/compiler.29373293_0\r\n\r\nbut still in intelliJIdea, \r\n\r\n![Screenshot from 2021-06-19 15-26-02](https://user-images.githubusercontent.com/50159788/122634741-ad2dab80-d112-11eb-823a-1978060a1df1.png)\r\n\r\nthe conda env list as following\r\n\r\n(models) pedro@Pedro-Abundio-Wang:~/deep-learning/models/research$ conda env list\r\n# conda environments:\r\n#\r\nbase                     /home/pedro/anaconda3\r\nGANs                     /home/pedro/anaconda3/envs/GANs\r\natom                     /home/pedro/anaconda3/envs/atom\r\ncomputer-vision          /home/pedro/anaconda3/envs/computer-vision\r\nd2l-numpy                /home/pedro/anaconda3/envs/d2l-numpy\r\ndeep-learning-specialization     /home/pedro/anaconda3/envs/deep-learning-specialization\r\nfastai                   /home/pedro/anaconda3/envs/fastai\r\nimage-classification     /home/pedro/anaconda3/envs/image-classification\r\nmodels                *  /home/pedro/anaconda3/envs/models\r\nnatural-language-processing     /home/pedro/anaconda3/envs/natural-language-processing\r\nopen-mmlab               /home/pedro/anaconda3/envs/open-mmlab\r\norigin                   /home/pedro/anaconda3/envs/origin\r\nploutos                  /home/pedro/anaconda3/envs/ploutos\r\nquantum                  /home/pedro/anaconda3/envs/quantum\r\ntensorflow-specialization     /home/pedro/anaconda3/envs/tensorflow-specialization\r\ntfjs-converter           /home/pedro/anaconda3/envs/tfjs-converter\r\nyad2k                    /home/pedro/anaconda3/envs/yad2k\r\n\r\n(models) pedro@Pedro-Abundio-Wang:~/deep-learning/models/research$ conda env export\r\nname: models\r\nchannels:\r\n  - defaults\r\ndependencies:\r\n  - _libgcc_mutex=0.1=main\r\n  - ca-certificates=2021.5.25=h06a4308_1\r\n  - certifi=2021.5.30=py38h06a4308_0\r\n  - ld_impl_linux-64=2.33.1=h53a641e_7\r\n  - libffi=3.3=he6710b0_2\r\n  - libgcc-ng=9.1.0=hdf63c60_0\r\n  - libstdcxx-ng=9.1.0=hdf63c60_0\r\n  - ncurses=6.2=he6710b0_1\r\n  - openssl=1.1.1k=h27cfd23_0\r\n  - pip=21.1.1=py38h06a4308_0\r\n  - python=3.8.10=hdb3f193_7\r\n  - readline=8.1=h27cfd23_0\r\n  - setuptools=52.0.0=py38h06a4308_0\r\n  - sqlite=3.35.4=hdfb4753_0\r\n  - tk=8.6.10=hbc83047_0\r\n  - wheel=0.36.2=pyhd3eb1b0_0\r\n  - xz=5.2.5=h7b6447c_0\r\n  - zlib=1.2.11=h7b6447c_3\r\n  - pip:\r\n    - absl-py==0.12.0\r\n    - argon2-cffi==20.1.0\r\n    - astunparse==1.6.3\r\n    - async-generator==1.10\r\n    - attrs==21.2.0\r\n    - backcall==0.2.0\r\n    - bleach==3.3.0\r\n    - cachetools==4.2.2\r\n    - cffi==1.14.5\r\n    - chardet==4.0.0\r\n    - decorator==5.0.9\r\n    - defusedxml==0.7.1\r\n    - entrypoints==0.3\r\n    - flatbuffers==1.12\r\n    - gast==0.4.0\r\n    - google-auth==1.30.1\r\n    - google-auth-oauthlib==0.4.4\r\n    - google-pasta==0.2.0\r\n    - grpcio==1.34.1\r\n    - h5py==3.1.0\r\n    - idna==2.10\r\n    - ipykernel==5.5.5\r\n    - ipython==7.24.1\r\n    - ipython-genutils==0.2.0\r\n    - ipywidgets==7.6.3\r\n    - jedi==0.18.0\r\n    - jinja2==3.0.1\r\n    - jsonschema==3.2.0\r\n    - jupyter==1.0.0\r\n    - jupyter-client==6.2.0\r\n    - jupyter-console==6.4.0\r\n    - jupyter-core==4.7.1\r\n    - jupyterlab-pygments==0.1.2\r\n    - jupyterlab-widgets==1.0.0\r\n    - keras-nightly==2.5.0.dev2021032900\r\n    - keras-preprocessing==1.1.2\r\n    - markdown==3.3.4\r\n    - markupsafe==2.0.1\r\n    - matplotlib-inline==0.1.2\r\n    - mistune==0.8.4\r\n    - nbclient==0.5.3\r\n    - nbconvert==6.0.7\r\n    - nbformat==5.1.3\r\n    - nest-asyncio==1.5.1\r\n    - notebook==6.4.0\r\n    - numpy==1.19.5\r\n    - oauthlib==3.1.1\r\n    - opt-einsum==3.3.0\r\n    - packaging==20.9\r\n    - pandocfilters==1.4.3\r\n    - parso==0.8.2\r\n    - pexpect==4.8.0\r\n    - pickleshare==0.7.5\r\n    - prometheus-client==0.11.0\r\n    - prompt-toolkit==3.0.18\r\n    - protobuf==3.17.2\r\n    - ptyprocess==0.7.0\r\n    - pyasn1==0.4.8\r\n    - pyasn1-modules==0.2.8\r\n    - pycparser==2.20\r\n    - pygments==2.9.0\r\n    - pyparsing==2.4.7\r\n    - pyrsistent==0.17.3\r\n    - python-dateutil==2.8.1\r\n    - pyyaml==5.4.1\r\n    - pyzmq==22.1.0\r\n    - qtconsole==5.1.0\r\n    - qtpy==1.9.0\r\n    - requests==2.25.1\r\n    - requests-oauthlib==1.3.0\r\n    - rsa==4.7.2\r\n    - scipy==1.6.3\r\n    - send2trash==1.5.0\r\n    - six==1.15.0\r\n    - tensorboard==2.5.0\r\n    - tensorboard-data-server==0.6.1\r\n    - tensorboard-plugin-wit==1.8.0\r\n    - tensorflow==2.5.0\r\n    - tensorflow-estimator==2.5.0\r\n    - termcolor==1.1.0\r\n    - terminado==0.10.0\r\n    - testpath==0.5.0\r\n    - tf-slim==1.1.0\r\n    - tornado==6.1\r\n    - traitlets==5.0.5\r\n    - typing-extensions==3.7.4.3\r\n    - urllib3==1.26.5\r\n    - wcwidth==0.2.5\r\n    - webencodings==0.5.1\r\n    - werkzeug==2.0.1\r\n    - widgetsnbextension==3.5.1\r\n    - wrapt==1.12.1\r\nprefix: /home/pedro/anaconda3/envs/models\r\n", "@pedro-abundio-wang \r\nAs cuda/GPU works as expecred, please move this to closed status as the issue opened is addressed.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50121\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50121\">No</a>\n", "https://blog.csdn.net/weixin_45080073/article/details/117034111\r\n\r\nimport tensorflow._api.v2.compat.v1 as tf\r\ntf.disable_v2_behavior()", "> https://blog.csdn.net/weixin_45080073/article/details/117034111\r\n> \r\n> import tensorflow._api.v2.compat.v1 as tf tf.disable_v2_behavior()\r\n\r\nWhile I can solve the problem this way\r\nBut I still want to know why this problem occurs ?\r\nAnd is this solution a fully equivalent replacement ?", "> @pedro-abundio-wang As cuda/GPU works as expecred, please move this to closed status as the issue opened is addressed.\r\n\r\nHi, I don't think CUDA/GPU was the poster's issue anyway.\r\nThe issue is that inside the IDEA IDE, tensorlfow.compat.v1 gives \"No module named 'compat'\" error, which was not resolved in this thread.\r\nI am facing the same issue right now.\r\nIs there any update as to how it can be resolved?\r\nThank you"]}, {"number": 50120, "title": "Adding Object-Detection / Segmentation applications to tf.keras.applications", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): TF 2.x\r\n- Are you willing to contribute it (Yes/No): Yes \r\n\r\n\r\n## Describe the feature and the current behavior/state.\r\n\r\nCurrently, we have a convenient feature in `tf.keras.applications` to use sota **classification models**. I'm wondering it would be great to have sota **object detection (OD)** (e.g efficient-det) and **segmentation model (Seg)** also (e.g. unet like an arch. with classification model backbone). \r\n\r\nThere are many open-source implementations of **OD** or **Seg** using `keras` or `tf.keras` but reliability and efficiency would be ensured if we have this application into `tf.keras.applications` modules. A similar framework like `pytorch` already has such [features](https://pytorch.org/vision/stable/models.html). It also provides a 3D model for video classification (ResNet 3D). \r\n\r\n**Will this change the current api? How?** would be enhanced. \r\n\r\n**Who will benefit from this feature?** ml practitioners. \r\n\r\n**Any Other info.**\r\nJust don't close this issue without having discussion or feedback, (for example like [this one](https://github.com/keras-team/keras/issues/10596).)\r\n\r\nP.S: I am aware of this https://github.com/tensorflow/models/tree/master/official). \r\n\r\n\r\n---\r\n\r\nAs `keras` moved to own repo, \r\nhttps://github.com/keras-team/keras/issues/15263", "comments": []}, {"number": 50119, "title": "Added protobuf systemlib stub needed by gRPC.", "body": "An unusual (but possible) systemlib configuration is to use system\r\nlibprotobuf but bundled gRPC. This doesn't currently work: gRPC requires\r\nthe protobuf_deps rule that isn't defined by systemlib libprotobuf.\r\n\r\nThis change adds the rule, fixing that particular systemlib\r\nconfiguration.", "comments": []}, {"number": 50118, "title": "Provide option for FTRL Optimizer to not reset variable value as zero when its first gradient is zero", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nUnder current implementation of FTRL optimizer, the value of the variable becomes zero regardless of its original value when its gradient is zero on initial `apply_gradients`.\r\n\r\nReproducible snippet:\r\n\r\n```python\r\nopt = tf.keras.optimizers.Ftrl(learning_rate=0.1, initial_accumulator_value=0.1)\r\nx = tf.Variable([-2, -1, 0, 1, 2], dtype=tf.float32)\r\n\r\nwith tf.GradientTape() as tape:\r\n    loss = tf.math.reduce_sum(tf.nn.relu(x))\r\n\r\ngrads = tape.gradient(loss, [x])\r\n\r\n\r\nprint('Before applying gradients', x.numpy())\r\nprint('Gradients:', grads)\r\nopt.apply_gradients(zip(grads, [x]))\r\nprint('After applying gradients', x.numpy())\r\n```\r\n\r\nResult:\r\n```\r\nBefore applying gradients [-2. -1.  0.  1.  2.]\r\nGradients: [<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 1.], dtype=float32)>]\r\nAfter applying gradients [0.        0.        0.        0.6031424 1.301631 ]\r\n```\r\nThe first three values became zero even their gradients were zero.\r\n\r\nThis behavior is not a bug as we initialize all model parameters as zero in the original paper. This was not a problem for linear models, but is problematic for deep models due to the increased importance of initial weight distribution.\r\n\r\nWe can support its usage for deep models as well by providing an option to prevent this phenomenon.\r\n\r\n**Will this change the current api? How?**\r\nYes, we may add a new boolean parameter in the constructor of `tf.keras.optimizers.Ftrl`.\r\n\r\n**Who will benefit with this feature?**\r\nWhoever uses FTRL optimizer for their deep models.\r\n\r\n**Any Other info.**\r\nI guess we can fix it by initializing the value of the `linear` slot based on the `variable` value when the slot is first created.\r\nIf it's desired change, I can prepare PR to fix it.", "comments": ["Thanks for reaching out.\r\n\r\n> Who will benefit with this feature?\r\n> Whoever uses FTRL optimizer for their deep models.\r\n\r\nThe FTRL optimizer was designed for shallow models (logistic regression over very large feature sets, in the context of ad targeting). I would recommend *not* using it for a deep model.\r\n\r\nBecause of this, we wouldn't be inclined to add an option to implement the behavior you describe.\r\n\r\nAs a workaround, are you able to make your own subclass of FTRL to implement the behavior you need?", "Although the FTRL optimizer was originally designed for linear models, it can also be used with deep models after making modifications as mentioned above.\r\n\r\nWith non-zero L1 hyperparams and proper `linear` slot initialization, it is mathematically equivalent to the Adagrad optimizer with pruning behavior (if the norm of params is greater than the L1 threshold, it behaves like Adagrad and if the norm is smaller than the L1 threshold, it sets the value of the parameter as zero).\r\n\r\nI believe other built-in optimizers don't have such pruning behavior, and we can expect more practical (compared to L1 loss) sparsity constraint on network parameters by using FTRL optimizer. \r\n\r\nAnyway, if not many people will benefit from this, maybe it would be better to write custom code rather than modifying FTRL class in keras. Please close this issue if that's the case.", "Closing this issue for now. Feel free to reopen if further discussion/information is available. Thanks!"]}, {"number": 50117, "title": "TensorFlow build issue", "body": "**System information**\r\nUbuntu 20.04.2 LTS\r\n\r\n- TensorFlow installed from (source or binary): Built from source\r\n- \r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.8.6\r\n- Installed using virtualenv? pip? conda?: Installed in virtualenv after building from source\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source):  9.3.0\r\n- CUDA/cuDNN version: Not used\r\n- GPU model and memory: Not used\r\n\r\n\r\n\r\nI have built tensorflow by following the steps in the website :\r\nhttps://www.tensorflow.org/install/source#build_the_package\r\n\r\nIt was built using : \r\nbazel build\u2014jobs=1 --config=opt//tensorflow/tools/pip_package:build_pip_package\r\n\r\nand I hadn't included any additions flags for the build.\r\n\r\nI managed to build it successfully and was able to use run the python codes for tensorflow.\r\nBut the following statements have been coming as warnings in the terminal when I run all the tensorflow python codes.How can this be rectified?\r\n\r\n\r\n2021-06-06 12:36:27.944619: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/count\r\n2021-06-06 12:36:27.944670: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/count\r\n2021-06-06 12:36:27.944685: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/api\r\n2021-06-06 12:36:27.944718: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/api\r\n2021-06-06 12:36:28.236837: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/count\r\n2021-06-06 12:36:28.236872: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/count\r\n2021-06-06 12:36:28.236887: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/api\r\n2021-06-06 12:36:28.236915: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/api\r\n\r\n\r\n\r\n\r\n", "comments": ["Did you build from a release branch or master?\r\nAlso can you simply import tf successfully after installation?", "> Did you build from a release branch or master?\r\n> Also can you simply import tf successfully after installation?\r\n\r\nSir I built it from the master branch.\r\n\r\nActually I have managed to build it and I have tested it with various python scripts for tf model conversions and fetching inference,and they are working perfectly\r\n\r\nBut the warning I mentioned above is appearing every single time. \r\nCan you please tell me about why this warning appears and what can be done to rectify it sir?\r\n", "Those can be ignored for now, seems that there is some ODR violation", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50117\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50117\">No</a>\n"]}, {"number": 50116, "title": "how does tf name a variable in a partition?", "body": "I found var names are not as what I defined them:\r\n```\r\nbase-network/fuly_connected/weights/ghts/part_9/Adagrad\r\nbase-network/fuly_connected/weights/ights/part_10/Adagrad\r\n```\r\n\r\nHow do these substrings come up? And I found diff num of partitions leads to diff var names. Could someone tell where the corresponding code are? Thanks!", "comments": ["@eveliao \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced].\r\nThanks\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50115, "title": "ImportError: DLL load failed with error code 3221225501 while importing _pywrap_tensorflow_internal", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"F:\\python\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"F:\\python\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code 3221225501 while importing _pywrap_tensorflow_internal\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"demo5.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\\u98ce\u4e2d\u53f6\u5b50\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"F:\\python\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"F:\\python\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code 3221225501 while importing _pywrap_tensorflow_internal\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\r\n   * For TF-GPU - See point 1\r\n   * For TF-CPU - See point 2\r\n-----------------------------------------------------------------------------------------------\r\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\r\n\r\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\r\n| TF  | CUDA |\r\n| :-------------: | :-------------: |\r\n| 2.5.0  | 11.2 |\r\n| 2.4.0  | 11.0 |\r\n| 2.1.0 - 2.3.0  | 10.1 |\r\n| 1.13.1 - 2.0  | 10.0  |\r\n| 1.5.0 - 1.12.0 | 9.0 |\r\n\r\n  * If you have above configuration and using _**Windows**_ platform -\r\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\r\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\r\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\r\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\r\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\r\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\r\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\r\n\r\n-----------------------------------------------------------------------------------------------\r\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\r\n\r\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\r\n\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n\r\n   * Try Google Colab to use TensorFlow.\r\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\r\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\r\n      * All you need is a good internet connection and you are all set.\r\n   * Try to build TF from sources by changing CPU optimization flags.\r\n\r\n*Please let us know if this helps.*\r\n", "@1619513467 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem\r\n", "Looking at the error log, seems like it is similar to this issues and let us know if it helps.[Link1](https://github.com/tensorflow/tensorflow/issues/42103#issuecomment-670291410),[Link2](https://github.com/tensorflow/tensorflow/issues/35598).\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50115\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50115\">No</a>\n"]}, {"number": 50114, "title": "Improved the if-else statement", "body": "Make the if-else statement a single-line assignment.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50114) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50114) for more info**.\r\n\r\n@googlebot I signed it!", "@jdematos There sure is a difference between ternary ops and if-else statements!\r\n\r\n<h3>Storage</h3>\r\nThe first obvious difference is the storage we need to store the code. Ternary operators win!\r\n\r\n<h3>Performance</h3>\r\nDepending on different devices, a ternary operator and an if-else statement may run slightly faster than the other. But behind the scenes, ternary operators compile less bytes than normal if-statements.\r\n\r\n[See this answer on Stack Overflow](https://stackoverflow.com/a/44599923/14185615)\r\n\r\nIn the example above, the ternary operator has 12 bytes to compile, whereas the if-else statement has 16, though the difference is not significant. However, that is not what we are working with. Instead of assigning to a variable like what we are doing now, the Stack Overflow answer returns the value right away. So let's produce a more relevant example.\r\n\r\n![image](https://user-images.githubusercontent.com/72343262/121123983-5bea0600-c84e-11eb-84c5-d9583572045d.png)\r\n![image](https://user-images.githubusercontent.com/72343262/121124023-6d331280-c84e-11eb-97cb-fb8018801309.png)\r\n\r\nAgain, ternary operators win! The bytecode of the ternary operator above has only 20 bytes to compile, whereas the normal if-else statement has 22.", "This is IMO more readable as-is. More lines, but more clear structure."]}, {"number": 50113, "title": "[INTEL MKL] Comparison and cast op fusion", "body": "In this PR, comparison op(bf16/fp32->bool) and cast op(bool->bf16/fp32) is fused into one(bf16/fp32->bf16/fp32). The reason to do this fusion is that comparison functors do not support vectorization, but new added scalar_cmp_with_cast_op functor supports vectorization. This can help greatly improve the performance of comparison op, especially for bf16.\r\n\r\nThis pr was submitted in https://github.com/tensorflow/tensorflow/pull/41047 but got reverted in https://github.com/tensorflow/tensorflow/commit/3f49de584cb7a9de005457006132f5720cc14dd6.", "comments": ["@ShengYang1  Can you please resolve conflicts? Thanks!\r\n", "> @ShengYang1 Can you please resolve conflicts? Thanks!\r\n\r\nDone.", "@ezhulenev - after this PR is merged, the changes got reverted by a follow-on commit (pasted below). Could you please share the reason of this revert?\r\n(FYI - @ShengYang1, @agramesh1  )\r\n`commit 7085dc4947b8237dac752e1c1cb32ff8e1f1e279\r\nAuthor: A. Unique TensorFlower <gardener@tensorflow.org>\r\nDate:   Tue Aug 3 06:29:08 2021 -0700\r\n    Internal change\r\n    PiperOrigin-RevId: 388440280\r\n    Change-Id: Ib18d245a11fbee823c755881b29b91f394778cd2\r\n`\r\n"]}, {"number": 50112, "title": "tf.gather prints a deprecation warning when inside a @tf.function", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- TensorFlow installed from: binary (from pip)\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\n\r\ntf.gather prints a deprecation warning about validate_indices when used inside a @tf.function, even when the call to the tf.gather does not provide a validate_indices.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo deprecation warning.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef foo(x):\r\n  return tf.gather(x, 0)\r\n\r\na = tf.constant([1, 2, 3])\r\nprint('\\n\\nThe next line causes a deprecation warning.\\n\\n')\r\nprint(foo(a))\r\n```\r\n", "comments": ["@bparr \r\nI ran the code on 2.4 and there is no warning please find the [gist here](https://colab.research.google.com/gist/Saduf2019/61fe0234ad17b54affb4a05b6b36c3ee/untitled.ipynb), tf 2.5 will be updated as there would be more releases to it, you cn ignore the warning as it will not effect the performance.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50112\">No</a>\n"]}, {"number": 50111, "title": "ValueError: No gradients provided for any variable: ['Variable:0']", "body": "I am using a custom training loop with GradientTape. This error `ValueError: No gradients provided for any variable: ['Variable:0']` is being thrown. \r\n\r\nI have written a complicated loss function so I imagine some operation I am doing is causing GradientTape to fail. What are some best practices to follow or common gotchas when doing calculations within a gradientape context? \r\n\r\nFor example, should I avoid bit-wise operations, or working with numpy arrays instead of tensors? ", "comments": ["@mattpodolak \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\nThanks\r\n", "Hi @UsharaniPagadala thanks for the response. I believe I had several errors in my implementation. I converted the tensor into a numpy array when passing it to my loss function. I have since fixed the error so I will close this issue.\r\n\r\nHowever, I would be curious to know the best practices for implementing a custom training loop with gradient tape to avoid this type of issue"]}, {"number": 50110, "title": "ptxas exited with non-zero error code 256, output ", "body": "version tensorflow 2.3.0-gpu\r\n\r\n```shell\r\n2021-06-06 03:21:05.290270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-06 03:21:07.202513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2021-06-06 03:21:07.231310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.232673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:00:08.0 name: Tesla P40 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 30 deviceMemorySize: 22.38GiB deviceMemoryBandwidth: 323.21GiB/s\r\n2021-06-06 03:21:07.232823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-06 03:21:07.234815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2021-06-06 03:21:07.236731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2021-06-06 03:21:07.237019: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2021-06-06 03:21:07.239001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2021-06-06 03:21:07.240099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2021-06-06 03:21:07.244241: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2021-06-06 03:21:07.244420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.245793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.247102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2021-06-06 03:21:07.247458: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-06-06 03:21:07.254386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2399995000 Hz\r\n2021-06-06 03:21:07.254792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f42b809f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-06-06 03:21:07.254818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-06-06 03:21:07.353171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.354886: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f42a982f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2021-06-06 03:21:07.354922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\r\n2021-06-06 03:21:07.355126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.356205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:00:08.0 name: Tesla P40 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 30 deviceMemorySize: 22.38GiB deviceMemoryBandwidth: 323.21GiB/s\r\n2021-06-06 03:21:07.356253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-06 03:21:07.356289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2021-06-06 03:21:07.356307: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2021-06-06 03:21:07.356322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2021-06-06 03:21:07.356337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2021-06-06 03:21:07.356352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2021-06-06 03:21:07.356367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2021-06-06 03:21:07.356421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.357489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:07.358524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2021-06-06 03:21:07.358576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2021-06-06 03:21:08.072108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-06-06 03:21:08.072157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2021-06-06 03:21:08.072167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2021-06-06 03:21:08.072387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:08.073502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-06-06 03:21:08.074578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21292 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci bus id: 0000:00:08.0, compute capability: 6.1)\r\nModel: \"movinet_classifier\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nimage (InputLayer)           [(None, None, None, None, 0         \r\n_________________________________________________________________\r\nmovinet (Movinet)            ({'stem': (None, None, No 911583    \r\n_________________________________________________________________\r\nclassifier_head (ClassifierH (None, 600)               2214488   \r\n=================================================================\r\nTotal params: 3,126,071\r\nTrainable params: 3,111,799\r\nNon-trainable params: 14,272\r\n_________________________________________________________________\r\n2021-06-06 03:21:17.983060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2021-06-06 03:21:18.261529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2021-06-06 03:21:19.360108: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\r\n2021-06-06 03:21:19.405225: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2021-06-06 03:21:19.592207: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:592] Internal: ptxas exited with non-zero error code 256, output: \r\nRelying on driver to perform ptx compilation. \r\nSetting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\r\nThis message will only be logged once.\r\n2021-06-06 03:21:19.671090: F tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:419] ptxas returned an error during compilation of ptx to sass: 'Internal: ptxas exited with non-zero error code 256, output: '  If the error message indicates that a file could not be written, please verify that sufficient filesystem space is provided.\r\nAborted (core dumped)\r\n```", "comments": ["The bug solved .  I reinstall cuda-10.1.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50110\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50110\">No</a>\n"]}, {"number": 50109, "title": "How to set/modify quantization_parameters (specifically quantized_dimension) for model conversion?", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): tf-nightly 2.6.0.dev20210523  \r\n\r\n### 2. Code\r\n\r\nI have a model with an input shape (1, 128, 64, 16) with the ordering (NHWC), that is images with 16 channels. Conversion to tflite seems to be fine. Conversion to a quantized model also works fine using the following code.\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_output_path)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.inference_input_type =  tf.int8\r\nconverter.inference_output_type =  tf.int8\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_model = converter.convert()\r\nwith open(<TFLITE_FILE>, 'wb') as w:\r\n    w.write(tflite_model)\r\n```\r\n\r\nHowever, the resulting quality of the quantized model is quite bad. Seems to be a problem with the quantization. Checking the input_details of the quantized model using\r\n\r\n```\r\nimport tflite_runtime\r\nfrom tflite_runtime.interpreter import Interpreter\r\ninterpreter = tflite_runtime.interpreter.Interpreter(<TFLITE_FILE>)\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\nprint(\"Input details: {}\".format(input_details))\r\n```\r\n\r\nreturns\r\n\r\n```\r\nInput details: [{'name': 'serving_default_model:0', 'index': 0, 'shape': array([  1, 128,  64,  16], dtype=int32), 'shape_signature': array([  1, 128,  64,  16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006251777522265911, -128), 'quantization_parameters': {'scales': array([0.00625178], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n\r\n_**Obviously, the \"quantized_dimension\" is zero (that is, why we have only one scales and zero_points value. I would like to have \"quantized_dimension\" = 3 with 16 scales and 16 zero_points.**_\r\n\r\n_**How can i tell the converter to use quantized_dimension = 3?**_\r\n\r\n\r\n### 3. Failure after conversion\r\n\r\n_**Conversion seems to be fine, however for 16 channel input images (input tensor shape = (1, 128, 64, 16)) the quantized_dimension = 0 (and i think it should be 3, to get channel-wise quantization).**_\r\n\r\nThanks for your help!\r\n", "comments": ["@teijeong Could you take a look or triage this as appropriate?", "@saikumarchalla @yyoon In between i was further digging into this issue: it seems that the tflite converter by default uses per-channel quantization, but per-channel (or you call it per-axis) quantization is only supported for a small subset of layers as one can see [here](https://www.tensorflow.org/lite/performance/quantization_spec). Basically only for certain parts of Conv_2d and deptwise_conv_2d. Since i have only 1 tensor (with 16 channels) as input, i guess for most of the layers it does only the per-tensor quantization. Unfortunately, the means and std-devs for the 16 channels are quite different such that this per-tensor quantization is suboptimal and produces bad results. Anyway, if you have comments/ideas on this topic, please let me know.", "Hi @tawiesn,\r\n\r\nI understand what you're trying to do, but unfortunately it's not possible in the current design. The input and activations (outputs from layers) are always per-tensor quantized, and as you discovered only convolutions has support for per-channel quantization.\r\n\r\nLooking from the performance point of view - say that input has 16 quantized dimensions, and the following convolution has 32 channels. To calculate correct outputs, it needs to calculate scale of output for `16 * 32` cases, and this quadratic behavior would increase scaling overhead for most cases.\r\n\r\nIf it's an input, can you consider normalizing the input activations per channel beforehand, so that a single scale can reasonably represent the entire input tensor? This would also possibly benefit model's stability and thus accuracy.\r\n\r\n", "@tawiesn, Did you refer [above comment](https://github.com/tensorflow/tensorflow/issues/50109#issuecomment-861196932)? ", "@chunduriv Yes, i have seen the comment from @teijeong in June and it absolutely makes sense to me. Maybe it would make sense to clarify the restrictions/constraints with respect to channel-wise quantization in the documentation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50109\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50109\">No</a>\n"]}, {"number": 50123, "title": "Train cnn model", "body": "tensorflow==2.5.0\r\nrun code on google colab\r\n\r\nwhen I train my model I get this error and my code and message error bellow\r\n\r\nMy Code\r\n\r\nimport os\r\n\r\nfrom silence_tensorflow import silence_tensorflow\r\n\r\nsilence_tensorflow()\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Input, Conv2D, \\\r\n    MaxPooling2D, Flatten, BatchNormalization\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\ntf.autograph.set_verbosity(0)\r\ntf.get_logger().setLevel('ERROR')\r\n\r\n\r\nclass CharCNN(object):\r\n    def __init__(self):\r\n        self.Model = Sequential()\r\n        self.build()\r\n\r\n    def build(self):\r\n        self.Model.add(Input(name='the_input', shape=(224, 224, 1), batch_size=16, dtype='float32'))\r\n        self.Model.add(Conv2D(32, (3, 3), activation='sigmoid', name='conv1'))\r\n        self.Model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        self.Model.add(Conv2D(32, (3, 3), activation='sigmoid', name='conv2'))\r\n        self.Model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        self.Model.add(Conv2D(64, (3, 3), activation='relu', name='conv3'))\r\n        self.Model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        self.Model.add(Flatten())\r\n\r\n        self.Model.add(Dense(512))\r\n        self.Model.add(Dropout(0.5))\r\n        self.Model.add(BatchNormalization(scale=False))\r\n        self.Model.add(Activation('relu'))\r\n        self.Model.add(Dropout(0.5))\r\n        self.Model.add(Dense(26, activation='softmax'))\r\n\r\n    def summary(self):\r\n        self.Model.summary()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    common_path = '/content/drive/MyDrive/alphdataset/'\r\n    C = CharCNN()\r\n    C.Model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\r\n    C.Model.summary()\r\n\r\n    with tf.device('/device:GPU:0'):\r\n        batch_size = 16\r\n        epochs = 50\r\n        train_dir = common_path + 'train/'\r\n        test_dir = common_path + 'test/'\r\n        checkpoint_path =   '/content/drive/MyDrive/SavedModels/Alphabet/'\r\n        train_image_generator = ImageDataGenerator(rescale=1. / 255)  # Generator for our training data\r\n        train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                                   directory=train_dir,\r\n                                                                   shuffle=True,\r\n                                                                   target_size=(224, 224),\r\n                                                                   class_mode='categorical',\r\n                                                                   color_mode='grayscale')\r\n\r\n        test_image_generator = ImageDataGenerator(rescale=1. / 255)  # Generator for our test data\r\n        test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                                 directory=test_dir,\r\n                                                                 shuffle=False,\r\n                                                                 target_size=(224, 224),\r\n                                                                 class_mode='categorical',\r\n                                                                 color_mode='grayscale')\r\n\r\n        # C.Model = tf.keras.models.load_model(checkpoint_path)\r\n        \r\n        callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\r\n                                                    patience=10,\r\n                                                    restore_best_weights=True,\r\n                                                    baseline=0.45)\r\n        \r\n        history = C.Model.fit(train_data_gen,\r\n                              steps_per_epoch=337,  # Number of images // Batch size\r\n                              epochs=epochs,\r\n                              verbose=1,\r\n                              validation_data=test_data_gen,\r\n                              validation_steps=37,\r\n                              callbacks=[callback])\r\n\r\n        C.Model.save(checkpoint_path, save_format='tf')\r\n        # Evaluate Model:\r\n        # Accuracy: 48.13%\r\n        C.Model.evaluate(test_data_gen)\r\n\r\n\r\n--------------------------------------------------------------------------------------------------------------------\r\n\r\nMessage Error \r\n\r\n  File \"/content/drive/MyDrive/Lipify-LipReading/NN_Models/CharacterCNN.py\", line 85, in <module>\r\n    callbacks=[callback])\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3024, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1961, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  required broadcastable shapes at loc(unknown)\r\n\t [[node sequential/dropout/dropout/Mul_1 (defined at content/drive/MyDrive/Lipify-LipReading/NN_Models/CharacterCNN.py:85) ]] [Op:__inference_train_function_1105]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n^C\r\n", "comments": ["@7AM7 Moving this issue to TF core repository since it is not related to models repo.Thanks!", "@7AM7 Can you please create a standalone code to reproduce the issue? I tried your code but it throws different error. \r\n\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/1d88ebd439f2fce20c202e8b71676d0a/untitled.ipynb). Can you update the gist or share a standalone code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50123\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50123\">No</a>\n"]}, {"number": 50107, "title": " Input 0 is incompatible with layer model: expected shape=(None, 256, 256, 1), found shape=(None, 128, 128, 3)", "body": "i am trying to evaluate my model but when i run model.evaluate(test_image), it showed this error:\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1323 test_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1314 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1307 run_step  **\r\n        outputs = model.test_step(data)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1266 test_step\r\n        y_pred = self(x, training=False)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\r\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:270 assert_input_compatibility\r\n        ', found shape=' + display_shape(x.shape))\r\n\r\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 256, 256, 1), found shape=(None, 128, 128, 3)\r\n\r\n\r\n\r\nHow do i resolve it?", "comments": ["@vjamishi ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the tensorflow version,complete code and dataset to reproduce the issue reported here.\r\n\r\nAlso please take a look at this issues with similar error.[Link1](https://stackoverflow.com/questions/67047026/valueerror-input-0-is-incompatible-with-layer-model-expected-shape-none-1499),[Link2](https://github.com/tensorflow/tensorflow/issues/46478#issuecomment-762188474).Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50106, "title": "Replace slow GPU API call in GetGpu3DLaunchConfig", "body": "- `cudaGetDeviceProperties` is a heavy-weight call. This PR replaces it with individual calls to `cudaDeviceGetAttribute`, which are much faster.\r\n- This is important here because the enclosing function is called for each kernel launch (for those ops that use it).\r\n- See https://developer.nvidia.com/blog/cuda-pro-tip-the-fast-way-to-query-device-properties/ for reference.\r\n\r\ncc @nluehr ", "comments": []}]