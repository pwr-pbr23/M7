[{"number": 36221, "title": "TF-Lite example label Image w shared library", "body": "I have built tf-lite with shared `libtensorflowlite.so` library, I  am looking for help to get compiled label_image example using that shared library. \r\nBasically to separate projects from the tf framework.\r\nHow do I set a shared library to use with label image example?\r\n", "comments": ["@peter197321, Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!"]}, {"number": 36220, "title": "Contributing: fix typos", "body": "", "comments": []}, {"number": 36219, "title": "tf.lite.converter.convert() Erroe", "body": "**System information**\r\n- OS Platform and Distribution Ubuntu 18.04\r\n- TensorFlow version (or github SHA if from source):2.0.0b1\r\n\r\nI am trying to test LSTM/GRU code using TensorFlow 2.0.0b1 in ubuntu 18.04.\r\nBelow you can find my simple model and converter code\r\n\r\n```\r\ndef create_gru_model():\r\n    model = tf.keras.models.Sequential();\r\n    model.add(tf.keras.layers.GRU(128))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add(tf.keras.layers.Dense(49,activation=tf.nn.softmax))\r\n    model.compile(optimizer='adam',loss=customLoss,metrics = ['accuracy'])\r\n    return model\r\nmodel = create_gru_model()\r\nmodel.fit(x_train, y_train, epochs = 3, callbacks = [cp_callback], validation_data = (x_valid,y_valid), verbose=0)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter=True\r\ntflite_model = converter.convert()\r\n```\r\n\r\nI get the following error\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 148, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 392, in convert\r\n    **converter_kwargs)\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n2020-01-26 12:56:17.818849: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818886: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818892: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818987: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StatefulPartitionedCall\r\n2020-01-26 12:56:17.827230: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f4c3f6b7740 (most recent call first):\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/pramod/.local/bin/toco_from_protos\", line 11 in <module>\r\nAborted (core dumped)\r\n\r\n\r\n\r\nError in sys.excepthook:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 63, in apport_excepthook\r\n    from apport.fileutils import likely_packaged, get_recent_crashes\r\n  File \"/usr/lib/python3/dist-packages/apport/__init__.py\", line 5, in <module>\r\n    from apport.report import Report\r\n  File \"/usr/lib/python3/dist-packages/apport/report.py\", line 30, in <module>\r\n    import apport.fileutils\r\n  File \"/usr/lib/python3/dist-packages/apport/fileutils.py\", line 23, in <module>\r\n    from apport.packaging_impl import impl as packaging\r\n  File \"/usr/lib/python3/dist-packages/apport/packaging_impl.py\", line 24, in <module>\r\n    import apt\r\n  File \"/usr/lib/python3/dist-packages/apt/__init__.py\", line 23, in <module>\r\n    import apt_pkg\r\nModuleNotFoundError: No module named 'apt_pkg'\r\n\r\nOriginal exception was:\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 148, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 392, in convert\r\n    **converter_kwargs)\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/pramod/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n2020-01-26 12:56:17.818849: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818886: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818892: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-26 12:56:17.818987: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StatefulPartitionedCall\r\n2020-01-26 12:56:17.827230: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f4c3f6b7740 (most recent call first):\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/pramod/.local/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/pramod/.local/bin/toco_from_protos\", line 11 in <module>\r\nAborted (core dumped)\r\n\r\n```\r\n", "comments": ["Why not switch to a final release? 2.0 or 2.1?", "@pramodjayram,\r\nPlease switch to latest versions of tf 2.0 or 2.1 and try adding \r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n``` \r\nin the code, and let us know if it helps. Please find refer #[35590](https://github.com/tensorflow/tensorflow/issues/35590) similar issue.Thanks!", "I switched to the latest version of tf 2.1 and added the above lines. It perfectly created the tflite file. But when I use the GRU model on the board, I get an error message on the serial console of the board.\r\n```\r\nOnly 1 subgraph is currently supported.\r\nAllocateTensors() failed\r\n```\r\nIf I remove the GRU layer from the model above, it works perfectly. But when GRU is included it ends up with this error.\r\nIt would be quite helpful if somebody knows the solution or an explanation for this following error report.", "Are you performing an optimizations on tf lite file? If so, then can you try without optimizations?\r\nSee https://github.com/tensorflow/tensorflow/issues/35194", "I tried with optimization and without but both resulted in the same error.", "Below is the exact code that I am running\r\n\r\n```\r\ndef customLoss(yTrue,yPred):\r\n\r\n    return tf.nn.softmax_cross_entropy_with_logits(labels=yTrue,logits=yPred)\r\n\r\n\r\ndef create_gru_model():\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Input(shape=(1, 49), name='input'),\r\n        tf.keras.layers.GRU(2),\r\n        tf.keras.layers.Dense(49, activation=tf.nn.softmax, name='output')\r\n    ])\r\n    model.compile(optimizer = 'adam',\r\n                  loss = customLoss,\r\n                  metrics = ['accuracy'])\r\n    return model\r\nx_train = tf.keras.utils.normalize(x_train, axis = 1)\r\nx_test = tf.keras.utils.normalize(x_test, axis = 1)\r\n\r\ncheckpoint_path = \"training_gru/cp-{epoch:04d}.ckpt\"\r\ncheckpoint_dir = os.path.dirname(checkpoint_path)\r\nmodel = create_gru_model()\r\nmodel.fit(x_train, y_train, epochs = 1)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\nopen(\"gru3.tflite\", \"wb\").write(tflite_model)\r\n```\r\nIt results in following error on the device serial console\r\n```\r\nOnly 1 subgraph is currently supported.\r\nAllocateTensors() failed\r\n```\r\nIf I remove the GRU layer or replace it with another one then the code works well.\r\nIt would be quite helpful if somebody knows the solution or an explanation for this following error report.", "The code looks incomplete, x_train and y_train are undefined. Also can you try compiling your model without custom loss perhaps use built in loss functions.", "I have defined x_train and y_train before and also tried with a built-in loss function. I just haven't included in the code above. The code is working perfectly.  I get the error on the serial console of the ARM device when I flashed the binary that was generated using the converted model.", "I get the exact same error, when I try to convert a model with lstm layers into tf lite and use post training optimization in form of: \r\n```\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = custom_generator\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                      tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\nI get this error:\r\n```\r\nRuntimeError: Only models with a single subgraph are supported, model had 5 subgraphs\r\n```\r\nWhen I do not use optimizations, it works. \r\nI am using tf 2.1.0 and tf-nightly version from 10.02.2020", "Is it possible to share the code? ", "> I switched to the latest version of tf 2.1 and added the above lines. It perfectly created the tflite file.\r\n\r\nThe `experimental_new_converter` attribute only work on TF 2.1 and above. When doing this in 2.0 it doesn't change anything. \r\n\r\n> But when I use the GRU model on the board, I get an error message on the serial console of the board.\r\n```\r\nOnly 1 subgraph is currently supported.\r\nAllocateTensors() failed\r\n```\r\n\r\nIt seems you're running the [microcontroller version of TFLite](https://www.tensorflow.org/lite/microcontrollers). At this moment it only support a subset of TFLite features, and control flow isn't supported yet. \r\n\r\nAt this moment it's working as intended. @petewarden do you have any comment about GRU support?", "@pramodjayram,\r\nIs this still an issue?\r\n\r\nI was able to run the code with TF v2.4.1, without any errors. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/eb4e7fbe3b73e7290c64c768febaab54/36219.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36219\">No</a>\n", "Hi, anybody else experiencing the same problem? I have the following error when trying to run my TFLite micro model on an ESP32\r\n`Only 1 subgraph is currently supported.\r\nAllocateTensors() failed`\r\nMy model is a 3-layer LSTM."]}, {"number": 36218, "title": "[core] Added null check for output buffer", "body": "Check output != nullptr before calling output->clear()", "comments": ["> if we just barely return false may induce other following logic issue, right?\r\n\r\n@Leslie-Fang , thanks a lot for the review. The function CompressInternal() returns false in most of the error cases, so I believe the caller should handle it the similar way that it handles other errors. Thoughts ?", "Hi, is there anything from my side here ? Please advise. Thanks.", "@gaurav1086 Can you please fix the build failures? Thanks!", "@mihaimaruseac @gbaned , rebased with the latest master", "@gaurav1086 Can you please fix the build failures? Thanks!", "@gbaned @mihaimaruseac fixed the build errors. Thank you."]}, {"number": 36217, "title": "Report \"model_pruner failed: Invalid argument: Invalid input graph.\" when i call C++ API", "body": "model format \".pb\"\r\npython are success to predict, input dim is {1,512},code like this:\r\n\r\n\r\nsess = tf.Session()\r\ngraph = tf.get_default_graph()\r\nwith tf.gfile.FastGFile('./model_tags.pb','rb') as f:\r\n\tgraph_def = tf.GraphDef()\r\n\tgraph_def.ParseFromString(f.read())\r\n\tsess.graph.as_default()\r\n\tg_in = tf.import_graph_def(graph_def)\r\n\ttensor_input = sess.graph.get_tensor_by_name('import/input_1:0')\r\n\ttensor_output = sess.graph.get_tensor_by_name('import/time_distributed_1/Reshape_1:0')\r\n\tpredictions = sess.run(tensor_output, {tensor_input: np.expand_dims(str_word_list_np, axis=0)})\r\n\r\nwhen i call c++ api,code:\r\n\r\n\r\n    tensorflow::Session *m_pTFSes;\r\n    tensorflow::GraphDef m_grBiLSTM;\r\n    tensorflow::Status status = tensorflow::NewSession(tensorflow::SessionOptions(), &m_pTFSes);\r\n    if (!status.ok())\r\n    {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return false;\r\n    }\r\n    status = tensorflow::ReadBinaryProto(tensorflow::Env::Default(), \"model_tags.pb\", &m_grBiLSTM);\r\n    if (!status.ok())\r\n    {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return false;\r\n    }\r\n    status = m_pTFSes->Create(m_grBiLSTM);\r\n    if (!status.ok())\r\n    {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return false;\r\n    }\r\n    tensorflow::Tensor tInput(tensorflow::DT_INT32, tensorflow::TensorShape({ 1, 512 }));\r\n    int*pSeq = tInput.flat<int>().data();\r\n    std::vector<std::string> vecLetters;\r\n    SplitString(strText, vecLetters);\r\n    for(int i = 0;i < 512;i++)\r\n    {\r\n        if(i < vecLetters.size())\r\n        {\r\n            pSeq[i] = m_umLetters[vecLetters[i]];\r\n        }\r\n        else\r\n        {\r\n            pSeq[i] = 0;\r\n        }\r\n    }\r\n    std::vector<std::pair<std::string, tensorflow::Tensor>> inSeq;\r\n    inSeq.push_back(std::make_pair(\"import/input_1:0\", tInput));\r\n    std::vector<tensorflow::Tensor> outSeq;\r\n    m_pTFSes->Run(inSeq, {\"import/time_distributed_1/Reshape_1:0\"}, {}, &outSeq);\r\n\r\n\r\nthat report \r\n2020-01-26 04:16:36.014125: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:562] model_pruner failed: Invalid argument: Invalid input graph.\r\n2020-01-26 04:16:36.525743: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:562] model_pruner failed: Invalid argument: Invalid input graph.\r\n\r\n", "comments": ["Please properly format all code blocks using ` ``` ` and also fill in the issue template.", "@jkkj1630, Please fill the issue [Template](https://github.com/tensorflow/tensorflow/issues/new/choose). ", "@jkkj1630 when closing the issue, please also update if it was user error or how you fixed the issue. This will allow others encountering the same problem to get to a fix faster.", " @jkkj1630 you can post your solution to fix the issue?"]}, {"number": 36216, "title": "Keras: expose loss metric of singular output", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): maybe\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently when training a keras model with multiple outputs, you get multiple \"loss\" metrics. One for each output, and then an overall loss for the whole model. However when your model only contains a single output, the metrics only contain a single loss value. [The documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable#compile) implies that this is because the overall loss is simply a weighted sum of the individual outputs, and thus is irrelevant when only one output is present. However this is incorrect. The overall loss used to train the model also includes other factors, such as [layer losses due to regularizer penalties](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/Regularizer). Thus even with a single output, the output's loss can be different from the model's overall loss.\r\nTo address this discrepancy, a metric for the output loss should be provided even when the model only has one output.\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\nAnyone with layer losses, such as due to regularizers.\r\n\r\n**Any Other info.**\r\n", "comments": ["I made the changes to implement the proposal, and they can be found here: https://github.com/tensorflow/tensorflow/commit/c68217f03ef5b42eb0837d21edd18ca1ee47998d\r\n\r\nI have not created a pull request as I cannot get the tests working. Even the dockerized tests fail (unrelated to my change, some sort of bazel toolchain issue). The change is pretty small, so if someone else wants to take this and run with it, feel free.", "Updated changes for version 2.2: https://github.com/phemmer/tensorflow/commit/a588fcce4336ba4aa1e3856d9904debbcfe8d97d", "@phemmer,\r\nSorry for the delayed response. Can you please confirm if you have submitted a `Pull Request` with the changes you submitted in the above comment? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36215, "title": "Update version numbers for TensorFlow 1.15.2", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 15 -> 15\nPatch: 1 -> 2\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.15.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:70:1.15.1\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.15.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:70:1.15.1\n```", "comments": []}, {"number": 36214, "title": "Update release notes for TensorFlow 1.15.2", "body": "This PR is intentionally incomplete. One of the Release Owners for 1.15.2\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 36213, "title": "Build using nvcc + clang?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit c044803bcd710a040d6baa6f39588581ae1c5c01 (with the problem in https://github.com/tensorflow/tensorflow/issues/36170 fixed locally)\r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: V10.1.243/7.6.5\r\n- GPU model and memory: GeForce GTX 1080, 8116 MiB \r\n\r\n\r\n**Describe the problem**\r\n\r\nI was able to build Tensorflow with (`bazel build tensorflow/tools/pip_package:build_pip_package`) using nvcc + gcc. But if I tried to manully override gcc using clang (8.0.1), the build will fail with\r\n```\r\nclang: error: unknown argument: '-fno-canonical-system-headers'\r\n``` \r\nIt seems the CC toolchain auto config still generates flags for nvcc + gcc, even though I choose to use clang. I confirmed that my gcc has this flag while my clang does not.\r\n\r\nIf I choose to use clang as CUDA compiler, it would fail with\r\n```\r\n error: cannot find libdevice for sm_61.\r\n``` \r\nwhich seems to mean that Clang cannot compile for this cuda compute capabilities (6.1). So I am wondering if there is any way of using nvcc + clang to build since I use clang as default (for all other builds). Shouldn't this be possible since clang is used by default on Macs? Thanks!", "comments": ["The original error when using clang as cuda compiler (cannot find libdevice) seems to go away after upgrading clang to a new version (10.0.0-++20200126090219+73a91477f70-1~exp1~20200126201656.19). Is the build supposed to be done either by gcc+nvcc or purely by clang? Or is Clang supported?\r\n\r\nUsing the new clang version still fails due to errors like the following. To isolate the problem, the target I built is\r\n```\r\nbazel build @nccl_archive//:device_lib\r\n```\r\nThe errors look like this\r\n```\r\nIn file included from <built-in>:1:\r\nIn file included from /usr/lib/llvm-10/lib/clang/10.0.0/include/__clang_cuda_runtime_wrapper.h:202:\r\nIn file included from /usr/include/string.h:494:\r\n/usr/include/x86_64-linux-gnu/bits/string_fortified.h:95:8: error: exception specification in declaration does not match previous declaration\r\n__NTH (stpcpy (char *__restrict __dest, const char *__restrict __src))\r\n       ^\r\n/usr/include/string.h:451:14: note: previous declaration is here\r\nextern char *stpcpy (char *__restrict __dest, const char *__restrict __src)\r\n             ^\r\n```\r\nThere is one such error for each function in `/usr/include/string.h` (installed from libc6-dev 2.27-3). It seems to be caused by the difference in their declaration and definition. gcc doesn't take it as an error while clang-10 does. For example, the declaration of `strcpy` in `string.h` is\r\n```c\r\n/* Copy SRC to DEST.  */\r\nextern char *strcpy (char *__restrict __dest, const char *__restrict __src)\r\n     __THROW __nonnull ((1, 2));\r\n```\r\nwhile in `/usr/include/x86_64-linux-gnu/bits/string_fortified.h` it is\r\n```c\r\n__fortify_function char *\r\n__NTH (stpcpy (char *__restrict __dest, const char *__restrict __src))\r\n{\r\n  return __builtin___stpcpy_chk (__dest, __src, __bos (__dest));\r\n}\r\n```\r\nThe latter does not throw while the former does? I am not sure if this should be a Tensorflow issue or Clang issue or there is something wrong with my set up. ", "I also saw the same error came up in this issue: https://github.com/tensorflow/tensorflow/issues/34098", "@Artem-B may have some details.\r\nAt one point, I remember CUDA headers had a check to block building with Clang, when we first tried this. I do not know if this still applies.\r\n\r\nAnother option is to just use clang when building TF. Clang can already compile cuda code.", "NVCC + custom crosstool w/ a wrapper script was very gcc-centric when I looked at it last time (mind, it was a while back). I would not expect that to work out of the box.\r\n\r\nAs for using clang for CUDA compilation, it's expected to work in general, but I don't have enough details to tell what went wrong in this case. \r\n\r\n> error: cannot find libdevice for sm_61.\r\n\r\nThis could happen if you install CUDA from packages (as opposed to installing it manually from a .run file). Packages tend to scatter CUDA files all over the place which confuses clang. I think there were recent changes to attempt dealing with some of this, but in general clang assumes a monolithic CUDA installation (I.e. all CUDA files are under a single directory).\r\n\r\nAs for mismatching declarations for stpcpy, here's how I'd debug it:\r\n\r\n* run blaze with --verbose_failures and extract exact compiler command line\r\n* reproduce the failure manually\r\n* If the failure was during compilation of a CUDA file run compiler with -v and extract command line of sub-compilation that fails.\r\n* run the failing sub-compilation with `-dD -E` and check what preprocessed declarations/definitions look like for the functions we're failing on.\r\n* track down the differences to a macro which leads to them (`__USE_XOPEN2K8` ? `__THROW` ?) and then figure out why the declarations are inconsistent.\r\n\r\nOne thing that could be the culprit is that CUDA does not support exceptions on the GPU side. If something/somewhere assumes that exceptions are available, things may not work as expected. Another possible source of trouble is that clang's `__clang_cuda_runtime_wrapper.h` which implements the magic massaging CUDA headers into something clang can pasre may need to be updated to deal with more recent headers on your machine. \r\n\r\n@djwenren If you can send me exact command line that fails, I'll try reproducing it locally and check what's going on. The headers on my machine appear to match the ones quoted above.", "Thanks for the detailed information, @Artem-B ! I reinstalled my Cuda toolkit (10.1) using runfiles from Nvidia. The problems seem to have gone away. I was able to build using purely Clang. Could have been some misconfiguration I had earlier.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36213\">No</a>\n"]}, {"number": 36212, "title": "Issue on importing tensorflow", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac Catalina version 10.15.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): installed from source\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**I've installed tensorflow on a virtual environment but I can't import to use it**\r\n\r\n** I've Followed the installation instructions from the tensorflow website on https://www.tensorflow.org/install/pip **\r\n\r\n\r\n**I don't know if this is linked but I can't find tensorflow on the Anaconda list of package after creating a new environment in the Anaconda Navigator **\r\n\r\n----------------------------------------------- \r\n(venvtensorflow) tim@MacBook-Pro-de-Timothee ~ % pip list\r\nPackage              Version   \r\n_________.           ___________\r\nabsl-py              0.9.0     \r\nastor                0.8.1     \r\ncachetools           4.0.0     \r\ncertifi              2019.11.28\r\nchardet              3.0.4     \r\ngast                 0.2.2     \r\ngoogle-auth          1.11.0    \r\ngoogle-auth-oauthlib 0.4.1     \r\ngoogle-pasta         0.1.8     \r\ngrpcio               1.26.0    \r\nh5py                 2.10.0    \r\nidna                 2.8       \r\nKeras-Applications   1.0.8     \r\nKeras-Preprocessing  1.1.0     \r\nMarkdown             3.1.1     \r\nnumpy                1.18.1    \r\noauthlib             3.1.0     \r\nopt-einsum           3.1.0     \r\npip                  20.0.2    \r\nprotobuf             3.11.2    \r\npyasn1               0.4.8     \r\npyasn1-modules       0.2.8     \r\nrequests             2.22.0    \r\nrequests-oauthlib    1.3.0     \r\nrsa                  4.0       \r\nscipy                1.4.1     \r\nsetuptools           45.1.0    \r\nsix                  1.12.0    \r\ntensorboard          2.1.0     \r\ntensorflow           2.1.0                         <- Tensorflow seems installed\r\ntensorflow-estimator 2.1.0     \r\ntermcolor            1.1.0     \r\nurllib3              1.25.8    \r\nWerkzeug             0.16.0    \r\nwheel                0.33.6    \r\nwrapt                1.11.2  \r\n\r\n\r\n----------------------------------------------- \r\n(venvtensorflow) tim@MacBook-Pro-de-Timothee ~ % python\r\nPython 3.7.3 (default, Dec 13 2019, 19:58:14) \r\n[Clang 11.0.0 (clang-1100.0.33.17)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow/__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 959, in _find_and_load_unlocked\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/google/protobuf/__init__.py\", line 37, in <module>\r\n    __import__('pkg_resources').declare_namespace(__name__)\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 84, in <module>\r\n    __import__('pkg_resources.extern.packaging.requirements')\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 9, in <module>\r\n    from pkg_resources.extern.pyparsing import stringStart, stringEnd, originalTextFor, ParseException\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 668, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 638, in _load_backward_compatible\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/extern/__init__.py\", line 43, in load_module\r\n    __import__(extant)\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 4756, in <module>\r\n    _escapedPunc = Word( _bslash, r\"\\[]-*.$+^?()~ \", exact=2 ).setParseAction(lambda s,l,t:t[0][1])\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1284, in setParseAction\r\n    self.parseAction = list(map(_trim_arity, list(fns)))\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1066, in _trim_arity\r\n    this_line = extract_stack(limit=2)[-1]\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/site-packages/pkg_resources/_vendor/pyparsing.py\", line 1050, in extract_stack\r\n    frame_summary = traceback.extract_stack(limit=-offset+limit-1)[offset]\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 211, in extract_stack\r\n    stack = StackSummary.extract(walk_stack(f), limit=limit)\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 363, in extract\r\n    f.line\r\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/traceback.py\", line 285, in line\r\n    self._line = linecache.getline(self.filename, self.lineno).strip()\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/linecache.py\", line 16, in getline\r\n    lines = getlines(filename, module_globals)\r\n  File \"/Users/tim/venvtensorflow/lib/python3.7/linecache.py\", line 48, in getlines\r\n    for mod in sys.modules.values():\r\nRuntimeError: dictionary changed size during iteration", "comments": ["This seems to be an ssue with the macos python. See also #33183", "Since this is not a TF issue, we'll close this issue."]}, {"number": 36211, "title": "[grappler] mutable graph: can_dedup_control", "body": "", "comments": ["There are no changes seen in this PR. Hence closing this PR.Thanks!"]}, {"number": 36210, "title": "Add converter for SparseSoftmaxCrossEntropyWithLogits", "body": "Adds converter for `sparse_softmax_cross_entropy_with_logits`. There is a chance that I'm missing something here.\r\ntensorflow/probability#749", "comments": ["@alextp sorry, there was a tiny issue with the test.", "@alextp can you please approve this?", "@alextp It's pylint now, fixed that too. Sorry, can you approve again please?", "@rrkarim Can you please check build failures? Thanks!", "@gbaned I'm not sure what is the issue here. It shows that the problem is with mlir but what is the cause of it, I'm missing.", "@rrkarim can you please resolve conflicts ? so that we can try to pull this in", "@rthadur I can not reproduce that. Can you please look at the logs, there are some issues with mlir tests.", "@mihaimaruseac any suggestions on @rrkarim comments.\r\n\r\n@rrkarim can you please resolve conflicts.", "Once conflicts are removed we should review and approve again. I think MLIR failures are fixed for now.", " @mihaimaruseac seems like they are not, at least for this PR. I really can't find the cause of the issue here.", "Rebase again on master?", "> Rebase again on master?\r\n\r\ndone.", "Internally the MLIR build succeeds. If this PR still fails then we'll have to dig deeper"]}, {"number": 36209, "title": "Segmentation fault when training DeepLab segmentation model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): `conda install tensorflow=1`\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6.7\r\n\r\n**Describe the current behavior**\r\nI am trying to train the DeepLab model following the directions in this [DeepLab example](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/pascal.md) using the following command:\r\n```\r\n$ python deeplab/train.py \\\r\n    --logtostderr \\\r\n    --training_number_of_steps=30000 \\\r\n    --train_split=\"train\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --train_crop_size=\"513,513\" \\\r\n    --train_batch_size=1 \\\r\n    --dataset=\"basins\" \\\r\n    --tf_initial_checkpoint=/home/james/deeplab/pretrained/x65-b2u1s2p-d48-2-3x256-sc-cr300k_init.ckpt.data-00000-of-00001 \\\r\n    --train_logdir=./deeplab/datasets/basins/exp/train_on_train_set/train \\\r\n    --dataset_dir=./deeplab/datasets/basins\r\n```\r\n\r\nI get the following output/error:\r\n```\r\n<thousands of useless/confusing warning messages>\r\n...\r\n2020-01-25 16:03:48.084849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\r\n2020-01-25 16:03:48.086476: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559e7db9e710 executing computations on platform Host. Devices:\r\n2020-01-25 16:03:48.086916: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Starting Session.\r\nINFO:tensorflow:Saving checkpoint to path ./deeplab/datasets/basins/exp/train_on_train_set/train/model.ckpt\r\nINFO:tensorflow:Starting Queues.\r\nSegmentation fault (core dumped)\r\n```\r\n**Describe the expected behavior**\r\nI am hoping that the model will train as advertised.\r\n\r\n**Code to reproduce the issue**\r\nRun a DeepLab model training as described in the DeepLab tutorial documentation referenced above.\r\n\r\nBTW I have had this happen on two separate machines, both of which are running Ubuntu 18.04. One is a Dell laptop with CPU and the other is an AWS EC2 instance with T4 GPU. On the EC2 instance the TF version installed is 1.15.0 and I also tried using TensorFlow 2.0 but when I did that the code failed immediately with a message indicating that tf.contrib is no longer included in TensorFlow so my assumption is that this code has not been ported to work for TF2. Please advise if there is a known version of TF that this code works with, it appears to be broken in its current state using the versions of TF that I've tried.\r\n\r\nThanks in advance for any insight or suggestions. And/or if there is a more up-to-date semantic segmentation model from TensorFlow other than DeepLab then please point me in the right direction.", "comments": ["I have just confirmed that this also happens on an AWS EC2 instance (Ubuntu 18.04) with GPU using tensorflow-gpu version 1.15, here is the output from the training command above:\r\n```\r\n...\r\nThread 0x00007fe15eaa9740 (most recent call first):\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443 in _call_tf_sessionrun\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350 in _run_fn\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365 in _do_call\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359 in _do_run\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180 in _run\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956 in run\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 490 in train_step\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 775 in train\r\n  File \"deeplab/train.py\", line 458 in main\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"deeplab/train.py\", line 464 in <module>\r\nSegmentation fault (core dumped)\r\n``` ", "As an alternative approach you could try Mask-RCNN [https://github.com/matterport/Mask_RCNN](url)  however i think maskrcnn is instance based. ", "Thanks @shashank3110 . Unfortunately, I have already tried Mask R-CNN and had similar issues with that model (see [this](https://github.com/matterport/Mask_RCNN/issues/1961) and [this](https://github.com/matterport/Mask_RCNN/pull/1896#issuecomment-578460832)).", "@monocongo Please post this issue in [tensorflow/models](https://github.com/tensorflow/models/issues) repo as this issue belongs to models repo and also you can get a faster response there. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36209\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36209\">No</a>\n", "Thanks for the good advice, @gowthamkpr \r\n\r\nAs suggested this issue was raised on the tensorflow/models issues tracker (see [8137](https://github.com/tensorflow/models/issues/8137))", "Hi\uff0cI fix this issue!\r\nI got exactly the same issue on cenos7 with `tensorflow==1.15.0`,  for me, it is only related with the dataset generation issues! \r\n\r\nWith `cityscapes` dataset, the generation of tfrecord following the tutorial doc would be \r\n```shell\r\n.\r\n\u251c\u2500\u2500 train-00002-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00003-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00004-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00005-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00006-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00007-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00008-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00009-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00000-of-00010.tfrecord\r\n\u251c\u2500\u2500 train-00001-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00000-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00001-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00002-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00003-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00004-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00005-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00006-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00007-of-00010.tfrecord\r\n\u251c\u2500\u2500 val-00008-of-00010.tfrecord\r\n\u2514\u2500\u2500 val-00009-of-00010.tfrecord\r\n```\r\n\r\nthe shell commands for me (in the `/reasearch` folder), \r\n```shell\r\npython deeplab/train.py --dataset cityscapes \\\r\n--dataset_dir=deeplab/datasets/cityscapes/tfrecord/ \\\r\n--train_logdir deeplab/datasets/cityscapes/exp/train_on_train_set/train/ \\\r\n--train_split=train_fine --model_variant=mobilenet_v3_large_seg \\\r\n--train_crop_size=769,769 --training_number_of_steps=1000 \\\r\n--decoder_output_stride=8 --image_pyramid=1 \\\r\n--image_se_uses_qsigmoid=1 --decoder_output_is_logits=1 \\\r\n--decoder_filters=19 --decoder_use_sum_merge=1 \\\r\n--aspp_with_squeeze_and_excitation=1 --aspp_with_concat_projection=0 \\\r\n--aspp_convs_filters=128 \\\r\n--image_pooling_stride=4,5 --image_pooling_crop_size=769,769\r\n```\r\n\r\nI use pretrained weights from [`mobilenet_v3_large_seg`](https://github.com/tensorflow/models/issues/7911),  since the [`L71-80 of script`](https://github.com/tensorflow/models/blob/1498d9419b799c3df61d8a8b63a879dcbca4504e/research/deeplab/datasets/data_generator.py) tells me it should be  `--train_split=train_fine`\uff0c\r\n```python\r\n_CITYSCAPES_INFORMATION = DatasetDescriptor(\r\n    splits_to_sizes={'train_fine': 2975,\r\n                     'train_coarse': 22973,\r\n                     'trainval_fine': 3475,\r\n                     'trainval_coarse': 23473,\r\n                     'val_fine': 500,\r\n                     'test_fine': 1525},\r\n    num_classes=19,\r\n    ignore_label=255,\r\n)\r\n```\r\n> (note that the parameter `--train_split=train_fine`)\r\n\r\nBUT tfrecord  dataset I have all start with `train-0000-...`,  **HERE IS THE  INCONSISTENCE !!!!**\r\nI change the name of tfrecord dataset to `train_fine-00000-of-00010.tfrecord` by hands,  all `Segmented fault` gone !!!\r\n\r\nand the screen outputs show as expected:\r\n```shell\r\n......lalalalalallala........\r\nnagement) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file utilities to get mtimes.\r\nINFO:tensorflow:Running local_init_op.\r\nI0331 21:53:58.600903 140616897775424 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0331 21:54:19.723121 140616897775424 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:Starting Session.\r\nI0331 21:54:25.378759 140616897775424 learning.py:754] Starting Session.\r\nINFO:tensorflow:Saving checkpoint to path deeplab/datasets/cityscapes/exp/train_on_train_set/train/model.ckpt\r\nI0331 21:54:25.692887 140594135426816 supervisor.py:1117] Saving checkpoint to path deeplab/datasets/cityscapes/exp/train_on_train_set/train/model.ckpt\r\nINFO:tensorflow:Starting Queues.\r\nI0331 21:54:25.693168 140616897775424 learning.py:768] Starting Queues.\r\n2020-03-31 21:54:40.171982: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 23 of 100\r\n2020-03-31 21:54:50.836214: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 33 of 100\r\nINFO:tensorflow:global_step/sec: 0\r\nI0331 21:54:54.143480 140594127034112 supervisor.py:1099] global_step/sec: 0\r\n2020-03-31 21:55:02.310592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 35 of 100\r\n2020-03-31 21:55:15.670713: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 41 of 100\r\n2020-03-31 21:55:27.116835: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 45 of 100\r\n2020-03-31 21:55:30.685718: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 47 of 100\r\n2020-03-31 21:55:43.929746: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 54 of 100\r\n2020-03-31 21:55:55.429286: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 59 of 100\r\n2020-03-31 21:55:58.944730: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 66 of 100\r\n2020-03-31 21:56:10.205733: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 78 of 100\r\n2020-03-31 21:56:25.282349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 85 of 100\r\n2020-03-31 21:56:31.110601: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 89 of 100\r\n2020-03-31 21:56:41.034107: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 98 of 100\r\n2020-03-31 21:56:41.034194: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.\r\n2020-03-31 21:56:55.479292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-03-31 21:59:02.041739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\nINFO:tensorflow:Recording summary at step 0.\r\nI0331 21:59:05.214339 140594118641408 supervisor.py:1050] Recording summary at step 0.\r\nINFO:tensorflow:global step 10: loss = 3.5340 (2.648 sec/step)\r\nI0331 21:59:49.024268 140616897775424 learning.py:507] global step 10: loss = 3.5340 (2.648 sec/step)\r\nINFO:tensorflow:global step 20: loss = 3.2525 (8.487 sec/step)\r\nI0331 22:00:49.050415 140616897775424 learning.py:507] global step 20: loss = 3.2525 (8.487 sec/step)\r\nINFO:tensorflow:global step 30: loss = 3.2256 (8.564 sec/step)\r\nI0331 22:02:40.427151 140616897775424 learning.py:507] global step 30: loss = 3.2256 (8.564 sec/step)\r\nINFO:tensorflow:global step 40: loss = 3.2458 (12.522 sec/step)\r\nI0331 22:04:02.487207 140616897775424 learning.py:507] global step 40: loss = 3.2458 (12.522 sec/step)\r\n```\r\nthanks for the link in [stackoverflow https://stackoverflow.com/questions/58938886/segmentation-fault-training-deeplab-with-cityscapes](https://stackoverflow.com/questions/58938886/segmentation-fault-training-deeplab-with-cityscapes)\r\n\r\nCheers ! ", "Hi,\r\nI just checked your solution @Papageno2 \r\n1- I could make tfrecords successfuly \r\n\r\nls /hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/tfrecord/\r\ntrain-00000-of-00004.tfrecord     trainval-00002-of-00004.tfrecord\r\ntrain-00001-of-00004.tfrecord     trainval-00003-of-00004.tfrecord\r\ntrain-00002-of-00004.tfrecord     val-00000-of-00004.tfrecord\r\ntrain-00003-of-00004.tfrecord     val-00001-of-00004.tfrecord\r\ntrainval-00000-of-00004.tfrecord  val-00002-of-00004.tfrecord\r\ntrainval-00001-of-00004.tfrecord  val-00003-of-00004.tfrecord\r\n\r\n2- I have two classes one background and other class, I edited data_generator.py L82-90 as the following\r\nI have 176 samples as shown below\r\n\r\n_PASCAL_VOC_SEG_INFORMATION = DatasetDescriptor(\r\n    splits_to_sizes={\r\n        'train': 150,\r\n        'train_aug': 100,\r\n        'trainval': 176,\r\n        'val': 26,\r\n    },\r\n    num_classes=2,\r\n    ignore_label=255,\r\n\r\n3- I have a file called SegmentationClass contains the segmented images using LabelMe like this example\r\n![8FX1JXR_CV66B002X0Y2560](https://user-images.githubusercontent.com/24913534/80576689-4cbf4480-8a0e-11ea-90eb-c116007a7b1f.png)\r\n\r\nIn JPEGImages I have png images like this \r\n![8FX1JXR_CV66B002X512Y2048](https://user-images.githubusercontent.com/24913534/80576760-68c2e600-8a0e-11ea-8136-0e072b7b5f90.png)\r\n\r\nin ImageSets/train.txt I have 150 items name of images without extension val.txt 26 item trainval.txt 150 items.\r\n\r\n4- The tensorflow version is 1.14.0\r\n\r\n5-When I run the local_test.sh it runs smoothly with no errors, just to check if the error from TF versions, but it seems not.\r\n\r\n6-My images sizes are 512*512\r\n\r\nFinally:\r\nbut When Im running the python train command I'm facing the Segmentation fault (core dumped)\r\n\r\npython deeplab/train.py \\\r\n    --logtostderr \\\r\n    --training_number_of_steps=30000 \\\r\n    --train_split=\"train\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --train_crop_size=\"513,513\" \\\r\n    --train_batch_size=1 \\\r\n    --dataset=\"pascal_voc_seg\" \\\r\n    --tf_initial_checkpoint=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/exp/train_on_tranval_set/init_modelsinit_models/deeplabv3_pascal_train_aug/model.ckpt} \\\r\n    --train_logdir=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/exp/train_on_tranval_set/train/} \\\r\n    --dataset_dir=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/tfrecord/} > output.txt  2>&1\r\n\r\n\r\nThe error is still the same, here is the log file(part of it)\r\nINFO:tensorflow:Running local_init_op.\r\nI0429 10:23:24.512071 140539206354688 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0429 10:23:24.996261 140539206354688 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:Starting Session.\r\nI0429 10:23:26.720231 140539206354688 learning.py:754] Starting Session.\r\nINFO:tensorflow:Starting Queues.\r\nI0429 10:23:26.721034 140539206354688 learning.py:768] Starting Queues.\r\nFatal Python error: Segmentation fault\r\n\r\nThread 0x00007fd1d578c700 (most recent call first):\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1429 in _call_tf_sessionrun\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1341 in _run_fn\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1356 in _do_call\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1350 in _do_run\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1173 in _run\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 950 in run\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 490 in train_step\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 775 in train\r\n  File \"deeplab/train.py\", line 458 in main\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"deeplab/train.py\", line 464 in <module>\r\n\r\n\r\n", " the log for the error:\r\n[output.txt](https://github.com/tensorflow/tensorflow/files/4550613/output.txt)\r\n", "What bothered me for several days was that the file path was wrong and the shell script was not written correctly, so I simply converted to the following, which was a bit ugly but useful.\r\n!python train.py --logtostderr --num_clones 1 --fine_tune_batch_norm False --training_number_of_steps 5000 --train_split \"train\" --model_variant \"xception_65\" --atrous_rates 4 --atrous_rates 6 --atrous_rates 12 --output_stride 8 --decoder_output_stride 4 --train_crop_size 513,513 --train_batch_size 1 --dataset \"pascal_voc_seg\" --initialize_last_layer False --last_layers_contain_logits_only False --train_logdir ./checkpointwrited --dataset_dir ./datasets/pascal_voc_seg/tfrecord", "The error in my case was that --dataset_dir was not pointed correctly to the tfrecord file (wrong path)"]}, {"number": 36208, "title": "tensorflow lite model prediction cause Segmentation fault (core dumped)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from source \r\n- TensorFlow version : 2.0\r\n- Python version: 3.6.9\r\n- Bazel version : 1.1\r\n- GCC/Compiler version (if compiling from source): 8.30\r\n- CUDA/cuDNN version: 10.0.13\r\n- GPU model and memory: GTX 1050 ti\r\n\r\n\r\n**Describe the current behavior**\r\nthe code below always cause Segmentation fault (core dumped), I just trained a model convert to tflite and try to test my tflite model\r\n\r\n**Describe the expected behavior**\r\nit suppose to generate result from testing data\r\n\r\n**Code to reproduce the issue**\r\n``````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport os\r\nimport pathlib\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nimport tensorflow_datasets as dataset\r\n\r\nimport os\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\ninterpreter= tf.lite.Interpreter(model_path=\"../model/CNN_mobileV2_2.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\nPATH='/home/linxiang/test/clarius_img'\r\n\r\nvalidation_dir=os.path.join(PATH, 'validation')\r\nvalidation_image_generator = ImageDataGenerator(validation_split=0.9)\r\nbatch_size = 16\r\nepochs = 40\r\nIMG_HEIGHT = 224#160\r\nIMG_WIDTH = 224#700\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                              directory=validation_dir,\r\n\t\t\t\t\t\t\t      shuffle=True,\r\n\t\t\t\t\t\t\t      subset='validation',\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='categorical',\r\n                                                              classes=['abd','bladder','cardiac','lung'],\r\n\t\t\t\t\t\t              color_mode='rgb')\r\n\r\nwrongNumber=0;\r\ninput_details=interpreter.get_input_details()\r\noutput_details=interpreter.get_output_details()\r\ninterpreter.resize_tensor_input(input_details[0]['index'],(16,224,224,3))\r\ninterpreter.resize_tensor_input(output_details[0]['index'],(16,4))\r\n\r\nval_img,val_label=next(iter(val_data_gen))\r\n#val_img_gen,val_label_gen=next(iter(val_data_gen))\r\ntrue_label_ids = np.argmax(val_label, axis=-1)\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], val_img)\r\ninterpreter.invoke()\r\ntflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\r\nprint(\"Prediction results:\", tflite_model_predictions)\r\n\r\n", "comments": ["Please properly format the code, use ` ``` ` around it.", "after I pull the newest version of tensorflow problem solved"]}, {"number": 36207, "title": "Need help in finding out the file where exactly TFlite \"Post training Quantization\" is implimented in the tensorflow Repository", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.0\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:xiomi a2\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:1.14\r\n- **Python version**:3.7\r\n- **Bazel version (if compiling from source)**:None\r\n- **GCC/Compiler version (if compiling from source)**:None\r\n- **CUDA/cuDNN version**:None\r\n- **GPU model and memory**:Geforce 150Mx 2GB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nI am Requesting a Feature\r\nWanted to locate the exact file where \"8 bit Post training Quantization\" scheme is impimented \r\nin the tensorflow repository.\r\n### Source code / logs\r\ni have traversed until here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/toco/python/toco_from_protos.py\r\nBut not able to trace the code from here.", "comments": ["I think this would be a better fit for StackOverflow", "> I think this would be a better fit for StackOverflow\r\n\r\nAbsolutely correct but i thought it may also help others if contributors specify bit ofmore information by specifying folder names that impliment major operations in the ReadMe section", "There are tools to inspect the code, you could place a debugger breakpoint and step through the code while a model is quantized. Or, you could identify the file history, look at the commits, etc.\r\n\r\nWe cannot do this for every single feature.\r\n\r\nHence, closing as offtopic.", "> There are tools to inspect the code, you could place a debugger breakpoint and step through the code while a model is quantized. Or, you could identify the file history, look at the commits, etc.\r\n> \r\n> We cannot do this for every single feature.\r\n> \r\n> Hence, closing as offtopic.\r\n\r\nThank You but it would be greate if you suggest any debugger that can traverse throughout the tensorflow module plzzz.. because whichever i know are only refering from executed script only\r\n"]}, {"number": 36206, "title": "Gradient doc changed to accurately show the returned params", "body": "This PR resolves the issue #35628. The two places where there were descriptions about returned params were inconsistent. I have made them consistent w.r.t. code.", "comments": ["Thanks for taking this on, @ashutosh1919. The documentation still isn't quite clear to me. The summation notation is ambiguous since it doesn't specify which axis is being reduced. Personally, I think the whole phrasing of \"...where each tensor is the `sum(ys/xs)`...\" needs to be replaced with something more clear.\r\n\r\nA snippet of code or a concrete example would also help.", "> Thanks for taking this on, @ashutosh1919. The documentation still isn't quite clear to me. The summation notation is ambiguous since it doesn't specify which axis is being reduced. Personally, I think the whole phrasing of \"...where each tensor is the `sum(ys/xs)`...\" needs to be replaced with something more clear.\r\n> \r\n> A snippet of code or a concrete example would also help.\r\n\r\n@sharvil , I have added an example for illustration. I think that example illustrates everything with which you can understand the function easily.", "Thanks, this looks reasonable to me. I'll leave it to the TF team to get it merged in. Thanks again, @ashutosh1919.", "> Thanks, this looks reasonable to me. I'll leave it to the TF team to get it merged in. Thanks again, @ashutosh1919.\r\n\r\n@sharvil now has a clear understanding on the gradient doc. So, I request @alextp to review this PR."]}, {"number": 36205, "title": "ModuleNotFoundError: No module named 'pycocotools._mask' PLEASE HELP ME!!!!", "body": "I am running a Windows 10 x64 machine and I do find the _mask.pyx file in the path specified but it still can't find it for some reason! I have followed the instructions off of this website. Any help is much appreciated, I have run the build.py off of the cocoAPI since I am on windows. I have tried to install pycotools through pip. I have gone through every website with this issue mentioned and nothing has worked!!!! Thanks!\r\n\r\n**Describe the current behavior**\r\nits giving me this error:\r\n\r\n    Traceback (most recent call last):\r\n    File \"model_main.py\", line 25, in <module>\r\n    from object_detection import model_lib\r\n    File \"C:\\Python37\\models\\research\\object_detection\\model_lib.py\", line 27, in <module>\r\n    from object_detection import eval_util\r\n    File \"C:\\Python37\\models\\research\\object_detection\\eval_util.py\", line 33, in <module>\r\n    from object_detection.metrics import coco_evaluation\r\n    File \"C:\\Python37\\models\\research\\object_detection\\metrics\\coco_evaluation.py\", line 25, in <module>\r\n    from object_detection.metrics import coco_tools\r\n    File \"C:\\Python37\\models\\research\\object_detection\\metrics\\coco_tools.py\", line 51, in <module>\r\n    from pycocotools import coco\r\n    File \"C:\\Python37\\models\\research\\pycocotools\\coco.py\", line 55, in <module>\r\n    from . import mask as maskUtils\r\n    File \"C:\\Python37\\models\\research\\pycocotools\\mask.py\", line 3, in <module>\r\n    import pycocotools._mask as _mask\r\n    ModuleNotFoundError: No module named 'pycocotools._mask'\r\n\r\n**Describe the expected behavior**\r\nIt should run this command:\r\n`python model_main.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssdlite_mobilenet_v2_coco.config`\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nIdk\r\n\r\n**Other info / logs**\r\nI included the logs above I really need help soon!!!\r\n", "comments": ["Please provide the information required by the issue template.", "@Brayden1000 ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 36204, "title": "Quantile Huber Loss to predict Specific Quantile Value", "body": "Fixes #36369 \r\n\r\nWe know that we have huber loss function added in keras tf-2 already which can perform both kind of behaviour MSE and MAE depending on the scale of data. In most of the prediction and analysis models, we often do not need just median or mean predicted value, but we also need the specific quantile value of prediction. This is the loss function I am adding which is derived from **huber_loss** here\r\n[https://arxiv.org/pdf/1402.4624.pdf](https://arxiv.org/pdf/1402.4624.pdf) I name it **quantile_huber_loss** and the class which calls it is QuantileHuber. I have given great attention to the detail in implementing the function. function takes two extra arguements delta and quantile, where delta is common as the huber_loss and quantile is the float number between 0 and 1. Equation looks as below.\r\n![64808942-dd4b3080-d5b5-11e9-9549-2f98fb18a042](https://user-images.githubusercontent.com/20843596/73123322-db0dcf80-3fb4-11ea-852d-9dc672bd0906.png)\r\n", "comments": ["Already added as Pin Ball Loss in Addons repo. Closing this."]}, {"number": 36203, "title": "unable to use TimeseriesGenerator with fit_generator", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.3 Tricia\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary from pip\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce GTX 970 4GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n`fit_generator`or `fit` can't handle a `TimeSeriesGenerator`\r\n**Describe the expected behavior**\r\nShould be handled\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\n# if we uncomment this line and comment the next one no more problems \r\n# import keras # version 2.3.1\r\nfrom tensorflow import keras # version 2.2.4-tf\r\nimport numpy as np\r\nfrom keras.preprocessing.sequence import TimeseriesGenerator\r\nprint(keras.__version__)\r\n# define dataset\r\nseries = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\r\n# define generator\r\nn_input = 2\r\ngenerator = TimeseriesGenerator(series, series, length=n_input, batch_size=8)\r\n\r\nmodel = keras.Sequential([\r\n    keras.layers.Dense(1, activation='relu', input_dim=2),\r\n    keras.layers.Dense(1)\r\n])\r\n\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\r\n\r\nmodel.fit_generator(generator, steps_per_epoch=1, epochs=10)\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-18-603f0c2b45d6> in <module>\r\n     17 model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\r\n     18 \r\n---> 19 model.fit_generator(generator, steps_per_epoch=1, epochs=10)\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    322               'in a future version' if date is None else ('after %s' % date),\r\n    323               instructions)\r\n--> 324       return func(*args, **kwargs)\r\n    325     return tf_decorator.make_decorator(\r\n    326         func, new_func, 'deprecated',\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1304         use_multiprocessing=use_multiprocessing,\r\n   1305         shuffle=shuffle,\r\n-> 1306         initial_epoch=initial_epoch)\r\n   1307 \r\n   1308   @deprecation.deprecated(\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    233           max_queue_size=max_queue_size,\r\n    234           workers=workers,\r\n--> 235           use_multiprocessing=use_multiprocessing)\r\n    236 \r\n    237       total_samples = _get_total_number_of_samples(training_data_adapter)\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n    531                      'at same time.')\r\n    532 \r\n--> 533   adapter_cls = data_adapter.select_data_adapter(x, y)\r\n    534 \r\n    535   # Handle validation_split, we want to split the data and get the training\r\n\r\n~/master/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py in select_data_adapter(x, y)\r\n    996         \"Failed to find data adapter that can handle \"\r\n    997         \"input: {}, {}\".format(\r\n--> 998             _type_name(x), _type_name(y)))\r\n    999   elif len(adapter_cls) > 1:\r\n   1000     raise RuntimeError(\r\n\r\nValueError: Failed to find data adapter that can handle input: <class 'keras.preprocessing.sequence.TimeseriesGenerator'>, <class 'NoneType'>\r\n```\r\nIf you need more logs just ask :).", "comments": ["Was able to reproduce the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.research.google.com/gist/gadagashwini/b4ffb529c9f547b739dcb41b4a6cfe73/untitled358.ipynb). Thanks!", "@Matoran I used a different code to test TimeseriesGenerator with fit_generator. Heres my [gist](https://colab.sandbox.google.com/gist/gowthamkpr/994a11657986b250976f2ec252abe1e0/untitled284.ipynb)\r\n\r\nI am not running into any error using tf-nightly. Please take a look at it.\r\n\r\nYou can also find the code that I used [here](https://github.com/Tony607/Keras_TimeseriesGenerator). Thanks!", "@gowthamkpr next time I should test tf-nightly before opening an issue :p. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36203\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36203\">No</a>\n"]}, {"number": 36202, "title": "Update third_party/flatbuffers/BUILD.bazel flatc linkopts", "body": "This is suggested for fixing issue #36170 .\r\n\r\nI tried building after reverting the linkopts in file `third_party/flatbuffers/BUILD.bazel` to before  https://github.com/tensorflow/tensorflow/commit/adf6e22e4af83afd55e0da3caa7e7959def1e6b6 :\r\ni.e. adding the following under \u201c# Public flatc compiler.\u201d\r\n```\r\n    linkopts = select({\r\n         \":freebsd\": [\r\n             \"-lm\",\r\n         ],\r\n         \":windows\": [],\r\n         \"//conditions:default\": [\r\n             \"-lm\",\r\n             \"-ldl\",\r\n         ],\r\n     }),\r\n```\r\nI get the following build error:\r\n```\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted:\r\n@flatbuffers//:freebsd is not a valid configuration key for @flatbuffers//:flatc\r\n```\r\nThen if I leave out the freebsd selection, I get the following build error:\r\n```\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted:\r\n@flatbuffers//:windows is not a valid configuration key for @flatbuffers//:flatc\r\n```\r\nSo I was able to build by just using `linkopts = [\u201c-lm\u201d,\u201d-ldl\u201d,],` under  \u201c# Public flatc compiler.\u201d", "comments": ["That is because the conditions are only effective in TF workspace, but not flatbuffers workspace in which `@flatbuffers//:flatc` is built.\r\n\r\n~~Setting `--linkopt=-lm --linkopt=-ldl` in [.bazelrc](https://github.com/tensorflow/tensorflow/blob/master/.bazelrc#L346) seems to fix builds on Linux. Not sure what to do on other platforms.~~\r\n\r\nEDIT: It doesn't work. See fix below.", "@dbonner Try using the following syntax:\r\n\r\n```\r\nlinkopts = select({\r\n    \"@//tensorflow:freebsd\": [\r\n        \"-lm\",\r\n    ],\r\n    \"@//tensorflow:windows\": [],\r\n    \"//conditions:default\": [\r\n        \"-lm\",\r\n        \"-ldl\",\r\n    ],\r\n}),\r\n```", "Thanks @byronyi . I tried the suggested changes that were in the email I got from you:\r\n```\r\n    linkopts = select({\r\n        \"@org_tensorflow//tensorflow:freebsd\": [\r\n\t    \"-lm\",\r\n        ],\r\n        \"@org_tensorflow//tensorflow:windows\": [],\r\n        \"@org_tensorflow//tensorflow:android\": [],\r\n        \"//conditions:default\": [\r\n\t    \"-lm\",\r\n\t    \"-ldl\",\r\n        ],\r\n    }),\r\n```\r\nThe build works with the above changes.  I made these changes in to commit https://github.com/tensorflow/tensorflow/pull/36202/commits/ad7b3dc4aac4f291ed087b64d7ad53a412a61904\r\nI noticed that your comment reads differently.  I guess you must have edited it.  Your comment says: `@//tensorflow:` instead of `@org_tensorflow//tensorflow:`.  I made a third commit https://github.com/tensorflow/tensorflow/pull/36202/commits/d95511f416d1a346a0c9f14ef4f48791b156b7f4 and this also builds successfully.  So the suggested fix from the latest commit at this stage is:\r\n```\r\nlinkopts = select({\r\n    \"@//tensorflow:freebsd\": [\r\n        \"-lm\",\r\n    ],\r\n    \"@//tensorflow:windows\": [],\r\n    \"//conditions:default\": [\r\n        \"-lm\",\r\n        \"-ldl\",\r\n    ],\r\n}),\r\n```", "This PR is obsoleted by #36264. @dbonner should probably close it.", "Yes #36264 fixes this.  Thanks :)"]}, {"number": 36201, "title": "\"Could not load dynamic library 'libnvinfer.so.6'\" when installing from WSL 2", "body": "**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu through **WSL 2** on Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip, no virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no, machine is Dell XPS 13 9530\r\n- GPU model and memory: no\r\n\r\n**Describe the problem**\r\nWhen installing tensorflow using pip I'm getting:\r\n\r\n    In [1]: import tensorflow as tf\r\n    2020-01-25 11:20:08.541504: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n    2020-01-25 11:20:08.541639: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n    2020-01-25 11:20:08.541689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nA fresh install of WSL 2 on Windows 10, I did:\r\n\r\n    sudo apt update -y && sudo apt upgarde -y\r\n    sudo apt install -y python3-pip\r\n    python3 -m pip install pip --upgrade --user\r\n    python3 -m pip install tensorflow --user\r\n", "comments": ["@galah92 , It seems that you must have GPU to work with the tensorflow-gpu packages. Your error is because the computer is not able to locate the file **libnvinfer.so.6**. If you have NVIDIA GPU installed and nvcc is running, please check TensorRT installation guide [here](https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html). Also take a look at [this past issue](https://github.com/tensorflow/tensorflow/issues/34329). \r\n\r\nBut it seems certain that the error will persist until you don't have NVIDIA Gpu with CUDA installed.", "> @galah92 , It seems that you must have GPU to work with the tensorflow-gpu packages. Your error is because the computer is not able to locate the file **libnvinfer.so.6**. If you have NVIDIA GPU installed and nvcc is running, please check TensorRT installation guide [here](https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html). Also take a look at [this past issue](https://github.com/tensorflow/tensorflow/issues/34329).\r\n> \r\n> But it seems certain that the error will persist until you don't have NVIDIA Gpu with CUDA installed.\r\n\r\nThank you for the response. This is exactly was I understood from the error, but I installed the non-GPU version of tensorflow so I don't understand why it expects a GPU. The best part is that I don't even have a dedicated GPU on my machine (Dell XPS 13 9530). This is the installed package:\r\n\r\n    galah92@XPS13:~$ python3 -m pip freeze | grep tensor\r\n    tensorboard==2.1.0\r\n    tensorflow==2.1.0\r\n    tensorflow-estimator==2.1.0", "@galah92 , Please install tensorflow==1.15 using pip and not 2.x because default mode for 2.x seems to be GPU and default mode for 1.15 is CPU\r\n\r\nUse\r\n```sh\r\n$ pip install tensorflow-cpu\r\n```", "@galah92 You can safely ignore those warning logs and continue using TF. Note that TF will implement cpu for all your computations. TF 2.x packages are provide both cpu and gpu support. \r\nSee https://www.tensorflow.org/install/pip#tensorflow-2-packages-are-available", "@galah92 Please let us know if the above comment helps and issue is resolved.", "@ymodak @Saduf2019 Thanks, I'm currently ignoring these warnings. It's just weird that that's the default, I didn't expect warning if my machine don't even have a GPU.\r\nThanks again.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36201\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36201\">No</a>\n", "As the issue has been resolved, moving it to closed status", "I had the same issue, and the warnings went away when I used python2.7", "@G-shift That is because python 2.7 defaults to TF1.X and doesn't use TF2. You can check with\r\n\r\n```\r\npython2 -m pip freeze | grep tensorflow\r\npython3 -m pip freeze | grep tensorflow\r\n```\r\n\r\nand compare which versions you have installed in both pythons. Note that python 2 has reached it's end of life, so if you are writing any new code consider migrating to python 3 :)", "> @galah92 , Please install tensorflow==1.15 using pip and not 2.x because default mode for 2.x seems to be GPU and default mode for 1.15 is CPU\r\n> \r\n> Use\r\n> \r\n> ```shell\r\n> $ pip install tensorflow-cpu\r\n> ```\r\n\r\nThanks, it worked\r\nI am using Keras version 2.2.4 and TensorFlow version 1.15"]}, {"number": 36200, "title": "Copyright years in the files", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\n\r\nUmm, a lot of the files have copyright 2015 (or some other year) shouldn't they be 2020?\r\nI dont really know whether this is right or wrong... I'm just posting what I saw in the files", "comments": ["Hi, that is not how it works. You can find a lot of ressources with a simple search like `copyright year`.  One good explanation: https://stackoverflow.com/questions/2390230/do-copyright-dates-need-to-be-updated", "Closing as it is not really an issue. Plus, @Matoran provided a reasoning", "I didn't really know much about this, so thanks for the explanation!"]}, {"number": 36199, "title": "./tensorflow/lite/tools/make/download_dependencies.sh: line 59: 1: Usage: download_and_extract URL DIR", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.19.0-6-amd64 #1 SMP Debian 4.19.67-2+deb10u2 (2019-11-11) x86_64 GNU/Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): from source at https://github.com/tensorflow/tensorflow/archive/v2.1.0.tar.gz\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.3 (but not relevant to this issue as I am only compiling tf lite using make)\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): gcc (Debian 8.3.0-6) 8.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n```\r\n$ wget https://github.com/tensorflow/tensorflow/archive/v2.1.0.tar.gz\r\n$ tar -zxvf v2.1.0.tar.gz \r\n$ cd tensorflow-2.1.0/\r\n$ ./tensorflow/lite/tools/make/download_dependencies.sh \r\n./tensorflow/lite/tools/make/download_dependencies.sh: line 59: 1: Usage: download_and_extract URL DIR\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nIt seems that the `EIGEN_URL` variable is not being set correctly because the following and `grep -o` fails in the following command: `EIGEN_URL=\"$(grep -o 'http.*bitbucket.org/eigen/eigen/get/.*tar\\.gz' \"${BZL_FILE_PATH}\" | grep -v mirror.tensorflow | head -n1)\"`. The eigen URL should be updated to something like `https://storage.googleapis.com/mirror.tensorflow.org/gitlab.com/libeigen/eigen/`.\r\n\r\n```\r\nbash -x ./tensorflow/lite/tools/make/download_dependencies.sh \r\n+ set -e\r\n+++ dirname ./tensorflow/lite/tools/make/download_dependencies.sh\r\n++ cd ./tensorflow/lite/tools/make\r\n++ pwd\r\n+ SCRIPT_DIR=/home/tlm/_tmp/imfind/tf/tensorflow-2.1.0/tensorflow/lite/tools/make\r\n+ cd /home/tlm/_tmp/imfind/tf/tensorflow-2.1.0/tensorflow/lite/tools/make/../../../..\r\n+ DOWNLOADS_DIR=tensorflow/lite/tools/make/downloads\r\n+ BZL_FILE_PATH=tensorflow/workspace.bzl\r\n+ '[' '!' -f tensorflow/workspace.bzl ']'\r\n++ grep -o 'http.*bitbucket.org/eigen/eigen/get/.*tar\\.gz' tensorflow/workspace.bzl\r\n++ grep -v mirror.tensorflow\r\n++ head -n1\r\n+ EIGEN_URL=\r\n++ grep -o 'https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/gemmlowp/.*zip' tensorflow/workspace.bzl\r\n++ head -n1\r\n+ GEMMLOWP_URL=https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/gemmlowp/archive/12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3.zip\r\n+ GOOGLETEST_URL=https://github.com/google/googletest/archive/release-1.8.0.tar.gz\r\n++ grep -o 'https://github.com/abseil/abseil-cpp/.*tar.gz' tensorflow/workspace.bzl\r\n++ head -n1\r\n+ ABSL_URL=https://github.com/abseil/abseil-cpp/archive/43ef2148c0936ebf7cb4be6b19927a9d9d145b8f.tar.gz\r\n+ NEON_2_SSE_URL=https://github.com/intel/ARM_NEON_2_x86_SSE/archive/master.zip\r\n+ FARMHASH_URL=https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/farmhash/archive/816a4ae622e964763ca0862d9dbd19324a1eaf45.tar.gz\r\n+ FLATBUFFERS_URL=https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz\r\n+ FFT2D_URL=https://storage.googleapis.com/mirror.tensorflow.org/www.kurims.kyoto-u.ac.jp/~ooura/fft2d.tgz\r\n+ download_and_extract '' tensorflow/lite/tools/make/downloads/eigen\r\n+ local 'usage=Usage: download_and_extract URL DIR'\r\n./tensorflow/lite/tools/make/download_dependencies.sh: line 59: 1: Usage: download_and_extract URL DIR\r\n```", "comments": ["Updating the `tensorflow/lite/tools/make/download_dependencies.sh` file as follows fixes this issue:\r\n```\r\nEIGEN_URL=\"$(grep -o 'https://storage.googleapis.com/mirror.tensorflow.org/gitlab.com/libeigen/eigen/.*tar.gz' \"${BZL_FILE_PATH}\")\"\r\n```", "Can I open a PR if you are not interested @thelinuxmaniac ?", "I did not understand what you meant by \"Can I open a PR if you are not interested\".\r\n\r\nI can open a pull request to send a fix for this issue, if it is required. I want to hear from the maintainers if they want a PR for this trivial issue or they can fix it themselves.", "patch:\r\n\r\n```\r\nsed -i \"/^EIGEN_URL=/c\\EIGEN_URL=\\\"\\$(grep -o 'https://storage.googleapis.com/mirror.tensorflow.org/gitlab.com/libeigen/eigen/.*tar.gz' \\\"\\${BZL_FILE_PATH}\\\")\\\"\" tensorflow/lite/tools/make/download_dependencies.sh\r\n```", ">I did not understand what you meant by \"Can I open a PR if you are not interested\".\r\n\r\nI meant that I can open a PR if you are not interested or you don't have time for that. \r\nBut yes you are right, we should ask the maintainers first. ", "@rushabh-v Thank you for offering to help. Let me wait for response from maintainers and I will send a pull request, if required.", "> I think this was fixed in [0071950](https://github.com/tensorflow/tensorflow/commit/0071950c073eb78e8935ad680f557e11f52b76a0) and [0438fe6](https://github.com/tensorflow/tensorflow/commit/0438fe668efd9c3e3c3d4692f0c4af4f1dff6395), though it is not release in TensorFlow 2.1\r\n\r\nclosing this issue as it has already been fixed."]}, {"number": 36198, "title": "model.summary() Does not Work in Some Cases", "body": "Tf Version 2.1\r\nHaving been suggested by @reedwm I am filing this bug. Please see the last comment in issue #35441 for details.\r\n/CC @reedwm", "comments": ["@yourtheron ,\r\nThank you for raising bug, can you please provide us an example to reproduce the issue?", "@oanush . As I mentioned above, please refer to the last comment in issue #35441 and talk to @reedwm , who actually found out the bug and suggested me about raising it in a new issue. How the bug was found out was too long and unnecessary to be repeated.", "Ah I see the issue. You never used either of your Concatenate layers. Here is a smaller example to reproduce:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass MyModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super(MyModel, self).__init__()\r\n    self.dense = tf.keras.layers.Dense(16)\r\n    self.concat = tf.keras.layers.Concatenate(axis=1)\r\n\r\n  def call(self, inputs):\r\n    return self.dense(inputs)\r\n\r\nmodel = MyModel()\r\nmodel.build((16, 16))\r\nmodel.summary()\r\n```\r\n\r\nThe error is\r\n\r\n```\r\nValueError: You tried to call `count_params` on concatenate, but the layer isn't built. You can build it manually via: `concatenate.build(batch_input_shape)`.\r\n```\r\n\r\nThis isn't a bug, but perhaps we could improve the error message?\r\n", "@tensorflowbutler Sorry for the delay due to the hotch-potch in China, I am also confused, is it not a bug related to model.summary() in tf2.1?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36198\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36198\">No</a>\n"]}, {"number": 36197, "title": "not even getting detected for the python3.8.1", "body": "![image](https://user-images.githubusercontent.com/48592314/73117091-98bda180-3f66-11ea-9ad4-163ea27b8904.png)\r\n", "comments": ["@vishwas1234567, Please take a look at [this issue](https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-577331441). It says that tensorflow is not supported for python 3.8 as of now. And if we talk about tensorflow 2.0 specifically, it supports the python range 3.4 to 3.7. If your computer has python 3.8 installed then you can install 3.7 too and use virtualenv to install tensorflow. Below is what you can do : \r\n\r\n```sh\r\n$ virtualenv --python=python3.7 my_venv  \r\n$ source my_venv/bin/activate \r\n$ pip install tensorflow  \r\n```\r\n\r\nIf your issue resolves by this method then please close the issue.", "Closing as duplicate of #33374. Please use search before opening new issues, especially when opening multiple related ones."]}, {"number": 36196, "title": "not getting installed in python 3.8.1", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["![image](https://user-images.githubusercontent.com/48592314/73117078-7e83c380-3f66-11ea-855d-349ba8a2d448.png)\r\n", "@vishwas1234567, Please take a look at [this issue](https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-577331441). It says that tensorflow is not supported for python 3.8 as of now. And if we talk about tensorflow 2.0 specifically, it supports the python range 3.4 to 3.7. If your computer has python 3.8 installed then you can install 3.7 too and use virtualenv to install tensorflow. Below is what you can do :\r\n\r\n```sh\r\n$ virtualenv --python=python3.7 my_venv  \r\n$ source my_venv/bin/activate \r\n$ pip install tensorflow  \r\n```\r\n\r\nIf your issue resolves by this method then please close the issue.\r\n", "Closing as duplicate of #33374. Please use search before opening new issues, especially when opening multiple related ones."]}, {"number": 36195, "title": "Update third_party/flatbuffers/BUILD.bazel to linkopts -lm -lpthread", "body": "This fixes #36170", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36195) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36195) for more info**.\n\n<!-- ok -->", "I doubt this is a proper fix. See the [linkopts](https://github.com/tensorflow/tensorflow/commit/adf6e22e4af83afd55e0da3caa7e7959def1e6b6#diff-4bdae93a605044a27f9df49a92bcf398L129-L138) before adf6e22e4af83afd55e0da3caa7e7959def1e6b6:\r\n\r\n```\r\n    linkopts = select({\r\n         \":freebsd\": [\r\n             \"-lm\",\r\n         ],\r\n         \":windows\": [],\r\n         \"//conditions:default\": [\r\n             \"-lm\",\r\n             \"-ldl\",\r\n         ],\r\n     }),\r\n```\r\n", "I'll close the request. I'll try building with the linkopts before https://github.com/tensorflow/tensorflow/commit/adf6e22e4af83afd55e0da3caa7e7959def1e6b6"]}, {"number": 36194, "title": "Can not train a BERT fine tuning model using TF on TPU", "body": "I am training a tensorflow model defined as follows on a TPU. But when it starts training, I run into this error: \r\nUnimplementedError: {{function_node __inference_distributed_function_299068}} Compilation failure: Dynamic concatenation is not supported yet: %reshape.3993 = s32[832]{0} reshape(s32[2,416]{1,0} %reshape.621), metadata={op_type=\"Reshape\" op_name=\"Reshape_1636\"}\r\n\tTPU compilation failed\r\n\t [[{{node tpu_compile_succeeded_assert/_14468581000393706631/_10}}]].\r\n\r\nI searched on google but did not find any clue to solve this. Any ideas?\r\n\r\ndef create_model(pretrained_path):\r\n\r\n    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n\r\n    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\r\n    config = BertConfig() \r\n\r\n    config.output_hidden_states = False  \r\n    bert_model = TFBertModel.from_pretrained(pretrained_path, config=config)\r\n    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\r\n    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\r\n    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\r\n    a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\r\n\r\n    x =  tf.keras.layers.Concatenate()([q, a])\r\n\r\n    x = tf.keras.layers.Dropout(0.2)(x)\r\n\r\n    x = tf.keras.layers.Dense(30, activation='sigmoid')(x)\r\n\r\n    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, a_id, a_mask, a_atn, ], outputs=x)\r\n    return model", "comments": ["@wmmxk, Can you provide the complete code to reproduce the reported issue and also Tensorflow version. Thanks!", "Having same issue.\r\nWhen starting training with \r\n```with tpu_strategy.scope():```\r\n\r\nIt starts to process the first batch and gives me this error", "@nariman9119 , Can you provide the complete code to replicate the reported issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "In case anyone comes across this ticket, and frustrated that there was no answer before it was closed, I ran into the exact same issue. For me, my issue was my TF Dataset pipeline causing this issue downstream. \r\n\r\nit was caused by TPUs lack of support for dynamic batch sizes. In TF2, this can be resolved by adding drop_remainder=True to your dataset pipeline's batch operation:\r\n\r\n`dataset.batch(..., drop_remainder=True)`\r\n\r\nHope this helps!!", "@mikeortman Yup that worked. Thank you, stranger."]}, {"number": 36193, "title": "ModuleNotFoundError: No module named 'tensorflow_estimator.contrib'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):\r\nI have installed tensorflow into my conda environment via `pip install tensorflow`\r\nIt shows as version 2.1.0 when I list the installed version, but when I import tensorflow within a Python interpreter I see version 1.15.0-rc1\r\n```\r\n$ conda list tensorflow\r\n# packages in environment at /home/james/miniconda3/envs/deeplab:\r\n#\r\n# Name                    Version                   Build  Channel\r\ntensorflow                2.1.0                    pypi_0    pypi\r\ntensorflow-estimator      2.1.0                    pypi_0    pypi\r\n\r\n$ python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nv1.15.0-rc1-42-g5adb433 1.15.0-rc2\r\n```\r\n- TensorFlow version (use command below): I am not sure, based on the above.\r\n- Python version: Python 3.7.6\r\n\r\n**Describe the current behavior**\r\nI am trying to run the [DeepLab example](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/pascal.md) using this command:\r\n```\r\n$ python deeplab/train.py \\\r\n    --logtostderr \\\r\n    --training_number_of_steps=30000 \\\r\n    --train_split=\"train\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --train_crop_size=\"513,513\" \\\r\n    --train_batch_size=1 \\\r\n    --dataset=\"basins\" \\\r\n    --tf_initial_checkpoint=/home/james/deeplab/pretrained/x65-b2u1s2p-d48-2-3x256-sc-cr300k_init.ckpt.data-00000-of-00001 \\\r\n    --train_logdir=./deeplab/datasets/basins/exp/train_on_train_set/train \\\r\n    --dataset_dir=./deeplab/datasets/basins\r\n```\r\nI get the following output/error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"deeplab/train.py\", line 26, in <module>\r\n    from tensorflow.contrib import quantize as contrib_quantize\r\n  File \"/home/james/.local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/home/james/.local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/home/james/miniconda3/envs/deeplab/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/james/.local/lib/python3.7/site-packages/tensorflow_core/contrib/__init__.py\", line 48, in <module>\r\n    from tensorflow.contrib import estimator\r\n  File \"/home/james/.local/lib/python3.7/site-packages/tensorflow_core/contrib/estimator/__init__.py\", line 30, in <module>\r\n    from tensorflow_estimator.contrib import estimator\r\nModuleNotFoundError: No module named 'tensorflow_estimator.contrib'\r\n```\r\n\r\n**Describe the expected behavior**\r\nI am hoping that the model will train as advertised.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n$ python -c 'import tensorflow as tf; tf.contrib.summary'\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@monocongo, I understood your problem. I have found out [this past issue](https://github.com/tensorflow/tensorflow/issues/23163) in which somebody else had the same problem. But with the below solution, it worked fine. \r\n\r\nTry this after installing tensorflow : \r\n```sh\r\n$ pip install -U tensorflow_estimator\r\n```\r\nThanks to [this](https://github.com/tensorflow/tensorflow/issues/23163#issuecomment-449767938).\r\n\r\n", "Thanks, @ashutosh1919 . I actually saw this before posting and tried the suggestions there to no avail. For example:\r\n```\r\n$ pip install -U tensorflow_estimator\r\nRequirement already up-to-date: tensorflow_estimator in /home/james/miniconda3/envs/deeplab/lib/python3.7/site-packages (2.1.0)\r\n```", "> Thanks, @ashutosh1919 . I actually saw this before posting and tried the suggestions there to no avail. For example:\r\n> \r\n> ```\r\n> $ pip install -U tensorflow_estimator\r\n> Requirement already up-to-date: tensorflow_estimator in /home/james/miniconda3/envs/deeplab/lib/python3.7/site-packages (2.1.0)\r\n> ```\r\n\r\ntry [this one](https://github.com/tensorflow/tensorflow/issues/23163#issuecomment-509178978). (Reinstallation may help)", "@ashutosh1919  That did the trick. Thanks so much for your help!", "> @ashutosh1919 That did the trick. Thanks so much for your help!\r\n\r\n@monocongo , You're most welcome. ", "I also have the same problem when I'm running Tensorflow model object detection API in Win10, Python3.7, tensorflow 1.15. I try `pip install -U tensorflow_estimator` as @ashutosh1919 suggested, but it didn't work. I solve the problem for these steps:\r\n1. `pip list` \r\n2. make sure your pip install packages like this:\r\n![Snipaste_2020-02-20_15-22-49](https://user-images.githubusercontent.com/43908098/74911323-51a4be00-53f7-11ea-8c47-d9848760218e.png)\r\n", "@Monkey1GIt , \r\n`pip install -U tensorflow_estimator` didn't help to @monocongo  too. What helped him is [this one](https://github.com/tensorflow/tensorflow/issues/23163#issuecomment-509178978). The reinstallation of the same helps. Please just change the version correctly as per your requirements.", "Hi, for those who still have problems, here's my experience:\r\nEnsure that you are importing tensorflow_estimator.contrib via the correct path. I realized my path to TensorFlow and path to tensorflow_estimator were different, whereby even though I did have tensorflow_estimator.contrib, my system path went the wrong way. Here's how to check:\r\n\r\n```\r\nimport tensorflow_estimator\r\nprint(tensorflow_estimator.__file__) \r\n```\r\n\r\nIf you realize the path given is incorrect, then do the following:\r\n```\r\nimport sys\r\nsys.path.remove('insert_your_incorrect_path') \r\n```\r\n\r\nNow, python will not scan the incorrect path and should be forced to look for tensorflow_estimator in the correct path. \r\n\r\nI'm a beginner, so if this mistake looks stupid, I'm sorry :( \r\n", "The solution is to `pip list`, identify all tensorflow ecosystem packages that are *NOT* on 1.15 and reinstall those to 1.15.\r\n\r\n`contrib` only exists in 1.15; installing any component at a later version will create issues.\r\n\r\nFor example, in https://github.com/tensorflow/tensorflow/issues/36193#issuecomment-588692406 you also need to uninstall `tensorflow-gpu-estimator`", "How we can Uninstall tensorflow-estimator and install the compatible version?\r\nFirst I had tf 2.1 but I was forced to downgrade to tf 1.15 and now I get this error with \r\ntf estimator since it's still 2.1. Could you please help me?", "when I use pip install 'tensorflow-estimator<1.15.0rc0,>=1.14.0rc0' --force-reinstall\r\nI get the following error.\r\nThe system cannot find the file specified.", "@Maryammhsnv `pip uninstall` or simply delete the files in `site-packages`. You can also create a new virtual environment. These are not issues related to TensorFlow, so let's not derail discussion.", "Mine is based on TensorFlow 2.0 and is built with '--config=v1' by myself.\r\nThe following changes works for me.\r\n\r\n$ vi /home/xxxx/.local/lib/python3.6/site-packages/tensorflow_core/contrib/estimator/__init__.py \r\n```\r\n.....\r\n 30 from tensorflow_estimator import estimator\r\n 31 #from tensorflow_estimator.contrib import estimator\r\n....\r\n 40 import tensorflow_core.contrib.estimator.python\r\n 41 #import tensorflow.contrib.estimator.python\r\n.....\r\n 47 #from tensorflow_estimator.contrib.estimator import *\r\n 48 from tensorflow.python.util.all_util import remove_undocumented\r\n```", "We don't really support `--config=v1` on the after 2.0 world."]}, {"number": 36192, "title": "TensorFlow fit() and GradientTape - number of epochs are different", "body": "if I define the architecture of a neural network using only dense fully connected layers and train them such that there are two models which are trained using **model.fit()** and **GradientTape**. Both the methods of training use the *same* model architecture.\r\n\r\nThe randomly initialized weights are shared between the two models and all other parameters such as optimizer, loss function and metrics are also the same.\r\n\r\nDimensions of training and testing sets are:\r\nX_train = (960, 4), y_train = (960,), X_test = (412, 4) & y_test = (412,)\r\n\r\n    import pandas as pd, numpy as np\r\n    import matplotlib.pyplot as plt\r\n    import seaborn as sns\r\n    from sklearn.model_selection import train_test_split\r\n    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\r\n    from sklearn.preprocessing import LabelEncoder\r\n    from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\r\n    \r\n    import tensorflow as tf\r\n    from tensorflow.keras.models import Sequential\r\n    from tensorflow.keras.layers import Dense\r\n    import tensorflow_model_optimization as tfmot\r\n    from tensorflow_model_optimization.sparsity import keras as sparsity\r\n    \r\n    \r\n    def create_nn():\r\n        \"\"\"\r\n        Function to create a\r\n        Neural Network\r\n        \"\"\"\r\n        model = Sequential()                                                    \r\n    \r\n        model.add(\r\n            Dense(\r\n                units = 4, activation = 'relu',\r\n                kernel_initializer = tf.keras.initializers.GlorotNormal(),\r\n                input_shape = (4,)\r\n            )\r\n        )\r\n    \r\n        model.add(\r\n            Dense(\r\n                units = 3, activation = 'relu',\r\n                kernel_initializer = tf.keras.initializers.GlorotNormal()\r\n            )\r\n        )\r\n    \r\n        model.add(\r\n            Dense(\r\n                units = 1, activation = 'sigmoid'\r\n            )\r\n        )\r\n    \r\n        \"\"\"\r\n        # Compile the defined NN model above-\r\n        model.compile(\r\n            loss = 'binary_crossentropy',  # loss = 'categorical_crossentropy'\r\n            optimizer = tf.keras.optimizers.Adam(lr = 0.001),\r\n            metrics=['accuracy']\r\n        )\r\n        \"\"\"\r\n    \r\n        return model\r\n    \r\n    \r\n    # Instantiate a model- model = create_nn()\r\n    \r\n    # Save weights for fair comparison- model.save_weights(\"Random_Weights.h5\", overwrite=True)\r\n    \r\n    \r\n    # Create datasets to be used for GradientTape-\r\n    # Use tf.data to batch and shuffle the dataset train_ds = tf.data.Dataset.from_tensor_slices(\r\n        (X_train, y_train)).shuffle(100).batch(32)\r\n    \r\n    test_ds = tf.data.Dataset.from_tensor_slices(\r\n        (X_test, y_test)).shuffle(100).batch(32)\r\n    \r\n    # Define early stopping- callback = tf.keras.callbacks.EarlyStopping(\r\n        monitor='val_loss', patience=3,\r\n        min_delta = 0.001, mode = 'min' )\r\n    \r\n    # Train defined model- history_orig = model.fit(\r\n        x = X_train, y = y_train,\r\n        batch_size = 32, epochs = 500,\r\n        validation_data = (X_test, y_test),\r\n        callbacks = [callback],\r\n        verbose = 1 )\r\n    \r\n    \r\n    # Instantiate a model- model_gt = create_nn()\r\n    \r\n    # Restore random weights as used by the previous model for fair comparison- model_gt.load_weights(\"Random_Weights.h5\")\r\n    \r\n    \r\n    # Choose an optimizer and loss function for training- loss_fn = tf.keras.losses.BinaryCrossentropy() optimizer = tf.keras.optimizers.Adam(lr = 0.001)\r\n    \r\n    # Select metrics to measure the error & accuracy of model.\r\n    # These metrics accumulate the values over epochs and then\r\n    # print the overall result- train_loss = tf.keras.metrics.Mean(name = 'train_loss') train_accuracy = tf.keras.metrics.BinaryAccuracy(name = 'train_accuracy')\r\n    \r\n    test_loss = tf.keras.metrics.Mean(name = 'test_loss') test_accuracy = tf.keras.metrics.BinaryAccuracy(name = 'train_accuracy')\r\n    \r\n    \r\n    # Use tf.GradientTape to train the model-\r\n    \r\n    @tf.function def train_step(data, labels):\r\n        \"\"\"\r\n        Function to perform one step of Gradient\r\n        Descent optimization\r\n        \"\"\"\r\n    \r\n        with tf.GradientTape() as tape:\r\n            predictions = model_gt(data)\r\n            loss = loss_fn(labels, predictions)\r\n    \r\n        gradients = tape.gradient(loss, model_gt.trainable_variables)\r\n        optimizer.apply_gradients(zip(gradients, model_gt.trainable_variables))\r\n    \r\n        train_loss(loss)\r\n        train_accuracy(labels, predictions)\r\n    \r\n    \r\n    @tf.function def test_step(data, labels):\r\n        \"\"\"\r\n        Function to test model performance\r\n        on testing dataset\r\n        \"\"\"\r\n        \r\n        predictions = model_gt(data)\r\n        t_loss = loss_fn(labels, predictions)\r\n    \r\n        test_loss(t_loss)\r\n        test_accuracy(labels, predictions)\r\n    \r\n    \r\n    EPOCHS = 100\r\n    \r\n    # User input- minimum_delta = 0.001 patience = 3\r\n    \r\n    patience_val = np.zeros(patience)\r\n    \r\n    \r\n    # Dictionary to hold scalar metrics- history = {}\r\n    \r\n    history['accuracy'] = np.zeros(EPOCHS) history['val_accuracy'] = np.zeros(EPOCHS) history['loss'] = np.zeros(EPOCHS) history['val_loss'] = np.zeros(EPOCHS)\r\n    \r\n    for epoch in range(EPOCHS):\r\n        # Reset the metrics at the start of the next epoch\r\n        train_loss.reset_states()\r\n        train_accuracy.reset_states()\r\n        test_loss.reset_states()\r\n        test_accuracy.reset_states()\r\n    \r\n        for x, y in train_ds:\r\n            train_step(x, y)\r\n    \r\n        for x_t, y_t in test_ds:\r\n            test_step(x_t, y_t)\r\n    \r\n        template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, Test Loss: {3:.4f}, Test Accuracy: {4:4f}'\r\n    \r\n        history['accuracy'][epoch] = train_accuracy.result()\r\n        history['loss'][epoch] = train_loss.result()\r\n        history['val_loss'][epoch] = test_loss.result()\r\n        history['val_accuracy'][epoch] = test_accuracy.result()\r\n    \r\n        print(template.format(epoch + 1, \r\n                              train_loss.result(), train_accuracy.result()*100,\r\n                              test_loss.result(), test_accuracy.result()*100))\r\n    \r\n        if epoch > 2:\r\n            # Computes absolute differences between 3 consecutive loss values-\r\n            differences = np.abs(np.diff(history['val_loss'][epoch - 3:epoch], n = 1))\r\n            \r\n            # Checks whether the absolute differences is greater than 'minimum_delta'-\r\n            check =  differences > minimum_delta\r\n            \r\n            # print('differences: {0}'.format(differences))\r\n            \r\n            # Count unique element with it's counts-\r\n            # elem, count = np.unique(check, return_counts=True)\r\n            # print('\\nelem = {0}, count = {1}'.format(elem, count))\r\n            \r\n            if np.all(check == False):\r\n            # if elem.all() == False and count == 2:\r\n                print(\"\\n\\nEarlyStopping Evoked! Stopping training\\n\\n\")\r\n                break\r\n\r\n\r\nIn \"model.fit()\" method, it takes around 82 epochs, while GradientTape method takes 52 epochs.\r\n\r\nWhy is there this discrepancy in the number of epochs?\r\n\r\nThanks!\r\n\r\n\r\nComplete code in GitHub-\r\nhttps://github.com/arjun-majumdar/tensorflow_codes/blob/master/EarlyStopping_with_GradientTape_using_TensorFlow_2.ipynb\r\n\r\n", "comments": ["I have tried on colab with TF version 2.0 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/cb1ab77eee77a220bd6632f2a2b0de3e/untitled594.ipynb). Thanks!", "@arjun-majumdar I agree that `EarlyStopping` is kicking in early in case of `GradientTape` where as it is kicking later using `model.fit`. However, the error levels at those Epochs are very different. Please check below. These numbers are from your GitHub link.\r\n\r\n#### Model.fit \r\n\r\n```\r\nEpoch 131/500\r\n960/960 [==============================] - 0s 84us/sample - loss: 0.0526 - accuracy: 0.9917 - val_loss: 0.0587 - val_accuracy: 0.9903\r\n```\r\n\r\n#### Gradient Taps\r\n`Epoch 99, Loss: 0.0751, Accuracy: 99.0625, Test Loss: 0.0815, Test Accuracy: 99.004120`\r\n\r\nIn case of using `GradientTape`, `EarlyStopping` is kicking in early as the defined condition met. But the `val_loss` is almost 40% higher than the `val_loss`  obtained using `model.fit`. If you run for some more iterations while using `GradientTape`, may be the losses would be similar. Thanks!\r\n\r\nI am closing this issue as it is resolved. Please feel free to reopen if I am mistaken. Thanks!"]}]