[{"number": 10773, "title": "PIP: Don't lock markdown version to 2.2.0", "body": "https://github.com/tensorflow/tensorflow/issues/10744\r\n\r\n> This markdown version lock could cause versioning conflict for downstream (e.g. if requirements are compiled and resolved by pip-compile). Wondering If there's a reason to lock this version. And it's already not sync with the CI install script (those --upgrade with locked version also doesn't seem right to me).", "comments": ["I meant to migrate this to TensorBoard \ud83d\ude1d"]}, {"number": 10772, "title": "Changing context search for BiasAddGrad rewrite from BFS to stricter check", "body": "Current approach for rewriting BiasAddGrad node searches the backward data-flow of BiasAddGrad for MatMul or Conv2D node, whatever is found earlier is considered as the context for rewriting BiasAddGrad.  We discovered that this approach is not robust, so we are changing it to rely on a much stricter and robust check for context search.", "comments": ["Can one of the admins verify this patch?", "@andydavis1 did anyone get a chance to take a look at the PR? Thanks.", "@tensorflow-jenkins test this please", "Awesome - thanks for getting this in quickly! Several folks are waiting on this fix so hopefully we can merge asap :)"]}, {"number": 10771, "title": "Refactor and implementation of the camera API 1, it fixes #8736", "body": "As detailed in #8736, the legacy devices should work with the Camera API 1, the detector demo would need even more refactor in order to work ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "For the CLA issue, @BrianOn99 are you okay with your commit being included in this PR?\r\n@osdamv could you resolve the conflict? Thanks!", "Sure.", "I think my PR could be closed as @osdamv 's approach looks better (less code duplication).  Thanks for the improvement!", "Confirmed to be working except the detector demo. ", "@yifeif I just fixed the conflicts", "Thanks @osdamv and @BrianOn99. \r\n@andrewharp could you take a look? Thanks!", "Jenkins, test this please.", "Jenkins, test this please.", "@osdamv to be clear, this is ready to be reviewed?", "Yeah, I hope there is no more sanity issues ", "Hi, I was too busy the last to weeks(I was studying for a Facebook interview!!) in order to make the requested changes. Hopefully this commit pass the review :).", "Hope it went well! Looking forward to the update.\n\nOn Jul 14, 2017 12:03 PM, \"osdamv\" <notifications@github.com> wrote:\n\nHi, I was too busy the last to weeks(I was studying for a Facebook\ninterview!!) in order to make the requested changes. Hopefully this commit\npass the review :).\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/pull/10771#issuecomment-315441091>,\nor mute the thread\n<https://github.com/notifications/unsubscribe-auth/AT_SbRofqHlznMLzZL5Y5PRxO2G-uCqhks5sN7tygaJpZM4N8vJo>\n.\n", "@tensorflow-jenkins Test this, please.", "Jenkins, test this please", "@osdamv Thank you for the contribution!", "@andrewharp  Your welcome!! Any thing else I can do please let me know "]}, {"number": 10770, "title": " Added 7 comments on core_rnn_cell_test.", "body": "I added 7 comments on core_rnn_cell_test.\r\nThanks!", "comments": ["Can one of the admins verify this patch?", "hi @chris-chris we usually try to reflect the content of tests in test names. I will close this PR for consistency. Thank you for your contribution!"]}, {"number": 10769, "title": "RunMetadata giving inconsistent RAM values", "body": "When viewing the GPU memory usage of a run metadata in TensorBoard, it shows for example one node \"model\" with 9.99 GB and another node \"optimization\" with 14.1 GB. The sum of these values exceeds the available memory on the GPU (12 GB) by far.", "comments": ["Redirecting to @mrry because he understands the RunMetadata api. In the past, he's told me it's very confusing to interpret these numbers.", "I'm not sure exactly what TensorBoard is visualizing, but it [looks like](https://github.com/tensorflow/tensorboard/blob/6aa3dba050c7a89e826051443a836f07c2e82913/tensorboard/plugins/graphs/tf_graph_common/graph.ts#L427) it's summing up the `total_bytes` fields from some subset of the nodes in a graph. These values represent the sum of all bytes *allocated* during the execution of an op, but don't account for when those bytes are *deallocated*. Therefore it's perfectly reasonable for them to sum to a larger value than the total memory in a device.", "@3rd3 you could build more accurate image of maximum memory by parsing memory deallocation messages like in https://github.com/yaroslavvb/memory_util", "@mrry Currently what is the suggest way for tracking down GPU memory usage ?"]}, {"number": 10768, "title": "Undefined Symbol Import error ", "body": "Hi,\r\n\r\nSO: Linux Mint 17 x64\r\nVersion 1.1\r\nCompiling from source\r\nOptions: sycl (Opencl)\r\nPython 2.7\r\n\r\n_Using TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"/home/kafka/PycharmProjects/Test1/Test1.py\", line 1, in <module>\r\n    from keras.models import Sequential\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/__init__.py\", line 3, in <module>\r\n    from . import activations\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/activations.py\", line 4, in <module>\r\n    from . import backend as K\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/__init__.py\", line 73, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN2cl4sycl7program30create_program_for_kernel_implESsPKhiPKPKcSt10shared_ptrINS0_6detail7contextEE\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help._\r\n\r\n\r\n\r\n\r\n", "comments": ["OpenCL is highly experimental  right now, so marking community support. It also is not yet performant. Follow along #22 for more info.", "Thanks", "For now you would be better on the branch referenced [here](https://www.codeplay.com/products/computesuite/computecpp/guides/how-to-setup-tensorflow-with-computecpp) until the changes make it upstream to the main TensorFlow branch \r\nhttps://github.com/lukeiwanski/tensorflow.git\r\nbranch: opencl_improvements ", "Thanks men, i will try it.", "Please open a new issue if this problem still persists with the latest Tensorflow version by providing all information asked in[ this template](https://github.com/tensorflow/tensorflow/issues/new/choose). "]}, {"number": 10766, "title": "MultivariateNormalDiag probability gradient fails", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.5\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-0-gce1d6ec49 1.2.0-rc2\r\n- **Bazel version (if compiling from source)**: 0.5.1-homebrew\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: python test_diag.py\r\n\r\n### Describe the problem\r\nThe gradients for the tensorflow.contrib.distributions.MultiVariateNormalDiag throw an error.  This might be related to #10149.  Notice that the tensorflow.contrib.distributions.Normal works as expected so I think this is a bug in the gradient implementation of the MultiVarateNormalDiag.\r\n\r\n### Source code\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.distributions as td\r\n\r\nassert_args = dict(validate_args=True, allow_nan_stats=False)\r\n\r\n# tf Graph Input\r\nx = tf.placeholder(shape=(4, 6), dtype=tf.float32, name=\"X\")\r\ny = tf.placeholder(shape=(4, 2), dtype=tf.float32, name=\"Y\")\r\n\r\n# Set model weights\r\nb = tf.Variable(np.ones((4, 6)), dtype=np.float32, name=\"b\")\r\nW = tf.Variable(np.ones((6, 6)), dtype=np.float32, name=\"W\")\r\n\r\npred_mu = tf.reshape(x@W + b, (4, 3, 2))\r\npred_sigma = tf.reshape(tf.exp(x@W + b), (4, 3, 2))\r\n\r\n# fails below\r\ndist = td.MultivariateNormalDiag(loc=pred_mu, scale_diag=pred_sigma, **assert_args)\r\nprob = dist.prob(y[:, tf.newaxis])\r\n\r\n# this works fine\r\n# dist_x = td.Normal(loc=pred_mu[:, :, 0], scale=pred_sigma[:, :, 0], **assert_args)\r\n# dist_y = td.Normal(loc=pred_mu[:, :, 1], scale=pred_sigma[:, :, 1], **assert_args)\r\n# prob = dist_x.prob(y[:, 0, tf.newaxis]) * dist_y.prob(y[:, 1, tf.newaxis])\r\n\r\ngradients = tf.gradients(prob, [b, W])\r\n\r\nfeed_dict = {\r\n    x: np.ones((4, 6), dtype=np.float32),\r\n    y: np.ones((4, 2), dtype=np.float32)\r\n}\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(prob, feed_dict=feed_dict)  # works fine\r\n    retval = sess.run(gradients, feed_dict=feed_dict)  # throws\r\n    print(retval)\r\n```\r\n\r\n### Output\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = -1 is not in [0, 3)\r\n\t [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test_diag.py\", line 41, in <module>\r\n    retval = sess.run(gradients, feed_dict=feed_dict) # throws\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = -1 is not in [0, 3)\r\n\t [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]\r\n\r\nCaused by op 'gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather', defined at:\r\n  File \"test_diag.py\", line 31, in <module>\r\n    gradients = tf.gradients(prob, [b, W])\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 129, in _ProdGrad\r\n    reduced_num = math_ops.reduce_prod(array_ops.gather(input_shape, reduced))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\r\n    validate_indices=validate_indices, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\n...which was originally created as op 'MultivariateNormalDiag_3/prob/Prod', defined at:\r\n  File \"test_diag.py\", line 24, in <module>\r\n    prob = dist.prob(y[:,tf.newaxis])\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\", line 712, in prob\r\n    return self._call_prob(value, name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\", line 694, in _call_prob\r\n    return self._prob(value, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/util.py\", line 688, in _fn\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py\", line 216, in _prob\r\n    return super(MultivariateNormalLinearOperator, self)._prob(x)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\", line 406, in _prob\r\n    prob = math_ops.reduce_prod(prob, self._reduce_event_indices)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1392, in reduce_prod\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1488, in _prod\r\n    keep_dims=keep_dims, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n\r\nInvalidArgumentError (see above for traceback): indices[0] = -1 is not in [0, 3)\r\n\t [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]\r\n```", "comments": ["Also fails on the released version of tensorflow (v1.2.0) built from source.", "Also fails when `gradients()` calculated for loss w.r.t. weights drawn from `MultivariateNormalDiag()` (in my case with the help of `contrib.bayesflow.stochastic_tensor.StochasticTensor`). Using `Normal()` appears to be a (slower) workaround.", "I had a similar problem as @jakedailey1 which is why I distilled this example down from a Mixture Density Network with a likelihood-based loss function.", "This turns out to be an issue with `tf.reduce_prod`, whereby gradients fail upon reduction over negative indices.  I'll get an internal fix started.", "Wow! Just when I thought I was stuck I find there's a solution already on the way. Nice work :D \r\nAt least it looks like the same issue with gradient back propagation, as here on [paste bin](https://pastebin.com/M4suZ68K)\r\n\r\nHow is it coming along?", "It looks like a fix has been put together [here](https://github.com/tensorflow/tensorflow/pull/11019).  I can't try this out right now, but perhaps you can just grab the latest files and it will work.", "I can confirm that ea79ba4 (mentioned above) fixes the issue.  I cherry-picked it to v1.2.1 to verify.  The fix is available on master.", "I upgraded my Tensorflow to v1.2.1. But I am still facing the same error message when I am trying to train a model to learn an appropriate sigma value for the Gaussian filter. Am I doing something wrong? My system is Win10. I installed Tensorflow through Anaonda. Here is my code.\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.distributions as ds\r\nimport numpy as np\r\nimport scipy.ndimage.filters as filters\r\n\r\n\r\n#set parameters-------------------\r\nIMAGE_SIZE = (576, 1024)\r\nKERNEL_SIZE = 3\r\n\r\n#build graph--------------\r\nimage = tf.placeholder(tf.float32, shape=(None,)+IMAGE_SIZE+(1,))\r\nlabel = tf.placeholder(tf.float32, shape=(None,)+IMAGE_SIZE+(1,))\r\nsigma = tf.Variable(tf.ones(1))\r\n\r\nxinds, yinds = np.unravel_index(range(KERNEL_SIZE*KERNEL_SIZE),                                 (KERNEL_SIZE, KERNEL_SIZE))\r\ninds = (np.column_stack((xinds,yinds))-\r\n                    [(KERNEL_SIZE-1)/2, (KERNEL_SIZE-1)/2]).astype(np.float32)\r\ninds = tf.constant(inds)\r\nloc = tf.zeros(2)\r\nscale_diag = tf.multiply(sigma, tf.ones([2,]))\r\n\r\nmvn = ds.MultivariateNormalDiag(\r\n    loc=loc,\r\n    scale_diag=scale_diag)\r\n\r\nkernel = mvn.prob(inds)\r\nkernel = tf.reshape(kernel, (KERNEL_SIZE, KERNEL_SIZE, 1, 1))\r\n\r\n\r\nx = tf.nn.conv2d(image, kernel, strides=[1,1,1,1], padding='SAME')\r\nloss = tf.nn.l2_loss(tf.subtract(x, label))\r\n\r\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n#start training-------------------------\r\nstimulus = np.zeros(IMAGE_SIZE)\r\nstimulus[300, 500] = 1\r\ntest_sigma = (30,30)\r\nfiltered = filters.gaussian_filter(stimulus, test_sigma)\r\nfeed_dict = {image: np.expand_dims(np.expand_dims(stimulus, 0), 3), \r\n                 label: np.expand_dims(np.expand_dims(filtered, 0), 3)}\r\nsess.run(train_op, feed_dict=feed_dict)\r\n```\r\n\r\nHere are the error messages.\r\n```\r\nInvalidArgumentError: indices[0] = -1 is not in [0, 2)\r\n\t [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]\r\n\r\nCaused by op 'gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather', defined at:\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 231, in <module>\r\n    main()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 227, in main\r\n    kernel.start()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\r\n    self._run_callback(self._callbacks.popleft())\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\r\n    ret = callback()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 265, in enter_eventloop\r\n    self.eventloop(self)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\eventloops.py\", line 106, in loop_qt5\r\n    return loop_qt4(kernel)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\eventloops.py\", line 99, in loop_qt4\r\n    _loop_qt(kernel.app)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\eventloops.py\", line 83, in _loop_qt\r\n    app.exec_()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\eventloops.py\", line 39, in process_stream_events\r\n    kernel.do_one_iteration()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 298, in do_one_iteration\r\n    stream.flush(zmq.POLLIN, 1)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 352, in flush\r\n    self._handle_recv()\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-7-de90f1cd6d46>\", line 40, in <module>\r\n    train_op = tf.train.AdamOptimizer().minimize(loss)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 315, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 386, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 346, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 129, in _ProdGrad\r\n    reduced_num = math_ops.reduce_prod(array_ops.gather(input_shape, reduced))\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1179, in gather\r\n    validate_indices=validate_indices, name=name)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\n...which was originally created as op 'MultivariateNormalDiag_3/prob/Prod', defined at:\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 231, in <module>\r\n    main()\r\n[elided 23 identical lines from previous traceback]\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-7-de90f1cd6d46>\", line 33, in <module>\r\n    kernel = mvn.prob(inds)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py\", line 712, in prob\r\n    return self._call_prob(value, name)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py\", line 694, in _call_prob\r\n    return self._prob(value, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\util.py\", line 688, in _fn\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\distributions\\python\\ops\\mvn_linear_operator.py\", line 216, in _prob\r\n    return super(MultivariateNormalLinearOperator, self)._prob(x)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\transformed_distribution.py\", line 406, in _prob\r\n    prob = math_ops.reduce_prod(prob, self._reduce_event_indices)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1392, in reduce_prod\r\n    name=name)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1488, in _prod\r\n    keep_dims=keep_dims, name=name)\r\n  File \"C:\\Users\\pasca\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n\r\nInvalidArgumentError (see above for traceback): indices[0] = -1 is not in [0, 2)\r\n\t [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]\r\n```", "v1.2.1 does not have the fix.  The fix is on master.  You need to cherry-pick the commit I mentioned above (ea79ba41be89d76180305b14d26d5c2f256d4c08)  onto your v1.2.1 branch.", "Oh now I see! Thank you so much @ktarplee !"]}, {"number": 10765, "title": "[Performance] contirb.seq2seq.attention_wrapper slower due to using matmul instead of reduce_sum", "body": "tf version '1.2.0-rc0' contirb.seq2seq.attention_wrapper is great, it make using attention much easier.\r\nHowever I found using attention_wrapper will be much slower then tf version 1.0.\r\nAfter some experiment I found it is due to using matmul instead of reduce_sum.\r\n\r\nfrom attetntion_wrapper.py 731\r\n      \r\n      expanded_alignments = array_ops.expand_dims(alignments, 1)\r\n      attention_mechanism_values = self._attention_mechanism.values\r\n      context = math_ops.matmul(expanded_alignments, attention_mechanism_values)\r\n      context = array_ops.squeeze(context, [1])\r\n\r\nUsing above code for one of my application got 2.2 batch/s, after changing to use reduce_sum(as tf version 1.0 did), the speed is 3.4 batch/s, improve a lot.\r\n\r\n      expanded_alignments = array_ops.expand_dims(alignments, 2)\r\n      attention_mechanism_values = self._attention_mechanism.values\r\n      context = math_ops.reduce_sum(expanded_alignments * attention_mechanism_values, [1])", "comments": ["Nagging Assignee @tfboyd: It has been 433 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing this as prefer to use eager mode seq2seq."]}, {"number": 10764, "title": "There is QuantizedInstanceNorm operation registered, But I could not find InstanceNorm operation anywhere.", "body": "OS: Ubuntu 16.04 64bits\r\nAndroid Version: 7.1 (Nougat)\r\nNDK Version: android-ndk-r12b\r\nHEXAGON SDK: 3.1\r\n\r\nThere is **QuantizedInstanceNorm** operation registered, But I could not find **InstanceNorm** operation anywhere.\r\n\r\nI am not sure why Quantized form is added without its original instance form, Maybe to convert graphs trained using other nets into pb and quantize them. Well this is my assumption.\r\n\r\nCould anyone tell how can I get **instancenorm** operation.\r\n\r\n\r\nthanks", "comments": ["It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "There isn't an InstanceNorm operation, rather it seems that it is implemented with other operations: see https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/layers/python/layers/normalization.py#L42\r\n\r\n"]}, {"number": 10763, "title": "What is the possible op substitute for set of OPerations on CPU to DSP Hexagon", "body": "OS: Ubuntu 16.04 64bits\r\nAndroid Version: 7.1 (Nougat)\r\nNDK Version: android-ndk-r12b\r\nHEXAGON SDK: 3.1\r\nnnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib\r\n\r\nI am trying to build a graph to run on hexagon,\r\nit uses few op's which hexagon doesn't support.\r\n\r\nnative : graph_transferer.cc:109 Failed to transfer graph Invalid argument: Mean has not been implemented yet.\r\n\r\nOP's details are as below:-\r\n\r\n {\"Mean\", SupportedOpType::**??**},\r\n {\"RealDiv\", SupportedOpType::**??**},\r\n {\"Pow\", SupportedOpType::**??**},\r\n {\"Conv2DBackpropInput\", SupportedOpType::**??**},\r\n {\"Square\", SupportedOpType::**??**},\r\n {\"SquaredDifference\", SupportedOpType::**??**},\r\n {\"StopGradient\", SupportedOpType::**??**},\r\n {\"Reciprocal\", SupportedOpType::**??**},\r\n\r\nIs there any possible substitute for the operation types Mean, Pow, Conv2DBackpropInput etc.. for hexagon.\r\n\r\nthanks in advance.", "comments": ["Unfortunately the current approach to HVX acceleration requires new op implementations to be written for the DSP before they can be used. Looking at the list of ops, a lot of them seem like they might be related to batch normalization. Are you able to run the `fold_constants` transform using the graph transform tool and see if some of them disappear?", "@petewarden \r\nWith **fold_constants, quantize option,** for tranform_graph,\r\nOn Hexagon, was able to get through <registration of nodes>.\r\nFailed in <Setupgraph> during instantiating the graph.\r\n\r\n```\r\nhexagon/src/newnode.c:177:### append_const_node\r\n hexagon/src/graphops.c:60:CAUSALITY VIOLATION: node ea63a670 (id=0x1005c) referenced output of node ea63d210 (id=0x10052) before instantiated in the graph\r\n hexagon/src/graphops.c:60:CAUSALITY VIOLATION: node ea63a910 (id=0x1005f) referenced output of node ea63d210 (id=0x10052) before instantiated in the graph\r\n hexagon/ops/src/op_prefree.c:71:prefree node id 0 ctor\r\n hexagon/src/newnode.c:177:### append_const_node\r\n```\r\n\r\nLogging in nnlib is not friendly, no node names etc..\r\nI will try to debug it further to get names stuff and try to fix (**Comment if you got any pointers to debug here**).\r\n\r\nAs I couldn't get working on Hexagon, to understand the changes underwent in graph after using **fold_constants,** I ran the graph on CPU,\r\nall ops are getting substituted with moments, as below:(**What it does?**)\r\n\r\n```\r\nnative : stat_summarizer.cc:407 \t              Dequantize\t   51.109\t    0.723\t    0.705\t  0.506%\t 36.654%\t  2457.600\tConv2D_2\r\nnative : stat_summarizer.cc:407 \t                    Mean\t   51.828\t    0.848\t    1.080\t  0.775%\t 37.429%\t     0.128\tmoments_1/Mean\r\nnative : stat_summarizer.cc:407 \t            StopGradient\t   52.920\t    0.014\t    0.015\t  0.010%\t 37.440%\t     0.000\tmoments_1/StopGradient\r\n```\r\n\r\n\r\nI assume, fold_constants can be a safe bet to get graph working on hexagon once after fixing the instantiate graph part.(Comment? if you have anything to say)\r\n\r\n**Can I visualize pre trained graph(pb) by any means if not through tensorboard?**\r\nthat would help me debug.\r\n\r\nthanks,", "@petewarden,\r\nI am implementing few of the ops mentioned above.\r\nstarted with mean, stop gradient and then\r\nconv2dbackpropinput.\r\n\r\n\r\nFor op_mean, collecting information from graph transferrer as below(4 inputs) (1 output):\r\n\r\n      const struct tensor *input = self->input[0];\r\n      const struct tensor *axes = self->input[1];\r\n      const struct tensor *dims = self->input[2];\r\n      const struct tensor *reduction = self->input[3];\r\n      struct tensor *output = self->outputs[0];\r\n      //do mean operation based on axes, dims\r\n\r\n      \r\nI am not sure what does **reduction_indices** does. -> I assume it is reducing the order of matrix from 3 to (3-2)->1\r\n\r\n![screenshot from 2017-07-06 19-58-10](https://user-images.githubusercontent.com/5010954/27916202-fdb39268-6285-11e7-8c79-d15ec5d46a63.png)\r\n\r\nnumber of inputs vary after graph transformation.\r\nso is there a guide to know number of inputs as well outputs for operations like -> Mean, Stop gradient, etc.\r\n\r\nThanks,\r\n", "A good place to look for op definitions is here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/ops\r\n\r\nIt's where all the different ops have their inputs, outputs, and attribute signatures defined. For example, here's the signature for \"Mean\":\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc#L1154\r\n```\r\nREGISTER_OP(\"Mean\")\r\n  .Input(\"input: T\")\r\n\u00a0 .Input(\"reduction_indices: Tidx\")\r\n\u00a0 .Output(\"output: T\")\r\n\u00a0 .Attr(\"keep_dims: bool = false\")\r\n\u00a0 .Attr(\"T: numbertype\")\r\n\u00a0 .Attr(\"Tidx: {int32, int64} = DT_INT32\")\r\n```\r\nThis is saying that the Mean op takes two inputs, the first of which is any number type, and the second must be an int32 or int64. It also has an option to keep the dimensions. The doc string below the definition has more information about what it does. ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "We're now focused on hardware acceleration through the NN API on Android, and don't expect to continue supporting direct access to HVX from TensorFlow, so closing this bug as no longer relevant."]}, {"number": 10762, "title": "Fix a bug in topk_op.cc", "body": "307df7080a8fe0538e05754170695b9925e2cea2 is causing failures in\r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/1110/console : \r\n```\r\n03:15:56 //py_test_dir/tensorflow/python/kernel_tests:metrics_test                FAILED in 3 out of 3 in 54.3s\r\n03:15:56 //py_test_dir/tensorflow/python/kernel_tests:topk_op_test                FAILED in 3.6s\r\n```\r\nThe test output doesn't show useful information:\r\n```\r\n03:13:23 FAIL: //py_test_dir/tensorflow/python/kernel_tests:metrics_test (shard 3 of 3) (see C:/tmp/_bazel_system/424zmya1/execroot/tf-master-win-bzl/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/kernel_tests/metrics_test/shard_3_of_3/test.log)\r\n03:13:23 INFO: From Testing //py_test_dir/tensorflow/python/kernel_tests:metrics_test (shard 3 of 3):\r\n03:13:23 ==================== Test output for //py_test_dir/tensorflow/python/kernel_tests:metrics_test (shard 3 of 3):\r\n03:13:23 .....C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\r\n03:13:23   if d.decorator_argspec is not None), _inspect.getargspec(target))\r\n03:13:23 ....................\\\\?\\c:\\tmp\\Bazel.runfiles_tbl0oj21\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\kernel_tests\\metrics_test.py:163: DeprecationWarning: Please use assertEqual instead.\r\n03:13:23   set(expected), set(v.name for v in variables.local_variables()))\r\n03:13:23 ..................================================================================================\r\n```\r\nBut when running the test locally I saw:\r\n![capture_topk_failure](https://user-images.githubusercontent.com/4171702/27226378-044bad8c-529f-11e7-9241-48c6ac705040.PNG)\r\n\r\nThis change fixed them.\r\n\r\n@gunan ", "comments": ["Trigger test: http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/26/console", "LGTM\n\nOn Jun 16, 2017 5:28 AM, \"Yun Peng\" <notifications@github.com> wrote:\n\n> http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/26/console\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10762#issuecomment-309013656>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim0ecewZtPZ9Yj5aLM6z5KZboMWFpks5sEnTdgaJpZM4N8ZIO>\n> .\n>\n"]}, {"number": 10761, "title": "Feature Request : Tensor Roll", "body": "Could you add an equivalent to [Numpy roll](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.roll.html) on Tensor in tensorflow in order to allow the user to roll a Tensor along one of the axis of the tensor ?\r\n", "comments": ["We definitely would welcome pr's to implement this functionality. Thanks!", "It should be easy to implement it using slice and concat. Does it need to be implemented in a C++ kernel?", "Hello, I am new to open source and would like to implement this feature. How do I determine which file to implement this feature in?", "Usually a feature like this will involve several files. The best thing to do is to look at a similar op (say, `transpose`, maybe), and find all the files that have to be touched for that op.\r\n\r\nThere will be at least some files in core/ops, core/kernels, and python/kernel_tests, plus the BUILD files.\r\n\r\nIf the op is a pure python op, you may get away with only changing/adding a file in python/ops. This is probably not a python op, unless I'm missing a simple way to construct it from existing ops.", "I implemented that with existing TF operations, see [here](https://github.com/rwth-i6/returnn/blob/master/TFUtil.py) `circular_pad`.", "I'd like try to implement this op. Should this go directly into core or somewhere in the contrib directory?", "It's fine to put it in core I think, though not sure what module it should be in (`tf.roll` or `tf.<something>.roll`). Deferring to @aselle for placement."]}, {"number": 10760, "title": "[OpenCL] Fixes device name comparison stage_op_test ", "body": "Changes the fixed '/device:GPU:0' expected device name string to the name returned by 'test/gpu_device_name()', as the device name could be '/device:SYCL:0' or '/device:GPU:0'.\r\n\r\nResubmission of #10682 ", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@jwlawson any luck with the test failure?", "Jenkins, test this please."]}, {"number": 10759, "title": "GPU->CPU Memcpy failed Error or InternalError c2c fft failed Error when using FFT2D ", "body": "### The problem\r\nI wrote a python script that used FFT2D from tensorflow you can find the Python script attached : TestFFT2D.py using GPU.\r\n\r\nIn this script, I first create a convolution apply to a tensor and than compute a loss between a reference input tensor and a variable one with ftt2d and ifft2d operations.\r\n\r\nWhen I launch my script, I get a GPU->CPU Memcpy failed Error or an InternalError c2c fft failed Error. I don't know why the error change when I run again my script. \r\nI test my code on two differents machine with Ubuntu 16.04 one with a GeForce GTX 680 GPU and one with a GeForce GTX 1080. In both case, I can randomly get both of the error messages.\r\n[Abandon.txt](https://github.com/tensorflow/tensorflow/files/1080533/Abandon.txt)\r\n[InternalError.txt](https://github.com/tensorflow/tensorflow/files/1080532/InternalError.txt)\r\nSometimes, my machine just crashes and I need to reboot it.\r\n\r\n### Source code / logs\r\nYou can find the terminal messages errors attached.\r\nThis is the TestFFT2D.py code : [TestFFT2D.py ](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D.py)\r\n`\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef get_loss(sess,net,img_ref,layer):\r\n    \r\n    total_loss  = 0.\r\n    \r\n    sess.run(net['input'].assign(img_ref))  \r\n    x = net[layer]\r\n    a = sess.run(net[layer])\r\n    x = tf.transpose(x, [0,3,1,2])\r\n    a = tf.transpose(a, [0,3,1,2])\r\n    _,N,_,_ = a.shape\r\n    F_x = tf.fft2d(tf.complex(x,0.))\r\n    F_x_conj = tf.conj(F_x)\r\n    F_a = tf.fft2d(tf.complex(a,0.))\r\n    F_a_conj = tf.conj(F_a)\r\n    \r\n    for i in range(N):\r\n        inter_corr_x = tf.multiply(F_x,F_x_conj)\r\n        inter_corr_a = tf.multiply(F_a,F_a_conj)\r\n        \r\n        ifft2_corr_x = tf.ifft2d(inter_corr_x)\r\n        ifft2_corr_a = tf.ifft2d(inter_corr_a)\r\n        \r\n        R_x = tf.real(ifft2_corr_x)\r\n        R_a = tf.real(ifft2_corr_a)\r\n        \r\n        style_loss = tf.nn.l2_loss(tf.subtract(R_x,R_a))  \r\n        total_loss += style_loss\r\n        \r\n        # Shift the tensor from on 1 unit on the dimension 1\r\n        F_x = tf.concat([tf.expand_dims(F_x[:,-1,:,:],0), F_x[:,:-1,:,:]], axis=1)\r\n        F_a = tf.concat([tf.expand_dims(F_a[:,-1,:,:],0), F_a[:,:-1,:,:]], axis=1)\r\n            \r\n    return(total_loss)\r\n\r\ndef main(args):\r\n    \r\n    # Definition of the first operations :\r\n    height, width, numberChannels = 400,300,3\r\n    net = {}\r\n    current = tf.Variable(np.zeros((1, height, width, numberChannels), dtype=np.float32))\r\n    net['input'] = current\r\n    kernel = tf.constant(np.random.uniform(low=-1,high=1,size=(400,300,3,64)),dtype=np.float32)\r\n    conv = tf.nn.conv2d(current, kernel, strides=(1, 1, 1, 1),padding='SAME',name='conv')\r\n    bias = tf.constant(np.random.uniform(low=-1,high=1,size=(64)),dtype=np.float32)\r\n    conv_add_bias = tf.nn.bias_add(conv, bias)\r\n    net['conv1_1'] = conv_add_bias\r\n    \r\n    img_ref = np.random.uniform(low=-128,high=128,size=(1, height, width, numberChannels))\r\n    init_img = np.random.uniform(low=-128,high=128,size=(1, height, width, numberChannels))\r\n    \r\n    sess = tf.Session()\r\n    \r\n    sess.run(net['input'].assign(img_ref))  \r\n    # Definition of the loss \r\n    loss = get_loss(sess,net,img_ref,'conv1_1')\r\n        \r\n    # Preparation of the assignation operation\r\n    placeholder = tf.placeholder(tf.float32, shape=init_img.shape)\r\n    assign_op = net['input'].assign(placeholder)\r\n        \r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(assign_op, {placeholder: init_img})\r\n    print(\"Before loss evaluation\")\r\n    loss_evaluation = sess.run(loss)\r\n    print(\"loss_evaluation\",loss_evaluation)\r\n    \r\n    return(0)\r\n\r\nif __name__ == '__main__':\r\n    import sys\r\n    sys.exit(main(sys.argv))\r\n`\r\n### System information\r\n- **Have I written custom code **: TestFFT2D.py\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: Source\r\n- **TensorFlow version**: v1.0.0-65-g4763edf-dirty 1.0.1\r\n- **CUDA/cuDNN version**:\r\nCuda compilation tools, release 7.5, V7.5.17 and  cuDNN  5 with the GeForce GTX 680\r\n Cuda compilation tools, release 8.0, V8.0.61and cuDNN 5 with the GeForce GTX 1080\r\n- **GPU model and memory**: Tested on GeForce GTX 680 with 2Go and on GeForce GTX 1080 with 12Go\r\n- ** Python version**: Python 3.6.1 |Anaconda 4.4.0 (64-bit)|\r\n- **Exact command to reproduce**: python TestFFT2D.py : copy-paste the code above and run it with python 3\r\n\r\n\r\n", "comments": ["It looks like you are compiling off the 1.0 branch.  Could you try reproducing this with master (or at least 1.2)?", "I have updated my Tensorflow version 1.0.1 to the version 1.2 and I can't reproduce those error with the former script : [TestFFT2D.py](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D.py)\r\n\r\nBut when I increase the size of the tensor I used (from 400 * 300 to 800 * 600), I got an Internal Error message again : \r\n[InternalError2.txt](https://github.com/tensorflow/tensorflow/files/1084781/InternalError2.txt)\r\nYou can test with this script : [TestFFT2D_1.py](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D_1.py) (I also reduce the size of the kernel filters).\r\n\r\nI can get the same type of error when I increase the number of filters I used.\r\n\r\nDo you advice me to present my problem on StackOverflow instead of Github ?\r\n\r\n\r\n\r\n", "I think that may be an out-of-memory error, as seen here: #8710; same\nreturn code.\n\nOn Mon, Jun 19, 2017 at 5:05 AM, Gonthier Nicolas <notifications@github.com>\nwrote:\n\n> I have updated my Tensorflow version 1.0.1 to the version 1.2 and I can't\n> reproduce those error with the former script : TestFFT2D.py\n> <https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D.py>\n>\n> But when I increase the size of the tensor I used (from 400 * 300 to 800 *\n> 600), I got an Internal Error message again :\n> InternalError2.txt\n> <https://github.com/tensorflow/tensorflow/files/1084781/InternalError2.txt>\n> You can test with this script : TestFFT2D_1.py\n> <https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D_1.py>\n> (I also reduce the size of the kernel filters).\n>\n> I can get the same type of error when I increase the number of filters I\n> used.\n>\n> Do you advice me to present my problem on StackOverflow instead of Github ?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10759#issuecomment-309420130>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AA1YDsLdIEIspSIkb-soRG7HC8PBjjGrks5sFmP5gaJpZM4N8Upp>\n> .\n>\n", "Yup, as @wolffg points out, this looks like the same out-of-memory error as #8710.  Closing this out, since it doesn't look like this is a bug in the core framework."]}, {"number": 10758, "title": "[OpenCL] Fixes grpc test failure for SYCL devices", "body": "The test constructs a graph containing an IdentityOp on strings, which doesn't exist on CUDA and SYCL devices. The test expects to fail for CUDA devices, so add the same expectation for SYCL devices.\r\n\r\nResubmission of #10698 ", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 10757, "title": " SparseMatmulOpTest.BroadcastPacketTest is failing on ppc64le", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n     Ubuntu 16.04 (ppc64le)\r\n- **TensorFlow installed from (source or binary)**:\r\n      Installed from source (v1.0.1)\r\n- **TensorFlow version (use command below)**:\r\n     ('v1.0.1-0-ge895d5c-dirty', '1.0.1')\r\n- **Bazel version (if compiling from source)**:\r\n     0.4.4-2017-05-26 (@80a07b5)\r\n- **CUDA/cuDNN version**:\r\n      CUDA = 8.0 and cuDNN = 5.1\r\n- **GPU model and memory**:\r\n      GPU 0: Tesla P100-SXM2-16GB\r\n      GPU 1: Tesla P100-SXM2-16GB\r\n- **Exact command to reproduce**:\r\n      bazel test --config=opt --config=cuda //tensorflow/core/kernels:sparse_matmul_op_test_gpu\r\n\r\n### Describe the problem\r\nThis is regarding failure of test case `SparseMatmulOpTest.BroadcastPacketTest` in `tensorflow/core/kernels/sparse_matmul_op_test.cc` file.While executing this test case on ppc64le, it was observed that following line returns unexpected results:\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op_test.cc#L255\r\n```\r\ninternal::pstoreu(data2, internal::pbroadcast_first<Packet>(\r\n                              internal::ploadu<Packet>(data1)));\r\n\r\n```\r\nHere we are getting expected result on `x86` for data2 array = `[0.170094 0.170094 0.170094 0.170094]`, however on `ppc64le` getting incorrect result i.e. `[  0.170094    0.14922 -0.0823886   0.026985]`\r\n\r\nI have done some investigation around this - using `print/cout` statement I tried to understand the code flow on `ppc64le `as well as on `X86 `platform.\r\nHere I found that for `internal::pbroadcast_first<Packet>` line ,on both the platform executed different functions, see below-\r\nOn x86 executed `EIGEN_STRONG_INLINE Packet4f pbroadcast_first<Packet4f>(const Packet4f& a) ` function(https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op.h#L197)\r\nAnd on ppc64le executed some different function i.e. `EIGEN_DEVICE_FUNC inline Packet pbroadcast_first(const Packet& a)` (https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op.h#L92)\r\n\r\nThat is why we are getting incorrect result on ppc64le for data2 array and test fails.\r\nI have done some debugging on this but couldn't find the reason - why control is going to different functions on both the platform for `internal::pbroadcast_first<Packet>` ?\r\n\r\nIf could get any suggestions/pointers to why this is happening that would be great! \r\n(I am new to tensorflow code but interested/would-like-to debug & help)\r\n\r\nThanks!\r\n\r\n### Source code / logs\r\n```\r\n$  bazel test --config=opt --config=cuda //tensorflow/core/kernels:sparse_matmul_op_test_gpu\r\n\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nRunning main() from test_main.cc\r\n[==========] Running 4 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 4 tests from SparseMatmulOpTest\r\n[ RUN      ] SparseMatmulOpTest.BroadcastPacketTest\r\n[0.170094 0.170094 0.170094 0.170094] != [  0.170094    0.14922 -0.0823886   0.026985], differences: [         0 -0.0208738  -0.252482  -0.143109]\r\ntensorflow/core/kernels/sparse_matmul_op_test.cc:257: Failure\r\nValue of: areApprox(ref, data2, PacketSize)\r\n  Actual: false\r\nExpected: true\r\n[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest (0 ms)\r\n[ RUN      ] SparseMatmulOpTest.InterleavePacketTest\r\n[       OK ] SparseMatmulOpTest.InterleavePacketTest (0 ms)\r\n[ RUN      ] SparseMatmulOpTest.Bfloat16ExpandTest\r\n[       OK ] SparseMatmulOpTest.Bfloat16ExpandTest (0 ms)\r\n[ RUN      ] SparseMatmulOpTest.Bfloat16LoadTest\r\n[       OK ] SparseMatmulOpTest.Bfloat16LoadTest (0 ms)\r\n[----------] 4 tests from SparseMatmulOpTest (0 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 4 tests from 1 test case ran. (0 ms total)\r\n[  PASSED  ] 3 tests.\r\n[  FAILED  ] 1 test, listed below:\r\n[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest\r\n\r\n 1 FAILED TEST\r\n\r\n```", "comments": ["It seems like there is a problem in Eigen's broadcasting code. Unfortunately we have no way to test or run on ppc64le, so we can't officially support it. @gunan", "I will mark this as a duplicate of #8945 and close this issue.\r\nAs @aselle stated, we do not have access to ppc64le machines, so we will not be able to officially support it.\r\nBut we will accept any contributions to fix the bugs that cause the test failures.", "Fixed in PR https://github.com/tensorflow/tensorflow/pull/12138"]}, {"number": 10756, "title": "Embedding visualizer of tensorboard is a blank page", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master c007ee2c1f8701effb410f632e9d8c4cd120f9c0\r\n- **Bazel version (if compiling from source)**: 0.5.0\r\n- **CUDA/cuDNN version**: 8.0.44/7.0\r\n- **GPU model and memory**: Titan X (Pascal)\r\n- **Exact command to reproduce**: tensorboard --logdir <path to model>\r\n\r\n### Describe the problem\r\n\r\nSimilarily to [this stackoverflow question](https://stackoverflow.com/questions/44201246/tensorboard-embedding-projector-blank) I have completely blank page without any controls when I'm trying to use the tensorboard embedding visualizer from the latest master. There is nothing in logs (at least on default log level).\r\n\r\nTensorboard from 1.0, 1.1, 1.2 binaries is working.", "comments": ["Hi @eiennohito!\r\n\r\nWe just moved TensorBoard to its own repo, over [here](https://github.com/tensorflow/tensorboard). It's also now possible to pip install latest TensorBoard separately from TensorFlow.\r\n\r\nSo, please `pip install tensorflow-tensorboard` and see if the embedding visualizer is still broken. If it is, please re-open an issue over at our new repo and we'll take it from there.", "Hi @dandelionmane , I'm the one who asked the Stack Overflow question mentioned by @eiennohito . I tried `pip install tensorflow-tensorboard` and it worked! It can visualize the embeddings, but it takes too much time parsing the metadata. I'll try it again, and if the error persists, I'll open an issue over at the tensorboard repo.", "Thanks @dandelionmane for answering.\r\n\r\n@eiennohito just for curiosity, since you said the parsing of the metadata takes a long time, how big is your embedding (number of points and dimensionality)?", "@dsmilkov Well, I don't know about eiennohito, but I was the one experiencing the long metadata parsing time. The metadata consists of just 50 embeddings with dimensionality 784.", "That's a small metadata. Can you share the files/logdir contents by any chance so we can reproduce the problem? Or a synthetic data that reproduces the problem. Thanks!", "@dsmilkov Here they are. It corresponds to 50 vectors from the MNIST dataset.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n[logdir.tar.gz](https://github.com/tensorflow/tensorflow/files/1086901/logdir.tar.gz)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "Hello, I've encountered this issue. I tried pip install tensorflow-tensorboard but it didn't work. This is screenshot of the files in the logdir. I'm not sure if its an issue or i'm doing something wrong but the same code worked (showed embedding no metadata) then nothing.\r\n![image](https://user-images.githubusercontent.com/31519736/29943079-6af1b6c0-8e6e-11e7-8932-6b1fc72f28ed.png)\r\n\r\nHere is the text from projector_config.pbtxt:\r\n(I tried editing the slashes but no luck)\r\nmodel_checkpoint_path: \"C:\\\\tmp\\\\Tensorboard\\\\CNN\\\\ooo\\\\model.ckpt-4\"\r\nembeddings {\r\n  tensor_name: \"cifar_embedding\"\r\n  metadata_path: \"C:\\\\tmp\\\\Tensorboard\\\\CNN\\\\ooo\\\\metadata.tsv\"\r\n  sprite {\r\n    image_path: \"C:\\\\tmp\\\\Tensorboard\\\\CNN\\\\ooo\\\\cifar_images.png\"\r\n    single_image_dim: 32\r\n    single_image_dim: 32\r\n  }\r\n}\r\nThanks in advance.\r\n\r\n"]}, {"number": 10755, "title": "Weird behavior of tf.train.Saver", "body": "### System information\r\n- Linux Ubuntu 14.04\r\n- TensorFlow installed from binary:\r\n- TensorFlow version v1.0.0-rc2:\r\n- CUDA: 8.0, CuDNN: 5.1\r\n- Tesla K80, 12GB\r\n\r\n### Describe the problem\r\nI have a problem with the tf.train.Saver, specifically with the 'max_to_keep' argument. If I create a Saver with 'max_to_keep' set to let's say 3 and use the saver.save function to save my model in the current directory it keeps all files and doesn't delete the old ones after 3 or more are created. If I set the path where to save the model to a different location it works just fine.\r\n\r\nSee also my [stackoverflow question](https://stackoverflow.com/questions/44458947/tensorflow-keeps-all-files-how-to-prevent-that)\r\n\r\n### Source code / logs\r\nCreates for the numbers 1 to 10 each 3 files:\r\n\r\n- testfile-1.data-00000-of-00001\r\n- testfile-1.index\r\n- testfile-1.meta\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(name='a', initial_value=0)\r\naddops = a+1\r\n\r\nsaver = tf.train.Saver(max_to_keep=3)\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\nfor i in range(10):\r\n    sess.run(addops)\r\n    save_path = saver.save(sess, 'testfile', global_step=i+1)\r\n\r\nsess.close()\r\n```\r\n\r\nThis code works as expected and deletes all the old files and I only end up with the numbers 8 to 10:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(name='a', initial_value=0)\r\naddops = a+1\r\n\r\nsaver = tf.train.Saver(max_to_keep=3)\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\nfor i in range(10):\r\n    sess.run(addops)\r\n    save_path = saver.save(sess, 'test/testfile', global_step=i+1)\r\n\r\nsess.close()\r\n```", "comments": ["Could you take a look @concretevitamin , please?", "Seems relevant to I/O layer.  Adding @rohan100jain.", "There is another bug if path to save contains double slash e.g. 'logdir//model'. In this case old checkpoints are not removed as well.", "Quite sure that https://github.com/tensorflow/tensorflow/commit/3e6c638727c3274908a7c9c6bbf4474c014511fe would have fixed the original issue... If you update your tf version to the latest one, it works.. \r\n\r\nThe // case is a little more complex since in some file systems paths have //'s in them... so I'd recommend just not having them in the path :)", "@rohan100jain python 'open' works ok with double slash, for me it's expected to have same behaviour with default bash, python semantics of path.", "I have experienced the same problem when using brackets in the name of the saving folder.", "Sorry for not following up on this but the original issue has been resolved. So I guess this can be closed. The best way to use the function is to hand over `os.path.abspath(filename)`.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly."]}, {"number": 10754, "title": "The current makefile is incomplete", "body": "Can someone provide a makefile that is equivalent to //tensorflow:libtensorflow_cc.so? This current makefile is missing many C++ API's. Is there a way to find all the files needed to build //tensorflow:libtensorflow_cc.so (recursively)?", "comments": ["Is there anyway but manually adding things, @petewarden? I know it uses many globs to avoid trivial new files but new directories I imagine are an issue.", "The tricky part with libtensorflow_cc is that it needs to compile a host-side tool first to generate the .cc and .h interfaces from the op definitions. That extra complexity means that neither the Bazel Android build process nor the Makefile build the lib. For the Makefile we try to mirror its globs and file list from the equivalents in the Bazel build process for Android, but since the CC interface isn't there, we can't do that in this case.", "I have tried the following steps to add the C and C++ APIs:\r\n1. Add all .cc files in the /c and /cc directories to the Makefile.\r\n2. Add all .pb.cc .pb_text.cc generated by Bazel to the Makefile.\r\n3. Include the dependencies (gtest, .pb.h and pb_text.h).\r\n4. Use the Makefile to create libtensoflow-core.a and .so.\r\n\r\nThe compilation terminates without error and the .a and the .so files are produced. However, when I try to use them to compile programs that use Tensorflow C or C++ APIs, I get undefined reference errors.", "From your description, it sounds like they're not being linked in, so you should look at what the command line that links all the .o files in the makefile logs looks like, and ensure it has the ones generated from the .cc's you want.\r\n\r\nAs a note, this sort of manual compilation will be a bit fragile, since you'll have to do the same steps #1 and #2 whenever ops are added or changed."]}, {"number": 10753, "title": "Fix typos", "body": "This PR revises the sample usages for lookup, and fixes some typos: `contants`, `Opeartor`, `squeee`, `nulll`, `Contant`, and `Tranpose`.", "comments": ["Can one of the admins verify this patch?", "Thank you@taehoonlee!"]}, {"number": 10752, "title": "BeamSearchDecoder: fix beam not full, and add test module", "body": "fix issue mentioned in https://github.com/tensorflow/tensorflow/issues/10641\r\nand add a test module for it", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I have signed the CLA", "CLAs look good, thanks!\n\n<!-- ok -->", "@ebrevdo could you take a look? Thanks!", "Jenkins, test this please.", "Strange, build was aborted.\r\n\r\nJenkins, test this please.", "Excuse me, but why would you need to rebuild? I only changed the python code.", "We run checks for compliance with style guide, tests, etc. In that case, the following failed.\r\n\r\n```\r\n\r\nFAIL: Found 6 non-whitelited pylint errors:\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:240: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:241: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:246: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:248: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:251: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/contrib/seq2seq/python/kernel_tests/beam_search_decoder_test.py:252: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n```", "could you please tell me how to check style? I will check it and make it right.", "I have corrected the style. now what do I do? I don't need to pull another request, do I?", "Jenkins, test this please.\n\nYou should be fine\n\nOn Jun 26, 2017 10:15 PM, \"JerrikEph\" <notifications@github.com> wrote:\n\n> I have corrected the style. now what do I do? I don't need to pull another\n> request, do I?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10752#issuecomment-311255050>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbRwnCvI4JLvP09QFLt-b6GTtqppVks5sIJAEgaJpZM4N78L3>\n> .\n>\n", "OK, tests pass, it's ready for @ebrevdo  to review.", "@adarob can you and cinjon do the rest of the review for correctness?  I'll be OOO.", "@ebrevdo  sure, i can look at it tomorrow.", "I have changed the code as requested\r\n", "Jenkins, test this please.", "I have no idea what is wrong.", "@tensorflow-jenkins test this please\r\n@ebrevdo, @adarob did you finish the review?", "@rmlarsen, @cinjon said he wanted to review it. I will ping him.", "any update?", "@adarob any luck?", "@adarob ping", "any update?", "sorry for losing track of this PR.  can you rebase on master?", "@JerrikEph btw does tf nightly handle this case correctly now?", "Akward, I don't know what tf nightly is. :(", "The tf nightly is the automatic build that is pushed nightly. They can be installed like [this](https://stackoverflow.com/questions/42950769/installing-tensorflow-windows-nightly-build-using-pip). Probably best to do that in a docker instance.", "@JerrikEph could you pull rebase and push again?", "@drpngx I have rebased my change on upstream tensorflow. Is it because I merged so it didn't pass? It's my first time contribute to tensorflow. Please tell me where I did wrong, why is it taking so long?\r\n", "Can anybody take look? : )", "@oahziur do you have time to review today?", "@oahziur you are right, thanks for pointing that out. I changed `self._finished` in `__init__`, since it's much easier\r\n\r\n---\r\nI replied on this earlier, bu got a pending message, don't know why.", "Seems like ` next_prediction_len = array_ops.where(next_beam_probs > -np.Inf,` is redundant. I will try remove it.", "Jenkins, test this please.\r\n\r\n@ebrevdo last call before we merge.", "LGTM!\n\nOn Sat, Jan 20, 2018, 11:00 AM drpngx <notifications@github.com> wrote:\n\n> Jenkins, test this please.\n>\n> @ebrevdo <https://github.com/ebrevdo> last call before we merge.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10752#issuecomment-359194049>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimw9qElr--5w-lJ7AGGyyeBn_hPeKks5tMjfhgaJpZM4N78L3>\n> .\n>\n"]}, {"number": 10751, "title": "Merging r1.2 back into master.", "body": "A bit confused with some of the resolutions on non_max_suppression_op.cc", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Something went wrong with the merge, retrying."]}, {"number": 10750, "title": "Fix sanity status reporting.", "body": "", "comments": []}, {"number": 10749, "title": "Numpy.fft.fft2() gives different result than tf.fft2d()", "body": "as mentioned in the issue #6401, the tf.fft2d() gives different result compared to np.fft.fft2(). Is there a reason for this ?\r\n\r\nNote : numpy gives proper fourier transform after np.fft.fftshift(), and I have taken care of that in my code.\r\nThe differences are not visible here, but the mean squared error is significant.\r\n\r\n![image1](https://user-images.githubusercontent.com/18488880/27207200-84637a88-5202-11e7-9d49-d22cf9a8057d.png)![image2](https://user-images.githubusercontent.com/18488880/27207198-8462f2b6-5202-11e7-88c2-7114b36c696a.png)    ![image3](https://user-images.githubusercontent.com/18488880/27207199-8462fe50-5202-11e7-8d7b-bca01bba063b.png)   ![image4](https://user-images.githubusercontent.com/18488880/27207631-f2a41284-5205-11e7-91a6-336d75755787.png)\r\n\r\nSecond image is the fft using tensorflow, and third one is using numpy. You can see the difference in the corners. The fourth image is the difference between the two images times 10.\r\n\r\n (tf has some features while numpy does not)\r\n\r\nI am working on an application which uses fft in backpropagation and thus it is of absolute importance that the fft in numpy are same as fft by tf.\r\n\r\nMy question is - Why is there a difference and how can I get the same fft as numpy ?\r\n\r\n\r\n", "comments": ["I am not sure if this is related to this issue #10735 ", "Can you give any indication about the relative error between the two versions? How much did you magnify the difference image?", "@aselle Hey, sorry for late response. I magnified the difference by a factor of 10.\r\n\r\nI realized that numpy uses float64 whereas tf uses float32. I could not find a way to use float64 in tf (creates a complex128, which is not supported by tf.fft2d). Could this be a possible problem ?\r\n\r\nThe difference kind of seems huge to consider floating point accuracy as the reason. ", "We use cuFFT to compute fft's, so it is a property of the cufft. You could look at its documentation to see if it has any insight (or google for cufft vs fftw). Also, you could see whether numpy.fft when run with floats matches better.", "This is still an issue. I am not sure how much it will matter in the long run if we are training a network around it anyway..., but it is quite shocking that the error is so high. This also makes debugging hard, because TF's FFT is undoubtedly not doing what we think it should be. Perhaps cuFFT's algorithm is not numerically stable? The error is there even for 1D, but it is much much smaller. This makes me think that the 2D implementation is not optimal, with a lot of fill in or non-optimal number of operations. If someone can point me to the code, maybe we can debug / suggest a fix without changing too much.\r\n\r\nSome python code to verify error using complex64 for both numpy and tf (i.e. based on float32):\r\n```\r\n## DEFINE FFTs\r\nfft1D_np = np.fft.fft\r\nfft1D_tf = tf.fft\r\nifft1D_np = np.fft.ifft\r\nifft1D_tf = tf.ifft\r\nfft2D_np = np.fft.fft2\r\nfft2D_tf = tf.fft2d\r\nifft2D_np = np.fft.ifft2\r\nifft2D_tf = tf.ifft2d\r\n```\r\n ```\r\n   ## TEST 2D FFT\r\n    np.random.seed(13)\r\n    M = np.random.random([1,2,2]).astype(np.complex64)\r\n    M_tf = tf.placeholder(dtype=M.dtype, shape=[None,*M.shape[1:]], name='M_tf')\r\n    eval_dict = {M_tf: M}\r\n    sess, gsaver = nn_utils.init_network()\r\n    Mhat = fft2D_np(M) \r\n    Mhat_tf = fft2D_tf(M_tf)\r\n    Mhat_tfeval = Mhat_tf.eval(feed_dict=eval_dict)\r\n    e = Mhat - Mhat_tfeval\r\n    err = np.linalg.norm(e.reshape([-1,1]))\r\n    assert( np.isclose(err, 0.0) )\r\n```\r\n\r\nDoing some prints in my session:\r\n```\r\n>>> M\r\narray([[[ 0.77770239+0.j,  0.23754121+0.j],\r\n        [ 0.82427853+0.j,  0.96574920+0.j]]], dtype=complex64)\r\n>>> Mhat\r\narray([[[ 2.80527139+0.j,  0.39869052+0.j],\r\n        [-0.77478409+0.j,  0.68163186+0.j]]], dtype=complex64)\r\n>>> Mhat_tfeval\r\narray([[[ 2.80527139+0.j,  0.39869046+0.j],\r\n        [-0.77478415+0.j,  0.68163186+0.j]]], dtype=complex64)\r\n>>> e\r\narray([[[  0.00000000e+00+0.j,   5.96046448e-08+0.j],\r\n        [  5.96046448e-08+0.j,   0.00000000e+00+0.j]]], dtype=complex64)\r\n>>> err\r\n8.4293696e-08\r\n>>> np.isclose(err, 0.0)\r\nFalse\r\n```", "@sirgogo, can you please post the source to `fft2D_np` and `fft2D_tf` in your example?\r\n\r\nAre your ops running on GPU or CPU? \r\n(have you verified that with `tf.ConfigProto(log_device_placement=True)`?)\r\n\r\nFWIW, NumPy is the oracle used for all of [the FFT unit tests](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/fft_ops_test.py).  The tolerance on those checks is `1e-4` at the moment, which is pretty high, but it's because we're using a one-size-fits all bound against Eigen's TensorFFT (CPU), and cuFFT (GPU). Please also note that the FFT unit tests include gradient tests, that verify the numerical gradient matches the symbolic gradient.\r\n\r\nDue to differences in the floating point hardware across your CPU and GPU, the results between NumPy and cuFFT will differ by some amount for an identical sequence of floating point operations. Additionally, NumPy uses fftpack for its FFTs -- so whether your ops are running on CPU or GPU, it's a different FFT implementation from TensorFlow's. That's not to say there isn't a bug in TensorFlow's invocation of these FFT implementations or the implementations themselves!\r\n\r\nHere are code pointers:\r\n* [Eigen TensorFFT](https://bitbucket.org/eigen/eigen/src/699b6595fc471456896fb27193c8ca51389b7850/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?at=default&fileviewer=file-view-default)\r\n* [TensorFlow FFT kernels](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fft_ops.cc). Used to invoke either Eigen TensorFFT or cuFFT.\r\n* [cuFFT documentation](http://docs.nvidia.com/cuda/cufft/index.html)\r\n* [StreamExecutor invocation of cuFFT](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_fft.cc)\r\n* [TensorFlow FFT gradient definitions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/spectral_grad.py)\r\n\r\nWhat is your expectation here?  e.g. would you be happy if `np.isclose` returned `True` in your example? That would imply you need something like `rtol=1e-5`, `atol=1e-8` ? ", "@rryan, thank you for the info and links! I will take a look shortly. Sorry for the  delay, I was out of town, server went down, etc etc. \r\n\r\nYou can run the example with the following simple definitions: I have updated that post with this\r\n```\r\nfft1D_np = np.fft.fft\r\nfft1D_tf = tf.fft\r\nifft1D_np = np.fft.ifft\r\nifft1D_tf = tf.ifft\r\nfft2D_np = np.fft.fft2\r\nfft2D_tf = tf.fft2d\r\nifft2D_np = np.fft.ifft2\r\nifft2D_tf = tf.ifft2d\r\n```\r\nI am running with tensorflow-GPU. This is the only way I was able to get any of the tf.fft-like functions to work. It complains if you are using the CPU-only version (at least for 2D). Is this sufficient to assume the ops are running on the GPU? I can try the `log_device_placement` setting.\r\n\r\nYes, I would expect that the maximum relative error needs to be lower. That would probably make me / most folks happy. Thanks for your insight into this. Just to clarify, you are saying this is an issue with Eigen's TensorFFT / cuFFT, and not something that would be fixed by compiling from source?", "Hi,\r\nusing tensorflow to do some signal processing and the fft problem has appeared. I did some tests and hope they are helpful. I also created a repository with the example signal where the fft really goes wrong using the cpu, error after fft is `>1e+14`. With a gpu it looks good.\r\n\r\nCode:\r\n(https://github.com/rassibassi/fftTensorflow)\r\n```python\r\nimport tensorflow as tf\r\nimport scipy.io\r\nimport numpy as np\r\n\r\nprint('tf:',tf.__version__)\r\nprint('scipy:',scipy.__version__)\r\nprint('np:',np.__version__)\r\n\r\n# numpy fft\r\nsignal = scipy.io.loadmat('signal.mat')['signal']\r\nsignal_f = np.fft.fft(signal)\r\n\r\n# tf fft\r\ntf_signal = tf.placeholder(shape=signal.shape,dtype=tf.complex64)\r\ntf_signal_f = tf.fft(tf_signal)\r\nsession = tf.InteractiveSession()\r\nout_signal_f, out_signal = session.run([tf_signal_f,tf_signal], feed_dict={tf_signal:signal})\r\n\r\nerrorBefore = np.mean(np.power(np.abs(out_signal-signal),2))\r\nerrorAfter = np.mean(np.power(np.abs(out_signal_f-signal_f),2))\r\nprint('Error before fft:',errorBefore)\r\nprint('Error after fft:',errorAfter)\r\n```\r\nunix ubuntu cpu:\r\n```\r\ntf: 1.4.0\r\nscipy: 0.19.1\r\nnp: 1.13.1\r\nError before fft: 6.43755807539e-22\r\nError after fft: 4.21685308781e+14\r\n```\r\n\r\nscientific linux hpc-cluster cpu:\r\n```\r\ntf: 1.3.0\r\nscipy: 0.17.1\r\nnp: 1.11.0\r\nError before fft: 6.43755807539e-22\r\nError after fft: 4.21685308781e+14\r\n```\r\n\r\nscientific linux hpc-cluster gpu (Tesla K80) with cudnn/v5.1:\r\n```\r\n('tf:', '1.0.1')\r\n('scipy:', '0.18.1')\r\n('np:', '1.11.2')\r\n('Error before fft:', 6.4375580753914162e-22)\r\n('Error after fft:', 2.8628744462657876e-15)\r\n```", "Thanks very much for the helpful repro @Rassibassi! I can also reproduce the issue.\r\n\r\nThis suggests an issue with Eigen TensorFFT or the TensorFlow plumbing that uses it. Interestingly, if I trim your 66528 tensor to length 65536 (power of 2) the results match numpy to 1e-8, but I get high error at length 65535. I get similar results when I trim the input tensor to length 32768/32767, but not when I trim to 16384/16383. Maybe suggests something is overflowing? We'll take a look.\r\n\r\ncc: @rmlarsen \r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 65536))\r\n('Error before fft:', 6.4749546908751922e-22)\r\n('Error after fft:', 1.0376122868548086e-08)\r\n```\r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 65535))\r\n('Error before fft:', 6.4750239427498006e-22)\r\n('Error after fft:', 55656499607300.164)\r\n```\r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 32768))\r\n('Error before fft:', 6.1796690528036584e-22)\r\n('Error after fft:', 7.996054658436124e-10)\r\n```\r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 32767))\r\n('Error before fft:', 6.1793787363606864e-22)\r\n('Error after fft:', 1754207811720195.0)\r\n```\r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 16384))\r\n('Error before fft:', 6.0547451539629847e-22)\r\n('Error after fft:', 1.1566757798862581e-10)\r\n```\r\n\r\n```\r\n('tf:', '1.4.1')\r\n('scipy:', '1.0.0')\r\n('np:', '1.13.3')\r\n('signal=', (1, 16383))\r\n('Error before fft:', 6.055074302285619e-22)\r\n('Error after fft:', 8.9115448530747228e-06)\r\n```", "Hi,\r\nI've gotten high errors also running one dimensional tf.rfft() on CPU over large signals (>280000 samples). On the other hand, after trimming the tensor length to the next power of two the results are quite better (in terms of error), as pointed out by @rryan .  ", "We think we tracked the issue (or part of the issue) down to this code in Eigen that computes twiddle factors for non-power-of-2 FFTs via Bluestein's algorithm. \r\n\r\nhttps://bitbucket.org/eigen/eigen/src/034b6c3e101792a3cc3ccabd9bfaddcabe85bb58/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?at=default&fileviewer=file-view-default#TensorFFT.h-230:249\r\n\r\nWe'll submit a fix to Eigen, then update the version of Eigen that TensorFlow uses.\r\n", "https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing", "I'm not sure if this is the same issue @Sushobhan04 is seeing though (the subject of this issue). \r\n\r\n@Sushobhan04, are you using power of 2 transforms? ", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "As of 67ff23036e093343a7ea02e17f36f2b02eaae740 the fix in https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing has been applied to TensorFlow.", "Hej!\r\nThanks for fixing the issue. It seems like there is still an issue with the CPU FFT. It's more subtle, but after calling `ifft(fft(signal))` several times the error becomes apparent. Take a look at the following script. \r\nI updated https://github.com/rassibassi/fftTensorflow with the new script in `run2.py`:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport scipy.io\r\nimport numpy as np\r\n\r\nprint('tf',tf.__version__)\r\nprint('scipy',scipy.__version__)\r\nprint('numpy',np.__version__)\r\n\r\ndef error(matlab,tf):\r\n    error = np.mean(np.square(np.abs(matlab-np.array(tf))))\r\n    return error\r\ndef relError(matlab,tf):\r\n    error = np.mean(np.square(np.abs(matlab-np.array(tf)))/np.square(np.abs(matlab)))\r\n    return error\r\ndef tf_i_fft(var,i=1):\r\n    for _ in range(i):\r\n        var = tf.ifft(tf.fft(var))\r\n    return var\r\ndef np_i_fft(var,i=1):\r\n    for _ in range(i):\r\n        var = np.fft.ifft(np.fft.fft(var))\r\n    return var    \r\n\r\ndef runTF(signal):\r\n    x = tf.placeholder(dtype=tf.complex64,shape=signal.shape)\r\n    out1 = tf_i_fft(x,1)\r\n    out20 = tf_i_fft(x,20)\r\n    out200 = tf_i_fft(x,200)\r\n    with tf.Session() as sess:\r\n        o1,o20,o200 = sess.run([out1,out20,out200],feed_dict={x:signal})\r\n        print(\"relError():\")\r\n        for x in [o1,o20,o200]:\r\n            print(relError(signal, x))\r\n        print(\"error():\")\r\n        for x in [o1,o20,o200]:\r\n            print(error(signal, x))\r\n        \r\ndef runNP(signal):\r\n    print(\"relError():\")\r\n    for i in [1,20,200]:\r\n        print(relError(signal, np_i_fft(signal,i)))\r\n    print(\"error():\")\r\n    for i in [1,20,200]:\r\n        print(relError(signal, np_i_fft(signal,i)))\r\n\r\nsignal = np.random.normal(size=2**14)+1j*np.random.normal(size=2**14)\r\nprint(\"TF error:\")\r\nrunTF(signal)\r\nprint(\"NP error:\")\r\nrunNP(signal)\r\n\r\nsignal = np.random.normal(size=2**16)+1j*np.random.normal(size=2**16)\r\nprint(\"TF error:\")\r\nrunTF(signal)\r\nprint(\"NP error:\")\r\nrunNP(signal)\r\n```\r\nOutput CPU:\r\n```\r\ntf 1.4.0\r\nscipy 0.19.1\r\nnumpy 1.13.1\r\n\r\nTF error:\r\nrelError():\r\n5.59392525962e-08\r\n2.2448001263e-05\r\n0.00232261390227\r\nerror():\r\n2.67353836243e-08\r\n1.07318864944e-05\r\n0.00110999929123\r\nNP error:\r\nrelError():\r\n3.1608419451e-30\r\n4.11521670168e-28\r\n3.64023186949e-26\r\nerror():\r\n3.1608419451e-30\r\n4.11521670168e-28\r\n3.64023186949e-26\r\n\r\nTF error:\r\nrelError():\r\n1.07720386138e-06\r\n0.000440561647239\r\n0.0554315680362\r\nerror():\r\n6.64006775289e-07\r\n0.000269907188294\r\n0.0315664672648\r\nNP error:\r\nrelError():\r\n6.42319902792e-30\r\n7.48332641966e-28\r\n4.85939408462e-26\r\nerror():\r\n6.42319902792e-30\r\n7.48332641966e-28\r\n4.85939408462e-26\r\n```\r\nOutput GPU:\r\n```\r\ntf 1.4.0\r\nscipy 0.19.1\r\nnumpy 1.13.1\r\n\r\nTF error:\r\nrelError():\r\n2.51723807688e-11\r\n2.20787161855e-09\r\n1.39922980127e-07\r\nerror():\r\n1.26221058554e-13\r\n2.72995514739e-11\r\n2.5727280163e-09\r\nNP error:\r\nrelError():\r\n4.08902237726e-29\r\n6.82474569015e-27\r\n8.05050948207e-25\r\nerror():\r\n4.08902237726e-29\r\n6.82474569015e-27\r\n8.05050948207e-25\r\n\r\nTF error:\r\nrelError():\r\n1.00672471898e-11\r\n1.62742361807e-10\r\n2.14752586388e-08\r\nerror():\r\n1.2714050306e-13\r\n2.48766311645e-11\r\n2.29909628833e-09\r\nNP error:\r\nrelError():\r\n9.99902717965e-29\r\n1.10272520665e-26\r\n2.09878555167e-24\r\nerror():\r\n9.99902717965e-29\r\n1.10272520665e-26\r\n2.09878555167e-24\r\n```", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@Rassibassi, I'm working on adding complex128 support to the FFT ops, and I ran your code snippet on CPU with the new complex128 support. It looks like a good bit of the difference comes down to floating point precision, but there is still a difference in magnitude of error between our Eigen CPU kernels and NumPy's FFTPACK-based implementation:\r\n\r\n```\r\n('tf', '1.7.0-rc1')\r\n('scipy', '1.0.0')\r\n('numpy', '1.13.3')\r\n\r\nTF complex64 error:\r\nrelError():\r\n5.69994795505e-08\r\n2.28822314134e-05\r\n0.00236386710254\r\nerror():\r\n2.67673230982e-08\r\n1.07452364853e-05\r\n0.00111161453476\r\n\r\nTF complex128 error:\r\nrelError():\r\n2.03202621417e-25\r\n8.12885273597e-23\r\n8.1293612227e-21\r\nerror():\r\n8.45195242854e-26\r\n3.3806405275e-23\r\n3.38062769196e-21\r\n\r\nNP error:\r\nrelError():\r\n1.46110214039e-30\r\n2.56749381389e-28\r\n2.15249955484e-26\r\nerror():\r\n1.46110214039e-30\r\n2.56749381389e-28\r\n2.15249955484e-26\r\n\r\nTF complex64 error:\r\nrelError():\r\n2.80140031472e-06\r\n0.00114172830632\r\n0.137244893593\r\nerror():\r\n6.57350034283e-07\r\n0.000267167590172\r\n0.0312076844667\r\n\r\nTF complex128 error:\r\nrelError():\r\n5.34248829151e-24\r\n2.136542245e-21\r\n2.1367747769e-19\r\nerror():\r\n7.49076129451e-25\r\n2.9962948344e-22\r\n2.99628924207e-20\r\n\r\nNP error:\r\nrelError():\r\n1.32333991018e-29\r\n4.18679573526e-27\r\n3.71090920591e-25\r\nerror():\r\n1.32333991018e-29\r\n4.18679573526e-27\r\n3.71090920591e-25\r\n```", "@sirgogo, running your code snippet using complex128 FFTs the error is `1.57009245868e-16`. Under complex64 the error is `5.1619136559e-08`.", "@rryan Thanks, this sounds promising.\r\n\r\nOne thing I was wondering (perhaps unrelated to this issue), is some of us are seeing different results on TF-CPU vs TF-GPU computation, even for networks with only simple operations like Add, Multiply, MatMul, reduce_sum, reduce_max, etc. I need to come up with a good set of tests to expose this, but do you have any insight on why this might be the case?", "Different results make sense, since the computation is being run by different hardware implementations of IEEE-754. Also, the implementation of reductions across CPU and GPU can be quite different. I've heard that Eigen on CPU can produce non-deterministic results when computing e.g. reductions using a thread pool. \r\n\r\nOne way to eliminate Eigen CPU non-determinism as a factor in testing is to set [intra_op_parallelism_threads](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L273) to 1 in your ConfigProto.\r\n\r\nDifferences can also arise from software bugs though, so please do file issues, ideally with reproducible test cases, for places where you think the difference might be a bug.", "@rryan Thanks! Looking forward to complex128 FFT functionality! :)\r\nwhat about running the examples with complex128 on a GPU?", "@Sushobhan04 Hi! \r\n\r\nAccording to the second that you have made, you used fftshift in tensorflow. Am I right? \r\nCan you, please, share tensorflow implementation of fftshift?\r\n ", "I added complex128 FFT support for CPU and GPU in https://github.com/tensorflow/tensorflow/commit/8f0a90b711480c12716d1a3b1094cc8b34939f2d. It'll be part of TensorFlow 1.9. \r\n\r\nRFFT/IRFFT support is on the way but a little more complicated, so I split it into a separate commit.", "It has been 21 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 36 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "hello, how to use tf.fft3d on rgb image, can you make a example? thank you very much.", "I am finding the 2dfft produces nonsensical results on complex data.  #28192", "@isaacgerg, commented on your issue. It looks like you were feeding a `[batch, height, width, channels]`, tensor to `tf.signal.fft2d`, so your FFT was over `[width, channels]` instead of `[height, width]` as you intended.", "@rryan Is the equivalent fix (https://github.com/tensorflow/tensorflow/commit/8f0a90b711480c12716d1a3b1094cc8b34939f2d)  for RFFT in the works? Until then I'm just truncating the output of the complex FFT but would be nice to have. ", "@PCerles RFFT complex128 support has been merged now. Sorry for the long delay! https://github.com/tensorflow/tensorflow/commit/4a3cbea5f3d1f79eb2ff6bb2c64875e951ca3ce2"]}, {"number": 10748, "title": "Add a tf.contrib.image.translate function", "body": "Progress on this issue: https://github.com/tensorflow/tensorflow/issues/781", "comments": ["Can one of the admins verify this patch?", "@sampepose how about what @ringw suggested?", "Ping for @sampepose !", "Closing in favor of #12306, where I made a small simplification. @sampepose can you please confirm there that it's ok to merge in your commit? Thanks!"]}, {"number": 10747, "title": "Striding behaviour different between caffe and tensorflow", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: Binary (pip install)\r\n- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: Tesla P100-SXM2 16MB\r\n- **Exact command to reproduce**: python caffe_to_tf_test.py\r\n\r\n### Describe the problem\r\nCaffe convolution produce different results then tensorflow with the same parameters.   This has something to do with striding - the attached test fails with striding equal to 2, and succeeds with striding equal to 1.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n[x.zip](https://github.com/tensorflow/tensorflow/files/1079200/x.zip)\r\n\r\n", "comments": ["Could you show the weights and tensors outputs from this program? I don't have both TensorFlow and Caffe installed. If the tensor is too big to show can you try to create a very small example like on a 3x3 image with a 2x2 filter?", "[test_and_output.zip](https://github.com/tensorflow/tensorflow/files/1081662/test_and_output.zip)\r\n\r\nHere is a zip file with the (random) weights, (random) biases, caffe output and TF output in .npy format. \r\n", "How hard is this to repro on a very small example i.e. 1x4x4x1 image and 1 channel in 1 channel out filter of size 2 or 3? That might make it clearer what the problem is.", "I can't do much smaller, but here is a 1x16x16x1 with a kernel size 7\r\n[test_and_data.zip](https://github.com/tensorflow/tensorflow/files/1081842/test_and_data.zip)\r\n", "P.S.  You can run a docker image of caffe from here: https://github.com/BVLC/caffe/tree/master/docker \r\nthen simply pip install tensorflow", "this might be the issue?\r\nhttps://stackoverflow.com/questions/42924324/tensorflows-asymmetric-padding-assumptions\r\n", "@amnonh-uw \r\nCenter Padding is happening in Gemmlowp,\r\nis this you wanted.?\r\n\r\n\"tensorflow/core/kernels/quantized_conv_ops.cc\"\r\n\r\n\r\n            // What we're doing here is trying to copy and fill the im2col\r\n             // buffer as efficiently as possible, using functions to set or\r\n             // duplicate values en masse. We know we don't have to worry about\r\n             // vertical edges because we dealt with that case above, so we\r\n             // just need to handle filters that overlap the left or right\r\n             // edges. Here's what that looks like:\r\n             //\r\n             // < left_zero_count > < center_copy_count > < right_zero_count >\r\n             // +------------------+---------------------+--------------------+\r\n             // |     (filter)     |       (image)       |      (filter)      |\r\n             // +------------------+---------------------+--------------------+\r\n             // in_x_origin        0                 input_width       in_x_end\r\n             //\r\n             // In reality it's unlikely that a filter patch will be wider\r\n             // than an input, but this shows all the edge cases.\r\n             // We use memset() to set the left and right sections to zeroes\r\n             // and memcpy() to copy over the input data for the center. These\r\n             // are preferred to std::fill and std::copy because they're much\r\n             // faster on Android.\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@reedwm, are you still looking at padding strategies in tf?", "Not really, but @yzhwang recently fixed a padding bug. I'm going to assume the issue is fixed since that was the only known padding bug; @amnonh-uw, please reopen if that's not the case in 1.7. "]}, {"number": 10746, "title": "Cifar10", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!\n\nRegards,\n\n*Sudarshan Shridhar Deo*\n\n\nOn Thu, Jun 15, 2017 at 3:04 PM, googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://mailtrack.io/trace/link/a1fe4a5f680e3a5651b9cfb6eb56d73d36f0e1e1?url=https%3A%2F%2Fcla.developers.google.com%2F&userId=1186381&signature=f2cb0c41f3a7e5f2>\n> to sign.*\n>\n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> verify. Thanks.\n> ------------------------------\n>\n>    - If you've already signed a CLA, it's possible we don't have your\n>    GitHub username or you're using a different email address. Check your\n>    existing CLA data\n>    <https://mailtrack.io/trace/link/42c8b38d999be14e5733c8d1a9058895ff00c328?url=https%3A%2F%2Fcla.developers.google.com%2Fclas&userId=1186381&signature=5a22a10fcb542369>\n>    and verify that your email is set on your git commits\n>    <https://mailtrack.io/trace/link/63b33a50ca5544e347b7411b5d30d062e3958bb9?url=https%3A%2F%2Fhelp.github.com%2Farticles%2Fsetting-your-email-in-git%2F&userId=1186381&signature=bf31d69e2333e70a>\n>    .\n>    - If your company signed a CLA, they designated a Point of Contact who\n>    decides which employees are authorized to participate. You may need to\n>    contact the Point of Contact for your company and ask to be added to the\n>    group of authorized contributors. If you don't know who your Point of\n>    Contact is, direct the project maintainer to go/cla#troubleshoot.\n>    - In order to pass this check, please resolve this problem and have\n>    the pull request author add another comment and the bot will run again.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://mailtrack.io/trace/link/cc5f7b524f0631a264e3474a8fb5e98b7fd8e360?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F10746%23issuecomment-308877841&userId=1186381&signature=f43d65704995c950>,\n> or mute the thread\n> <https://mailtrack.io/trace/link/28a38ca62c7c12916be0ff69a259862c5c7ec902?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAVuE932Ti56fpQQElD3LKrA8ATpk3CD0ks5sEaptgaJpZM4N7y3m&userId=1186381&signature=263b1ca55f629a0c>\n> .\n>\n", "Is this PR intended? Closing for now. @enggsudarshan could you sync to the latest and reopen if you would still like to make a change? Thanks!"]}, {"number": 10745, "title": "Fix shape.go's Size function.", "body": "Fixes #10741.", "comments": []}, {"number": 10744, "title": "[PIP] Markdown version locked to `2.2.0`", "body": "This markdown version lock could cause versioning conflict for downstream (e.g. if requirements are compiled and resolved by pip-compile). Wondering If there's a reason to lock this version. And it's already not sync with the [CI install script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_pip_packages.sh) (those `--upgrade` with locked version also doesn't seem right to me). ", "comments": ["A tiny [PR](https://github.com/tensorflow/tensorflow/pull/10743)", "The markdown requirement is going to leave setup.py for TensorFlow shortly, because it's only needed by TensorBoard, and TensorBoard is exiting to its own repo. So I'm going to close this here, and migrate to TensorBoard."]}, {"number": 10743, "title": "don't lock markdown version and bring CI deps install script in sync with setup.py", "body": "This markdown version lock could cause versioning conflict for downstream (e.g. if requirements are compiled and resolved by `pip-compile`). Wondering If there's a reason to lock this version \r\n\r\nSeems someone pushed `1.2.0` to PYPI and it cause some dependency conflict. \r\n", "comments": ["Can one of the admins verify this patch?", "I am inclined to reject the changes in install_pip_packages.sh file.\r\nFirst, that file is for our continuous integration system, and end users should not be using/depending on it.\r\nSecond, in our CI I would like all our dependencies to be tightly controlled.\r\nFor example, your changes will cause numpy to be upgraded to 1.13, which causes a lot of test failures due to a bug in the new numpy version. Without a version lock on numpy version, our CI will start breaking and debugging such issues would be very difficult.\r\n\r\nFor the changes to setup.py, I think that is a tensorboard dependency.\r\nPlease send a pull request with this change to our brand new tensorboard repository for discussion.", "OK. I don't think lock versions are a great thing to do especially it's not in sync with the actual `setup.py` which breaks the parity between CI and end user. @gunan  ", "Thanks for your input, however we will favor reproducibility in our CI to help us with debugging. `setup.py` is designed to be more flexible to enable a wider variety of user environments, but our CI has to be reproducible so that we can clearly pinpoint any issues in our build history."]}]