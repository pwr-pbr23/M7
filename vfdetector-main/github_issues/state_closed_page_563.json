[{"number": 36804, "title": "TFlite got error output when enable hexagon delegate", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** - Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): - OS Platform and Distribution (\r\nLinux Ubuntu 16.04): - Mobile device (OPPO reno ace) if\r\nthe issue happens on mobile device: - TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): - Python version: - Bazel\r\nversion (if compiling from source): - GCC/Compiler version (if compiling from\r\nsource): - CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI use this model for testing: https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip\r\nI set all input values as 1(just for tesing), then print the first 50 values of output[0], see below picture, on the left is the values when running on CPU, on the right is the values when enable hexagon delegate, \r\n![cpu_dsp](https://user-images.githubusercontent.com/29744812/74617424-eee9c300-5167-11ea-9061-53225444a7b7.png)\r\n\r\nCPU and DSP got diffrent output\r\n\r\n\r\n**Describe the expected behavior**\r\nCPU and DSP should get the same output values\r\n\r\n\r\n**Code to reproduce the issue** Provide a reproducible test case that is the\r\nbare minimum necessary to generate the problem.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@huanyingjun Please provide us with simple executable stand alone code[along with the tensorflow version] so we could replicate the issue in our environment.", "@Saduf2019\r\ntensorflow is at commit ID: a00bd4687adac4d5f1880595262276e656375322, Date:   Sun Feb 16 15:18:17 2020 -0800\r\nI use tflite benchmark_model for testing, just modify a few lines:\r\nbenchmark_tflite_model.cc   \r\nline 478  PrepareInputData \uff1a\r\n```\r\n} else if (t->type == kTfLiteUInt8) {\r\nint low = 1;//has_value_range ? low_range : 0;\r\nint high = 1;//has_value_range ? high_range : 254;\r\n```\r\n\r\nand line 656, modify \"RunImpl\" as below:\r\n```\r\nTfLiteStatus BenchmarkTfLiteModel::RunImpl() { \r\n\tTfLiteStatus ret = interpreter_->Invoke(); \r\n\tauto interpreter_outputs = interpreter_->outputs();\r\n\tTfLiteTensor* t = interpreter_->tensor(interpreter_outputs[0]);\r\n\tfloat* out_ptr = t->data.f;\r\n\tprintf(\"==================\\n\");\r\n\tfor (int i = 0; i < 50; i++)\r\n\t{\r\n\t\tif (i % 10 == 0 && i) printf(\"\\n\");\r\n\t\tprintf(\"%f \", out_ptr[i]);\r\n\t}\r\n\tprintf(\"\\n==================\\n\");\r\n\treturn ret;\r\n}\r\n```\r\n\r\nthen run benchmark with CPU and DSP\uff0c you can get the output value.\r\n\r\n", "And I also test with mobilenet-v2 ( https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz )\r\n\r\nAlso set input values as 1 just for testing, modify below codes:\r\nbenchmark_tflite_model.cc\r\nline 478 PrepareInputData \uff1a\r\n```\r\n} else if (t->type == kTfLiteUInt8) {\r\nint low = 1;//has_value_range ? low_range : 0;\r\nint high = 1;//has_value_range ? high_range : 254;\r\n```\r\n\r\nand line 656, modify \"RunImpl\" as below:\r\n```\r\nTfLiteStatus BenchmarkTfLiteModel::RunImpl() { \r\n\tTfLiteStatus ret = interpreter_->Invoke(); \r\n\r\n\tauto interpreter_outputs = interpreter_->outputs();\r\n\tTfLiteTensor* t = interpreter_->tensor(interpreter_outputs[0]);\r\n\tuint8_t* out_ptr = t->data.uint8;\r\n\tprintf(\"==================\\n\");\r\n\tfor (int i = 0; i < 50; i++)\r\n\t{\r\n\t\tif (i % 10 == 0 && i)  printf(\"\\n\");\r\n\t\tprintf(\"%f \", (out_ptr[i] - t->params.zero_point) * t->params.scale);\r\n\t}\r\n\tprintf(\"\\n==================\\n\");\r\n\t\r\n\treturn ret;\r\n}\r\n```\r\nCPU and DSP got different output values\r\n![cpu_dsp_mv2](https://user-images.githubusercontent.com/29744812/74650556-f6878700-51bc-11ea-90b4-ab6645328c35.png)\r\n\r\n\r\n", "@huanyingjun Can you please share the tensorflow version used, it helps us resolve the issue", "@Saduf2019\r\ntensorflow is at commit ID: a00bd46, Date: Sun Feb 16 15:18:17 2020 -0800", "Hey @huanyingjun, the output-pointer casting in your MobileNetv2 example (where you use `t->data.uint8`) is the correct, but the SSD one is wrong - I assume you fixed it later.\r\n\r\nIt might also be good to generate random data instead of using all 1s (but then you will need to run both settings with the same). \r\nMinimal, equal activations (such as 1) amplify the small differences in execution on DSP & CPU - they are never the exact same.\r\n\r\nAlso, may you try our [inference_diff](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff) tool which was specifically built for this kind of testing? It runs both settings (CPU/delegate) with the same random data and returns errors between each output tensor. If these are high for you, we need to debug.", "@srjoglekar246\r\nhello, I tried inference_diff with 3 models, below is the result:\r\nmobilenet_v1_1.0_224_quant.tflite (https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224_quant.tgz)\r\n```\r\noutput_errors {\r\n      max_value: 0.0659340695\r\n      min_value: 0.00799200777\r\n      avg_value: 0.026453545093536378\r\n      std_deviation: 0.0120730288\r\n    }\r\n```\r\n\r\n\r\nmobilenet_v2_1.0_224_quant.tflite ( https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz )\r\n```\r\noutput_errors {\r\n      max_value: 5.48851156\r\n      min_value: 5.13486528\r\n      avg_value: 5.251767578125\r\n      std_deviation: 0.0698218346\r\n    }\r\n```\r\ndetect.tflite (https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip)\r\n```\r\noutput_errors {\r\n      max_value: 0.433035672\r\n      min_value: 0.255494833\r\n      avg_value: 0.33961360931396484\r\n      std_deviation: 0.0411406\r\n    }\r\n    output_errors {\r\n      max_value: 37.4\r\n      min_value: 7.9\r\n      avg_value: 20.665998535156248\r\n      std_deviation: 6.46516037\r\n    }\r\n    output_errors {\r\n      max_value: 0.707812488\r\n      min_value: 0.662890613\r\n      avg_value: 0.68922660827636717\r\n      std_deviation: 0.00848944299\r\n    }\r\n    output_errors {\r\n      max_value: 0\r\n      min_value: 0\r\n      avg_value: 0\r\n      std_deviation: 0\r\n    }\r\n```\r\n\r\nseems mobilenet-v1 is correct.\r\nbut for mobilenet-v2 and  SSD, the  avg_value is high\r\nmobilenet-v2:  (avg_value: 5.251767578125), \r\nSSD:  (avg_value: 20.665998535156248)\r\n\r\nCould you please help check this ?\r\n\r\n", "@huanyingjun Hi, I have been trying to use Hexagon Delegate with QCS605 and I'm getting the same results for SSD MobileNet as described here #36927 . It now seems like a similar issue.\r\n\r\nIs it possible to get access to previous versions of libraries?", "I can reproduce this issue. Lemme debug and send a fix :-)", "@srjoglekar246\r\nThanks for your kindly response, I have an other question, Could you please share me how to build libhexagon_nn_skel.so for tflite?\r\nTFLite hexagon delegate is based on hexagon nnlib, I can get nnlib source code from https://source.codeaurora.org/quic/hexagon_nn/nnlib, and I can build ibhexagon_nn_skel.so according to \"README.HOW_TO_BUILD\" in nnlib, but my build libhexagon_nn_skel.so can not be used for tflite, report some error. Does tflite modify the nnlib code ? how to build libhexagon_nn_skel.so using the nnlib source code ?\r\n", "Short answer is, you cannot (unless you have Qualcomm's dev board).\r\nOnly Qualcomm can build & sign a binary that runs on non-debug devices in the wild.", "The fix for this should be in by now. We were handling Convolution with an activation (RELU6) incorrectly, hence the issue with SSD MobileNet.\r\n\r\nAbout the outputs from the `inference_diff` tool & your own scripting:\r\nI see diffs for MobileNetV2 & the int vector of SSD still, but when I checked with our [classification & object detection tooling](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks), the models got correct accuracy with the ImageNet/COCO datasets.\r\n\r\nFrom what I understand, randomized inputs are hard to interpret like actual data (eg images), since constant values or gaussian distributions don't entail typical model behavior. For example, the NMS post-processing that SSD does causes large deviations for random inputs, since there is sorting going on under-the-hood.\r\n\r\nThe way we typically use the diff tool is take a 'snapshot' of the output errors when we know the model is behaving correctly with the delegate, and then debug if the errors suddenly diverge. For example, the SSD model - with the fix, its avg diff for output tensor#1 is 8 with low std_deviation, while the one we saw before that is ~20 with a high std_deviation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36804\">No</a>\n", "@srjoglekar246 so where the bug was exactly and what should I update? Cheers!", "The bug was in the TensorFlow code, so you just need to use the latest nightly/master version. If you are using Android, the [nightly AAR](https://www.tensorflow.org/lite/performance/hexagon_delegate#step_1_edit_appbuildgradle_to_use_the_nightly_hexagon_delegate_aar_2) should work. Or if you are using the benchmark tool, BUILD from master :-)", "@srjoglekar246 Thank you :))", "Thanks for solving this problem, can you kindly direct me to the pr/commit link where you fix this bug?", "The fix landed a while back, but everything after [this commit](https://github.com/tensorflow/tensorflow/commit/920bf272c8187ee68d810d468209400ba7f7c4c9#diff-c47a66c8e8e1fead95278a60d5aa66a287b7b44467137998f093b5d203105061) included the fix."]}, {"number": 36803, "title": "Start the thread in Hook, resulting in failure to exit when train_step fails", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** - Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): - OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: - TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): - Python version: - Bazel\r\nversion (if compiling from source): - GCC/Compiler version (if compiling from\r\nsource): - CUDA/cuDNN version: - GPU model and memory:\r\n\r\nUbuntu16.04 x86_64 GNU/Linux\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nTensorflow@v1.12.0\r\n\r\n**Describe the current behavior**\r\n\r\nI use the Estimator for training, and implements a hook (I'm sorry, but for some reason I can't show the source code), in the hook's\u2019 `after_create_session` method, I started a python thread (a bit like TPUInfeedOutfeedSessionHook) which sess.run a block type op(eg. `dequeue`). Also, I implemented the end method,which will run an op(eg. `enqueue`) to prevent the thread from getting stuck.But Estimator explicitly describes the behavior of the hooks: if sess.run on in train step return failure, it will not call the end (and after_run) method. In the code, MonitorSession call the _close_internal method (it will invoke the Session.close()) which will wait for all the work thread ends, but obviously, the thread executing sess.run in my hook's after_create_session will not be able to exit )\r\n\r\n**Describe the expected behavior**\r\n\r\nI feel my usage is not strange, also the realization of the reference part TPUEstimator (TPUInfeedOutfeedSessionHook is similar to my hook). Does tensorflow not allowed to start a thread in the hook?As once it's started, when something goes wrong in the training step, the next call is session.close()\uff0cEventually the Tensorflow process got stuck.\r\n\r\n**Code to reproduce the issue** Provide a reproducible test case that is the\r\nbare minimum necessary to generate the problem.\r\n```PYTHON\r\ndef my_thread_task:\r\n while True:\r\n        try:\r\n          session.run(self._dequeue_ops)\r\n        except tf.errors.OutOfRangeError: # this signal will send by end() method\r\n          break\r\n        except Exception as e:\r\n          # raise runtime error\r\ndef after_create_session:\r\n  threading.Thread(target=my_thread_task)\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36803\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36803\">No</a>\n", "forget this issue...TF provides the mechanism for coord"]}, {"number": 36802, "title": "DataLoss error on TFRecords - Randomly when accessing the dataset on S3 like storage", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): CentOS Linux 7.7\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel\r\n- CUDA/cuDNN version: 410.79/V10.0.130\r\n- GPU model and memory: V100 8 GPUs /16130MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI'm running tensorflow benchmark ResNet50 on Fuse of cloud storage(Alibaba Cloud Storage: oss). It succeed many times, or failed at the beginning of training. And when it passed the beginning,  it never failed during the training. And the speed is also good.\r\n\r\n The workload is 4 V100 GPU instances and each has 8 GPUs: 32 GPUs in total. \r\n\r\n```\r\n  (0) Data loss: corrupted record at 0\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[input_processing/IteratorGetNext]]\r\n\t [[cluster_5_1/merge_oidx_1/_951]]\r\n  (1) Data loss: corrupted record at 0\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[input_processing/IteratorGetNext]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.DataLossError: 2 root error(s) found.\r\n  (0) Data loss: corrupted record at 0\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[input_processing/IteratorGetNext]]\r\n\t [[cluster_5_1/merge_oidx_1/_951]]\r\n  (1) Data loss: corrupted record at 0\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[input_processing/IteratorGetNext]]\r\n```\r\n\r\nI can make sure the tfrecords are correct, because we have checked it one by one.\r\nThe logs of fuse and Cloud storage system doesn't have any hint.\r\nCould your guys suggest what may cause this issue? Is there any latency requirement? Or could we set timeout in somewhere? Thanks very much for your help!\r\n\r\n\r\nHere is the full log:\r\n[test.log](https://github.com/tensorflow/tensorflow/files/4211351/test.log)\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue** Provide a reproducible test case that is the\r\nbare minimum necessary to generate the problem.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/13463) especially this [comment](https://github.com/tensorflow/tensorflow/issues/13463#issuecomment-456122189) and this [one](https://github.com/tensorflow/tensorflow/issues/13463#issuecomment-460947809) and let me know if it helps. Thanks!", "It doesn't really help. May I know what may cause this issue? It's my guess on the storage level. https://github.com/Alluxio/alluxio/issues/10929 Does it make sense?", "@cheyang Please try using `tf.data.experimental.ignore_errors()` as fixed in this issue [here](https://github.com/tensorflow/tensorflow/issues/25700). This should help you work around Data loss error as shown [here](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/core/kernels/data/reader_dataset_ops.cc#L848) I cannot exactly point to the reason why its happening in your case.\r\n\r\n@jsimsa Can you PTAL?", "I was trying to add some debug info in the fuse level, and found there are really zero bytes in some reads. Can this give you some ideas on this issue?\r\n\r\nalluxio-fuse-c9qx2-alluxio-fuse.log:2020-03-14 12:20:12,531 ERROR AlluxioFuseFileSystem - read(file=/train/train-00847-of-01024,offset=103022136,size=456): all bytes zero\r\nalluxio-fuse-c9qx2-alluxio-fuse.log:2020-03-14 12:20:39,752 ERROR AlluxioFuseFileSystem - read(file=/train/train-00586-of-01024,offset=144964184,size=1448): all bytes zero\r\nalluxio-fuse-hrvzs-alluxio-fuse.log:2020-03-14 12:20:15,441 ERROR AlluxioFuseFileSystem - read(file=/train/train-00048-of-01024,offset=121632152,size=2664): all bytes zero\r\nalluxio-fuse-hrvzs-alluxio-fuse.log:2020-03-14 12:20:41,876 ERROR AlluxioFuseFileSystem - read(file=/train/train-00489-of-01024,offset=13631032,size=456): all bytes zero\r\nalluxio-fuse-qp4b4-alluxio-fuse.log:2020-03-14 12:20:40,514 ERROR AlluxioFuseFileSystem - read(file=/train/train-00271-of-01024,offset=1310264,size=456): all bytes zero\r\nalluxio-fuse-qp4b4-alluxio-fuse.log:2020-03-14 12:20:41,806 ERROR AlluxioFuseFileSystem - read(file=/train/train-00487-of-01024,offset=10484232,size=1528): all bytes zero", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36802\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36802\">No</a>\n"]}, {"number": 36801, "title": "TypeError: Object of type float32 is not JSON serializable", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Mac OS Catalina (Version: 10.15.3)\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7.5\r\n- GPU model and memory: Intel Iris Pro 1536 MB\r\n\r\n**Describe the current behavior**\r\n\r\nI get the following error\r\n\r\n> TypeError: Object of type float32 is not JSON serializable\r\n\r\nwhen I try to save the state of the optimizer **after** having trained the model. Before training the model, I can save the state of the optimizer without getting any error.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error.\r\n\r\n**Code to reproduce the issue** \r\n\r\n```\r\nimport json\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef get_model(input_shape=(1,)):\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Input(shape=input_shape))\r\n    model.add(tf.keras.layers.Dense(8, activation=\"relu\"))\r\n    model.add(tf.keras.layers.Dense(1))\r\n    model.summary()\r\n    model.compile(loss=\"mse\", optimizer=\"adam\")\r\n    return model\r\n\r\n\r\ndef write_config(model, optimizer_file_path=\"optimizer.json\"):\r\n    with open(optimizer_file_path, \"w\") as f:\r\n        json.dump(model.optimizer.get_config(), f, indent=4, sort_keys=True)\r\n\r\n\r\ndef get_data(n=100):\r\n    import numpy as np\r\n    data_x = np.random.rand(n, 1)\r\n    data_y = np.asarray([1 if x > 0.5 else 0 for x in data_x]).reshape(data_x.shape)\r\n    return data_x, data_y\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = get_model()\r\n\r\n    x, y = get_data()\r\n\r\n    # No error before fitting.\r\n    # write_config(model)\r\n\r\n    model.fit(x, y, epochs=2)\r\n\r\n    # Error after fitting.\r\n    write_config(model)\r\n```\r\n\r\n**Other**\r\n\r\nNote that [the documentation of `model.optimizer.get_config()` says that the returned value is serializable](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#get_config)\r\n\r\n> An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer.", "comments": ["@nbro can you please confirm if the issue faced is similar to [link](https://github.com/tensorflow/tensorflow/issues/28799).", "@Saduf2019 In my case, the thing that isn't apparently serializable is a float32, while in the other issue a `Variable` isn't serializable. Furthermore, I am not using `save_model` or any similar method (because I can't use them and then load models from those save files with TFP). They are similar in the sense that a float32 (in the variable of the other issue) is involved and serialization doesn't work.", "@nbro As mentioned in the issue [here](https://stackoverflow.com/questions/53082708/typeerror-object-of-type-float32-is-not-json-serializable) converting the optimizer value to string will not result in any error. Heres the [gist](https://colab.sandbox.google.com/gist/gowthamkpr/eef2fcd8bc3bda8c3eb46304a0404c42/untitled22.ipynb).", "@gowthamkpr Yes, I had also tried that. However, I don't want to save a string, but a dictionary! If I do what you're suggesting, I will have a file whose contents have quotes.", "I have serialized the optimizer using `tf.keras.optimizers.serialize()` \r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/639b68e7b04130b81a98cb18fa4b0ece/untitled22.ipynb)\r\n\r\n", "@gowthamkpr I still get the initial error with my actual code and not your gist or the example above.", "I am unable to reproduce your error @nbro. I am going to close this issue now as it not a bug. Please post your question in stackoverflow. Thanks!", "@gowthamkpr How do you know it's not a bug?", "Sorry for closing it abruptly @nbro but what I was mentioning is that the optimizer is of type dictionary and you cannot serialize it using json.dumps() which doesn't support serializing dictionary type . \r\nBut using `tf.keras.optimizers.serialize()` you can easily serialize the model as shown below.\r\nSo, I would recommend you saving it using `tf.keras.optimizers.serialize()` which works perfectly in this case and so its not a bug.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue as it has been inactive for more than 4 weeks . Please add additional comments and we can open this issue again. Thanks!"]}, {"number": 36800, "title": "Pip package building fail on third party NASM linking ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro (version 1903 ; 18362.657)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): MSVC 16 (VS2019)\r\n- CUDA/cuDNN version: 10.2 + 7\r\n- GPU model and memory: NVIDIA Titan RTX\r\n\r\n**Describe the problem**\r\n\r\nBuilding from source the pip package fails due to a failing linking to a third-party library (NASM)\r\n**NOTE**: During the first building try, my antivirus (Avira) put a nasm-related generated file in quarantine, so I disabled it before doing a clean new build.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- Preamble : Installed all prerequisites as given by https://www.tensorflow.org/install/source_windows\r\n- Run the configuration script (`python ./configure.py`) with following options: python 3.7 ; XLA support ; no ROCm ; CUDA 10.2 + cuDNN 7 ; AVX2 instruction set ; Eigen inline override\r\n- Fix the WORKSPACE file by adding:\r\n~~~~\r\nhttp_archive(\r\n    name = \"io_bazel_rules_docker\",\r\n    sha256 = \"dc97fccceacd4c6be14e800b2a00693d5e8d07f69ee187babfd04a80a9f8e250\",\r\n    strip_prefix = \"rules_docker-0.14.1\",\r\n    urls = [\"https://github.com/bazelbuild/rules_docker/releases/download/v0.14.1/rules_docker-v0.14.1.tar.gz\"],\r\n)\r\n~~~~\r\nafter the http_archive for closure rules (otherwise build fails when trying to execute `git reset --hard [...]` on @io_bazel_rules_docker)\r\n- Run the bazel build (`bazel build //tensorflow/tools/pip_package:build_pip_package`)\r\nThe build fail during the linking of the 3rd party NASM library (see error log under)\r\n\r\n**Any other info / logs**\r\n\r\npython configure.py\r\n~~~~\r\nPlease specify the location of python. [Default is C:\\Program Files\\Python_3.7.3\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Program Files\\Python_3.7.3\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Program Files\\Python_3.7.3\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.2 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/include\r\nFound cuDNN 7 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.5\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]: /arch:AVX2\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n~~~~\r\n\r\nBuild error\r\n~~~~\r\nERROR: C:/users/tyrmalion/_bazel_tyrmalion/mrkkanxp/external/nasm/BUILD.bazel:8:1: Linking of rule '@nasm//:nasm' failed (Exit 1104): link.exe failed: error executing command\r\n  cd C:/users/tyrmalion/_bazel_tyrmalion/mrkkanxp/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.17763.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Program Files/Python_3.7.3/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Program Files/Python_3.7.3/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\TYRMAL~1\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\TYRMAL~1\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.24.28314/bin/HostX64/x64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/external/nasm/nasm /SUBSYSTEM:CONSOLE /MACHINE:X64 @bazel-out/x64_windows-opt/bin/external/nasm/nasm-2.params\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nLINK : fatal error LNK1104: cannot open file 'bazel-out\\x64_windows-opt\\bin\\external\\nasm\\nasm'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 478.038s, Critical Path: 27.71s\r\nINFO: 563 processes: 563 local.\r\nFAILED: Build did NOT complete successfully\r\n~~~~", "comments": ["@tim-evain Could you please try on the latest stable version of **TF 2.6.0** and let us know if it is still an issue? Please refer to [build from source](https://www.tensorflow.org/install/source_windows) and let us know if it helps? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36799, "title": "Feature Request: General Purpose Metrics Callback", "body": "# Background\r\nI am coming from tensorflow addons and have been send here by @pavithrasv and @seanpmorgan to start this discussion. The root of this is that we have great problems to implement a clean and bugfree F1 metric for keras. See here: https://github.com/tensorflow/addons/issues/825\r\n\r\n# Feature Request Description\r\nFor keras / tensorflow it is possible to implement custom metrics. These metrics are basicaly keras layers and have to be implemented with tensorflow itself. For many reasons it is not easy to implement certain metrics. This is the reason why some metrics like F1 are still not available in TF and have a history of ugly bugs. This is why I think that it would be good to implement a callback to plug in any metric without having to use TF. So you could plug in all sklearn metrics you want to use.\r\nThis is the case with other tools like LightGBM and XGBoost. See `feval` parameter of `lightgbm.train`: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html#lightgbm.train\r\n\r\n# First Idea of Implementation\r\nA first implementation version could look like this (but has some limitations - see below):\r\n\r\n``` python\r\nclass MetricsCallback(keras.callbacks.Callback):\r\n    def __init__(self, val_data, val_labels, fmetrics):\r\n        super().__init__()\r\n        self.val_data = val_data\r\n        self.val_labels = val_labels\r\n        self.fmetrics = fmetrics\r\n        # TODO: more checks\r\n\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        logs = logs or {}\r\n        predict_results = self.model.predict(self.val_data)\r\n\r\n        for fm in self.fmetrics:\r\n            metric_name, value = fm(self.val_labels, predict_results)\r\n            logs[metric_name] = value\r\n```\r\n\r\n## Limitations\r\nYou have to give validation data to this callback and not to the fit function of keras. Otherwise the validation data will be predicted twice - once from keras fit and once from this callback. \r\n\r\nAnd if you want to use the EarlyStopping callback you have to provide this callback before the EarlyStopping callback.\r\n\r\n# Next Steps\r\nWhat are the next steps? I would like to start a discussion on how to implement the first version in a way that integrates with keras and does not feel like a hack.", "comments": ["As I wrote in https://github.com/tensorflow/addons/issues/825, it seems that `keras.metrics.Precision(name='precision')` and `keras.metrics.Recall(name='recall')` already solve the batch problem. So keras would only need to add the obvious F1 computation from these values. Then there is no need to add all this to tensorflow.\r\n", "If one wants to be able to use numpy in a `Metric`, I believe that's possible. A metric doesn't require any gradient and you just have to execute `result` and `update_states` in eager mode. I mean, in eager mode you can do pretty much anything you want anyway, so I fail to see how using numpy would be a problem.\r\n\r\n> The root of this is that we have great problems to implement a clean and bugfree F1 metric for keras.\r\n\r\nTensorFlow addons have (and had since quite some time) a clean and bugfree F1 metric implementation for tf.keras. Not for multi-backend keras though, but this is fine since multi-backend keras is deprecated. The issue mentioned here: tensorflow/addons#825  was just a misunderstanding concerning the compatibility between multi-backend keras and TF Addons. As such, it's not a valid bug report.", "@gabrieldemarmiesse I don't think the F1 implemented in Addons is bug-free. It keeps complaining about the ranks because it forces the output (even in binary case) to be one-hot vector as pointed out [here](https://github.com/tensorflow/addons/issues/746#issuecomment-562963134). I do think this needs to change.", "> If one wants to be able to use numpy in a `Metric`, I believe that's possible. A metric doesn't require any gradient and you just have to execute `result` and `update_states` in eager mode. I mean, in eager mode you can do pretty much anything you want anyway, so I fail to see how using numpy would be a problem.\r\n> \r\n> > The root of this is that we have great problems to implement a clean and bugfree F1 metric for keras.\r\n> \r\n> TensorFlow addons have (and had since quite some time) a clean and bugfree F1 metric implementation for tf.keras. Not for multi-backend keras though, but this is fine since multi-backend keras is deprecated. The issue mentioned here: [tensorflow/addons#825](https://github.com/tensorflow/addons/issues/825) was just a misunderstanding concerning the compatibility between multi-backend keras and TF Addons. As such, it's not a valid bug report.\r\n\r\nDoes the f1-score metric implementation in tf-addons calculate score per batch wise (or) on the full validation set? It wasn't mentioned clearly.", "It's computing the score on the full validation set to get more meaningful results :) ", "@PhilipMay Is there any actionable item like raising PR? \r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36796, "title": "allow Tensors in the RNN state size", "body": "Currently, the RNN class does not allow a RNN cell wrapped with an AttentionWrapper, since the `AttentionWrapper.state_size` property produces Tensors for[ two of its sub-states](https://github.com/tensorflow/addons/blob/caa0454578ac276918f7bce73ee62c5e70a8a780/tensorflow_addons/seq2seq/attention_wrapper.py#L1906) (specifically the alignments & alignment_history, whose size is a Tensor calculated as `tf.shape(self.keys)[1]`.\r\n", "comments": ["Right, good point.\r\nI have a nice commit that will fix this problem in AttentionWrapper.\r\n"]}, {"number": 36795, "title": "docfix: fix docstring error in KerasHistory", "body": "fixed a tiny docstring error for KerasHistory", "comments": []}, {"number": 36794, "title": "a bug about tf.function", "body": "WARNING:tensorflow:AutoGraph could not transform <function converge_to_2 at 0x7f6e047dae50> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: invalid value for \"node\": expected \"ast.AST\", got \"<class 'NoneType'>\"; to visit lists of nodes, use \"visit_block\" instead\r\nWARNING: AutoGraph could not transform <function converge_to_2 at 0x7f6e047dae50> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: invalid value for \"node\": expected \"ast.AST\", got \"<class 'NoneType'>\"; to visit lists of nodes, use \"visit_block\" instead\r\ntf.Tensor(1.9999981, shape=(), dtype=float32)", "comments": ["@tf.function\r\ndef converge_to_2(n_iters):\r\n    total = tf.constant(0.)\r\n    increment = tf.constant(1.)\r\n    for _ in range(n_iters):\r\n        total +=increment\r\n        increment /= 2.0\r\n    return total\r\nprint(converge_to_2(20))", "@paokuwansui, Check the `gast` version. Tensorflow 2.x supports gast ==0.2.2. Thanks!", "Thank you, but my gast == 0.2.2\r\n\r\ndocutils                   0.16    \r\nentrypoints                0.3     \r\net-xmlfile                 1.0.1   \r\nfuture                     0.18.2  \r\ngast                       0.2.2   #-----------------------\r\ngoogle-auth                1.10.0  \r\ngoogle-auth-oauthlib       0.4.1   \r\ngoogle-pasta               0.1.7   \r\ngrpcio                     1.27.0  \r\nh5py                       2.10.0  \r\nhtml5lib                   1.0.1   \r\nidna                       2.8     \r\n", "@paokuwansui, Can you provide the complete code to replicate the reported issue. Thanks!", "@paokuwansui, Is this still an issue?", "import tensorflow as tf\r\n@tf.function\r\ndef converge_to_2(n_iters):\r\n    total = tf.constant(0.)\r\n    increment = tf.constant(1.)\r\n    for _ in range(n_iters):\r\n        total +=increment\r\n        increment /= 2.0\r\n    return total\r\nprint(converge_to_2(20))", "> Is this still an issue?\r\nYes, this problem is still unresolved \r\nMy system is manjaro\r\ntensorflow == 2.1.0\r\n\r\nSource code\uff1a\r\nimport tensorflow as tf\r\n@tf.function\r\ndef converge_to_2(n_iters):\r\n  total = tf.constant(0.)\r\n  increment = tf.constant(1.)\r\n  for _ in range(n_iters):\r\n    total +=increment\r\n    increment /= 2.0\r\n  return total\r\nprint(converge_to_2(20))", "@paokuwansui, I tried on colab with Tf 2.1. Its working without any warnings.\r\nPlease take a look at gist [here](https://colab.sandbox.google.com/gist/gadagashwini/68db324a7685ee397abf70aa28b0ce7e/untitled421.ipynb). Thanks!", "@paokuwansui, Let us if still issue persists. Thanks!", "Yes, I hope I can provide you with more information\r\n\r\nBut i don't know what information to give you\r\n\r\n[lzh@lzh-pc ~]$ python\r\nPython 3.8.1 (default, Jan 22 2020, 06:38:00) \r\n[GCC 9.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> @tf.function\r\n... def a (n):\r\n...     return n*2\r\n... \r\n>>> a(10)\r\n2020-03-13 19:09:06.982192: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-03-13 19:09:07.030306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800500000 Hz\r\n2020-03-13 19:09:07.031321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f35ef5d720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-03-13 19:09:07.031349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:AutoGraph could not transform <function a at 0x7fe0080c50d0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function a at 0x7fe0080c50d0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nWARNING: AutoGraph could not transform <function a at 0x7fe0080c50d0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function a at 0x7fe0080c50d0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\n<tf.Tensor: shape=(), dtype=int32, numpy=20>\r\n>>> \r\n\r\n\r\n\r\n\r\nI use a laptop\r\nThe system is manjaro\r\nCPU is i5 8550u\r\nThe graphics card is Max150\r\n\r\n", "@paokuwansui You can safely ignore the warning log as its intended to debug logging in AutoGraph issues. Thanks !", "Thank you very much------------------ \u539f\u59cb\u90ae\u4ef6 ------------------\r\n\u53d1\u4ef6\u4eba: \"gowthamkpr\"<notifications@github.com>\r\n\u53d1\u9001\u65f6\u95f4: 2020\u5e743\u670831\u65e5(\u661f\u671f\u4e8c) \u51cc\u66685:48\r\n\u6536\u4ef6\u4eba: \"tensorflow/tensorflow\"<tensorflow@noreply.github.com>;\r\n\u6284\u9001: \"paokuwansui\"<1059773473@qq.com>;\"Mention\"<mention@noreply.github.com>;\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] a bug about tf.function (#36794)\r\n\r\n\r\n\r\n\r\n \r\n@paokuwansui You can safely ignore the warning log as its intended to debug logging in AutoGraph issues. Thanks !\r\n \r\n&mdash;\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or unsubscribe."]}, {"number": 36793, "title": "Same input - different output", "body": "I have written a small code, and notice that I get a different result dependent on if I use Numpy or not. \r\n\r\nThis code should give the same result for both df_dy and df_dy_p, but it does not. It does not matter if I change the order of the calculations. \r\n\r\n`from math import e\r\nimport numpy as np\r\n\r\ndef calc_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        sigma = cal_sigma(-y)\r\n        f = (x + sigma) / np.power((x - y), 2)\r\n        p = (x + sigma) / ((x -y)**2)\r\n    print(x, y, f, p)\r\n    df_dy = tape.gradient(f, x) \r\n    df_dy_p = tape.gradient(p, x)\r\n    print(df_dy)\r\n    print(df_dy_p)\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nget_derivative(x, y)`\r\n\r\nThe output is:\r\n\r\ntf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(-3.0, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32)\r\ntf.Tensor(0.0625, shape=(), dtype=float32)\r\ntf.Tensor(0.0014820583, shape=(), dtype=float32)\r\n\r\nAs one can see, the input is the same, but the output differs. ", "comments": ["@oeyvindds please provide with simple stand alone code with all dependencies from the code for us to replicate in our environment, i was unable to replicate the code shared by you due to dependencies in the code.\r\nAlso please highlight the tensorflow version you are facing th eissue in.", "Hello.\r\n\r\nHere is a complete code that runs fine on my machine (Anaconda Python) in an empty notebook:\r\n\r\n`import tensorflow as tf\r\nimport numpy as np\r\nfrom math import e\r\n\r\ndef calc_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        sigma = calc_sigma(-y)\r\n        f = (x + sigma) / np.power((x - y), 2)\r\n        p = (x + sigma) / ((x -y)**2)\r\n    print('Variable x: {}'.format(x))\r\n    print('Variable y: {}'.format(y))\r\n    print('Input from f: {}'.format(f))\r\n    print('Input from p: {}'.format(p))\r\n    \r\n    df_dy_p = tape.gradient(p, x)\r\n    df_dy = tape.gradient(f, x) \r\n    \r\n    print('Output from f: {}'.format(df_dy))\r\n    print('Output from p: {}'.format(df_dy_p))\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nget_derivative(x, y)`\r\n\r\ntf.__version__ gives '2.1.0'\r\n\r\nThe code give the following output:\r\n\r\nVariable x: 1.0\r\nVariable y: -3.0\r\nInput from f: 0.12203588336706161\r\nInput from p: 0.12203588336706161\r\nOutput from f: 0.0625\r\nOutput from p: 0.0014820583164691925", "@oeyvindds please provide us with indented code that is executable and has all dependencies, [code](https://colab.sandbox.google.com/gist/Saduf2019/026fb6e01f24facc0844a2f731e8c276/untitled44.ipynb) shared is not indented , dependencies are not shared.\r\nyou could share a gist of your code using colab.", "Here is the code indented:\r\n\r\n```\r\nfrom math import e\r\nimport numpy as np\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\ndef calc_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        sigma = calc_sigma(-y)\r\n        f = (x + sigma) / np.power((x - y), 2)\r\n        p = (x + sigma) / ((x -y)**2)\r\n        \r\n        print(x, y, f, p)\r\n    df_dy = tape.gradient(f, x)\r\n    df_dy_p = tape.gradient(p, x)\r\n    print(df_dy)\r\n    print(df_dy_p)\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nget_derivative(x, y)\r\n```\r\nIt gives this output:\r\n```\r\n2.1.0\r\ntf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(-3.0, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32)\r\ntf.Tensor(0.0625, shape=(), dtype=float32)\r\ntf.Tensor(0.0014820583, shape=(), dtype=float32)\r\n```\r\n\r\n", "I am able to replicate this issue, please find the gist [here](https://colab.sandbox.google.com/gist/Saduf2019/e550000c42d48279ab15c62c12253e54/untitled53.ipynb)", "@oeyvindds and @Saduf2019, The problem is because the f is evaluated by converting (x-y)^2 in numpy before computing gradient. So, in f, denominator `np.power((x-y),2)` is not a variable at the time of differentiation. Instead, it is a constant with value 16. \r\nWhereas, in p, `((x-y)**2)` is a tensor and it will be variable at the time of differentiation.\r\n\r\nLook at below two codes which are tested and their outputs:\r\n\r\n**Code 1 :**\r\n```py\r\nfrom math import e\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef calc_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        sigma = calc_sigma(-y)\r\n        f = (x + sigma) / np.power((x - y), 2)\r\n        p = (x + sigma) / ((x-y)**2).numpy()\r\n        \r\n    df_dy = tape.gradient(f, x)\r\n    df_dy_p = tape.gradient(p, x)\r\n    print(df_dy)\r\n    print(df_dy_p)\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nget_derivative(x, y)\r\n```\r\n**Output :**\r\n```py\r\ntf.Tensor(0.0625, shape=(), dtype=float32)\r\ntf.Tensor(0.0625, shape=(), dtype=float32)\r\n```\r\n\r\n**Code 2:**\r\n```py\r\nfrom math import e\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef calc_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        sigma = calc_sigma(-y)\r\n        f = (x + sigma) / tf.math.square(x - y)\r\n        p = (x + sigma) / ((x-y)**2)\r\n        \r\n    df_dy = tape.gradient(f, x)\r\n    df_dy_p = tape.gradient(p, x)\r\n    print(df_dy)\r\n    print(df_dy_p)\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nget_derivative(x, y)\r\n```\r\n**Output :**\r\n```py\r\ntf.Tensor(0.0014820583, shape=(), dtype=float32)\r\ntf.Tensor(0.0014820583, shape=(), dtype=float32)\r\n```", "Thanks for the explanation :-)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36793\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36793\">No</a>\n"]}, {"number": 36792, "title": "Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array", "body": "Hello.\r\n\r\nI am trying to derive with Tensorflow, and get an error telling me to report the behavior to the TensorFlow team. Hence this post. \r\n\r\nMy code:\r\n```python\r\nfrom math import e\r\n\r\ndef cal_sigma(y):\r\n    return 1 / (1 + np.power(e, -y) )\r\n\r\n@tf.function\r\ndef get_derivative(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(x)\r\n        tape.watch(y)\r\n        y_sigma = cal_sigma(-y)\r\n        f = (x + y_sigma) / np.power((x -y), 2)\r\n    df_dy = tape.gradient(f, y) \r\n    return df_dy\r\n\r\nx = tf.constant (1.)\r\ny = tf.constant (-3.)\r\nprint(get_derivative(x, y))\r\n\r\nIf I derive with respect to x (df_dy = tape.gradient(f, x) in second to last line; it works. However, with y, I get the following error:\r\n\r\nWARNING:tensorflow:AutoGraph could not transform <method-wrapper '__call__' of numpy.ufunc object at 0x110a96950> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.\r\nWARNING: AutoGraph could not transform <method-wrapper '__call__' of numpy.ufunc object at 0x110a96950> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-11-a4cdc628e4ad> in <module>\r\n      2 y = tf.constant (-3.)\r\n      3 #print(get_derivative(x, y))\r\n----> 4 print(get_derivative2(x, y))\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    604       # In this case we have not created variables on the first call. So we can\r\n    605       # run the first trace but we should fail if variables are created.\r\n--> 606       results = self._stateful_fn(*args, **kwds)\r\n    607       if self._created_variables:\r\n    608         raise ValueError(\"Creating variables on a non-first call to a function\"\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2360     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   2361     with self._lock:\r\n-> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2364 \r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2701 \r\n   2702       self._function_cache.missed.add(call_context_key)\r\n-> 2703       graph_function = self._create_graph_function(args, kwargs)\r\n   2704       self._function_cache.primary[cache_key] = graph_function\r\n   2705       return graph_function, args, kwargs\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2591             arg_names=arg_names,\r\n   2592             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2593             capture_by_value=self._capture_by_value),\r\n   2594         self._function_attributes,\r\n   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    438         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    440     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    441 \r\n\r\n/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nNotImplementedError: in converted code:\r\n\r\n    <ipython-input-9-af8fccc461fb>:20 get_derivative2  *\r\n        y_sigma = cal_sigma(-y)\r\n    <ipython-input-9-af8fccc461fb>:4 cal_sigma  *\r\n        return 1 / (1 + np.power(e, -y) )\r\n    /opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:728 __array__\r\n        \" array.\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.\r\n```", "comments": ["I did manage to get around it by not relying on numpy. The new code is:\r\n\r\ndef cal_sigma(y):\r\n    return 1 / (1 + e**-y)\r\n\r\n@tf.function\r\ndef get_derivative2(x, y):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(y)\r\n        y_sigma = cal_sigma(-y)\r\n        f = (x + y_sigma) / ((x -y)**2)\r\n    df_dy = tape.gradient(f, y) \r\n    return df_dy\r\n\r\nWith these changes, it does work also for y. However, it gives an unpredictable answer. See https://github.com/tensorflow/tensorflow/issues/36793", "@oeyvindds  Could you please confirm to close this as it looks like a duplicate issue  You can track the progress in #36793.", "No. This is not the same issue. This seems to be a bug related to TensorFlow not being able to use Numpy. Here it cannot convert the symbolic Tensor to a numpy array. Hence, when using Numpy it comes to a complete stop.\r\n\r\nThe workaround for this issue turned into issue #36793. But I believe both issues should be researched and hopefully fixed.\r\n\r\nAs issue #36793 is a different issue from my point of view. There it works fine with numpy. However, the two seemingly identical ways of doing a task give two different outputs. \r\n\r\nIt might be related to numpy as well. However, here TensorFlow comes to a complete stop and gives an error-message, while in the other issue it gives a result that most likely is not correct. ", "Was able to reproduce the issue in colab with TF 2.1. With out using Numpy ,I am not facing any issue. Please find the [gist](https://colab.sandbox.google.com/gist/saikumarchalla/aa5e9834f9cca84bf3ab1e6b65d2b01f/untitled8.ipynb) here. Thanks!", "I also am getting the error `NotImplementedError: Cannot convert a symbolic Tensor (truediv_3:0) to a numpy array.`\r\nMy code is:\r\n\r\n```\r\nbatch_size = 250\r\nlatent_space_depth = 128\r\n\r\ndef sample_z(args):\r\n    z_mean, z_log_var = args\r\n    eps = K.random_normal(shape=(batch_size, latent_space_depth), mean=0., stddev=1.)\r\n    return z_mean + K.exp(z_log_var / 2) * eps\r\ndef VariationalAutoEncoder(num_pixels):\r\n    \r\n    input_img = Input(shape=(32, 32, 1))\r\n\r\n    channels = 4\r\n    x = input_img\r\n    for i in range(5):\r\n        left = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\r\n        right = Conv2D(channels, (2, 2), activation='relu', padding='same')(x)\r\n        conc = Concatenate()([left, right])\r\n        x = MaxPooling2D((2, 2), padding='same')(conc)\r\n        channels *= 2\r\n\r\n    x = Dense(channels)(x)\r\n    encoder_hidden = Flatten()(x)\r\n\r\n    z_mean = Dense(latent_space_depth, activation='linear')(encoder_hidden)\r\n    z_log_var = Dense(latent_space_depth, activation='linear')(encoder_hidden)\r\n    \r\n    def KL_loss(y_true, y_pred):\r\n        return 0.0001 * K.sum(K.exp(z_log_var) + K.square(z_mean) - 1 - z_log_var, axis=1)\r\n\r\n    def reconstruction_loss(y_true, y_pred):\r\n        y_true = K.batch_flatten(y_true)\r\n        y_pred = K.batch_flatten(y_pred)\r\n        return binary_crossentropy(y_true, y_pred)\r\n\r\n    def total_loss(y_true, y_pred):\r\n        return reconstruction_loss(y_true, y_pred) + KL_loss(y_true, y_pred)\r\n\r\n    z = Lambda(sample_z, output_shape=(latent_space_depth, ))([z_mean, z_log_var])\r\n    decoder_in = Input(shape=(latent_space_depth,))\r\n\r\n    d_x = Reshape((1, 1, latent_space_depth))(decoder_in)\r\n    e_x = Reshape((1, 1, latent_space_depth))(z)\r\n    for i in range(5):\r\n        conv = Conv2D(channels, (3, 3), activation='relu', padding='same')\r\n        upsampling = UpSampling2D((2, 2))\r\n        d_x = conv(d_x)\r\n        d_x = upsampling(d_x)\r\n        e_x = conv(e_x)\r\n        e_x = upsampling(e_x)\r\n        channels //= 2\r\n\r\n    final_conv = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\r\n    auto_decoded = final_conv(e_x)\r\n    decoder_out = final_conv(d_x)\r\n    \r\n    decoder = Model(decoder_in, decoder_out)    \r\n    \r\n    auto_encoder = Model(input_img, auto_decoded)\r\n\r\n    auto_encoder.compile(optimizer=Adam(lr=0.001), \r\n                         loss=total_loss,\r\n                         metrics=[KL_loss, reconstruction_loss])\r\n    \r\n    return auto_encoder, decoder\r\n\r\nvar_auto_encoder, decoder = VariationalAutoEncoder(32)\r\nvar_auto_encoder.summary()\r\n\r\ndef truncate_to_batch(x):\r\n    l = x.shape[0]\r\n    return x[:l - l % batch_size, :, :, :]\r\n\r\nx_train_trunc = truncate_to_batch(x_train)\r\nx_test_trunc = truncate_to_batch(x_test)\r\nx_train_trunc.shape, x_test_trunc.shape\r\n\r\nimport tensorflow as tf\r\ntf.config.experimental_run_functions_eagerly(True)\r\nvar_auto_encoder.fit(x_train_trunc, x_train_trunc, verbose=1, \r\n                 batch_size=batch_size, epochs=100,\r\n                 validation_data=(x_test_trunc, x_test_trunc))\r\n```\r\nMy calculations of loss use K, not numpy\r\n\r\nThe actual trace is:\r\n```\r\nTrain on 6500 samples, validate on 1000 samples\r\nEpoch 1/100\r\n 250/6500 [>.............................]\r\n\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in on_epoch(self, epoch, mode)\r\n    766     try:\r\n--> 767       yield epoch_logs\r\n    768     finally:\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    341                 training_context=training_context,\r\n--> 342                 total_epochs=epochs)\r\n    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    180       cbks.make_logs(model, batch_logs, batch_outs, mode)\r\n--> 181       step += 1\r\n    182 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/contextlib.py in __exit__(self, type, value, traceback)\r\n    118             try:\r\n--> 119                 next(self.gen)\r\n    120             except StopIteration:\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in on_batch(self, step, mode, size)\r\n    788               mode, 'end', step, batch_logs)\r\n--> 789           self.progbar.on_batch_end(step, batch_logs)\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py in on_batch_end(self, batch, logs)\r\n    780     if self.verbose and (self.target is None or self.seen < self.target):\r\n--> 781       self.progbar.update(self.seen, self.log_values)\r\n    782 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py in update(self, current, values)\r\n    558         if isinstance(self._values[k], list):\r\n--> 559           avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\r\n    560           if abs(avg) > 1e-3:\r\n\r\n<__array_function__ internals> in mean(*args, **kwargs)\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/fromnumeric.py in mean(a, axis, dtype, out, keepdims)\r\n   3334     return _methods._mean(a, axis=axis, dtype=dtype,\r\n-> 3335                           out=out, **kwargs)\r\n   3336 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/_methods.py in _mean(a, axis, dtype, out, keepdims)\r\n    134 def _mean(a, axis=None, dtype=None, out=None, keepdims=False):\r\n--> 135     arr = asanyarray(a)\r\n    136 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/_asarray.py in asanyarray(a, dtype, order)\r\n    137     \"\"\"\r\n--> 138     return array(a, dtype, copy=False, order=order, subok=True)\r\n    139 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __array__(self)\r\n    727     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\r\n--> 728                               \" array.\".format(self.name))\r\n    729 \r\n\r\nNotImplementedError: Cannot convert a symbolic Tensor (truediv_1:0) to a numpy array.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-28-9bb14bc81d2b> in <module>\r\n      3 var_auto_encoder.fit(x_train_trunc, x_train_trunc, verbose=1, \r\n      4                  batch_size=batch_size, epochs=100,\r\n----> 5                  validation_data=(x_test_trunc, x_test_trunc))\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    395                       total_epochs=1)\r\n    396                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\r\n--> 397                                  prefix='val_')\r\n    398 \r\n    399     return model.history\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/contextlib.py in __exit__(self, type, value, traceback)\r\n    128                 value = type()\r\n    129             try:\r\n--> 130                 self.gen.throw(type, value, traceback)\r\n    131             except StopIteration as exc:\r\n    132                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in on_epoch(self, epoch, mode)\r\n    770         # Epochs only apply to `fit`.\r\n    771         self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n--> 772       self.progbar.on_epoch_end(epoch, epoch_logs)\r\n    773 \r\n    774   @tf_contextlib.contextmanager\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)\r\n    787         self.log_values.append((k, logs[k]))\r\n    788     if self.verbose:\r\n--> 789       self.progbar.update(self.seen, self.log_values)\r\n    790 \r\n    791 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py in update(self, current, values)\r\n    557         info += ' - %s:' % k\r\n    558         if isinstance(self._values[k], list):\r\n--> 559           avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\r\n    560           if abs(avg) > 1e-3:\r\n    561             info += ' %.4f' % avg\r\n\r\n<__array_function__ internals> in mean(*args, **kwargs)\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/fromnumeric.py in mean(a, axis, dtype, out, keepdims)\r\n   3333 \r\n   3334     return _methods._mean(a, axis=axis, dtype=dtype,\r\n-> 3335                           out=out, **kwargs)\r\n   3336 \r\n   3337 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/_methods.py in _mean(a, axis, dtype, out, keepdims)\r\n    133 \r\n    134 def _mean(a, axis=None, dtype=None, out=None, keepdims=False):\r\n--> 135     arr = asanyarray(a)\r\n    136 \r\n    137     is_float16_result = False\r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/numpy/core/_asarray.py in asanyarray(a, dtype, order)\r\n    136 \r\n    137     \"\"\"\r\n--> 138     return array(a, dtype, copy=False, order=order, subok=True)\r\n    139 \r\n    140 \r\n\r\n~/anaconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __array__(self)\r\n    726   def __array__(self):\r\n    727     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\r\n--> 728                               \" array.\".format(self.name))\r\n    729 \r\n    730   def __len__(self):\r\n`\r\nNotImplementedError: Cannot convert a symbolic Tensor (truediv_3:0) to a numpy array.`\r\n\r\n\r\n```\r\n\r\nAm I misreading the trace when the error seems to stem from `yield epoch_logs`", "In general, you can't mix NumPy and TF ops. But the error messages should be more informative, and we need to fix that.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36792\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36792\">No</a>\n", "This PR resolves the autograph warning.\r\n\r\nThere will be a subsequent PR to improve the error message a bit.", "- Hello , I am a beginner at keras\r\n- I am having the same error\r\n- here is the code\r\n```\r\ndef create_model(vocabulary_size, seq_len):\r\n    model = Sequential()\r\n    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\r\n    model.add(LSTM(50, return_sequences=True,input_shape=(1, 1)))\r\n    model.add(LSTM(50))\r\n    model.add(Dense(50, activation='relu'))\r\n\r\n    model.add(Dense(vocabulary_size, activation='softmax'))\r\n    \r\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n   \r\n    model.summary()\r\n    \r\n    return model\r\n```\r\n\r\nHere is the error \r\n```\r\n---------------------------------------------------------\r\nNotImplementedError     Traceback (most recent call last)\r\n<ipython-input-148-0d748fa4f8c3> in <module>\r\n----> 1 model = create_model(vocabulary_size+1,seq_len)\r\n      2 #vocabulary_Size is nuber of unqie words\r\n\r\n<ipython-input-147-162603b5f80b> in create_model(vocabulary_size, seq_len)\r\n      2     model = Sequential()\r\n      3     model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\r\n----> 4     model.add(LSTM(50, return_sequences=True,input_shape=(1, 1)))\r\n      5     model.add(LSTM(50))\r\n      6     model.add(Dense(50, activation='relu'))\r\n\r\n\r\n....\r\n\r\nNotImplementedError: Cannot convert a symbolic Tensor (lstm_5/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n\r\n\r\n```\r\n\r\n- Please tell me, how can i correct it ?", "Just use pytorch. Tensorflow and keras dont go well together", "@rohan2734 could you include the few bottom frames in the error message? The top ones are not very informative.", "> @rohan2734 could you include the few bottom frames in the error message? The top ones are not very informative.\r\n\r\n```\r\nNotImplementedError: Cannot convert a symbolic Tensor (lstm_5/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n- These are the bottom most lines of error\r\n\r\n@hockman1 sir, I was doing NLP , and i was working with spacy and keras, not tensorflow actually\r\n", "That's the error message. There are no stack trace lines above it, that indicate the actual code which generated the error? Note that ipython might truncate the full stack trace.\r\n\r\nAlso, I recommend asking the question in the spacy support forums as well.\r\n\r\nFor example, if I write this:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef f():\r\n  return np.add(tf.constant(1), 1)\r\n\r\nf()\r\n```\r\n\r\nI get this error message:\r\n\r\n```\r\n... other stack frames ...\r\n\r\nNotImplementedError: in user code:\r\n\r\n    <ipython-input-2-b543a3f722c0>:6 f  *\r\n        return np.add(tf.constant(1), 1)               <-----------  *** this is what we're looking for ***\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:855 __array__  **\r\n        \" a NumPy call, which is not supported\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (Const:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```", "I faced this problem with TF version 2.4\r\nMoved back to TF version 2.3\r\nNo longer facing this issue.", "> I faced this problem with TF version 2.4\r\n> Moved back to TF version 2.3\r\n> No longer facing this issue.\r\n\r\n@anuragbhatia1980  That didn't work in my case! I have downgraded numpy to 1.9 as well! this the error traces I get:NotImplementedError                       Traceback (most recent call last)\r\n\r\n<ipython-input-158-ef99b450fe96> in <module>\r\n      6     callbacks=callbacks,\r\n      7     validation_data=valid_dataloader,\r\n----> 8     validation_steps=len(valid_dataloader),\r\n      9 )\r\n     10 \r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n-> 1100                 context.async_wait()\r\n   1101               logs = tmp_logs  # No error, now safe to assign to logs.\r\n   1102               end_step = step + data_handler.step_increment\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826       # interestingly an exception was raised) so we no longer need a lock.\r\n    827       self._lock.release()\r\n--> 828 \r\n    829     if self._created_variables:\r\n    830       try:\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    869               \"The reason this crashes is that @tf.function annotated\"\r\n    870               \" function returns a **`tf.Tensor`** with the **value** of the\"\r\n--> 871               \" variable when the function is called rather than the\"\r\n    872               \" variable instance itself. As such there is no code holding a\"\r\n    873               \" reference to the `v` created inside the function and Python\"\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    724     return f\r\n    725 \r\n--> 726   def _decorate(self, decorator):\r\n    727     \"\"\"Allows the captured Python function to be decorated in place.\r\n    728 \r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2967       # an instance-specific `Function` that uses a weak reference to the\r\n   2968       # instance (so that the instance will be correctly gc'd).\r\n-> 2969 \r\n   2970       # And finally add the wrapped function to the description cache\r\n   2971       self._descriptor_cache[instance] = class_method_to_instance_method(\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3359   outer graph otherwise.\r\n   3360 \r\n-> 3361   _Input Signatures_\r\n   3362 \r\n   3363   By default, `F = tf.contrib.eager.defun(f)` instantiates a separate graph\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3204       # 1. shape relaxation is explicitly enabled\r\n   3205       # and 2. there's no provided input signature\r\n-> 3206       # and 3. there's been a cache miss for this calling context\r\n   3207       if (self._experimental_relax_shapes\r\n   3208           and self.input_signature is None\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n    989       # TensorArrays and `None`s.\r\n--> 990       func_outputs = nest.map_structure(convert, func_outputs,\r\n    991                                         expand_composites=True)\r\n    992 \r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    632 \r\n    633     if self._implements is not None:\r\n--> 634       attributes = self._create_implements_attribute()\r\n    635 \r\n    636     share = self._shared_rendezvous\r\n\r\n~/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975               raise\r\n    976 \r\n--> 977         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n    978         # to be accurate.\r\n    979         converted_func = tf_decorator.make_decorator(original_func, wrapper)\r\n\r\nNotImplementedError: in user code:\r\n\r\n    /home/navid/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /home/navid/Python/CGG/segmentation_models/segmentation_models/base/objects.py:114 __call__  *\r\n        return self.l1(gt, pr) + self.l2(gt, pr)\r\n    /home/navid/Python/CGG/segmentation_models/segmentation_models/losses.py:97 __call__  *\r\n        pr,\r\n    /home/navid/Python/CGG/segmentation_models/segmentation_models/base/functional.py:150 f_score  *\r\n        score = average(score, per_image, class_weights, **kwargs)\r\n    /home/navid/Python/CGG/segmentation_models/segmentation_models/base/functional.py:53 average  *\r\n        x = x * class_weights\r\n    /home/navid/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1175 binary_op_wrapper\r\n        del binary_op_wrapper_sparse\r\n    /home/navid/.virtualenvs/CGG/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:855 __array__\r\n        @staticmethod\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (dice_loss_plus_1focal_loss/truediv:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n\r\n", "@NavidCOMSC the stack trace suggests that at this line: `x = x * class_weights` `x` is a NumPy array, but `class_weights` is a `Tensor` - in tf.function, tensors and numpy arrays don't mix well. Can you check if that's the case? Also, when you train the model, what is your input?\r\n\r\nAlternatively, you may be able run everything eagerly by calling `tf.config.experimental_run_functions_eagerly` (or `tf.config.run_functions_eagerly` in newer versions). That may be slower and will not let you save models, but perhaps you don't need that.", "I am running the new apple native tensorflow package 2.4, and ran into a problem I did not have before. Here is the error stack:\r\n\r\n```\r\nNotImplementedError: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-20-73358e637fe3> in <module>\r\n      4 model = Sequential()\r\n      5 model.add(Embedding(vocab_size+1, W2V_SIZE, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\r\n----> 6 model.add(LSTM(500, dropout=0.2, recurrent_dropout=0.2))\r\n      7 model.add(Dense(units = 10000, kernel_initializer = 'glorot_uniform', activation = 'relu'))\r\n      8 model.add(Dropout(0.35))\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    515     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    516     try:\r\n--> 517       result = method(self, *args, **kwargs)\r\n    518     finally:\r\n    519       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    221       # If the model is being built continuously on top of an input layer:\r\n    222       # refresh its output.\r\n--> 223       output_tensor = layer(self.outputs[0])\r\n    224       if len(nest.flatten(output_tensor)) != 1:\r\n    225         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\r\n    658 \r\n    659     if initial_state is None and constants is None:\r\n--> 660       return super(RNN, self).__call__(inputs, **kwargs)\r\n    661 \r\n    662     # If any of `initial_state` or `constants` are specified and are Keras\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    944     # >> model = tf.keras.Model(inputs, outputs)\r\n    945     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n--> 946       return self._functional_construction_call(inputs, args, kwargs,\r\n    947                                                 input_list)\r\n    948 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n   1083           layer=self, inputs=inputs, build_graph=True, training=training_value):\r\n   1084         # Check input assumptions set after layer building, e.g. input shape.\r\n-> 1085         outputs = self._keras_tensor_symbolic_call(\r\n   1086             inputs, input_masks, args, kwargs)\r\n   1087 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)\r\n    815       return nest.map_structure(keras_tensor.KerasTensor, output_signature)\r\n    816     else:\r\n--> 817       return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n    818 \r\n    819   def _infer_output_signature(self, inputs, args, kwargs, input_masks):\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)\r\n    856           # TODO(kaftan): do we maybe_build here, or have we already done it?\r\n    857           self._maybe_build(inputs)\r\n--> 858           outputs = call_fn(inputs, *args, **kwargs)\r\n    859 \r\n    860         self._handle_activity_regularization(inputs, outputs)\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)\r\n   1161     # LSTM does not support constants. Ignore it during process.\r\n   1162     orig_initial_state = initial_state\r\n-> 1163     inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n   1164 \r\n   1165     if isinstance(mask, list):\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _process_inputs(self, inputs, initial_state, constants)\r\n    857         initial_state = self.states\r\n    858     elif initial_state is None:\r\n--> 859       initial_state = self.get_initial_state(inputs)\r\n    860 \r\n    861     if len(initial_state) != len(self.states):\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in get_initial_state(self, inputs)\r\n    640     dtype = inputs.dtype\r\n    641     if get_initial_state_fn:\r\n--> 642       init_state = get_initial_state_fn(\r\n    643           inputs=None, batch_size=batch_size, dtype=dtype)\r\n    644     else:\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in get_initial_state(self, inputs, batch_size, dtype)\r\n   2504 \r\n   2505   def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n-> 2506     return list(_generate_zero_filled_state_for_cell(\r\n   2507         self, inputs, batch_size, dtype))\r\n   2508 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype)\r\n   2985     batch_size = array_ops.shape(inputs)[0]\r\n   2986     dtype = inputs.dtype\r\n-> 2987   return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n   2988 \r\n   2989 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _generate_zero_filled_state(batch_size_tensor, state_size, dtype)\r\n   3001 \r\n   3002   if nest.is_nested(state_size):\r\n-> 3003     return nest.map_structure(create_zeros, state_size)\r\n   3004   else:\r\n   3005     return create_zeros(state_size)\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n    657 \r\n    658   return pack_sequence_as(\r\n--> 659       structure[0], [func(*x) for x in entries],\r\n    660       expand_composites=expand_composites)\r\n    661 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n    657 \r\n    658   return pack_sequence_as(\r\n--> 659       structure[0], [func(*x) for x in entries],\r\n    660       expand_composites=expand_composites)\r\n    661 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in create_zeros(unnested_state_size)\r\n   2998     flat_dims = tensor_shape.TensorShape(unnested_state_size).as_list()\r\n   2999     init_state_size = [batch_size_tensor] + flat_dims\r\n-> 3000     return array_ops.zeros(init_state_size, dtype=dtype)\r\n   3001 \r\n   3002   if nest.is_nested(state_size):\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in wrapped(*args, **kwargs)\r\n   2817 \r\n   2818   def wrapped(*args, **kwargs):\r\n-> 2819     tensor = fun(*args, **kwargs)\r\n   2820     tensor._is_zeros_tensor = True\r\n   2821     return tensor\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)\r\n   2866           # Create a constant if it won't be very big. Otherwise create a fill\r\n   2867           # op to prevent serialized GraphDefs from becoming too large.\r\n-> 2868           output = _constant_if_small(zero, shape, dtype, name)\r\n   2869           if output is not None:\r\n   2870             return output\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in _constant_if_small(value, shape, dtype, name)\r\n   2802 def _constant_if_small(value, shape, dtype, name):\r\n   2803   try:\r\n-> 2804     if np.prod(shape) < 1000:\r\n   2805       return constant(value, shape=shape, dtype=dtype, name=name)\r\n   2806   except TypeError:\r\n<__array_function__ internals> in prod(*args, **kwargs)\r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/numpy/core/fromnumeric.py in prod(a, axis, dtype, out, keepdims, initial, where)\r\n   3028     10\r\n   3029     \"\"\"\r\n-> 3030     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n   3031                           keepdims=keepdims, initial=initial, where=where)\r\n   3032 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)\r\n     85                 return reduction(axis=axis, out=out, **passkwargs)\r\n     86 \r\n---> 87     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n     88 \r\n     89 \r\n~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __array__(self)\r\n    850 \r\n    851   def __array__(self):\r\n--> 852     raise NotImplementedError(\r\n    853         \"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\r\n    854         \" This error may indicate that you're trying to pass a Tensor to\"\r\nNotImplementedError: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n\r\nI know that this was OK before this apple native version of tf2.4. any suggestions?", "> I am running the new apple native tensorflow package 2.4, and ran into a problem I did not have before. Here is the error stack:\r\n> \r\n> ## NotImplementedError: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n> NotImplementedError Traceback (most recent call last)\r\n\r\n\r\nI have the same error with tf.2.4.1, numpy1.20.1 at the following codes\r\n```python\r\n# at __init__()\r\nsingle_layer = layers.GRU(rnn_units, return_state=False)\r\nself.rnn = layers.Bidirectional(single_layer, name='bigru')\r\n# at call()\r\nx = self.rnn(x, training=training)\r\n```\r\nWhen I run the same code at a CPU-only machine,  It works well. But I run at GPU server, it  thorw this Error.\r\nMy CPU-only machine works well with tf2.4.1 and numpy1.19.4, and after I update numpy to 1.20.1, the same error occurs. So, there is any imcompatible between TF2.4.1 and numpy1.20.1", "Please file a new issue for these errors. Since it's unclear whether they're related to the original bug, they need separate triage.", "Dan, do you mean I repost this again where? I posted this in stack\noverflow, is it the place you want me to post it?\nThanks\nTom\n\nOn Mon, Mar 29, 2021 at 9:33 AM Dan Moldovan ***@***.***>\nwrote:\n\n> Please file a new issue for these errors. Since it's unclear whether\n> they're related to the original bug, they need separate triage.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36792#issuecomment-809380531>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AO3IBUK53PRKXB6MVVJPQSTTGB6TBANCNFSM4KWBU2CA>\n> .\n>\n\n\n-- \nTom Xu\n", "StackOverflow is fine. But if it's a bug and you need to repost it here, it'e best done as a new issue.", "> When I run the same code at a CPU-only machine, It works well. But I run at GPU server, it thorw this Error.\r\n\r\n@caixxiong exactly the same here! windows with gpu, get this error. linux with cpu, goes fine. i am using the exact same files on both.", "I have the same issue.  \r\n\r\nPlease see: https://github.com/tensorflow/tensorflow/issues/50353\r\n\r\n1. the tensorflow_mac repository has been archived, so I can't add an issue.\r\n2. the tensorflow_metal project (e.g. Tensorflow 2.5) gets an exception \r\nhttps://github.laobiao.workers.dev/tensorflow/tensorflow/issues/50541\r\nE.g. tensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 6): Symbol not found: _TF_AssignUpdateVariable\r\n\r\n```\r\n(tensorflow-metal) (base) davidlaxer@x86_64-apple-darwin13 notebooks % python test1.py \r\nTraceback (most recent call last):\r\n  File \"test1.py\", line 7, in <module>\r\n    from top2vec import Top2Vec\r\n  File \"/Users/davidlaxer/Top2Vec/top2vec/__init__.py\", line 1, in <module>\r\n    from top2vec.Top2Vec import Top2Vec\r\n  File \"/Users/davidlaxer/Top2Vec/top2vec/Top2Vec.py\", line 10, in <module>\r\n    import umap\r\n  File \"/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/umap_learn-0.5.1-py3.8.egg/umap/__init__.py\", line 7, in <module>\r\n    from .parametric_umap import ParametricUMAP\r\n  File \"/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/umap_learn-0.5.1-py3.8.egg/umap/parametric_umap.py\", line 13, in <module>\r\n    import tensorflow as tf\r\n  File \"/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/tensorflow/__init__.py\", line 449, in <module>\r\n    _ll.load_library(_plugin_dir)\r\n  File \"/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 154, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 6): Symbol not found: _TF_AssignUpdateVariable\r\n  Referenced from: /Users/davidlaxer/tensorflow-metal/lib/python3.8/site-packages/tensorflow-plugins/libmetal_plugin.dylib\r\n  Expected in: flat namespace\r\n```\r\n3. #505353 has gone 'stale'.", "Does tensorflow-metal and/or tensorflow-macos require OS X Monterey?", "Try making a new python environment and install tensorflow==2.4.0\r\n"]}, {"number": 36791, "title": "tflite save issue", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n2020-02-16 21:52:52.869005: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-02-16 21:52:52.869341: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-02-16 21:52:52.869351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-02-16 21:52:55.481557: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.497984: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.498578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.498607: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.499028: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.499052: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-02-16 21:52:55.499231: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: CombinedNonMaxSuppression\r\n2020-02-16 21:52:55.535714: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 735 operators, 1368 arrays (0 quantized)\r\n2020-02-16 21:52:55.561395: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 735 operators, 1368 arrays (0 quantized)\r\n2020-02-16 21:52:56.057040: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 284 operators, 533 arrays (0 quantized)\r\n2020-02-16 21:52:56.062129: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 284 operators, 533 arrays (0 quantized)\r\n2020-02-16 21:52:56.067209: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 284 operators, 533 arrays (0 quantized)\r\n2020-02-16 21:52:56.071019: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 284 operators, 533 arrays (0 quantized)\r\n2020-02-16 21:52:56.073859: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 284 operators, 533 arrays (0 quantized)\r\n2020-02-16 21:52:56.083033: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 66560128 bytes, theoretical optimal value: 44408960 bytes.\r\n2020-02-16 21:52:56.083962: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 61503185\r\n2020-02-16 21:52:56.091894: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.\r\nTraceback (most recent call last):\r\n  File \"/home/kji/anaconda3/envs/py37_tf/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI don't know changing input size in tensorflow 2.1 tflite", "comments": ["@JaeinKim85, Can you provide the standalone code to replicate the reported issue. Thanks!", "@JaeinKim85 ,\r\nIf you are using the [Python converter](https://www.tensorflow.org/lite/convert/python_api), with the latest version of TF/TFLite (nightly maybe?) could you try adding the following line pre-conversion:\r\n\r\nconverter.experimental_new_converter = True\r\n\r\nIf that doesn't work, it looks like we don't support the op yet :-(. You could try using [Select TF ops](https://www.tensorflow.org/lite/guide/ops_select) if you are using our C++/Java APIs. Thanks!"]}, {"number": 36790, "title": "tf.keras.backend.set_floatx() causing ValueError (dtype conversion error) while computing tf.keras.metrics.*", "body": "**System information** - Have I written custom code on **Google Colab**: - \r\n**Code:**\r\n```\r\ntf.keras.backend.set_floatx('float64')\r\n\r\nmodel.compile(optimizer= Adam(learning_rate= 0.001, clipnorm=1.0, clipvalue=0.5),\r\n              loss={\r\n                  'class_output': BinaryCrossentropy(),\r\n                  'decoder_output': BinaryCrossentropy()\r\n              },\r\n              loss_weights=[0.5, 1.0],\r\n               metrics = {\r\n                  'class_output':[tf.metrics.Recall(), tf.metrics.Precision()],\r\n                  'decoder_output':[tf.metrics.Recall(), tf.metrics.Precision()],\r\n              }\r\n             ) \r\n```\r\n**Error:**\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1288       raise ValueError(\r\n   1289           \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n-> 1290           (dtype.name, value.dtype.name, value))\r\n   1291     return value\r\n   1292 \r\n\r\nValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics_6/class_output_recall_8/Sum:0' shape=(1,) dtype=float32>\r\n```\r\n\r\nOS Platform and Distribution : - \r\n```\r\nos.uname()\r\n>>> posix.uname_result(sysname='Linux', nodename='ed841897617b', release='4.14.137+', version='#1 SMP Thu Aug 8 02:47:02 PDT 2019', machine='x86_64')\r\n```\r\nTensorFlow installed from : - \r\n```!pip install tensorflow==2.10```\r\nTensorFlow version : - \r\n```\r\ntf.__version__\r\n>>> '2.1.0'\r\n```\r\nPython version: - \r\n```\r\n!python -V\r\n>>> Python 3.6.9\r\n```\r\n~~Bazel version :-  NA~~\r\n~~GCC/Compiler version : - NA~~  \r\n~~CUDA/cuDNN version: -  NA~~\r\n\r\nGPU model and memory:\r\n```\r\nfrom psutil import virtual_memory\r\nmem = virtual_memory()\r\nprint(mem.total / 1024**3, 'GB') # total physical memory available\r\n>>>12.717426300048828 GB\r\n````\r\n~~You can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`~~\r\n\r\n**Describe the current behavior**\r\nWhen using `tf.keras.backend.set_floatx('float64')` , whole tf should be set to float64, right ?\r\nBut the tf.metrics are not getting set as shown in the code above\r\n\r\n**Describe the expected behavior**\r\nAll of tf including tf.metrics should be calculated on the basis of tf.keras.backend.set_floatx('float64')\r\n\r\n**Code to reproduce the issue** \r\n```\r\nimport tensorflow as tf \r\n\r\ntf.keras.backend.set_floatx('float64')\r\n\r\nm = tf.keras.metrics.Recall()\r\nm.update_state([0, 1, 1, 1], [1, 0, 1, 1])\r\nprint('Final result: ', m.result().numpy())\r\n```\r\n\r\n**Other info / logs** ~~Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.~~\r\nStackTrace:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-30-86f79f751766> in <module>()\r\n      6               loss_weights=[0.5, 1.0],\r\n      7                metrics = {\r\n----> 8                   'class_output':[tf.metrics.Recall(), tf.metrics.Precision()],\r\n      9                 #  'decoder_output':[tf.metrics.Recall(), tf.metrics.Precision()],\r\n     10               }\r\n\r\n13 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    437           targets=self._targets,\r\n    438           skip_target_masks=self._prepare_skip_target_masks(),\r\n--> 439           masks=self._prepare_output_masks())\r\n    440 \r\n    441       # Prepare sample weight modes. List with the same length as model outputs.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)\r\n   2002           metric_results.extend(\r\n   2003               self._handle_per_output_metrics(self._per_output_metrics[i],\r\n-> 2004                                               target, output, output_mask))\r\n   2005         if return_weighted_and_unweighted_metrics or return_weighted_metrics:\r\n   2006           metric_results.extend(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)\r\n   1953       with K.name_scope(metric_name):\r\n   1954         metric_result = training_utils.call_metric_function(\r\n-> 1955             metric_fn, y_true, y_pred, weights=weights, mask=mask)\r\n   1956         metric_results.append(metric_result)\r\n   1957     return metric_results\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in call_metric_function(metric_fn, y_true, y_pred, weights, mask)\r\n   1153 \r\n   1154   if y_pred is not None:\r\n-> 1155     return metric_fn(y_true, y_pred, sample_weight=weights)\r\n   1156   # `Mean` metric only takes a single value.\r\n   1157   return metric_fn(y_true, sample_weight=weights)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in __call__(self, *args, **kwargs)\r\n    194     from tensorflow.python.keras.distribute import distributed_training_utils  # pylint:disable=g-import-not-at-top\r\n    195     return distributed_training_utils.call_replica_local_fn(\r\n--> 196         replica_local_fn, *args, **kwargs)\r\n    197 \r\n    198   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in call_replica_local_fn(fn, *args, **kwargs)\r\n   1133     with strategy.scope():\r\n   1134       return strategy.extended.call_for_each_replica(fn, args, kwargs)\r\n-> 1135   return fn(*args, **kwargs)\r\n   1136 \r\n   1137 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in replica_local_fn(*args, **kwargs)\r\n    177     def replica_local_fn(*args, **kwargs):\r\n    178       \"\"\"Updates the state of the metric in a replica-local context.\"\"\"\r\n--> 179       update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\r\n    180       with ops.control_dependencies([update_op]):\r\n    181         result_t = self.result()  # pylint: disable=not-callable\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in decorated(metric_obj, *args, **kwargs)\r\n     74 \r\n     75     with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):\r\n---> 76       update_op = update_state_fn(*args, **kwargs)\r\n     77     if update_op is not None:  # update_op will be None in eager execution.\r\n     78       metric_obj.add_update(update_op)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in update_state(self, y_true, y_pred, sample_weight)\r\n   1340         top_k=self.top_k,\r\n   1341         class_id=self.class_id,\r\n-> 1342         sample_weight=sample_weight)\r\n   1343 \r\n   1344   def result(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\r\n    438       update_ops.append(\r\n    439           weighted_assign_add(label, pred, weights_tiled,\r\n--> 440                               variables_to_update[matrix_cond]))\r\n    441 \r\n    442   return control_flow_ops.group(update_ops)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in weighted_assign_add(label, pred, weights, var)\r\n    414     if weights is not None:\r\n    415       label_and_pred *= weights\r\n--> 416     return var.assign_add(math_ops.reduce_sum(label_and_pred, 1))\r\n    417 \r\n    418   loop_vars = {\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py in assign_add(self, delta, use_locking, name, read_value)\r\n    783     with _handle_graph(self.handle), self._assign_dependencies():\r\n    784       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\r\n--> 785           self.handle, ops.convert_to_tensor(delta, dtype=self.dtype),\r\n    786           name=name)\r\n    787     if read_value:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1288       raise ValueError(\r\n   1289           \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n-> 1290           (dtype.name, value.dtype.name, value))\r\n   1291     return value\r\n   1292 \r\n\r\nValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics_6/class_output_recall_8/Sum:0' shape=(1,) dtype=float32>\r\n```\r\n", "comments": ["@MarkDaoust \r\nTagging you for escalation. Kindly excuse me if this is unprofessional.", "@Hemal-Mamtora Could you please confirm if the issue faced by you is similar to existing [issue](https://github.com/tensorflow/tensorflow/issues/33365)", "Yes, seems like TF 2.0 has issues with float 64\r\n\r\nTill when would this issue be resolved ?", "Hi @Hemal-Mamtora , \r\n\r\nI think you're right.\r\n\r\nIt looks like this is being caused by the mismatch of [metric.py recognizing `floatx`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/metrics.py#L146)  but [metric_utils.py casting directly to float32](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/metrics_utils.py#L427) .\r\n\r\n@pavithrasv, what's the right way to fix this?\r\n", "Thank you @MarkDaoust. It should be cast to the predictions' dtype. If anyone would like to work on the fix please feel free to send me a PR.", "Added a fix and test case in PR #39134 that will address this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36790\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36790\">No</a>\n"]}, {"number": 36789, "title": "image-utils", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@sushil579 We notice that nothing is filled in the template, please provide with stand alone code to replicate the issue faced by you with tensorflow version.\r\n", "@sushil579 Kindly update as per the above comment.", "@sushil579 \r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 36788, "title": "How to use tensorflow js on a nodejs server?", "body": "Hi everyone \ud83d\udc68\u200d\ud83d\udcbb, \r\nI would like to use the tensorflow js plugin with cocossd and mobilenet on the server side with nodejs.\r\nI've already done a script on the client side that works where when the user submits a form I run tfjs:\r\n```javascript\r\n\r\n    const img = new Image(100, 100);\r\n    img.src = //base64 encoded image\r\n    \r\n    // Load the model.\r\n    mobilenet.load().then(async model => {\r\n        const post_predictions = []; \r\n        model.classify(img).then(classify_predictions => {\r\n            classify_predictions.forEach(function(element){\r\n                const each_class = element[\"className\"].split(\", \")\r\n                each_class.forEach(function(this_element){\r\n                    post_predictions.push([this_element, (element.probability*100)]);\r\n                })\r\n            })\r\n            cocoSsd.load().then(model => {\r\n                // detect objects in the image.\r\n                model.detect(img).then(predictions => {\r\n                    predictions.forEach(function(this_element){\r\n                        post_predictions.unshift([this_element.class, (this_element.score*100)]);\r\n                    });\r\n                    post_predictions.sort(function(a, b) {\r\n                        return b[1]-a[1];\r\n                    });\r\n\r\n                    console.log(post_predictions)\r\n                });\r\n            })\r\n        });\r\n    });\r\n```\r\n\r\nI would like to do the same on the server side but I have node idea what modules require or how to load an image from it's base 64.\r\n\r\nI tried to download cocossd and mobilenet on my server with:\r\n\r\n> npm i @tensorflow-models/mobilenet\r\n\r\n> npm i @tensorflow-models/coco-ssd\r\n\r\nAnd then i tried to install tensorflow js for node with:\r\n\r\n> npm i @tensorflow/tfjs-node\r\n\r\nBut when i do :\r\n> npm i tensorflow\r\n\r\nI get this error :\r\n>npm ERR! code EBADPLATFORM\r\n\r\n>npm ERR! notsup Unsupported platform for tensorflow@0.7.0: wanted {\"os\":\"linux,darwin\",\"arch\":\"any\"} (current: {\"os\":\"win32\",\"arch\":\"x64\"})\r\n\r\n>npm ERR! notsup Valid OS:    linux,darwin\r\n\r\n>npm ERR! notsup Valid Arch:  any\r\n\r\n>npm ERR! notsup Actual OS:   win32\r\n\r\n>npm ERR! notsup Actual Arch: x64\r\n\r\n\r\n>npm ERR! A complete log of this run can be found in:\r\n\r\n>npm ERR!     C:\\Users\\johan\\AppData\\Roaming\\npm-cache\\_logs\\2020-02-16T05_27_15_276Z-debug.log\r\n\r\nPls someone help me \ud83d\ude4f\r\nThanks", "comments": ["@yo-png, Can you raise this issue on [Tensorflow js repository](https://github.com/tensorflow/tfjs/issues). ", "> @yo-png, Can you raise this issue on [Tensorflow js repository](https://github.com/tensorflow/tfjs/issues).\r\n\r\nYes I've already did that \ud83d\ude09\r\nThanks ", "@yo-png, Will close this issue. We can track the solution in Tf js repository. Thanks!"]}, {"number": 36787, "title": "  AttributeError: 'module' object has no attribute 'random_normal' ", "body": "\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-5-73592c5fe983> in <module>()\r\n----> 1 W=tf.Variable(initial_value=tf.random_normal(shape=(1,4),mean=100,stddev=0.35),name=\"W\")\r\n      2 b=tf.Variable(tf.zeros([4]),name=\"b\")\r\n\r\nAttributeError: 'module' object has no attribute 'random_normal'\r\n\r\n\r\ntf has no attribute 'random_normal' ?", "comments": ["@LGDHS Please provide with executable stand alone code to replicate this issue in our environment along with the version on tensorflow been used.", "I believe the library now uses `tf.random.normal()` instead of the older `tf.random_normal()`. Please replace the function and see if that works. I am assuming you are using TF2.0. Sharing here as I was also once stuck with this error to later realize the problem!\r\n\r\nHTH", "@LGDHS please confirm if the above comment helps", "I confirm @SivamPillai 's  solution above. Replace the \"`_`\" with a \"`.`\".\r\n```bash\r\n$ python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\ntf.Tensor(-1584.1108, shape=(), dtype=float32)\r\n```", "As the solution above helps, moving this issue to closed status."]}, {"number": 36786, "title": "Add \"See also\"  references", "body": "This is sort of a follow up to #33756. The TF docs have undergone huge improvements over the last couple months. However, one thing I really like about the PyTorch docs which is still (mostly) missing in the TF docs are \"**See also**\"  references.\r\n\r\nA lot of functions have similar or related functionality. Examples include:\r\n\r\n1. `tf.split`, `tf.unstack`\r\n2. `tf.size`, `tf.shape`\r\n3. `tf.repeat`, `tf.concat`, `tf.tile`, `tf.stack`\r\n4. `tf.exp`, `tf.math.log`\r\n5. `tf.keras.layers.MaxPool2D`, `tf.nn.max_pool2d `\r\n6. `tf.ones`, `tf.ones_like` and `tf.zeros`, `tf.zeros_like`\r\n\r\njust to name a few.\r\n\r\nOften people happen to find one and start using it regularly but remain unaware of the others for quite a while. Even if I do know about all of them, I often find myself wanting to compare the signature of similar functions to find the one most suitable to the current use case. In those cases, it takes way too many clicks to get from one to the other(s).\r\n\r\nIn short, would be great if the docs referenced related content. That should help guide people to use the best tool for the job right from the start.", "comments": ["I look forward to do this task but i need some guide how to do this. I am a beginner.\r\n", "I agree, it would be beneficial to let the user explore the documentations more by finding relevant searches for the user. \r\nPull requests have been made as per above. I suggest keeping this issue open so other contributors can suggest other additions as well ( other 'see also' references ) because I'm plenty sure there are more out there.", "Adding on the list.\r\n7. ``` tf.math.multiply ```, ``` tf.math.scalar_mul ```", "@janosh \r\nIs this still an issue?", "I'd say the situation has markedly improved but browsing quickly through the docs, there are some references I listed above that haven't been added yet. Of course it's up to you to decide if you want to have those or not. Missing are\r\n\r\n4. `tf.exp`, `tf.math.log`\r\n5. `tf.keras.layers.MaxPool2D`, `tf.nn.max_pool2d `\r\n7. `tf.math.multiply`, `tf.math.scalar_mul` (added by @abhinavsp0730)\r\n\r\nwhich I agree are less important than, say, `tf.repeat`, `tf.concat`, `tf.tile`, `tf.stack`. So feel free to close this if all the references you want are there.", "Thanks to everyone who's submitted PRs for this!\r\n\r\nWe always encourage authors to add these, it's on our internal quality checklists.\r\n\r\nIf you have anymore PRs please send them to me for review. \r\n\r\nBut we don't need to keep this bug open."]}, {"number": 36785, "title": "TF 2.1/tf.keras AdaDelta optimizer: default epsilon and learning rate values", "body": "Hi @tanzhenyu @lamberta @dynamicwebpaige There are two param default values for AdaDelta that look different from the original implementation. It is probably explained in past discussions (and if it is the case pls let me know where I can find it so we can close this issue.) Cheers.\r\n\r\nSimilar issues: https://github.com/tensorflow/tensorflow/issues/31024 and https://github.com/tensorflow/tensorflow/pull/31025.\r\n\r\nTF 2.1 [API docs for the Adadelta optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta) come from [`/optimizer-v2/`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adadelta.py), where: \r\n- The learning rate is set to 0.001:\r\n  - Keras' implementation states that learning rate is 1.\r\n  - [`optimizer.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.py) (v1) sets it to 1 (synced with Keras, I suppose).\r\n  - There's a Keras PR - https://github.com/keras-team/keras/pull/12841 - that proposed to change the LR from 1 to 0.001. It may have been reverted back to 1 (see commit https://github.com/keras-team/keras/pull/12888/commits/2009cab5217a57bfbb4dae88371640ce1bb4a0e9).\r\n- The default epsilon does not match the one in the original AdaDelta [paper](https://arxiv.org/pdf/1212.5701.pdf) as well as Keras' implementation:\r\n  - They use `1e-6` instead of `1e-7` (`\"Setting the hyperparameters to \u03b5 = 1e \u2212 6 and \u03c1 = 0.95...\"`).\r\n\r\nSources: \r\n\r\n- [TF 2.1 /optimizer_v2/](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adadelta.py):\r\n\r\n```python\r\n@keras_export('keras.optimizers.Adadelta')\r\nclass Adadelta(optimizer_v2.OptimizerV2):\r\n  ...\r\n  def __init__(self,\r\n               learning_rate=0.001,\r\n               rho=0.95,\r\n               epsilon=1e-7,\r\n               name='Adadelta',\r\n               **kwargs):\r\n```\r\n\r\n- [TF 2.1 optimizers.py - version 1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.py):\r\n\r\n```python\r\nclass Adadelta(Optimizer):\r\n...\r\n  def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0., **kwargs):\r\n...\r\n```\r\n\r\n- [Keras optimizers.py](https://github.com/keras-team/keras/blob/master/keras/optimizers.py):\r\n```python\r\nclass Adadelta(Optimizer):\r\n...\r\n    def __init__(self, learning_rate=1.0, rho=0.95, **kwargs):\r\n...\r\n```\r\n\r\nThanks for taking your time to look at this potential issue.", "comments": ["Hi @8bitmp3 , I also had a similar doubt when I came across the paper and the API documentation. I think according to the paper,the step size converges to 1 at end of training and the convergence occurs when the gradients and parameters updates are smaller. However there is a mismatch in the documentation which suggests that lr=0.001 whereas in the paper it is lr=1.0 and epsilon=1e-6. The less the LR I think it would be locally stuck in minima and not contribute significantly .", "Hi @8bitmp3 ,@gadagashwini, Have made a comment in the  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adadelta.py \r\nThe comment states the original details as mentioned in the paper with LR 1 and epsilon 1e-6.\r\n PR #36832 ", "@8bitmp3 I checked that @abhilash1910 PR https://github.com/tensorflow/tensorflow/pull/36849 got merged and I also reviewed that `AddaDelta` in `keras-team/keras` and `tf.keras` are in sync.\r\n\r\n[Here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta?version=nightly) is the TF page on `AdaDelta` with the update.\r\n\r\n[Here](https://github.com/keras-team/keras/blob/master/keras/optimizer_v2/adadelta.py) is the link to `AddaDelta` in `keras-team/keras`.\r\n```\r\n  def __init__(self,\r\n               learning_rate=0.001,\r\n               rho=0.95,\r\n               epsilon=1e-7,\r\n               name='Adadelta',\r\n               **kwargs):\r\n```\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "Thank you @jvishnuvardhan @lamberta \r\n\r\n`learning_rate=0.001`, `epsilon=1e-7`\r\n\r\n\ud83d\udc4d Closing the issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36785\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36785\">No</a>\n"]}, {"number": 36784, "title": "Allow overriding `_validate_state_spec` in RNN [Feature Request]", "body": "We are allowed to define `get_initial_state()` for initializing custom states, but not for validating them; I have a scalar hidden state, which raises an exception per `flat_state_spec[i].shape[1:]` (it assumes a 2D+ tensor). Below modification resolves it, but isn't really a workaround since it [modifies](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L586) the parent class for all RNNs - so TF can either include such scalar handling, or enable method overriding.\r\n\r\n```python\r\n# ...\r\nfor i in range(len(flat_cell_state_size)):\r\n  state_spec_shape = flat_state_spec[i].shape\r\n  if len(state_spec_shape) == 1 and not (tensor_shape.TensorShape(\r\n    # Check scalar case first\r\n    state_spec_shape[0]).is_compatible_with(\r\n        tensor_shape.TensorShape(flat_cell_state_size[i]))):\r\n    raise validation_error\r\n  elif not tensor_shape.TensorShape(\r\n    # Ignore the first axis for init_state which is for batch\r\n    state_spec_shape[1:]).is_compatible_with(\r\n        tensor_shape.TensorShape(flat_cell_state_size[i])):\r\n    raise validation_error\r\n```", "comments": ["Err, IDE fault - it _is_ overridable.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36784\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36784\">No</a>\n"]}, {"number": 36783, "title": "tensorflow-1.14 and tensorflow1.15, avx512f does no performance improvements than avx2", "body": "HI :\r\n    I run a model use tensorflow-1.14 compiled with avx2, avx512f , and found that: avx512 does no performance improvements than avx2. The timeline of avx2 or avx512f were the same as below. MatMul is most expensive op.\r\n\r\nMachine A:\r\navx512 CPU: Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz\r\navx512 compile command: \r\nbazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 --copt=-mavx512f --copt=-mavx512cd --copt=-mavx512dq --copt=-mavx512bw --copt=-mavx512vl . \r\ngcc version: 7.3.0\r\n\r\nMachine B:\r\navx2 CPU: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz\r\navx2 compile command:\r\nbazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 \r\ngcc version: 4.8.5\r\n    \r\n![image](https://user-images.githubusercontent.com/10751631/74588331-6d464800-5036-11ea-80dc-dd26b71e0f25.png)\r\n\r\n\r\n", "comments": ["@haolujun In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "I think MatMul is most expensive op, and most people say that avx512 can improve the float-mul operation than avx2 two times . But In my case, that not work.", "@rmlarsen, who would be the best person to investigate this?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 36782, "title": "Unable to package tensorflow with Py2App", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: Yes, installed in a virtualenv using pip\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\nOn running an executable that was packaged using Py2App, the executable throws the following error: \r\n\r\n```\r\nFile \"/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/aftershoot.py\", line 4, in <module>\r\n    import asexposure.ASExposure as Exposure\r\n  File \"asexposure/ASExposure.pyc\", line 1, in <module>\r\n  File \"/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow/__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\nModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package\r\n```\r\nUpon looking into the line of code causing this issue, it looks like `tensorflow_core`'s `init.py` is trying to import `module_util` from `tensorflow.python.tools`. However, isnide my site-packages,  there's northing inside the package named `tensorflow`. Instead the package above `python.tools` exists inside `tensorflow_core`.\r\n\r\nHere's a screenshot showcasing this: \r\n\r\n<img width=\"626\" alt=\"Screenshot 2020-02-15 at 6 06 56 PM\" src=\"https://user-images.githubusercontent.com/47669588/74587897-20567780-501e-11ea-9ff1-91b268c2a160.png\">\r\n\r\nAs you can see here, python folder is inside tensorflow_core, but the init.py tries to refer it from tensorflow.\r\n<img width=\"817\" alt=\"Screenshot 2020-02-15 at 6 07 52 PM\" src=\"https://user-images.githubusercontent.com/47669588/74587901-264c5880-501e-11ea-9814-63e8d9ded432.png\">\r\n\r\nIs this a known issue? And if so, is there a way to fix this?", "comments": ["Apologies for the delay in response. Is this still an issue? You may refer this [thread](https://github.com/tensorflow/tensorflow/issues/34722)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36782\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36782\">No</a>\n"]}, {"number": 36781, "title": "Blas GEMM launch failed", "body": "- Have I written custom code: yes\r\n- OS Platform and Distribution: ubuntu 18.04\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 2.1.0 (TensorFlow-GPU)\r\n- Keras version: 2.3.1\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: Cuda 10.1 / cuDNN 7.6.4\r\n- GPU model and memory: Tesla K80 with 11441MiB Memory\r\n\r\n**Describe the current behavior**\r\n\r\nOn an AWS p2.xlarge instance, when calling `model.fit` on a TF model with GPU support activated, the process crashes with the following error message:\r\n\r\n```\r\nInternalError:  Blas GEMM launch failed : a.shape=(32, 116032), b.shape=(116032, 256), m=32, n=256, k=116032\r\n\t [[node dense_1/MatMul (defined at /home/ubuntu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_1645]\r\n\r\nFunction call stack:\r\nkeras_scratch_graph\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nWhen calling `model.fit`, the model would simply train normally like it does when using a CPU.\r\n\r\n**Code to reproduce the issue**\r\n\r\nRun a p2.xlarge instance on AWS\r\nInstall all the GPU-related requirements as per https://www.tensorflow.org/install/gpu\r\nCreate a basic Sequential model with Keras (TF backend)\r\nCompile the model (this runs fine)\r\nCall `model.fit` on some training data\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nLogs of the error:\r\n```\r\n2020-02-15 11:07:22.795814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10770 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n2020-02-15 11:07:27.168747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-15 11:07:27.169206: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.169297: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.169377: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170036: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170106: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170242: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170302: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170533: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.170593: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:27.180263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-15 11:07:28.554099: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:28.709952: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:28.808561: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:28.820285: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-02-15 11:07:28.820399: W tensorflow/stream_executor/stream.cc:2041] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\n2020-02-15 11:07:28.820463: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: Blas GEMM launch failed : a.shape=(32, 116032), b.shape=(116032, 256), m=32, n=256, k=116032\r\n```\r\n\r\nThis is the output of `nvidia-smi` **before** calling `model.compile()`:\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   45C    P0    74W / 149W |      0MiB / 11441MiB |    100%      Default |   <<<--- 0% Memory usage\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |   <<<--- nothing running\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nAnd the output of `nvidia-smi` **after** calling `model.compile()` (and immediately before `model.fit()`):\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   45C    P0    72W / 149W |  10942MiB / 11441MiB |      0%      Default |   <<<--- 96% Memory usage\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1811      C   /usr/bin/python3                           10929MiB |   <<<--- TF model here\r\n+-----------------------------------------------------------------------------+\r\n```", "comments": ["@JivanRoquet Please refer to this [link](https://github.com/tensorflow/tensorflow/issues/11812) and [this link](https://github.com/tensorflow/tensorflow/issues/35029), let us know if this helps resolve your issue.", "@Saduf2019 already went through it. It doesn\u2019t solve anything.", "From the logs it looks like `cublasCreate` is failing with `CUBLAS_STATUS_NOT_INITIALIZED`.  NVIDIA's  docs says this means \"the CUDA\u2122 Runtime initialization failed\" but I'm not sure how to debug past that.  If you have the full logs can you please attach them?  Maybe we'll be able to spot a red flag there.", "i am also experiencing the same error and the linked solutions did not resolve the issue\r\n\r\nedit: this post allowed me to resolve the issue https://github.com/tensorflow/tensorflow/issues/9489#issuecomment-562394257", "The problem is probably libcublas10 version 10.2.2.89-1. Using a previous version might fix the problem - see #37233 ", "@JivanRoquet  It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version 2.5 or 2.4.1 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36781\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36781\">No</a>\n"]}, {"number": 36780, "title": "GPU ran out of memory when run training", "body": "<em>\r\nfrom imageai.Detection.Custom import DetectionModelTrainer\r\ntrainer = DetectionModelTrainer()\r\ntrainer.setModelTypeAsYOLOv3()\r\ntrainer.setDataDirectory(data_directory=\"dataset\")\r\ntrainer.setTrainConfig(object_names_array=[\"bottle\", \"plastic\"], batch_size=4, num_experiments=100, train_from_pretrained_model=\"pretrained-yolov3.h5\")\r\ntrainer.trainModel()\r\n</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution Window 10 Pro 64bit\r\n- TensorFlow installed from (source or binary): \r\npip3 install tensorflow==1.15      # CPU\r\npip3 install tensorflow-gpu==1.15  # GPU\r\n- TensorFlow version: 1.15\r\n- Python version: 3.6.0\r\n- Installed using pip3 \r\n- Bazel version (if compiling from source): none\r\n- GCC/Compiler version (if compiling from source): none\r\n- CUDA/cuDNN version: 10.0/ 7.6.4.38\r\n- GPU model and memory: NVIDIA GTX 1060 6gb\r\n\r\nProblem:\r\nAfter I set the code for running the Train Object Detection AI with pre-trained YOLOv3 model, i ran out with this error:  \r\n\r\n2020-02-15 17:58:40.777296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1800 next 2814 of size 256\r\n2020-02-15 17:58:40.780241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1900 next 678 of size 512\r\n2020-02-15 17:58:40.782580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1B00 next 2205 of size 4718592\r\n2020-02-15 17:58:40.785012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541B00 next 1697 of size 256\r\n2020-02-15 17:58:40.787373: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541C00 next 1556 of size 256\r\n2020-02-15 17:58:40.790582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541D00 next 2196 of size 256\r\n2020-02-15 17:58:40.793020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541E00 next 2383 of size 256\r\n2020-02-15 17:58:40.795391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541F00 next 2190 of size 256\r\n2020-02-15 17:58:40.798532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B542000 next 1369 of size 1179648\r\n2020-02-15 17:58:40.801057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662000 next 809 of size 256\r\n2020-02-15 17:58:40.803499: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662100 next 1642 of size 256\r\n2020-02-15 17:58:40.806536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662200 next 2930 of size 256\r\n2020-02-15 17:58:40.808913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662300 next 878 of size 256\r\n2020-02-15 17:58:40.811696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662400 next 1558 of size 256\r\n2020-02-15 17:58:40.814127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662500 next 1954 of size 256\r\n2020-02-15 17:58:40.817189: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662600 next 1943 of size 256\r\n2020-02-15 17:58:40.819655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662700 next 1672 of size 1024\r\n2020-02-15 17:58:40.822389: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662B00 next 1521 of size 4718592\r\n2020-02-15 17:58:40.825378: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2B00 next 1588 of size 256\r\n2020-02-15 17:58:40.827745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2C00 next 1907 of size 256\r\n2020-02-15 17:58:40.830129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2D00 next 417 of size 512\r\n2020-02-15 17:58:40.832533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2F00 next 1830 of size 1179648\r\n2020-02-15 17:58:40.835571: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC02F00 next 1758 of size 256\r\n2020-02-15 17:58:40.837951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03000 next 1594 of size 256\r\n2020-02-15 17:58:40.840512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03100 next 1666 of size 256\r\n2020-02-15 17:58:40.843507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03200 next 660 of size 2048\r\n2020-02-15 17:58:40.845865: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03A00 next 1300 of size 1024\r\n2020-02-15 17:58:40.848297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03E00 next 2656 of size 256\r\n2020-02-15 17:58:40.850647: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03F00 next 1076 of size 294912\r\n2020-02-15 17:58:40.853831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC4BF00 next 2117 of size 32768\r\n2020-02-15 17:58:40.856371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC53F00 next 397 of size 294912\r\n2020-02-15 17:58:40.858778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC9BF00 next 2031 of size 1024\r\n2020-02-15 17:58:40.861655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC9C300 next 3033 of size 524288\r\n2020-02-15 17:58:40.864087: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C300 next 2131 of size 256\r\n2020-02-15 17:58:40.866517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C400 next 1153 of size 1024\r\n2020-02-15 17:58:40.868924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C800 next 2046 of size 4096\r\n2020-02-15 17:58:40.872127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1D800 next 1257 of size 4096\r\n2020-02-15 17:58:40.874570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1E800 next 2437 of size 256\r\n2020-02-15 17:58:40.876956: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1E900 next 1338 of size 4096\r\n2020-02-15 17:58:40.880136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1F900 next 2366 of size 524288\r\n2020-02-15 17:58:40.882579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9F900 next 2002 of size 256\r\n2020-02-15 17:58:40.884978: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FA00 next 1843 of size 256\r\n2020-02-15 17:58:40.887920: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FB00 next 1676 of size 1024\r\n2020-02-15 17:58:40.890800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FF00 next 2630 of size 2048\r\n2020-02-15 17:58:40.893214: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0700 next 1410 of size 256\r\n2020-02-15 17:58:40.895593: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0800 next 3238 of size 256\r\n2020-02-15 17:58:40.898808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0900 next 610 of size 256\r\n2020-02-15 17:58:40.901215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0A00 next 493 of size 1179648\r\n2020-02-15 17:58:40.903636: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0A00 next 2618 of size 256\r\n2020-02-15 17:58:40.906728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0B00 next 2224 of size 256\r\n2020-02-15 17:58:40.909136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0C00 next 2275 of size 512\r\n2020-02-15 17:58:40.911535: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0E00 next 2534 of size 256\r\n2020-02-15 17:58:40.913780: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0F00 next 1557 of size 2048\r\n2020-02-15 17:58:40.917027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1700 next 2737 of size 256\r\n2020-02-15 17:58:40.919477: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1800 next 2972 of size 256\r\n2020-02-15 17:58:40.921979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1900 next 3166 of size 2048\r\n2020-02-15 17:58:40.924925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC2100 next 2625 of size 131072\r\n2020-02-15 17:58:40.927463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2100 next 775 of size 256\r\n2020-02-15 17:58:40.929845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2200 next 3153 of size 256\r\n2020-02-15 17:58:40.932791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2300 next 3043 of size 256\r\n2020-02-15 17:58:40.935236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2400 next 2032 of size 786432\r\n2020-02-15 17:58:40.938012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2400 next 1761 of size 2048\r\n2020-02-15 17:58:40.940588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2C00 next 2285 of size 256\r\n2020-02-15 17:58:40.943803: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2D00 next 914 of size 256\r\n2020-02-15 17:58:40.946200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2E00 next 1162 of size 131072\r\n2020-02-15 17:58:40.948620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC2E00 next 1386 of size 1024\r\n2020-02-15 17:58:40.951614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3200 next 2160 of size 2048\r\n2020-02-15 17:58:40.954028: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3A00 next 1553 of size 256\r\n2020-02-15 17:58:40.956652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3B00 next 1069 of size 32768\r\n2020-02-15 17:58:40.959735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBB00 next 1831 of size 256\r\n2020-02-15 17:58:40.962109: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBC00 next 1460 of size 256\r\n2020-02-15 17:58:40.964488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBD00 next 593 of size 1024\r\n2020-02-15 17:58:40.966847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCC100 next 3182 of size 256\r\n2020-02-15 17:58:40.969843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCC200 next 2262 of size 2097152\r\n2020-02-15 17:58:40.972330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC200 next 1199 of size 256\r\n2020-02-15 17:58:40.974758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC300 next 724 of size 256\r\n2020-02-15 17:58:40.977834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC400 next 1524 of size 256\r\n2020-02-15 17:58:40.980250: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC500 next 1395 of size 1024\r\n2020-02-15 17:58:40.982642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC900 next 923 of size 256\r\n2020-02-15 17:58:40.984972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CCA00 next 481 of size 256\r\n2020-02-15 17:58:40.987981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CCB00 next 2112 of size 4718592\r\n2020-02-15 17:58:40.990616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C64CB00 next 2870 of size 256\r\n2020-02-15 17:58:40.992968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C64CC00 next 2704 of size 18874368\r\n2020-02-15 17:58:40.996329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CC00 next 2333 of size 256\r\n2020-02-15 17:58:40.998776: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CD00 next 1368 of size 256\r\n2020-02-15 17:58:41.001143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CE00 next 1835 of size 4718592\r\n2020-02-15 17:58:41.003596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCCE00 next 3272 of size 2048\r\n2020-02-15 17:58:41.006686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCD600 next 3026 of size 256\r\n2020-02-15 17:58:41.009001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCD700 next 2483 of size 524288\r\n2020-02-15 17:58:41.011411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4D700 next 1259 of size 2048\r\n2020-02-15 17:58:41.014383: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4DF00 next 1530 of size 256\r\n2020-02-15 17:58:41.016763: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E000 next 2089 of size 256\r\n2020-02-15 17:58:41.019121: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E100 next 2655 of size 2048\r\n2020-02-15 17:58:41.021508: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E900 next 1337 of size 4096\r\n2020-02-15 17:58:41.024727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4F900 next 2173 of size 1179648\r\n2020-02-15 17:58:41.027171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6F900 next 2593 of size 256\r\n2020-02-15 17:58:41.029614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FA00 next 1310 of size 256\r\n2020-02-15 17:58:41.032548: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FB00 next 1832 of size 256\r\n2020-02-15 17:58:41.035066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FC00 next 1185 of size 4718592\r\n2020-02-15 17:58:41.038111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFC00 next 3209 of size 256\r\n2020-02-15 17:58:41.041349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFD00 next 706 of size 256\r\n2020-02-15 17:58:41.043756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFE00 next 596 of size 1024\r\n2020-02-15 17:58:41.046180: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2F0200 next 2671 of size 524288\r\n2020-02-15 17:58:41.048597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370200 next 2706 of size 256\r\n2020-02-15 17:58:41.051761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370300 next 732 of size 256\r\n2020-02-15 17:58:41.054156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370400 next 950 of size 256\r\n2020-02-15 17:58:41.056652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370500 next 3163 of size 256\r\n2020-02-15 17:58:41.059514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370600 next 2668 of size 2048\r\n2020-02-15 17:58:41.062021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370E00 next 2047 of size 256\r\n2020-02-15 17:58:41.064415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370F00 next 462 of size 256\r\n2020-02-15 17:58:41.066813: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371000 next 2494 of size 1024\r\n2020-02-15 17:58:41.070152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371400 next 1841 of size 256\r\n2020-02-15 17:58:41.072626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371500 next 2080 of size 256\r\n2020-02-15 17:58:41.075187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371600 next 999 of size 4096\r\n2020-02-15 17:58:41.078354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372600 next 2983 of size 256\r\n2020-02-15 17:58:41.080727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372700 next 2922 of size 2048\r\n2020-02-15 17:58:41.083190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372F00 next 1863 of size 256\r\n2020-02-15 17:58:41.086185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373000 next 2359 of size 512\r\n2020-02-15 17:58:41.088645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373200 next 1555 of size 256\r\n2020-02-15 17:58:41.091062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373300 next 3260 of size 1024\r\n2020-02-15 17:58:41.093460: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373700 next 1679 of size 256\r\n2020-02-15 17:58:41.096540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373800 next 2248 of size 256\r\n2020-02-15 17:58:41.098937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373900 next 2026 of size 256\r\n2020-02-15 17:58:41.101410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373A00 next 2178 of size 18874368\r\n2020-02-15 17:58:41.104438: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F573A00 next 719 of size 1024\r\n2020-02-15 17:58:41.106953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F573E00 next 3251 of size 1024\r\n2020-02-15 17:58:41.109370: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574200 next 1465 of size 1024\r\n2020-02-15 17:58:41.111759: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574600 next 2182 of size 1024\r\n2020-02-15 17:58:41.114917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574A00 next 2308 of size 256\r\n2020-02-15 17:58:41.117627: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574B00 next 2007 of size 131072\r\n2020-02-15 17:58:41.120103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F594B00 next 561 of size 1024\r\n2020-02-15 17:58:41.123939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F594F00 next 2008 of size 256\r\n2020-02-15 17:58:41.126341: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595000 next 3034 of size 2048\r\n2020-02-15 17:58:41.128774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595800 next 1354 of size 1024\r\n2020-02-15 17:58:41.131750: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595C00 next 489 of size 512\r\n2020-02-15 17:58:41.134168: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595E00 next 2811 of size 512\r\n2020-02-15 17:58:41.136566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F596000 next 664 of size 256\r\n2020-02-15 17:58:41.138991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F596100 next 2059 of size 1179648\r\n2020-02-15 17:58:41.141980: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F6B6100 next 2228 of size 256\r\n2020-02-15 17:58:41.144370: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F6B6200 next 3064 of size 4718592\r\n2020-02-15 17:58:41.146829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FB36200 next 1085 of size 256\r\n2020-02-15 17:58:41.149925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FB36300 next 2066 of size 524288\r\n2020-02-15 17:58:41.152418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6300 next 2113 of size 256\r\n2020-02-15 17:58:41.154847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6400 next 1277 of size 256\r\n2020-02-15 17:58:41.157369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6500 next 2976 of size 256\r\n2020-02-15 17:58:41.160431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6600 next 1688 of size 256\r\n2020-02-15 17:58:41.162912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6700 next 2702 of size 73728\r\n2020-02-15 17:58:41.165495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8700 next 1219 of size 256\r\n2020-02-15 17:58:41.168809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8800 next 699 of size 256\r\n2020-02-15 17:58:41.171469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8900 next 1389 of size 256\r\n2020-02-15 17:58:41.174371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8A00 next 2586 of size 73728\r\n2020-02-15 17:58:41.177705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAA00 next 752 of size 256\r\n2020-02-15 17:58:41.180396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAB00 next 1165 of size 256\r\n2020-02-15 17:58:41.182959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAC00 next 3020 of size 3584\r\n2020-02-15 17:58:41.186178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBA00 next 2548 of size 256\r\n2020-02-15 17:58:41.189193: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBB00 next 1735 of size 256\r\n2020-02-15 17:58:41.191923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBC00 next 1159 of size 256\r\n2020-02-15 17:58:41.195381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBD00 next 680 of size 256\r\n2020-02-15 17:58:41.197971: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBE00 next 648 of size 256\r\n2020-02-15 17:58:41.200653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBF00 next 2529 of size 256\r\n2020-02-15 17:58:41.203891: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC000 next 1273 of size 256\r\n2020-02-15 17:58:41.206874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC100 next 3058 of size 256\r\n2020-02-15 17:58:41.209513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC200 next 1770 of size 512\r\n2020-02-15 17:58:41.213017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC400 next 2194 of size 256\r\n2020-02-15 17:58:41.215632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC500 next 3095 of size 256\r\n2020-02-15 17:58:41.218356: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC600 next 1904 of size 256\r\n2020-02-15 17:58:41.220851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC700 next 590 of size 256\r\n2020-02-15 17:58:41.224289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC800 next 727 of size 256\r\n2020-02-15 17:58:41.226964: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC900 next 2871 of size 256\r\n2020-02-15 17:58:41.229544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCA00 next 3218 of size 256\r\n2020-02-15 17:58:41.232704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCB00 next 2227 of size 256\r\n2020-02-15 17:58:41.235329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCC00 next 3177 of size 256\r\n2020-02-15 17:58:41.237926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCD00 next 2867 of size 256\r\n2020-02-15 17:58:41.241441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCE00 next 2799 of size 256\r\n2020-02-15 17:58:41.244158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCF00 next 3028 of size 256\r\n2020-02-15 17:58:41.246775: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDD000 next 1909 of size 256\r\n2020-02-15 17:58:41.250085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDD100 next 945 of size 294912\r\n2020-02-15 17:58:41.252655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25100 next 1009 of size 256\r\n2020-02-15 17:58:41.255448: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25200 next 3111 of size 512\r\n2020-02-15 17:58:41.258604: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25400 next 2824 of size 256\r\n2020-02-15 17:58:41.261063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25500 next 2456 of size 1179648\r\n2020-02-15 17:58:41.263586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45500 next 971 of size 512\r\n2020-02-15 17:58:41.266049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45700 next 2061 of size 256\r\n2020-02-15 17:58:41.269139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45800 next 2081 of size 32768\r\n2020-02-15 17:58:41.271671: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4D800 next 1781 of size 256\r\n2020-02-15 17:58:41.274198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4D900 next 938 of size 256\r\n2020-02-15 17:58:41.277204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DA00 next 2035 of size 256\r\n2020-02-15 17:58:41.279583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DB00 next 870 of size 1024\r\n2020-02-15 17:58:41.282031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DF00 next 3050 of size 256\r\n2020-02-15 17:58:41.284972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E000 next 1322 of size 256\r\n2020-02-15 17:58:41.287366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E100 next 1515 of size 1024\r\n2020-02-15 17:58:41.289957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E500 next 1974 of size 256\r\n2020-02-15 17:58:41.292400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E600 next 2401 of size 512\r\n2020-02-15 17:58:41.295368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E800 next 2553 of size 256\r\n2020-02-15 17:58:41.297768: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E900 next 405 of size 256\r\n2020-02-15 17:58:41.300128: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EA00 next 1802 of size 256\r\n2020-02-15 17:58:41.303077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EB00 next 1026 of size 512\r\n2020-02-15 17:58:41.305517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4ED00 next 1139 of size 256\r\n2020-02-15 17:58:41.307917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EE00 next 3037 of size 1024\r\n2020-02-15 17:58:41.310338: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F200 next 2314 of size 512\r\n2020-02-15 17:58:41.313322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F400 next 2344 of size 256\r\n2020-02-15 17:58:41.315689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F500 next 1380 of size 256\r\n2020-02-15 17:58:41.318074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F600 next 820 of size 1024\r\n2020-02-15 17:58:41.321098: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FA00 next 1101 of size 256\r\n2020-02-15 17:58:41.323551: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FB00 next 3036 of size 256\r\n2020-02-15 17:58:41.325924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FC00 next 738 of size 512\r\n2020-02-15 17:58:41.328267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FE00 next 2188 of size 256\r\n2020-02-15 17:58:41.331362: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FF00 next 2317 of size 256\r\n2020-02-15 17:58:41.333726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD50000 next 1454 of size 131072\r\n2020-02-15 17:58:41.336396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70000 next 1187 of size 256\r\n2020-02-15 17:58:41.339585: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70100 next 2360 of size 256\r\n2020-02-15 17:58:41.341949: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70200 next 1093 of size 1024\r\n2020-02-15 17:58:41.344371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70600 next 1918 of size 256\r\n2020-02-15 17:58:41.346847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70700 next 609 of size 256\r\n2020-02-15 17:58:41.350104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70800 next 1889 of size 256\r\n2020-02-15 17:58:41.352521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70900 next 3059 of size 1024\r\n2020-02-15 17:58:41.354921: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70D00 next 2820 of size 256\r\n2020-02-15 17:58:41.357943: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70E00 next 3027 of size 1179648\r\n2020-02-15 17:58:41.360483: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE90E00 next 1467 of size 256\r\n2020-02-15 17:58:41.363124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE90F00 next 3156 of size 512\r\n2020-02-15 17:58:41.366368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91100 next 1271 of size 256\r\n2020-02-15 17:58:41.368933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91200 next 1693 of size 256\r\n2020-02-15 17:58:41.371463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91300 next 1374 of size 256\r\n2020-02-15 17:58:41.374963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91400 next 1412 of size 1024\r\n2020-02-15 17:58:41.377657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91800 next 414 of size 256\r\n2020-02-15 17:58:41.380364: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91900 next 1752 of size 256\r\n2020-02-15 17:58:41.382835: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91A00 next 1926 of size 512\r\n2020-02-15 17:58:41.386326: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91C00 next 3085 of size 2048\r\n2020-02-15 17:58:41.389358: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92400 next 594 of size 256\r\n2020-02-15 17:58:41.392043: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92500 next 750 of size 256\r\n2020-02-15 17:58:41.395505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92600 next 2982 of size 524288\r\n2020-02-15 17:58:41.398441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12600 next 1713 of size 256\r\n2020-02-15 17:58:41.402286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12700 next 2629 of size 256\r\n2020-02-15 17:58:41.405092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12800 next 1075 of size 1024\r\n2020-02-15 17:58:41.407996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12C00 next 482 of size 131072\r\n2020-02-15 17:58:41.411444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32C00 next 1240 of size 256\r\n2020-02-15 17:58:41.414124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32D00 next 1849 of size 256\r\n2020-02-15 17:58:41.416909: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32E00 next 2782 of size 256\r\n2020-02-15 17:58:41.420152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32F00 next 1724 of size 1179648\r\n2020-02-15 17:58:41.422957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0052F00 next 2628 of size 256\r\n2020-02-15 17:58:41.425675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0053000 next 2463 of size 1179648\r\n2020-02-15 17:58:41.428891: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0173000 next 1919 of size 256\r\n2020-02-15 17:58:41.431488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0173100 next 961 of size 2097152\r\n2020-02-15 17:58:41.433938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373100 next 2743 of size 256\r\n2020-02-15 17:58:41.436452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373200 next 1945 of size 256\r\n2020-02-15 17:58:41.439669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373300 next 615 of size 256\r\n2020-02-15 17:58:41.442032: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373400 next 2454 of size 256\r\n2020-02-15 17:58:41.444608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373500 next 2779 of size 131072\r\n2020-02-15 17:58:41.447620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393500 next 1111 of size 256\r\n2020-02-15 17:58:41.449985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393600 next 1577 of size 512\r\n2020-02-15 17:58:41.452369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393800 next 3267 of size 131072\r\n2020-02-15 17:58:41.454884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B3800 next 1237 of size 2048\r\n2020-02-15 17:58:41.457894: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4000 next 2135 of size 256\r\n2020-02-15 17:58:41.460374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4100 next 1870 of size 1024\r\n2020-02-15 17:58:41.462765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4500 next 2599 of size 256\r\n2020-02-15 17:58:41.465603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4600 next 2622 of size 1024\r\n2020-02-15 17:58:41.468001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4A00 next 2550 of size 256\r\n2020-02-15 17:58:41.470397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4B00 next 2807 of size 2048\r\n2020-02-15 17:58:41.473079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5300 next 3071 of size 1024\r\n2020-02-15 17:58:41.476163: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5700 next 2685 of size 256\r\n2020-02-15 17:58:41.478531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5800 next 1227 of size 1024\r\n2020-02-15 17:58:41.480998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5C00 next 3216 of size 256\r\n2020-02-15 17:58:41.484022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5D00 next 1071 of size 2048\r\n2020-02-15 17:58:41.486416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6500 next 1838 of size 256\r\n2020-02-15 17:58:41.488862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6600 next 2609 of size 256\r\n2020-02-15 17:58:41.491821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6700 next 2521 of size 256\r\n2020-02-15 17:58:41.494470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6800 next 2395 of size 256\r\n2020-02-15 17:58:41.496856: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6900 next 3002 of size 524288\r\n2020-02-15 17:58:41.499487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0436900 next 2511 of size 1377280\r\n2020-02-15 17:58:41.502460: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0586D00 next 2144 of size 1024\r\n2020-02-15 17:58:41.504995: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0587100 next 2818 of size 4096\r\n2020-02-15 17:58:41.507542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0588100 next 2619 of size 43008\r\n2020-02-15 17:58:41.510509: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0592900 next 918 of size 524288\r\n2020-02-15 17:58:41.512958: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612900 next 785 of size 256\r\n2020-02-15 17:58:41.515443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612A00 next 921 of size 1024\r\n2020-02-15 17:58:41.517795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612E00 next 1379 of size 1024\r\n2020-02-15 17:58:41.520913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613200 next 2688 of size 256\r\n2020-02-15 17:58:41.523625: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613300 next 1478 of size 256\r\n2020-02-15 17:58:41.526149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613400 next 1630 of size 256\r\n2020-02-15 17:58:41.529156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613500 next 2107 of size 512\r\n2020-02-15 17:58:41.531725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613700 next 2279 of size 1024\r\n2020-02-15 17:58:41.534113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613B00 next 740 of size 256\r\n2020-02-15 17:58:41.537141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613C00 next 1598 of size 256\r\n2020-02-15 17:58:41.539785: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613D00 next 2270 of size 4718592\r\n2020-02-15 17:58:41.542341: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93D00 next 2162 of size 256\r\n2020-02-15 17:58:41.544874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93E00 next 3233 of size 256\r\n2020-02-15 17:58:41.547897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93F00 next 2109 of size 256\r\n2020-02-15 17:58:41.550328: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A94000 next 534 of size 786432\r\n2020-02-15 17:58:41.552727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54000 next 1791 of size 256\r\n2020-02-15 17:58:41.555755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54100 next 1365 of size 1024\r\n2020-02-15 17:58:41.558350: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54500 next 1981 of size 256\r\n2020-02-15 17:58:41.560941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54600 next 479 of size 4718592\r\n2020-02-15 17:58:41.564039: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0FD4600 next 2882 of size 524288\r\n2020-02-15 17:58:41.566555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054600 next 1779 of size 256\r\n2020-02-15 17:58:41.569031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054700 next 2496 of size 256\r\n2020-02-15 17:58:41.571624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054800 next 1003 of size 1024\r\n2020-02-15 17:58:41.574794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054C00 next 691 of size 256\r\n2020-02-15 17:58:41.577270: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054D00 next 1661 of size 256\r\n2020-02-15 17:58:41.579716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054E00 next 2195 of size 256\r\n2020-02-15 17:58:41.582670: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054F00 next 2883 of size 256\r\n2020-02-15 17:58:41.585259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055000 next 2017 of size 256\r\n2020-02-15 17:58:41.587770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055100 next 3128 of size 256\r\n2020-02-15 17:58:41.591226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055200 next 925 of size 2048\r\n2020-02-15 17:58:41.593734: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055A00 next 2889 of size 1024\r\n2020-02-15 17:58:41.596226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055E00 next 2716 of size 256\r\n2020-02-15 17:58:41.598621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055F00 next 1854 of size 256\r\n2020-02-15 17:58:41.601824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1056000 next 544 of size 1179648\r\n2020-02-15 17:58:41.604294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176000 next 2970 of size 512\r\n2020-02-15 17:58:41.606820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176200 next 484 of size 1024\r\n2020-02-15 17:58:41.609950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176600 next 2207 of size 4718592\r\n2020-02-15 17:58:41.612454: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6600 next 1350 of size 256\r\n2020-02-15 17:58:41.614837: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6700 next 2155 of size 2048\r\n2020-02-15 17:58:41.618093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6F00 next 1751 of size 1024\r\n2020-02-15 17:58:41.620497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7300 next 1820 of size 256\r\n2020-02-15 17:58:41.623352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7400 next 3199 of size 256\r\n2020-02-15 17:58:41.625727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7500 next 2969 of size 256\r\n2020-02-15 17:58:41.628934: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7600 next 1766 of size 1179648\r\n2020-02-15 17:58:41.631486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717600 next 1429 of size 256\r\n2020-02-15 17:58:41.633950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717700 next 948 of size 256\r\n2020-02-15 17:58:41.636862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717800 next 1956 of size 512\r\n2020-02-15 17:58:41.639400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717A00 next 1241 of size 256\r\n2020-02-15 17:58:41.641784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717B00 next 2924 of size 2048\r\n2020-02-15 17:58:41.644711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718300 next 629 of size 256\r\n2020-02-15 17:58:41.647082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718400 next 818 of size 256\r\n2020-02-15 17:58:41.649497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718500 next 1827 of size 256\r\n2020-02-15 17:58:41.651907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718600 next 2686 of size 524288\r\n2020-02-15 17:58:41.654909: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798600 next 851 of size 256\r\n2020-02-15 17:58:41.657330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798700 next 1916 of size 256\r\n2020-02-15 17:58:41.659713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798800 next 2715 of size 1024\r\n2020-02-15 17:58:41.662162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798C00 next 1547 of size 256\r\n2020-02-15 17:58:41.665208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798D00 next 1415 of size 512\r\n2020-02-15 17:58:41.667581: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798F00 next 3155 of size 131072\r\n2020-02-15 17:58:41.669997: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B8F00 next 2507 of size 256\r\n2020-02-15 17:58:41.672967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9000 next 839 of size 256\r\n2020-02-15 17:58:41.675352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9100 next 676 of size 256\r\n2020-02-15 17:58:41.678303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9200 next 1614 of size 256\r\n2020-02-15 17:58:41.681599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9300 next 620 of size 2048\r\n2020-02-15 17:58:41.684149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9B00 next 1635 of size 256\r\n2020-02-15 17:58:41.686545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9C00 next 2219 of size 1024\r\n2020-02-15 17:58:41.689022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17BA000 next 1109 of size 1179648\r\n2020-02-15 17:58:41.692317: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA000 next 3086 of size 256\r\n2020-02-15 17:58:41.694788: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA100 next 1320 of size 1024\r\n2020-02-15 17:58:41.697189: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA500 next 623 of size 256\r\n2020-02-15 17:58:41.700086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA600 next 1569 of size 1024\r\n2020-02-15 17:58:41.702512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAA00 next 3249 of size 1024\r\n2020-02-15 17:58:41.704916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAE00 next 662 of size 256\r\n2020-02-15 17:58:41.707876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAF00 next 1683 of size 4096\r\n2020-02-15 17:58:41.710311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DBF00 next 549 of size 2048\r\n2020-02-15 17:58:41.712727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC700 next 1382 of size 256\r\n2020-02-15 17:58:41.715100: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC800 next 996 of size 256\r\n2020-02-15 17:58:41.718035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC900 next 2051 of size 256\r\n2020-02-15 17:58:41.720469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DCA00 next 1675 of size 256\r\n2020-02-15 17:58:41.722968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DCB00 next 1252 of size 294912\r\n2020-02-15 17:58:41.726110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1924B00 next 588 of size 512\r\n2020-02-15 17:58:41.728527: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1924D00 next 1012 of size 131072\r\n2020-02-15 17:58:41.730972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1944D00 next 1488 of size 256\r\n2020-02-15 17:58:41.733337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1944E00 next 1759 of size 512\r\n2020-02-15 17:58:41.736365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1945000 next 1179 of size 524288\r\n2020-02-15 17:58:41.738839: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5000 next 1928 of size 256\r\n2020-02-15 17:58:41.741254: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5100 next 886 of size 256\r\n2020-02-15 17:58:41.744203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5200 next 641 of size 256\r\n2020-02-15 17:58:41.746888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5300 next 1006 of size 4096\r\n2020-02-15 17:58:41.749305: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6300 next 958 of size 256\r\n2020-02-15 17:58:41.751700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6400 next 634 of size 256\r\n2020-02-15 17:58:41.754738: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6500 next 475 of size 256\r\n2020-02-15 17:58:41.757226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6600 next 2062 of size 256\r\n2020-02-15 17:58:41.759614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6700 next 1148 of size 1024\r\n2020-02-15 17:58:41.762565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6B00 next 3240 of size 512\r\n2020-02-15 17:58:41.764940: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6D00 next 2965 of size 512\r\n2020-02-15 17:58:41.767310: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6F00 next 418 of size 256\r\n2020-02-15 17:58:41.769658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C7000 next 1013 of size 256\r\n2020-02-15 17:58:41.772774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C7100 next 2862 of size 4096\r\n2020-02-15 17:58:41.775225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8100 next 2399 of size 256\r\n2020-02-15 17:58:41.777591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8200 next 1542 of size 256\r\n2020-02-15 17:58:41.780452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8300 next 559 of size 2048\r\n2020-02-15 17:58:41.782830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8B00 next 2064 of size 4096\r\n2020-02-15 17:58:41.785213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C9B00 next 1653 of size 2048\r\n2020-02-15 17:58:41.787597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CA300 next 2611 of size 4096\r\n2020-02-15 17:58:41.790689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB300 next 1508 of size 1024\r\n2020-02-15 17:58:41.793214: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB700 next 1411 of size 256\r\n2020-02-15 17:58:41.795793: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB800 next 1383 of size 256\r\n2020-02-15 17:58:41.798899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB900 next 1497 of size 2048\r\n2020-02-15 17:58:41.801281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC100 next 1164 of size 256\r\n2020-02-15 17:58:41.803699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC200 next 3187 of size 1024\r\n2020-02-15 17:58:41.806942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC600 next 1266 of size 256\r\n2020-02-15 17:58:41.809355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC700 next 506 of size 256\r\n2020-02-15 17:58:41.811706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC800 next 3217 of size 256\r\n2020-02-15 17:58:41.814178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC900 next 1592 of size 256\r\n2020-02-15 17:58:41.817066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CCA00 next 700 of size 2048\r\n2020-02-15 17:58:41.819557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CD200 next 2410 of size 4096\r\n2020-02-15 17:58:41.822007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE200 next 2216 of size 256\r\n2020-02-15 17:58:41.824908: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE300 next 3200 of size 256\r\n2020-02-15 17:58:41.827313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE400 next 710 of size 256\r\n2020-02-15 17:58:41.829722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE500 next 2264 of size 256\r\n2020-02-15 17:58:41.832303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE600 next 933 of size 256\r\n2020-02-15 17:58:41.835313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE700 next 1701 of size 256\r\n2020-02-15 17:58:41.837740: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE800 next 2088 of size 2048\r\n2020-02-15 17:58:41.840374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF000 next 1192 of size 1024\r\n2020-02-15 17:58:41.843569: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF400 next 2283 of size 256\r\n2020-02-15 17:58:41.846126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF500 next 960 of size 256\r\n2020-02-15 17:58:41.848652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF600 next 1025 of size 1024\r\n2020-02-15 17:58:41.851968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFA00 next 1527 of size 256\r\n2020-02-15 17:58:41.855046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFB00 next 2859 of size 256\r\n2020-02-15 17:58:41.857760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFC00 next 3270 of size 256\r\n2020-02-15 17:58:41.861059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFD00 next 1721 of size 4096\r\n2020-02-15 17:58:41.863663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D0D00 next 2339 of size 2048\r\n2020-02-15 17:58:41.866406: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1500 next 698 of size 256\r\n2020-02-15 17:58:41.869176: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1600 next 1986 of size 2048\r\n2020-02-15 17:58:41.873329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1E00 next 1110 of size 256\r\n2020-02-15 17:58:41.876011: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1F00 next 1804 of size 256\r\n2020-02-15 17:58:41.879428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2000 next 613 of size 256\r\n2020-02-15 17:58:41.882171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2100 next 2528 of size 256\r\n2020-02-15 17:58:41.884814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2200 next 3164 of size 512\r\n2020-02-15 17:58:41.888455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2400 next 389 of size 256\r\n2020-02-15 17:58:41.891657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2500 next 2723 of size 256\r\n2020-02-15 17:58:41.894443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2600 next 2263 of size 2048\r\n2020-02-15 17:58:41.897994: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2E00 next 2640 of size 256\r\n2020-02-15 17:58:41.900719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2F00 next 421 of size 256\r\n2020-02-15 17:58:41.903495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3000 next 3099 of size 256\r\n2020-02-15 17:58:41.907303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3100 next 1221 of size 256\r\n2020-02-15 17:58:41.910010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3200 next 1180 of size 256\r\n2020-02-15 17:58:41.912814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3300 next 1707 of size 4096\r\n2020-02-15 17:58:41.916139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4300 next 1100 of size 256\r\n2020-02-15 17:58:41.918765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4400 next 2231 of size 2048\r\n2020-02-15 17:58:41.921529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4C00 next 2130 of size 86016\r\n2020-02-15 17:58:41.925219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19E9C00 next 837 of size 256\r\n2020-02-15 17:58:41.927861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19E9D00 next 756 of size 2048\r\n2020-02-15 17:58:41.930718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA500 next 2036 of size 256\r\n2020-02-15 17:58:41.934014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA600 next 491 of size 256\r\n2020-02-15 17:58:41.936574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA700 next 2830 of size 2048\r\n2020-02-15 17:58:41.939506: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EAF00 next 1760 of size 256\r\n2020-02-15 17:58:41.942820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EB000 next 2808 of size 256\r\n2020-02-15 17:58:41.945554: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EB100 next 2100 of size 4096\r\n2020-02-15 17:58:41.948217: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EC100 next 2014 of size 2048\r\n2020-02-15 17:58:41.951516: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EC900 next 1955 of size 256\r\n2020-02-15 17:58:41.954067: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19ECA00 next 911 of size 2048\r\n2020-02-15 17:58:41.957010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19ED200 next 3112 of size 1545472\r\n2020-02-15 17:58:41.960359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66700 next 1157 of size 256\r\n2020-02-15 17:58:41.963079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66800 next 1078 of size 1024\r\n2020-02-15 17:58:41.965789: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66C00 next 2748 of size 2048\r\n2020-02-15 17:58:41.968795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B67400 next 1351 of size 131072\r\n2020-02-15 17:58:41.971276: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B87400 next 1390 of size 196608\r\n2020-02-15 17:58:41.974080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7400 next 1596 of size 256\r\n2020-02-15 17:58:41.976476: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7500 next 1275 of size 2048\r\n2020-02-15 17:58:41.979545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7D00 next 583 of size 256\r\n2020-02-15 17:58:41.981923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7E00 next 2846 of size 256\r\n2020-02-15 17:58:41.984320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7F00 next 2694 of size 256\r\n2020-02-15 17:58:41.987246: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8000 next 2071 of size 256\r\n2020-02-15 17:58:41.989842: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8100 next 2073 of size 1024\r\n2020-02-15 17:58:41.992291: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8500 next 1551 of size 1024\r\n2020-02-15 17:58:41.994685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8900 next 861 of size 256\r\n2020-02-15 17:58:41.997686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8A00 next 903 of size 4718592\r\n2020-02-15 17:58:42.000144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2038A00 next 2123 of size 524288\r\n2020-02-15 17:58:42.002599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8A00 next 2363 of size 512\r\n2020-02-15 17:58:42.005790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8C00 next 813 of size 512\r\n2020-02-15 17:58:42.008154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8E00 next 2053 of size 256\r\n2020-02-15 17:58:42.010531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8F00 next 2316 of size 512\r\n2020-02-15 17:58:42.012886: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9100 next 2145 of size 256\r\n2020-02-15 17:58:42.015838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9200 next 2948 of size 2048\r\n2020-02-15 17:58:42.018220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9A00 next 1214 of size 256\r\n2020-02-15 17:58:42.020602: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9B00 next 1210 of size 256\r\n2020-02-15 17:58:42.023631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9C00 next 1317 of size 256\r\n2020-02-15 17:58:42.026097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9D00 next 2326 of size 256\r\n2020-02-15 17:58:42.028469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9E00 next 1744 of size 4718592\r\n2020-02-15 17:58:42.030913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2539E00 next 3258 of size 2097152\r\n2020-02-15 17:58:42.034037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2739E00 next 1464 of size 4718592\r\n2020-02-15 17:58:42.036985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2BB9E00 next 2570 of size 18874368\r\n2020-02-15 17:58:42.039692: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A3DB9E00 next 1560 of size 18874368\r\n2020-02-15 17:58:42.042684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A4FB9E00 next 894 of size 4718592\r\n2020-02-15 17:58:42.045116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A5439E00 next 2375 of size 2097152\r\n2020-02-15 17:58:42.047651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A5639E00 next 3145 of size 18874368\r\n2020-02-15 17:58:42.050697: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6839E00 next 2451 of size 2097152\r\n2020-02-15 17:58:42.053278: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6A39E00 next 1680 of size 4718592\r\n2020-02-15 17:58:42.055815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6EB9E00 next 1501 of size 2097152\r\n2020-02-15 17:58:42.058828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A70B9E00 next 2522 of size 18874368\r\n2020-02-15 17:58:42.061324: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82B9E00 next 2575 of size 256\r\n2020-02-15 17:58:42.063730: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82B9F00 next 1308 of size 256\r\n2020-02-15 17:58:42.066104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA000 next 1176 of size 256\r\n2020-02-15 17:58:42.069059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA100 next 2097 of size 256\r\n2020-02-15 17:58:42.071449: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA200 next 3159 of size 1024\r\n2020-02-15 17:58:42.073876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA600 next 1684 of size 18874368\r\n2020-02-15 17:58:42.076897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA600 next 1794 of size 256\r\n2020-02-15 17:58:42.079284: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA700 next 1616 of size 256\r\n2020-02-15 17:58:42.081676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA800 next 2320 of size 256\r\n2020-02-15 17:58:42.084157: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA900 next 659 of size 256\r\n2020-02-15 17:58:42.087004: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BAA00 next 1535 of size 256\r\n2020-02-15 17:58:42.089455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BAB00 next 1269 of size 4096\r\n2020-02-15 17:58:42.091850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BBB00 next 2985 of size 256\r\n2020-02-15 17:58:42.094258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BBC00 next 614 of size 2048\r\n2020-02-15 17:58:42.097483: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BC400 next 433 of size 256\r\n2020-02-15 17:58:42.100725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BC500 next 586 of size 2048\r\n2020-02-15 17:58:42.103263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCD00 next 2309 of size 256\r\n2020-02-15 17:58:42.106431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCE00 next 1104 of size 256\r\n2020-02-15 17:58:42.108840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCF00 next 1130 of size 1024\r\n2020-02-15 17:58:42.111231: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD300 next 2412 of size 256\r\n2020-02-15 17:58:42.114300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD400 next 2429 of size 256\r\n2020-02-15 17:58:42.116684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD500 next 807 of size 256\r\n2020-02-15 17:58:42.119256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD600 next 1929 of size 4096\r\n2020-02-15 17:58:42.122225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BE600 next 631 of size 2048\r\n2020-02-15 17:58:42.124638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BEE00 next 2257 of size 256\r\n2020-02-15 17:58:42.127063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BEF00 next 2453 of size 256\r\n2020-02-15 17:58:42.129447: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF000 next 2020 of size 256\r\n2020-02-15 17:58:42.132624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF100 next 2256 of size 256\r\n2020-02-15 17:58:42.135024: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF200 next 3229 of size 256\r\n2020-02-15 17:58:42.137397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF300 next 3256 of size 131072\r\n2020-02-15 17:58:42.140594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF300 next 2695 of size 256\r\n2020-02-15 17:58:42.142960: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF400 next 2552 of size 256\r\n2020-02-15 17:58:42.145368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF500 next 1209 of size 1179648\r\n2020-02-15 17:58:42.147815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FF500 next 788 of size 2048\r\n2020-02-15 17:58:42.150859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FFD00 next 2919 of size 256\r\n2020-02-15 17:58:42.153288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FFE00 next 1848 of size 21504\r\n2020-02-15 17:58:42.155746: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605200 next 2209 of size 1024\r\n2020-02-15 17:58:42.158628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605600 next 1486 of size 512\r\n2020-02-15 17:58:42.161036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605800 next 760 of size 256\r\n2020-02-15 17:58:42.163385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605900 next 485 of size 256\r\n2020-02-15 17:58:42.165800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605A00 next 1321 of size 256\r\n2020-02-15 17:58:42.168781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605B00 next 2457 of size 256\r\n2020-02-15 17:58:42.171161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605C00 next 2018 of size 256\r\n2020-02-15 17:58:42.173570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605D00 next 2204 of size 4096\r\n2020-02-15 17:58:42.177096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9606D00 next 632 of size 1024\r\n2020-02-15 17:58:42.179622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9607100 next 2467 of size 256\r\n2020-02-15 17:58:42.181989: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9607200 next 954 of size 18874368\r\n2020-02-15 17:58:42.185071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807200 next 2739 of size 256\r\n2020-02-15 17:58:42.187495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807300 next 774 of size 256\r\n2020-02-15 17:58:42.190262: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807400 next 2169 of size 43008\r\n2020-02-15 17:58:42.192863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA811C00 next 1385 of size 256\r\n2020-02-15 17:58:42.196252: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA811D00 next 2392 of size 4096\r\n2020-02-15 17:58:42.198689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA812D00 next 2069 of size 1024\r\n2020-02-15 17:58:42.201209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813100 next 2708 of size 256\r\n2020-02-15 17:58:42.204106: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813200 next 1163 of size 256\r\n2020-02-15 17:58:42.206669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813300 next 880 of size 256\r\n2020-02-15 17:58:42.209020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813400 next 992 of size 256\r\n2020-02-15 17:58:42.212033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813500 next 2651 of size 256\r\n2020-02-15 17:58:42.214401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813600 next 2562 of size 512\r\n2020-02-15 17:58:42.216764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813800 next 595 of size 524288\r\n2020-02-15 17:58:42.219167: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA893800 next 1950 of size 1024\r\n2020-02-15 17:58:42.222102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA893C00 next 959 of size 524288\r\n2020-02-15 17:58:42.224530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA913C00 next 2697 of size 4718592\r\n2020-02-15 17:58:42.227012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AAD93C00 next 1533 of size 4718592\r\n2020-02-15 17:58:42.230086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB213C00 next 1852 of size 4096\r\n2020-02-15 17:58:42.232510: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB214C00 next 2767 of size 2097152\r\n2020-02-15 17:58:42.234942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB414C00 next 2577 of size 4096\r\n2020-02-15 17:58:42.237352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB415C00 next 1601 of size 1024\r\n2020-02-15 17:58:42.240521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB416000 next 626 of size 1024\r\n2020-02-15 17:58:42.242993: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB416400 next 3039 of size 131072\r\n2020-02-15 17:58:42.245452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436400 next 1503 of size 256\r\n2020-02-15 17:58:42.248301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436500 next 419 of size 256\r\n2020-02-15 17:58:42.250674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436600 next 390 of size 294912\r\n2020-02-15 17:58:42.253078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47E600 next 1208 of size 512\r\n2020-02-15 17:58:42.255556: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AB47E800 next 1505 of size 256\r\n2020-02-15 17:58:42.258735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47E900 next 3125 of size 1024\r\n2020-02-15 17:58:42.261142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47ED00 next 3087 of size 4718592\r\n2020-02-15 17:58:42.263592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FED00 next 1181 of size 2048\r\n2020-02-15 17:58:42.266526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FF500 next 2627 of size 2048\r\n2020-02-15 17:58:42.268983: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FFD00 next 1117 of size 1024\r\n2020-02-15 17:58:42.271450: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB900100 next 1623 of size 2048\r\n2020-02-15 17:58:42.273939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB900900 next 1120 of size 2048\r\n2020-02-15 17:58:42.276912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB901100 next 1033 of size 4096\r\n2020-02-15 17:58:42.279286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB902100 next 2260 of size 2048\r\n2020-02-15 17:58:42.281700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB902900 next 1205 of size 2097152\r\n2020-02-15 17:58:42.284600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02900 next 1887 of size 512\r\n2020-02-15 17:58:42.287021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02B00 next 1949 of size 512\r\n2020-02-15 17:58:42.289416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02D00 next 2382 of size 21504\r\n2020-02-15 17:58:42.291914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB08100 next 2006 of size 8192\r\n2020-02-15 17:58:42.294862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB0A100 next 2165 of size 512\r\n2020-02-15 17:58:42.297253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB0A300 next 2098 of size 32768\r\n2020-02-15 17:58:42.299732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB12300 next 3141 of size 1024\r\n2020-02-15 17:58:42.302706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB12700 next 523 of size 131072\r\n2020-02-15 17:58:42.305148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007ABB32700 next 3045 of size 256\r\n2020-02-15 17:58:42.307584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB32800 next 2342 of size 524288\r\n2020-02-15 17:58:42.310007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB2800 next 1821 of size 1024\r\n2020-02-15 17:58:42.313019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB2C00 next 1260 of size 2048\r\n2020-02-15 17:58:42.315296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3400 next 1937 of size 512\r\n2020-02-15 17:58:42.317703: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3600 next 574 of size 512\r\n2020-02-15 17:58:42.320694: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007ABBB3800 next 2239 of size 256\r\n2020-02-15 17:58:42.323159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3900 next 1049 of size 1024\r\n2020-02-15 17:58:42.325849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3D00 next 617 of size 1179648\r\n2020-02-15 17:58:42.329032: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCD3D00 next 1629 of size 256\r\n2020-02-15 17:58:42.331446: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCD3E00 next 604 of size 131072\r\n2020-02-15 17:58:42.333885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCF3E00 next 3146 of size 18874368\r\n2020-02-15 17:58:42.336411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF3E00 next 2850 of size 2048\r\n2020-02-15 17:58:42.339367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF4600 next 3178 of size 1024\r\n2020-02-15 17:58:42.341772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF4A00 next 1377 of size 2048\r\n2020-02-15 17:58:42.344245: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF5200 next 1994 of size 1536\r\n2020-02-15 17:58:42.347161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF5800 next 1446 of size 18874368\r\n2020-02-15 17:58:42.349634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE0F5800 next 802 of size 768\r\n2020-02-15 17:58:42.352091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE0F5B00 next 889 of size 75264\r\n2020-02-15 17:58:42.354538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE108100 next 542 of size 75264\r\n2020-02-15 17:58:42.357580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11A700 next 1604 of size 2048\r\n2020-02-15 17:58:42.359987: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11AF00 next 2823 of size 2816\r\n2020-02-15 17:58:42.362409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11BA00 next 3212 of size 1024\r\n2020-02-15 17:58:42.365409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11BE00 next 2524 of size 2048\r\n2020-02-15 17:58:42.367862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11C600 next 2931 of size 1024\r\n2020-02-15 17:58:42.370309: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11CA00 next 2994 of size 1024\r\n2020-02-15 17:58:42.372801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11CE00 next 3133 of size 1024\r\n2020-02-15 17:58:42.375937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11D200 next 1456 of size 1024\r\n2020-02-15 17:58:42.378359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11D600 next 447 of size 1024\r\n2020-02-15 17:58:42.380748: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11DA00 next 2060 of size 1024\r\n2020-02-15 17:58:42.384158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11DE00 next 1290 of size 1024\r\n2020-02-15 17:58:42.386606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E200 next 2909 of size 512\r\n2020-02-15 17:58:42.389092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E400 next 2602 of size 1024\r\n2020-02-15 17:58:42.392223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E800 next 2701 of size 1024\r\n2020-02-15 17:58:42.394637: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11EC00 next 919 of size 1024\r\n2020-02-15 17:58:42.397053: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F000 next 2470 of size 1024\r\n2020-02-15 17:58:42.399575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F400 next 1482 of size 1024\r\n2020-02-15 17:58:42.402526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F800 next 3029 of size 1024\r\n2020-02-15 17:58:42.405101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11FC00 next 874 of size 1024\r\n2020-02-15 17:58:42.407798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120000 next 2004 of size 1024\r\n2020-02-15 17:58:42.410996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120400 next 2858 of size 1024\r\n2020-02-15 17:58:42.413509: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120800 next 1235 of size 1024\r\n2020-02-15 17:58:42.415902: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120C00 next 504 of size 1024\r\n2020-02-15 17:58:42.418281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121000 next 2124 of size 1024\r\n2020-02-15 17:58:42.421294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121400 next 957 of size 1024\r\n2020-02-15 17:58:42.423772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121800 next 1677 of size 2048\r\n2020-02-15 17:58:42.426261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE122000 next 476 of size 2048\r\n2020-02-15 17:58:42.429258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE122800 next 1959 of size 2048\r\n2020-02-15 17:58:42.431762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE123000 next 381 of size 2048\r\n2020-02-15 17:58:42.434158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE123800 next 2714 of size 2048\r\n2020-02-15 17:58:42.437155: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE124000 next 1660 of size 1024\r\n2020-02-15 17:58:42.439616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE124400 next 2584 of size 3840\r\n2020-02-15 17:58:42.442311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE125300 next 422 of size 2048\r\n2020-02-15 17:58:42.444791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE125B00 next 1858 of size 2048\r\n2020-02-15 17:58:42.448010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE126300 next 693 of size 2048\r\n2020-02-15 17:58:42.450374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE126B00 next 846 of size 2048\r\n2020-02-15 17:58:42.452749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127300 next 2310 of size 2048\r\n2020-02-15 17:58:42.456684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127B00 next 600 of size 1024\r\n2020-02-15 17:58:42.459352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127F00 next 1397 of size 1024\r\n2020-02-15 17:58:42.461817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128300 next 446 of size 1024\r\n2020-02-15 17:58:42.464171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128700 next 2913 of size 2048\r\n2020-02-15 17:58:42.467466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128F00 next 2201 of size 2048\r\n2020-02-15 17:58:42.469847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE129700 next 2662 of size 2048\r\n2020-02-15 17:58:42.472355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE129F00 next 3206 of size 2048\r\n2020-02-15 17:58:42.475568: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12A700 next 1805 of size 2048\r\n2020-02-15 17:58:42.478035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12AF00 next 1343 of size 2048\r\n2020-02-15 17:58:42.480401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12B700 next 3060 of size 2048\r\n2020-02-15 17:58:42.483356: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12BF00 next 1792 of size 3584\r\n2020-02-15 17:58:42.485810: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE12CD00 next 1968 of size 37632\r\n2020-02-15 17:58:42.488283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE136000 next 437 of size 112896\r\n2020-02-15 17:58:42.490877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE151900 next 1087 of size 150528\r\n2020-02-15 17:58:42.493962: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE176500 next 1213 of size 150528\r\n2020-02-15 17:58:42.496417: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE19B100 next 1922 of size 150528\r\n2020-02-15 17:58:42.498859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE1BFD00 next 2881 of size 150528\r\n2020-02-15 17:58:42.501969: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE1E4900 next 387 of size 6422528\r\n2020-02-15 17:58:42.504422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE804900 next 786 of size 11023872\r\n2020-02-15 17:58:42.507126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF287F00 next 2598 of size 75264\r\n2020-02-15 17:58:42.510202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF29A500 next 3162 of size 112896\r\n2020-02-15 17:58:42.512655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2B5E00 next 1728 of size 768\r\n2020-02-15 17:58:42.515022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2B6100 next 2579 of size 23808\r\n2020-02-15 17:58:42.517467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BBE00 next 645 of size 512\r\n2020-02-15 17:58:42.520371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC000 next 552 of size 512\r\n2020-02-15 17:58:42.522888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC200 next 386 of size 512\r\n2020-02-15 17:58:42.525432: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC400 next 2274 of size 512\r\n2020-02-15 17:58:42.528376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC600 next 2154 of size 512\r\n2020-02-15 17:58:42.530772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC800 next 873 of size 512\r\n2020-02-15 17:58:42.533137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCA00 next 1925 of size 512\r\n2020-02-15 17:58:42.535487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCC00 next 3107 of size 512\r\n2020-02-15 17:58:42.538700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2BCE00 next 1790 of size 256\r\n2020-02-15 17:58:42.541358: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCF00 next 1957 of size 256\r\n2020-02-15 17:58:42.543816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD000 next 2015 of size 256\r\n2020-02-15 17:58:42.546888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD100 next 2074 of size 1024\r\n2020-02-15 17:58:42.549292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD500 next 1540 of size 1024\r\n2020-02-15 17:58:42.551724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD900 next 2307 of size 1024\r\n2020-02-15 17:58:42.554160: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BDD00 next 2832 of size 1024\r\n2020-02-15 17:58:42.557498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE100 next 764 of size 1024\r\n2020-02-15 17:58:42.560016: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE500 next 3174 of size 1024\r\n2020-02-15 17:58:42.562455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE900 next 2966 of size 1024\r\n2020-02-15 17:58:42.565410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BED00 next 520 of size 1024\r\n2020-02-15 17:58:42.567840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF100 next 1528 of size 512\r\n2020-02-15 17:58:42.570273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF300 next 1178 of size 512\r\n2020-02-15 17:58:42.573301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF500 next 1549 of size 1024\r\n2020-02-15 17:58:42.575925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF900 next 1030 of size 1024\r\n2020-02-15 17:58:42.578328: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BFD00 next 2356 of size 1024\r\n2020-02-15 17:58:42.580809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0100 next 2086 of size 512\r\n2020-02-15 17:58:42.583877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0300 next 2328 of size 512\r\n2020-02-15 17:58:42.586288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0500 next 2721 of size 1024\r\n2020-02-15 17:58:42.588938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0900 next 1525 of size 1024\r\n2020-02-15 17:58:42.591999: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0D00 next 973 of size 512\r\n2020-02-15 17:58:42.594349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0F00 next 989 of size 512\r\n2020-02-15 17:58:42.596717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C1100 next 1979 of size 1024\r\n2020-02-15 17:58:42.599096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C1500 next 2354 of size 1536\r\n2020-02-15 17:58:42.602223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2C1B00 next 2490 of size 18944\r\n2020-02-15 17:58:42.604635: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C6500 next 598 of size 75264\r\n2020-02-15 17:58:42.607104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2D8B00 next 1774 of size 150528\r\n2020-02-15 17:58:42.610014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2FD700 next 2860 of size 75264\r\n2020-02-15 17:58:42.612473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF30FD00 next 1996 of size 75264\r\n2020-02-15 17:58:42.614873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF322300 next 2378 of size 6422528\r\n2020-02-15 17:58:42.618048: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF942300 next 1494 of size 6422528\r\n2020-02-15 17:58:42.620533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AFF62300 next 2516 of size 9700352\r\n2020-02-15 17:58:42.623082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B08A2700 next 666 of size 6422528\r\n2020-02-15 17:58:42.625528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B0EC2700 next 404 of size 7076864\r\n2020-02-15 17:58:42.628488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B1582300 next 845 of size 12845056\r\n2020-02-15 17:58:42.630988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B21C2300 next 1963 of size 12845056\r\n2020-02-15 17:58:42.633605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B2E02300 next 2918 of size 6422528\r\n2020-02-15 17:58:42.636659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3422300 next 424 of size 3211264\r\n2020-02-15 17:58:42.639137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3732300 next 2845 of size 3441664\r\n2020-02-15 17:58:42.641808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3A7A700 next 1253 of size 13075456\r\n2020-02-15 17:58:42.644283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B46F2B00 next 3152 of size 6422528\r\n2020-02-15 17:58:42.647474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B4D12B00 next 1910 of size 6422528\r\n2020-02-15 17:58:42.649914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5332B00 next 1408 of size 3211264\r\n2020-02-15 17:58:42.652386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5642B00 next 793 of size 3211264\r\n2020-02-15 17:58:42.655377: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5952B00 next 2999 of size 6422528\r\n2020-02-15 17:58:42.657857: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5F72B00 next 429 of size 6422528\r\n2020-02-15 17:58:42.660271: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B6592B00 next 2506 of size 6422528\r\n2020-02-15 17:58:42.663338: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B6BB2B00 next 1366 of size 10354688\r\n2020-02-15 17:58:42.665800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7592B00 next 1975 of size 3211264\r\n2020-02-15 17:58:42.668248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B78A2B00 next 1246 of size 3211264\r\n2020-02-15 17:58:42.670696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7BB2B00 next 2752 of size 3211264\r\n2020-02-15 17:58:42.673936: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7EC2B00 next 2856 of size 6422528\r\n2020-02-15 17:58:42.676372: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B84E2B00 next 2997 of size 3211264\r\n2020-02-15 17:58:42.678933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B87F2B00 next 1798 of size 3211264\r\n2020-02-15 17:58:42.682023: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B8B02B00 next 687 of size 3211264\r\n2020-02-15 17:58:42.684467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B8E12B00 next 1010 of size 3211264\r\n2020-02-15 17:58:42.686932: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9122B00 next 877 of size 3211264\r\n2020-02-15 17:58:42.689931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9432B00 next 929 of size 3211264\r\n2020-02-15 17:58:42.692354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9742B00 next 963 of size 6422528\r\n2020-02-15 17:58:42.694983: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9D62B00 next 1650 of size 6422528\r\n2020-02-15 17:58:42.697433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BA382B00 next 2740 of size 3211264\r\n2020-02-15 17:58:42.700376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BA692B00 next 1439 of size 6422528\r\n2020-02-15 17:58:42.702818: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BACB2B00 next 1444 of size 6422528\r\n2020-02-15 17:58:42.705314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BB2D2B00 next 1899 of size 3211264\r\n2020-02-15 17:58:42.708344: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BB5E2B00 next 2841 of size 6422528\r\n2020-02-15 17:58:42.710898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BBC02B00 next 1092 of size 3277824\r\n2020-02-15 17:58:42.713343: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BBF22F00 next 2499 of size 3211264\r\n2020-02-15 17:58:42.715794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BC232F00 next 1113 of size 6422528\r\n2020-02-15 17:58:42.718771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BC852F00 next 1923 of size 6422528\r\n2020-02-15 17:58:42.721248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BCE72F00 next 1908 of size 6422528\r\n2020-02-15 17:58:42.723808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BD492F00 next 443 of size 3211264\r\n2020-02-15 17:58:42.726782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BD7A2F00 next 1740 of size 3211264\r\n2020-02-15 17:58:42.729286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BDAB2F00 next 517 of size 3211264\r\n2020-02-15 17:58:42.731781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BDDC2F00 next 2959 of size 6422528\r\n2020-02-15 17:58:42.734263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE3E2F00 next 432 of size 3277824\r\n2020-02-15 17:58:42.737244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE703300 next 2265 of size 1179648\r\n2020-02-15 17:58:42.739826: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE823300 next 2772 of size 8454144\r\n2020-02-15 17:58:42.742308: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BF033300 next 881 of size 6422528\r\n2020-02-15 17:58:42.745401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BF653300 next 1714 of size 6422528\r\n2020-02-15 17:58:42.747860: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BFC73300 next 1007 of size 3211264\r\n2020-02-15 17:58:42.750321: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BFF83300 next 1480 of size 6422528\r\n2020-02-15 17:58:42.753366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C05A3300 next 865 of size 3211264\r\n2020-02-15 17:58:42.755937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C08B3300 next 1967 of size 6422528\r\n2020-02-15 17:58:42.758407: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C0ED3300 next 2200 of size 3211264\r\n2020-02-15 17:58:42.761063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C11E3300 next 2346 of size 6422528\r\n2020-02-15 17:58:42.764351: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C1803300 next 2159 of size 3211264\r\n2020-02-15 17:58:42.766928: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C1B13300 next 3263 of size 6422528\r\n2020-02-15 17:58:42.769657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2133300 next 997 of size 3211264\r\n2020-02-15 17:58:42.773190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2443300 next 2174 of size 3211264\r\n2020-02-15 17:58:42.775834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2753300 next 759 of size 3211264\r\n2020-02-15 17:58:42.778582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2A63300 next 1938 of size 6422528\r\n2020-02-15 17:58:42.781845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C3083300 next 492 of size 6422528\r\n2020-02-15 17:58:42.784663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C36A3300 next 2132 of size 3211264\r\n2020-02-15 17:58:42.787532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C39B3300 next 1406 of size 3211264\r\n2020-02-15 17:58:42.791548: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C3CC3300 next 826 of size 6422528\r\n2020-02-15 17:58:42.794368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C42E3300 next 2077 of size 6422528\r\n2020-02-15 17:58:42.797158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C4903300 next 1689 of size 3211264\r\n2020-02-15 17:58:42.800627: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C4C13300 next 1881 of size 6422528\r\n2020-02-15 17:58:42.803553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5233300 next 2115 of size 6422528\r\n2020-02-15 17:58:42.807207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5853300 next 3115 of size 3211264\r\n2020-02-15 17:58:42.809924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5B63300 next 2573 of size 6422528\r\n2020-02-15 17:58:42.812726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6183300 next 3007 of size 3211264\r\n2020-02-15 17:58:42.816216: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6493300 next 1810 of size 6422528\r\n2020-02-15 17:58:42.819050: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6AB3300 next 2837 of size 3211264\r\n2020-02-15 17:58:42.821758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6DC3300 next 2903 of size 3211264\r\n2020-02-15 17:58:42.825251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C70D3300 next 2411 of size 3211264\r\n2020-02-15 17:58:42.828025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C73E3300 next 804 of size 6422528\r\n2020-02-15 17:58:42.830761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C7A03300 next 1561 of size 6422528\r\n2020-02-15 17:58:42.834200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8023300 next 2582 of size 3211264\r\n2020-02-15 17:58:42.836947: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8333300 next 373 of size 3211264\r\n2020-02-15 17:58:42.840057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8643300 next 1489 of size 6422528\r\n2020-02-15 17:58:42.843389: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8C63300 next 1932 of size 6704640\r\n2020-02-15 17:58:42.845866: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C92C8100 next 2261 of size 18874368\r\n2020-02-15 17:58:42.848598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CA4C8100 next 761 of size 3211264\r\n2020-02-15 17:58:42.851261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CA7D8100 next 2365 of size 6422528\r\n2020-02-15 17:58:42.854349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CADF8100 next 897 of size 9633792\r\n2020-02-15 17:58:42.857239: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CB728100 next 808 of size 9633792\r\n2020-02-15 17:58:42.859672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC058100 next 828 of size 6422528\r\n2020-02-15 17:58:42.862798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC678100 next 1809 of size 3211264\r\n2020-02-15 17:58:42.865318: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC988100 next 1044 of size 3211264\r\n2020-02-15 17:58:42.867927: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CCC98100 next 3210 of size 3211264\r\n2020-02-15 17:58:42.871046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CCFA8100 next 951 of size 3211264\r\n2020-02-15 17:58:42.873618: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD2B8100 next 1326 of size 3211264\r\n2020-02-15 17:58:42.876082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD5C8100 next 1912 of size 3211264\r\n2020-02-15 17:58:42.879076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD8D8100 next 814 of size 3211264\r\n2020-02-15 17:58:42.881589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CDBE8100 next 2167 of size 6422528\r\n2020-02-15 17:58:42.884192: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CE208100 next 1424 of size 6422528\r\n2020-02-15 17:58:42.886756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CE828100 next 2099 of size 3211264\r\n2020-02-15 17:58:42.890099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CEB38100 next 2282 of size 6422528\r\n2020-02-15 17:58:42.892633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CF158100 next 1613 of size 9700352\r\n2020-02-15 17:58:42.895079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CFA98500 next 1023 of size 6422528\r\n2020-02-15 17:58:42.898152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D00B8500 next 1481 of size 6422528\r\n2020-02-15 17:58:42.900623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D06D8500 next 1128 of size 6422528\r\n2020-02-15 17:58:42.903058: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D0CF8500 next 2234 of size 6422528\r\n2020-02-15 17:58:42.906296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1318500 next 1492 of size 3211264\r\n2020-02-15 17:58:42.908766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1628500 next 1876 of size 3211264\r\n2020-02-15 17:58:42.911829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1938500 next 1971 of size 3211264\r\n2020-02-15 17:58:42.915207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1C48500 next 1442 of size 3211264\r\n2020-02-15 17:58:42.917741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1F58500 next 1941 of size 3211264\r\n2020-02-15 17:58:42.920177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2268500 next 953 of size 3211264\r\n2020-02-15 17:58:42.922687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2578500 next 795 of size 3211264\r\n2020-02-15 17:58:42.925679: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2888500 next 2900 of size 3211264\r\n2020-02-15 17:58:42.928266: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2B98500 next 1143 of size 6422528\r\n2020-02-15 17:58:42.930755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D31B8500 next 2709 of size 6422528\r\n2020-02-15 17:58:42.933755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D37D8500 next 956 of size 6422528\r\n2020-02-15 17:58:42.936209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D3DF8500 next 1244 of size 6422528\r\n2020-02-15 17:58:42.938760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D4418500 next 782 of size 6422528\r\n2020-02-15 17:58:42.941240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D4A38500 next 1874 of size 6422528\r\n2020-02-15 17:58:42.944333: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5058500 next 1548 of size 6422528\r\n2020-02-15 17:58:42.946854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5678500 next 2398 of size 3211264\r\n2020-02-15 17:58:42.949301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5988500 next 2680 of size 6422528\r\n2020-02-15 17:58:42.952425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5FA8500 next 1183 of size 3211264\r\n2020-02-15 17:58:42.954911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D62B8500 next 2840 of size 3211264\r\n2020-02-15 17:58:42.957392: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D65C8500 next 709 of size 3211264\r\n2020-02-15 17:58:42.960285: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D68D8500 next 2578 of size 3211264\r\n2020-02-15 17:58:42.962861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D6BE8500 next 2386 of size 3211264\r\n2020-02-15 17:58:42.965312: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D6EF8500 next 726 of size 6422528\r\n2020-02-15 17:58:42.967751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7518500 next 1829 of size 3277824\r\n2020-02-15 17:58:42.970762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7838900 next 2766 of size 3211264\r\n2020-02-15 17:58:42.973254: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7B48900 next 3129 of size 6422528\r\n2020-02-15 17:58:42.975743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8168900 next 576 of size 6422528\r\n2020-02-15 17:58:42.978651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8788900 next 1170 of size 6422528\r\n2020-02-15 17:58:42.981116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8DA8900 next 415 of size 3277824\r\n2020-02-15 17:58:42.983528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D90C8D00 next 1432 of size 6422528\r\n2020-02-15 17:58:42.985995: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D96E8D00 next 1340 of size 3211264\r\n2020-02-15 17:58:42.989178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D99F8D00 next 550 of size 3211264\r\n2020-02-15 17:58:42.991963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D9D08D00 next 780 of size 1605632\r\n2020-02-15 17:58:42.994511: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D9E90D00 next 2827 of size 1605632\r\n2020-02-15 17:58:42.997580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA018D00 next 2012 of size 150528\r\n2020-02-15 17:58:43.000033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DA03D900 next 1066 of size 18944\r\n2020-02-15 17:58:43.002437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA042300 next 887 of size 75264\r\n2020-02-15 17:58:43.005687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA054900 next 822 of size 150528\r\n2020-02-15 17:58:43.008224: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DA079500 next 1387 of size 75264\r\n2020-02-15 17:58:43.010651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA08BB00 next 1461 of size 150528\r\n2020-02-15 17:58:43.013072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA0B0700 next 1652 of size 165376\r\n2020-02-15 17:58:43.016381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA0D8D00 next 2753 of size 2656256\r\n2020-02-15 17:58:43.018903: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA361500 next 2885 of size 6653952\r\n2020-02-15 17:58:43.021679: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA9B9D00 next 864 of size 6422528\r\n2020-02-15 17:58:43.024814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DAFD9D00 next 3173 of size 786432\r\n2020-02-15 17:58:43.027594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB099D00 next 557 of size 2424832\r\n2020-02-15 17:58:43.030264: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB2E9D00 next 1824 of size 3211264\r\n2020-02-15 17:58:43.033490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB5F9D00 next 1189 of size 3211264\r\n2020-02-15 17:58:43.036366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB909D00 next 2048 of size 3211264\r\n2020-02-15 17:58:43.039612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DBC19D00 next 2068 of size 1605632\r\n2020-02-15 17:58:43.042869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DBDA1D00 next 3009 of size 3211264\r\n2020-02-15 17:58:43.045666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC0B1D00 next 3053 of size 1605632\r\n2020-02-15 17:58:43.048348: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC239D00 next 1016 of size 1605632\r\n2020-02-15 17:58:43.051663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC3C1D00 next 1114 of size 1605632\r\n2020-02-15 17:58:43.054445: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC549D00 next 2559 of size 1605632\r\n2020-02-15 17:58:43.057498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC6D1D00 next 1223 of size 2557952\r\n2020-02-15 17:58:43.060945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC942500 next 1585 of size 6653952\r\n2020-02-15 17:58:43.063721: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DCF9AD00 next 2133 of size 1605632\r\n2020-02-15 17:58:43.066699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD122D00 next 2954 of size 3211264\r\n2020-02-15 17:58:43.070113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD432D00 next 3081 of size 3211264\r\n2020-02-15 17:58:43.073061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD742D00 next 2939 of size 1605632\r\n2020-02-15 17:58:43.075786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD8CAD00 next 932 of size 1605632\r\n2020-02-15 17:58:43.079078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDA52D00 next 2491 of size 1605632\r\n2020-02-15 17:58:43.081819: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDBDAD00 next 1812 of size 3211264\r\n2020-02-15 17:58:43.084629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDEEAD00 next 721 of size 1605632\r\n2020-02-15 17:58:43.087926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE072D00 next 1491 of size 3211264\r\n2020-02-15 17:58:43.091489: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE382D00 next 1020 of size 3211264\r\n2020-02-15 17:58:43.094232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE692D00 next 1520 of size 1605632\r\n2020-02-15 17:58:43.097666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE81AD00 next 2839 of size 1605632\r\n2020-02-15 17:58:43.100490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE9A2D00 next 562 of size 2228224\r\n2020-02-15 17:58:43.103259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DEBC2D00 next 628 of size 3211264\r\n2020-02-15 17:58:43.106591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DEED2D00 next 2616 of size 3211264\r\n2020-02-15 17:58:43.109249: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF1E2D00 next 985 of size 3211264\r\n2020-02-15 17:58:43.111903: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF4F2D00 next 949 of size 3211264\r\n2020-02-15 17:58:43.115126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF802D00 next 1405 of size 3211264\r\n2020-02-15 17:58:43.117733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFB12D00 next 2273 of size 1605632\r\n2020-02-15 17:58:43.120178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFC9AD00 next 1015 of size 3211264\r\n2020-02-15 17:58:43.123522: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFFAAD00 next 2258 of size 3211264\r\n2020-02-15 17:58:43.126076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E02BAD00 next 2797 of size 3211264\r\n2020-02-15 17:58:43.128543: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E05CAD00 next 3244 of size 3211264\r\n2020-02-15 17:58:43.131830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E08DAD00 next 2449 of size 3211264\r\n2020-02-15 17:58:43.134375: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E0BEAD00 next 1600 of size 3211264\r\n2020-02-15 17:58:43.137073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E0EFAD00 next 1138 of size 1605632\r\n2020-02-15 17:58:43.140442: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1082D00 next 1129 of size 1605632\r\n2020-02-15 17:58:43.142990: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E120AD00 next 858 of size 1605632\r\n2020-02-15 17:58:43.145630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1392D00 next 1669 of size 1605632\r\n2020-02-15 17:58:43.148251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E151AD00 next 1754 of size 1605632\r\n2020-02-15 17:58:43.151495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E16A2D00 next 2826 of size 1605632\r\n2020-02-15 17:58:43.154300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E182AD00 next 1090 of size 1605632\r\n2020-02-15 17:58:43.157179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E19B2D00 next 442 of size 1605632\r\n2020-02-15 17:58:43.160359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1B3AD00 next 1058 of size 3211264\r\n2020-02-15 17:58:43.163159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1E4AD00 next 2330 of size 3211264\r\n2020-02-15 17:58:43.165842: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E215AD00 next 2774 of size 3211264\r\n2020-02-15 17:58:43.169367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E246AD00 next 1951 of size 3211264\r\n2020-02-15 17:58:43.172273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E277AD00 next 1341 of size 3211264\r\n2020-02-15 17:58:43.175475: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E2A8AD00 next 975 of size 3211264\r\n2020-02-15 17:58:43.178898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E2D9AD00 next 3008 of size 3211264\r\n2020-02-15 17:58:43.181592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E30AAD00 next 1443 of size 1605632\r\n2020-02-15 17:58:43.184311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3232D00 next 525 of size 1605632\r\n2020-02-15 17:58:43.187466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E33BAD00 next 2703 of size 1605632\r\n2020-02-15 17:58:43.190594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3542D00 next 1479 of size 1605632\r\n2020-02-15 17:58:43.193386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E36CAD00 next 1328 of size 1771520\r\n2020-02-15 17:58:43.196685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E387B500 next 3121 of size 3211264\r\n2020-02-15 17:58:43.199313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3B8B500 next 2172 of size 1605632\r\n2020-02-15 17:58:43.201773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3D13500 next 1552 of size 3211264\r\n2020-02-15 17:58:43.204885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4023500 next 1859 of size 3211264\r\n2020-02-15 17:58:43.207990: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4333500 next 1097 of size 1605632\r\n2020-02-15 17:58:43.210610: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E44BB500 next 2168 of size 3211264\r\n2020-02-15 17:58:43.213872: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E47CB500 next 859 of size 3211264\r\n2020-02-15 17:58:43.216292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4ADB500 next 1171 of size 3211264\r\n2020-02-15 17:58:43.218796: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4DEB500 next 2134 of size 3377152\r\n2020-02-15 17:58:43.221864: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5123D00 next 703 of size 1605632\r\n2020-02-15 17:58:43.224392: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E52ABD00 next 3110 of size 1605632\r\n2020-02-15 17:58:43.226922: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5433D00 next 1915 of size 3211264\r\n2020-02-15 17:58:43.230142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5743D00 next 3189 of size 1605632\r\n2020-02-15 17:58:43.232675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E58CBD00 next 2019 of size 1605632\r\n2020-02-15 17:58:43.235202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5A53D00 next 2947 of size 1605632\r\n2020-02-15 17:58:43.237751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5BDBD00 next 2419 of size 1605632\r\n2020-02-15 17:58:43.241111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5D63D00 next 2904 of size 1869824\r\n2020-02-15 17:58:43.243850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5F2C500 next 1611 of size 3211264\r\n2020-02-15 17:58:43.246298: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E623C500 next 539 of size 3211264\r\n2020-02-15 17:58:43.249391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E654C500 next 657 of size 3211264\r\n2020-02-15 17:58:43.251857: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E685C500 next 875 of size 1605632\r\n2020-02-15 17:58:43.254357: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E69E4500 next 1422 of size 3211264\r\n2020-02-15 17:58:43.257955: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E6CF4500 next 1964 of size 3211264\r\n2020-02-15 17:58:43.260400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7004500 next 3077 of size 1605632\r\n2020-02-15 17:58:43.262833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E718C500 next 1736 of size 3211264\r\n2020-02-15 17:58:43.265261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E749C500 next 3021 of size 3211264\r\n2020-02-15 17:58:43.268474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E77AC500 next 1445 of size 4816896\r\n2020-02-15 17:58:43.271086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7C44500 next 630 of size 3211264\r\n2020-02-15 17:58:43.274220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7F54500 next 2318 of size 1605632\r\n2020-02-15 17:58:43.277491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E80DC500 next 2551 of size 1605632\r\n2020-02-15 17:58:43.280256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8264500 next 3051 of size 1605632\r\n2020-02-15 17:58:43.282991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E83EC500 next 644 of size 3211264\r\n2020-02-15 17:58:43.286207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E86FC500 next 2345 of size 1605632\r\n2020-02-15 17:58:43.289291: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8884500 next 2198 of size 3211264\r\n2020-02-15 17:58:43.292015: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8B94500 next 2836 of size 1605632\r\n2020-02-15 17:58:43.295412: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8D1C500 next 705 of size 3211264\r\n2020-02-15 17:58:43.298256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E902C500 next 2367 of size 3211264\r\n2020-02-15 17:58:43.300970: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E933C500 next 3057 of size 1605632\r\n2020-02-15 17:58:43.304318: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E94C4500 next 2298 of size 1605632\r\n2020-02-15 17:58:43.307486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E964C500 next 1112 of size 1605632\r\n2020-02-15 17:58:43.310339: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E97D4500 next 1519 of size 1605632\r\n2020-02-15 17:58:43.313832: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E995C500 next 1119 of size 3211264\r\n2020-02-15 17:58:43.316518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E9C6C500 next 3172 of size 4816896\r\n2020-02-15 17:58:43.319445: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA104500 next 625 of size 1605632\r\n2020-02-15 17:58:43.322869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA28C500 next 927 of size 1605632\r\n2020-02-15 17:58:43.325621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA414500 next 670 of size 1605632\r\n2020-02-15 17:58:43.328422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA59C500 next 1493 of size 3211264\r\n2020-02-15 17:58:43.331675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA8AC500 next 1934 of size 3211264\r\n2020-02-15 17:58:43.334524: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EABBC500 next 2778 of size 3211264\r\n2020-02-15 17:58:43.337359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EAECC500 next 1124 of size 3211264\r\n2020-02-15 17:58:43.340899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB1DC500 next 3017 of size 1605632\r\n2020-02-15 17:58:43.343699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB364500 next 686 of size 3211264\r\n2020-02-15 17:58:43.346480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB674500 next 2434 of size 1605632\r\n2020-02-15 17:58:43.349629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB7FC500 next 2146 of size 3211264\r\n2020-02-15 17:58:43.352306: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBB0C500 next 1414 of size 1605632\r\n2020-02-15 17:58:43.355149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBC94500 next 1038 of size 1605632\r\n2020-02-15 17:58:43.358642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBE1C500 next 2206 of size 1605632\r\n2020-02-15 17:58:43.361179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBFA4500 next 2955 of size 3211264\r\n2020-02-15 17:58:43.363618: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC2B4500 next 1541 of size 3211264\r\n2020-02-15 17:58:43.366764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC5C4500 next 1054 of size 1605632\r\n2020-02-15 17:58:43.369233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC74C500 next 2464 of size 1605632\r\n2020-02-15 17:58:43.371820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC8D4500 next 1329 of size 3211264\r\n2020-02-15 17:58:43.374890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ECBE4500 next 692 of size 3211264\r\n2020-02-15 17:58:43.377375: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ECEF4500 next 2825 of size 1605632\r\n2020-02-15 17:58:43.379963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED07C500 next 396 of size 3211264\r\n2020-02-15 17:58:43.383314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED38C500 next 1279 of size 4816896\r\n2020-02-15 17:58:43.385987: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED824500 next 1571 of size 3211264\r\n2020-02-15 17:58:43.388965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDB34500 next 867 of size 3211264\r\n2020-02-15 17:58:43.392315: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDE44500 next 464 of size 1605632\r\n2020-02-15 17:58:43.395124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDFCC500 next 2660 of size 1605632\r\n2020-02-15 17:58:43.397985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE154500 next 2968 of size 1605632\r\n2020-02-15 17:58:43.401307: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE2DC500 next 2407 of size 1605632\r\n2020-02-15 17:58:43.404088: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE464500 next 2531 of size 1839104\r\n2020-02-15 17:58:43.407244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE625500 next 527 of size 3444736\r\n2020-02-15 17:58:43.410534: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE96E500 next 1216 of size 802816\r\n2020-02-15 17:58:43.413326: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEA32500 next 2590 of size 802816\r\n2020-02-15 17:58:43.416237: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEAF6500 next 1203 of size 1605632\r\n2020-02-15 17:58:43.419552: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEC7E500 next 2795 of size 1605632\r\n2020-02-15 17:58:43.422518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEE06500 next 3245 of size 1605632\r\n2020-02-15 17:58:43.425368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEF8E500 next 3114 of size 1605632\r\n2020-02-15 17:58:43.428716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF116500 next 1254 of size 802816\r\n2020-02-15 17:58:43.431499: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF1DA500 next 830 of size 1294336\r\n2020-02-15 17:58:43.434300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF316500 next 1330 of size 802816\r\n2020-02-15 17:58:43.437555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF3DA500 next 2563 of size 802816\r\n2020-02-15 17:58:43.440595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF49E500 next 983 of size 1605632\r\n2020-02-15 17:58:43.443428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF626500 next 647 of size 1605632\r\n2020-02-15 17:58:43.446820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF7AE500 next 1301 of size 1605632\r\n2020-02-15 17:58:43.449614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF936500 next 2829 of size 802816\r\n2020-02-15 17:58:43.452397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF9FA500 next 1513 of size 802816\r\n2020-02-15 17:58:43.455910: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFABE500 next 991 of size 1605632\r\n2020-02-15 17:58:43.458982: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFC46500 next 2079 of size 802816\r\n2020-02-15 17:58:43.461861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFD0A500 next 1627 of size 802816\r\n2020-02-15 17:58:43.465400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFDCE500 next 2396 of size 2228224\r\n2020-02-15 17:58:43.468219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFFEE500 next 1681 of size 3211264\r\n2020-02-15 17:58:43.470923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F02FE500 next 1063 of size 3211264\r\n2020-02-15 17:58:43.474531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F060E500 next 3092 of size 6686720\r\n2020-02-15 17:58:43.477374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0C6ED00 next 1892 of size 1605632\r\n2020-02-15 17:58:43.480242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0DF6D00 next 1671 of size 1605632\r\n2020-02-15 17:58:43.483669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0F7ED00 next 3019 of size 1605632\r\n2020-02-15 17:58:43.486513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1106D00 next 642 of size 1605632\r\n2020-02-15 17:58:43.489684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F128ED00 next 1247 of size 802816\r\n2020-02-15 17:58:43.492886: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1352D00 next 1409 of size 1605632\r\n2020-02-15 17:58:43.495593: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F14DAD00 next 2244 of size 1605632\r\n2020-02-15 17:58:43.498156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1662D00 next 689 of size 802816\r\n2020-02-15 17:58:43.501219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1726D00 next 890 of size 802816\r\n2020-02-15 17:58:43.503634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F17EAD00 next 2863 of size 1294336\r\n2020-02-15 17:58:43.506420: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1926D00 next 2149 of size 802816\r\n2020-02-15 17:58:43.509453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F19EAD00 next 1906 of size 802816\r\n2020-02-15 17:58:43.512061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1AAED00 next 3131 of size 802816\r\n2020-02-15 17:58:43.514544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1B72D00 next 2854 of size 802816\r\n2020-02-15 17:58:43.517020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1C36D00 next 2028 of size 1605632\r\n2020-02-15 17:58:43.520164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1DBED00 next 1783 of size 1605632\r\n2020-02-15 17:58:43.522859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1F46D00 next 1226 of size 1605632\r\n2020-02-15 17:58:43.525566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F20CED00 next 3271 of size 1605632\r\n2020-02-15 17:58:43.528579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2256D00 next 3234 of size 1605632\r\n2020-02-15 17:58:43.531137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F23DED00 next 3042 of size 1605632\r\n2020-02-15 17:58:43.533628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2566D00 next 1638 of size 802816\r\n2020-02-15 17:58:43.536833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F262AD00 next 2681 of size 1294336\r\n2020-02-15 17:58:43.539738: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2766D00 next 762 of size 1605632\r\n2020-02-15 17:58:43.542265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F28EED00 next 1980 of size 802816\r\n2020-02-15 17:58:43.545557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F29B2D00 next 3140 of size 802816\r\n2020-02-15 17:58:43.548185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2A76D00 next 1022 of size 802816\r\n2020-02-15 17:58:43.550887: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2B3AD00 next 3123 of size 802816\r\n2020-02-15 17:58:43.553541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2BFED00 next 1789 of size 1605632\r\n2020-02-15 17:58:43.557272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2D86D00 next 720 of size 1605632\r\n2020-02-15 17:58:43.559896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2F0ED00 next 829 of size 802816\r\n2020-02-15 17:58:43.563192: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2FD2D00 next 1242 of size 1605632\r\n2020-02-15 17:58:43.565954: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F315AD00 next 2974 of size 1605632\r\n2020-02-15 17:58:43.568885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F32E2D00 next 568 of size 1605632\r\n2020-02-15 17:58:43.572253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F346AD00 next 679 of size 1605632\r\n2020-02-15 17:58:43.575148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F35F2D00 next 2720 of size 802816\r\n2020-02-15 17:58:43.577870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F36B6D00 next 2741 of size 1605632\r\n2020-02-15 17:58:43.581283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F383ED00 next 1634 of size 1605632\r\n2020-02-15 17:58:43.583899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F39C6D00 next 3013 of size 802816\r\n2020-02-15 17:58:43.586741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3A8AD00 next 899 of size 802816\r\n2020-02-15 17:58:43.590444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3B4ED00 next 1711 of size 802816\r\n2020-02-15 17:58:43.593253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3C12D00 next 2665 of size 802816\r\n2020-02-15 17:58:43.596038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3CD6D00 next 1989 of size 2818048\r\n2020-02-15 17:58:43.599306: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3F86D00 next 2468 of size 802816\r\n2020-02-15 17:58:43.602061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F404AD00 next 1036 of size 802816\r\n2020-02-15 17:58:43.604744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F410ED00 next 1720 of size 1605632\r\n2020-02-15 17:58:43.608438: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4296D00 next 1589 of size 802816\r\n2020-02-15 17:58:43.611320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F435AD00 next 3242 of size 1605632\r\n2020-02-15 17:58:43.614166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F44E2D00 next 1803 of size 1605632\r\n2020-02-15 17:58:43.617514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F466AD00 next 2781 of size 802816\r\n2020-02-15 17:58:43.620334: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F472ED00 next 2422 of size 1605632\r\n2020-02-15 17:58:43.623294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F48B6D00 next 2210 of size 802816\r\n2020-02-15 17:58:43.626605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F497AD00 next 2783 of size 1605632\r\n2020-02-15 17:58:43.629467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4B02D00 next 1145 of size 802816\r\n2020-02-15 17:58:43.632313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4BC6D00 next 1879 of size 1605632\r\n2020-02-15 17:58:43.635669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4D4ED00 next 685 of size 802816\r\n2020-02-15 17:58:43.638623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4E12D00 next 2971 of size 802816\r\n2020-02-15 17:58:43.641433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4ED6D00 next 1186 of size 802816\r\n2020-02-15 17:58:43.644740: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4F9AD00 next 2381 of size 1294336\r\n2020-02-15 17:58:43.647496: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F50D6D00 next 2580 of size 1605632\r\n2020-02-15 17:58:43.650330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F525ED00 next 968 of size 802816\r\n2020-02-15 17:58:43.653536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5322D00 next 1211 of size 1605632\r\n2020-02-15 17:58:43.656720: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F54AAD00 next 3195 of size 1605632\r\n2020-02-15 17:58:43.659589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5632D00 next 1587 of size 802816\r\n2020-02-15 17:58:43.662876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F56F6D00 next 1626 of size 1605632\r\n2020-02-15 17:58:43.665782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F587ED00 next 1370 of size 1605632\r\n2020-02-15 17:58:43.668471: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5A06D00 next 1296 of size 802816\r\n2020-02-15 17:58:43.671641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5ACAD00 next 1775 of size 802816\r\n2020-02-15 17:58:43.674501: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5B8ED00 next 2576 of size 1605632\r\n2020-02-15 17:58:43.677232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5D16D00 next 2536 of size 1605632\r\n2020-02-15 17:58:43.680540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5E9ED00 next 1871 of size 802816\r\n2020-02-15 17:58:43.683143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5F62D00 next 383 of size 1605632\r\n2020-02-15 17:58:43.685702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F60EAD00 next 1231 of size 802816\r\n2020-02-15 17:58:43.688365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F61AED00 next 584 of size 1605632\r\n2020-02-15 17:58:43.691522: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6336D00 next 1579 of size 802816\r\n2020-02-15 17:58:43.694130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F63FAD00 next 1976 of size 401408\r\n2020-02-15 17:58:43.696795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F645CD00 next 375 of size 75264\r\n2020-02-15 17:58:43.699998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F646F300 next 2666 of size 150528\r\n2020-02-15 17:58:43.702716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6493F00 next 2690 of size 175616\r\n2020-02-15 17:58:43.705755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F64BED00 next 2416 of size 802816\r\n2020-02-15 17:58:43.709089: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6582D00 next 1433 of size 872448\r\n2020-02-15 17:58:43.711843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6657D00 next 2949 of size 1605632\r\n2020-02-15 17:58:43.714795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F67DFD00 next 1024 of size 1605632\r\n2020-02-15 17:58:43.718164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6967D00 next 962 of size 1605632\r\n2020-02-15 17:58:43.720897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6AEFD00 next 1413 of size 1605632\r\n2020-02-15 17:58:43.724034: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F6C77D00 next 1834 of size 150528\r\n2020-02-15 17:58:43.727322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6C9C900 next 1346 of size 250880\r\n2020-02-15 17:58:43.730251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6CD9D00 next 2513 of size 401408\r\n2020-02-15 17:58:43.732949: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6D3BD00 next 2093 of size 1605632\r\n2020-02-15 17:58:43.736314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6EC3D00 next 2738 of size 1605632\r\n2020-02-15 17:58:43.739398: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F704BD00 next 1692 of size 802816\r\n2020-02-15 17:58:43.742327: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F710FD00 next 909 of size 802816\r\n2020-02-15 17:58:43.745693: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F71D3D00 next 2809 of size 1605632\r\n2020-02-15 17:58:43.748495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F735BD00 next 1434 of size 802816\r\n2020-02-15 17:58:43.751268: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F741FD00 next 3180 of size 3211264\r\n2020-02-15 17:58:43.754553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F772FD00 next 2027 of size 401408\r\n2020-02-15 17:58:43.757715: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7791D00 next 1202 of size 150528\r\n2020-02-15 17:58:43.760568: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F77B6900 next 627 of size 250880\r\n2020-02-15 17:58:43.763784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F77F3D00 next 603 of size 401408\r\n2020-02-15 17:58:43.766549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7855D00 next 980 of size 401408\r\n2020-02-15 17:58:43.769330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F78B7D00 next 2267 of size 3211264\r\n2020-02-15 17:58:43.772727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F7BC7D00 next 1305 of size 1605632\r\n2020-02-15 17:58:43.775573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7D4FD00 next 1940 of size 1605632\r\n2020-02-15 17:58:43.778331: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F7ED7D00 next 2940 of size 802816\r\n2020-02-15 17:58:43.781586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7F9BD00 next 3018 of size 802816\r\n2020-02-15 17:58:43.784431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F805FD00 next 2745 of size 4333568\r\n2020-02-15 17:58:43.787204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8481D00 next 2679 of size 802816\r\n2020-02-15 17:58:43.791588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8545D00 next 1182 of size 802816\r\n2020-02-15 17:58:43.794373: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8609D00 next 2455 of size 802816\r\n2020-02-15 17:58:43.797156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F86CDD00 next 2163 of size 1605632\r\n2020-02-15 17:58:43.800505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8855D00 next 2357 of size 1605632\r\n2020-02-15 17:58:43.803353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F89DDD00 next 1757 of size 1605632\r\n2020-02-15 17:58:43.806553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8B65D00 next 2425 of size 1605632\r\n2020-02-15 17:58:43.809863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8CEDD00 next 876 of size 1605632\r\n2020-02-15 17:58:43.812614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8E75D00 next 1554 of size 3211264\r\n2020-02-15 17:58:43.815414: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9185D00 next 1207 of size 3211264\r\n2020-02-15 17:58:43.818762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9495D00 next 2085 of size 3211264\r\n2020-02-15 17:58:43.821369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F97A5D00 next 2300 of size 1605632\r\n2020-02-15 17:58:43.824153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F992DD00 next 2898 of size 1605632\r\n2020-02-15 17:58:43.827353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9AB5D00 next 671 of size 1646592\r\n2020-02-15 17:58:43.829862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9C47D00 next 2906 of size 4816896\r\n2020-02-15 17:58:43.832430: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA0DFD00 next 684 of size 1605632\r\n2020-02-15 17:58:43.835374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA267D00 next 1537 of size 1605632\r\n2020-02-15 17:58:43.837834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA3EFD00 next 2936 of size 1605632\r\n2020-02-15 17:58:43.840436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA577D00 next 1458 of size 4816896\r\n2020-02-15 17:58:43.843433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAA0FD00 next 2472 of size 3211264\r\n2020-02-15 17:58:43.845933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAD1FD00 next 2063 of size 1605632\r\n2020-02-15 17:58:43.848381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAEA7D00 next 2249 of size 1904640\r\n2020-02-15 17:58:43.850960: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB078D00 next 3066 of size 1605632\r\n2020-02-15 17:58:43.854084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB200D00 next 2719 of size 3211264\r\n2020-02-15 17:58:43.856645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB510D00 next 753 of size 3211264\r\n2020-02-15 17:58:43.859287: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB820D00 next 2861 of size 3211264\r\n2020-02-15 17:58:43.862292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBB30D00 next 1662 of size 3211264\r\n2020-02-15 17:58:43.865138: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBE40D00 next 3192 of size 802816\r\n2020-02-15 17:58:43.868507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBF04D00 next 1155 of size 802816\r\n2020-02-15 17:58:43.872102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBFC8D00 next 460 of size 3211264\r\n2020-02-15 17:58:43.874859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC2D8D00 next 1121 of size 1605632\r\n2020-02-15 17:58:43.877563: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC460D00 next 2757 of size 1605632\r\n2020-02-15 17:58:43.880846: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC5E8D00 next 1499 of size 6422528\r\n2020-02-15 17:58:43.883612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FCC08D00 next 2413 of size 6422528\r\n2020-02-15 17:58:43.886388: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD228D00 next 2094 of size 3211264\r\n2020-02-15 17:58:43.890350: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD538D00 next 1158 of size 3211264\r\n2020-02-15 17:58:43.893175: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD848D00 next 2698 of size 3211264\r\n2020-02-15 17:58:43.895959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FDB58D00 next 413 of size 2784768\r\n2020-02-15 17:58:43.899421: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FDE00B00 next 1645 of size 5178368\r\n2020-02-15 17:58:43.902337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE2F0F00 next 1722 of size 3211264\r\n2020-02-15 17:58:43.905577: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE600F00 next 3084 of size 3211264\r\n2020-02-15 17:58:43.909042: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE910F00 next 1233 of size 3211264\r\n2020-02-15 17:58:43.911858: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEC20F00 next 1753 of size 1605632\r\n2020-02-15 17:58:43.915187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEDA8F00 next 1391 of size 1605632\r\n2020-02-15 17:58:43.917930: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEF30F00 next 1570 of size 1605632\r\n2020-02-15 17:58:43.920676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF0B8F00 next 509 of size 3211264\r\n2020-02-15 17:58:43.924208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007FF3C8F00 next 1698 of size 802816\r\n2020-02-15 17:58:43.927044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF48CF00 next 924 of size 802816\r\n2020-02-15 17:58:43.929812: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF550F00 next 1885 of size 1605632\r\n2020-02-15 17:58:43.932576: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF6D8F00 next 503 of size 3211264\r\n2020-02-15 17:58:43.935769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF9E8F00 next 734 of size 3211264\r\n2020-02-15 17:58:43.938790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FFCF8F00 next 2372 of size 3211264\r\n2020-02-15 17:58:43.942491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800008F00 next 3275 of size 1605632\r\n2020-02-15 17:58:43.945575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000800190F00 next 3171 of size 2408448\r\n2020-02-15 17:58:43.948352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008003DCF00 next 2296 of size 802816\r\n2020-02-15 17:58:43.951557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000008004A0F00 next 2884 of size 1605632\r\n2020-02-15 17:58:43.954295: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800628F00 next 2485 of size 3211264\r\n2020-02-15 17:58:43.957480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800938F00 next 1134 of size 3211264\r\n2020-02-15 17:58:43.960914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800C48F00 next 723 of size 3937024\r\n2020-02-15 17:58:43.963687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080100A200 next 2321 of size 1605632\r\n2020-02-15 17:58:43.966518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801192200 next 1743 of size 802816\r\n2020-02-15 17:58:43.969709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801256200 next 1459 of size 802816\r\n2020-02-15 17:58:43.972874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080131A200 next 982 of size 802816\r\n2020-02-15 17:58:43.975648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000008013DE200 next 1014 of size 2408448\r\n2020-02-15 17:58:43.978907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080162A200 next 1342 of size 3211264\r\n2020-02-15 17:58:43.981678: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080193A200 next 2319 of size 3211264\r\n2020-02-15 17:58:43.984491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801C4A200 next 1295 of size 3211264\r\n2020-02-15 17:58:43.987741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801F5A200 next 1451 of size 3211264\r\n2020-02-15 17:58:43.991413: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080226A200 next 2380 of size 3211264\r\n2020-02-15 17:58:43.994248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080257A200 next 1352 of size 3211264\r\n2020-02-15 17:58:43.997664: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080288A200 next 2945 of size 3211264\r\n2020-02-15 17:58:44.000462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000802B9A200 next 2980 of size 3211264\r\n2020-02-15 17:58:44.003204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000802EAA200 next 2986 of size 3932160\r\n2020-02-15 17:58:44.006573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080326A200 next 548 of size 6422528\r\n2020-02-15 17:58:44.009162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080388A200 next 564 of size 6422528\r\n2020-02-15 17:58:44.011663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000803EAA200 next 673 of size 20881408\r\n2020-02-15 17:58:44.014858: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000805294200 next 1419 of size 3211264\r\n2020-02-15 17:58:44.017466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008055A4200 next 1801 of size 3211264\r\n2020-02-15 17:58:44.019988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008058B4200 next 838 of size 3211264\r\n2020-02-15 17:58:44.022644: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000805BC4200 next 1602 of size 16909056\r\n2020-02-15 17:58:44.025798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000806BE4500 next 987 of size 6422528\r\n2020-02-15 17:58:44.028299: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807204500 next 3073 of size 6422528\r\n2020-02-15 17:58:44.030851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807824500 next 834 of size 3211264\r\n2020-02-15 17:58:44.033795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807B34500 next 1371 of size 3211264\r\n2020-02-15 17:58:44.036573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807E44500 next 815 of size 6422528\r\n2020-02-15 17:58:44.039707: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808464500 next 2404 of size 3211264\r\n2020-02-15 17:58:44.043235: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808774500 next 2632 of size 4003072\r\n2020-02-15 17:58:44.046035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808B45A00 next 1531 of size 6422528\r\n2020-02-15 17:58:44.048714: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809165A00 next 426 of size 6422528\r\n2020-02-15 17:58:44.051979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809785A00 next 2222 of size 6422528\r\n2020-02-15 17:58:44.054708: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809DA5A00 next 2076 of size 10358272\r\n2020-02-15 17:58:44.057892: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080A786800 next 2872 of size 6422528\r\n2020-02-15 17:58:44.061166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080ADA6800 next 1011 of size 6422528\r\n2020-02-15 17:58:44.063805: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080B3C6800 next 1238 of size 6422528\r\n2020-02-15 17:58:44.066486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080B9E6800 next 2139 of size 6422528\r\n2020-02-15 17:58:44.069779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080C006800 next 898 of size 6422528\r\n2020-02-15 17:58:44.072433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080C626800 next 2865 of size 6422528\r\n2020-02-15 17:58:44.074914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080CC46800 next 2771 of size 6422528\r\n2020-02-15 17:58:44.078099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080D266800 next 946 of size 6422528\r\n2020-02-15 17:58:44.080645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080D886800 next 2379 of size 2784768\r\n2020-02-15 17:58:44.083166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080DB2E600 next 1167 of size 2784768\r\n2020-02-15 17:58:44.085663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080DDD6400 next 2118 of size 10348544\r\n2020-02-15 17:58:44.088899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080E7B4C00 next 1029 of size 9633792\r\n2020-02-15 17:58:44.091521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080F0E4C00 next 3094 of size 6422528\r\n2020-02-15 17:58:44.093953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080F704C00 next 2055 of size 3211264\r\n2020-02-15 17:58:44.096953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080FA14C00 next 428 of size 4928768\r\n2020-02-15 17:58:44.099384: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080FEC8100 next 3196 of size 25690112\r\n2020-02-15 17:58:44.101968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000811748100 next 3080 of size 42467328\r\n2020-02-15 17:58:44.105092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000813FC8100 next 832 of size 12845056\r\n2020-02-15 17:58:44.107634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000814C08100 next 1511 of size 12845056\r\n2020-02-15 17:58:44.110095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000815848100 next 2545 of size 25690112\r\n2020-02-15 17:58:44.112604: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008170C8100 next 558 of size 1179648\r\n2020-02-15 17:58:44.115614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008171E8100 next 372 of size 524288\r\n2020-02-15 17:58:44.118146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817268100 next 2591 of size 524288\r\n2020-02-15 17:58:44.120681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008172E8100 next 1742 of size 131072\r\n2020-02-15 17:58:44.123701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817308100 next 2313 of size 6422528\r\n2020-02-15 17:58:44.126181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817928100 next 2920 of size 786432\r\n2020-02-15 17:58:44.128643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008179E8100 next 1381 of size 7284480\r\n2020-02-15 17:58:44.131653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008180DA800 next 941 of size 25614592\r\n2020-02-15 17:58:44.134207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000819948100 next 2596 of size 18874368\r\n2020-02-15 17:58:44.136682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081AB48100 next 779 of size 1024\r\n2020-02-15 17:58:44.139136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081AB48500 next 597 of size 27409408\r\n2020-02-15 17:58:44.142277: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C100 next 824 of size 1024\r\n2020-02-15 17:58:44.144663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C500 next 1325 of size 512\r\n2020-02-15 17:58:44.147110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C700 next 1151 of size 2048\r\n2020-02-15 17:58:44.150112: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56CF00 next 2136 of size 1024\r\n2020-02-15 17:58:44.152514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56D300 next 1364 of size 294912\r\n2020-02-15 17:58:44.154988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C5B5300 next 508 of size 25690112\r\n2020-02-15 17:58:44.157540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081DE35300 next 1583 of size 27410432\r\n2020-02-15 17:58:44.160595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081F859300 next 663 of size 25690112\r\n2020-02-15 17:58:44.163091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008210D9300 next 2790 of size 2097152\r\n2020-02-15 17:58:44.165596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008212D9300 next 2707 of size 18874368\r\n2020-02-15 17:58:44.168542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008224D9300 next 1840 of size 6422528\r\n2020-02-15 17:58:44.170969: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000822AF9300 next 1004 of size 6422528\r\n2020-02-15 17:58:44.173484: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000823119300 next 1857 of size 21495808\r\n2020-02-15 17:58:44.176466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000824599300 next 3222 of size 25690112\r\n2020-02-15 17:58:44.179031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000825E19300 next 944 of size 25690112\r\n2020-02-15 17:58:44.181487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000827699300 next 2340 of size 6422528\r\n2020-02-15 17:58:44.183965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000827CB9300 next 18446744073709551615 of size 35430400\r\n2020-02-15 17:58:44.187393: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size:\r\n2020-02-15 17:58:44.189939: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 922 Chunks of size 256 totalling 230.5KiB\r\n2020-02-15 17:58:44.192509: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 221 Chunks of size 512 totalling 110.5KiB\r\n2020-02-15 17:58:44.195599: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 22 Chunks of size 768 totalling 16.5KiB\r\n2020-02-15 17:58:44.198076: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 370 Chunks of size 1024 totalling 370.0KiB\r\n2020-02-15 17:58:44.200615: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 1280 totalling 6.3KiB\r\n2020-02-15 17:58:44.203631: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 9 Chunks of size 1536 totalling 13.5KiB\r\n2020-02-15 17:58:44.206586: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 1792 totalling 3.5KiB\r\n2020-02-15 17:58:44.209034: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 294 Chunks of size 2048 totalling 588.0KiB\r\n2020-02-15 17:58:44.211667: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2304 totalling 4.5KiB\r\n2020-02-15 17:58:44.214688: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2560 totalling 2.5KiB\r\n2020-02-15 17:58:44.217355: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2816 totalling 2.8KiB\r\n2020-02-15 17:58:44.219852: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 3072 totalling 12.0KiB\r\n2020-02-15 17:58:44.223013: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 3584 totalling 24.5KiB\r\n2020-02-15 17:58:44.225587: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 3840 totalling 7.5KiB\r\n2020-02-15 17:58:44.228201: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 119 Chunks of size 4096 totalling 476.0KiB\r\n2020-02-15 17:58:44.231379: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4352 totalling 4.3KiB\r\n2020-02-15 17:58:44.233689: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4864 totalling 4.8KiB\r\n2020-02-15 17:58:44.236247: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5632 totalling 5.5KiB\r\n2020-02-15 17:58:44.239664: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 6144 totalling 12.0KiB\r\n2020-02-15 17:58:44.242382: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7168 totalling 7.0KiB\r\n2020-02-15 17:58:44.244920: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 8192 totalling 56.0KiB\r\n2020-02-15 17:58:44.247523: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 14592 totalling 14.3KiB\r\n2020-02-15 17:58:44.250609: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 21504 totalling 147.0KiB\r\n2020-02-15 17:58:44.253276: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 15 Chunks of size 32768 totalling 480.0KiB\r\n2020-02-15 17:58:44.256358: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 40960 totalling 40.0KiB\r\n2020-02-15 17:58:44.259439: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 43008 totalling 336.0KiB\r\n2020-02-15 17:58:44.262080: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 56576 totalling 55.3KiB\r\n2020-02-15 17:58:44.264551: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 15 Chunks of size 73728 totalling 1.05MiB\r\n2020-02-15 17:58:44.267577: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 75264 totalling 588.0KiB\r\n2020-02-15 17:58:44.270239: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 86016 totalling 504.0KiB\r\n2020-02-15 17:58:44.273113: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 94464 totalling 92.3KiB\r\n2020-02-15 17:58:44.276249: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 103424 totalling 101.0KiB\r\n2020-02-15 17:58:44.278770: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 112896 totalling 220.5KiB\r\n2020-02-15 17:58:44.281437: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 124928 totalling 122.0KiB\r\n2020-02-15 17:58:44.284520: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 75 Chunks of size 131072 totalling 9.38MiB\r\n2020-02-15 17:58:44.287166: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 9 Chunks of size 150528 totalling 1.29MiB\r\n2020-02-15 17:58:44.290431: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 163840 totalling 160.0KiB\r\n2020-02-15 17:58:44.293622: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 165376 totalling 161.5KiB\r\n2020-02-15 17:58:44.296174: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 175616 totalling 171.5KiB\r\n2020-02-15 17:58:44.298785: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 196608 totalling 1.50MiB\r\n2020-02-15 17:58:44.301392: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 201984 totalling 197.3KiB\r\n2020-02-15 17:58:44.304678: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 244224 totalling 238.5KiB\r\n2020-02-15 17:58:44.307514: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 250880 totalling 245.0KiB\r\n2020-02-15 17:58:44.310231: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 23 Chunks of size 294912 totalling 6.47MiB\r\n2020-02-15 17:58:44.313381: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 401408 totalling 1.91MiB\r\n2020-02-15 17:58:44.315964: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 74 Chunks of size 524288 totalling 37.00MiB\r\n2020-02-15 17:58:44.318679: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 586752 totalling 573.0KiB\r\n2020-02-15 17:58:44.321701: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 657152 totalling 641.8KiB\r\n2020-02-15 17:58:44.324460: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 677376 totalling 661.5KiB\r\n2020-02-15 17:58:44.327104: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 786432 totalling 6.00MiB\r\n2020-02-15 17:58:44.330250: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 58 Chunks of size 802816 totalling 44.41MiB\r\n2020-02-15 17:58:44.332809: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 872448 totalling 852.0KiB\r\n2020-02-15 17:58:44.335442: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 979968 totalling 957.0KiB\r\n2020-02-15 17:58:44.338907: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1007872 totalling 984.3KiB\r\n2020-02-15 17:58:44.341871: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 82 Chunks of size 1179648 totalling 92.25MiB\r\n2020-02-15 17:58:44.344558: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 1294336 totalling 4.94MiB\r\n2020-02-15 17:58:44.347681: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1377280 totalling 1.31MiB\r\n2020-02-15 17:58:44.350298: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1545472 totalling 1.47MiB\r\n2020-02-15 17:58:44.352739: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 133 Chunks of size 1605632 totalling 203.66MiB\r\n2020-02-15 17:58:44.355438: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1646592 totalling 1.57MiB\r\n2020-02-15 17:58:44.358654: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1771520 totalling 1.69MiB\r\n2020-02-15 17:58:44.360962: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1839104 totalling 1.75MiB\r\n2020-02-15 17:58:44.363428: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1869824 totalling 1.78MiB\r\n2020-02-15 17:58:44.366192: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1904640 totalling 1.82MiB\r\n2020-02-15 17:58:44.368592: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 49 Chunks of size 2097152 totalling 98.00MiB\r\n2020-02-15 17:58:44.370963: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2109440 totalling 2.01MiB\r\n2020-02-15 17:58:44.373414: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2162688 totalling 2.06MiB\r\n2020-02-15 17:58:44.376322: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2228224 totalling 4.25MiB\r\n2020-02-15 17:58:44.378717: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2424832 totalling 2.31MiB\r\n2020-02-15 17:58:44.381106: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2557952 totalling 2.44MiB\r\n2020-02-15 17:58:44.384003: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2656256 totalling 2.53MiB\r\n2020-02-15 17:58:44.386346: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 2784768 totalling 7.97MiB\r\n2020-02-15 17:58:44.388721: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2818048 totalling 2.69MiB\r\n2020-02-15 17:58:44.391058: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 168 Chunks of size 3211264 totalling 514.50MiB\r\n2020-02-15 17:58:44.394068: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 3277824 totalling 12.50MiB\r\n2020-02-15 17:58:44.396498: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3377152 totalling 3.22MiB\r\n2020-02-15 17:58:44.398988: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3441664 totalling 3.28MiB\r\n2020-02-15 17:58:44.401939: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3444736 totalling 3.29MiB\r\n2020-02-15 17:58:44.404247: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3637248 totalling 3.47MiB\r\n2020-02-15 17:58:44.406887: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3932160 totalling 3.75MiB\r\n2020-02-15 17:58:44.409178: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3937024 totalling 3.75MiB\r\n2020-02-15 17:58:44.412272: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4003072 totalling 3.82MiB\r\n2020-02-15 17:58:44.414555: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4333568 totalling 4.13MiB\r\n2020-02-15 17:58:44.416888: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 81 Chunks of size 4718592 totalling 364.50MiB\r\n2020-02-15 17:58:44.419783: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 4816896 totalling 32.16MiB\r\n2020-02-15 17:58:44.422109: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4928768 totalling 4.70MiB\r\n2020-02-15 17:58:44.424421: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5178368 totalling 4.94MiB\r\n2020-02-15 17:58:44.426714: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5351680 totalling 5.10MiB\r\n2020-02-15 17:58:44.429627: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5505024 totalling 5.25MiB\r\n2020-02-15 17:58:44.431785: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6029312 totalling 5.75MiB\r\n2020-02-15 17:58:44.434041: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 97 Chunks of size 6422528 totalling 594.13MiB\r\n2020-02-15 17:58:44.436386: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 6653952 totalling 12.69MiB\r\n2020-02-15 17:58:44.439410: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6686720 totalling 6.38MiB\r\n2020-02-15 17:58:44.441740: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6704640 totalling 6.39MiB\r\n2020-02-15 17:58:44.444197: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7076864 totalling 6.75MiB\r\n2020-02-15 17:58:44.447101: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7142656 totalling 6.81MiB\r\n2020-02-15 17:58:44.449356: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7284480 totalling 6.95MiB\r\n2020-02-15 17:58:44.451676: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 8454144 totalling 8.06MiB\r\n2020-02-15 17:58:44.453946: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 9240576 totalling 8.81MiB\r\n2020-02-15 17:58:44.456789: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 9633792 totalling 27.56MiB\r\n2020-02-15 17:58:44.459086: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 9700352 totalling 18.50MiB\r\n2020-02-15 17:58:44.461487: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10348544 totalling 9.87MiB\r\n2020-02-15 17:58:44.463777: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10354688 totalling 9.88MiB\r\n2020-02-15 17:58:44.466719: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10358272 totalling 9.88MiB\r\n2020-02-15 17:58:44.469014: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 11023872 totalling 10.51MiB\r\n2020-02-15 17:58:44.471332: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12451840 totalling 11.88MiB\r\n2020-02-15 17:58:44.474144: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 21 Chunks of size 12845056 totalling 257.25MiB\r\n2020-02-15 17:58:44.476486: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 13075456 totalling 24.94MiB\r\n2020-02-15 17:58:44.478885: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 13664768 totalling 13.03MiB\r\n2020-02-15 17:58:44.481274: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 15957504 totalling 15.22MiB\r\n2020-02-15 17:58:44.484311: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 16777216 totalling 48.00MiB\r\n2020-02-15 17:58:44.486626: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16909056 totalling 16.13MiB\r\n2020-02-15 17:58:44.489046: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 48 Chunks of size 18874368 totalling 864.00MiB\r\n2020-02-15 17:58:44.491885: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 20881408 totalling 19.91MiB\r\n2020-02-15 17:58:44.494300: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 21495808 totalling 20.50MiB\r\n2020-02-15 17:58:44.496657: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 21561856 totalling 20.56MiB\r\n2020-02-15 17:58:44.498997: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23199744 totalling 22.13MiB\r\n2020-02-15 17:58:44.501873: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23592960 totalling 22.50MiB\r\n2020-02-15 17:58:44.504227: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25459712 totalling 24.28MiB\r\n2020-02-15 17:58:44.506917: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25614592 totalling 24.43MiB\r\n2020-02-15 17:58:44.509899: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 25690112 totalling 318.50MiB\r\n2020-02-15 17:58:44.512278: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25920000 totalling 24.72MiB\r\n2020-02-15 17:58:44.514599: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27409408 totalling 26.14MiB\r\n2020-02-15 17:58:44.516967: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27410432 totalling 26.14MiB\r\n2020-02-15 17:58:44.519942: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 30556928 totalling 29.14MiB\r\n2020-02-15 17:58:44.522436: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 35430400 totalling 33.79MiB\r\n2020-02-15 17:58:44.524830: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 37591296 totalling 35.85MiB\r\n2020-02-15 17:58:44.527775: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 42467328 totalling 40.50MiB\r\n2020-02-15 17:58:44.530087: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 45869824 totalling 43.74MiB\r\n2020-02-15 17:58:44.532440: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 51380224 totalling 245.00MiB\r\n2020-02-15 17:58:44.534795: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 64685312 totalling 61.69MiB\r\n2020-02-15 17:58:44.537692: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 68157440 totalling 65.00MiB\r\n2020-02-15 17:58:44.540211: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 68161024 totalling 65.00MiB\r\n2020-02-15 17:58:44.542593: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 4.59GiB\r\n2020-02-15 17:58:44.544742: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 4937233152 memory_limit_: 4937233203 available bytes: 51 curr_region_allocation_bytes_: 9874466816\r\n2020-02-15 17:58:44.549137: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:\r\nLimit:                  4937233203\r\nInUse:                  4925189888\r\nMaxInUse:               4927248640\r\nNumAllocs:                  403889\r\nMaxAllocSize:           1742209024\r\n\r\n2020-02-15 17:58:44.554733: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ****************************************************************************************************\r\n2020-02-15 17:58:44.558242: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[2,56,56,3,37,2] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"C:\\Python\\AI.py\", line 7, in <module>\r\n    trainer.trainModel()\r\n  File \"C:\\Python\\lib\\site-packages\\imageai\\Detection\\Custom\\__init__.py\", line 291, in trainModel\r\n    max_queue_size=8\r\n  File \"C:\\Python\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Python\\lib\\site-packages\\keras\\engine\\training.py\", line 1732, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"C:\\Python\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 220, in fit_generator\r\n    reset_metrics=False)\r\n  File \"C:\\Python\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in train_on_batch\r\n    outputs = self.train_function(ins)\r\n  File \"C:\\Python\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"C:\\Python\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\r\n    run_metadata_ptr)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\r\n  (0) Resource exhausted: OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node training/Adam/Square_207}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[training/Adam/sub_646/_7481]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n  (1) Resource exhausted: OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node training/Adam/Square_207}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\n\r\nAnyone know this? please help\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@traduy1998 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@traduy1998  Any update on this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 36779, "title": "Change in the Dimension (shape) because of np.hstack on tf.keras.preprocessing.text.Tokenizer.texts_to_sequences", "body": "**System information** \r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n\r\n- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): - NA, as it can be replicated in Google Colab, irrespective of an OS\r\n\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - NA\r\n\r\nTensorFlow installed from (source or binary): - pip install tensorflow==2.1\r\n\r\nTensorFlow version (use command below): - 2.1\r\n\r\nPython version: - Google Colab Python 3\r\n\r\nBazel version (if compiling from source): NA\r\n\r\nGCC/Compiler version (if compiling from source): - CUDA/cuDNN version: NA\r\n\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**: TLDR, working properly for Testing (Validation) Labels but shape is changing for Training Labels.\r\n\r\nI have applied np.hstack on `tensorflow.keras.preprocessing.text.Tokenizer.texts_to_sequences` for both Training Labels and for Validation (Testing) Labels.\r\n\r\nSurprisingly and mystically, the Size of the Output, after I applied on Training Labels is different from that of before I have applied `np.hstack`. However, there is no Change in the Shape for Validation Labels, before and after the application of `tensorflow.keras.preprocessing.text.Tokenizer.texts_to_sequences` and `np.hstack`.\r\n\r\n**Describe the expected behavior**: There should not be change in the Shape before and after application of above Methods and the behavior should be same for both Training Labels and Testing Labels.\r\n\r\n**Code to reproduce the issue** :  This is the Link of the [Github Gist](https://colab.sandbox.google.com/gist/rmothukuru/fa586147ebefdc9f2eb9ff03206e5787/discrepancy_keras_tokenizer.ipynb), to reproduce the error easily.\r\n\r\nComplete Code to reproduce the Error is given below (just in case if the link doesn't work):\r\n\r\n```\r\n!pip install tensorflow==2.1\r\n\r\n# For Preprocessing the Text => To Tokenize the Text\r\nfrom tensorflow.keras.preprocessing.text import Tokenizer\r\n# If the Two Articles are of different length, pad_sequences will make the length equal\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\n# Package for performing Numerical Operations\r\nimport numpy as np\r\n\r\nUnique_Labels_List = ['India', 'USA', 'Australia', 'Germany', 'Bhutan', 'Nepal', 'New Zealand', 'Israel', 'Canada', 'France', 'Ireland', 'Poland', 'Egypt', 'Greece', 'China', 'Spain', 'Mexico']\r\n\r\n\r\nTrain_Labels = Unique_Labels_List[0:14]\r\n#print('Train Labels = {}'.format(Train_Labels))\r\n\r\nVal_Labels =  Unique_Labels_List[14:]\r\n#print('Val_Labels = {}'.format(Val_Labels))\r\n\r\nNo_Of_Train_Items = [248, 200, 200, 218, 248, 248, 249, 247, 220, 200, 200, 211, 224, 209]\r\nNo_Val_Items = [212, 200, 219]\r\n\r\nT_L = []\r\nfor Each_Label, Item in zip(Train_Labels, No_Of_Train_Items):\r\n    T_L.append([Each_Label] * Item)\r\n\r\nT_L = [item for sublist in T_L for item in sublist]\r\n\r\nV_L = []\r\nfor Each_Label, Item in zip(Val_Labels, No_Val_Items):\r\n    V_L.append([Each_Label] * Item)\r\n\r\nV_L = [item for sublist in V_L for item in sublist]\r\n\r\n\r\nlen(T_L)\r\n\r\nlen(V_L)\r\n\r\nlabel_tokenizer = Tokenizer()\r\n\r\nlabel_tokenizer.fit_on_texts(Unique_Labels_List)\r\n\r\n# Since it should be a Numpy Array, we should Convert the Sequences to Numpy Array, for both Training and \r\n# Test Labels\r\n\r\ntraining_label_list = label_tokenizer.texts_to_sequences(T_L)\r\n\r\nvalidation_label_list = label_tokenizer.texts_to_sequences(V_L)\r\n\r\ntraining_label_seq = np.hstack(training_label_list)\r\n\r\nvalidation_label_seq = np.hstack(validation_label_list)\r\n\r\nprint('Actual Number of Train Labels before np.hstack are {}'.format(len(training_label_list)))\r\nprint('Change in the Number of Train Labels because of np.hstack are {}'.format(len(training_label_seq)))\r\n\r\nprint('-------------------------------------------------------------------------------------------------------')\r\n\r\nprint('Actual Number of Validation Labels before np.hstack are {}'.format(len(validation_label_list)))\r\nprint('However, there is no change in the Number of Validation Labels because of np.hstack {}'.format(len(validation_label_seq)))\r\n```\r\n\r\n**Other info / logs** :\r\n", "comments": ["@rmothukuru, Can you refer similar issue resolution on stackoverflow https://stackoverflow.com/questions/60237754/change-in-the-dimension-shape-because-of-np-hstack-on-tf-keras-preprocessing-t. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36779\">No</a>\n"]}, {"number": 36778, "title": "TFTRT Int8 calibrate cost all of memory and Fail", "body": "**System information** \r\nHardware : i7 + 1660ti \r\nTensorFlow installed from source using bazel\r\nThe tf_env.txt is shown :\r\n\r\n== check python ===================================================\r\npython version: 3.5.2\r\npython branch: \r\npython build version: ('default', 'Oct  8 2019 13:06:37')\r\npython compiler version: GCC 5.4.0 20160609\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Linux\r\nos kernel version: #30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020\r\nos release version: 5.3.0-28-generic\r\nos platform: Linux-5.3.0-28-generic-x86_64-with-Ubuntu-16.04-xenial\r\nlinux distribution: ('Ubuntu', '16.04', 'xenial')\r\nlinux os distribution: ('Ubuntu', '16.04', 'xenial')\r\nmac version: ('', ('', '', ''), '')\r\nuname: uname_result(system='Linux', node='xuxin', release='5.3.0-28-generic', version='#30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020', machine='x86_64', processor='x86_64')\r\narchitecture: ('64bit', 'ELF')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                1.17.3                \r\nprotobuf             3.10.0                \r\ntensorflow           1.15.0                \r\ntensorflow-estimator 1.15.1                \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nSat Feb 15 07:29:47 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 166...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   41C    P0    28W /  N/A |    346MiB /  5944MiB |     13%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-1b201d85.so.10.1\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 1.15.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.5/dist-packages\r\nRequired-by: \r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(2, 7, 12, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\nBuild label: 0.24.1\r\nBuild time: Tue Apr 2 16:29:26 2019 (1554222566)\r\nBuild timestamp: 1554222566\r\nBuild timestamp as int: 1554222566\r\n\r\n**Describe the current behavior**\r\n\r\nI use tftrt module to calibrate int8 model.\r\nI can convert() the model successfully and cost a little memory.\r\nBut, as I do calibrate(), the memory increase crazily and use the whole memory.\r\nI set config as following and send to init TrtGraphConverter:\r\n        config = tf.ConfigProto()\r\n        config.gpu_options.per_process_gpu_memory_fraction = 0.5\r\n        config.gpu_options.allow_growth = True\r\n        config.allow_soft_placement = True\r\n        config.log_device_placement = False\r\n\r\nBut it is useless.\r\nBy the way, I can use my PC to infer the model normally but calibrate always fail. \r\n\r\n\r\n**Code to reproduce the issue**\r\n```\r\n        config = tf.ConfigProto()\r\n        config.gpu_options.per_process_gpu_memory_fraction = 0.5\r\n        config.gpu_options.allow_growth = True\r\n        config.allow_soft_placement = True\r\n        config.log_device_placement = False\r\n\r\n        tftrt_graph = tftrt.TrtGraphConverter(\r\n            input_graph_def=graph.frozen_graph,\r\n            nodes_blacklist=graph.y_name,\r\n            session_config=config,\r\n            max_batch_size=1,\r\n            max_workspace_size_bytes=1 << 32,\r\n            precision_mode='INT8',\r\n            is_dynamic_op=True,\r\n            minimum_segment_size=5)\r\n\r\n      engine_graph = tftrt_graph.convert()\r\n      engine_graph = tftrt_graph.calibrate(\r\n                fetch_names=[x + ':0' for x in graph.y_name],\r\n                num_runs=1,\r\n                feed_dict_fn=feed_dict_fn)\r\n```\r\n\r\n**Other info / logs** \r\n\r\nThe TFTRT output :\r\n2020-02-15 07:03:29.178998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-15 07:03:29.179482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:01:00.0\r\n2020-02-15 07:03:29.179549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-15 07:03:29.179572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-15 07:03:29.179608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-15 07:03:29.179642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-15 07:03:29.179652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-15 07:03:29.179701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-15 07:03:29.179715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-15 07:03:29.179777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-15 07:03:29.180161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-15 07:03:29.180449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-02-15 07:03:29.180472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-15 07:03:29.180498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-02-15 07:03:29.180525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-02-15 07:03:29.180604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-15 07:03:29.180926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-15 07:03:29.181202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5214 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-02-15 07:03:30.620789: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7f1be40085e0\r\n2020-02-15 07:03:30.621001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-02-15 07:03:30.621392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-02-15 07:03:36.767786: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-02-15 07:03:36.768004: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-02-15 07:03:36.768058: E tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:838] Calibration failed: Internal: Failed to build TensorRT engine\r\nterminate called without an active exception\r\nAborted (core dumped)\r\n\r\n\r\n\r\n", "comments": ["These lines from the log look pertinent:\r\n\r\n```\r\n2020-02-15 07:03:36.767786: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-02-15 07:03:36.768004: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-02-15 07:03:36.768058: E tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:838] Calibration failed: Internal: Failed to build TensorRT engine\r\nterminate called without an active exception\r\nAborted (core dumped)\r\n```\r\n\r\nAre you sure you have a cuDNN installation?\r\n\r\nYou could consider using the [TensorFlow GPU docker images](https://www.tensorflow.org/install/docker#examples_using_gpu-enabled_images) to guarantee that the right versions of libraries like cuDNN are available.", "I meet the same problem when calibrate some models, and succeed when calibrate other models, it seems not a cuDNN problem. Here is my log:\r\nCuda error in file src/implicit_gemm.cu at line 585: out of memory\r\nCuda error in file src/implicit_gemm.cu at line 648: out of memory\r\nDefaultLogger ../builder/cudnnCalibrator.cpp (703) - Cuda Error in add: 2 (out of memory)", "> I meet the same problem when calibrate some models, and succeed when calibrate other models, it seems not a cuDNN problem.\r\n\r\nAre you sure this is the same problem?  @double344931987 's logs don't have \"out of memory\" errors.\r\n\r\nCan you try using [`set_memory_growth`](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) to prevent TF from allocating all of the GPU memory on startup? Does that address this issue?\r\n", "I try using set_memory_growth but the error still happens, @sanjoy. My code is:\r\n```\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\r\nconfig.gpu_options.allow_growth = True\r\n\r\nconverter = trt.TrtGraphConverter(input_graph_def=original_graph_def,\r\n                                        nodes_blacklist=preserve_nodes,\r\n                                        session_config=config,\r\n                                        max_batch_size=self.max_batch_size,\r\n                                        max_workspace_size_bytes=(1 << 30) * 8,\r\n                                        precision_mode=\"INT8\",\r\n                                        minimum_segment_size=self.minimum_segment_size,\r\n                                        is_dynamic_op=self.is_dynamic_op,\r\n                                        maximum_cached_engines=self.maximum_cached_engines,\r\n                                        use_calibration=True)\r\n```", "@wangxiang2713 Thanks.  Do you mind opening a separate github issue, with a reproducer (i.e. a script I can run to reproduce the problem)?", "I am very sorry that i can't provide the code and model because of authority, but i find that i can calibrate the model successfully with 16G GPU, but 'out of memory' log still esits. Can i control the GPU the function uses? ", "> Can i control the GPU the function uses?\r\n\r\nYes, see [here](https://www.tensorflow.org/guide/gpu#using_a_single_gpu_on_a_multi-gpu_system).", "> > Can i control the GPU the function uses?\r\n> \r\n> Yes, see [here](https://www.tensorflow.org/guide/gpu#using_a_single_gpu_on_a_multi-gpu_system).\r\n\r\nThankyou, I get the answer. TensorFlo GPU memory allocator is created once (per GPU device) - the first time a session is created in the process. Changing per_process_gpu_memory_fraction in the following sessions will not have any effect.\r\n\r\nThat's why i can't control the GPU.", "I also met this error during calibrate, follow is my test script, I use tf1.15 and tf2.0 ,they all have the same error:\r\nimport os\r\n  2 import sys\r\n  3 import time\r\n  4 \r\n  5 import numpy as np\r\n  6 import tensorflow as tf\r\n  7 from tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n  8 \r\n  9 sys.path.append(\".\")\r\n 10 from preprocessing import vgg_preprocess as vgg_preprocessing\r\n 11 \r\n 12 BATCH_SIZE = 1\r\n 13 NUM_CALIB_IMAGES = 1\r\n 14 \r\n 15 SAVED_MODEL_DIR = \"../models/resnet_v1_fp32/saved_model\"\r\n 16 # SAVED_MODEL_DIR = \"../models/ssd_mobilenet-v2/saved_model\"\r\n 17 INT8_SAVED_MODEL_DIR = SAVED_MODEL_DIR + \"_TFTRT_INT8/2\"\r\n 18 \r\n 19 data_directory = \"../imagenet-data/Calibration_data\"\r\n 20 \r\n 21 calibration_files = [os.path.join(path, name) for path, _, files in os.walk(data_directory) for name in files]\r\n 22 print('There are %d calibration files. \\n%s\\n%s\\n...' % (\r\n 23     len(calibration_files), calibration_files[0], calibration_files[-1]))\r\n 24 calibration_files = calibration_files[:NUM_CALIB_IMAGES]\r\n 25 \r\n 26 \r\n 27 def parse_file(filepath):\r\n 28     image = tf.io.read_file(filepath)\r\n 29     image = tf.image.decode_jpeg(image, channels=3)\r\n 30     image = vgg_preprocessing(image, 224, 224)\r\n 31     return image\r\n 32     \r\n 33 \r\n 34 num_calibration_batches = 2\r\n 35 \r\n 36 dataset = tf.data.Dataset.from_tensor_slices(calibration_files)\r\n 37 dataset = dataset.map(map_func=parse_file, num_parallel_calls=20)\r\n 38 dataset = dataset.batch(batch_size=BATCH_SIZE)\r\n 39 dataset = dataset.repeat(None)\r\n 40 calibration_dataset = dataset.take(num_calibration_batches)\r\n 41 \r\n42 \r\n 43 def calibration_input_fn():\r\n 44     for x in calibration_dataset:\r\n 45     \u00a6   yield (x,)\r\n 46 \r\n 47 \r\n 48 conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\r\n 49     precision_mode=trt.TrtPrecisionMode.INT8)\r\n 50 \r\n 51 converter = trt.TrtGraphConverterV2(\r\n 52     input_saved_model_dir=SAVED_MODEL_DIR,\r\n 53     conversion_params=conversion_params)\r\n 54 \r\n 55 converter.convert(calibration_input_fn=calibration_input_fn)\r\n 56 \r\n 57 converter.save(INT8_SAVED_MODEL_DIR)\r\n\r\n# and get this error:\r\nname: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\npciBusID: 0000:01:00.0\r\n2020-03-19 10:37:47.218951: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-03-19 10:37:47.219014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-19 10:37:47.219244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-19 10:37:47.219454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-03-19 10:37:47.219485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-19 10:37:47.219489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-03-19 10:37:47.219493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-03-19 10:37:47.219553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-19 10:37:47.219783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-19 10:37:47.219996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6970 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-03-19 10:37:47.985509: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 5 ops of 4 different types in the graph that are not converted to TensorRT: Softmax, ArgMax, Placeholder, NoOp, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-03-19 10:37:48.002648: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:633] Number of TensorRT candidate segments: 1\r\n2020-03-19 10:37:48.120657: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node resnet_model/TRTEngineOp_0 added for segment 0 consisting of 465 nodes succeeded.\r\n2020-03-19 10:37:48.557035: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:183] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2020-03-19 10:37:48.684367: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: tf_graph\r\n2020-03-19 10:37:48.684399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 470 nodes (-267), 485 edges (-267), time = 204.18ms.\r\n2020-03-19 10:37:48.684404: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   layout: Graph size after: 476 nodes (6), 491 edges (6), time = 131.973ms.\r\n2020-03-19 10:37:48.684407: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 472 nodes (-4), 487 edges (-4), time = 114.032ms.\r\n2020-03-19 10:37:48.684411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   TensorRTOptimizer: Graph size after: 8 nodes (-464), 4 edges (-483), time = 294.006ms.\r\n2020-03-19 10:37:48.684414: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 5 nodes (-3), 4 edges (0), time = 60.511ms.\r\n2020-03-19 10:37:48.684417: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: resnet_model/TRTEngineOp_0_native_segment\r\n2020-03-19 10:37:48.684420: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 467 nodes (0), 482 edges (0), time = 83.015ms.\r\n2020-03-19 10:37:48.684423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   layout: Graph size after: 467 nodes (0), 482 edges (0), time = 103.606ms.\r\n2020-03-19 10:37:48.684426: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 467 nodes (0), 482 edges (0), time = 75.662ms.\r\n2020-03-19 10:37:48.684431: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   TensorRTOptimizer: Graph size after: 467 nodes (0), 482 edges (0), time = 13.073ms.\r\n2020-03-19 10:37:48.684434: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 467 nodes (0), 482 edges (0), time = 75.931ms.\r\n2020-03-19 10:37:51.852897: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7fdd3000b8d0\r\n2020-03-19 10:37:52.727164: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-03-19 10:37:52.727317: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)\r\n2020-03-19 10:37:52.727569: E tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:838] Calibration failed: Internal: Failed to build TensorRT engine\r\n2020-03-19 10:37:52.727656: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to feed calibration data\r\n\t [[{{node resnet_model/TRTEngineOp_0}}]]\r\nTraceback (most recent call last):\r\n  File \"V2ConvertTFTRTInt8.py\", line 63, in <module>\r\n    converter.convert(calibration_input_fn=calibration_input_fn)\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py\", line 984, in convert\r\n    self._converted_func(*map(ops.convert_to_tensor, inp))\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError:  Failed to feed calibration data\r\n\t [[node resnet_model/TRTEngineOp_0 (defined at /home/guo/runprogram/Envs/py36tf20/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_pruned_8870]\r\n\r\nFunction call stack:\r\npruned\r\n\r\nterminate called without an active exception\r\n\u5df2\u653e\u5f03", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 36777, "title": "[Intel MKL] Optimize combinedNMS performance", "body": "This PR optimize the CombinedNonMaxSuppression op CPU kernel from  single thread to multi-thread.", "comments": ["Also, could you please post the benchmark numbers comparison between before and after the PR? Thank you very much!", "@penpornk For the performance data, here is some data I got before. For the update performance data, due to the original single thread code take very log time, I will update when it finished.\r\n| Batch size | Single thread | Multi-thread | ratio  |\r\n|------------|---------------|--------------|--------|\r\n| 1          | 10.8613       | 1.95         | 5.57x  |\r\n| 28         | 336.59        | 31.05        | 10.84x |\r\n| 32         | 383.72        | 35.56        | 10.79x |\r\n| 64         | 770.59        | 63.68        | 12.10x |", "@penpornk update the performance data, time in ns\r\nBM_CombinedNMS_cpu_1_500_25_1\t\t2323039 ->\t489212\r\nBM_CombinedNMS_cpu_28_500_25_1\t\t58247530 ->\t9023750\r\nBM_CombinedNMS_cpu_32_500_25_1\t\t68019130 ->\t9980150\r\nBM_CombinedNMS_cpu_64_500_25_1\t\t133137160 ->\t17240980\r\nBM_CombinedNMS_cpu_1_1000_25_1\t\t2623302 ->\t467080\r\nBM_CombinedNMS_cpu_28_1000_25_1\t\t71364650 ->\t9396000\r\nBM_CombinedNMS_cpu_32_1000_25_1\t\t81346500 ->\t10320460\r\nBM_CombinedNMS_cpu_64_1000_25_1\t\t164225940 ->\t17787690\r\nBM_CombinedNMS_cpu_1_1917_25_1\t\t3652162 ->\t538108\r\nBM_CombinedNMS_cpu_28_1917_25_1\t\t94482740 ->\t9732510\r\nBM_CombinedNMS_cpu_32_1917_25_1\t\t108465480 ->\t10609850\r\nBM_CombinedNMS_cpu_64_1917_25_1\t\t217078980 ->\t18926130\r\nBM_CombinedNMS_cpu_1_2500_25_1\t\t4283823 ->\t517773\r\nBM_CombinedNMS_cpu_28_2500_25_1\t\t111175170 ->\t10150130\r\nBM_CombinedNMS_cpu_32_2500_25_1\t\t127008710 ->\t11184190\r\nBM_CombinedNMS_cpu_64_2500_25_1\t\t253058940 ->\t19643400\r\nBM_CombinedNMS_cpu_1_500_25_25\t\t2253545 ->\t454969\r\nBM_CombinedNMS_cpu_28_500_25_25\t\t56916130 ->\t9267910\r\nBM_CombinedNMS_cpu_32_500_25_25\t\t66019460 ->\t10186830\r\nBM_CombinedNMS_cpu_64_500_25_25\t\t133661190 ->\t17726410\r\nBM_CombinedNMS_cpu_1_1000_25_25\t\t2831089 ->\t463359\r\nBM_CombinedNMS_cpu_28_1000_25_25\t\t70988320 ->\t9753240\r\nBM_CombinedNMS_cpu_32_1000_25_25\t\t83533500 ->\t10642970\r\nBM_CombinedNMS_cpu_64_1000_25_25\t\t167970350 ->\t18761130\r\nBM_CombinedNMS_cpu_1_1917_25_25\t\t3525720 ->\t521659\r\nBM_CombinedNMS_cpu_28_1917_25_25\t\t98398690 ->\t10358520\r\nBM_CombinedNMS_cpu_32_1917_25_25\t\t112060740 ->\t11647260\r\nBM_CombinedNMS_cpu_64_1917_25_25\t\t233556880 ->\t20978420\r\nBM_CombinedNMS_cpu_1_2500_25_25\t\t4191191 ->\t597319\r\nBM_CombinedNMS_cpu_28_2500_25_25\t\t113747490 ->\t11175120\r\nBM_CombinedNMS_cpu_32_2500_25_25\t\t132507210 ->\t12499690\r\nBM_CombinedNMS_cpu_64_2500_25_25\t\t267890750 ->\t22600950\r\nBM_CombinedNMS_cpu_1_500_90_1\t\t7309910 ->\t1847117\r\nBM_CombinedNMS_cpu_28_500_90_1\t\t200441650 ->\t29992800\r\nBM_CombinedNMS_cpu_32_500_90_1\t\t233193640 ->\t33024660\r\nBM_CombinedNMS_cpu_64_500_90_1\t\t470689830 ->\t58343810\r\nBM_CombinedNMS_cpu_1_1000_90_1\t\t8930110 ->\t1825090\r\nBM_CombinedNMS_cpu_28_1000_90_1\t\t246605820 ->\t30728370\r\nBM_CombinedNMS_cpu_32_1000_90_1\t\t278993340 ->\t34076850\r\nBM_CombinedNMS_cpu_64_1000_90_1\t\t568423760 ->\t60270210\r\nBM_CombinedNMS_cpu_1_1917_90_1\t\t12124350 ->\t1900205\r\nBM_CombinedNMS_cpu_28_1917_90_1\t\t338306180 ->\t32426880\r\nBM_CombinedNMS_cpu_32_1917_90_1\t\t384421020 ->\t35914810\r\nBM_CombinedNMS_cpu_64_1917_90_1\t\t774663220 ->\t64348500\r\nBM_CombinedNMS_cpu_1_2500_90_1\t\t14097700 ->\t1884557\r\nBM_CombinedNMS_cpu_28_2500_90_1\t\t396658660 ->\t34139710\r\nBM_CombinedNMS_cpu_32_2500_90_1\t\t454546510 ->\t37974240\r\nBM_CombinedNMS_cpu_64_2500_90_1\t\t909600120 ->\t68007810\r\nBM_CombinedNMS_cpu_1_500_90_90\t\t7508650 ->\t1848519\r\nBM_CombinedNMS_cpu_28_500_90_90\t\t208535130 ->\t30469320\r\nBM_CombinedNMS_cpu_32_500_90_90\t\t240093220 ->\t33806870\r\nBM_CombinedNMS_cpu_64_500_90_90\t\t480372590 ->\t60929960\r\nBM_CombinedNMS_cpu_1_1000_90_90\t\t9130900 ->\t1869414\r\nBM_CombinedNMS_cpu_28_1000_90_90\t\t267777270 ->\t32220050\r\nBM_CombinedNMS_cpu_32_1000_90_90\t\t307633500 ->\t35853710\r\nBM_CombinedNMS_cpu_64_1000_90_90\t\t626706220 ->\t64038160\r\nBM_CombinedNMS_cpu_1_1917_90_90\t\t12437620 ->\t1909809\r\nBM_CombinedNMS_cpu_28_1917_90_90\t\t383174840 ->\t34798410\r\nBM_CombinedNMS_cpu_32_1917_90_90\t\t438880640 ->\t38745970\r\nBM_CombinedNMS_cpu_64_1917_90_90\t\t889625800 ->\t70248640\r\nBM_CombinedNMS_cpu_1_2500_90_90\t\t14539030 ->\t1956012\r\nBM_CombinedNMS_cpu_28_2500_90_90\t\t457186240 ->\t36712930\r\nBM_CombinedNMS_cpu_32_2500_90_90\t\t524073030 ->\t41214980\r\nBM_CombinedNMS_cpu_64_2500_90_90\t\t1062754490 ->\t74883870\r\nBM_CombinedNMS_cpu_1_500_200_1\t\t15750910 ->\t3826558\r\nBM_CombinedNMS_cpu_28_500_200_1\t\t453637270 ->\t55639170\r\nBM_CombinedNMS_cpu_32_500_200_1\t\t511463770 ->\t62462100\r\nBM_CombinedNMS_cpu_64_500_200_1\t\t1026653820 ->\t118736620\r\nBM_CombinedNMS_cpu_1_1000_200_1\t\t19583570 ->\t3644278\r\nBM_CombinedNMS_cpu_28_1000_200_1\t\t547092330 ->\t57528180\r\nBM_CombinedNMS_cpu_32_1000_200_1\t\t628781270 ->\t64561770\r\nBM_CombinedNMS_cpu_64_1000_200_1\t\t1251330520 ->\t121423990\r\nBM_CombinedNMS_cpu_1_1917_200_1\t\t26624460 ->\t3749215\r\nBM_CombinedNMS_cpu_28_1917_200_1\t\t755978880 ->\t61018550\r\nBM_CombinedNMS_cpu_32_1917_200_1\t\t871875440 ->\t68690820\r\nBM_CombinedNMS_cpu_64_1917_200_1\t\t1747990780 ->\t129082990\r\nBM_CombinedNMS_cpu_1_2500_200_1\t\t30810760 ->\t3844000\r\nBM_CombinedNMS_cpu_28_2500_200_1\t\t886065080 ->\t64371340\r\nBM_CombinedNMS_cpu_32_2500_200_1\t\t1012045410 ->\t72465650\r\nBM_CombinedNMS_cpu_64_2500_200_1\t\t2065319100 ->\t138367530\r\nBM_CombinedNMS_cpu_1_500_200_200\t\t16516840 ->\t3667984\r\nBM_CombinedNMS_cpu_28_500_200_200\t\t468808630 ->\t57981460\r\nBM_CombinedNMS_cpu_32_500_200_200\t\t530057360 ->\t64955740\r\nBM_CombinedNMS_cpu_64_500_200_200\t\t1070955330 ->\t122629750\r\nBM_CombinedNMS_cpu_1_1000_200_200\t\t20182400 ->\t3741022\r\nBM_CombinedNMS_cpu_28_1000_200_200\t\t587699560 ->\t60782560\r\nBM_CombinedNMS_cpu_32_1000_200_200\t\t671253770 ->\t68633970\r\nBM_CombinedNMS_cpu_64_1000_200_200\t\t1348274040 ->\t129640540\r\nBM_CombinedNMS_cpu_1_1917_200_200\t\t27440800 ->\t3876423\r\nBM_CombinedNMS_cpu_28_1917_200_200\t\t827276050 ->\t67455700\r\nBM_CombinedNMS_cpu_32_1917_200_200\t\t941913330 ->\t75362430\r\nBM_CombinedNMS_cpu_64_1917_200_200\t\t1934794720 ->\t143265870\r\nBM_CombinedNMS_cpu_1_2500_200_200\t\t32190200 ->\t3975077\r\nBM_CombinedNMS_cpu_28_2500_200_200\t\t983298270 ->\t72819920\r\nBM_CombinedNMS_cpu_32_2500_200_200\t\t1126059520 ->\t81536040\r\nBM_CombinedNMS_cpu_64_2500_200_200\t\t2286195960 ->\t154580820\r\n", "@penpornk this is a 2 socket system with 28 cores each. Thank you!", "@guizili0 Thank you very much! :)"]}, {"number": 36776, "title": "tf.config.list_physical_devices() does not show GPU", "body": "**System information** \r\nOS Platform and Distribution - Windows 10 home\r\nTensorFlow installed using - pip install tensorflow-gpu\r\nTensorFlow version - 2.1.0\r\nPython version - 3.7.4\r\nCUDA/cuDNN version - 10.1\r\nGPU - NVIDIA GeForce GTX 1650\r\n\r\nI can see the GPUs in my machine as shown below.\r\n![image](https://user-images.githubusercontent.com/42920503/74582198-e4bc9e80-4f86-11ea-9626-70c844e87bdd.png)\r\n\r\nI have installed, visual studio 2019 express, CUDA tool kit 10.1 with cuDNN. \r\n\r\nWhen I try to see all the physical devices detected by tensorflow, I can see only cpu is detcted.\r\n![image](https://user-images.githubusercontent.com/42920503/74582236-5563bb00-4f87-11ea-9294-863b7a91e11f.png)\r\n\r\nKindly check the issue.", "comments": ["@amahendrakar The type of this issue is not a bug. ", "I can see the GPU after restarting my system.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36776\">No</a>\n", "I have a similar issue. Tensorflow can see my GPU however when I run scrips it does not use it? I have been stuck on this for days, any help would be massively appreciated.  ", "@georgeparry12 I realized that pytorch, cuda and tensorflow all need to be compatible with each other for the above to work. \r\n\r\nInstall pytorch using below - \r\n\r\nconda install pytorch torchvision cudatoolkit=10.1 -c pytorch\r\n\r\n, If your cuda toolkit is 10.1. Try restarting the system once and check.\r\n\r\n", "@ManasRMohanty thank you for this. I tried what you suggested but task manager still shows no activation on the GPU when I run the script? There are more details of the problem on this post-https://github.com/tensorflow/tensorflow/issues/37164 . \r\n\r\nI wonder if you have any more suggestions? "]}, {"number": 36775, "title": "First example on the Tensor page results in an error", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Tensor\r\n\r\nThe page has the breadcrumbs `TensorFlow > API > TensorFlow Core v2.1.0 > Python`.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nRunning the first example on the [Tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor) page results in an error.\r\n\r\n### Clear description\r\n\r\nHere is the outcome of running the first example.\r\n``` py\r\n>>> # Build a dataflow graph.\r\n... c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\r\n>>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\r\n>>> e = tf.matmul(c, d)\r\n>>> # Construct a `Session` to execute the graph.\r\n... sess = tf.compat.v1.Session()\r\n>>> # Execute the graph and store the value that `e` represents in `result`.\r\n... result = sess.run(e)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 960, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1108, in _run\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n```\r\n\r\nI understand from [here](https://kodlogs.com/34085/runtimeerror-the-session-graph-is-empty-add-operations-to-the-graph-before-calling-run) that a session is no longer required in tf v2.\r\n\r\nBut the Tensor documentation starts off with multiple session references which appears to now be obsolete or not required.\r\n", "comments": ["I could replicate the issue with Tf 2.1.", "@jraman This was updates in the `tf-nightly`. Please check it [here](https://www.tensorflow.org/api_docs/python/tf/Tensor?version=nightly). \r\n\r\nBy default, eager is enabled in `TF2.x`. If you want to run any op in graph then please disable the eager mode. If you still want to use a `tf.Session` then please add  `tf.compat.v1.disable_eager_execution()` at the start, before defining any operation. \r\n\r\n[Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/41bba3681a9af7724ed235606f09cd7f/tf36775.ipynb) is the gist for your reference. Thanks!\r\n\r\nI am closing this issue as it is resolved. Thanks!", "@jvishnuvardhan, thank you for updating the document.  I was looking for documentation and not a way to use `tf.Session`.  The updated doc looks good to me.\r\n\r\nCouple of questions/suggestions:\r\n 1. It may be good to point out early in the document that there are two modes of execution: eager mode (the default) and graph mode.\r\n 1. The updated document refers to Graph mode as legacy.  But, `tf.function` constructs a callable that executes a graph (`tf.Graph`).  Legacy to me connotes something that is out of practice, but I think that here the case is that graph mode is something that is very much in use, but occurs under the hood.  Right?\r\n 1. The link to the Tensor guide does not work for me.  Looks like the link has extra characters.\r\n\r\nThanks!", "@jraman Agree with you on (1) and (3). regarding (2), `legacy` term was used to denote that graph mode as in TF1.x is going to be out of practice and not supported in the future. A graph mode with `tf.function` in TF2.x is supported. \r\n\r\nAre you interested in creating a PR. If you are not interested, then I will create a PR. If you are interested to create PR, [here](https://www.tensorflow.org/guide/tensor) is the correct link for (3) . Thanks!", "@jvishnuvardhan, thanks for getting back.  Sure, no worries, I'll create a PR.\r\n\r\nI see what you mean by legacy--it's legacy in TF1, but not in TF2.  Since this is documentation for TF2, I think using legacy here may confusing since TF2 supports graph mode.  In any case, let me open a PR and maybe we can take it from there.", "@jvishnuvardhan, please see [PR-36947](https://github.com/tensorflow/tensorflow/pull/36947)."]}, {"number": 36774, "title": "tflite: Fix typo of RPI build", "body": "There was typo on RPI build of TFLite. This PR fixes it.", "comments": []}, {"number": 36773, "title": "Support Keras grouped convolutions", "body": "This PR adds support for grouped convolutions to Keras layers.\r\n\r\nFor a more in-depth discussion see https://github.com/keras-team/governance/pull/16\r\n\r\nCloses #36431", "comments": ["@gbaned @fchollet Any updates on this?", "Any updates? Grouped convolutions seem to be used a lot more these days and I look forward to seeing it in tf-keras.", "+1, this would be extremely useful to have.", "Somehow this wasn't in my radar. Looking into it now.", "> Somehow this wasn't in my radar. Looking into it now.\r\n\r\n@tanzhenyu thanks for checking it out :+1:", "Looks like `api_compatibility_test` fails on CI. I'll rebase and update the API goldens. This might take a few hours on my machine though since I don't have a warm build cache.\r\n\r\n> Though it'd be nice to add test for DepthwiseConv as well\r\n\r\nGood idea, I will do that once TF finished building on my machine. I only thought about that this can be used for testing when writing https://github.com/tensorflow/tensorflow/pull/36773#discussion_r404294541", "> Looks like `api_compatibility_test` fails on CI. I'll rebase and update the API goldens. This might take a few hours on my machine though since I don't have a warm build cache.\r\n> \r\n> > Though it'd be nice to add test for DepthwiseConv as well\r\n> \r\n> Good idea, I will do that once TF finished building on my machine. I only thought about that this can be used for testing when writing [#36773 (comment)](https://github.com/tensorflow/tensorflow/pull/36773#discussion_r404294541)\r\n\r\nYep I'm not sure if you can run `bazel run third_party/tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True`?", "@tanzhenyu I improved the tests in 52160bc31c19a2fa1be5d8df3f09ccd50ea343d8 and rebased onto master so that the API snapshot update won't introduce any merge conflicts.\r\n\r\n> Yep I'm not sure if you can run bazel run third_party/tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True\r\n\r\nI am trying it now, but it's still compiling \ud83d\ude1e. Feel free to update the API snapshots during the internal merge.", "> @tanzhenyu I improved the tests in [52160bc](https://github.com/tensorflow/tensorflow/commit/52160bc31c19a2fa1be5d8df3f09ccd50ea343d8) and rebased onto master so that the API snapshot update won't introduce any merge conflicts.\r\n> \r\n> > Yep I'm not sure if you can run bazel run third_party/tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True\r\n> \r\n> I am trying it now, but it's still compiling \ud83d\ude1e. Feel free to update the API snapshots during the internal merge.\r\n\r\nThere is no \"internal merge\" before this PR passes all CI builds (unfortunately). If the bazel run doesn't work, you can probably manually edit the .pbtxt files.", "@tanzhenyu I updated the goldens in 212616f0cae39ac2ccfcc2988eca5fcb3161cdf4.\r\n\r\nUnfortunately the `api_compatibility_test` segfaults on my machine, but it seems to work when only checking the `keras.layers` APIs endpoints, so hopefully CI will be happy with it.\r\n\r\nSorry for the cumbersome review process, but a fast response time for non-trivial changes is sadly not possible for me when the TF build takes an entire night to run \ud83d\ude09 ", "> @tanzhenyu I updated the goldens in [212616f](https://github.com/tensorflow/tensorflow/commit/212616f0cae39ac2ccfcc2988eca5fcb3161cdf4).\r\n> \r\n> Unfortunately the `api_compatibility_test` segfaults on my machine, but it seems to work when only checking the `keras.layers` APIs endpoints, so hopefully CI will be happy with it.\r\n> \r\n> Sorry for the cumbersome review process, but a fast response time for non-trivial changes is sadly not possible for me when the TF build takes an entire night to run \ud83d\ude09\r\n\r\nNo worries. We're working on faster build time these days.\r\nI'm slightly worried about the position of this argument. We would usually put this at end of all positional arguments for backward compatibility reasons.", "> I'm slightly worried about the position of this argument. We would usually put this at end of all positional arguments for backward compatibility reasons.\r\n\r\nPersonally I think the current placement makes the most sense. It is before `activation` and `use_bias` that change the output after doing the convolution and before configuration of initializers and constraints. But it is the last argument that changes the actual convolution operations (i.e. after `filters`, `kernel_size`, `strides`, `dilation`, ...). This is also where [PyTorch places the groups argument](https://pytorch.org/docs/stable/nn.html#conv2d) though that shouldn't influence this decision too much.\r\n\r\nI wouldn't expect most users to change the `data_format` format keyword, so my gut feeling is that every keyword argument after `data_format` will likely not be addressed via positional arguments anyway. But I agree technically this might be a breaking change for some users.\r\nI am not sure what the general policy for TensorFlow is, but adding it behind the `name` keyword seems not very consistent. Are there any plans to make some arguments [keyword only](https://www.python.org/dev/peps/pep-3102/), so that future additions like this can be made without risking breaking user code?", "> > I'm slightly worried about the position of this argument. We would usually put this at end of all positional arguments for backward compatibility reasons.\r\n> \r\n> Personally I think the current placement makes the most sense. It is before `activation` and `use_bias` that change the output after doing the convolution and before configuration of initializers and constraints. But it is the last argument that changes the actual convolution operations (i.e. after `filters`, `kernel_size`, `strides`, `dilation`, ...). This is also where [PyTorch places the groups argument](https://pytorch.org/docs/stable/nn.html#conv2d) though that shouldn't influence this decision too much.\r\n> \r\n> I wouldn't expect most users to change the `data_format` format keyword, so my gut feeling is that every keyword argument after `data_format` will likely not be addressed via positional arguments anyway. But I agree technically this might be a breaking change for some users.\r\n> I am not sure what the general policy for TensorFlow is, but adding it behind the `name` keyword seems not very consistent. Are there any plans to make some arguments [keyword only](https://www.python.org/dev/peps/pep-3102/), so that future additions like this can be made without risking breaking user code?\r\n\r\nYeah putting `group` here makes sense. Though for compatibility reasons I would imagine putting it after activation would be better, since most users specify up until activation. (For Resnet they might set `use_bias=False` as well). But I believe they would most likely achieve this by keywords. \r\n\r\nAFAIK we don't have this plan. If you would like to contribute, that'd be great.", "> Though for compatibility reasons I would imagine putting it after activation would be better, since most users specify up until activation. (For Resnet they might set `use_bias=False` as well). But I believe they would most likely achieve this by keywords.\r\n\r\nI cannot judge how important backwards compatibility to the TensorFlow team is so I'm happy to follow your lead.\r\nIn my personal experience I had to make some adjustment after most minor TF version upgrades anyway so as long as it is mentioned in the release notes I would prefer consistent argument placement over backwards compatibility in this case, but your mileage might vary.\r\n\r\n> AFAIK we don't have this plan. If you would like to contribute, that'd be great.\r\n\r\nI'm happy to contribute it, though this would definitely be a breaking change then (though one with a very clear error message and simple upgrade path).\r\nThis largely depends on if TensorFlow already accepts Python 3 only code, since AFAIK keyword only arguments are not supported in Python 2.", "> This largely depends on if TensorFlow already accepts Python 3 only code, since AFAIK keyword only arguments are not supported in Python 2.\r\n\r\n@lgeiger The team only ships Python 3 binaries these days so I believe it's fine. Btw thanks for the detailed explanation of grouped/depthwise convolution in the review comments. Very helpful indeed.", "@tanzhenyu Thanks for the approval! Looks like the tests are passing, is there anything that is left to do before this can be merged?", "@lgeiger Hi, thanks for ur implementation. Did u test the speed ?, it seems that ur group conv very slow, even with group = input filters, it's still run very slow compared with normal convolution.", "> Hi, thanks for ur implementation. Did u test the speed ?, it seems that ur group conv very slow, even with group = input filters, it's still run very slow compared with normal convolution.\r\n\r\nI did not benchmark this code, as it only implements a user facing Keras API that relies on `tf.nn.convolution` to execute the actual grouped convolution either using CUDNN or XLA.", ">  it seems that ur group conv very slow, even with group = input filters, it's still run very slow compared with normal convolution.\r\n\r\n@dathudeptrai How does the performance of the native grouped convolutions implemented in this PR compare to a loop based implementation as mentioned in https://github.com/tensorflow/tensorflow/pull/36773#discussion_r404294541?", "@lgeiger hi, the problem is not about this PR. The problem cause it run very slow is that i apply mixed precision training for group convolution (mixed preicision is still speedup when apply for normal convolution :D).", "> hi, the problem is not about this PR. The problem cause it run very slow is that i apply mixed precision training for group convolution (mixed preicision is still speedup when apply for normal convolution :D).\r\n\r\nMakes sense. @dathudeptrai I think it would be best to open a new issue for this.", "@gbaned It looks like the PR is approved and CI, including the internal `import/copybara` review, is green. Is there a reason why this PR hasn't been merged, or is this a problem with copybara.\r\n\r\nLet me know if there is still something that needs clarification.", "@lgeiger Can you please check @jsimsa comments and keep us posted. Thanks!", "CI currently fails on this PR due to a build failure that has been fixed on master, I am happy to rebase if that helps.\r\n\r\n@gbaned @jsimsa @fchollet @tanzhenyu This PR has now been open for over two and a half months, is there anything that is still blocking this from being merged?", "This seems to be reverted in dd2ea875d92eeb83e81b1cb92e29e61d488e98b2.", "> This seems to be reverted in [dd2ea87](https://github.com/tensorflow/tensorflow/commit/dd2ea875d92eeb83e81b1cb92e29e61d488e98b2).\r\n\r\nIt broke the gpu unit tests which was added in this PR.\r\n\r\nSome obscured error message:\r\nTraceback (most recent call last):\r\n  File \"/third_party/tensorflow/python/keras/layers/convolutional_test.py\", line 393, in test_group_conv\r\n    self.assertAllClose(layer(inputs), expected_outputs, rtol=1e-5)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 1217, in decorated\r\n    return f(*args, **kwds)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 2598, in assertAllClose\r\n    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol, msg=msg)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 2558, in _assertAllCloseRecursive\r\n    (path_str, path_str, msg)))\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 2451, in _assertArrayLikeAllClose\r\n    a = self._GetNdArray(a)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 2445, in _GetNdArray\r\n    a = self.evaluate(a)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 2151, in evaluate\r\n    return sess.run(tensors)\r\n  File \"/third_party/tensorflow/python/framework/test_util.py\", line 1683, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"/third_party/tensorflow/python/client/session.py\", line 958, in run\r\n    run_metadata_ptr)\r\n  File \"/third_party/tensorflow/python/client/session.py\", line 1181, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/third_party/tensorflow/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/third_party/tensorflow/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nthird_party.tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\r\n  (0) Failed precondition: Read of uninitialized variable \r\n\t [[node conv1d/BiasAdd/ReadVariableOp (defined at /third_party/tensorflow/python/keras/layers/convolutional_test.py:393) ]]\r\n\t [[xla_compile]]\r\n\t [[xla_run/_1]]\r\n  (1) Failed precondition: Read of uninitialized variable \r\n\t [[node conv1d/BiasAdd/ReadVariableOp (defined at /third_party/tensorflow/python/keras/layers/convolutional_test.py:393) ]]\r\n\t [[xla_compile]]", "@tanzhenyu This is strange, since CI passed in this PR. Do you think this could be related to unrelated changes, since this PR has been opened almost three months ago?\r\n\r\nUnfortunately I am currently not able to easily reproduce this since I don't have a GPU available. However, I checked that the added test passes when executing with XLA CPU.\r\n\r\nShould I rebase this PR and open it again, so CI can run?\r\n", "I resubmitted the changes in #39516", "@gbaned @jsimsa @fchollet @tanzhenyu I resubmitted the changes at #39516 and locally verified that the tests don't fail when rebased on latest master. Could you please take another look and approve the resubmission so that CI can run?\r\n\r\nThis PR has now been pending for over 3 months and the RFC for even longer. It would be great to be able to land this soon.", "#39516 has been merged, thank you all for the detailed reviews \ud83d\ude80 "]}]