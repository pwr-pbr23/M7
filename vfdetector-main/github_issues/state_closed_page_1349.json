[{"number": 12613, "title": "tensorflow installation error", "body": "I have installed tensorflow and keras. I have used virtualenviroment given in tensorflow website. It is showing the below error when I try to import keras with tensorflow as backend\r\n\r\n\r\n CPU_COUNT = psutil.cpu_count()\r\nAttributeError: 'module' object has no attribute 'cpu_count'\r\n\r\ntensorflow version = Version: 1.3.0\r\n\r\nkeras = Version: 2.0.7\r\n\r\ndask = Version: 0.15.0\r\n\r\npandas = Version: 0.20.3\r\n\r\nFor detailed error, attaching the image\r\n![untitled](https://user-images.githubusercontent.com/18217467/29738791-2213765e-8a4b-11e7-8305-b3fa516097f1.png)\r\n", "comments": ["First try running\r\n`sudo pip install --upgrade psutil`\r\nto make sure you have the latest version of psutil, as `cpu_count` was added in version 2.0. Beyond that, this issue seems to be a duplicate of https://github.com/tensorflow/tensorflow/issues/6513 .", "This worked.."]}, {"number": 12612, "title": "Eager execution with string tensors.", "body": "@alextp String tensors seem to cause lots of errors for me, when using the eager execution API, that do not occur when using normal ops and executing them using a session.\r\n\r\nThe way I'm creating string tensors is by allocating a `TF_Tensor` with the right data type, shape, and size (where I use `TF_StringEncodedSize` to get the byte sizes of each element). Then, I encode the strings using `TF_StringEncode` and write them in the tensor buffer along with the offset table, as described [here](https://github.com/tensorflow/tensorflow/blob/752dcb61ef7a8fd6555909dc37c1f2a2e5792227/tensorflow/c/c_api.h#L211). Afterwards, I call `TFE_NewTensorHandle` to get an eager tensor handle and I delete the `TF_Tensor` object. This works fine for normal op construction and execution using sessions, but it fails for eager execution. Often I get a `check failed: IsAligned()` error from `tensor.cc`, but other times the whole application crashes, such as in the example that follows:\r\n\r\n```scala\r\nval t = Tensor.fill(STRING, Shape())(\"test\")  // The generated tensor is good. \r\n                                              // I can access its elements and use it \r\n                                              // with session execution.\r\nval tt = tfe.stack(Seq(t, t))  // I can no longer access the tensor elements correctly \r\n                               // and when I try to slice it I get either errors (crashing) \r\n                               // or empty strings.\r\ntt.unstack(2)                  // Crashes with the error shown below.\r\n```\r\n\r\nThis is run using my Scala API but I hope that the error I get may help resolve it. In the error stacktrace I get this:\r\n\r\n```\r\nStack: [0x0000700011571000,0x0000700011671000],  sp=0x000070001166cbf0,  free space=1006k\r\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\nC  [libsystem_platform.dylib+0x15da]  _platform_memmove$VARIANT$Nehalem+0x1da\r\nC  [libc++.1.dylib+0x3af29]  _ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC2ERKS5_+0x8d\r\nC  [libtensorflow.so+0x502fdb]  _ZNSt3__110__function6__funcIZN5Eigen8internal14TensorExecutorIKNS2_14TensorAssignOpINS2_9TensorMapINS2_6TensorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEELi1ELi1ElEELi16ENS2_11MakePointerEEEKNS2_15TensorSlicingOpIKNS2_6DSizesIlLi1EEESK_KNS6_INS7_IKSD_Li1ELi1ElEELi16ESF_EEEEEENS2_16ThreadPoolDeviceELb0EE3runERSS_RKST_EUlllE_NSB_ISY_EEFvllEEclEOlS12_+0x5b\r\nC  [libtensorflow.so+0x1aa30d]  _ZNK5Eigen16ThreadPoolDevice11parallelForElRKNS_12TensorOpCostENSt3__18functionIFllEEENS5_IFvllEEE+0xbd\r\nC  [libtensorflow.so+0x502ebf]  _ZN5Eigen8internal14TensorExecutorIKNS_14TensorAssignOpINS_9TensorMapINS_6TensorINSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEELi1ELi1ElEELi16ENS_11MakePointerEEEKNS_15TensorSlicingOpIKNS_6DSizesIlLi1EEESI_KNS3_INS4_IKSB_Li1ELi1ElEELi16ESD_EEEEEENS_16ThreadPoolDeviceELb0EE3runERSQ_RKSR_+0x11f\r\nC  [libtensorflow.so+0x5a06f6]  _ZN10tensorflow22HandleStridedSliceCaseIN5Eigen16ThreadPoolDeviceENSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEELi1EEEvPNS_15OpKernelContextERKNS_3gtl10ArraySliceIxEESG_SG_RKNS_11TensorShapeEbPNS_6TensorE+0x136\r\nC  [libtensorflow.so+0x58b082]  _ZN10tensorflow14StridedSliceOpIN5Eigen16ThreadPoolDeviceENSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEE7ComputeEPNS_15OpKernelContextE+0x5f2\r\nC  [libtensorflow.so+0x1c60b9b]  _ZN10tensorflow16ThreadPoolDevice7ComputeEPNS_8OpKernelEPNS_15OpKernelContextE+0x13b\r\nC  [libtensorflow.so+0x8585]  _ZN10tensorflow15KernelAndDevice3RunEPNSt3__16vectorINS_6TensorENS1_9allocatorIS3_EEEES7_+0x285\r\nC  [libtensorflow.so+0x47ce]  TFE_Execute+0x36e\r\n```\r\n\r\n**EDIT:** The following error seems to actually come up with all tensor data types, for various ops (such as the `\"Unpack\"` op).\r\n\r\nAnother time I also got this error:\r\n\r\n```\r\nC  [libtensorflow.so+0x20f0]  TFE_TensorHandleDeviceName+0x0\r\n```", "comments": ["I think I've traced it down to the eager API not using the `TF_TensorToTensor` function to convert from the `TF_Tensor` representation for string tensors, to that used internally. I guess my question is, why are the two formats different? And, if I want to avoid the copying done by `TF_TensorToTensor`, what is the underlying format being used so I replicate it?\r\n\r\nIn either case, not using `TF_TensorToTensor` introduces an inconsistency in the way `TF_Tensor` and eager tensors interact.\r\n\r\nAll that is assuming that I am correct about where the problem lies.", "Asim, this seems suspicious. Can you take a look?\r\n\r\nAnthony, can we get reproducing code we can run? Happy to do so offline if you're still not comfortable sharing your in-progress implementation of the scala bindings.", "@alextp Closing this as it was resolved in #12627. If you are interested in a use of the eager API, all my bindings are located [here](https://github.com/eaplatanios/tensorflow_scala/tree/master/jni/src/main/native). The `generated` folder contains the eager API bindings as they are automatically generated. I am packaging the JNI bindings part of my library separately from the API and so I believe that eventually we could look into merging it with your Java API since it already supports much more functionality; or, even better, creating a separate TensorFlow sub-project containing only JNI bindings for TF. These could be usable by your Java API, my Scala API, @bpiel 's Clojure API, and probably others.", "@alextp By the way, the only issue I am currently encountering with the eager API is that I get exceptions when I invoke `TFE_Execute` for the same context, concurrently multiple times. Is a context supposed to only be used one thread at a time?", "@eaplatanios : It is intended to be thread safe. ", "Ok, I'll try to dig into what's going wrong.", "Never mind, I can't reproduce the behavior with the current master branch code so it may have been resolved or it may have been something wrong with my implementation that I resolved without realizing. :)"]}, {"number": 12611, "title": "tf.gfile.FastGFile can't read french path", "body": "tf.gfile.FastGFile(r'F:\\train\\Rubus_pedatifolius_Gen\u00e9v\\4000.jpg', 'rb').read() failed,\r\nbut, tf.gfile.FastGFile(r'C:\\Users\\d\\Desktop\\4000.jpg', 'rb').read() successed!\r\nso, is it  a bug or  tf.gfile.FastGFile can't read french path?", "comments": ["PR #11562 fixed the issue of non-ASCII character in Windows path. That PR was merged in several weeks ago. Maybe it is not part of your local TensorFlow installment yet?", "@yongtang , there are many other normal paths(non french) under the directory and they are OK. but only those french paths failed. ", "To help you, we'll need the information that is requested in the issue template. \r\n\r\nIn particular, are you using the released build of TensorFlow 1.3 or a more recent version (e.g. a nightly build)?", "@mrry \uff0cTensorFlow 1.1 + Python3.5 + Windows7 ", "@micklexqg I believe TensorFlow 1.1 was unable to process non-ASCII characters in Windows. The French char `\u00e9` is non-ASCII so the issue you encountered is expected in 1.1. \r\n\r\nPR #11562 fixed the issue of non-ASCII character in Windows several weeks ago though it seems like the PR is not included in TensorFlow 1.3. \r\n\r\nI think you may give the nightly build a try or building TensorFlow from the source (https://www.tensorflow.org/install/install_sources) if you need this feature sooner.", "@yongtang \uff0c thanks\uff0ckeep attention.", "As @yongtang mentioned, this has been fixed at HEAD but not included in a release. It will be included in the TF 1.4 release, but you can try a nightly build in the mean time.", "glad to hear that, @mrry "]}, {"number": 12610, "title": "tf.estimator.inputs.numpy_input_fn does not accept dict as labels.", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 x64\r\n- **TensorFlow installed from (source or binary)**: pip install\r\n- **TensorFlow version (use command below)**: r1.3\r\n- **Python version**:  3.5 amd 64\r\n- **Bazel version (if compiling from source)**: Used binary\r\n- **CUDA/cuDNN version**: CUDA 8.0 + CuDNN 6.0\r\n- **GPU model and memory**:  GeForce GTX 1070 8.00GiB\r\n\r\n\r\nAccording to the ```tf.estimator.Estimator``` [document](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator), estimator accept dict as labels input. However, when I creating a ```tf.estimator.inputs.numpy_input_fn``` as:\r\n```python\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": samples.astype(np.float32)},\r\n    y={'go_action': np.full(samples.shape[0], 1), 'operation': ops.astype(np.float32)},\r\n    batch_size=100,\r\n    num_epochs=None,\r\n    shuffle=True)\r\n``` \r\n\r\nthen feed it to ```estimator``` like:\r\n```python\r\naction_estimator.train(\r\n    input_fn=train_input_fn,\r\n    steps=20000,\r\n    hooks=[logging_hook])\r\n\r\n```\r\n\r\nit throw me an error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"G:/Python/onmyoji-hacker/primary/cnnopnet.py\", line 120, in <module>\r\n    hooks=[logging_hook])\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 628, in _train_model\r\n    input_fn, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 499, in _get_features_and_labels_from_input_fn\r\n    result = self._call_input_fn(input_fn, mode)\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 585, in _call_input_fn\r\n    return input_fn(**kwargs)\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\numpy_io.py\", line 109, in input_fn\r\n    if len(set(v.shape[0] for v in ordered_dict_x.values())) != 1:\r\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\numpy_io.py\", line 109, in <genexpr>\r\n    if len(set(v.shape[0] for v in ordered_dict_x.values())) != 1:\r\nAttributeError: 'dict' object has no attribute 'shape'\r\n\r\n```\r\n\r\n", "comments": ["Hi, @DeckerCHAN . [numpy_input_fn](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn) API: `y: numpy array object. None if absent.`. It confirms that `y` cannot be a dictionary. \r\n\r\nSo if I understand correctly, the issue is a feature request, right? I can work on it, however, I don't know whether tensorflower approve it. \r\n\r\nBy the way, perhaps `pandas_input_fn` needs handle DataFrame for y as well.", "@facaiy Thank you for the reply!\r\n\r\nYes, this is about a feature. I am working on a model seems like: \r\n![this](https://i.stack.imgur.com/gxxo0.png)\r\n\r\nIn fact, the model is more complex than that due to the model is used to simulate game operation. Classification is responsible for decide whether it is good time for action. Then the regression will give the details about the action. It contains a combination of CNN and RNN.\r\n\r\nSo that, when I'm training the model, I have to let model know whether I am training the classification or regression since I had a proper loss function. I'm wondering if we can feed feature with dict, why we can not feed labels with dict as well.\r\n", "Sounds reasonable! I'll open a PR next week. However, you have to wait for next release even though the PR is accepted. Or to patch the file by yourself.", "@DeckerCHAN Don't close the issue until it's resolved or rejected. So, reopen it please.", "Status on this? It's a huge limitation of the tf.estimator API that labels can only be a tensor, IMO. It would be a lot nicer to have named tensors in the case of multi-headed output.\r\n\r\nEDIT: I see that @facaiy's pr was merged to master, so the docs should be updated accordingly (e.g. https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model)", "Yes, I think the issue has been resolved. Could you close it, @DeckerCHAN. Thank you.", "I assume it's still a problem for the corresponding Pandas input_fn though, right? And similarly throughout the docs there is a very strong assumption that the output of an estimator will always be a single tensor of labels (which is not the case for a multitude of common models).\r\n\r\nOverall, it's strange that `features` can be multi-headed while `labels` cannot, and I think it should be changed to match for example how Keras does it where `Model(inputs, outputs)` takes dicts, lists or single tensors.", "Yes, I think pandas_input_fn is unchanged. And would you like to make a contribution?", "No, I fear we'll just run into problems further down the line when deploying to Serving and the like.\r\n\r\nMaybe the author of the Estimator API could clarify if it's supposed to only be used for predicting a one/multi-hot vector or if it's intended for more general usage of any models with a fit/predict workflow.\r\n\r\nMy particular use case at the moment is a stateful RNN with one sequence as input and two sequences as output (meaning I also input the previous RNN states, to work over several minibatches during inference).", "Hi, @carlthome. I don't have any experience on multi-lable problem, hence the problem is beyond my scope. However, I really appreciate your feedback, and I believe your worry should be reasonable.\r\n\r\nPerhaps it could be better to open a new issue for you and take a further discussion for Estimator API there. By the way, you might be interested in #13511.\r\n", "Hi, @DeckerCHAN. Because the PR has been merged, could you close the issue? Thanks.", "Close the issue as the PR has been merged. Thanks!"]}, {"number": 12609, "title": "Branch 166528119", "body": "", "comments": ["@jhseu, thanks for your PR! By analyzing the history of the files in this pull request, we identified @protoget, @keveman and @tensorflower-gardener to be potential reviewers."]}, {"number": 12608, "title": "gather_nd bounds checking not working", "body": "When using `gather_nd`, sometimes out-of-bounds `indices` lead to errors (bounds checking -- the expected behavior) and sometimes it seems to just read zeros. I expect it reading just other memory from the GPU, but I've never observed anything _other_ than zeros so I'm not sure. When I run on the CPU the bounds seem to be appropriately checked i.e. I get the errors desired. Here's some example code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\nprint(sess.run(tf.gather_nd(tf.zeros([5,5,5]) + 1, [[6,6,6]])))\r\nprint(sess.run(tf.gather_nd(tf.zeros([1,5]) + 1, [-50000000000000000])))\r\nprint(sess.run(tf.gather_nd(tf.reshape(tf.range(5*5*5), [5,5,5]), [[6,6,6]])))\r\n```\r\n\r\nThe first two print statements execute successfully, which is a bug: the indices are clearly out of range, and the arrays are clearly all 1's; but instead it returns an appropriately shaped array of 0's. (The +1 is not necessary to trigger the bug, but highlights that it's drawing from incorrect memory). The third line, for some reason, has the bounds checking operate correctly, and says that -- yes -- the index [6,6,6] is not in the bounds. It appears to something based on what the previous op is, _maybe_? Where some ops, such as `stack`, allow me to go outside the bounds, while others such as `reshape` don't. Here's an example interactive session to show the output I get.\r\n\r\n```python\r\nPython 3.5.2 (default, Nov 17 2016, 17:05:23) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> sess = tf.Session()\r\n2017-08-25 17:10:43.788433: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-25 17:10:43.788455: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-25 17:10:43.788463: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-25 17:10:43.788466: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-25 17:10:43.788470: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-25 17:10:43.919384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-08-25 17:10:43.919779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \r\nname: GeForce GTX 1070\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.59GiB\r\n2017-08-25 17:10:43.919795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \r\n2017-08-25 17:10:43.919801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \r\n2017-08-25 17:10:43.919814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\r\n>>> sess.run(tf.gather_nd(tf.zeros([5,5,5]) + 1, [[6,6,6]]))\r\narray([ 0.], dtype=float32)\r\n>>> sess.run(tf.gather_nd(tf.zeros([1,5]) + 1, [-50000000000000000]))\r\narray([ 0.,  0.,  0.,  0.,  0.], dtype=float32)\r\n>>> sess.run(tf.gather_nd(tf.reshape(tf.range(5*5*5), [5,5,5]), [[6,6,6]]))\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [6, 6, 6] does not index into param (shape: [5,5,5]).\r\n\t [[Node: GatherNd_2 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape/_7, GatherNd_2/indices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [6, 6, 6] does not index into param (shape: [5,5,5]).\r\n\t [[Node: GatherNd_2 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape/_7, GatherNd_2/indices)]]\r\n\r\nCaused by op 'GatherNd_2', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in gather_nd\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): flat indices[0, :] = [6, 6, 6] does not index into param (shape: [5,5,5]).\r\n\t [[Node: GatherNd_2 = GatherNd[Tindices=DT_INT32, Tparams=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape/_7, GatherNd_2/indices)]]\r\n```\r\n\r\nVersion info:\r\nLinux Mint 4.4.0-53-generic x86_64\r\nPython version 3.5.2\r\nCUDA version release 8.0, V8.0.61\r\ncuDNN version 6.0.21\r\nTensorflow version v1.3.0-rc2-20-g0787eee 1.3.0\r\nnvidia drivers version 375\r\n\r\n", "comments": ["Related: #12405 ", "@langmore, are you able to take a look?", "Any array bounds checking issues would involve digging into the C++, or maybe even the GPU kernel.  That's beyond what I can do.", "It looks like relevant bounds-checking code for the CPU is in https://github.com/tensorflow/tensorflow/blob/dff1062bbf53cd8890d8d43ea815c90ba4555ba4/tensorflow/core/kernels/gather_nd_op_cpu_impl.h#L57 The 'out_of_bounds' variable gets stored in 'error_loc' and then passed out as 'bad_i' in https://github.com/tensorflow/tensorflow/blob/e073322452e41e76754314aa75d543d071003fc5/tensorflow/core/kernels/gather_nd_op.cc#L126\r\n\r\nBut based on L144 in gather_nd_op.cc, it seems that the GPU kernel is currently not designed to do the bounds checking.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e073322452e41e76754314aa75d543d071003fc5/tensorflow/core/kernels/gather_nd_op_gpu.cu.cc#L56 shows that it deliberately returns an all-zero tensors when the bounds check fails, but doesn't report the error. L91 says something about it requiring CPU/GPU communication that I honestly don't understand. I figure this will be a #dontfix for now then? :| \r\n\r\nTagging @ebrevdo since it looks like his code (many thanks, though, for this useful function!) ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "The issue and #12405 seems both similar with #13687, which requests a bound checking for GPU . cc @ebrevdo.\r\n\r\n> It's hard to efficiently check an error condition coming off the GPU\r\n> gather_nd does in a similar case. Want to send a PR to update the documentation for those two", "Added a PR #15857 to update the docs."]}, {"number": 12607, "title": "First base version of snapcraft.yaml. Work in progress. [DO NOT MERGE]", "body": "I'm following the instructions from https://www.tensorflow.org/install/install_sources\r\n\r\nI'm using this as a tutorial. https://snapcraft.io/docs/build-snaps/python", "comments": ["https://github.com/av8ramit/tensorflow-snap"]}, {"number": 12606, "title": "Add `-Wno-write-strings` to remove the warning in external protobuf compilation", "body": "This fix is an effort based on the discussion https://github.com/tensorflow/tensorflow/issues/10838#issuecomment-311420644\r\n\r\nCurrently a big chunk (200+) of the warnings when compiling tensorflow are caused by `-Wwrite-strings` in external protobuf package:\r\n```\r\nexternal/protobuf_archive/python/google/protobuf/pyext/message_factory.cc:78:37: warning: ISO C++ forbids converting a string constant to 'char*' [-Wwrite-strings]\r\n...\r\n```\r\n\r\nAs protobuf is external, it makes sense to add the flag of `-Wno-write-strings` to reduce the number of warnings in the output.\r\n\r\nThis fix reduces 200+ warnings.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Please suggest this change directly to the protobuf repository instead. We want to minimize the amount of patching we have to do to external repos."]}, {"number": 12605, "title": "Impossible to change variable inside checkpoint", "body": "I have a checkpoint file and I want to change (increase) shapes of some Variables from this checkpoint.\r\nIt seems to be impossible using tf.assign \r\nTried to use `tf.assign()`:\r\n\r\n    `for var in tf.global_variables():\r\n         if var.name == \"22-convolutional/biases:0\":\r\n             assign = tf.assign(var, a, validate_shape=False)\r\n             sess.run(assign)`\r\n\r\nAnd then, when I am trying to execute \r\n\r\n`sess.run(tf.global_variables_initializer())`\r\n\r\nI have an error\r\n\r\n`Assign requires shapes of both tensors to match. lhs shape= [1,1,1024,60] rhs shape= [1,1,1024,55]\r\n[[Node: 22-convolutional/kernel/Adam_1/Assign = Assign[T=DT_FLOAT, \r\n_class=[\"loc:@22-convolutional/kernel\"], use_locking=true, validate_shape=true, \r\n_device=\"/job:localhost/replica:0/task:0/cpu:0\"](22-convolutional/kernel/Adam_1, zeros_51)]]`\r\n\r\nSo, is it really impossible in TF? Could it be a feature request?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I did it [here](https://stackoverflow.com/questions/45885504/cannot-assign-values-with-different-shapes-in-tensorflow)\r\nBut anyway, I didn't get answer, if it is possible to change variables inside checkpoint", "I see a response on your stackoverflow question."]}, {"number": 12604, "title": "`export_meta_graph` fails if graph has no variables", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.3\r\n- **Python version**: \r\n3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n8\r\n- **GPU model and memory**:\r\n1060\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\n\r\nx = tf.placeholder(\"float32\")\r\ny = x + x\r\ntf.train.export_meta_graph(\"test.meta\")\r\ntf.reset_default_graph()\r\ng = tf.train.import_meta_graph(\"test.meta\")\r\n```\r\nyields\r\n\r\n**INFO:tensorflow:Saver not created because there are no variables in the graph to restore**\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nThe export and import meta_graph features fail if a graph has no variables.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nx = tf.placeholder(\"float32\")\r\ny = x + x\r\ntf.train.export_meta_graph(\"test.meta\")\r\ntf.reset_default_graph()\r\ng = tf.train.import_meta_graph(\"test.meta\")\r\n```", "comments": ["It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Is this still an issue for you?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of activity. Please reopen if there is still a problem."]}, {"number": 12603, "title": "Fix TensorFlow Windows build", "body": "1. fix configure.py on Windows\r\n2. Update nsync to make it work on Windows\r\n3. disabled some failing tests.\r\n\r\n@yifeif @gunan ", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jart, @tensorflower-gardener and @wangqr to be potential reviewers.", "Jenkins, test this please", "Add @m3bm3b for nsync change. Mike updated the nsync binary to head from internal to make nsync work for cmake on macOS. Would that version also work for Windows @meteorcloudy? ", "@yifeif Just checked, yes it will work for Windows.", "Jenkins, test this please", "I'll re-enable these tests in #12680"]}, {"number": 12602, "title": "Updating install_linux.md for cuDNN 6.", "body": "@gunan does line 59 need to be updated as well?", "comments": ["Not that line, but let's convert line 58 to say CUDA 8.0 or greater\n\nOn Fri, Aug 25, 2017 at 10:19 AM, Wolff Dobson <notifications@github.com>\nwrote:\n\n> *@wolffg* approved this pull request.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12602#pullrequestreview-58712445>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOUEK6_ho8TRiZKx2zgAUA8b72oOfks5sbwI_gaJpZM4PC5Se>\n> .\n>\n"]}, {"number": 12601, "title": "Produce mask when padding batches", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: binary via pip\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See source code below\r\n\r\n### Describe the problem\r\nCurrently, the Dataset API (as well as the older queue-based API) allows for batches to be padded, but there is no way to determine which values were inserted for padding in the resulting output tensors unless care is taken to pick a padding value that will never occur in the original dataset. It would be useful if this could be indicated via a separate mask tensor that indicates this rather than having the user compute it manually (if it's even possible for their particular data). E.g., this is useful for sequential tagging (like part-of-speech tagging), where each example is a multi-word sentence and each label is actually a sequence of labels. Computing the correct losses requires knowledge of which values were just included for padding.\r\n\r\nCurrently, I do this using Fuel, which, for a given batch, gives me one array for the input data, one for the label, and then one mask each for the input and the label. The masks are binary and of the same shape as the input/label array, respectively. I then feed these into TensorFlow via the feed_dict mechanism.\r\n\r\nHere's an example from the programmer's guide:\r\n```\r\ndataset = tf.contrib.data.Dataset.range(100)\r\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\r\ndataset = dataset.padded_batch(4, padded_shapes=[None])\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nprint(sess.run(next_element))  # ==> [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]\r\nprint(sess.run(next_element))  # ==> [[4, 4, 4, 4, 0, 0, 0],\r\n                               #      [5, 5, 5, 5, 5, 0, 0],\r\n                               #      [6, 6, 6, 6, 6, 6, 0],\r\n                               #      [7, 7, 7, 7, 7, 7, 7]]\r\n```\r\nWith a mask, this might look like:\r\n```\r\ndataset = tf.contrib.data.Dataset.range(100)\r\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\r\ndataset = dataset.padded_batch(4, padded_shapes=[None], mask=True)\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nprint(sess.run(next_element))  # ==> ([[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]],\r\n                               #      [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1]])\r\nprint(sess.run(next_element))  # ==> ([[4, 4, 4, 4, 0, 0, 0],\r\n                               #       [5, 5, 5, 5, 5, 0, 0],\r\n                               #       [6, 6, 6, 6, 6, 6, 0],\r\n                               #       [7, 7, 7, 7, 7, 7, 7]],\r\n                               #      [[1, 1, 1, 1, 0, 0, 0],\r\n                               #       [1, 1, 1, 1, 1, 0, 0],\r\n                               #       [1, 1, 1, 1, 1, 1, 0],\r\n                               #       [1, 1, 1, 1, 1, 1, 1]])\r\n```\r\n\r\n(Obviously, this particular example is simple to compute manually, but imagine the case where there is no obvious padding value to pick that wouldn't occur in the data.)", "comments": ["One possible workaround is to build the mask yourself using a `map()`:\r\n\r\n```\r\ndataset = tf.contrib.data.Dataset.range(100)\r\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\r\n\r\ndef build_mask(x):\r\n  return tf.ones_like(x, dtype=tf.int32)\r\ndataset = dataset.map(lambda x: (x, build_mask(x)))\r\n\r\ndataset = dataset.padded_batch(4, padded_shapes=([None], [None]))\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n```\r\n\r\n", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 12600, "title": "Add estimators.md", "body": "Copied from master: \r\n\r\n    git checkout master -- tensorflow/docs_src/programmers_guide/estimators.md\r\n\r\nIt's already referenced in `tensorflow/docs_src/programmers_guide/leftnav_files`.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 12599, "title": "accept", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 12598, "title": "data dependent variable initialization in tf 1.3.0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ArchLinux\r\n- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: `v1.3.0-rc2-20-g0787eee 1.3.0`\r\n- **Python version**: `Python 3.6.2`\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: `cuda 8.0.61`/`cudnn6 6.0.21`\r\n- **GPU model and memory**: GeForce GTX 980M 8GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nAfter updating to tf 1.3 my usual routines for data dependent initialization of variables are broken. They take massive amounts of time and memory. I have written a minimal example to reproduce the problem (see below). In fact, the example suggests that the time increases exponentially with the number of layers, i.e. it takes takes roughly 6, 12 and 24 seconds to initialize 10, 11 and 12 layers, respectively. On a different machine running on tf 1.2.1 the same code initializes 100 layers in less than a second yet it produces the same, correct values. Similiarly, the (host) memory usage explodes. I should also mention that the issue appears when defining the graph, i.e. before any session is opened, and not during execution of the initialization operation.\r\n\r\nI would be glad if someone can point out a better way of doing the kind of data dependent initialization shown in the example (using two passes is somewhat annoying) but the issue is that the update made this method completely unusable. [Traceback from keyboard interrupt](https://github.com/tensorflow/tensorflow/files/1251882/traceback.txt) suggest that the recently introduced [`_build_initializer_expr`](https://github.com/tensorflow/tensorflow/blob/ebc421daf2c812fdfc3007294741c6c07f4957c3/tensorflow/python/ops/variables.py#L763) might be involved.\r\n\r\n### Source code / logs\r\n\r\n    import time\r\n    import tensorflow as tf\r\n\r\n    def layer(x, name, init):\r\n        with tf.variable_scope(name, reuse = not init):\r\n            initializer = x\r\n            b = tf.get_variable('b', dtype=tf.float32, initializer = initializer)\r\n            # without next if we get error\r\n            # 'Attempting to use uninitialized variable.'\r\n            # for layer 1\r\n            if init:\r\n                return x + b.initialized_value()\r\n            else:\r\n                return x + b\r\n\r\n\r\n    if __name__ == \"__main__\":\r\n        n_layers = 10\r\n\r\n        print(\"tensorflow {} {}\".format(tf.GIT_VERSION, tf.VERSION))\r\n        print(\"n_layers {}\".format(n_layers))\r\n\r\n        def _pass(x, init):\r\n            h = x\r\n            for i in range(n_layers):\r\n                h = layer(h, \"layer_{}\".format(i), init)\r\n            return h\r\n        \r\n        # first pass for initialization\r\n        x = tf.constant([1.0])\r\n        t = time.time()\r\n        h = _pass(x, True)\r\n        print(\"init pass {:.4}\".format(time.time() - t))\r\n\r\n        # second pass as usual\r\n        t = time.time()\r\n        h = _pass(x, False)\r\n        print(\"next pass {:.4}\".format(time.time() - t))\r\n\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            print(\"final value {}\".format(h.eval()))\r\n\r\n\r\nThis is basically the data dependent initialization method as described in [OpenAI's weight norm code](https://github.com/openai/weightnorm) stripped down to the bare minimum where the problem occurs. This weight normalization code as well as the [PixelCNN++ code](https://github.com/openai/pixel-cnn) are also affected by this.\r\n\r\nOutput on 1.3.0:\r\n\r\n    tensorflow v1.3.0-rc2-20-g0787eee 1.3.0\r\n    n_layers 10\r\n    init pass 5.934\r\n    next pass 0.003919\r\n    final value [ 1024.]\r\n\r\nOutput on 1.2.1 (different machine):\r\n\r\n    tensorflow 1.2.1\r\n    n_layers 10\r\n    init pass 0.1085\r\n    next pass 0.00644\r\n    final value [ 1024.]\r\n\r\n\r\n\r\n\r\n", "comments": ["I have exactly the same problem. \r\n\r\nAny idea on how to solve/avoid this?\r\n\r\nA related issue [4920](https://github.com/tensorflow/tensorflow/issues/4920).\r\n\r\nI also find it recursively calls the _build_initializer_expr. ", "Indeed, the problem seems to be with `_build_initializer_expr` and its exhaustive graph traversal. Just replacing this function with an identity function works fine for me so I'm not sure why it is needed.\r\n\r\nAs a workaround without modifying tensorflow code, I found that one can use an arbitrary initializer for variables and then work with the node returned from an assign op during the initialization pass. This should automatically propagate dependencies and works without modification of tensorflow code. \r\n\r\nEdit: Example for PixelCNN https://github.com/pesser/pixel-cnn/blob/c625c9d033683bcb9a149245bc4b11951b4f3634/pixel_cnn_pp/nn.py#L190\r\n  ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "@benoitsteiner can you take a look or redirect? Thanks!", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I still think something's off with `_build_initializer_expr` but there is a workaround and I don't expect any activity."]}, {"number": 12597, "title": "TF-Slim can't exclude variables when import data from checkpoint files", "body": "I exclude variables that don't exist in the checkpoint file by using the he func \r\n\r\n          variables_to_restore = slim.get_variables_to_restore(exclude=exclude_set) \r\n\r\nthese variables come from slim.train.MomentumOptimizer() which include  '../momentum:0' in name.But the program seems to still try to find them in the checkpoint.This really confusing me. Anyone can help me?\r\n\r\n\r\nThe link of stackoverflow is:\r\nhttps://stackoverflow.com/questions/45877948/tf-slim-cant-exclude-variables-when-import-data-from-checkpoint-files", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I think it is a bug. I am fine-tuning VGG16  to MNIST and would like to replace the fc8 layer. Here are my results:\r\n(1) When I run\r\n```\r\n    variables_to_restore =  slim.get_variables_to_restore(exclude=['fc8'])\r\n    print(variables_to_restore)\r\n```\r\nI got\r\n`[<tf.Variable 'vgg_16/conv1/conv1_1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc8/weights:0' shape=(1, 1, 4096, 10) dtype=float32_ref>, <tf.Variable 'vgg_16/fc8/biases:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'global_step:0' shape=() dtype=int64_ref>]`\r\n\r\n(2) When I run\r\n```\r\n    variables_to_restore2 =  slim.get_variables_to_restore()\r\n    print(variables_to_restore2)\r\n```\r\n`\r\nI got\r\n[<tf.Variable 'vgg_16/conv1/conv1_1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc8/weights:0' shape=(1, 1, 4096, 10) dtype=float32_ref>, <tf.Variable 'vgg_16/fc8/biases:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'global_step:0' shape=() dtype=int64_ref>]\r\n`\r\n.\r\n\r\n(1) and (2) have identical outputs.\r\n\r\n\r\n\r\n"]}, {"number": 12595, "title": "[Slim]No cross validation in inception?", "body": "\r\nI run the code for fine tune inception in slim. but I find that only train split is used when training. so is there no  cross validation in inception?  how should I stop training(just at the max_steps)? what's validation split for? (evaluate the trained model?)  ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12594, "title": "fix: profiler bazel build usage", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 12593, "title": "Android Demo - Bug - Exception in TF Detect activity", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nAt build.gradle (Module: android)\r\ndef nativeBuildSystem = 'none'\r\nAt CameraActivity.java:\r\nuseCamera2API = true;\r\nSuggested by @andrewharp at #12431\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows version: 10 Pro\r\nAndroid version: 6.0.1\r\nDemo version: commit 18e4590\r\n- **TensorFlow installed from (source or binary)**:\r\nx\r\n- **TensorFlow version (use command below)**:\r\nx\r\n- **Python version**:\r\nx \r\n- **Bazel version (if compiling from source)**:\r\nx\r\n- **CUDA/cuDNN version**:\r\nx\r\n- **GPU model and memory**:\r\nx\r\n- **Exact command to reproduce**:\r\nx\r\n\r\n### Describe the problem\r\nRunning the activity TF Detect after installing the project with Android Studio results in an IllegalArgumentException being thrown.\r\n\r\nThe problem has been noticed before with other configurations at issue #12431 and pull request #10771 and tested recently by @ArtsiomCh  using CMake and Ubuntu.\r\n\r\n### Source code / logs\r\n```\r\n08-25 11:46:10.596 9185-9185/? I/art: Late-enabling -Xcheck:jni\r\n08-25 11:46:10.636 9185-9185/? D/TidaProvider: TidaProvider()\r\n08-25 11:46:10.722 9185-9185/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.DetectorActivity@df7138f\r\n08-25 11:46:10.749 9185-9185/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n08-25 11:46:10.784 9185-9185/org.tensorflow.demo I/tensorflow: CameraActivity: Camera API lv2?: true\r\n08-25 11:46:10.788 9185-9185/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.DetectorActivity@df7138f\r\n08-25 11:46:10.788 9185-9185/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.DetectorActivity@df7138f\r\n08-25 11:46:10.796 9185-9217/org.tensorflow.demo D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\r\n08-25 11:46:10.801 9185-9185/org.tensorflow.demo D/ActivityThreadInjector: clearCachedDrawables.\r\n08-25 11:46:10.840 9185-9217/org.tensorflow.demo I/Adreno: QUALCOMM build                   : a7823f5, I59a6815413\r\n                                                           Build Date                       : 09/23/16\r\n                                                           OpenGL ES Shader Compiler Version: XE031.07.00.00\r\n                                                           Local Branch                     : mybranch22028469\r\n                                                           Remote Branch                    : quic/LA.BR.1.3.3_rb2.26\r\n                                                           Remote Branch                    : NONE\r\n                                                           Reconstruct Branch               : NOTHING\r\n08-25 11:46:10.846 9185-9217/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n08-25 11:46:10.858 9185-9185/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480\r\n08-25 11:46:10.858 9185-9185/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Valid preview sizes: [1280x960, 1280x720, 864x480, 640x640, 800x480, 720x480, 640x480, 480x640]\r\n08-25 11:46:10.859 9185-9185/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Rejected preview sizes: [832x468, 768x432, 576x432, 640x360, 480x360, 480x320, 384x288, 352x288, 320x240, 240x320, 240x160, 176x144]\r\n08-25 11:46:10.859 9185-9185/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Exact size match found.\r\n08-25 11:46:10.861 9185-9185/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n08-25 11:46:10.861 9185-9185/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: person\r\n... Etc.\r\n08-25 11:46:10.863 9185-9185/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: hair drier\r\n08-25 11:46:10.863 9185-9185/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toothbrush\r\n08-25 11:46:10.864 9185-9185/org.tensorflow.demo I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded\r\n08-25 11:46:10.864 9185-9185/org.tensorflow.demo E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n08-25 11:46:10.864 9185-9185/org.tensorflow.demo I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n08-25 11:46:10.896 9185-9185/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n08-25 11:46:12.133 9185-9185/org.tensorflow.demo I/TensorFlowInferenceInterface: Model load took 1213ms, TensorFlow version: 1.2.0\r\n08-25 11:46:12.136 9185-9185/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_mobilenet_v1_android_export.pb'\r\n08-25 11:46:12.137 9185-9185/org.tensorflow.demo I/tensorflow: DetectorActivity: Sensor orientation: 90, Screen orientation: 0\r\n08-25 11:46:12.137 9185-9185/org.tensorflow.demo I/tensorflow: DetectorActivity: Initializing at size 640x480\r\n08-25 11:46:12.139 9185-9185/org.tensorflow.demo W/tensorflow: ImageUtils: Native library not found, native RGB -> YUV conversion may be unavailable.\r\n08-25 11:46:12.148 9185-9185/org.tensorflow.demo I/CameraManager: Using legacy camera HAL.\r\n08-25 11:46:12.280 9185-9216/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 640x480\r\n08-25 11:46:12.285 9185-9216/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING\r\n08-25 11:46:12.286 9185-9217/org.tensorflow.demo E/HAL: hw_get_module_by_class: module name gralloc\r\n08-25 11:46:12.286 9185-9290/org.tensorflow.demo I/RequestThread-0: Configure outputs: 2 surfaces configured.\r\n08-25 11:46:12.286 9185-9217/org.tensorflow.demo E/HAL: hw_get_module_by_class: module name gralloc\r\n08-25 11:46:12.286 9185-9290/org.tensorflow.demo D/Camera: app passed NULL surface\r\n08-25 11:46:12.297 9185-9185/org.tensorflow.demo I/Choreographer: Skipped 85 frames!  The application may be doing too much work on its main thread.\r\n08-25 11:46:12.309 9185-9216/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state IDLE\r\n08-25 11:46:12.313 9185-9216/org.tensorflow.demo I/RequestQueue: Repeating capture request set.\r\n08-25 11:46:12.314 9185-9290/org.tensorflow.demo W/LegacyRequestMapper: convertRequestMetadata - control.awbRegions setting is not supported, ignoring value\r\n08-25 11:46:12.314 9185-9290/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n08-25 11:46:12.314 9185-9290/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n08-25 11:46:12.493 9185-9291/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CAPTURING\r\n08-25 11:46:12.515 9185-9216/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 307200\r\n08-25 11:46:12.516 9185-9216/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 153599\r\n08-25 11:46:12.516 9185-9216/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 153599\r\n08-25 11:46:12.517 9185-9216/org.tensorflow.demo E/tensorflow: ObjectTracker: libtensorflow_demo.so not found, tracking unavailable\r\n08-25 11:46:12.517 9185-9216/org.tensorflow.demo I/tensorflow: MultiBoxTracker: Initializing ObjectTracker: 640x480\r\n08-25 11:46:12.517 9185-9216/org.tensorflow.demo E/tensorflow: ObjectTracker: Native object tracking support not found. See tensorflow/examples/android/README.md for details.\r\n08-25 11:46:12.525 9185-9216/org.tensorflow.demo E/tensorflow: MultiBoxTracker: Object tracking support not found. See tensorflow/examples/android/README.md for details.\r\n08-25 11:46:12.544 9185-9216/org.tensorflow.demo E/art: No implementation found for void org.tensorflow.demo.env.ImageUtils.convertYUV420ToARGB8888(byte[], byte[], byte[], int[], int, int, int, int, int, boolean) (tried Java_org_tensorflow_demo_env_ImageUtils_convertYUV420ToARGB8888 and Java_org_tensorflow_demo_env_ImageUtils_convertYUV420ToARGB8888___3B_3B_3B_3IIIIIIZ)\r\n08-25 11:46:12.545 9185-9216/org.tensorflow.demo W/tensorflow: ImageUtils: Native YUV -> RGB implementation not found, falling back to Java implementation\r\n08-25 11:46:12.717 9185-9217/org.tensorflow.demo V/RenderScript: 0x558f6c1290 Launching thread(s), CPUs 6\r\n08-25 11:46:13.060 9185-9215/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[image_tensor], outputs:[detection_boxes, detection_scores, detection_classes, num_detections]\r\n                                                                                 \r\n                                                                                 --------- beginning of crash\r\n08-25 11:46:13.060 9185-9215/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                                                                   Process: org.tensorflow.demo, PID: 9185\r\n                                                                   java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                     device='CPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_STRING]\r\n                                                                     device='GPU'; T in [DT_BOOL]\r\n                                                                     device='GPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_FLOAT]\r\n                                                                   \r\n                                                                   \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater, Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater)]]\r\n                                                                       at org.tensorflow.Session.run(Native Method)\r\n                                                                       at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                       at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                       at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)\r\n                                                                       at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)\r\n                                                                       at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:340)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:742)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:154)\r\n                                                                       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n08-25 11:46:13.061 9185-9215/org.tensorflow.demo E/MQSEventManagerDelegate: failed to get MQSService.\r\n08-25 11:46:13.080 9185-9185/org.tensorflow.demo I/RequestQueue: Repeating capture request cancelled.\r\n08-25 11:46:13.194 9185-9327/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-9185-1] cancelBuffer: BufferQueue has been abandoned\r\n```", "comments": ["I suspect you're missing the `#define TF_CALL_bool(m)  m(bool)` addition from https://github.com/tensorflow/tensorflow/commit/53aabd5cb0ffcc1fd33cbd00eb468dd8d8353df2. Are you using an older version of the TF native libs?", "Current update: \r\nTF version shown as 1.3 in log (Master branch from GitHub on Sep 1 / 2017, head on commit a2e1a5e0985d8d2c1ec3a3f246dad214600af21c)\r\napp build at Android Studio 2.3.3 on Linux Ubuntu 16.04\r\napp tested on Meizu M2 Note (Android 5.1, API 22)\r\n\r\nWith `useCamera2API = true` TF Detect works with both `nativeBuildSystem = 'cmake'` and `nativeBuildSystem = 'none'` (i.e. with Java and native implementation of YUV to RGB transformation: `convertYUV420ToARGB8888`).\r\n\r\nWith `useCamera2API = false` TF Detect doesn't work with either `nativeBuildSystem = 'cmake'` and `nativeBuildSystem = 'none'` (Java implementation of YUV to RGB transformation `convertYUV420SPToARGB8888` used from #12622 ).\r\n Pressing the volume keys on a device doesn't toggle debug visualizations on/off.\r\nApp also doesn't produce any additional errors in the log:\r\n[TFDetect_log_cmake_CameraAPI2_false.txt](https://github.com/tensorflow/tensorflow/files/1272377/TFDetect_log_cmake_CameraAPI2_false.txt)\r\nFor comparison log of working TF Detect with `useCamera2API = true` and `nativeBuildSystem = 'cmake'`:\r\n[TFDetect_log_cmake_CameraAPI2_true.txt](https://github.com/tensorflow/tensorflow/files/1272382/TFDetect_log_cmake_CameraAPI2_true.txt)\r\n", "@andrewharp Just checked with 1.3.0 and same as @ArtsiomCh, with the camera fix TF Detect works with `nativeBuildSystem = 'none'`, without it still throws an `UnsatisfiedLinkError` for the method `convertYUV420SPToARGB8888`.", "I believe the UnsatisfiedLinkError should be fixed by @ArtsiomCh in 0e69f536c13d6db7e8276ee7ffe249a82d89f246.\r\n\r\nI've also submitted an internal commit that should be public soon which will enable the object tracker when using camera 1 API.", "I have a similar issue with the TF Detection using Samsung Galaxy S5 with android version 6,  built from Android Studio in windows 10.  After the APK was installed to the Galaxy S5, the camera preview showed for a couple seconds and then the app stopped.  the  error message is:\r\n\r\nE/BufferQueueProducer: [SurfaceTexture-1-8262-1] dequeueBuffer: min undequeued buffer count (2) exceeded (dequeued=5 undequeued=1)\r\n\r\nbelow is the logcat generated when running it:\r\n\r\note: v2\r\n10-11 09:12:02.241 8262-8262/? I/libpersona: KNOX_SDCARD checking this for 10262\r\n10-11 09:12:02.241 8262-8262/? I/libpersona: KNOX_SDCARD not a persona\r\n10-11 09:12:02.251 8262-8262/? I/SELinux: Function: selinux_compare_spd_ram, index[1], SPD-policy is existed. and_ver=SEPF_SECMOBILE_6.0.1 ver=11\r\n10-11 09:12:02.251 8262-8262/? W/SELinux: Function: selinux_compare_spd_ram, index[1], priority [2], priority version is VE=SEPF_SECMOBILE_6.0.1_0029\r\n10-11 09:12:02.251 8262-8262/? E/Zygote: accessInfo : 0\r\n10-11 09:12:02.251 8262-8262/? W/SELinux: SELinux: seapp_context_lookup: seinfo=default, level=s0:c512,c768, pkgname=org.tensorflow.demo \r\n10-11 09:12:02.251 8262-8262/? I/art: Late-enabling -Xcheck:jni\r\n10-11 09:12:02.291 8262-8262/org.tensorflow.demo D/TimaKeyStoreProvider: TimaSignature is unavailable\r\n10-11 09:12:02.291 8262-8262/org.tensorflow.demo D/ActivityThread: Added TimaKeyStore provider\r\n10-11 09:12:02.311 8262-8262/org.tensorflow.demo W/ResourcesManager: getTopLevelResources: /data/app/org.tensorflow.demo-1/base.apk / 1.0 running in org.tensorflow.demo rsrc of package null\r\n10-11 09:12:02.401 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_dependencies_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_dependencies_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.461 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_0_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_0_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.521 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_1_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_1_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.581 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_2_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_2_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.641 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_3_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_3_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.691 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_4_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_4_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.751 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_5_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_5_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.801 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_6_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_6_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.861 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_7_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_7_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.911 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_8_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_8_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.981 8262-8262/org.tensorflow.demo W/art: Failed execv(/system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --debuggable --instruction-set=arm --instruction-set-features=smp,div,atomic_ldrd_strd --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --runtime-arg -Xms64m --runtime-arg -Xmx512m --instruction-set-variant=krait --instruction-set-features=default --dex-file=/data/app/org.tensorflow.demo-1/split_lib_slice_9_apk.apk --oat-file=/data/dalvik-cache/arm/data@app@org.tensorflow.demo-1@split_lib_slice_9_apk.apk@classes.dex) because non-0 exit status\r\n10-11 09:12:02.981 8262-8262/org.tensorflow.demo I/InstantRun: starting instant run server: is main process\r\n10-11 09:12:03.021 8262-8262/org.tensorflow.demo W/ResourcesManager: getTopLevelResources: /data/app/org.tensorflow.demo-1/base.apk / 1.0 running in org.tensorflow.demo rsrc of package null\r\n10-11 09:12:03.031 8262-8262/org.tensorflow.demo W/ResourcesManager: getTopLevelResources: /data/app/org.tensorflow.demo-1/base.apk / 1.0 running in org.tensorflow.demo rsrc of package null\r\n10-11 09:12:03.031 8262-8262/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.DetectorActivity@86593f0\r\n10-11 09:12:03.051 8262-8262/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n10-11 09:12:03.061 8262-8262/org.tensorflow.demo I/tensorflow: CameraActivity: Camera API lv2?: true\r\n10-11 09:12:03.111 8262-8262/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.DetectorActivity@86593f0\r\n10-11 09:12:03.111 8262-8262/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.DetectorActivity@86593f0\r\n10-11 09:12:03.121 8262-8262/org.tensorflow.demo D/SecWifiDisplayUtil: Metadata value : none\r\n10-11 09:12:03.121 8262-8262/org.tensorflow.demo D/ViewRootImpl: #1 mView = com.android.internal.policy.PhoneWindow$DecorView{bad45dd I.E...... R.....ID 0,0-0,0}\r\n10-11 09:12:03.131 8262-8325/org.tensorflow.demo D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\r\n10-11 09:12:03.161 8262-8325/org.tensorflow.demo I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: EGL 1.4 QUALCOMM build:  (Ia10634f51b)\r\n                                                               OpenGL ES Shader Compiler Version: E031.29.00.00\r\n                                                               Build Date: 01/28/16 Thu\r\n                                                               Local Branch: ss\r\n                                                               Remote Branch: \r\n                                                               Local Patches: \r\n                                                               Reconstruct Branch: \r\n10-11 09:12:03.161 8262-8325/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0xadf907c4\r\n10-11 09:12:03.161 8262-8325/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n10-11 09:12:03.191 8262-8262/org.tensorflow.demo D/ViewRootImpl: MSG_RESIZED_REPORT: ci=Rect(0, 0 - 0, 0) vi=Rect(0, 0 - 0, 0) or=1\r\n10-11 09:12:03.211 8262-8262/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480\r\n10-11 09:12:03.211 8262-8262/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Valid preview sizes: [1920x1080, 1440x1080, 1280x720, 1056x864, 960x720, 800x480, 720x480, 640x480]\r\n10-11 09:12:03.211 8262-8262/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Rejected preview sizes: [352x288, 320x240, 176x144]\r\n10-11 09:12:03.211 8262-8262/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Exact size match found.\r\n10-11 09:12:03.221 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.221 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: person\r\n10-11 09:12:03.221 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bicycle\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: car\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: motorcycle\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: airplane\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bus\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: train\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: truck\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: boat\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: traffic light\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: fire hydrant\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: stop sign\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: parking meter\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bench\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bird\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cat\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: dog\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: horse\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sheep\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cow\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: elephant\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bear\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: zebra\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: giraffe\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: backpack\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: umbrella\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: handbag\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tie\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: suitcase\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: frisbee\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: skis\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: snowboard\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sports ball\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: kite\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: baseball bat\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: baseball glove\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: skateboard\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: surfboard\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tennis racket\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bottle\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: wine glass\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cup\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: fork\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: knife\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: spoon\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bowl\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: banana\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: apple\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sandwich\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: orange\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: broccoli\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: carrot\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: hot dog\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: pizza\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: donut\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cake\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: chair\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: couch\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: potted plant\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bed\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: dining table\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toilet\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.231 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tv\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: laptop\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: mouse\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: remote\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: keyboard\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cell phone\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: microwave\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: oven\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toaster\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sink\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: refrigerator\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: book\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: clock\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: vase\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: scissors\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: teddy bear\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: hair drier\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toothbrush\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n10-11 09:12:03.241 8262-8262/org.tensorflow.demo I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n10-11 09:12:03.311 8262-8262/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n10-11 09:12:05.351 8262-8262/org.tensorflow.demo I/TensorFlowInferenceInterface: Model load took 1996ms, TensorFlow version: 1.3.0-rc2\r\n10-11 09:12:05.351 8262-8262/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_mobilenet_v1_android_export.pb'\r\n10-11 09:12:05.361 8262-8262/org.tensorflow.demo I/tensorflow: DetectorActivity: Sensor orientation: 90, Screen orientation: 0\r\n10-11 09:12:05.361 8262-8262/org.tensorflow.demo I/tensorflow: DetectorActivity: Initializing at size 640x480\r\n10-11 09:12:05.391 8262-8262/org.tensorflow.demo I/CameraManager: Using legacy camera HAL.\r\n10-11 09:12:05.651 8262-8262/org.tensorflow.demo W/DisplayListCanvas: DisplayListCanvas is started on unbinded RenderNode (without mOwningView)\r\n10-11 09:12:05.651 8262-8324/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 640x480\r\n10-11 09:12:05.661 8262-8324/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING\r\n10-11 09:12:05.661 8262-8399/org.tensorflow.demo I/RequestThread-0: Configure outputs: 2 surfaces configured.\r\n10-11 09:12:05.671 8262-8399/org.tensorflow.demo D/Camera: app passed NULL surface\r\n10-11 09:12:05.681 8262-8401/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0x9dcfc3f4\r\n10-11 09:12:05.691 8262-8262/org.tensorflow.demo I/Choreographer: Skipped 148 frames!  The application may be doing too much work on its main thread.\r\n10-11 09:12:05.701 8262-8262/org.tensorflow.demo I/Timeline: Timeline: Activity_idle id: android.os.BinderProxy@9ab15b4 time:19994310\r\n10-11 09:12:05.751 8262-8324/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state IDLE\r\n10-11 09:12:05.751 8262-8324/org.tensorflow.demo I/RequestQueue: Repeating capture request set.\r\n10-11 09:12:05.751 8262-8399/org.tensorflow.demo W/LegacyRequestMapper: convertRequestMetadata - control.awbRegions setting is not supported, ignoring value\r\n10-11 09:12:05.751 8262-8399/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n10-11 09:12:05.751 8262-8399/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n10-11 09:12:06.441 8262-8401/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0x9dcfc2fc\r\n10-11 09:12:06.441 8262-8401/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CAPTURING\r\n10-11 09:12:06.471 8262-8325/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0xadf9062c\r\n10-11 09:12:06.481 8262-8324/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 307200\r\n10-11 09:12:06.481 8262-8324/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 153599\r\n10-11 09:12:06.481 8262-8324/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 153599\r\n10-11 09:12:06.501 8262-8324/org.tensorflow.demo I/tensorflow: MultiBoxTracker: Initializing ObjectTracker: 640x480\r\n10-11 09:12:06.501 8262-8324/org.tensorflow.demo I/native: Initializing object tracker. 320x240 @0xae1b8cdc\r\n10-11 09:12:06.501 8262-8294/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] dequeueBuffer: min undequeued buffer count (2) exceeded (dequeued=5 undequeued=1)\r\n10-11 09:12:06.501 8262-8401/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0x9dcfc2fc\r\n10-11 09:12:06.501 8262-8324/org.tensorflow.demo I/native: Initialized!\r\n10-11 09:12:06.511 8262-8324/org.tensorflow.demo I/tensorflow: DetectorActivity: Preparing image 1 for detection in bg thread.\r\n10-11 09:12:06.521 8262-8325/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0xadf9062c\r\n10-11 09:12:06.561 8262-8323/org.tensorflow.demo I/tensorflow: DetectorActivity: Running detection on image 1\r\n10-11 09:12:06.571 8262-8401/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0x9dcfc2fc\r\n10-11 09:12:06.641 8262-8401/org.tensorflow.demo D/libEGL: eglInitialize EGLDisplay = 0x9dcfc2fc\r\n10-11 09:12:07.281 8262-8323/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[image_tensor], outputs:[detection_boxes, detection_scores, detection_classes, num_detections]\r\n10-11 09:12:07.281 8262-8323/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                                                                   Process: org.tensorflow.demo, PID: 8262\r\n                                                                   java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                     device='GPU'; T in [DT_STRING]\r\n                                                                     device='GPU'; T in [DT_BOOL]\r\n                                                                     device='GPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_INT32]\r\n                                                                   \r\n                                                                   \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater, Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater)]]\r\n                                                                       at org.tensorflow.Session.run(Native Method)\r\n                                                                       at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                       at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                       at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:143)\r\n                                                                       at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)\r\n                                                                       at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:293)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:739)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:158)\r\n                                                                       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n10-11 09:12:07.341 8262-8262/org.tensorflow.demo I/RequestQueue: Repeating capture request cancelled.\r\n10-11 09:12:07.401 8262-8401/org.tensorflow.demo D/libEGL: eglTerminate EGLDisplay = 0x9dcfc48c\r\n10-11 09:12:07.401 8262-8401/org.tensorflow.demo D/libEGL: eglTerminate EGLDisplay = 0x9dcfc414\r\n10-11 09:12:07.401 8262-8401/org.tensorflow.demo D/libEGL: eglTerminate EGLDisplay = 0x9dcfc414\r\n10-11 09:12:07.401 8262-8401/org.tensorflow.demo D/libEGL: eglTerminate EGLDisplay = 0x9dcfc414\r\n10-11 09:12:07.401 8262-8401/org.tensorflow.demo D/libEGL: eglTerminate EGLDisplay = 0x9dcfc414\r\n10-11 09:12:07.441 8262-8304/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] dequeueBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.441 8262-8294/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] queueBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.701 8262-8291/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] cancelBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.701 8262-8274/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] cancelBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.701 8262-8273/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] cancelBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.701 8262-8297/org.tensorflow.demo E/BufferQueueProducer: [SurfaceTexture-1-8262-1] cancelBuffer: BufferQueue has been abandoned\r\n10-11 09:12:07.931 8262-8262/org.tensorflow.demo D/tensorflow: CameraActivity: onPause org.tensorflow.demo.DetectorActivity@86593f0\r\n10-11 09:12:51.501 8262-8268/org.tensorflow.demo W/art: Suspending all threads took: 50.114ms\r\n10-11 09:13:26.041 8262-8268/org.tensorflow.demo W/art: Suspending all threads took: 6.732ms\r\n10-11 09:17:07.401 8262-8323/org.tensorflow.demo I/Process: Sending signal. PID: 8262 SIG: 9\r\n\r\nSince I do not have other devices to test it, please help to see if this is a Samsung Galaxy S5 specific issue or a general issue.  Thank you very much!", "@w9wang2 Do you have your build.gradle set up to grab an explicit version of the TF library? This should be fixed in [1.3.1-alpha](https://bintray.com/google/tensorflow/tensorflow/1.3.1-alpha). It looks like you're grabbing a 1.3.0 release, which did not build in the necessary bool support.", "the build.gradle I used is like below, I should change it to\u00a0compile 'org.tensorflow:tensorflow-android:1.3.1-alpha', right?compile 'org.tensorflow:tensorflow-android:+'\nThanks.      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 10:41 AM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \n@w9wang2 Do you have your build.gradle set up to grab an explicit version of the TF library? This should be fixed in 1.3.1-alpha. It looks like you're grabbing a 1.3.0 release, which did not build in the necessary bool support.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   ", "I just tried build.gradle with\u00a0compile 'org.tensorflow:tensorflow-android:1.3.1-alpha', but it could not find it. How to get this one?\nThanks.\n\n      From: Wensu Wang <w9wang2@yahoo.com>\n To: tensorflow/tensorflow <reply@reply.github.com>; tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 10:59 AM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \nthe build.gradle I used is like below, I should change it to\u00a0compile 'org.tensorflow:tensorflow-android:1.3.1-alpha', right?compile 'org.tensorflow:tensorflow-android:+'\nThanks.      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 10:41 AM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n  \n@w9wang2 Do you have your build.gradle set up to grab an explicit version of the TF library? This should be fixed in 1.3.1-alpha. It looks like you're grabbing a 1.3.0 release, which did not build in the necessary bool support.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   \n\n   ", "The '+' should work to find the latest version, if it doesn't then I doubt writing 1.3.1-alpha explicitly will (but you could try).\r\n\r\nWe may have a temporary problem with resolving the latest archive as we try to consolidate the various TF bintray/jcenter/maven entries, so until that is resolved I'd suggest dropping the AAR into your project manually.", "Could you please advise how to include the AAR manually to the tensorflow detect project in Android studio.\nThanks.\n\n      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 11:14 AM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \nThe + should work, if it doesn't then I doubt writing 1.3.1-alpha will (but you could try).We may have a temporary problem with resolving the latest archive as we try to consolidate the TF bintray/jcenter/maven entries, so until that is resolved I'd suggest dropping the AAR into your project manually.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   ", "https://stackoverflow.com/questions/29826717/how-to-import-a-aar-file-into-android-studio-1-1-0-and-use-it-in-my-code\r\n\r\nYou can find the latest successful nightly build of the TF AAR [here](https://ci.tensorflow.org/view/Nightly/job/nightly-android/lastSuccessfulBuild/artifact/out/tensorflow.aar), or download the latest released version from the bintray link above.", "I manually add the AAP file, now the TF Detect works as expected, Thank you very much for your help!\n\n      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 12:01 PM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \nhttps://stackoverflow.com/questions/29826717/how-to-import-a-aar-file-into-android-studio-1-1-0-and-use-it-in-my-codeYou can find the latest successful nightly build of the TF AAR here, or download the latest released version from the bintray link above.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   ", "Hi, Could you please let me know how many objects can be detected in the TF Detect demo app, I found the maximum is 3, is it correct?\nThanks.\n\n      From: Wensu Wang <w9wang2@yahoo.com>\n To: tensorflow/tensorflow <reply@reply.github.com>; tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 1:16 PM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \nI manually add the AAP file, now the TF Detect works as expected, Thank you very much for your help!\n\n      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Mention <mention@noreply.github.com>\n Sent: Wednesday, October 11, 2017 12:01 PM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n  \nhttps://stackoverflow.com/questions/29826717/how-to-import-a-aar-file-into-android-studio-1-1-0-and-use-it-in-my-codeYou can find the latest successful nightly build of the TF AAR here, or download the latest released version from the bintray link above.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   \n\n   ", "In principle it can track up to 15 at a time, which is the length of the color list in MultiBoxTracker.java. In practice you'll never see that amount at once since there is non-max suppression logic in place to make sure that every box is distinct from the others. However you should be able to get more than 3 at once. Apart from the implicit max of 15, there is no other hard-coded limitation in either the detector itself or the tracker logic to limit the number of boxes.\r\n\r\nIf you press the volume keys you can see the actual preview frame and detections being made in it. If something there seems strange, please file a new issue with a screenshot and other relevant details.", "Thanks for the info.\n\n      From: Andrew Harp <notifications@github.com>\n To: tensorflow/tensorflow <tensorflow@noreply.github.com> \nCc: w9wang2 <w9wang2@yahoo.com>; Comment <comment@noreply.github.com>\n Sent: Wednesday, October 11, 2017 2:56 PM\n Subject: Re: [tensorflow/tensorflow] Android Demo - Bug - Exception in TF Detect activity (#12593)\n   \nIn principle it can track up to 15 at a time, which is the length of the color list in MultiBoxTracker.java. In practice you'll never see that amount at once since there is non-max suppression logic in place to make sure that every box is distinct from the others. However you should be able to get more than 3 at once.If you press the volume keys you can see the actual preview frame and detections being made in it. If something there seems strange, please file a new issue with a screenshot and other relevant details.\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.  \n\n   "]}, {"number": 12592, "title": "Tensorflow internally creates operators", "body": "System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, I made custom distributed inception code\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\r\nTensorFlow installed from (source or binary): Unmodified source with RDMA Verbs enabled\r\nTensorFlow version (use command below): 1.3.0-rc1\r\nPython version: 2.7.12\r\nBazel version (if compiling from source): 0.5.1\r\nCUDA/cuDNN version: 8.0/5.1.5\r\nGPU model and memory: NVIDIA TITAN Xp PCIe 12GB (4 per node)\r\n\r\nI tried to run distributed inception, and I removed some nodes by breaking control dependencies in the graph.  However, tensorflow creates operators such as \"inception_v3/mixed_17x17x1280a/branch7x7x3/Conv_2/BatchNorm/AssignMovingAvg_1_S21149\" internally and called it. Why this kind of operators are created and is there any way to prevent it? ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12591, "title": "Error: tensorflow.python.framework.errors_impl.InternalError: Unable to get element from the feed as bytes.", "body": "I have met this error:\r\n\r\n> Traceback (most recent call last):\r\n  File \"demo_pb.py\", line 25, in <module>\r\n    result_dict = news_demo.newsAggreg({image_path})\r\n  File \"/home/rszj/liutao/news_aggreg/news_demo_pb.py\", line 32, in newsAggreg\r\n    predict = news_predict.run(images_path)\r\n  File \"/home/rszj/liutao/news_aggreg/news_predict_pb.py\", line 201, in run\r\n    predict = sess.run(pred, feed_dict={x: imgs, is_train:False})\r\n  File \"/home/rszj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/home/rszj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/rszj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/rszj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Unable to get element from the feed as bytes.\r\n\r\nBackground: \r\n    Firstly, I have a simple cnn program, and I build a model.ckpt files. \r\n    Secondly, I make be ckpt converting to pb.\r\n    Thridly, I used ckpt model doing predict and pb model doing predict.\r\n    In simple cnn program, ckpt and pb all do normal predict by using `predict = sess.run(pred, feed_dict={x: imgs, is_train:False})` .\r\n   \r\n   However, when I using upper method to cnn-rnn program, I could have a normal predict result using ckpt model file, but it had a `tensorflow.python.framework.errors_impl.InternalError: Unable to get element from the feed as bytes.` problem using pb.\r\n   I can't solve this problem, I need help!\r\n  Please!\r\n  Thanks!", "comments": ["Please fill out the template, and send a reproducible test case."]}, {"number": 12590, "title": "Cannot build TF 1.3/1.2 for iOS", "body": "I've built TF 1.1 before without problems as follows\r\n\r\n    git clone --branch r1.1 https://github.com/tensorflow/tensorflow.git\r\n    ./<makefile_dir>/build_all_ios.sh\r\n\r\nIf I change the branch to `r1.3` it stops with a segmentation fault. Also seems to happen with `r1.2`.\r\n\r\n```\r\n...\r\ngcc --std=c++11 -DIS_SLIM_BUILD -fno-exceptions -DNDEBUG -O3 -mios-simulator-version-min=8.0 -arch x86_64 -fembed-bitcode -D__thread= -DUSE_GEMM_FOR_CONV -Wno-c++11-narrowing -DTF_LEAN_BINARY -D__ANDROID_TYPES_SLIM__ -fno-exceptions -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator10.3.sdk -MT <REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_X86_64/tensorflow/core/kernels/reduction_ops_common.o -MMD -MP -MF <REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/dep/ios_X86_64//tensorflow/core/kernels/reduction_ops_common.Td -I. -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/downloads/ -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/downloads/eigen -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/downloads/gemmlowp -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/proto/ -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/proto_text/ -I<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include -c tensorflow/core/kernels/reduction_ops_common.cc -o <REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_X86_64/tensorflow/core/kernels/reduction_ops_common.o\r\nclang: error: unable to execute command: Segmentation fault: 11\r\nclang: error: clang frontend command failed due to signal (use -v to see invocation)\r\nApple LLVM version 8.1.0 (clang-802.0.42)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\nclang: note: diagnostic msg: PLEASE submit a bug report to http://developer.apple.com/bugreporter/ and include the crash backtrace, preprocessed source, and associated run script.\r\nclang: note: diagnostic msg: \r\n********************\r\n\r\nPLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:\r\nPreprocessed source(s) and associated run script(s) are located at:\r\nclang: note: diagnostic msg: /var/folders/xy/txmq57f90mq40d8ltjxhkqgm0000gn/T/reduction_ops_sum-5e29c4.cpp\r\nclang: note: diagnostic msg: /var/folders/xy/txmq57f90mq40d8ltjxhkqgm0000gn/T/reduction_ops_sum-5e29c4.sh\r\nclang: note: diagnostic msg: Crash backtrace is located in\r\nclang: note: diagnostic msg: /Users/era/Library/Logs/DiagnosticReports/clang_<YYYY-MM-DD-HHMMSS>_<hostname>.crash\r\nclang: note: diagnostic msg: (choose the .crash file that corresponds to your crash)\r\nclang: note: diagnostic msg: \r\n\r\n********************\r\nmake: *** [<REDACTED>/tfbuild/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_X86_64/tensorflow/core/kernels/reduction_ops_sum.o] Error 254\r\nmake: *** Waiting for unfinished jobs....\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'x86_64 compilation failed.'\r\nx86_64 compilation failed.\r\n+ exit 1\r\n```\r\n\r\nSystem MacOS Sierra 10.12.6 (16G29)\r\n\r\nIt also seems to fail with other error messages in different compile runs (on different files of course) like `clang: error: unable to execute command: Illegal instruction: 4` or malloc/free errors.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "How is this not a bug if TF stops building at a certain revision?"]}, {"number": 12589, "title": "ValueError: graph_def is invalid at node u'a/Assign': Input tensor 'a:0' Cannot convert a tensor of type string to an input of type string_ref.", "body": "I want to change the input directory for validation using `input_map` in tf.train.import_meta_graph. Here is the demo code\r\n\r\nFor training:\r\n```\r\nfrom tensorflow.core.framework import variable_pb2\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import variables\r\nfrom tensorflow.python.framework.ops import register_proto_function\r\n\r\nregister_proto_function(\r\n    ops.GraphKeys.LOCAL_VARIABLES,\r\n    proto_type=variable_pb2.VariableDef,\r\n    to_proto=variables.Variable.to_proto,\r\n    from_proto=variables.Variable.from_proto)\r\na = tf.train.match_filenames_once('data/wxtrain/*', name='a')\r\nwith tf.Session() as ss:\r\n    ss.run(tf.group(tf.local_variables_initializer(),tf.global_variables_initializer()))\r\n    saver = tf.train.Saver(tf.local_variables())\r\n    saver.save(ss, 'log/model.ckpt')\r\n    print(ss.run(a, feed_dict={a:'1.'}))\r\n```\r\nFor testing:\r\n```\r\nfrom tensorflow.core.framework import variable_pb2\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import variables\r\nfrom tensorflow.python.framework.ops import register_proto_function\r\n\r\nregister_proto_function(\r\n    ops.GraphKeys.LOCAL_VARIABLES,\r\n    proto_type=variable_pb2.VariableDef,\r\n    to_proto=variables.Variable.to_proto,\r\n    from_proto=variables.Variable.from_proto)\r\nnewa = tf.train.match_filenames_once('data/wxtest/*', name='newa')\r\nlatest = tf.train.latest_checkpoint('log/')\r\nsaver = tf.train.import_meta_graph(latest+'.meta', \r\n                                   input_map={'a:0':newa},\r\n                                   import_scope='import')\r\nwith tf.Session() as ss:\r\n    ss.run(tf.group(tf.local_variables_initializer(),tf.global_variables_initializer()))\r\n    saver.restore(ss, latest)\r\n    print(\"resume \", latest)\r\n    print(ss.run(newa, feed_dict={newa:'2.'}))\r\n```\r\nHowever, I encounter the following errors:\r\n\r\n> ValueError: graph_def is invalid at node u'a/Assign': Input tensor 'a:0' Cannot convert a tensor of type string to an input of type string_ref.\r\n\r\nI use tensorflow 1.2. It seems to be a bug.", "comments": ["Which line is failing? Is it the last one, where you call session.run with a feed_dict? Is `newa` supposed to be a variable? You cannot feed variables in tensorflow.", "It fails on line \r\n```\r\nsaver = tf.train.import_meta_graph(latest+'.meta', \r\n                                   input_map={'a:0':newa},\r\n                                   import_scope='import')\r\n```\r\nHere gives you the whole traceback\r\n\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/home/jqj/anaconda2/lib/python2.7/site-packages/spyder/utils/site/sitecustomize.py\", line 880, in runfile\r\n>     execfile(filename, namespace)\r\n>   File \"/home/jqj/anaconda2/lib/python2.7/site-packages/spyder/utils/site/sitecustomize.py\", line 94, in execfile\r\n>     builtins.execfile(filename, *where)\r\n>   File \"/home/jqj/ad/test.py\", line 163, in <module>\r\n>     import_scope='import')\r\n>   File \"/home/jqj/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1686, in import_meta_graph\r\n>     **kwargs)\r\n>   File \"/home/jqj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 504, in import_scoped_meta_graph\r\n>     producer_op_list=producer_op_list)\r\n>   File \"/home/jqj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 391, in import_graph_def\r\n>     node, 'Input tensor %r %s' % (input_name, te)))\r\n> ValueError: graph_def is invalid at node u'a/Assign': Input tensor 'a:0' Cannot convert a tensor of type string to an input of type string_ref.", "Right. The problem is your usage of input_map. It has the same behavior as\nfeeding, and it is not valid in tensorflow to remap a variable in the\nmetagraph's input_map.\n\nOn Sat, Aug 26, 2017 at 12:26 AM, jiqiujia <notifications@github.com> wrote:\n\n> It fails on line\n>\n> saver = tf.train.import_meta_graph(latest+'.meta',\n>                                    input_map={'a:0':newa},\n>                                    import_scope='import')\n>\n> Here gives you the whole traceback\n> T\n>\n> raceback (most recent call last):\n> File \"\", line 1, in\n> File \"/home/jqj/anaconda2/lib/python2.7/site-packages/spyder/utils/site/sitecustomize.py\",\n> line 880, in runfile\n> execfile(filename, namespace)\n> File \"/home/jqj/anaconda2/lib/python2.7/site-packages/spyder/utils/site/sitecustomize.py\",\n> line 94, in execfile\n> builtins.execfile(filename, *where)\n> File \"/home/jqj/ad/test.py\", line 163, in\n> import_scope='import')\n> File \"/home/jqj/anaconda2/lib/python2.7/site-packages/\n> tensorflow/python/training/saver.py\", line 1686, in import_meta_graph\n> **kwargs)\n> File \"/home/jqj/anaconda2/lib/python2.7/site-packages/\n> tensorflow/python/framework/meta_graph.py\", line 504, in\n> import_scoped_meta_graph\n> producer_op_list=producer_op_list)\n> File \"/home/jqj/anaconda2/lib/python2.7/site-packages/\n> tensorflow/python/framework/importer.py\", line 391, in import_graph_def\n> node, 'Input tensor %r %s' % (input_name, te)))\n> ValueError: graph_def is invalid at node u'a/Assign': Input tensor 'a:0'\n> Cannot convert a tensor of type string to an input of type string_ref.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12589#issuecomment-325083957>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxdvZ9IXHYragEkI2wnQU1CLyyH8yks5sb55egaJpZM4PCcir>\n> .\n>\n\n\n\n-- \n - Alex\n"]}, {"number": 12588, "title": "Error with tf.losses.sparse_softmax_cross_entropy: weights?", "body": "I use the function tf.losses.sparse_softmax_cross_entropy for my unbalanced dataset but i get error when using it. My question is if my labels in one batch have shape (8,4096) , my prediction or logits have shape (8,4096,14) and I have 14 classes. What should the shape of my weights?\r\n\r\nAnother question: should i have one specific weight for each class or a specific weight for each sample?\r\nThanks", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "For those who will need it later, weight must have the same shape as the batch_size so (8,4096). Those weights represent weight for each sample."]}, {"number": 12587, "title": "[building tensorflow with bazel]Error:Constants.h:429:2: error: #error The preprocessor symbol 'Success' is defined", "body": "- Environment information:\r\n\r\nUbuntu version: 14.04\r\nbazel version: 0.5.1\r\ntensorflow version:  r 1.1\r\ncuda version: 8.0.44\r\ncudnn version: 5.1.5\r\ncommand: bazel build tensorflow/examples/PreProcess_modify\r\n\r\n- Describe the problem:\r\n\r\ntensorflow/examples/PreProcess_modify/BUILD:10:1: C++ compilation of rule '//tensorflow/examples/PreProcess_modify:chartest' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 130 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:360:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/cc/framework/ops.h:21,\r\n                 from ./tensorflow/cc/ops/const_op.h:19,\r\n                 from ./tensorflow/examples/PreProcess_modify/Tensorflow/TFClassifier.h:29,\r\n                 from ./tensorflow/examples/PreProcess_modify/include/GameRecognize.h:14,\r\n                 from ./tensorflow/examples/PreProcess_modify/GameRecog/CharRecognize.h:23,\r\n                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:13:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:429:2: error: #error The preprocessor symbol 'Success' is defined, possibly by the X11 header file X.h\r\n #error The preprocessor symbol 'Success' is defined, possibly by the X11 header file X.h\r\n  ^\r\nIn file included from /usr/include/X11/Xlib.h:44:0,\r\n                 from ./tensorflow/examples/PreProcess_modify/Os/TqcOs.h:21,\r\n                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:11:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected identifier before numeric constant\r\n   Success = 0,        \r\n   ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected '}' before numeric constant\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected unqualified-id before numeric constant\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:360:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/cc/framework/ops.h:21,\r\n                 from ./tensorflow/cc/ops/const_op.h:19,\r\n                 from ./tensorflow/examples/PreProcess_modify/Tensorflow/TFClassifier.h:29,\r\n                 from ./tensorflow/examples/PreProcess_modify/include/GameRecognize.h:14,\r\n                 from ./tensorflow/examples/PreProcess_modify/GameRecog/CharRecognize.h:23,\r\n                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:13:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:549:1: error: expected declaration before '}' token\r\n } // end namespace Eigen\r\n ^\r\nINFO: Elapsed time: 678.166s, Critical Path: 5.46s", "comments": ["@benoitsteiner @rmlarsen Can either of you comment this? Thanks...", "Nagging Assignee @rohan100jain: It has been 393 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 408 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Is this still a problem?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 12586, "title": "Update metrics_op.py", "body": "Using core method over private", "comments": ["@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @jhseu and @lukaszkaiser to be potential reviewers.", "Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 12585, "title": "Tensorflow estimator with shared network", "body": "I am building a tensorflow model with new [estimator]( https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) high level api. My model looks like ![this]( https://i.stack.imgur.com/gxxo0.png).\r\n\r\nIn fact, the model is more complex than that due to the model is used to simulate game operation. Classification is responsible for decide whether it is good time for action. Then the regression will give the details about the action. It contains a combination of CNN and RNN. \r\n\r\nHowever, due to the complexity and memory consumption, it is impossible to train and run classification and regression as two network simultaneously. Also, when I create my estimator like:\r\n\r\n```python\r\n    # Create the Estimator\r\n    mnist_classifier = tf.estimator.Estimator(\r\n        model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\r\n\r\n```\r\nI can only provide one model function for the estimator. Is is possibile to train and run two estimator together? ", "comments": []}, {"number": 12584, "title": "Fix: indices is out of bounds in _OneHotColumn", "body": "The PR is opened to fix #12583. CF pr #12638.\r\n\r\n### What changes were proposed in this pull request?\r\n\r\nslice `weighted_column` to get rid of -1 index.\r\n\r\n### How was this patch tested?\r\n\r\n+ [x] add unit tests.\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "@facaiy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @jart and @ispirmustafa to be potential reviewers.", "Same bug exists in `_IndicatorColumn` of `tf.feature_column`. However, its fix is blocked by #12558. When #12558 is merged, I'll open a new PR to fix the bug in `tf.feature_column`.", "Thanks for your approval, @ispirmustafa !  Perhaps you will be interested in #12638 , could you take a look?", "Jenkins, test this please.", "Jenkins, test this please.\r\n\r\nRerunning because of github flake.", "XLA rerun: http://ci.tensorflow.org/job/tensorflow-pull-requests-xla/2639", "Thanks, @martinwicke . If I understand correctly, all tests are passed in fact, right?"]}, {"number": 12583, "title": "BUG: indices[0] = [0,-1] is out of bounds for _OneHotColumn", "body": "### Describe the problem\r\n\r\nFor `sparse_column_with_keys`, out-of-vocabulary feature values is -1 by default. However, -1 is invalid index when sparse_tensor is converted to tensor in `one_hot_column`.\r\n\r\n\r\n### Source code / logs\r\n\r\ncode:\r\n\r\n```python\r\n    ids = fc.sparse_column_with_keys(\"ids\", [\"marlo\", \"omar\", \"stringer\"])\r\n    weighted_ids = fc.weighted_sparse_column(ids, \"weights\")\r\n    one_hot = fc.one_hot_column(weighted_ids)\r\n```\r\n\r\nlogs:\r\n\r\n```python\r\n  File \"/Users/facai/Workshop/sina/Prometheus/prometheus/python/feature/column_test.py\", line 373, in _feature_column_from_tensor_dict\r\n    return layers.input_from_feature_columns(tensor_dicts, feature_columns)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.py\", line 212, in input_from_feature_columns\r\n    default_name='input_from_feature_columns')\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.py\", line 143, in _input_from_feature_columns\r\n    output_rank=output_rank))\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py\", line 936, in _to_dnn_input_layer\r\n    return sparse_ops.sparse_tensor_to_dense(weighted_column)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py\", line 845, in sparse_tensor_to_dense\r\n    name=name)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py\", line 710, in sparse_to_dense\r\n    name=name)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_sparse_ops.py\", line 1094, in _sparse_to_dense\r\n    validate_indices=validate_indices, name=name)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): indices[0] = [0,-1] is out of bounds: need 0 <= index < [1,4]\r\n         [[Node: input_from_feature_columns/col_tag_weighted_by_col_weight_one_hot/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_from_feature_columns/col_tag_weighted_by_col_weight_one_hot/SparseMerge/SparseReorder, input_from_feature_columns/col_tag_weighted_by_col_weight_one_hot/SparseMerge/Identity, input_from_feature_columns/col_tag_weighted_by_col_weight_one_hot/SparseMerge/SparseReorder:1, input_from_feature_columns/col_tag_weighted_by_col_weight_one_hot/SparseToDense/default_value)]]\r\n```\r\n", "comments": ["@jhseu please close this once #12584 and #12558 are merged...", "Hi, the out-of-bounds bug in `tf.contrib.layers.feature_column` is fixed in #12584, and `tf.feature_columns` is fixed in #12638. Please close this once they are both accepted and merged. Thanks."]}]