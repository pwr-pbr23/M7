[{"number": 8572, "title": "Image Labeler Fails with Gifs?", "body": "The image_label example assumes that decode_gif (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc#L105) will return a 3-d tensor ([height, width, channels]) in the same way that decode_jpeg or decode_png would. However decode_dif returns a 4-d shape ([frames, height, width, channels], https://www.tensorflow.org/api_docs/python/tf/image/decode_gif). This will cause ResizeBilinear to fail.\r\n\r\nThis could be fixed by pulling the first frame from the gif, or by choosing to not expand dimensions on the gif (and classifying each frame).\r\n\r\n", "comments": ["I think you typically just decode a single channel by passing the channel argument to the `tf.image.decode_*` functions?", "Since only the single frame gif will be used in this label_image, frames should be 1. So we can use Squeeze() to remove it. See my PR, https://github.com/tensorflow/tensorflow/pull/9877", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 8571, "title": "shape of state in the output of dynamic_rnn is undetermined", "body": "short code:\r\n```\r\nsequence_lengths, (sequences, labels) = bucket_by_sequence_length(\r\n                                              input_length=sequence_length,\r\n                                              tensors=[sequence, label],\r\n                                              batch_size=72,\r\n                                              bucket_boundaries=[80, 160, 240, 320, 400],\r\n                                              dynamic_pad=True)\r\nlstm_cell = core_rnn_cell.BasicLSTMCell(num_units=56)\r\nlookup = tf.nn.embedding_lookup(......)\r\n_, state = tf.nn.dynamic_rnn(\r\n                      cell=lstm_cell,\r\n                      inputs=lookup,\r\n                      sequence_length=sequence_lengths,\r\n                      dtype=tf.float32)\r\n```\r\nthen `state.h` and `state.c` should be of shape `[72, 56]`, but actually the first dim(batch_size) is undetermined in program, is it a bug?", "comments": ["CC @ebrevdo for comments", "What is the shape of lookup?", "@ebrevdo does it matter? let's say embedding matrix is of shape [vocab_size=90000, embed_size=500], so lookup will be of shape [72, unkown, 500], output should be [72, unknown, 56], state.h should be [72, 56]", "can you confirm lookup is shape [72, unknown, 500]?\n\nOn Wed, Mar 22, 2017 at 7:37 PM, Jie Zhou <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> does it matter? let's say embedding\n> matrix is of shape [vocab_size=90000, embed_size=500], so lookup will be of\n> shape [72, unkown, 500], output should be [72, unknown, 56], state.h should\n> be [72, 56]\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8571#issuecomment-288600264>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzfXEmN2UUFq-eea9GWs9sXt3nPQks5rodsDgaJpZM4MjTwm>\n> .\n>\n", "```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import core_rnn_cell\r\nclass Option(object):\r\n    def __init__(self, filename, batch_size):\r\n        self.sequences, self.labels, self.sequence_lengths = produce_input(filename=filename, batch_size=batch_size)\r\n        self.vocab_size = 90000\r\n        self.embedding_size = 500\r\n        self.hidden_units = 56\r\n        self.num_classes = 2\r\n\r\n\r\n\r\noption = Option('train', 72)\r\nembedding = tf.get_variable(name='embedding',\r\n                            shape=[option.vocab_size, option.embedding_size],\r\n                            initializer=tf.truncated_normal_initializer(stddev=0.05),\r\n                            dtype=tf.float32)\r\nlookup = tf.nn.embedding_lookup(embedding, option.sequences)\r\nlstm_cell = core_rnn_cell.BasicLSTMCell(num_units=option.hidden_units, state_is_tuple=True)\r\noutput, state = tf.nn.dynamic_rnn(cell=lstm_cell,\r\n                                  inputs=lookup,\r\n                                  sequence_length=option.sequence_lengths,\r\n                                  dtype=tf.float32)\r\noutput\r\nOut[6]: \r\n<tf.Tensor 'rnn/transpose:0' shape=(72, ?, 56) dtype=float32>\r\nlookup\r\nOut[7]: \r\n<tf.Tensor 'embedding_lookup:0' shape=(72, ?, 500) dtype=float32>\r\nstate\r\nOut[8]: \r\nLSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 56) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 56) dtype=float32>)\r\n\r\n```", "@ebrevdo What's the status of this issue?", "I think this is fixed in tf 1.2... OP can you confirm?\n\nOn Jun 16, 2017 1:40 PM, \"Geoffrey Irving\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> What's the status of this issue?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8571#issuecomment-309128560>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1bnJBGaW_RNRGN4k3WMBwCEKMO9ks5sEugSgaJpZM4MjTwm>\n> .\n>\n", "@ebrevdo Hi, I'm having the same problem with the shape of the state being undetermined when using a dynamic_rnn. \r\n\r\nI'm using tensorflow version 1.2.1. \r\n`        (outputs,final_state) =(\r\n        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\r\n                                    cell_bw=encoder_cell,\r\n                                    inputs=encoder_inputs_embedded,\r\n                                    sequence_length=encoder_inputs_length,\r\n                                    dtype=tf.float32, time_major=True)\r\n        )\r\n`\r\n\r\nEncoder_inputs_embedded is the following:\r\nTensor(\"embedding_lookup:0\", shape=(8, 11, 20), dtype=float32) \r\n\r\nwhile final_state is the following:\r\n(LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>))", "What about in tf 1.3?\n\nOn Sep 3, 2017 1:33 PM, \"Alex Fabbri\" <notifications@github.com> wrote:\n\n> Hi, I'm having the same problem with the shape of the state being\n> undetermined when using a dynamic_rnn.\n> I'm using tensorflow version 1.2.1.\n> (outputs,final_state) =( tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n> cell_bw=encoder_cell, inputs=encoder_inputs_embedded,\n> sequence_length=encoder_inputs_length, dtype=tf.float32, time_major=True)\n> )\n> Encoder_inputs_embedded is the following:\n> Tensor(\"embedding_lookup:0\", shape=(8, 11, 20), dtype=float32) while\n> final_state is the following:\n> (LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0'\n> shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0'\n> shape=(?, 20) dtype=float32>), LSTMStateTuple(c=<tf.Tensor\n> 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>,\n> h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20)\n> dtype=float32>))\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8571#issuecomment-326829438>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimwjPP56wsPLfP8KHXoeQh_cJ1W2dks5sew0EgaJpZM4MjTwm>\n> .\n>\n", "I just tried it on tf 1.3, and it worked. Thanks :) ", "Great!"]}, {"number": 8570, "title": "Generating sentences using the RNN model", "body": "How do we generate sentences with the trained rnn model in:\r\n[https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb](url)\r\n\r\nI found some people doing it here and there but nothing that is well documented with a working code, at least not ones that are compatible with TF 1.0\r\n\r\nI found this answer on stackoverflow but I keep getting errors with it\r\n[http://stackoverflow.com/a/38729349/7568128](url)\r\n\r\nHere is a copy of the file I'm working with \r\n[ptb_word_lm2 (copy).txt](https://github.com/tensorflow/tensorflow/files/856981/ptb_word_lm2.copy.txt)\r\n\r\n", "comments": ["That's a great question for stackoverflow, where we monitor all questions with the tag `tensorflow`. We try to keep the github issues to bugs and feature requests only. Thanks."]}, {"number": 8569, "title": "Incorrect results from tfprof", "body": "I was profiling a few matrix multiplications with tfprof but couldn't make sense of the output. The per-op timing results are hard to believe to be true.\r\n\r\nCode:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.tfprof as tfprof\r\n\r\ndim = 6000\r\nn = 5\r\nwith tf.device('/gpu:0'):\r\n    X, Y, Z, _X, _Y = [], [], [], [], []\r\n    for i in range(n):\r\n        X.append(tf.random_uniform([dim, dim], 0, 10, name='X' + str(i)))\r\n        Y.append(tf.random_uniform([dim, dim], 0, 10, name='Y' + str(i)))\r\n        _X.append(tf.placeholder(dtype=tf.float32, shape=[dim, dim]))\r\n        _Y.append(tf.placeholder(dtype=tf.float32, shape=[dim, dim]))\r\n        Z.append(tf.matmul(_X[i], _Y[i]))\r\n    W = tf.ones([dim, dim])\r\n    for i in range(n):\r\n        W = tf.matmul(W, Z[i])\r\n\r\nsess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\r\nsess.run(tf.global_variables_initializer())\r\nX_, Y_ = sess.run([X, Y])\r\n\r\nrun_metadata = tf.RunMetadata()\r\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\nW_ = sess.run(W,\r\n              {_i: i_ for _i, i_ in zip(_X + _Y, X_ + Y_)},\r\n              options=run_options,\r\n              run_metadata=run_metadata)\r\n\r\ntfprof.model_analyzer.print_model_analysis(\r\n    tf.get_default_graph(),\r\n    run_meta=run_metadata,\r\n    tfprof_options=tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY)\r\n```\r\n\r\nOutput:\r\n```\r\n_TFProfRoot (0B/1296.00MB, 0us/778.18ms)\r\n  MatMul (144.00MB/144.00MB, 162.51ms/162.51ms)\r\n  MatMul_1 (144.00MB/144.00MB, 145.03ms/145.03ms)\r\n  MatMul_2 (144.00MB/144.00MB, 145.07ms/145.07ms)\r\n  MatMul_3 (144.00MB/144.00MB, 162.69ms/162.69ms)\r\n  MatMul_4 (144.00MB/144.00MB, 162.57ms/162.57ms)\r\n  MatMul_5 (144.00MB/144.00MB, 241us/241us)\r\n  MatMul_6 (144.00MB/144.00MB, 21us/21us)\r\n  MatMul_7 (144.00MB/144.00MB, 16us/16us)\r\n  MatMul_8 (144.00MB/144.00MB, 10us/10us)\r\n  MatMul_9 (144.00MB/144.00MB, 19us/19us)\r\n  ones (144.00MB/144.00MB, 6us/6us)\r\n```\r\n\r\nGraph:\r\n![image](https://cloud.githubusercontent.com/assets/425637/24126577/0f5aafbe-0d8c-11e7-9b3e-92a5df5548cc.png)\r\n\r\n**As shown in the profiling output, MatMul_[0-4] take 1,000 -10,000x longer than MatMul_[5-9]. However, they are all matrix multiplications of the same size!**\r\n\r\n### Environment info\r\nOperating System: Ubuntu 14.04.5\r\n\r\nInstalled version of CUDA and cuDNN: \r\n```\r\n-rw-r--r-- 1 root root 556000 Mar  1 12:58 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Mar  1 12:58 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Mar  1 12:58 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rwxr-xr-x 1 root root 415432 Mar  1 12:58 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root 775162 Mar  1 12:58 /usr/local/cuda/lib64/libcudart_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n`tensorflow_gpu-1.0.1-cp27-cp27mu-manylinux1_x86_64.whl`\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n`1.0.1`\r\n", "comments": ["As a reference, I profiled the same program with NVIDIA Visual Profiler. It shows that each matrix multiplication (MatMul_[0-9]) takes around 65-75ms.\r\n\r\nIn comparison, tfprof doubles the amount of runtime of MatMul_[0-4] while counting that of MatMul_[5-9] almost as zero.", "@panyx0718 would you mind taking a look at this?", "Looking. It seems tfprof correctly reports the stats returned in RunMetadata. However, why RunMetadata (from tensorflow internal) gives such result is being investigated.", "I looked into the tensorflow internals a bit deeper. The numbers gathered in gpu_tracer.cc (~ln 580) using CUPTI Activity API are consistent with NVIDIA Visual Profiler (NVVP). But these numbers are not used in RunMetadata.\r\n\r\nI can see the GPU perf numbers being used in direct_session.cc (~ln 535) to build the cost model. But the annotated cost graph is not incorporated into RunMetadata or used by tfprof.\r\n\r\nThe numbers in RunMetadata are from executor.cc (~ln 1360) which are purely CPU-based. Thus, the numbers are actually GPU kernel launch time rather than kernel execution time.\r\n", "@bowang Those numbers should be in the RunMetadata - but they will be shown as kernel times on a device with name \"/gpu:0/stream...\".  If you use the timings from the  \"/gpu:0\" device you will just see the time taken to enqueue the CUDA kernels  (i.e. the time spent in MatMulOp::Compute())\r\n\r\nThis is likely to be a problem with tfprof, not the tracing.  I expect that the chrome timeline will show the correct behavior.  (if it doesn't then this *is* a TF bug!)\r\n\r\nIt would help to have a copy of the RunMetadata proto (or just the StepStats).", "@prb12 Thanks for the explanation.\r\n\r\nSo looks like tfprof is tracking the MatMulOp::Compute(). It is actually the GPU kernel schedule time.\r\nWhile the needed ones are the actually GPU execution time, which is in gpu:0/stream.\r\n\r\nAnother place I found is in the compute_cost in cost_graph, which can be propagated to Python via the:\r\n    config = tf.ConfigProto(\r\n        graph_options=tf.GraphOptions(build_cost_model=1))\r\n\r\n\r\n", "@prb12 Just verified with chrome timeline where the GPU timing is correct under \"/gpu:0/stream...\".\r\n@panyx0718  It would be very helpful to correct it in tfprof.", "A fix has been submitted, will be released.", "@panyx0718 Can you refer me to the commit that fixes this issue?", "https://github.com/tensorflow/tensorflow/commit/404db0358aacc0fc2319fc333df4cc5bc0fc404a\n\nOn Tue, Mar 28, 2017 at 10:50 AM, Bo Wang <notifications@github.com> wrote:\n\n> @panyx0718 <https://github.com/panyx0718> Can you refer me to the commit\n> that fixes this issue?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8569#issuecomment-289849860>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ACwQe5iansiCjJJZuQ10ljnSy4Va5D1Lks5rqUh5gaJpZM4MjKHs>\n> .\n>\n\n\n\n-- \nThanks\nXin\n", "Thanks @panyx0718 ", "@panyx0718 I am seeing similar issue even after picking [404db03](https://github.com/tensorflow/tensorflow/commit/404db0358aacc0fc2319fc333df4cc5bc0fc404a). \r\n\r\n_TFProfRoot (0B/1584.00MB, 0us/1.72sec)\r\n  MatMul (144.00MB/144.00MB, 343.61ms/343.61ms)\r\n  MatMul_1 (144.00MB/144.00MB, 343.71ms/343.71ms)\r\n  MatMul_2 (144.00MB/144.00MB, 343.74ms/343.74ms)\r\n  MatMul_3 (144.00MB/144.00MB, 343.45ms/343.45ms)\r\n  MatMul_4 (144.00MB/144.00MB, 343.58ms/343.58ms)\r\n  MatMul_5 (144.00MB/144.00MB, 169us/169us)\r\n  MatMul_6 (144.00MB/144.00MB, 25us/25us)\r\n  MatMul_7 (144.00MB/144.00MB, 22us/22us)\r\n  MatMul_8 (144.00MB/144.00MB, 21us/21us)\r\n  MatMul_9 (144.00MB/144.00MB, 21us/21us)\r\n  ones (144.00MB/144.00MB, 5us/5us)", "@jeevandev I might have re-introduced the problem during some recent changes. Let me take a look", "I noticed the RunMetadata has format changes that break tfprof's assumptions.", "Thanks for letting us know. I guess we can reopen the issue?", "Sure, I'm fixing it.", "@jeevandev I submitted a fix, might take a some time to release", "Thank you. Can you pls point us to the commit?", "d78a121\r\nCan you try the latest version"]}, {"number": 8568, "title": "Branch 150685391", "body": "", "comments": []}, {"number": 8567, "title": "Is there a way to do partial_run with queues?", "body": "I'm reading a bunch of image files using the FIFO queue provided by `string_input_producer`. Some of these files have bad format and cannot be decoded properly. Therefore I would want to print the names of these files when the related functions from `tf.image` throw `tf.errors.InvalidArgumentError` exceptions.\r\n\r\nMy graph definition looks like this:\r\n\r\n    ...\r\n    filename_queue = tf.train.string_input_producer(files, num_epochs=1, shuffle=True)\r\n    image_reader = tf.WholeFileReader()\r\n    key, image_file = image_reader.read(filename_queue)\r\n    is_png = tf.py_func(has_png_ext, [key], [tf.bool])\r\n    image = tf.cond(pred=is_png[0],\r\n                    fn1=lambda: tf.image.decode_png(image_file),\r\n                    fn2=lambda: tf.image.decode_jpeg(image_file))\r\n    ...\r\n\r\nAnd then I'm fetching the output like this:\r\n\r\n    ...\r\n    with tf.Session() as sess:\r\n        sess.run(init_op)\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(coord=coord)\r\n        try:\r\n            while not coord.should_stop():\r\n                try:\r\n                    nodes = sess.run([key, image])\r\n                    nodes_results.append(nodes)\r\n                    num_files += 1\r\n                except tf.errors.InvalidArgumentError:\r\n                    num_failed += 1\r\n                    num_failed_dir += 1\r\n    ...\r\n\r\nInitially I've tried to print the value of `key` in the `except` block but this won't work. Then I've tried a bunch of ideas and none of them seems to be working. I've been trying to see if [partial_run](https://www.tensorflow.org/api_docs/python/tf/Session#partial_run) could help but it takes a `feed_dict` input instead of a native queue input.\r\n\r\nSo in short, my question is, is there a way to make partial_run work while using native queue inputs? Or is there a better way to solve my problem - output the file names when `tf.image.decode_*` throw exceptions?", "comments": ["Another idea I've tried is based on this [stackoverflow answer](stackoverflow.com/a/37584169) where the OP suggests using `tf.placeholder_with_default` and set its default input as the output from the FIFO queue.\r\n\r\nAs a result I've tried something like this:\r\n\r\n    ...\r\n    input_from_filename_queue = image_reader.read(filename_queue)\r\n    input = tf.placeholder_with_default(input=input_from_filename_queue, shape=(2, ))\r\n    ...\r\n    h = sess.partial_run_setup(fetches=[file_name, image], feeds=input)\r\n    file_name_tensor = sess.partial_run(handle=h, fetches=file_name, feed_dict=None)\r\n    image_tensor = sess.partial_run(handle=h, fetches=image, feed_dict=None)\r\n    ...\r\n\r\nI've tried different variations of things to feed into the `feed_dict` in the above snippet but they all failed. I'm wondering whether this approach could be modified into a working solution.\r\n\r\nPS: I'm not exactly sure whether this fits into a *new feature request*. I've tried asking the same question on [stackoverflow](http://stackoverflow.com/questions/42757785/how-should-i-output-partial-information-in-tensorflow-when-exceptions-are-thrown) without receiving any answer so I want to try and see if this question fits here.", "BTW, \"persistent tensors\" reuse the same machinery as partial run but are a bit easier/more explicit, here's an example of using it: http://stackoverflow.com/questions/37644984/run-train-op-multiple-times-in-tensorflow/37736888#37736888\r\n\r\nYou can dequeue some value and save it as persistent tensor, and then reuse it in next session run. This does not trigger fetching/transferring tensor contents from TensorFlow runtime", "@suharshs can you comment on whether partial run can support this?", "Also @caisq could tfdbg help here?", "Does the InvalidArgumentError not have the name of the file that is invalid?", "@derekhh @skye \r\nAssuming the `sess.run([key, image])` does not run in a distributed setting, tfdbg (TensorFlow Debugger) should be able to help here. (tfdbg supports only `DirectSessions` right now; support for distributed session is in the works.)\r\n\r\nModifying @derekhh 's code example a little, we have:\r\n```python\r\nfrom tensorflow.python import debug as tf_debug  # tfdbg-required import\r\n\r\nwith tf.Session() as sess:\r\n    # Activate tfdbg CLI!\r\n    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\r\n\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(coord=coord)\r\n\r\n    num_files = 0\r\n    num_failed = 0\r\n    while not coord.should_stop():\r\n      try:\r\n        key_val, image_val = sess.run([key, image])\r\n        num_files += 1\r\n      except tf.errors.InvalidArgumentError:\r\n        num_failed += 1\r\n```\r\n\r\nThen, when you run your program, you will automatically drop to the tfdbg CLI. Keep entering `tfdbg> run` until you reach the error screen that looks like the\r\n![gh1](https://cloud.githubusercontent.com/assets/16824702/24298761/5fcdf53e-107d-11e7-82c3-0bf03b03180c.png)\r\n\r\n(You may run into the problem that there are too many images and you need to enter `run` too many times to encounter the first error. In that case, you can set `shuffle=False` and figure out in which iteration the error occurs. Say it is the 12345th iteration. Then in tfdbg CLI, you can do `tfdbg> run -t 12345` to stop at the error.)\r\n\r\nClick the `li -r cond/DecodeJpeg` link with your mouse (or type it in, if you like typing) and you'll see a screen like the following:\r\n![debug_string_input_producer_2](https://cloud.githubusercontent.com/assets/16824702/24278808/73d4159c-101c-11e7-8e4f-e76e5493988c.png)\r\n\r\nThe first input, namely `cond/DecodeJpeg/Switch`, corresponds to the tf.cond node. The node `ReaderReadV2` is the input to the `PyFunc`. To see the value of the first output (i.e., the key) of it, do\r\n```\r\ntfdbg> pt ReaderReadV2:0\r\n```\r\nand that should give you the value of the file name/path string.\r\n![debug_string_input_producer_3](https://cloud.githubusercontent.com/assets/16824702/24278907/2da6c064-101d-11e7-939a-b0258f753b4b.png)\r\n\r\nFoot note: I don't know what version of TF you are using, but tfdbg UI has undergone some improvement since the 1.0 release. The screenshots above are generated with the latest release (1.1.0rc0). So please use 1.1.0rc0 or nightly if you want the best experience.\r\n\r\n\r\n", "Closing since complex use of queues are deprecated in favor of @mrry's `tf.contrib.data`."]}, {"number": 8566, "title": "avg_pool() is quietly returning garbage.", "body": "I'm seeing an issue with various networks where, depending on image input size, it either works, crashes with a CUDA_ERROR_ILLEGAL_ADDRESS error, or, most worryingly, runs without issue but visually has strange artifacts (see attached). Does not happen if running on CPU.\r\n\r\nOS: Ubuntu 16.04. Running docker image based on tensorflow/tensorflow:1.0.1-gpu, with nvidia-docker 17.03.0-ce. GPUs: 2x Titan X (Pascal). Was also able to replicate running native on similar machine with same OS and hardware.\r\n\r\nPossibly related github issues:  #6509, #4425, #3422 but these seem to be generally fixed by upgrading to same or earlier tensorflow or cudnn versions.\r\n\r\nls -l /usr/local/nvidia/lib64/libcud*\r\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so -> libcuda.so.370.28\r\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so.1 -> libcuda.so.370.28\r\n-rw-r--r-- 2 root root 8219624 Sep  2  2016 /usr/local/nvidia/lib64/libcuda.so.370.28\r\n\r\nThis code can demonstrate the issues. Changing run_type changes the effect, hopefully each option is clear. Problem here starts after avg_pool, but I've seen with other outputs, e.g. activation functions.\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nrun_type = \"gpu_artifacts\"  # \"gpu_works\" \"gpu_artifacts\" \"gpu_crashes\" \"cpu\"\r\nif run_type == \"gpu_works\":\r\n    num_gpus = 1\r\n    num_rows = 900\r\nelif run_type == \"gpu_crashes\":\r\n    num_gpus = 1\r\n    num_rows = 950\r\nelif run_type == \"gpu_artifacts\":\r\n    num_gpus = 1\r\n    num_rows = 1000\r\nelif run_type == \"cpu\":\r\n    num_gpus = 0\r\n    num_rows = 950\r\n\r\nnum_cols = 1900\r\nxx, yy = np.meshgrid(np.linspace(0, 2 * np.pi, num_cols), np.linspace(0, 2 * np.pi, num_rows))\r\nfaux_img = np.zeros((num_rows, num_cols, 3))\r\nfaux_img[:, :, 0] = np.sin(xx) + np.cos(yy)\r\nfaux_img[:, :, 1] = np.cos(xx) + np.cos(yy)\r\nfaux_img[:, :, 2] = np.cos(xx) + np.sin(yy)\r\n\r\nplt.figure()\r\nplt.imshow(faux_img)\r\nplt.title(\"input\")\r\n\r\ninput_shape = faux_img.shape\r\ninput_shape = np.append([-1], input_shape)\r\ninputs = np.array([faux_img.copy().ravel()])\r\n\r\nx_in_ravel = tf.placeholder(tf.float32, [None, np.prod(input_shape[1::])], name=\"x_in_ravel\")\r\nx_in = tf.reshape(x_in_ravel, input_shape)\r\nfilt_vals = np.random.randn(5, 5, 3, 30).astype(np.float32)\r\nW_0 = tf.Variable(tf.constant(filt_vals))\r\nstrides = [1, 1, 1, 1]\r\nconv_out = tf.nn.conv2d(x_in, W_0, strides=strides, padding=\"VALID\", name=\"conv1\")\r\npool_out = tf.nn.avg_pool(conv_out, ksize=[1, 9, 9, 1], strides=strides, padding=\"VALID\", name=\"pool1\")\r\n\r\nconfig = tf.ConfigProto(device_count={'GPU': num_gpus})\r\nsess = tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\nouts_conv, outs_pool = sess.run([conv_out, pool_out], feed_dict={x_in_ravel: inputs})\r\n\r\nfilt_out_fig, filt_out_ax = plt.subplots()\r\npool_out_fig, pool_out_ax = plt.subplots()\r\nfilt_out_ax.imshow(outs_conv[0, :, :, 15])\r\nfilt_out_ax.set_title(\"conv2d output, looks normal\")\r\npool_out_ax.imshow(outs_pool[0, :, :, 15])\r\npool_out_ax.set_title(\"avg_pool output, striping artifacts\")\r\n\r\nplt.show()\r\n```\r\n\r\nOutput for run_type = \"gpu_crashes\":\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:02:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.75GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x37cb5b0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\r\n```\r\n\r\nOutput plots for run_type = \"gpu_artifacts\":\r\n![input](https://cloud.githubusercontent.com/assets/3643255/24121814/e47dd59c-0d76-11e7-9b35-4ee1327c0230.png)\r\n![conv_out](https://cloud.githubusercontent.com/assets/3643255/24121821/e806480c-0d76-11e7-839d-b94da94a3c75.png)\r\n![pool_out](https://cloud.githubusercontent.com/assets/3643255/24121824/e9f23176-0d76-11e7-931f-62bb49bf2abd.png)\r\n\r\n\r\n", "comments": ["@zheng-xq, have you seen anything like this?", "Assigning to protoget@", "@sullivak please try setting environment variable TF_AVGPOOL_USE_CUDNN=1.\r\nWe use Eigen implementation of this operation, if you use the default data_format setting in tf.nn.avg_pool and leaving TF_AVGPOOL_USE_CUDNN=0.(default)\r\n\r\nOur investigation shows there's a potential a bug in Eigen SpatialAvgPooling.\r\nPlus Cudnn impl is way faster than Eigen.", "Good catch, protoget@!\r\n\r\nIn the past, we couldn't turn this flag on by default, because Cudnn handles boundary differently. Maybe we can try to enable it back again. ", "Not sure how I missed seeing the suggestion from @protoget but that seems to work, thanks! "]}, {"number": 8565, "title": "Type conversion for non-fused, default batch norm #8535", "body": "CLA signed and submitted.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Updated", "Jenkins, test this please.", "Can you addess the test failures?", "I believe the failures are due to lack of precision for float16.\r\n\r\n```python\r\n    # The dynamic range of fp16 is too limited to support the collection of\r\n    # sufficient statistics. As a workaround we simply perform the operations\r\n    # on 32-bit floats before converting the mean and variance back to fp16\r\n    y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_impl.py#L631-L634\r\n\r\nFix options:\r\n\r\n- Lower numerical tolerance when testing for float16; hides practical limits of float16 for batch norm. \ud83d\udc4e \r\n- Use float32 for running stats; converting float32 to float16 to apply batch norm still has problems with precision. \ud83d\udc4e \r\n- ???\r\n\r\nSuggestions?\r\n\r\nP.S. Low priority pull request: I stopped using float16 in favor of smaller models/batches w/ multi-gpu setup. Works \ud83d\udcaf for fully automated lung segmentation!", "I think lowering the numeric tolerance for float16 tests is fine here; I think we need to experiment more to find out how to make best use of batch norm for float16 but we don't need to block this PR on it.", "Updated, but normalization_test still fails, this time with nan errors for the float16 gradient. Normalization error is also nearly 1 with float16, quite substantial an error. Thoughts?", "This to me sounds like getting this to work well with float16 will be more subtle than simply updating the dtypes. Maybe it's worth going back to float32 and changing each individual tensor to float16 to see which ones lead to breakage, and seeing then if it's possible to go around that somehow?", "Unfortunately, simply changing a subset of the variable types is not a simple fix either.\r\n\r\nThe original issue was that when the batch norm variables did not match the input tensor type, e.g. `float16` inputs vs `float32` variables, Tensorflow would throw a type error. We've seen that simply using `float16` runs into numerical precision issues.\r\n\r\nCasting `float32` to `float16` has issues with numerical precision as well. I don't know how truncating `float32` to `float16` would work out, seems like a rabbit hole I'd rather avoid...\r\n\r\nFor reference, 4 variables are defined for `batch_norm`:\r\n\r\n- `beta`\r\n- `gamma`\r\n- `moving_mean`\r\n- `moving_variance`\r\n\r\nP.S. Implementing evolutionary learning as described by Salimans et al. (2017) sounds more promising in terms of the original goal to make more GPU memory available to build larger models. Salimans et al. estimated in their [talk](https://www.technologyreview.com/s/603921/elon-musks-openai-unveils-a-simpler-way-for-machines-to-learn/) that not calculating gradients means models take up to 1/3 the memory. This is 33% better memory efficiency that a conversion to float16 would offer, assuming float16 models take 50% less memory than float32 (`1. - .33/.5 = .33`).\r\n\r\nIn terms of performance, the Salisman et al. implementation scales linearly with additional nodes, something Tensorflow already support.", "Ok, @jakelee8 @alextp, what do we do about this PR?", "I think as it is we should close it. It seems like simply changing the dtypes in batchnorm to float16 is not the right solution to make it work well with float16, so it might require more thought.", "Closing as per discussion."]}, {"number": 8564, "title": "`tf.test.compute_gradient` gives error when computation involves TensorArrays", "body": "### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n``` python\r\na = tf.TensorArray(tf.float32, size=1)\r\nx = tf.ones(5)\r\na = a.write(0, x)\r\ny = a.stack()\r\n\r\ngrads = tf.gradients(y, x)\r\n\r\nwith tf.Session() as sess:\r\n    print(\"y\")\r\n    print(sess.run(y))\r\n\r\n    print(\"grad\")\r\n    print(sess.run(grads))\r\n\r\n    # gives error:\r\n    tf.test.compute_gradient(x, (5,), y, (5,))\r\n```\r\n\r\nThe gradient calculation (`sess.run(grads)`) works fine, it is just something to do with how the gradients are being calculated within `tf.test.compute_gradients`.  Here is the stack trace:\r\n```\r\nFile \"...\\tensorflow\\python\\ops\\gradient_checker.py\", line 312, in compute_gradient\r\n    dx, dy = _compute_dx_and_dy(x, y, y_shape)\r\n  File \"...\\tensorflow\\python\\ops\\gradient_checker.py\", line 193, in _compute_dx_and_dy\r\n    grads = gradients.gradients(y, x, dy)\r\n  File \"...\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"...\\tensorflow\\python\\ops\\gradients_impl.py\", line 368, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"...\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"...\\tensorflow\\python\\ops\\tensor_array_grad.py\", line 158, in _TensorArrayGatherGrad\r\n    grad_source = _GetGradSource(grad)\r\n  File \"...\\tensorflow\\python\\ops\\tensor_array_grad.py\", line 74, in _GetGradSource\r\n    \", got: %s\" % op_or_tensor.name)\r\nValueError: Expected op/tensor name to start with gradients (excluding scope), got: Identity:0\r\n```", "comments": ["@yuanbyu @ebrevdo this test was introduced in an old CL (118251112). Any idea?", "What version of tensorflow are you using?\n\nOn Wed, Mar 22, 2017 at 12:18 PM, drpngx <notifications@github.com> wrote:\n\n> @yuanbyu <https://github.com/yuanbyu> @ebrevdo\n> <https://github.com/ebrevdo> this test was introduced in an old CL\n> (118251112). Any idea?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8564#issuecomment-288509134>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9jUS-bGN2k87umxBTSHgFPnR2xEks5roXP-gaJpZM4Mi__g>\n> .\n>\n", "This is on `master` (commit af2ebdb827f0b07d8f7d2b76b061976a2a778cb0)", "What happens if you do:\n\nz = tf.identity(y)\n\nthen use z in gradients and test_gradients?\n\nOn Wed, Mar 22, 2017 at 1:11 PM, Daniel Rasmussen <notifications@github.com>\nwrote:\n\n> This is on master (commit af2ebdb\n> <https://github.com/tensorflow/tensorflow/commit/af2ebdb827f0b07d8f7d2b76b061976a2a778cb0>\n> )\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8564#issuecomment-288523693>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim_o6vg7zj3qTcoT_gD06pwE7MlL9ks5roYBYgaJpZM4Mi__g>\n> .\n>\n", "Hi all (new user here),\r\n\r\nI also experienced this problem, also on master. I found that if you slice the stacked tensor then the gradient test passes, like:\r\n`y = a.stack()[:] `\r\n(with adjusted size in the compute_gradient call `tf.test.compute_gradient(x, (5,), y, (1,5))`\r\n\r\n@ebrevdo tried the tf.identity, this didn't resolve the issue. \r\n\r\nHope this helps.\r\n\r\n\r\n", "Just double checked, and this issue is still occurring in release 1.3.0.", "/CC @alextp ", "This will be resolved when we move from TensorArray to TensorList under the covers, cc @alextp.", "@alextp do you want to take this over and close it when everything's TensorList, or should we put a special label on it?", "@drasmuss Is this issue resolved? Please update here If it was not resolved already. Thanks!", "Yes it looks like this has been resolved now (as of TF 1.13).", "@drasmuss Thanks for confirming. I am closing the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=8564\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=8564\">No</a>\n"]}, {"number": 8563, "title": "Remove unused assets/code from iOS Camera Example", "body": "After going through the iOS camera example this weekend I noticed several assets are unused, and there are several methods that only call `super`. Let me know if I missed something and they're there for a reason. Feel free to squash commits (or I can as well) if preferred.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please.", "I have tested for camer sample.  It 's different result  from load local bmp  with the same modle,when I use moible phone against the same bmp.  Anyone else have this problem?\r\ncapture frame data is different  from loading bmp picture data?  how to make the same?"]}, {"number": 8562, "title": "Branch 150655275", "body": "", "comments": []}, {"number": 8561, "title": "CTC_Greedy_Decoder outputs sum of logits and not logprobs", "body": "## CTC_Greedy_Decoder outputs sum of logits and not logprobs\r\n\r\nI have been writing my own CTC_Greedy_Decoder function in order to decode the output of a RNN trained with the CTC loss. To check my version, I decided to compare my outputs with TensorFlow's ones. We had the same first output (the decoded label) but we had big differences on second (the logprobs).\r\n\r\nAfter some debugging, I figured out that TF's GreedyDecoder outputs the opposite of the sum of the higher logit of each column. Whereas, in the documentation it is written that we should expect logprobs. \r\n\r\n### How to fix:\r\n- Change the documentation from logprobs to logits\r\n- Instead of summing the logits, it would be  better to sum the higher logit of each column minus the logsumexp of the column. With that fix, the output will be logprobs as written in the documentation.\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\nTensorFlow: 1.0.1 running on CPU\r\n\r\n\r\n", "comments": ["Do you mind submitting a PR and CC @ebrevdo ?", "I can do that. Should I make a PR to change the doc or to change the code so that the function actually returns logprobs ?", "We use un-normalized logits everywhere, so I would go for changing the docs.", "+1\n\nOn Mar 23, 2017 5:11 PM, \"drpngx\" <notifications@github.com> wrote:\n\n> We use un-normalized logits everywhere, so I would go for changing the\n> docs.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8561#issuecomment-288897478>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8BV1l6vHa41zvEDf2Q49h4Iw_xFks5rowoTgaJpZM4Mixgd>\n> .\n>\n", "PR : #8690\r\n", "Looks like this is already fixed by #8690.\r\nClosing issue."]}, {"number": 8560, "title": "GPU PoolAllocator never satisfied with the eviction rate. Can we limit its allocated size?", "body": "I have a tensorflow network where I call `sess.run()` with **tensors of widly changing sizes**. _(to be more precise it takes two tensors as input a [None, E, None, None] and a [None, None, M])_. Additionally, I use some `tf.where` calls which generate variable sized tensors to be transferred to the GPU.\r\n\r\nEverything works fine and training goes nicely and quickly, but eventually it seems that the **`pool_allocator` is never satisfied with the eviction rate it gets and constantly try to increase its size**. \r\n\r\n```\r\n2017-03-20 18:24:07.895271: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 590087 get requests, put_count=590089 evicted_count=2000 eviction_rate=0.00338932 and unsatisfied allocation rate=0.0140911\r\n2017-03-20 18:24:07.895342: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 69492 to 76441\r\n```\r\n\r\nEventually, it **fills the whole machine RAM** (256GB....) and **kills itself by running out-of-memory** (in less than 1h...).\r\n\r\nThis behavior only happens when running on GPU. I checked that no ops are added during training through calling `graph.finalize()`.\r\n\r\nI also tried using `tcmalloc` as proposed [here](http://stackoverflow.com/documentation/tensorflow/3883/how-to-debug-a-memory-leak-in-tensorflow#t=201703201715326785429), and ran the profiler which was saying it was staying at a happy 500MB while the memory usage in `top` was multiple GB. As far as I understand, the `pool_allocator` uses his own `malloc` system so it would not show in `tcmalloc` profiler right?\r\n\r\n[tcmalloc profiler output](https://github.com/tensorflow/tensorflow/files/855907/output_1.pdf)\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n- [How to interpret PoolAllocator messages](http://stackoverflow.com/questions/35151207/how-to-interpret-poolallocator-messages-in-tensorflow)\r\n- [How to debug a memory leak in TF](http://stackoverflow.com/documentation/tensorflow/3883/how-to-debug-a-memory-leak-in-tensorflow#t=201703201715326785429)\r\n- The question I asked [here](http://stackoverflow.com/questions/42861956/gpu-poolallocator-explodes-the-cpu-memory) on SO, without much success.\r\n\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04\r\nCUDA 8.0 + cuDNN 5.1\r\n\r\npython 3.5 nighty build\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nI honestly tried, but it seems that if I simplify the system the problem goes away.", "comments": ["Just a quick update on this, I \"solved\" my issue by recompiling tensorflow with changing the hardcoded parameters of the PoolAllocator. Just setting it to relatively high size and non-resizable allowed me not to run OutOfMemory.\r\n\r\nSee [here](https://github.com/SeguinBe/tensorflow/commit/2097a40d6ebfa3d4a690c5bb7592e8c433e6546e)\r\n\r\nI suppose having it as a configuration parameter of the `GPUOptions` protobuf would probably be the best way of allowing this flexibility? Should I try to investigate this direction?", "I agree that the pool_allocator parameters should be exposed as some kind of config option.  What's going on in this case is that ProcessState is trying to reduce the overhead of page locking CPU memory regions for DMA with the GPUs by keeping pre-locked buffers in a pool.  Your application is unusual and needs to tolerate a higher eviction rate.    I'm not sure whether this should go into GPUOptions or elsewhere.  I'll start a change percolating here. ", "Note that there is another plausible design solution to this problem.  If your CPU has enough RAM for this purpose, a large area could be carved out, pre-locked for DMA, then a BFCAllocator or similar could be provisioned on top of that.  The PoolAllocator is a simple solution that works well enough when there's a small, fixed number of Tensor sizes on the GPU.  I don't have time to work on the more complex solution right now, and it's probably of little value for most users.  ", "There is an internal CL that tries to switch to BFCAllocator all together. We can only do it after verifying it is safe to do by default. We will update when that happens.\r\n\r\nFor the brave souls, these are the pending changes. We might add an environment variable to control which one to use in the transitional period. In the long term, one of them will stay.\r\n\r\n```\r\ntensorflow/core/common_runtime/gpu/process_state.cc:\r\n+        new BFCAllocator(new BasicCPUAllocator(), true /*allow_growth*/,\r\n+                         \"bfc_cpu_allocator_for_gpu\" /*name*/);\r\n-        new PoolAllocator(100 /*pool_size_limit*/, true /*auto_resize*/,\r\n-                          new BasicCPUAllocator(), new NoopRounder, \"cpu_pool\")\r\n\r\n```", "Not sure how the `BFCAllocator` behaves but just setting `allow_growth` to `True`, wouldn't there be a risk of still having unlimited growing?", "Yes, but BFC is a recompacting allocator, while PoolAllocator, with a low miss toleration factor and auto_resize=true, is very much not.  So, if you're using a large variety of different sizes, but only a few of them at once, BFC should not grow its memory region arbitrarily large.", "@poxvoculi @zheng-xq have any of the solutions discussed been committed?", "I am facing this issue as well. Just wondering if pool_size_limit has a upperbound that is proportional to the system RAM?", "I think you could just run with environment variable `TF_CPU_ALLOCATOR_USE_BFC=true` to enable that. See [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc#L165) for details.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Since we are systematically switching to BFC allocators. Closing this for now. "]}, {"number": 8559, "title": "forward pass projection", "body": "Hi,\r\n\r\nIs there any way to define a layer that for forward-pass calculates its output by projecting the weight values into a different value range, but for the back-propagation uses the real weight values? i.e., as an example from the [mnist.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py) file, if for the hidden layer 1 forward pass we could have `hidden1 = tf.nn.relu(tf.matmul(images, projection_func(weights)) + biases)`, but for the gradient calculation during back-propagation the weights were updated without `projection_func()`.\r\n\r\nThis would be useful to implement BNNs, to apply functions such as the ones mentioned by @Jony101K [here](https://github.com/itayhubara/BinaryNet/issues/9#issuecomment-243705218).\r\n\r\nThanks.\r\nAlexandre", "comments": ["@bhack, could you help me with this?", "Maybe you can try https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/function.py. It allows you to construct a new op with existing ones, and define its gradient.\r\n\r\n```python\r\nfrom tensorflow.python.framework.function import Defun\r\n\r\ndef _projection_func_grad(op, grad):\r\n    # compute the (fake) gradient, in this case just pass it through\r\n    return grad\r\n\r\n@Defun(tf.float32, python_grad_func=_projection_func_grad)\r\ndef projection_func(weights):\r\n    # do something\r\n    return weights\r\n```", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 8558, "title": "Mention Julia API bindings", "body": "In several places, like [here](https://www.tensorflow.org/api_docs/), API bindings for other languages are mentioned. It would be nice to mention the [Julia bindings](https://github.com/malmaud/TensorFlow.jl), which are now fairly stable and are actively used by many people.\r\n\r\nIt appears much of the website content comes from this repo but I can't find that page to make a PR. Would greatly appreciate a pointer to the right place for this.\r\n\r\ncc @malmaud", "comments": ["@wolffg : Any thoughts on this?", "All the mentioned APIs are merged into our core repository.\r\nWe also have haskell and rust bindings as external repositories, which are not mentioned in our website.\r\nhttps://github.com/tensorflow/haskell\r\nhttps://github.com/tensorflow/rust\r\nThe above are even owned by tensorflow github org, but not mentioned.\r\nSo I object these to be mentioned in the core API documentation. We should only list officially supported languages here:\r\nhttps://www.tensorflow.org/api_docs/\r\n\r\nHowever, we have a lot of external contributions that we can point people to. Maybe we can have a section in api_docs landing page that is along these lines:\r\n\"\"\"\r\nBelow are a list of languages that are supported by our commmunity.\r\nPlease reach out to repository owners for support and documentation:\r\n\r\n<language> - <website>\r\n\"\"\"\r\nWhat do you think @wolffg @asimshankar ", "Yup, I think that's what @MikeInnes was suggesting and sounds okay to me - to give a shoutout to various community supported bindings (FYI @jhseu )", "Completely agree. The current wording on the page is:\r\n\r\n> We hope that the TensorFlow community will develop front ends for other languages like JavaScript, Lua, R and perhaps others [...]\r\n\r\nThis reads to me as if the listed bindings are the only ones so far. I think it'd be great to list community supported bindings here as well as calling for more (with a disclaimer that they are not official).", "Done. You can currently see this on the version 1.1 page: https://www.tensorflow.org/versions/r1.1/api_docs/ \r\nand once the 1.1 release is finalized, that https://www.tensorflow.org/api_docs will look the same.\r\n\r\nThanks for making the bindings!", "Awesome, thankyou!", "Thanks @asimshankar! "]}, {"number": 8557, "title": "Error building TensorFlow with local LLVM repository. ( Using local_repository extension in bazel )", "body": "Essentially, I want to run TensorFlow with a custom LLVM repository and not the llvm-mirror that bazel pulls from. \r\n\r\nI made the following changes:\r\n\r\n1. Changed the ```temp_workaround_http_archive``` rule in ```//tensorflow/workspace.bzl``` to:\r\n\r\n          native.local_repository (\r\n              name = \"llvm\",\r\n              path = \"/git/llvm/\",\r\n          )\r\n\r\nWhere ```/git/llvm``` is my local llvm repository.\r\n\r\n2. In ```/git/llvm``` I added the file ```WORKSPACE``` containing:\r\n\r\n        workspace( name = \"llvm\" )\r\n\r\n\r\nError log:\r\n\r\n    bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n    ERROR: /git/tensorflow/tensorflow/tools/pip_package/BUILD:81:1: no such package '@llvm//': BUILD file not found on package path and referenced by '//tensorflow/tools/pip_package:licenses'.\r\n    ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\n    INFO: Elapsed time: 0.219s\r\n\r\n\r\nInstalled TensorFlow from source. Here is the version info:\r\n\r\n    $ git rev-parse HEAD\r\n    4c3bb1aeb7bb46bea35036433742a720f39ce348\r\n\r\n    $ bazel version\r\n    Build label: 0.4.5\r\n    Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n    Build time: Thu Mar 16 12:19:38 2017 (1489666778)\r\n    Build timestamp: 1489666778\r\n    Build timestamp as int: 1489666778\r\n\r\n\r\nNow, obviously a ```llvm.build``` file is required, I just need to know how and where to place it. Also, how can I build tools like Polly from the bazel build files?\r\n\r\nThanks in advance!\r\n\r\n", "comments": ["This is an issue for your local setup.\r\nNot an issue with the checked in TensorFlow code.\r\nTherefore, I will close this issue.\r\n\r\nPlease reach out to stackoverflow with debugging support of your own code.", "I need to compile TF with local repositories  and  I have the same issue."]}, {"number": 8556, "title": "Tenor flow distributed support for spectrum lsf ", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["We are getting benchmark requests for tens or flow in a distributed environment. Spectrum lsf is our scheduler and tens or flow and all distributed powerai applications need to run in this environment. \r\nDocumentation on how to run with spectrum lsf should be included. ", "LSF is not a workflow that we have knowledge or support of. However, the first google search result for \"tensor lsf\" links to this stackoverflow which has a link to blog entry that is helpful for setting it up.\r\nhttp://stackoverflow.com/questions/41220475/tensorflow-lsf-distributed-tensorflow-on-lsf-cluster"]}, {"number": 8555, "title": "Only run test that requires int64 support when the driver supports int64", "body": "Making a test that requires int64 support conditional on support from int64 in the device under test.\r\n", "comments": ["Can one of the admins verify this patch?", "thanks for that.  agreed about the ().  I guess I've been switching languages too quickly\r\n", "hi guys.  is there a long waiting list for the sanity checks?  strange that it has not gone through, if it is an automated system.\r\n", "Jenkins, test this please.", "The tests have to be manually triggered, either by the reviewer or by the person triaging pull requests. Apologies for not triggering them myself last week --- I was out of office.", "cheers.  nice one."]}, {"number": 8554, "title": "Floating Point Exception/SIGFPE in tf.map_fn over an empty tensor", "body": "Working on a custom implementation of Faster-RCNN, it runs fine for ~150 - 300 batches but then I get a Floating Point Error, apparently in ConcatGPUImpl.\r\n\r\nSource is here: https://github.com/Panaetius/woipv (src/models/train_model.py and src/models/model.py, it's a bit of a mess still since it's a work in progress), reproducible as of commit 6eb1e3c5e818919b64a0a981abb98c2f3bc3dea1\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 5\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n-rw-r--r-- 1 root root   558720 Okt  4 23:15 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Okt  4 23:15 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Okt  4 23:15 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 Okt  4 23:15 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Okt  4 23:15 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Okt  4 23:23 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Okt  4 23:23 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Okt  4 23:23 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Okt  4 23:23 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: official python 3 tensorflow-gpu package\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\r\n\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n1.0.0\r\n\r\n\r\n\r\n### Logs or other output that would be helpful\r\ngdb:\r\n\r\nThread 49 \"python\" received signal SIGFPE, Arithmetic exception.\r\n[Switching to Thread 0x7fff10bb8700 (LWP 8227)]\r\n0x00007fffcaab91de in void tensorflow::ConcatGPUImpl<float, int>(Eigen::GpuDevice const&, tensorflow::CudaDeviceArrayStruct<float const*, 8> const&, tensorflow::CudaDeviceArrayStruct<int, 8> const&, bool, int, tensorflow::TTypes<float, 2, long>::Matrix*) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n\r\n\r\nBacktrace:\r\n\r\n#0  0x00007fffcaab91de in void tensorflow::ConcatGPUImpl<float, int>(Eigen::GpuDevice const&, tensorflow::CudaDeviceArrayStruct<float const*, 8> const&, tensorflow::CudaDeviceArrayStruct<int, 8> const&, bool, int, tensorflow::TTypes<float, 2, long>::Matrix*) () from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#1  0x00007fffcaaaf45c in void tensorflow::(anonymous namespace)::ConcatGPUCall<float, int>(tensorflow::OpKernelContext*, std::vector<std::unique_ptr<tensorflow::TTypes<float, 2, long>::ConstMatrix, std::default_delete<tensorflow::TTypes<float, 2, long>::ConstMatrix> >, std::allocator<std::unique_ptr<tensorflow::TTypes<float, 2, long>::ConstMatrix, std::default_delete<tensorflow::TTypes<float, 2, long>::ConstMatrix> > > > const&, tensorflow::TTypes<float, 2, long>::Tensor*) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#2  0x00007fffc9b14c16 in tensorflow::TensorArrayPackOrGatherOp<Eigen::GpuDevice, float, false>::Compute(tensorflow::OpKernelContext*) () from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#3  0x00007fffcad155b2 in tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#4  0x00007fffcad56183 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#5  0x00007fffcad569fa in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#6  0x00007fffcb09a960 in std::_Function_handler<void (), Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, tensorflow::thread::EigenEnvironment)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#7  0x00007fffcb099c10 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /home/zenon/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n---Type <return> to continue, or q <return> to quit---\r\n#8  0x00007fffc7f2c260 in ?? () from /home/zenon/anaconda3/envs/tensorflow/bin/../lib/libstdc++.so.6\r\n#9  0x00007ffff76d16fa in start_thread (arg=0x7fff10bb8700) at pthread_create.c:333\r\n#10 0x00007ffff6aefb5d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n\r\n", "comments": ["Upon researching this issue some more (with the good old \"Sprinkle Prints everywhere\" method of debugging), it seems to happen when the input labels/regions are empty. The MSCOCO dataset apparently has images with no labels, so those would cause the issue. I'm reading the labels/regions with a tf.VarLengthFeature, so the dimensions aren't known ahead of time.\r\n\r\nIt's somewhere inside one of the two tf.map_fn() applications, going by the gdb stacktrace, though have yet to narrow it down precisely to write a simple test case\r\n\r\n", "Ok I managed to reproduce it in a simple test case: https://gist.github.com/Panaetius/8da26064491ab4ad1890bca3dfd86eff\r\n\r\nThe test case can probably be made smaller still (for instance, the whole save data -> load data with tf.VarLenFeature is probably not needed, you could just construct an empty SparseTensor, though I couldn't get this to work when I gave it a quick try).\r\n\r\nBasically, calling tf.map_fn with an empty tensor ( [ ] ) leads to the SIGFPE, most likely when the x[0] is done in the lambda.\r\n\r\nI'll change the title of the issue to reflect that this is an issue with tf.map_fn\r\n\r\nOf course I'll have to change my code to correctly deal with empty/missing labels, so I doubt this will be an issue for me in the future, though tf.map_fn actually trying to run over an empty tensor and then just straight crashing seems like a bug that should be fixed to me", "@yuanbyu, do you think there is a way we could make this failure case in tf.map_fn more intuitive to detect?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8553, "title": "Add header only build rules for XLA external plugins", "body": "This change includes the exporting of XLA symbols in the main python plugin.\r\n\r\nThis allows external shared-object plugins to be built against the XLA source header files\r\nand to be loaded into a running process.\r\n\r\nNote:  I have only exposed some protobuf symbols.  Exposing *protobuf* causes tensorboard to fail to load. \r\n", "comments": ["Can one of the admins verify this patch?", "hello.   i've been looking into my problems with the startup error when Variables are included in the graph (not always - but it fails for all of the variable type unit tests).\r\n\r\nhttps://github.com/google/protobuf/issues/2894\r\n\r\nI suspect, after reading a lot of protobuf stuff, that it might be hard/impossible to have a plugin due to protobuf global state / static initializers.  i note that it seems to be ok for kernel_op plugins, but they might sidestep some global state issue.\r\n\r\nnevertheless, i think that a public headers interface for XLA is a good thing, so that I can have my driver code elsewhere in the repo.  At the moment only things in //tensorflow/compiler can access enough of the headers to compile.\r\n\r\n", "ok - i'm abandoning this.  i am going to build a 'tf with poplar' integrated release along the lines of the other backends. ", "at some point i will still upstream some header only targets, just to keep my stuff as much in line with the public repo as possible."]}, {"number": 8552, "title": "SyncReplicasOptimizer' object has no attribute 'get_clean_up_op'", "body": "```\r\npython /models/slim/train_image_classifier.py \\\r\n  --worker_replicas=2 \\\r\n  --num_ps_tasks=1 \\\r\n  --sync_replicas=True \\\r\n  --replicas_to_aggregate=2 \\\r\n  --task=0 \\\r\n  --dataset_name=imagenet  \\\r\n  --train_dir=/tmp/train_logs  \\\r\n  --dataset_split_name=train \\\r\n  --dataset_dir=/imagenet/dataEgs \\\r\n  --model_name=inception_v3\r\n\r\n````\r\n\r\nRun /models/slim/train_image_classifier.py \r\n\r\n```\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=2; total_num_replicas=2\r\nINFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.\r\nTraceback (most recent call last):\r\n  File \"/models/slim/train_image_classifier.py\", line 583, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/models/slim/train_image_classifier.py\", line 579, in main\r\n    sync_optimizer=optimizer if FLAGS.sync_replicas else None)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 733, in train\r\n    cleanup_op = sync_optimizer.get_clean_up_op()\r\nAttributeError: 'SyncReplicasOptimizer' object has no attribute 'get_clean_up_op'\r\n\r\n```\r\n\r\nI confirm that more than one demos will encounter this issue if using distributed training under tensorflow 1.0.1 image. \r\n\r\nHope some improvements for distributed training to demo how to use distributed training. \r\n\r\nThanks. ", "comments": ["https://github.com/tensorflow/tensorflow/commit/74514bffc4bbac7e6717e1079aca055b1c837229 might fix this issue.\r\n\r\nUnfortunately, it's only available on master as of now.\r\nIs there any chance that this commit can be picked into r1.0 branch for the next minor release?\r\n\r\n", "@pclove1 \r\n\r\nThanks for your mentions.\r\n\r\nI have fixed it manually before, but to run distributed training more and more bugs will be found with r1.0.1. It seems that the distributed training demo have not been updated for long time.  Hope for some more improvements.", "@mrry, could you take a look if there is anything new we need to do to update the example?", "It looks like these were never fixed after `tf.train.SyncReplicasOptimizer` was replaced by `tf.train.SyncReplicasOptimizerV2` in 059ccad4d4bac851da9fa9694c23dd49a4089bc6.\r\n\r\nI'm not sure what all the changes were between these two versions, but @jmchen-g should be.", "The new version of sync opt doesn't need any clean up op so you can safely remove them in the training code.", "So just to be clear, I was able to modify /tensorflow/contrib/slim/python/slim/learning.py and remove this: \r\n\r\nif isinstance(sync_optimizer,\r\n                    sync_replicas_optimizer.SyncReplicasOptimizer):\r\n        cleanup_op = sync_optimizer.get_clean_up_op()\r\n\r\nIs the suggestion going forward to replace the SyncReplicasOptimizer() with SyncReplicasOptimizerV2 in models/slim/train_image_classifier.py when SyncReplicasOptimizerV2 is added to a release?\r\n\r\nI was able to run synchronous distributed tf-1.0.1 with the above lines commented out in learning.py and it ran as expected.", "@jbalma Interested in submitting a pull request to remove the obsolete code?", "It looks like `get_clean_up_op` has been removed in commit https://github.com/tensorflow/tensorflow/commit/74514bffc4bbac7e6717e1079aca055b1c837229\r\n\r\nI think this issue could be closed?", "Right. That op get_clean_up_op was gone for a while. This issue should be\nclosed.\n\nOn Sun, Jul 2, 2017 at 7:31 AM, Yong Tang <notifications@github.com> wrote:\n\n> It looks like get_clean_up_op has been removed in commit 74514bf\n> <https://github.com/tensorflow/tensorflow/commit/74514bffc4bbac7e6717e1079aca055b1c837229>\n>\n> I think this issue could be closed?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8552#issuecomment-312495167>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APD49niEyknsu74IHEYyzbvJ4O5aKiZBks5sJ6nSgaJpZM4MiLg->\n> .\n>\n", "Looks good . Thanks "]}, {"number": 8551, "title": "  tf.image.decode_image doesn't return tensor's shape", "body": "I try to use \"image.decode_image\" to read image file as tensor, but this function returns a tensor without \"shape\".\r\nAs said in the doc:\r\n>  Their input and output are all of variable size. If you need fixed size images, pass the output of the decode Ops to one of the cropping and resizing Ops.\r\nBut actually it cannot be passed to resizing op without shape.\r\n\r\nIs there a way to use import image as a normal tensor?\r\n\r\nCodes: I ran it in ipy notebook\r\n```\r\nfn = '8.png'\r\nimage_contents = tf.read_file(fn)\r\nimage = tf.image.decode_image(image_contents, channels=1)\r\nimage\r\n\r\nimage.shape\r\n\r\nimage.eval().shape\r\n\r\nimg_resize = tf.image.resize_images(image, [28,28])\r\n```\r\nOutput:\r\n<tf.Tensor 'decode_image/cond_jpeg/Merge:0' shape=<unknown> dtype=uint8>\r\n\r\nTensorShape(None)\r\n\r\n(250, 250, 1)\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-b913c79cb137> in <module>()\r\n----> 1 img_resize = tf.image.resize_images(image, [28,28])\r\n\r\n/home/tianwei/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/image_ops_impl.pyc in resize_images(images, size, method, align_corners)\r\n    641   images = ops.convert_to_tensor(images, name='images')\r\n    642   if images.get_shape().ndims is None:\r\n--> 643     raise ValueError('\\'images\\' contains no shape.')\r\n    644   # TODO(shlens): Migrate this functionality to the underlying Op's.\r\n    645   is_batch = True\r\n\r\nValueError: 'images' contains no shape.\r\n\r\n", "comments": ["Yes, this is bothering. My workaround is using `tf.image.resize_image_with_crop_or_pad` as it said, and maybe manually set shape.", "@inflation Thanks, it works. But I also noticed that, this function returns a tensor without channel dimension...like this:\r\n```\r\nimage_contents = tf.read_file(fn)\r\nimage = tf.image.decode_image(image_contents, channels=3)\r\nimage = tf.image.resize_image_with_crop_or_pad(image, 250, 250)\r\nimage.shape\r\n```\r\nTensorShape([Dimension(250), Dimension(250), Dimension(None)])", "And that's what I mean manually set it.", "You can use `tf.Tensor.set_shape` if you need a fixed static shape info.", "Keep in mind everything you're doing is symbolic. Therefore, you cannot know the shape of your supposed image before actually loading it \u2014 and this is why the Tensor is \"shapeless\". Even the last dimension isn't inferrable, because it could be a grayscale image (then third dimension = 1), a colored image (third dimension = 3), a gif (third dimension = 4), or something else.\r\n\r\nAs @ppwwyyxx said, you can (1) use set_shape if you know the shape of the tensor/image and want to simplify its usage, this can be used to force the third dimension, if you're sure your images will always be on the same format; (2) manipulate your images with operations that accept symbolic shapes throughout your pipeline, like `tf.reshape`; or (3) split your graph and load the images with a `sess.run` before actually sending them through the rest of the graph, this will allow you to know their exact shape \"beforehand\" (subject to interpretations).\r\n\r\nThe symbolic operation to get a tensor's (possibly image) shape is `tf.shape(x)`.", "Thanks, the set_shape works well here.\r\n\r\nBut one thing I'm curious about is that, if I split the graph, (add a sess.run, and get the result of image array, then construct tensor, send it to rest of the graph), does this increase overhead? \r\nWhile actually when running it, it seems that the \"set_shape\" method will take more time to run than 'split graph\" method...\r\nI'm not clear how much overhead does it take if I split the graph and run session.\r\n", "@TianweiXing, both approaches have different overheads and it is problem dependent. The best way to find out is to try it both ways and profile. Given that it is more of a usage question rather than a bug or feature request, I am closing this problem.", "The annoying bit is that while `tf.image.decode_image` does not return a shape, both `tf.image.decode_jpeg` and `tf.image.decode_png` do.", "@mrharicot Really, which version of tensorflow? Currently using 1.1.0 `tf.image.decode_jpeg` behave just the same as  `tf.image.decode_image`, which does not return a shape.", "@Cooper-Yang I was using 1.0 at the time.\r\n`tf.image.decode_jpeg` gives me the image size, so I ended up using an [ugly workaround](https://github.com/mrharicot/monodepth/blob/master/monodepth_dataloader.py#L98)\r\n", "Once you upgrade to TF 1.2 decode_png will decode both jpg as well as png and vice versa. decode_image cannot be used along with resize since it also supports .gif . \r\n\r\nYou can read this thread: https://github.com/tensorflow/tensorflow/issues/9356"]}, {"number": 8550, "title": "Android \"TF Stylize\" demo crash with \"input_max_range must be larger than input_min_range\"", "body": "I have compiled and installed the demo app according to the instruction in the [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md).  The \"TF Detect\" and \"TF Classify\" apps are working as expected.  However, starting the \"TF Stylize\" app, it always crashes in about 3 seconds.  The prebuilt apk crashes in the same way.  Here is the android logcat recorded:\r\n\r\n> $ adb -s b80360c7 logcat  | grep Tensor\r\nI/TensorFlowInferenceInterface( 6801): Checking to see if TensorFlow native methods are already loaded\r\nI/TensorFlowInferenceInterface( 6801): TensorFlow native methods not found, attempting to load via tensorflow_inference\r\nI/TensorFlowInferenceInterface( 6801): Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\nI/TensorFlowInferenceInterface( 6801): Model load took 540ms, TensorFlow version: 1.0.1\r\nI/TensorFlowInferenceInterface( 6801): Successfully loaded model from 'file:///android_asset/stylize_quantized.pb'\r\nE/TensorFlowInferenceInterface( 6801): Failed to run TensorFlow inference with inputs:[input, style_num], outputs:[transformer/expand/conv3/conv/Sigmoid]\r\nE/TensorFlowInferenceInterface( 6801): Inference exception: java.lang.IllegalArgumentException: input_max_range must be larger than input_min_range.\r\nE/TensorFlowInferenceInterface( 6801):   [[Node: transformer/contract/conv1/Relu_eightbit_quantize_transformer/contract/conv1/InstanceNorm/batchnorm/add_1 = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_min_transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_max_transformer/contract/conv1/InstanceNorm/batchnorm/add_1)]]\r\nE/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.getTensor(TensorFlowInferenceInterface.java:486)\r\nE/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeIntoFloatBuffer(TensorFlowInferenceInterface.java:332)\r\nE/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeFloat(TensorFlowInferenceInterface.java:287)\r\n\r\nAs can be inferred from the logcat, the problem happens in `tensorflow/core/kernels/quantize_op.cc` line 71.  The app is using a quantized model.  I found that `input_min_range` is set to be `inf`, and `input_max_range` is `-inf`, which is obviously wrong.\r\n\r\nWhat should be done to fix it?\r\n\r\nThe crash appears on Samsung Galaxy S4, but does not appears on emulator with Intel CPU.\r\n\r\n[Edit]\r\nWith more experiment I found that sometimes the apps works without crashing, about 1 out of 10 trials.", "comments": ["It is found that if `DEBUG_MODEL` is set to `true` in StylizeActivity.java, which replace the camera captured bitmap with a predefined one, the app will not crash.", "Do the other demos work for you? If so, I'm guessing the preview frame size it's choosing is broken somehow (stylization uses a larger one than the other demos).\r\n\r\nCan you paste a full log please?", "@andrewharp thanks for looking into this issue.  Actually the other demo has some non-fatal problems (I thought they were unrelated).\r\n\r\n## TF classify\r\n- Sometimes a Toast \"Failed\" is shown, then there is no camera preview.\r\n- In case problem 1 does not happen, the camera preview is widened.\r\n## TF Detect\r\n- Same issues as TF classify\r\n- I have not yet success in using it to detect any people\r\n\r\nI can reproduce all of these problems, except \"Failed\" Toast, in another phone (LG G4c, also android 5).  So could it be android 5 specific problem.  I have no more phones on my hand for testing so could somebody here try it out?\r\n\r\nHere is the full log from the LG phone captured from AndroidStudiio:\r\n```\r\n03-22 11:01:10.090 9698-9698/? I/art: Late-enabling -Xcheck:jni\r\n03-22 11:01:10.230 9698-9698/org.tensorflow.demo D/ContextHelper: convertTheme. context->name=org.tensorflow.demo themeResourceId=2131165185\r\n03-22 11:01:10.230 9698-9698/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.StylizeActivity@35597053\r\n03-22 11:01:10.240 9698-9698/org.tensorflow.demo I/PhoneWindow: [generateLayout] setColorNavigationBar => color=0x ff000001\r\n03-22 11:01:10.240 9698-9698/org.tensorflow.demo D/PhoneWindowEx: [PWEx][generateLayout] setNavigationBarColor2 : colors=0xff000000\r\n03-22 11:01:10.240 9698-9698/org.tensorflow.demo I/PhoneWindow: [setNavigationBarColor2] color=0x ff000000\r\n03-22 11:01:10.260 9698-9698/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.StylizeActivity@35597053\r\n03-22 11:01:10.260 9698-9698/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.StylizeActivity@35597053\r\n03-22 11:01:10.260 9698-9698/org.tensorflow.demo I/Activity: Activity.onPostResume() called \r\n03-22 11:01:10.270 9698-9718/org.tensorflow.demo D/OpenGLRenderer: Render dirty regions requested: true\r\n03-22 11:01:10.270 9698-9718/org.tensorflow.demo I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: EGL 1.4 QUALCOMM build:  (I68fa98814b)\r\n                                                               OpenGL ES Shader Compiler Version: E031.25.03.01\r\n                                                               Build Date: 07/17/15 Fri\r\n                                                               Local Branch: LA.BR.1.1.2_RB1-AU010-1169358\r\n                                                               Remote Branch: \r\n                                                               Local Patches: \r\n                                                               Reconstruct Branch: \r\n03-22 11:01:10.270 9698-9718/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n03-22 11:01:10.290 9698-9718/org.tensorflow.demo D/OpenGLRenderer: Enabling debug mode 0\r\n03-22 11:01:10.310 9698-9698/org.tensorflow.demo D/Atlas: Validating map...\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value mw_continuous-picture\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value manual\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value emboss\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value sketch\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value neon\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value asd\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value backlight\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value flowers\r\n03-22 11:01:10.390 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value AR\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1920x1440\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1920x1200\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1920x1080\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1600x1200\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1468x1200\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 1280x960\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 1280x800\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 1280x720\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 960x720\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 864x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 854x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 848x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 800x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 720x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 768x432\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 640x480\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 576x432\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 480x320\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 384x288\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 352x288\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 320x240\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 240x160\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 176x144\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 144x176\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 160x120\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Chosen size: 1468x1200\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n03-22 11:01:10.400 9698-9698/org.tensorflow.demo I/TensorFlowInferenceInterface: Loading tensorflow_inference.\r\n03-22 11:01:11.000 9698-9698/org.tensorflow.demo I/TensorFlowInferenceInterface: Model load took -496ms, TensorFlow version: 1.0.0\r\n03-22 11:01:11.000 9698-9698/org.tensorflow.demo I/tensorflow: StylizeActivity: Sensor orientation: 90, Screen orientation: 0\r\n03-22 11:01:11.110 9698-9713/org.tensorflow.demo I/art: CheckpointMarkThreadRoots callback created = 0xb7e9a3d8\r\n03-22 11:01:11.120 9698-9713/org.tensorflow.demo I/art: CheckpointMarkThreadRoots callback created = 0xb7c21750\r\n03-22 11:01:11.130 9698-9713/org.tensorflow.demo I/art: CheckpointMarkThreadRoots callback created = 0xb8187ab0\r\n03-22 11:01:11.140 9698-9713/org.tensorflow.demo I/art: CheckpointMarkThreadRoots callback created = 0xb7ed5610\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value mw_continuous-picture\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value manual\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value emboss\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value sketch\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value neon\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value asd\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value backlight\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value flowers\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value AR\r\n03-22 11:01:11.420 9698-9698/org.tensorflow.demo I/CameraManager: Using legacy camera HAL.\r\n03-22 11:01:11.560 9698-9708/org.tensorflow.demo W/art: Suspending all threads took: 19.075ms\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value mw_continuous-picture\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value manual\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value emboss\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value sketch\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value neon\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value asd\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value backlight\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value flowers\r\n03-22 11:01:11.610 9698-9698/org.tensorflow.demo W/ArrayUtils: Ignoring invalid value AR\r\n03-22 11:01:11.630 9698-9717/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 1468x1200\r\n03-22 11:01:11.640 9698-9698/org.tensorflow.demo I/Choreographer: Skipped 73 frames!  The application may be doing too much work on its main thread.\r\n03-22 11:01:11.650 9698-9717/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING\r\n03-22 11:01:11.650 9698-9777/org.tensorflow.demo I/RequestThread-0: Configure outputs: 2 surfaces configured.\r\n03-22 11:01:11.650 9698-9777/org.tensorflow.demo D/Camera: app passed NULL surface\r\n03-22 11:01:11.710 9698-9717/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state IDLE\r\n03-22 11:01:11.710 9698-9698/org.tensorflow.demo I/art: Thread[1,tid=9698,WaitingForJniOnLoad,Thread*=0xb752c300,peer=0x766c3328,\"main\"] recursive attempt to load library \"/system/lib/libhook_jni.so\"\r\n03-22 11:01:11.720 9698-9717/org.tensorflow.demo I/RequestQueue: Repeating capture request set.\r\n03-22 11:01:11.720 9698-9777/org.tensorflow.demo W/LegacyRequestMapper: convertRequestMetadata - control.awbRegions setting is not supported, ignoring value\r\n03-22 11:01:11.720 9698-9777/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n03-22 11:01:11.720 9698-9777/org.tensorflow.demo W/LegacyRequestMapper: Only received metering rectangles with weight 0.\r\n03-22 11:01:11.720 9698-9698/org.tensorflow.demo E/MediaProfilesEx-JNI: register_com_lge_media_MediaProfilesEx\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo E/MediaRecorderEx-JNI: register_com_lge_media_MediaRecorderEx\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo D/AudioSystemEx: register_com_lge_media_LGAudioSystem\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo E/SurfaceControlEx: register_com_lge_view_SurfaceControlEx\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo I/art: Thread[1,tid=9698,WaitingForJniOnLoad,Thread*=0xb752c300,peer=0x766c3328,\"main\"] recursive attempt to load library \"/system/lib/libhook_jni.so\"\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo D/LGMtpDatabaseJNI: register_android_mtp_LGMtpDatabase\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo I/art: Thread[1,tid=9698,WaitingForJniOnLoad,Thread*=0xb752c300,peer=0x766c3328,\"main\"] recursive attempt to load library \"/system/lib/libhook_jni.so\"\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo D/LGMtpServerJNI: register_android_mtp_LGMtpServer\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo I/art: Thread[1,tid=9698,WaitingForJniOnLoad,Thread*=0xb752c300,peer=0x766c3328,\"main\"] recursive attempt to load library \"/system/lib/libhook_jni.so\"\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo E/MediaPlayerEx-jni: register_com_lge_view_MediaPlayerEx\r\n03-22 11:01:11.730 9698-9698/org.tensorflow.demo I/art: Thread[1,tid=9698,WaitingForJniOnLoad,Thread*=0xb752c300,peer=0x766c3328,\"main\"] recursive attempt to load library \"/system/lib/libhook_jni.so\"\r\n                                                        \r\n                                                        [ 03-22 11:01:11.730  9698: 9698 D/         ]\r\n                                                        register_com_lge_emoji_EmojiUtil\r\n03-22 11:01:11.900 9698-9698/org.tensorflow.demo I/Timeline: Timeline: Activity_idle id: android.os.BinderProxy@b0a0dc1 time:128717133\r\n03-22 11:01:11.970 9698-9778/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CAPTURING\r\n03-22 11:01:12.200 9698-9717/org.tensorflow.demo D/ImageReader_JNI: ImageReader_imageSetup: Overriding buffer format YUV_420_888 to 32315659.\r\n03-22 11:01:12.200 9698-9717/org.tensorflow.demo I/tensorflow: StylizeActivity: Initializing at size preview size 1468x1200, stylize size 256\r\n03-22 11:01:12.200 9698-9717/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 1766400\r\n03-22 11:01:12.210 9698-9717/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 441600\r\n03-22 11:01:12.220 9698-9717/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 441600\r\n03-22 11:01:13.420 9698-9716/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow session: java.lang.IllegalArgumentException: input_max_range must be larger than input_min_range.\r\n                                                                                 \t [[Node: transformer/contract/conv1/Relu_eightbit_quantize_transformer/contract/conv1/InstanceNorm/batchnorm/add_1 = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_min_transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_max_transformer/contract/conv1/InstanceNorm/batchnorm/add_1)]]\r\n03-22 11:01:13.460 9698-9716/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                                                                   Process: org.tensorflow.demo, PID: 9698\r\n                                                                   java.lang.IndexOutOfBoundsException: Invalid index 0, size is 0\r\n                                                                       at java.util.ArrayList.throwIndexOutOfBoundsException(ArrayList.java:255)\r\n                                                                       at java.util.ArrayList.get(ArrayList.java:308)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.getTensor(TensorFlowInferenceInterface.java:473)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeIntoFloatBuffer(TensorFlowInferenceInterface.java:320)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeFloat(TensorFlowInferenceInterface.java:275)\r\n                                                                       at org.tensorflow.demo.StylizeActivity.stylizeImage(StylizeActivity.java:591)\r\n                                                                       at org.tensorflow.demo.StylizeActivity.access$1400(StylizeActivity.java:66)\r\n                                                                       at org.tensorflow.demo.StylizeActivity$3.run(StylizeActivity.java:543)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:739)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:135)\r\n                                                                       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n03-22 11:01:13.480 9698-9698/org.tensorflow.demo I/RequestQueue: Repeating capture request cancelled.\r\n03-22 11:01:13.640 9698-9715/org.tensorflow.demo E/BufferQueueProducer: [unnamed-9698-2] cancelBuffer: BufferQueue has been abandoned\r\n03-22 11:01:13.640 9698-9714/org.tensorflow.demo E/BufferQueueProducer: [unnamed-9698-2] cancelBuffer: BufferQueue has been abandoned\r\n03-22 11:01:13.640 9698-9715/org.tensorflow.demo E/BufferQueueProducer: [unnamed-9698-2] cancelBuffer: BufferQueue has been abandoned\r\n03-22 11:01:13.640 9698-9714/org.tensorflow.demo E/BufferQueueProducer: [unnamed-9698-2] cancelBuffer: BufferQueue has been abandoned\r\n03-22 11:01:13.640 9698-9715/org.tensorflow.demo E/BufferQueueProducer: [unnamed-9698-2] cancelBuffer: BufferQueue has been abandoned\r\n03-22 11:01:13.710 9698-9698/org.tensorflow.demo D/tensorflow: CameraActivity: onPause org.tensorflow.demo.StylizeActivity@35597053\r\n03-22 11:01:19.370 9698-9710/org.tensorflow.demo W/MessageQueue: Handler (android.os.Handler) {eaa714e} sending message to a Handler on a dead thread\r\n                                                                 java.lang.IllegalStateException: Handler (android.os.Handler) {eaa714e} sending message to a Handler on a dead thread\r\n                                                                     at android.os.MessageQueue.enqueueMessage(MessageQueue.java:325)\r\n                                                                     at android.os.Handler.enqueueMessage(Handler.java:631)\r\n                                                                     at android.os.Handler.sendMessageAtFrontOfQueue(Handler.java:623)\r\n                                                                     at android.hardware.camera2.legacy.RequestThreadManager.quit(RequestThreadManager.java:941)\r\n                                                                     at android.hardware.camera2.legacy.LegacyCameraDevice.close(LegacyCameraDevice.java:444)\r\n                                                                     at android.hardware.camera2.legacy.LegacyCameraDevice.finalize(LegacyCameraDevice.java:468)\r\n                                                                     at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:190)\r\n                                                                     at java.lang.Daemons$FinalizerDaemon.run(Daemons.java:173)\r\n                                                                     at java.lang.Thread.run(Thread.java:818)\r\n```", "I would like to emphasize that this issue does not always happen.  Sometimes stylization works for several frames and then crash due to this issue.", "It's probably giving back an unexpected buffer format:\r\n`03-22 11:01:12.200 9698-9717/org.tensorflow.demo D/ImageReader_JNI: ImageReader_imageSetup: Overriding buffer format YUV_420_888 to 32315659.` 32315659 maps to NV12.\r\n\r\nWhat is the `android.info.supportedHardwareLevel` on your device? Some devices don't fully support the camera2 api, unfortunately, and emulate it problematically internally.\r\n\r\nIf you press the volume keys you'll turn on debug mode, which will render the image being processed. Might be helpful to see what that looks like in each of the demos.", "It is \"2\", which correspond to INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY.  So does it mean the issue cannot be solved?", "If it cannot be solved I think it would be better to show a warning on the demo app for those phones.", "If it is suitable I can contribute code or just make a test.", "The best thing to do would probably be to interact with the camera via the original android.hardware.Camera if the supportedHardwareLevel or Android API level is too low.\r\n\r\nIf you or someone else would like to contribute that it would be very much appreciated. This might also resolve #7464.", "An easier workaround would be if INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY is detected, just use the Y (luminance) plane. It can be mapped directly into RGB grayscale values. Detection quality might suffer a small amount (so a toast/log message would be warranted), but at least it wouldn't crash.", "@BrianOn99 What is your device's API level? I'm wondering if maybe it might just be a good idea to use android.hardware.Camera on devices < API 23. There is an example of doing that [here](https://github.com/hamidb/tensorflow/blob/api20/tensorflow/examples/android/src/org/tensorflow/demo/CameraConnectionFragment.java).", "@BrianOn99 Another idea from the other issue: can you try hardcoding the size to 1920x1080? It's a few more pixels to convert YUV->RGB than 1468x1200, but it may behave better because it's a more popular video size and so would have had more testing by Samsung.", "Thanks. I will try it later today.", "Do you mean changing the previewSize in CameraConnectionFragment?", "Yes, exactly.\r\n\r\n`previewSize = new Size(1920, 1080);` should work.", "Nope. I applied the following:\r\n``` diff\r\n-        previewSize =\r\n-            chooseOptimalSize(map.getOutputSizes(SurfaceTexture.class),\r\n-                inputSize, inputSize, largest);\r\n+        previewSize = new Size(1920, 1080);\r\n```\r\nAnd then got this log:\r\n> Surface with size (w=1920, h=1080) and format 0x23 is not valid, size not in valid set: [1440x1080, 1280x720, 1056x864, 960x720, 720x480, 640x480, 320x240, 176x144]\r\n\r\nAnd then get a Toast of \"Failed\"\r\nChanging to  new Size(1920, 1080) will create the Exception mentioned above.\r\nDid I miss anything?", "Ok, that's strange. It's logged as a valid size.\r\n\r\nWhat about 1280x720? It'll have to upscale at the highest resolutions, but it should look ok.", "> Changing to new Size(1920, 1080) will create the Exception mentioned above.\r\n\r\nSorry, actually I mean new Size(1440, 1080).  No matter it is 1440 or 1920 it will not work.", "Change to (1280x720) still crash.  Also for (320x240), (640x480)\r\n\r\n> 03-24 17:24:53.354 10536-10549/org.tensorflow.demo E/BufferQueueProducer: [unnamed-10536-2] dequeueBuffer: min undequeued buffer count (2) exceeded (dequeued=10 undequeued=1)\r\n03-24 17:24:53.434 10536-10578/org.tensorflow.demo D/ImageReader_JNI: ImageReader_imageSetup: Overriding buffer format YUV_420_888 to 32315659.\r\n03-24 17:24:53.434 10536-10578/org.tensorflow.demo I/tensorflow: StylizeActivity: Initializing at size preview size 640x480, stylize size 256\r\n03-24 17:24:53.434 10536-10578/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 307200\r\n03-24 17:24:53.434 10536-10578/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 76800\r\n03-24 17:24:53.444 10536-10578/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 76800\r\n03-24 17:24:53.904 10536-10536/org.tensorflow.demo D/ViewRootImpl: ViewPostImeInputStage ACTION_DOWN\r\n03-24 17:24:54.435 10536-10577/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[input, style_num], outputs:[transformer/expand/conv3/conv/Sigmoid]", "Ok, so 1920x1080 produces the inference error, while 1440x1080 complains about invalid size? That makes more sense.\r\n\r\nThree possible options here when legacy mode is detected:\r\n\r\n1. Only use the luminance plane to create the image. It would be something like:\r\n```\r\nbyte[] inputBuffer = // from preview frame plane 0\r\nint[] bitmapBuffer = new int[frameHeight * frameWidth];\r\nfor (int y = 0; y < frameHeight; ++y) {\r\n  for (int x = 0; x < frameWidth; ++x) {\r\n    int pixelValue = inputBuffer[y * frameWidth + x];\r\n    bitmapBuffer[y * frameWidth + x] = Color.ARGB(255, value, value, value);\r\n  }\r\n}\r\n```\r\n\r\nThen bitmapBuffer would be used to initialize the RGB bitmap before it gets resized.\r\n\r\n\r\n2. Use the android.hardware.Camera API rather than Camera2 and see if you have better luck. You could try updating the implementation [here](https://github.com/hamidb/tensorflow/blob/api20/tensorflow/examples/android/src/org/tensorflow/demo/CameraConnectionFragment.java) to work with the current demo code.\r\n\r\n\r\n3. Figure out the correct conversion for whatever random color format your phone tries to use, but that would mean finding out programmatically what that is.\r\n\r\n\r\nI'd suggest 1 or 2, which we would gladly welcome contributions for. 3 seems a bit too special-cased for this demo code, but if you just want to get it working for yourself is an option.\r\n\r\n\r\n\r\n", "As mentioned in stackoverflow here http://stackoverflow.com/questions/31350451/using-camera2-api-with-imagereader, Samsung really has terrible Camera2 API support.  I am also having a \"mirror image\" issue.  So approach 1 will not be a good solution.  I am working on approach 2 now.", "I've got it working.  Will make a PR after more testing.", "I have another unrelated question about \"TF Stylize\", but I cannot find another place to ask for.  The problem is about generation of the model.  Trying to reproduce the `stylize_quantized.pb` file, I modified the [magenta project](https://github.com/tensorflow/magenta), to get the graphDef:\r\n``` diff\r\n--- magenta/magenta/models/image_stylization/image_stylization_transform.py     2017-03-24 19:09:20.000000000 +0800\r\n+++ mag/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py     2017-03-28 16:14:03.000000000 +0800\r\n@@ -103,18 +103,20 @@\r\n def _multiple_styles(input_image, which_styles, output_dir):\r\n   \"\"\"Stylizes image into a linear combination of styles and writes to disk.\"\"\"\r\n   with tf.Graph().as_default(), tf.Session() as sess:\r\n-    mixture = _style_mixture(which_styles, FLAGS.num_styles)\r\n+    input_placeholder = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"input\")\r\n+    mixture = tf.placeholder(tf.float32, shape=[32], name=\"style_num\")\r\n     stylized_images = model.transform(\r\n-        input_image,\r\n+        input_placeholder,\r\n         normalizer_fn=ops.weighted_instance_norm,\r\n         normalizer_params={\r\n-            'weights': tf.constant(mixture),\r\n+            'weights': mixture,\r\n             'num_categories': FLAGS.num_styles,\r\n             'center': True,\r\n             'scale': True})\r\n+    tf.train.write_graph(sess.graph_def, \"/tmp\", \"magenta_mul_style.pb\", True)\r\n     _load_checkpoint(sess, FLAGS.checkpoint)\r\n\r\n-    stylized_image = stylized_images.eval()\r\n+    stylized_image = stylized_images.eval(feed_dict={input_placeholder: input_image, mixture: _style_mixture(which_styles, FLAGS.num_styles)})\r\n     image_utils.save_np_image(\r\n```\r\n``` diff\r\n--- magenta/magenta/models/image_stylization/model.py   2017-03-24 19:09:20.000000000 +0800\r\n+++ mag/lib/python2.7/site-packages/magenta/models/image_stylization/model.py   2017-03-24 19:10:56.000000000 +0800\r\n@@ -128,7 +128,10 @@\r\n   if kernel_size % 2 == 0:\r\n     raise ValueError('kernel_size is expected to be odd.')\r\n   with tf.variable_scope(scope):\r\n-    _, height, width, _ = [s.value for s in input_.get_shape()]\r\n+    shape = tf.shape(input_)\r\n+    height = shape[1]\r\n+    width = shape[2]\r\n+    #_, height, width, _ = [s.value for s in input_.get_shape()]\r\n     upsampled_input = tf.image.resize_nearest_neighbor(\r\n```\r\n\r\nwhere `shape=[32]` is the number of styles in the officially provided model `multistyle-pastiche-generator-varied.ckpt`.  The input/output node name are the same as those of android sample.  Then I freeze the graph by\r\n\r\n``` sh\r\nbazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/tmp/magenta_mul_style.pb --input_checkpoint=$HOME/repos/magenta/multistyle-pastiche-generator-varied.ckpt --output_graph=/tmp/frozen_graph.pb --output_node_names=transformer/expand/conv3/conv/Sigmoid\r\n```\r\n\r\nRunning the freezed graph is fine on python interface.  However, plugging it into TF Stylize app , and expanding the `STYLE_NODE` from 26 to 32:\r\n``` diff\r\n@@ -636,7 +637,9 @@ public class StylizeActivity extends CameraActivity implements OnImageAvailableL\r\n     // Copy the input data into TensorFlow.\r\n     inferenceInterface.feed(\r\n         INPUT_NODE, floatValues, 1, bitmap.getWidth(), bitmap.getHeight(), 3);\r\n-    inferenceInterface.feed(STYLE_NODE, styleVals, NUM_STYLES);\r\n+    final float[] styleVals32 = new float[32];\r\n+    System.arraycopy(styleVals, 0, styleVals32, 0, NUM_STYLES);\r\n+    inferenceInterface.feed(STYLE_NODE, styleVals32, 32);\r\n```\r\n\r\nThe output from inference is all `NaN`.  May I know if any of the steps is wrong?  Or if some additional steps is required, such as quantization?  I think documenting these step could be beneficial to other users.  Thanks in advance!", "@keveman Any ideas here?", "@andrewharp Thanks for the help from tensorflowers.  I think I have isolated the problem.  The root of the `NaN` comes from the models.  For example inspecting the magenta official pretrained `multistyle-pastiche-generator-varied.ckpt` from [here](http://download.magenta.tensorflow.org/models/multistyle-pastiche-generator-varied.ckpt) by inspect_checkpoint:\r\n\r\n```\r\nbazel run tensorflow/python/tools:inspect_checkpoint -- --tensor_name=transformer/contract/conv1/weights --file_name=/Users/brianchiu/repos/magenta/multistyle-pastiche-generator-varied.ckpt | less\r\n```\r\nThen you will see:\r\n> tensor_name:  transformer/contract/conv1/weights\r\n> [[[[  2.50682741e-01  -5.05237103e-01  -1.81590185e-01 ...,\r\n>     -1.78870350e-01  -2.17410363e-02              nan]\r\n>   [  7.23770410e-02  -2.00065762e-01  -3.67106795e-02 ...,\r\n>      1.28681719e-01  -1.13809042e-01              nan]\r\n>   [ -3.85547698e-01   3.57045144e-01   2.51499917e-02 ...,\r\n>     -1.22621819e-01  -1.01349823e-01              nan]]\r\n>  [ I skipped other output here... ]\r\n\r\nPlease notice the `nan`s.\r\n\r\nIn the magenta model this weight will be fed to `transformer/contract/conv1/convolution`, then instance normalization, and then to a relu `transformer/contract/conv1/Relu`.\r\n\r\nIn a python shell, the output of relu looks like this:\r\n```\r\nprint(relu_out.shape, relu_out[0][0][0], sep=\"\\n\")\r\n\r\n(1, 256, 256, 32)\r\n[ 0.64510179  0.          0.          0.          0.          0.\r\n  0.09357953  0.85106254  0.          0.          0.          0.6241231\r\n  0.77822381  0.          0.          0.          0.          0.          0.\r\n  0.          0.          0.          1.0667696   0.61502713  0.\r\n  0.33891544  0.          1.0223285   0.04408208  0.09238994  0.46202463\r\n  0.        ]\r\n```\r\n\r\nHowever, using the same image in android, the output of the relu is (only copied the first 32)\r\n```\r\n[0.51562506, 0.0, 0.0, 0.0, NaN, 0.0,\r\n0.03912145, 0.8153123, NaN, NaN, 0.0, 0.6545086,\r\n1.4677725, 0.0, 0.0, 0.0, 0.0, NaN, 0.0,\r\nNaN, NaN, 0.0, 0.0, 0.62697417, 0.6989541,\r\n0.068830535, NaN, 0.73944664, 0.0, 0.0, 0.746428, NaN]\r\n```\r\n\r\nThe activations are different slightly probably due to different way to decode image.  The problem is in python interface the `nan` in weights from `transformer/contract/conv1/weights` does not propagate to the relu activation, but in android it does.\r\n\r\nMay I know if it is expected to have `nan` in a checkpoint?  And why there is different behavior in android and in a PC with python interface?", "@BrianOn99 Talked to @keveman and he can correct me if I'm wrong, but it sounds like there is a problem with that checkpoint. Retraining may be the easiest solution, checking for NaNs along the way.", "Thanks @keveman.  So it seems it is a problem of magenta rather than Tensorflow?  It is interesting to know style transfer still work when 1/4 of the weight for a layer is effectively zero.", "So it is just lucky that the model used in android demo does not have nan.  @keveman May I know any other technique to generate that model, after freezing from magenta? for example which mode of quantization?", "Over in [this issue](https://github.com/googlecodelabs/tensorflow-style-transfer-android/issues/4), @amolgupta reports a reproducible failure on a Nexus 5X. I saw something similar on one of the Pixels at I/O where we ran this app in codelab form (running O DP), but I'm not sure I can recover that specific device (I'll try though).", "This happens to some graphs generated with the [Graph Transform Tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms) too.\r\n\r\nUsing the commands detailed in https://github.com/tensorflow/models/issues/1609, I was able to benchmark the graph transformed from frozen_inference_graph.pb of one of the the official [object detection models](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md).\r\n\r\nAfter changing `num_classes` to 90 and `score_threshold` to 0.1 or bigger values in [ssd_mobilenet_v1_pets.config](https://github.com/tensorflow/models/blob/master/object_detection/samples/configs/ssd_mobilenet_v1_pets.config), I exported, transformed and benchmarked new inference graphs from the checkpoints with the following commands.\r\n```shell\r\npython object_detection/export_inference_graph.py \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path ssd_mobilenet_v1_pets.config \\\r\n    --checkpoint_path model.ckpt \\\r\n    --inference_graph_path output_inference_graph.pb\r\n\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=output_inference_graph.score_threshold_0.1.pb \\\r\n--out_graph=transformed_inference_graph.score_threshold_0.1.pb \\\r\n--inputs='image_tensor' \\\r\n--outputs='detection_boxes,detection_scores,detection_classes,num_detections' \\\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float)\r\n  remove_nodes(op=CheckNumerics)\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  fuse_resize_pad_and_conv\r\n  fuse_pad_and_conv\r\n  fuse_resize_and_conv\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n\r\nadb shell /data/local/tmp/benchmark_model \\\r\n --graph=/data/local/tmp/transformed_inference_graph.score_threshold_0.1.pb \\\r\n --input_layer=image_tensor:0 \\\r\n --input_layer_shape=1,224,224,3 \\\r\n --input_layer_type=uint8 \\\r\n --output_layer=detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0 \\\r\n > transformed_inference_graph.score_threshold_0.1.benchmark\r\n```\r\nThe benchmark failed with the logs shown below.\r\n```\r\nnative : benchmark_model.cc:382 Graph: [/data/local/tmp/transformed_inference_graph.score_threshold_0.3.pb]\r\n\r\nnative : benchmark_model.cc:383 Input layers: [image_tensor:0]\r\n\r\nnative : benchmark_model.cc:384 Input shapes: [1,224,224,3]\r\n\r\nnative : benchmark_model.cc:385 Input types: [uint8]\r\n\r\nnative : benchmark_model.cc:386 Output layers: [detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0]\r\n\r\nnative : benchmark_model.cc:387 Num runs: [50]\r\n\r\nnative : benchmark_model.cc:388 Inter-run delay (seconds): [-1.0]\r\n\r\nnative : benchmark_model.cc:389 Num threads: [-1]\r\n\r\nnative : benchmark_model.cc:390 Benchmark name: []\r\n\r\nnative : benchmark_model.cc:391 Output prefix: []\r\n\r\nnative : benchmark_model.cc:392 Show sizes: [0]\r\n\r\nnative : benchmark_model.cc:393 Warmup runs: [2]\r\n\r\nnative : benchmark_model.cc:53 Loading TensorFlow.\r\n\r\nnative : benchmark_model.cc:60 Got config, 0 devices\r\n\r\ncan't determine number of CPU cores: assuming 4\r\n\r\ncan't determine number of CPU cores: assuming 4\r\n\r\nnative : benchmark_model.cc:258 Running benchmark for 2 iterations without detailed stat logging:\r\n\r\nnative : benchmark_model.cc:234 Error during inference: Invalid argument: input_max_range must be larger than input_min_range.\r\n\r\n\t [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/quantize = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm, FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/min, FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/max)]]\r\n\r\nnative : benchmark_model.cc:269 Failed on run 0\r\n\r\nnative : benchmark_model.cc:452 Timing failed with Invalid argument: input_max_range must be larger than input_min_range.\r\n\r\n\t [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/quantize = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm, FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/min, FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6_eightbit/FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm/max)]]\r\n```\r\n@petewarden please have a look at the possible causes.", "There is no problem to benchmark the transformed graphs after removing `quantize_nodes` from the `transforms` parameter.", "@futurely , have u addressed the problem with quantize_nodes option?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@BrianOn99 \r\nI have the same problem as you.But when I replace the camera captured bitmap with a predefined one,I couldn't get a stylized picture , just a grey one.I wanted to ask you how you handled the designated bitmap.", "Nagging Assignee @andrewharp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrewharp: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closed because I don't care about it anymore and this issue has been inactive."]}, {"number": 8549, "title": "How to  use MMI in seq2seq model?", "body": "", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 8548, "title": "Modified mnist.py to use random seeds.", "body": "Modified mnist.py to use random seeds to allow for repeatable behavior during development and testing.  This may be especially helpful in the MNIST tutorials.  Both graph level seeds via the tf.set_random_seed call like:  tf.set_random_seed(1238)\r\nand op level via something like:\r\nmnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True, seed=12345)\r\nare allowed, to be consistent with the overall Tensorflow random seed handling.", "comments": ["Can one of the admins verify this patch?", "Geoffrey can you check the random seed logic in this?", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "@caisq I think the error is unrelated. Feel free to merge."]}, {"number": 8547, "title": "Incorrect hessian of a quadratic function", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/5876\r\nhttps://github.com/tensorflow/tensorflow/issues/7403\r\n\r\n### Environment info\r\nOperating System:\r\nmac 10.12.3\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\nNo, it is a CPU version.\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n1.0.1\r\n```\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nHi,\r\n\r\nI am testing hessian computation:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport matplotlib as plt\r\nimport numpy as np\r\nimport math\r\n```\r\n\r\n```\r\ndef getHessian(dim):\r\n    g = tf.Graph()\r\n    with g.as_default():\r\n        # First create placeholders for inputs: A, b, and c.\r\n        A = tf.placeholder(tf.float32, shape=[dim, dim])\r\n        b = tf.placeholder(tf.float32, shape=[dim, 1])\r\n        c = tf.placeholder(tf.float32, shape=[1])\r\n        # Define our variable\r\n        x = tf.Variable(np.float32(np.repeat(1,dim).reshape(dim,1)))\r\n        # Construct the computational graph for quadratic function: f(x) = 1/2 * x^t A x + b^t x + c\r\n        fx = 0.5 * tf.matmul(tf.matmul(tf.transpose(x), A), x) + tf.matmul(tf.transpose(b), x) + c\r\n        \r\n        # Get gradients of fx with repect to x\r\n        dfx = tf.gradients(fx, x)[0]\r\n        # Compute hessian\r\n        for i in range(dim):\r\n            dfx_i = tf.slice(dfx, begin=[i,0] , size=[1,1])\r\n            ddfx_i = tf.gradients(dfx_i, x)[0] # whenever we use tf.gradients, make sure you get the actual tensors by putting [0] at the end\r\n            if i == 0: hess = [ ddfx_i ]\r\n            else: hess.append(ddfx_i) \r\n\r\n        hess = tf.stack(hess,axis=0)\r\n        hess = tf.squeeze(hess)\r\n        init_op = tf.initialize_all_variables()\r\n    \r\n        with tf.Session() as sess:\r\n            sess.run(init_op)\r\n            # We need to feed actual values into the computational graph that we created above. \r\n            feed_dict = {A: np.float32(np.vstack([[1,2,3],[4,5,6],[7,8,9]])), \r\n                         b: np.float32(np.repeat(3,dim).reshape(dim,1)) , c: [1]}\r\n            # sess.run() executes the graph. Here, \"hess\" will be calculated with the values in \"feed_dict\".\r\n            print(sess.run(hess, feed_dict))\r\n\r\n\r\n```\r\n\r\n```\r\ngetHessian(3)\r\n```\r\n\r\n```\r\nWARNING:tensorflow:From <ipython-input-2-ed7e9735185e>:31: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\n[[ 1.  3.  5.]\r\n [ 3.  5.  7.]\r\n [ 5.  7.  9.]]\r\n```\r\n\r\nThis is obviously wrong.\r\n\r\n### What other attempted solutions have you tried?\r\nI tried `np.float64`, it didn't help. \r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Can you isolate a bit further where the mistake is happening? There's a lot of code, is this a misunderstanding of how TensorFlow works, or a specific operation producing result that contradicts its documentation?\r\n\r\nHere's a slightly simple example of computing Hessian which produces values that make sense:\r\nhttps://groups.google.com/a/tensorflow.org/d/msg/discuss/Xb_lwMIsNPc/sLk7aNcZCQAJ", "OK. I was not sure that Hessian works correctly, so that code in the min code you need to compute the hessian of a quadratic function:\r\n$ f(x) =  1/2* x^T A x + b^T x + c$\r\nThe hessian of this function is A. In the code, you see:\r\n```\r\n            feed_dict = {A: np.float32(np.vstack([[1,2,3],[4,5,6],[7,8,9]])), \r\n                         b: np.float32(np.repeat(3,dim).reshape(dim,1)) , c: [1]}\r\n```\r\n\r\nand the function is defined here:\r\n```\r\n        fx = 0.5 * tf.matmul(tf.matmul(tf.transpose(x), A), x) + tf.matmul(tf.transpose(b), x) + c\r\n\r\n```\r\n\r\nSo the result should be:\r\n```\r\n[[ 1.  2.  3.]\r\n [ 4.  5.  6.]\r\n [ 7.  8.  9.]]\r\n```\r\n\r\nI don't think this is misunderstanding of how TF work (it is possible) because the code is simple. Here is how the hessian is computed:\r\n\r\n```\r\n        # Get gradients of fx with repect to x\r\n        dfx = tf.gradients(fx, x)[0]\r\n        # Compute hessian\r\n        for i in range(dim):\r\n            dfx_i = tf.slice(dfx, begin=[i,0] , size=[1,1])\r\n            ddfx_i = tf.gradients(dfx_i, x)[0] \r\n\r\n            if i == 0: hess = [ ddfx_i ]\r\n            else: hess.append(ddfx_i) \r\n\r\n        # make a matrix from the list\r\n        hess = tf.stack(hess,axis=0)\r\n        hess = tf.squeeze(hess)\r\n```\r\n\r\nam I missing something?\r\n\r\n ", "Note that you are using `tf.gradients`, so you are saying this is a bug in gradients, right? The code is complicated enough that I can't immediately tell if it's a bug in gradients or your code, can you narrow it down to simpler example?", "@yaroslavvb I was wrong. It is computed correctly. Here is a simpler example showing that is computed correctly:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport matplotlib as plt\r\nimport numpy as np\r\nimport math\r\n\r\ndim = 3\r\ntrueA     = np.array([[1,2,3],\r\n                     [4,5,6],\r\n                     [7,8,9]])\r\n\r\ntrueHess = 0.5*trueA + 0.5*trueA.T\r\n\r\ntrueb = np.random.rand(3,1)\r\n\r\nprint \"True Hess : \", trueHess\r\n\r\n\r\n# define variables\r\nA = tf.placeholder(tf.float32, shape=[dim, dim])\r\nb = tf.placeholder(tf.float32, shape=[dim, 1])\r\nc = tf.placeholder(tf.float32, shape=[1])\r\nx = tf.Variable(np.float32(np.repeat(1,dim).reshape(dim,1)))\r\n\r\n# define function: 0.5 x^T A x + b^T x + c\r\nfx = 0.5 * tf.matmul(tf.matmul(tf.transpose(x), A), x) + tf.matmul(tf.transpose(b), x) + c\r\n\r\n# Get gradients of fx with repect to x\r\ndf_dx = tf.gradients(fx, x)[0]\r\n\r\n# get the second gradient of the first entry with respect to x\r\ndf_dx1 = tf.slice(df_dx, begin=[0,0] , size=[1,1])\r\nddfx_ddx1 = tf.gradients(df_dx1, x)[0]\r\n\r\n\r\n#------------------------\r\n# print the results\r\ninit_op = tf.initialize_all_variables()\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n    # We need to feed actual values into the computational graph that we created above. \r\n    feed_dict = {A: trueA, \r\n                 b: trueb , \r\n                 c: [1]}\r\n    # sess.run() executes the graph. Here, \"hess\" will be calculated with the values in \"feed_dict\".\r\n    print(sess.run(ddfx_ddx1, feed_dict))\r\n\r\n\r\n```\r\n\r\nPlease close this issue."]}, {"number": 8546, "title": "Fix several minor issues with C++ custom ops (`adding_an_op.md`) documentation", "body": "This fix tries to address several issues related to C++ custom ops (`adding_an_op.md`) documentation:\r\n1. The `tf.load_op_library('zero_out.so')` should use full path or relative path (`./`)\r\n   This issue has been raised in #4727 as well.\r\n2. The mentioning of `zero_out_op_1.py` and `tf.load_op_library('zero_out_op_kernel_1.so')`\r\n   is really misleading. While `zero_out_op_1.py` is located in  `tensorflow/examples/adding_an_op/`,\r\n   the documentation (`adding_an_op.md`) does not  really use `zero_out_op_1.py`.\r\n   It is better to use the `zero_out.cc` that is presented in the doc instead to avoid confusion.\r\n\r\nThis fix changes `tf.load_op_library('zero_out.so')` to `tf.load_op_library('./zero_out.so')`\r\nand updates a few places so that following the documentation could have the expected result.\r\n\r\nThis fix fixes #4727.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 8545, "title": "R0.12", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 8544, "title": "Adds renormalization #7476", "body": "Adds an additional parameter called renorm to add a stop gradient on gamma, beta parameters during the training phase. This has been discussed here https://github.com/tensorflow/tensorflow/issues/7476", "comments": ["Can one of the admins verify this patch?", "Any updates ?", "Sergey Ioffe mentions the following: \r\n\r\n*\"There are multiple issues with that git change. It keeps maintaining the moving variance instead of standard deviation; will not work early in training due to the lack of debiasing; is inefficient because they do BN first and then correct; and finally the computation is wrong because they apply gamma and beta before the correction, but they should be applied after.\"*\r\n\r\nSergey is working on a correct implementation of batch renormalization and will be pushing it soon. We will not be moving forward with this PR. Sorry about that."]}, {"number": 8543, "title": "Fix some comments in the run() method of the BaseSession class.", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for the fixes, @palimarrao "]}]