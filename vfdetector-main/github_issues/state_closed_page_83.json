[{"number": 52685, "title": "libdevice not found at ./libdevice.10.bc", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10 Enterprise\r\n- Issue occurs on a desktop\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:  'GIT_VERSION': 'v2.6.0-rc2-32-g919f693420e'\r\n- Python version: 3.8.12\r\n- Installed using conda:\r\n- CUDA/cuDNN version: V11.5/8.2\r\n- GPU model and memory: NVIDIA GeForce RTX 3060 Ti 8Gb\r\n\r\nJust installed TensorFlow and TensorFlow probability to go through [Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/). Everything runs fine if I disable GPU. When I enable GPU use I'm getting the following error:\r\n\r\n```\r\nInternalError:  libdevice not found at ./libdevice.10.bc\r\n\t [[{{node cluster_0_1/xla_compile}}]] [Op:__inference_lbeta_369]\r\n\r\nFunction call stack:\r\nlbeta\r\n```\r\n\r\nI have libdevice.10.bc file in the locations defined both in Windows PATH and via conda develop PATH definition. I can't figure out where exactly TensorFlow is looking for this file, as the traceback is not helpful. I found [the solution](https://discuss.tensorflow.org/t/libdevice-not-found-why-is-it-not-found-in-the-searched-path/3419) by Julian Moore, but it did not help in my case.", "comments": ["@kuvychko ,\r\nEvery TensorFlow release is compatible with a certain version, for more information please take a look at the tested build [configurations](https://www.tensorflow.org/install/source_windows#gpu).In this case, can you please try installing TensorFlow v2.6 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!", "Understood - thank you! It looks like I missed step#3 in [cuDNN install procedure](https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installwindows). It is working now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52685\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52685\">No</a>\n", "@kuvychko ,\r\nGlad the suggestion worked to resolve the issue.Thanks!"]}, {"number": 52684, "title": "Update RELEASE.md", "body": "@mihaimaruseac looks like the tensorflow jenkins release script is broken example PR # https://github.com/tensorflow/tensorflow/pull/52116", "comments": ["Thank you @mihaimaruseac "]}, {"number": 52683, "title": "[TF:TRT] Better CombinedNMS Support through EfficientNMS TRT Plugin", "body": "This replaces the CombinedNMS TFTRT converter with one that uses the EfficientNMS TensorRT plugin, instead of the older BatchedNMS implementation.\r\n\r\nThe converter is #if-gated through a TRT version checker *OR* a build time flag override:\r\n- If the user meets the minimum TRT version requirement, then nothing else is needed, everything will work as expected. \r\n- Otherwise, users on older TRT versions that require this functionality can build the corresponding TensorRT OSS version locally (must use a specific branch for TRT 7.x compatibility, for example), and re-build TFTRT with the appropriate build define flag. This would allow for a temporary solution while the OSS third party dependency is finalized.\r\n\r\nBehavior changes for the new method compared with the previous CombinedNMS converter:\r\n- Supports dynamic shape in all tensor dimensions.\r\n- Does not require a TopK override.\r\n- Padding elements are 0's as is done in the TF op, not -1 as the previous plugin.\r\n- Depending on op configuration, the new EfficientNMS plugin can be considerably faster at inference time (especially when score_threshold >= 0.01).\r\n- Unit tests have been updated to reflect the new behaviors.\r\n- Implicit batch mode support has been dropped for this operation due to incompatibility with the new plugin (implicit batch mode is on its way out anyway).", "comments": ["@bixia1 : Could you take a look at this PR please? \r\nThe PR is still in draft state while some details are finalized, along with further cross-version testing. We can discuss further offline. \r\nThank you.", "@bixia1 I added the fallback to the old CombinedNMS converter as we discussed previously. \r\nI'm leaving it in just in case we still find a way to merge this before the third_party dependency approval goes through, so TFTRT users can start using this sooner if needed.\r\nAlternatively, if the third_party dependency is approved sooner, we can remove the fallback, and relax the #if-gate constraints."]}, {"number": 52682, "title": "[oneDNN] Bug-fix: add CPU device explicitly in the test.", "body": "When TF is build with both cuda and oneDNN, CPU optimization should take place if device placement places CPU device. This PR updates grappler remapper python test with explicitly adding a CPU device.\r\n\r\nFollowing is an example test command\r\n`bazel test --config=cuda --test_env TF_ENABLE_ONEDNN_OPTS=1 -c opt //tensorflow/python/grappler:remapper_test_gpu`", "comments": []}, {"number": 52681, "title": "In Tensorflow 2.6, tf.keras.backend.gradients() return None", "body": "I try to customize a loss functionm, But when I run the following code:\r\n\r\n```\r\npressure_grad_x = tf.keras.backend.gradients(out2, cur_x_input)[0]\r\npressure_grad_y = tf.keras.backend.gradients(out2, cur_y_input)[0]\r\npressure_grad_z = tf.keras.backend.gradients(out2, cur_z_input)[0]\r\npressure_grad = tf.convert_to_tensor([pressure_grad_x, pressure_grad_y, pressure_grad_z])\r\n```\r\n\r\nAn error will be reported(The above code is in the custom function.)\uff1a\r\n\r\n```\r\n<ipython-input-42-23232050871c>:34 call  *\r\n    pressure_grad = tf.convert_to_tensor([pressure_grad_x, pressure_grad_y, pressure_grad_z])\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\r\n    return target(*args, **kwargs)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py:1431 convert_to_tensor_v2_with_dispatch\r\n    value, dtype=dtype, dtype_hint=dtype_hint, name=name)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py:1441 convert_to_tensor_v2\r\n    as_ref=False)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\r\n    return func(*args, **kwargs)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py:1566 convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346 _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\constant_op.py:272 constant\r\n    allow_broadcast=True)\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\constant_op.py:290 _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\nC:\\Users\\dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:553 make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\n\r\nTypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, None, None]. Consider casting elements to a supported type.\r\n```\r\nWhen I tried to solve it, I found that the value of pressure_grad_x (or pressure_grad_y, pressure_grad_z) is None.\r\n\r\nThe model i used if LSTM model and take the custom loss function as the last layer of the model.\r\n\r\nout2 is the outputs of LSTM model. cur_x_input, cur_y_input, cur_z_input is the inputs of LSTM model.The version of Tensorflow is 2.6.0.\r\n\r\nI have no way to solve this problem. I hope someone can help me solve this problem.", "comments": ["@Liozizy Could you please close either of these issues #52647 and #52681 as they both are duplicates and edit the issue and properly fill out the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!", "> @Liozizy Could you please close either of these issues #52647 and #52681 as they both are duplicates and edit the issue and properly fill out the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n\r\nThank you for your reply.\r\nI've closed another same issue.\r\n\r\nI think the reason for this problem is the value of the tf.keras.backend.gradients(out2, cur_x_input)[0] (or tf.keras.backend.gradients(out2, cur_y_input)[0], tf.keras.backend.gradients(out2, cur_z_input)[0]) is None. \r\nThe shape of out2 is (None, 4), the shape of cur_x_input( cur_y_input, cur_z_input ) is (None,4,1).\r\nCan you give me some other comments?\r\n\r\nAs a novice, I also have some difficulty understanding the following code:\r\n`a_C_unrolled =  tf.reshape(a_C, shape=tf.constant([int(m), int(n_H * n_W), int(n_C)]))`\r\n`a_C_unrolled = tf.reshape(tf.transpose(a_C,perm=[0,3,1,2]),shape=[m,n_H*n_W,n_C])`\r\nCould you give me some explanation?\r\nThank you very much!", "@Liozizy ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52681\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52681\">No</a>\n"]}, {"number": 52680, "title": "Inconsistent results on every run with GPU", "body": "\r\n**System information**\r\n- OS Platform and Distribution: Colab\r\n- TensorFlow version: 2.6.0 GPU\r\n\r\n**Describe the current behavior**\r\nHello, I'm using TensorFlow 2.4.0 with GPU support on my local machine to train a small CNN model. I can get the same training results when I train it on CPU mode if I fixed the random seed, but always get inconsistent results on GPU mode.\r\n\r\n*So I test it on Colab, which has TensorFlow 2.6.0 installed in default, but still got inconsistent results on GPU mode.*\r\n\r\n**Describe the expected behavior**\r\nThe results should be the same.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing): x\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is the test code\r\n[Colab](https://colab.research.google.com/drive/1Xr_p9rsKM0bk3DDt9CL3L-dN7Vvz179Q?usp=sharing)\r\nRun it for many times with GPU enabled, you will get different results on each run.\r\n\r\n**Other info / logs*\r\nI found that only when I use `relu`, `leaky_relu` or `tf.maximum` as the activation function the results change on every run. But if I use `sigmoid`, `tanh`, or other non-relu-like activation functions the results will remain the same.", "comments": ["Hi @sanatmpa1 ! Could you please look at this issue? It is replicating in [TF 2.6](https://colab.sandbox.google.com/gist/mohantym/6f83b66aec780f61d61db06c163d939b/tensorflow-gradient-bug.ipynb#scrollTo=JsOrWiRpRVa6)  and throwing  different error in [TF 2.5 ](https://colab.sandbox.google.com/gist/mohantym/8772c2733579c384a2020db0cee9c4c0/tensorflow-gradient-bug.ipynb#scrollTo=y8U749VTSEkJ)and [nightly.](https://colab.sandbox.google.com/gist/mohantym/249b809b865745e892d35f9a4ff7ab62/tensorflow-gradient-bug.ipynb#scrollTo=JsOrWiRpRVa6) Thanks!", "@Ending2015a,\r\n\r\nCan you try adding this line of code in your program and let us know is the issue still persists? Thanks\r\n\r\n```python\r\nimport os\r\nos.environ['TF_CUDNN_DETERMINISTIC']='1'\r\n```\r\n\r\nAlso can you take a look at this [SO thread](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu) which explains about non determisim when training on GPU.", "@sanatmpa1,\r\nthanks for your reply. \r\n> Can you try adding this line of code in your program and let us know is the issue still persists? Thanks\r\n> \r\n> ```python\r\n> import os\r\n> os.environ['TF_CUDNN_DETERMINISTIC']='1'\r\n> ```\r\nThe issue still exists after adding those lines.\r\n\r\nI know that some OP are not deterministic in TensorFlow. \r\nBut it doesn't make sense the results become fixed after I replace the `relu` with other non-relu activations, e.g. \r\n`sigmoid`: final loss = 15.795916\r\n`tanh`: final loss = 15.851234.\r\nDoes that mean `relu`, `leaky_relu` or `tf.maximum` are non-deterministic OPs?\r\nI also test the eager mode by adding the following line, but still has that issue.\r\n```\r\ntf.config.run_functions_eagerly(True)\r\n```\r\n\r\nBesides, the [same code in PyTorch](https://colab.research.google.com/drive/17YWEc3T_qrDA_0JaCVJkWefh80z7WlnB?usp=sharing) has no such issue.\r\n\r\n\r\n\r\n", "I'm able to see the same result in multiple runs using Tensorflow 2.7, please find the Gist [here](https://colab.research.google.com/gist/sachinprasadhs/5751a9c525624aa9132c3975d9dfba05/tensorflow-gradient-bug.ipynb). Thanks!", "@sachinprasadhs,\r\n\r\nNo, the loss is still changing in TF 2.7.\r\nThe `final sampled` is the training data sampled from numpy so it must be fixed.\r\n\r\n![Screenshot from 2021-11-12 15-52-01](https://user-images.githubusercontent.com/18180004/141430348-27da70bb-72b5-41c9-9a30-370455e69e2c.png)\r\n\r\n![Screenshot from 2021-11-12 15-49-32](https://user-images.githubusercontent.com/18180004/141430136-bc9484e6-2831-4dca-9b27-03b8b601e32c.png)\r\n\r\n\r\n", "I see it now, thanks for pointing it out, as you have mentioned that it happens only with certain activation functions, we may have to investigate on that first.\r\nSince, development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!", "@sachinprasadhs, OK, I will post it to keras, thank you.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52680\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52680\">No</a>\n"]}, {"number": 52679, "title": "import tensorflow.experimental.numpy as tnp", "body": "why i cant use \"import tensorflow.experimental.numpy as tnp\" and it shows \"no module\"\r\nbut import tensorflow as tf  and tf.experimental.numpy are good\r\n", "comments": ["@WangHuachen \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. I am able to run`import tensorflow.experimental.numpy as tnp`  successfully on colab using TF v2.6.0, please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/d661791c6613e50e07f85007891e3ac2/untitled482.ipynb) as reference.Could you please close the duplicate ticket  #52677 of the same issue ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52678, "title": "Shapes are incompatible when train pose_classification", "body": "Error \"ValueError: Shapes (16, 1) and (16, 5) are incompatible\" occurs when I'm running \"pose_classification.ipynb\" on custom dataset at this line\r\n```\r\nhistory = model.fit(X_train, y_train,\r\n                        epochs=200,\r\n                        batch_size=16,\r\n                        validation_data=(X_val, y_val),\r\n                        callbacks=[checkpoint, earlystopping])\r\n```\r\n\r\n-------Update---------\r\nIt seems not a bug, the problem should be the dataset and its labeling. I'll close it now.\r\nSorry for inconvenience.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52678\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52678\">No</a>\n"]}, {"number": 52677, "title": "import tensorflow.experimental.numpy as tnp", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @WangHuachen ! closing this issue as a duplicate to issue [#52679](https://github.com/tensorflow/tensorflow/issues/52679) .Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52677\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52677\">No</a>\n"]}, {"number": 52676, "title": "Undefined behaviour in Range", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): all\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): git HEAD\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/0b67dee3f02e2e055230ca6dd6cc7d090af72baa/tensorflow/core/ops/math_ops.cc#L1484 has undefined behaviour when size is greater than std::numeric_limits<int64_t>::max()\r\nThis leads to the unit test RangeTest.testLargeStarts failing on AARCH64 where the g++ implements different behaviour from x86. On x86 the result of the cast is large and -ve, on AARCH64 it is large and +ve. Neither is incorrect as the behaviour of casting into a type that cannot hold the value is undefined.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe code should be written to avoid relying on undefined behaviour of the source.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\nTest the variable 'size' for exceeding the greatest possible value that can be safely cast to int64_t and throw an error if found.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n$ bazel test --flaky_test_attempts=3 --test_output=all --cache_test_results=no --remote_http_cache=\"\"  --remote_cache_proxy=\"\" --noremote_accept_cached --config=nonccl --verbose_failures -- //tensorflow/python/kernel_tests:init_ops_test\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n======================================================================\r\nERROR: testLargeStarts (__main__.RangeTest)\r\nRangeTest.testLargeStarts\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/init_ops_test.py\", line 553, in testLargeStarts\r\n    v = math_ops.range(start=-1e+38, limit=1)\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/util/traceback_utils.py\", line 141, in error_handler\r\n    return fn(*args, **kwargs)\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/util/dispatch.py\", line 1092, in op_dispatch_handler\r\n    return dispatch_target(*args, **kwargs)\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py\", line 2113, in range\r\n    return gen_math_ops._range(start, limit, delta, name=name)\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 7737, in _range\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/kernel_tests/init_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 7131, in raise_from_not_ok_status\r\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[9223372036854775807] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Range]\r\n\r\n", "comments": ["@cfRod @nSircombe ", "@elfringham This issue will be closed once the PR is merged. Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52676\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52676\">No</a>\n"]}, {"number": 52675, "title": "Problem with TF Object Detection API", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9\r\n- GPU model and memory: RTX 2060\r\n\r\n**Problem**\r\nI'm trying to build and train an object detection model (using ssd_resnet50_v1_fpn) configuring a pipeline with paths to train.tfrecord, test.tfrecord and label_map.pbtxt. I get the last files from cvat.org when export the project in the TFRecord format. \r\n\r\n**Info / logs**\r\nI run:\r\n python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v\r\n1_fpn/pipeline.config\r\nand below what I read:\r\n\r\n2021-10-26 10:36:02.910336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)\r\nto use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-10-26 10:36:04.117867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3967 MB memory:\r\n -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI1026 10:36:04.304352 16668 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nINFO:tensorflow:Maybe overwriting train_steps: None\r\nI1026 10:36:04.309246 16668 config_util.py:552] Maybe overwriting train_steps: None\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI1026 10:36:04.309246 16668 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from\r\n_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nW1026 10:36:04.327197 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\model_lib_v2.py:557: StrategyBase.experime\r\nntal_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nINFO:tensorflow:Reading unweighted datasets: ['annotations\\\\Train.tfrecord']\r\nI1026 10:36:04.334176 16668 dataset_builder.py:163] Reading unweighted datasets: ['annotations\\\\Train.tfrecord']\r\nINFO:tensorflow:Reading record datasets for input file: ['annotations\\\\Train.tfrecord']\r\nI1026 10:36:04.646700 16668 dataset_builder.py:80] Reading record datasets for input file: ['annotations\\\\Train.tfrecord']\r\nINFO:tensorflow:Number of filenames to read: 1\r\nI1026 10:36:04.646700 16668 dataset_builder.py:81] Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW1026 10:36:04.648099 16668 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.p\r\nython.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Opti\r\nons.experimental_deterministic`.\r\nW1026 10:36:04.654085 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_\r\ninterleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Opti\r\nons.experimental_deterministic`.\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (fr\r\nom tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW1026 10:36:04.688991 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1\r\n.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.spar\r\nse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nW1026 10:36:10.687601 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sparse_to_dense (fr\r\nom tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sample_distorted_bounding_box (from tensorflow.p\r\nython.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW1026 10:36:13.237039 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sample_distorted_bo\r\nunding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from tensorflow.python.ops.math_o\r\nps) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW1026 10:36:14.707938 16668 deprecation.py:339] From C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from\r\n tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\n2021-10-26 10:36:16.954501: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\nTraceback (most recent call last):\r\n  File \"D:\\programmi\\tensorflow\\workspace\\training_demo\\model_main_tf2.py\", line 115, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\absl\\app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"D:\\programmi\\tensorflow\\workspace\\training_demo\\model_main_tf2.py\", line 106, in main\r\n    model_lib_v2.train_loop(\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 599, in train_loop\r\n    load_fine_tune_checkpoint(\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 394, in load_fine_tune_checkpoint\r\n    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 159, in _ensure_model_is_built\r\n    features, labels = iter(input_dataset).next()\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 689, in next\r\n    return self.__next__()\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 693, in __next__\r\n    return self.get_next()\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 731, in get_next\r\n    self._iterators[i].get_next_as_list_static_shapes(new_name))\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 1951, in get_next_as_list_static_shapes\r\n    return self._format_data_list_with_options(self._iterator.get_next())\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py\", line 573, in get_next\r\n    result.append(self._device_iterators[i].get_next())\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 814, in get_next\r\n    return self._next_internal()\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 744, in _next_internal\r\n    ret = gen_dataset_ops.iterator_get_next(\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2727, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"C:\\Users\\donat\\anaconda3\\envs\\doEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6941, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input is empty.\r\n         [[{{node case/cond/else/_10/case/cond/cond_jpeg/else/_105/case/cond/cond_jpeg/decode_image/DecodeImage}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]] [Op:IteratorGetNext]", "comments": ["@Cadodo97 ,\r\nCan you please refer this [issue](https://github.com/tensorflow/tensorflow/issues/46958) with the similar error.It helps.Thanks!", "@tilakrayal I had already seen there issue, the problem is similar but not the same. In my case I get file.tfrecord from cvat.org instead of code.", "@Cadodo97 ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset or colab gist to reproduce the issue reported here.Thanks!", "I just solve it, when I export the project from cvat.org I didn't able save picture, so in the file.tfrecord there aren't info about pics. Now the script work well. I suggest to upload the pics in cvat.org with jpeg format in order to get the lighter weigth possible.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52675\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52675\">No</a>\n", "@Cadodo97 Hi , Can you please write the steps to fix this issue?\r\nI'm having the same issue. I uploaded images to cvat and after annotating it I exported it as tfrecord \r\nBut when I started training it produce the issue. My images are jpeg format\r\nCan you please explain the steps to fix the issus? Do I have to t images and upload and converre-annotate my images?\r\n\r\nThanks", "When you export the project/task is important that you flag \"Save images\" and you must export in the TFRecord 1.0 format. ", "@Cadodo97 It works, thank you so much."]}, {"number": 52674, "title": "Install error on m1 MBP (Python 3.9)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.6\r\n- TensorFlow installed from (source or binary): Try it but not worked.\r\n- Python version: 3.9.5\r\n- Installed using virtualenv? pip? conda?: conda\r\n- GPU model and memory: M1\r\n\r\nOkay. I was try to installing on my m1 mbp (python 3.9) and i got some error like this..\r\n<pre>\r\n\r\n\r\nInstallation script for pre-release tensorflow_macos 0.1alpha3.  Please visit https://github.com/apple/tensorflow_macos\r\nfor instructions and license information.\r\n\r\nThis script will download tensorflow_macos 0.1alpha3 and needed binary dependencies, then install them into a new\r\nor existing Python 3.8 virtual environment.\r\nContinue [y/N]? y\r\n\r\nDownloading installer.\r\n/var/folders/01/5f5ftlvn2w7c9prxbs4410780000gn/T/tmp.U2PQuGHt ~\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   641  100   641    0     0   8434      0 --:--:-- --:--:-- --:--:--  8434\r\n100  359M  100  359M    0     0  4320k      0  0:01:25  0:01:25 --:--:-- 5176k\r\nExtracting installer.\r\nPath to new or existing virtual environment [default: /Users/bahk_insung/tensorflow_macos_venv/]: /Users/bahk_insung/miniforge3/envs/pycv/tensorflow_mac_venv/\r\n##############################################################\r\n\r\nERROR: Error retrieving python version, or python executable /Users/bahk_insung/miniforge3/envs/pycv/bin/python3 not version 3.8.  Please specify a Python 3.8 executable with the --python option.\r\n\r\n\r\nError running installation script with default options.  Please fix the above errors and proceed by running\r\n\r\n  /var/folders/01/5f5ftlvn2w7c9prxbs4410780000gn/T/tmp.U2PQuGHt/tensorflow_macos/install_venv.sh --prompt\r\n\r\n\r\n</pre>\r\n\r\nI think my conda environment is not fitted for tensorflow. I try it with <a href=\"https://github.com/apple/tensorflow_macos\">this one</a>. plz help me why does it.", "comments": ["Are you following the steps specified here: https://developer.apple.com/metal/tensorflow-plugin/", "@insung3511 Please look at the the code [here](https://github.com/apple/tensorflow_macos/blob/542bc261b3ed4b7994fc0d70025fd3df3a11f591/scripts/install_venv.sh#L235-L240) or at the following code snippet.\r\n\r\n> ```shell\r\n>  # Check: Make sure the python version is correct.  \r\n>  if [[ $($python_bin --version) != *\"3.8\"* ]] ; then \r\n>    error_exit \"Error retrieving python version, or python executable $python_bin not version 3.8.  Please specify a Python 3.8 executable with the --python option.\"\r\n>  else\r\n>    echo \"Using python from $python_bin.\" \r\n>  fi\r\n> ```\r\n\r\nYou are getting the following error message:\r\n\r\n> Error retrieving python version, or python executable $python_bin not version 3.8.  Please specify a Python 3.8 executable with the --python option.\r\n\r\nWhich is the result of the truthiness of the following check:\r\n\r\n> ```shell\r\n> if [[ $($python_bin --version) != *\"3.8\"* ]] ; then \r\n> ```\r\n\r\nAnd as mentioned in the issue you are using __Python 3.9.5__.\r\n> Python version: 3.9.5\r\n\r\nSo to install __tensorflow__ on your system you need to install a __Python__ version that satisfies __3.8.*__.", "> Are you following the steps specified here: https://developer.apple.com/metal/tensorflow-plugin/\r\n\r\nNo I try it with this https://github.com/apple/tensorflow_macos/", "> @insung3511 Please look at the the code [here](https://github.com/apple/tensorflow_macos/blob/542bc261b3ed4b7994fc0d70025fd3df3a11f591/scripts/install_venv.sh#L235-L240) or at the following code snippet.\r\n> \r\n> > ```shell\r\n> >  # Check: Make sure the python version is correct.  \r\n> >  if [[ $($python_bin --version) != *\"3.8\"* ]] ; then \r\n> >    error_exit \"Error retrieving python version, or python executable $python_bin not version 3.8.  Please specify a Python 3.8 executable with the --python option.\"\r\n> >  else\r\n> >    echo \"Using python from $python_bin.\" \r\n> >  fi\r\n> > ```\r\n> \r\n> You are getting the following error message:\r\n> \r\n> > Error retrieving python version, or python executable $python_bin not version 3.8.  Please specify a Python 3.8 executable with the --python option.\r\n> \r\n> Which is the result of the truthiness of the following check:\r\n> \r\n> > ```shell\r\n> > if [[ $($python_bin --version) != *\"3.8\"* ]] ; then \r\n> > ```\r\n> \r\n> And as mentioned in the issue you are using **Python 3.9.5**.\r\n> \r\n> > Python version: 3.9.5\r\n> \r\n> So to install **tensorflow** on your system you need to install a **Python** version that satisfies **3.8.***.\r\n\r\nHmm.. then I can't using on python3.9?", "Hi @insung3511! Please try again with Python 3.8 too else follow instructions mentioned in this [thread](https://developer.apple.com/metal/tensorflow-plugin/). Thank you!", "oh okay I will reference it. appreciate it \ud83d\ude04 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52674\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52674\">No</a>\n", "hey guys i got some error like this again. i reference [this](https://developer.apple.com/metal/tensorflow-plugin/)  one\r\n\r\n```\r\nerror: Command \"clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/bahk_insung/miniforge3/envs/pycv/include -arch arm64 -fPIC -O2 -isystem /Users/bahk_insung/miniforge3/envs/pycv/include -arch arm64 -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/Users/bahk_insung/miniforge3/envs/pycv/include/python3.9 -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.9/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.0-arm64-3.9/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.0-arm64-3.9/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers\" failed with exit status 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for numpy\r\nFailed to build numpy\r\nERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\r\n```", "Hi @insung3511 ! Could you please try again by installing/upgrading numpy . Reference: [link1](https://discuss.codecademy.com/t/error-installing-numpy-on-m1-mac-using-terminal/580706/5),[link2](https://exerror.com/building-wheel-for-numpy-pyproject-toml/). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52674\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52674\">No</a>\n"]}, {"number": 52672, "title": "Warning persists after upgrading to Mac OS 12- Could not identify NUMA node of platform GPU ID 0", "body": "**This warning was supposed to be resolved in MacOs 12 . How to fix this?**\r\n```\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import models\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10, activation='softmax'))\r\nmodel.summary()\r\n```\r\n```\r\n\r\nMetal device set to: Apple M1\r\n2021-10-26 01:42:59.638063: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-26 01:42:59.638241: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n```\r\n", "comments": ["@par1hsharma ,\r\nPlease take a look at this  similar issues [link](https://github.com/tensorflow/tensorflow/issues/52138), #44751,#47782 with similar errror and for installation please take a look at this [link](https://github.com/apple/tensorflow_macos). It helps.Thanks!\r\n", "@tilakrayal none of the link you mentioned is related to my Issue . Every link you mentioned has MacOs version of 11 which is Big Sur. TF is not compatible with BIG Sur.Thats why they are facing issue. My problem is that I have upgraded my MacOs to 12 (which is compatible with TF as mentioned on Apple's official website) and the issue still persists .\r\n", "@par1hsharma Checkout this [thread](https://stackoverflow.com/questions/55511186/could-not-identify-numa-node-of-platform-gpu), in case it didn't help, create a issue in [Keras](https://github.com/keras-team/keras/issues) repository. Thanks!", "@par1hsharma ,\r\nCan you please confirm the tensorflow version you are using.Thanks", "I just upgraded to Montegrey just now and have this same issue. My AMD Radeon Pro 5600M 8 GB on Big Surr was working just fine.\r\n\r\nNow:\r\n\r\n2021-10-28 19:57:00.337745: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-28 19:57:00.337974: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n2021-10-28 19:57:00.797158: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\r\n2021-10-28 19:57:00.797172: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\r\n2021-10-28 19:57:00.797199: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\r\n2021-10-28 19:57:01.749236: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n\r\nAnd the kernel dies\r\n\r\nI am running Intel (not silicon), MacOS Monterey, tensorflow 2.6, python 3.8.12 - again, all of my scripts were working fine until I upgraded to Monterey tonight.\r\n\r\ntensorflow                2.6.0            py38h50d1736_0    conda-forge\r\ntensorflow-base           2.6.0            py38h8860697_0    conda-forge\r\ntensorflow-data-validation 1.3.0                    pypi_0    pypi\r\ntensorflow-datasets       4.3.0              pyhd8ed1ab_0    conda-forge\r\ntensorflow-estimator      2.6.0            py38h5519746_0    conda-forge\r\ntensorflow-macos          2.6.0                    pypi_0    pypi\r\ntensorflow-metadata       1.2.0              pyhd8ed1ab_0    conda-forge\r\ntensorflow-metal          0.2.0                    pypi_0    pypi\r\ntensorflow-serving-api    2.6.0                    pypi_0    pypi", "I have same warning on macOS 12.0.1\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.test.is_gpu_available(\r\n...     cuda_only=False, min_cuda_compute_capability=None\r\n... )\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\nMetal device set to: Apple M1 Pro\r\n\r\nsystemMemory: 16.00 GB\r\nmaxCacheSize: 5.33 GB\r\n\r\n2021-10-29 13:22:31.102416: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-29 13:22:31.103383: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n```", "yes exactly this issue persists but the TensorFlow team on GitHub is unable to catch this issue and they keep directing us to different threads .They dont even check the MacOs version people are using .", "**@rayjennings3rd** **@xiangpeng2008** \r\nI recommend you to check [this](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb) installation guide for proper installation on M1 Macs.I am not sure about the intel Macs .\r\n", "> @par1hsharma ,\r\n> Can you please confirm the tensorflow version you are using.Thanks\r\n\r\n2.6.0", "This fixed this issue for me (M1 MacBook Pro, macOS Monterey 12.0.1):\r\n\r\n1. Removing my previous kernel\r\n`jupyter kernelspec remove tensorflow` \r\n\r\n2. Installing the [TensorFlow Metal plugin](https://developer.apple.com/metal/tensorflow-plugin/) (Skip the Miniforge installation if you already have it installed, I also have it installed globally)\r\n`conda install -c apple tensorflow-deps`\r\n`python -m pip uninstall tensorflow-macos`\r\n`python -m pip uninstall tensorflow-metal`\r\n`conda install -c apple tensorflow-deps --force-reinstall`\r\n`conda install -c apple tensorflow-deps==2.6.0`\r\n`python -m pip install tensorflow-macos`\r\n`python -m pip install tensorflow-metal`\r\n\r\n3. Creating a new kernel\r\n`python -m ipykernel install --user --name tensorflow --display-name \"Python 3.9 (tensorflow)\"`\r\n\r\n\r\n", "@par1hsharma what you listing is from the past. I've always been using Intel based Macs. Again, this problem happened on exactly the day (and immediately right after) upgrading to MacOS Monterey. This is not an issue of not being able to install it. I can still install it, it just fails on a keras model fit() call when it never did before.\r\n\r\nI can run something like:\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.config.list_physical_devices()\r\n```\r\n\r\nAnd see my CPU and GPU but doing something more substantial will not work.", "@par1hsharma \r\nPlease refer tot he above comments and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I just encountered the same issue insalled all the deps of tensorflow and running macos 12. \r\nusing keras.\r\n\r\nmessage:\r\n\r\nMetal device set to: Apple M1 Pro\r\nsystemMemory: 32.00 GB\r\nmaxCacheSize: 10.67 GB\r\n\r\n2021-11-10 18:12:48.892303: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-11-10 18:12:48.892954: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n", "I encountered the same error everything works perfectly fine but error while running epochs, running macos 12\r\nMetal device set to: m1 pro\r\n\r\nCould not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.", "@Arsham1024 @ssd31  - did you notebook/program die after that or was it just downgraded. My kernel completely dies.", "> @Arsham1024 @ssd31 - did you notebook/program die after that or was it just downgraded. My kernel completely dies.\r\n\r\nmine runs completely fine but while running epochs CPU and GPU running at 0 frequency I don't know why! i am fedup searching for the solution as nobody has it as of now\r\n", "I am also getting this issue after following the install instructions here:  https://developer.apple.com/metal/tensorflow-plugin/ which references this project\r\n\r\n'\r\nMetal` device set to: Apple M1 Pro\r\n\r\nsystemMemory: 32.00 GB\r\nmaxCacheSize: 10.67 GB\r\n\r\n2021-11-22 08:20:43.007615: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-11-22 08:20:43.007998: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\nTraceback (most recent call last):\r\n  File \"/Users/frush/GIT/TensorFlow-Examples/examples/1_Introduction/helloworld.py\", line 22, in <module>\r\n    sess = tf.Session()\r\n`", "I get those warnings too (at the start of training) but I also get a message:\r\n`I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.`\r\nTraining then continues using the GPU.", "I also got the same warning.\r\nI am using a M1 macbook pro with Monterey OS (12.0.1).\r\nWhen I created a virtual environment using miniforge3 and run the following python script in the virtual environment, the warning happened.\r\n\r\n```\r\nPython 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \r\n[Clang 11.1.0 ] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.python.client import device_lib\r\n>>> device_lib.list_local_devices()\r\nMetal device set to: Apple M1 Pro\r\n\r\nsystemMemory: 16.00 GB\r\nmaxCacheSize: 5.33 GB\r\n\r\n2021-11-26 20:35:32.907078: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-11-26 20:35:32.908054: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 17996024400387806521\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nlocality {\r\n  bus_id: 1\r\n}\r\nincarnation: 7243645344964346266\r\nphysical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\r\n]\r\n```\r\n\r\nI tried the method described here and [Getting Started with tensorflow-metal PluggableDevice](https://developer.apple.com/metal/tensorflow-plugin/) but could not solve the problem.", "Had the exact same response as @Okabe-Junya. ", "Got M1 and am currently OS 12.0.1\r\nI'm using pyenv instead of Conda, installed tendorflow-macos and tensorflow-metal\r\n```                             \r\nPython 3.8.10 (default, Nov 29 2021, 09:43:34) \r\n[Clang 13.0.0 (clang-1300.0.29.3)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.config.list_physical_devices()\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n\r\n>>> with tf.device('/GPU'):\r\n...     a = tf.random.normal(shape=(2,), dtype=tf.float32)\r\n...     b = tf.nn.relu(a)\r\n... \r\n2021-11-29 11:44:15.755838: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nMetal device set to: Apple M1\r\n\r\nsystemMemory: 16.00 GB\r\nmaxCacheSize: 5.33 GB\r\n\r\n2021-11-29 11:44:15.758586: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-11-29 11:44:15.761337: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n```", "Guys i've had the same problem while using M1 pro:\r\n`Metal device set to: Apple M1 Pro\r\n2021-12-01 16:46:02.449022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-12-01 16:46:02.449505: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)`\r\n\r\nsorry to see that we all stuck here.", "> I followed the installing guidance [here](https://github.com/jeffheaton/t81_558_deep_learning/tree/master/install), it's for M1 not M1 pro, I thought it would be the same but I failed.\r\n> And I haven't tried the Apple developer's instructions [here](https://developer.apple.com/metal/tensorflow-plugin/), don't know if the document is up to date.\r\n\r\nThat is up to date install it from apple developer instruction\r\n@KejianCui99 ", "Hey I've finally solved this problem by completely following [this](https://makeoptim.com/en/deep-learning/tensorflow-metal) install guidance. Although it's for M1, it works well on my M1 pro.\r\n\r\nThere will still be warnings but the code works, and I can see from the GPU monitor that it is actually using my GPU.\r\nHowever I found the training speed is quite slow, it may due to the lack of adaptation, so I decided to disable GPU and use CPU only and it works much better. \r\n\r\nTo disable GPU you can use: `tf.config.experimental.set_visible_devices([], 'GPU')` at the beginning of your code.\r\nThis is how my device works:\r\n\r\n![A708CB10-B0A2-43EF-B060-429E553E262A](https://user-images.githubusercontent.com/73149097/144365894-81b558d5-417f-4c8a-b204-d287ef443346.jpeg)\r\n\r\n\r\n", "I've also confirmed that a fresh re-install of Miniforge using the instructions referenced by @KejianCui99 seem to clear up this issue. (though others related to jupyter that are unrelated remain...)\r\n\r\nThanks for the find!\r\n\r\nI ran both with and without GPU support (and confirmed GPU usage or lack thereof) and got similar times...\r\n\r\n`2021-12-04 10:15:35.681524: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\nEpoch 1/5\r\n2021-12-04 10:15:36.097538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n938/938 [==============================] - 12s 9ms/step - loss: 0.2221 - accuracy: 0.9314\r\nEpoch 2/5\r\n938/938 [==============================] - 9s 9ms/step - loss: 0.0758 - accuracy: 0.9762\r\nEpoch 3/5\r\n938/938 [==============================] - 9s 9ms/step - loss: 0.0556 - accuracy: 0.9824\r\nEpoch 4/5\r\n938/938 [==============================] - 9s 10ms/step - loss: 0.0442 - accuracy: 0.9860\r\nEpoch 5/5\r\n938/938 [==============================] - 9s 10ms/step - loss: 0.0365 - accuracy: 0.9883\r\n<keras.callbacks.History object at 0x15c0c8f40>`\r\n\r\nvs no GPU, which was slightly (5s) faster:\r\n\r\n`>>> model.fit(train_images, train_labels, epochs=5, batch_size=64)\r\n2021-12-04 10:28:04.884353: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\nEpoch 1/5\r\n938/938 [==============================] - 8s 8ms/step - loss: 0.1684 - accuracy: 0.9484\r\nEpoch 2/5\r\n938/938 [==============================] - 8s 9ms/step - loss: 0.0452 - accuracy: 0.9855\r\nEpoch 3/5\r\n938/938 [==============================] - 9s 9ms/step - loss: 0.0312 - accuracy: 0.9902\r\nEpoch 4/5\r\n938/938 [==============================] - 9s 9ms/step - loss: 0.0243 - accuracy: 0.9924\r\nEpoch 5/5\r\n938/938 [==============================] - 9s 10ms/step - loss: 0.0187 - accuracy: 0.9940\r\n<keras.callbacks.History object at 0x14bcd9ac0>`\r\n", "> \r\n\r\nMaybe we are using different network structures, mine was extremely slow when using GPU (about 40s per epoch).", "With respect to CPU vs GPU performance, I see two possibilities: \r\n\r\n1. There is a tensorflow-metal implementation issue that makes using the GPU slow (possibly CPU-bound). \r\n2. The M1 architecture itself is such that tensorflow operations are as fast or faster via the CPU vs the GPU. There could be various reasons for this. \r\n\r\nIt would be nice to get an answer for this; as it is tensorflow-metal is worse than useless. Side question: tensorflow-metal allows us to use the GPU, but is it using the GPU or the neural engine or what? ", "FYI there's a lot of discussion of installation and performance issues in the apple developer forums : https://developer.apple.com/forums/tags/tensorflow-metal\r\n\r\nIn particular [this thread](https://developer.apple.com/forums/thread/687654) suggests that the CPU simply works better for small models/batch/data, but the GPU works better for large models/batch/data. ", "> I've also confirmed that a fresh re-install of Miniforge using the instructions referenced by @KejianCui99 seem to clear up this issue. (though others related to jupyter that are unrelated remain...)\r\n\r\n@rfrush do you know why a \"fresh re-install of Miniforge\" meant you stopped getting the message about `Could not identify NUMA node of platform GPU ID 0`? e.g. had you previously installed Miniforge via Homebrew rather than directly from the bash script?", "@ollie-bell  I had followed the instructions at https://developer.apple.com/metal/tensorflow-plugin/, which are very similar to https://makeoptim.com/en/deep-learning/tensorflow-metal.    It does appear that between the two installs the TensorFlow version had also updated, so there could be multiple factors leading to the fix.   ", "I've tried TensorFlow 2.6.0 and 2.7.0 on python versions 3.8 and 3.9. Unfortunately none of above solves `Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.`", "deadend here, as well after following both the [Apple](https://developer.apple.com/metal/tensorflow-plugin/) and [MakeOptim](https://makeoptim.com/en/deep-learning/tensorflow-metal) instructions on a new MBA M1\r\n\r\n```\r\nmodel = Sequential([\r\n    Dense(32, activation='relu', input_shape=(10,)),\r\n    Dense(32, activation='relu'),\r\n    Dense(1, activation='sigmoid'),\r\n])\r\n\r\nMetal device set to: Apple M1\r\n2021-12-19 12:18:04.851761: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-12-19 12:18:04.858068: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n```\r\n\r\nhere is my mambaforge environment\r\n```\r\nname: tensorflow\r\nchannels:\r\n  - apple\r\n  - conda-forge\r\ndependencies:\r\n  - absl-py=0.10.0=pyhd8ed1ab_1\r\n  - aiohttp=3.8.1=py39h5161555_0\r\n  - aiosignal=1.2.0=pyhd8ed1ab_0\r\n  - anyio=3.4.0=py39h2804cbe_0\r\n  - appnope=0.1.2=py39h2804cbe_2\r\n  - argon2-cffi=21.1.0=py39h5161555_2\r\n  - astunparse=1.6.3=pyhd8ed1ab_0\r\n  - async-timeout=4.0.1=pyhd8ed1ab_0\r\n  - async_generator=1.10=py_0\r\n  - attrs=21.2.0=pyhd8ed1ab_0\r\n  - babel=2.9.1=pyh44b312d_0\r\n  - backcall=0.2.0=pyh9f0ad1d_0\r\n  - backports=1.0=py_2\r\n  - backports.functools_lru_cache=1.6.4=pyhd8ed1ab_0\r\n  - bleach=4.1.0=pyhd8ed1ab_0\r\n  - blinker=1.4=py_1\r\n  - brotli=1.0.9=h3422bc3_6\r\n  - brotli-bin=1.0.9=h3422bc3_6\r\n  - brotlipy=0.7.0=py39h5161555_1003\r\n  - c-ares=1.18.1=h3422bc3_0\r\n  - ca-certificates=2021.10.8=h4653dfc_0\r\n  - cached-property=1.5.2=hd8ed1ab_1\r\n  - cached_property=1.5.2=pyha770c72_1\r\n  - cachetools=4.2.4=pyhd8ed1ab_0\r\n  - certifi=2021.10.8=py39h2804cbe_1\r\n  - cffi=1.15.0=py39h52b1de0_0\r\n  - charset-normalizer=2.0.9=pyhd8ed1ab_0\r\n  - click=8.0.3=py39h2804cbe_1\r\n  - cryptography=36.0.1=py39hfb8cd70_0\r\n  - cycler=0.11.0=pyhd8ed1ab_0\r\n  - dataclasses=0.8=pyhc8e2a94_3\r\n  - debugpy=1.5.1=py39hfb83b0d_0\r\n  - decorator=5.1.0=pyhd8ed1ab_0\r\n  - defusedxml=0.7.1=pyhd8ed1ab_0\r\n  - entrypoints=0.3=pyhd8ed1ab_1003\r\n  - fonttools=4.28.5=py39h5161555_0\r\n  - freetype=2.10.4=h17b34a0_1\r\n  - frozenlist=1.2.0=py39h5161555_1\r\n  - gast=0.4.0=pyh9f0ad1d_0\r\n  - google-auth=1.35.0=pyh6c4a22f_0\r\n  - google-auth-oauthlib=0.4.6=pyhd8ed1ab_0\r\n  - google-pasta=0.2.0=pyh8c360ce_0\r\n  - grpcio=1.43.0=py39h9e1b6db_0\r\n  - h5py=3.1.0=nompi_py39h99babb8_100\r\n  - hdf5=1.10.6=nompi_h0fc092c_1114\r\n  - idna=3.1=pyhd3deb0d_0\r\n  - importlib-metadata=4.9.0=py39h2804cbe_0\r\n  - importlib_resources=5.4.0=pyhd8ed1ab_0\r\n  - ipykernel=6.6.0=py39h32adebf_0\r\n  - ipython=7.30.1=py39h2804cbe_0\r\n  - ipython_genutils=0.2.0=py_1\r\n  - jbig=2.1=h3422bc3_2003\r\n  - jedi=0.18.1=py39h2804cbe_0\r\n  - jinja2=3.0.3=pyhd8ed1ab_0\r\n  - joblib=1.1.0=pyhd8ed1ab_0\r\n  - jpeg=9d=h27ca646_0\r\n  - json5=0.9.5=pyh9f0ad1d_0\r\n  - jsonschema=4.3.1=pyhd8ed1ab_0\r\n  - jupyter_client=7.1.0=pyhd8ed1ab_0\r\n  - jupyter_core=4.9.1=py39h2804cbe_1\r\n  - jupyter_server=1.13.1=pyhd8ed1ab_0\r\n  - jupyterlab=3.2.5=pyhd8ed1ab_0\r\n  - jupyterlab_pygments=0.1.2=pyh9f0ad1d_0\r\n  - jupyterlab_server=2.9.0=pyhd8ed1ab_0\r\n  - keras=2.7.0=pyhd8ed1ab_0\r\n  - keras-preprocessing=1.1.2=pyhd8ed1ab_0\r\n  - kiwisolver=1.3.2=py39h4d2d688_1\r\n  - krb5=1.19.2=hd92b7a7_3\r\n  - lcms2=2.12=had6a04f_0\r\n  - lerc=3.0=hbdafb3b_0\r\n  - libblas=3.9.0=12_osxarm64_openblas\r\n  - libbrotlicommon=1.0.9=h3422bc3_6\r\n  - libbrotlidec=1.0.9=h3422bc3_6\r\n  - libbrotlienc=1.0.9=h3422bc3_6\r\n  - libcblas=3.9.0=12_osxarm64_openblas\r\n  - libcurl=7.80.0=h8fe1914_1\r\n  - libcxx=12.0.1=h168391b_0\r\n  - libdeflate=1.8=h3422bc3_0\r\n  - libedit=3.1.20191231=hc8eb9b7_2\r\n  - libev=4.33=h642e427_1\r\n  - libffi=3.4.2=h3422bc3_5\r\n  - libgfortran=5.0.0.dev0=11_0_1_hf114ba7_23\r\n  - libgfortran5=11.0.1.dev0=hf114ba7_23\r\n  - liblapack=3.9.0=12_osxarm64_openblas\r\n  - libllvm11=11.1.0=h93073aa_2\r\n  - libnghttp2=1.43.0=he4cd7f6_1\r\n  - libopenblas=0.3.18=openmp_h5dd58f0_0\r\n  - libpng=1.6.37=hf7e6567_2\r\n  - libprotobuf=3.19.1=hccf11d3_0\r\n  - libsodium=1.0.18=h27ca646_1\r\n  - libssh2=1.10.0=hb80f160_2\r\n  - libtiff=4.3.0=h74060c4_2\r\n  - libwebp-base=1.2.1=h3422bc3_0\r\n  - libzlib=1.2.11=hee7b306_1013\r\n  - llvm-openmp=12.0.1=hf3c4609_1\r\n  - lz4-c=1.9.3=hbdafb3b_1\r\n  - markdown=3.3.6=pyhd8ed1ab_0\r\n  - markupsafe=2.0.1=py39h5161555_1\r\n  - matplotlib=3.5.1=py39hdf13c20_0\r\n  - matplotlib-base=3.5.1=py39h5aa4fe7_0\r\n  - matplotlib-inline=0.1.3=pyhd8ed1ab_0\r\n  - mistune=0.8.4=py39h5161555_1005\r\n  - multidict=5.2.0=py39h5161555_1\r\n  - munkres=1.1.4=pyh9f0ad1d_0\r\n  - nbclassic=0.3.4=pyhd8ed1ab_0\r\n  - nbclient=0.5.9=pyhd8ed1ab_0\r\n  - nbconvert=6.3.0=py39h2804cbe_1\r\n  - nbformat=5.1.3=pyhd8ed1ab_0\r\n  - ncurses=6.2=h9aa5885_4\r\n  - nest-asyncio=1.5.4=pyhd8ed1ab_0\r\n  - notebook=6.4.6=pyha770c72_0\r\n  - numpy=1.19.5=py39h1f3b974_2\r\n  - oauthlib=3.1.1=pyhd8ed1ab_0\r\n  - olefile=0.46=pyh9f0ad1d_1\r\n  - openjpeg=2.4.0=h062765e_1\r\n  - openssl=1.1.1l=h3422bc3_0\r\n  - opt_einsum=3.3.0=pyhd8ed1ab_1\r\n  - packaging=21.3=pyhd8ed1ab_0\r\n  - pandas=1.3.5=py39h7f752ed_0\r\n  - pandocfilters=1.5.0=pyhd8ed1ab_0\r\n  - parso=0.8.3=pyhd8ed1ab_0\r\n  - pexpect=4.8.0=pyh9f0ad1d_2\r\n  - pickleshare=0.7.5=py_1003\r\n  - pillow=8.4.0=py39ha74c66e_0\r\n  - pip=21.3.1=pyhd8ed1ab_0\r\n  - prometheus_client=0.12.0=pyhd8ed1ab_0\r\n  - prompt-toolkit=3.0.24=pyha770c72_0\r\n  - protobuf=3.19.1=py39hfb83b0d_1\r\n  - ptyprocess=0.7.0=pyhd3deb0d_0\r\n  - pyasn1=0.4.8=py_0\r\n  - pyasn1-modules=0.2.7=py_0\r\n  - pycparser=2.21=pyhd8ed1ab_0\r\n  - pygments=2.10.0=pyhd8ed1ab_0\r\n  - pyjwt=2.3.0=pyhd8ed1ab_1\r\n  - pyopenssl=21.0.0=pyhd8ed1ab_0\r\n  - pyparsing=3.0.6=pyhd8ed1ab_0\r\n  - pyrsistent=0.18.0=py39h5161555_0\r\n  - pysocks=1.7.1=py39h2804cbe_4\r\n  - python=3.9.7=h54d631c_3_cpython\r\n  - python-dateutil=2.8.2=pyhd8ed1ab_0\r\n  - python_abi=3.9=2_cp39\r\n  - pytz=2021.3=pyhd8ed1ab_0\r\n  - pyu2f=0.1.5=pyhd8ed1ab_0\r\n  - pyzmq=22.3.0=py39h02c6a76_1\r\n  - readline=8.1=hedafd6a_0\r\n  - requests=2.26.0=pyhd8ed1ab_1\r\n  - requests-oauthlib=1.3.0=pyh9f0ad1d_0\r\n  - rsa=4.8=pyhd8ed1ab_0\r\n  - scikit-learn=1.0.1=py39hef7049f_3\r\n  - scipy=1.7.3=py39h5060c3b_0\r\n  - send2trash=1.8.0=pyhd8ed1ab_0\r\n  - setuptools=59.6.0=py39h2804cbe_0\r\n  - six=1.15.0=pyh9f0ad1d_0\r\n  - sniffio=1.2.0=py39h2804cbe_2\r\n  - sqlite=3.37.0=h72a2b83_0\r\n  - tensorboard=2.6.0=pyhd8ed1ab_1\r\n  - tensorboard-data-server=0.6.0=py39hfb8cd70_1\r\n  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0\r\n  - tensorflow-deps=2.7.0=0\r\n  - termcolor=1.1.0=py_2\r\n  - terminado=0.12.1=py39h2804cbe_1\r\n  - testpath=0.5.0=pyhd8ed1ab_0\r\n  - threadpoolctl=3.0.0=pyh8a188c0_0\r\n  - tk=8.6.11=he1e0b03_1\r\n  - tornado=6.1=py39h5161555_2\r\n  - traitlets=5.1.1=pyhd8ed1ab_0\r\n  - typing-extensions=3.7.4.3=0\r\n  - typing_extensions=3.7.4.3=py_0\r\n  - tzdata=2021e=he74cb21_0\r\n  - urllib3=1.26.7=pyhd8ed1ab_0\r\n  - wcwidth=0.2.5=pyh9f0ad1d_2\r\n  - webencodings=0.5.1=py_1\r\n  - websocket-client=1.2.3=pyhd8ed1ab_0\r\n  - werkzeug=2.0.1=pyhd8ed1ab_0\r\n  - wheel=0.35.1=pyh9f0ad1d_0\r\n  - wrapt=1.12.1=py39h5161555_3\r\n  - xz=5.2.5=h642e427_1\r\n  - yarl=1.7.2=py39h5161555_1\r\n  - zeromq=4.3.4=hbdafb3b_1\r\n  - zipp=3.6.0=pyhd8ed1ab_0\r\n  - zlib=1.2.11=hee7b306_1013\r\n  - zstd=1.5.0=h861e0a7_0\r\n  - pip:\r\n    - flatbuffers==2.0\r\n    - libclang==12.0.0\r\n    - tensorflow-estimator==2.7.0\r\n    - tensorflow-macos==2.7.0\r\n    - tensorflow-metal==0.3.0\r\n```", "None of the suggestions written previously prevent the `Could not identify NUMA node of platform GPU ID 0, defaulting to 0` message on my MBA M1 (MacOS 12.1). I have tried TensorFlow 2.5.0, 2.6.0 and 2.7.0 with tensorflow-metal plugins 0.1.2, 0.2.0 and 0.3.0 respectively. This was the first thing I tried after doing a complete reinstall of MacOS (which I did for unrelated reasons).\r\n\r\nThe simplest way for me to encounter the issue is to `tf.config.list_logical_devices()`. Note that `tf.config.list_physical_devices()` doesn't trigger the message.\r\n\r\n```\r\n>>> import tensorflow as tf\r\nInit Plugin\r\nInit Graph Optimizer\r\nInit Kernel\r\n>>> tf.config.list_physical_devices()\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n>>> tf.config.list_logical_devices()\r\nMetal device set to: Apple M1\r\n\r\nsystemMemory: 8.00 GB\r\nmaxCacheSize: 2.67 GB\r\n\r\n2022-01-09 15:57:38.705551: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2022-01-09 15:57:38.706074: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\r\n```", "@par1hsharma I can reproduce the issue. I ran a simple model (from TF tutorials page) on Apple M1 mini. [Here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb) is the code for reference. \r\n\r\nThe trace is as shown below\r\n\r\n```\r\n(base) vishnu@vishnuvhansmini ~ % /Users/vishnu/miniforge3/bin/python3 /Users/vishnu/Desktop/Codes/TF_Keras/test.py\r\n\r\n2.7.0\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 3s 0us/step\r\n11501568/11490434 [==============================] - 3s 0us/step\r\nMetal device set to: Apple M1\r\n\r\nsystemMemory: 8.00 GB\r\nmaxCacheSize: 2.67 GB\r\n\r\n2022-01-21 11:08:28.160120: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2022-01-21 11:08:28.160641: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n2022-01-21 11:08:28.778421: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\nEpoch 1/5\r\n2022-01-21 11:08:28.909028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n1875/1875 [==============================] - 11s 5ms/step - loss: 0.2919 - accuracy: 0.9158\r\nEpoch 2/5\r\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.1383 - accuracy: 0.9591\r\nEpoch 3/5\r\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.1013 - accuracy: 0.9689\r\nEpoch 4/5\r\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0818 - accuracy: 0.9749\r\nEpoch 5/5\r\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0687 - accuracy: 0.9782\r\n2022-01-21 11:09:14.423644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n313/313 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9743\r\n```\r\n\r\nHowever, this is more related to Apple. Community is trying to build TF for Apple M1 [here](https://github.com/tensorflow/tensorflow/issues/52160). Please follow that thread for more discussion. Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Got the same message, but checked after msg  ...import sys\r\n\r\nimport tensorflow.keras\r\nimport pandas as pd\r\nimport sklearn as sk\r\n# -----------   \r\nprint(f\"Tensor Flow Version: {tf.__version__}\")\r\nprint(f\"Keras Version: {tensorflow.keras.__version__}\")\r\nprint()\r\nprint(f\"Python {sys.version}\")\r\nprint(f\"Pandas {pd.__version__}\")\r\nprint(f\"Scikit-Learn {sk.__version__}\")\r\ngpu = len(tf.config.list_physical_devices('GPU'))>0\r\nprint(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\r\n\r\nand received :  \r\nTensor Flow Version: 2.5.0\r\nKeras Version: 2.5.0\r\n\r\nPython 3.9.7 (default, Sep 16 2021, 23:53:23) \r\n[Clang 12.0.0 ]\r\nPandas 1.3.5\r\nScikit-Learn 1.0.2\r\nGPU is available. \r\n\r\nSo, is the msg spurious? \r\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52672\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52672\">No</a>\n"]}, {"number": 52671, "title": "[TF-TRT] Adding a detailled non-conversion report capability on demand", "body": "@bixia1 @tfeher for review\r\n\r\nThis PR does the following:\r\n- Adds `TF_TRT_SHOW_DETAILED_REPORT=1` capability to modify the conversion report and increase verbosity.\r\n- Changes `struct ConversionParams.output_names` to `struct ConversionParams.input_output_names` to be more precise on the actual use of the parameter.\r\n- Removes `at <layer_name>` from the error message generated for unconverted ops\r\n  - allows similar errors generated at different layers to be grouped together\r\n  - removes some redundancy where the information is \"double printed\", see here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2tensorrt/segment/segment.cc#L737-L740", "comments": ["## Example with BERT without dynamic shape\r\n\r\n### Normal execution mode\r\n\r\n```bash\r\n################################################################################\r\nTensorRT unsupported/unconverted OP Report:\r\n\t- Reshape -> 197x\r\n\t- Prod -> 146x\r\n\t- GatherV2 -> 146x\r\n\t- Pack -> 126x\r\n\t- Shape -> 88x\r\n\t- ConcatV2 -> 73x\r\n\t- StridedSlice -> 18x\r\n\t- NoOp -> 5x\r\n\t- Identity -> 2x\r\n\t- Fill -> 2x\r\n\t- Tile -> 1x\r\n\t- Range -> 1x\r\n\t- Placeholder -> 1x\r\n\t- ExpandDims -> 1x\r\n\t- Cast -> 1x\r\n--------------------------------------------------------------------------------\r\n\t- Total unconverted OPs: 808\r\n\t- Total unconverted OP Types: 15\r\nFor more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\r\n################################################################################\r\n```\r\n\r\n### Now with `TF_TRT_SHOW_DETAILED_REPORT=1 python my_script.py`\r\n\r\n```bash\r\n################################################################################\r\nTensorRT unsupported/unconverted OP Report:\r\n\t- Reshape -> 197x\r\n\t\t- [Count: 196x] The input \"shape\" for Reshape must be a constant in implicit batch mode.\r\n\t\t- [Count: 1x] Reshape on batch dimension is not supported\r\n\r\n\t- Prod -> 146x\r\n\t\t- [Count: 146x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- GatherV2 -> 146x\r\n\t\t- [Count: 146x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- Pack -> 126x\r\n\t\t- [Count: 126x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- Shape -> 88x\r\n\t\t- [Count: 88x] Shape is only supported for explicit batch mode.\r\n\r\n\t- ConcatV2 -> 73x\r\n\t\t- [Count: 73x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- StridedSlice -> 18x\r\n\t\t- [Count: 17x] implicit batch mode requires input shape with at least two dimensions\r\n\t\t- [Count: 1x] In implicit batch mode, dynamic input size is not supported.\r\n\r\n\t- NoOp -> 5x\r\n\t\t- [Count: 5x] Op type NoOp is not supported.\r\n\r\n\t- Identity -> 2x\r\n\t\t- [Count: 2x] excluded by segmenter option. Most likely an input or output node.\r\n\r\n\t- Fill -> 2x\r\n\t\t- [Count: 2x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- Tile -> 1x\r\n\t\t- [Count: 1x] Op type Tile is not supported.\r\n\r\n\t- Range -> 1x\r\n\t\t- [Count: 1x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- Placeholder -> 1x\r\n\t\t- [Count: 1x] excluded by segmenter option. Most likely an input or output node.\r\n\r\n\t- ExpandDims -> 1x\r\n\t\t- [Count: 1x] implicit batch mode requires input shape with at least two dimensions\r\n\r\n\t- Cast -> 1x\r\n\t\t- [Count: 1x] Cast op is not supported - input dtype != DT_HALF, received: int32\r\n\r\n--------------------------------------------------------------------------------\r\n\t- Total unconverted OPs: 808\r\n\t- Total unconverted OP Types: 15\r\nFor more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\r\n################################################################################\r\n```", "?", "@bixia1 for now I keep my commits separated, when the PR is ready to be merged I'll squash everything together :)", "I modified the PR description, please check.", "@bixia1 addressed all your comments except https://github.com/tensorflow/tensorflow/pull/52671#discussion_r737746862 where I don't really agree with your suggestion. I squashed my changes", "@bixia1 all comments have been addressed", "@bixia1 please re-review", "this PR was rollback because it causes segment fault when running some internal tests that I can't shared here.\r\nthe trace clearly indicates it is a problem introduced by this PR.\r\n```\r\nW1112 14:02:08.878509    5816 thread.cc:1869] --- Thread 7f4e32187000 (name: main/5799) stack: ---\r\nW1112 14:02:08.962981    5816 thread.cc:1869] PC: @     0x56549228241f  std::__u::__sort<>()\r\nW1112 14:02:08.963018    5816 thread.cc:1869]     @     0x56549228241f  std::__u::__sort<>()\r\nW1112 14:02:09.045756    5816 thread.cc:1869]     @     0x565492281fd1  std::__u::__sort<>()\r\nW1112 14:02:09.629577    5816 thread.cc:1869]     @     0x565492276f0c  tensorflow::tensorrt::segment::GenerateUnconversionReport()\r\nW1112 14:02:09.714269    5816 thread.cc:1869]     @     0x565492279a93  tensorflow::tensorrt::segment::SegmentGraph()\r\nW1112 14:02:09.810223    5816 thread.cc:1869]     @     0x56549221fcd8  tensorflow::tensorrt::convert::ConvertAfterShapes()\r\nW1112 14:02:09.895439    5816 thread.cc:1869]     @     0x5654922748dd  tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize()\r\nW1112 14:02:09.978627    5816 thread.cc:1869]     @     0x5654a70c57ff  tensorflow::grappler::MetaOptimizer::RunOptimizer()\r\nW1112 14:02:10.549734    5816 thread.cc:1869]     @     0x5654a70c472f  tensorflow::grappler::MetaOptimizer::OptimizeGraph()\r\nW1112 14:02:10.636108    5816 thread.cc:1869]     @     0x5654a70c710d  tensorflow::grappler::MetaOptimizer::OptimizeConsumeItem()\r\nW1112 14:02:10.636292    5816 thread.cc:1869]     @     0x7f4e1df1f053  pybind11::cpp_function::initialize<>()::{lambda()#1}::__invoke()\r\nW1112 14:02:10.636359    5816 thread.cc:1869]     @     0x7f4e1df19fc4  pybind11::cpp_function::dispatcher()\r\nW1112 14:02:10.733224    5816 thread.cc:1869]     @     0x5654ab3a6904  _PyMethodDef_RawFastCallKeywords\r\nW1112 14:02:10.830382    5816 thread.cc:1869]     @     0x5654ab3a5ce9  _PyCFunction_FastCallKeywords\r\nW1112 14:02:10.914472    5816 thread.cc:1869]     @     0x5654ab46c37e  call_function\r\nW1112 14:02:10.998766    5816 thread.cc:1869]     @     0x5654ab46920a  _PyEval_EvalFrameDefault\r\nW1112 14:02:11.558407    5816 thread.cc:1869]     @     0x5654ab46d23b  _PyEval_EvalCodeWithName\r\nW1112 14:02:11.646977    5816 thread.cc:1869]     @     0x5654ab3a5c68  _PyFunction_FastCallKeywords\r\nW1112 14:02:11.732484    5816 thread.cc:1869]     @     0x5654ab46c3f0  call_function\r\nW1112 14:02:11.818363    5816 thread.cc:1869]     @     0x5654ab469324  _PyEval_EvalFrameDefault\r\nW1112 14:02:11.904147    5816 thread.cc:1869]     @     0x5654ab3a6155  function_code_fastcall\r\nW1112 14:02:11.904170    5816 thread.cc:1869]     @     0x5654ab46c3f0  call_function\r\nW1112 14:02:11.988992    5816 thread.cc:1869]     @     0x5654ab4691f0  _PyEval_EvalFrameDefault\r\nW1112 14:02:11.989070    5816 thread.cc:1869]     @     0x5654ab3a6155  function_code_fastcall\r\nW1112 14:02:11.989111    5816 thread.cc:1869]     @     0x5654ab46c3f0  call_function\r\nW1112 14:02:11.989160    5816 thread.cc:1869]     @     0x5654ab4691f0  _PyEval_EvalFrameDefault\r\nW1112 14:02:11.989199    5816 thread.cc:1869]     @     0x5654ab3a6155  function_code_fastcall\r\nW1112 14:02:11.989237    5816 thread.cc:1869]     @     0x5654ab46c3f0  call_function\r\nW1112 14:02:11.989294    5816 thread.cc:1869]     @     0x5654ab4691f0  _PyEval_EvalFrameDefault\r\nW1112 14:02:11.989333    5816 thread.cc:1869]     @     0x5654ab46d23b  _PyEval_EvalCodeWithName\r\nW1112 14:02:11.989381    5816 thread.cc:1869]     @     0x5654ab3a5c68  _PyFunction_FastCallKeywords\r\nW1112 14:02:11.989421    5816 thread.cc:1869]     @     0x5654ab46c3f0  call_function\r\nW1112 14:02:11.989459    5816 thread.cc:1869]     @     0x5654ab469324  _PyEval_EvalFrameDefault\r\n\r\n```", "@bixia1 the stack trace is not helping to understand where is the bug. Anything you could send me maybe privately ? "]}, {"number": 52670, "title": "Add a note about cudaMallocAsync in the release note of TF2.7", "body": null, "comments": ["Should I port that to the master branch?", "No, we'll merge the relnotes to master after the releases finishes. Thanks for the question", "This doesn't seem to be included in 2.7 release notes here:\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v2.7.0\r\n\r\nAny idea why?", "Just noticed this now. The PR added this to the 2.6 release notes, not the 2.7 ones.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.7/RELEASE.md", "Thanks for catching this. Here is the fix to the release branch:\r\nhttps://github.com/tensorflow/tensorflow/pull/52990"]}, {"number": 52668, "title": "Does XLA handle FusedBatchNormV3 correctly in GPUs", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):: 2.6\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\nIt appears that when tf_xla_auto_jit=2 is set and mixed precision (fp16) is used,  networks run  significantly faster (3.5x) over non-XLA .  The advantage disappears when batchnorm is disabled ( about 1.3 x) \r\n\r\n**Describe the expected behavior**\r\nShould not show such marked differences  with and without batchnorm.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nJust use any code  with tf.keras.layers.BatchNormalization  \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@whatdhack ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52668\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52668\">No</a>\n"]}, {"number": 52667, "title": "Merge pull request #51359 from yongtang:46913-range-overflow", "body": "PiperOrigin-RevId: 391529518\r\nChange-Id: Ie3db4ae6d3c0f3dc88404e1dbdc22f7d03cbeb3b", "comments": []}, {"number": 52666, "title": "Merge pull request #51359 from yongtang:46913-range-overflow", "body": "PiperOrigin-RevId: 391529518\r\nChange-Id: Ie3db4ae6d3c0f3dc88404e1dbdc22f7d03cbeb3b", "comments": []}, {"number": 52665, "title": "Merge pull request #51359 from yongtang:46913-range-overflow", "body": "PiperOrigin-RevId: 391529518\r\nChange-Id: Ie3db4ae6d3c0f3dc88404e1dbdc22f7d03cbeb3b", "comments": []}, {"number": 52664, "title": "Target //tensorflow/tools/pip_package:build_pip_package failed to build", "body": "### System information\r\n\r\n- Im trying to build tensorflow to run custom code\r\n- Using macOS Big Sur 11.4\r\n- Tensorflow installed from source\r\n- Can't find Tensorflow version\r\n- Python 3.7\r\n- bazel 3.1.0\r\n- Intel HD Graphics 530 1536 MB\r\n- 16 GB 2133 MHz LPDDR3\r\n- bazel build -c opt $COPT -k //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n### Describe the problem\r\n6 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /Users/gwendolynsarapata/tensorflow/tensorflow/python/tools/BUILD:99:1 C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1): cc_wrapper.sh failed: error executing command \r\n  (cd /private/var/tmp/_bazel_gwendolynsarapata/0ae91cddfac444443cadbf8c325d1a60/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/gwendolynsarapata/opt/anaconda3/envs/test/bin:/Users/gwendolynsarapata/opt/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n \r\n...\r\n\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 249.809s, Critical Path: 49.62s\r\nINFO: 612 processes: 612 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@g-sarapata  Did you follow the instructions given here in [Build from source (macos)](https://www.tensorflow.org/install/source#macos).\r\n\r\n> Can't find Tensorflow version\r\n\r\nIf you're building from the `master` branch then the `Tensorflow` version is the latest commit hash. If you are building from any release branch then the version is the branch name.\r\n\r\nI can see your `bazel` version does not satisfy the following:\r\n\r\n```python\r\n_TF_MIN_BAZEL_VERSION = '3.7.2'\r\n_TF_MAX_BAZEL_VERSION = '3.99.0'\r\n```\r\n\r\n> Make sure to install a supported Bazel version: any version between `_TF_MIN_BAZEL_VERSION` and `_TF_MAX_BAZEL_VERSION` as specified in `tensorflow/configure.py`.\r\n\r\nYou can install bazel from here [Installing Bazel on macOS](https://docs.bazel.build/versions/main/install-os-x.html). You should have a look at [tested build configurations](https://www.tensorflow.org/install/source#macos) as the compiler's details are also missing in your issue.", "Hi @g-sarapata ! Inline with above comment , you can also check these threads for reference . [link1](https://github.com/tensorflow/tensorflow/issues/36134),[link2](https://stackoverflow.com/questions/43364264/how-to-install-tensorflow-from-source-for-mac),[link3 ](https://medium.com/gft-engineering/macbook-m1-tensorflow-on-jupyter-notebooks-6171e1f48060) .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52664\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52664\">No</a>\n"]}, {"number": 52663, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": []}, {"number": 52662, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": []}, {"number": 52661, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": []}, {"number": 52660, "title": "ausashet", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@ausashet \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52660\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52660\">No</a>\n"]}, {"number": 52659, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": []}, {"number": 52658, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": []}, {"number": 52657, "title": "Numpy 1.21.2/3 Causing Feature Column Unit Test Failures", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): latest test was with https://github.com/tensorflow/tensorflow/commit/94bc26a5f71ad14f2390def5a6ecead451f7c9bc (an Oct'25 2021 commit on main branch)\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): \"We have bazel 3.7.2 installed.\"\r\n- GCC/Compiler version (if compiling from source): gcc-7\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThis commit bumped up numpy version. https://github.com/tensorflow/tensorflow/commit/f96917ea887d1108358132c9dc9a0a0366e7d69e\r\nMany CI relies on the above file to run their nightlies. \r\n//tensorflow/python/feature_column:feature_column_test unit test failures with numpy 1.21.2 or numpy 1.21.3 with the following error message. numpy 1.19.5 was successful. \r\n\r\n[2021-10-25T12:40:03.025Z] ERROR: test_fills_cols_to_vars (__main__.LinearModelTest)\r\n[2021-10-25T12:40:03.025Z] LinearModelTest.test_fills_cols_to_vars\r\n[2021-10-25T12:40:03.025Z] ----------------------------------------------------------------------\r\n[2021-10-25T12:40:03.025Z] Traceback (most recent call last):\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/feature_column/feature_column_test.py\", line 1612, in test_fills_cols_to_vars\r\n[2021-10-25T12:40:03.025Z]     self.assertAllEqual(cols_to_vars['bias'], [bias])\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1390, in decorated\r\n[2021-10-25T12:40:03.025Z]     return f(*args, **kwds)\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 3055, in assertAllEqual\r\n[2021-10-25T12:40:03.025Z]     a = self._GetNdArray(a)\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2799, in _GetNdArray\r\n[2021-10-25T12:40:03.025Z]     return np.array(a)\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 534, in __array__\r\n[2021-10-25T12:40:03.025Z]     return np.asarray(self.numpy(), dtype=dtype)\r\n[2021-10-25T12:40:03.025Z]   File \"/home/tensorflow_ci_jenkins/workspace/workspace/workspace/tensorflow-eigen-test/bazel-ci_build-cache/.cache/bazel/_bazel_tensorflow_ci_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/feature_column/feature_column_test.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 674, in numpy\r\n[2021-10-25T12:40:03.025Z]     raise NotImplementedError(\r\n[2021-10-25T12:40:03.025Z] NotImplementedError: numpy() is only available when eager execution is enabled.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe unit test should pass. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n- Downgrade numpy to ~1.19.2 as workaround. Not sure about the root-cause and fix. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nSimply run the //tensorflow/python/feature_column:feature_column_test unit test. \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nAn example full failure log can be found in Intel's public CI page via https://tensorflow-ci.intel.com/job/tensorflow-eigen-test/492/artifact/eigen_test.log/*view*/ (subject to expiration). \r\n", "comments": ["@wei-v-wang ,\r\nCan you please take a look at this issue [1](https://github.com/tensorflow/tensorflow/issues/50204) and [2](https://github.com/tensorflow/tensorflow/issues/48747) with the similar error.It helps.Thanks!", "Thank you for the link. A lot of discussion, but I am still not quite clear about the way to fix the unit test failure.", "Hi could you please provide the minimal reproducible code.\r\nAlso, please check the attached Gist [here](https://colab.research.google.com/gist/sachinprasadhs/e30e6375fb8c829fbfa49b2bbc4e580b/feature_columns.ipynb) with Numpy 1.21.2 and Feature column example. Thanks", "Hi @sachinprasadhs , the reproducible code is the official TensorFlow unit test located here: \r\nhttps://github.com/tensorflow/tensorflow/blob/5f5af2a06251dbcb7ecdc2c571b42a9400aafede/tensorflow/python/feature_column/feature_column_test.py\r\n\r\nIf you run the following command with numpy 1.21.2 or numpy 1.21.3 \r\nbazel test  //tensorflow/python/feature_column:feature_column_test\r\n\r\nYou should be able to see the errors. \r\n\r\nPlease let me know if you insist on getting a standalone .py file. ", "Please use the following reproducer: \r\n\r\nhttps://gist.github.com/wei-v-wang/7c502d48d79d00c9839846b0062524ea \r\n\r\nRunning with numpy1.18.5 based TF: output is the following\r\nWARNING:tensorflow:From .../lib64/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:563: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.add_weight` method instead.\r\n[<tf.Variable 'linear_model/bias_weights:0' shape=(1,) dtype=float32>]\r\nListWrapper([<tf.Variable 'linear_model/bias_weights:0' shape=(1,) dtype=float32>])\r\n\r\nRunning with numpy 1.21.4 based TF: output is the following\r\n\r\nsite-packages/tensorflow/python/keras/engine/base_layer_v1.py:1702: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\r\n  warnings.warn('`layer.add_variable` is deprecated and '\r\n[<tf.Variable 'linear_model/bias_weights:0' shape=(1,) dtype=float32>]\r\n[<tf.Variable 'linear_model/bias_weights:0' shape=(1,) dtype=float32>]\r\nTraceback (most recent call last):\r\n  File \"standalone_feature_column.py\", line 58, in <module>\r\n    main()\r\n  File \"standalone_feature_column.py\", line 55, in main\r\n    my_test.reproduce()\r\n  File \"standalone_feature_column.py\", line 49, in reproduce\r\n    self.assertAllEqual(a=cols_to_vars['bias'], b=[bias])\r\n  File \"/root/test-py38-feature-column-venv/lib/python3.8/site-packages/tensorflow/python/framework/test_util.py\", line 1383, in decorated\r\n    return f(*args, **kwds)\r\n  File \"/root/test-py38-feature-column-venv/lib/python3.8/site-packages/tensorflow/python/framework/test_util.py\", line 3048, in assertAllEqual\r\n    a = self._GetNdArray(a)\r\n  File \"/root/test-py38-feature-column-venv/lib/python3.8/site-packages/tensorflow/python/framework/test_util.py\", line 2792, in _GetNdArray\r\n    return np.array(a)\r\n  File \"/root/test-py38-feature-column-venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 506, in __array__\r\n    return np.asarray(self.numpy(), dtype=dtype)\r\n  File \"/root/test-py38-feature-column-venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 646, in numpy\r\n    raise NotImplementedError(\r\nNotImplementedError: numpy() is only available when eager execution is enabled.", "Should we duplicate this to #48935 ?", "Testing on going with PR48935 on our end. \r\nThis page https://tensorflow-ci.intel.com/job/tensorflow-mkl-linux-cpu-pr/11933/console will show the test results with https://github.com/tensorflow/tensorflow/pull/48935\r\n\r\nHoping that the results still not show feature column unit failures with this PR. Let's see. \r\n", "The above test results show that the feature column unit tests still fail even with PR#48935. \r\n\r\nError message is the same as the above standalone reproducer: \r\n\r\nNotImplementedError: numpy() is only available when eager execution is enabled.\r\n", "Since, `Numpy 1.2 `compatibility require lot of changes and backward compatibility also has to be taken care of, it is already a work in progress, you can track the progress [here](https://github.com/tensorflow/tensorflow/pull/48935). \r\nClosing this as the duplicate to the above linked issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52657\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52657\">No</a>\n", "The following commit temporarily skips these failed tests: \r\nhttps://github.com/tensorflow/tensorflow/commit/2efbaddd53d21fcada1e22bad86682b52ccc4d9f ", "Yes, we had to disable those tests for now to work on the release of PYthon 3.10 wheels. The tests will have to be re-enabled though, code owners have been pinged and are working on this"]}, {"number": 52656, "title": "ValueError: as_list() is not defined on an unknown TensorShape when using dataset.from_generator on model.fit(dataset)", "body": "Tensorflow 2.4.1\r\n\r\nI'm trying to convert a generator to dataset, I'm able to create the dataset successfully and iterate through it. However when I call model.fit(dataset) I get the above error. \r\n\r\n````\r\nclass Generator(Sequence):\r\n\r\n    def __init__(self, filelist, batch_size, input_size, train=True, max_ones = 1):\r\n        self.batch_size = batch_size\r\n        self.filelist = filelist\r\n        self.input_size = input_size\r\n        self.train = train\r\n        self.max_ones = max_ones\r\n        \r\n        if int(len(self.filelist['1'])) == 0:\r\n            self.max_ones = 0\r\n            \r\n        self.shuffle()\r\n        \r\n\r\n    def __len__(self):\r\n        if int(len(self.filelist['1'])) == 0:\r\n            return 16\r\n        else:\r\n            return int(len(self.filelist['1'])) \r\n        \r\n    def shuffle(self):\r\n\r\n        print('shuffling')\r\n        self.filelist_shuffled = self.filelist.copy()\r\n       \r\n        random.shuffle(self.filelist_shuffled['1'])\r\n        random.shuffle(self.filelist_shuffled['0'])\r\n            \r\n        print(self.filelist_shuffled['0'][:10])\r\n        self.ind = dict()\r\n        self.ind['1'] = 0\r\n        self.ind['0'] = 0\r\n\r\n    def get_cropped_image(self, label):\r\n\r\n        while True:\r\n            \r\n            label = str(random.randint(0, 1))\r\n            \r\n            ind = self.ind[label]\r\n            \r\n            if label == \"1\":\r\n                ind = random.randrange(0,len(self.filelist_shuffled[label]))\r\n             \r\n            coord = self.filelist_shuffled[label][ind]\r\n            \r\n            Icrop = np.load(coord)\r\n\r\n            self.ind[label] = (self.ind[label] + 1) % len(self.filelist[label])\r\n\r\n            return cv2.resize(Icrop, self.input_size), label\r\n\r\n    def __getitem__(self, idx):\r\n\r\n        if idx == 0:\r\n            self.shuffle()\r\n\r\n        X = []\r\n        Y = []\r\n\r\n        count = 0\r\n        while count < self.batch_size:\r\n\r\n            if self.train:\r\n                I0,label_0 = self.get_cropped_image('0')\r\n                I1,label_1 = self.get_cropped_image('1')\r\n\r\n                X.append(I0)\r\n                X.append(I1)\r\n\r\n                Y.append(int(label_0))\r\n                Y.append(int(label_1))\r\n\r\n                count += 2\r\n            else:\r\n                if count < self.max_ones:\r\n                    I1,label_1 = self.get_cropped_image('1')\r\n                    X.append(I1)\r\n                    Y.append(int(label_1))\r\n                else:\r\n                    I0,label_0 = self.get_cropped_image('0')\r\n                    X.append(I0)\r\n                    Y.append(int(label_0))\r\n\r\n                count += 1\r\n        return np.array(X), np.array(Y)\r\n\r\ndef make_gen_callable(_gen):\r\n        def gen():\r\n            for x in _gen:\r\n                 yield x\r\n        return gen\r\ntrain_ = make_gen_callable(generator_train)\r\n\r\ndataset = tf.data.Dataset.from_generator(train_, (tf.float32, tf.int32))\r\n```\r\n", "comments": ["```\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    869       # This is the first call of __call__, so we have to initialize.\r\n    870       initializers = []\r\n--> 871       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    872     finally:\r\n    873       # At this point we know that the initialization is complete (or less\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    724     self._concrete_stateful_fn = (\r\n    725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 726             *args, **kwds))\r\n    727 \r\n    728     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2967       args, kwargs = None, None\r\n   2968     with self._lock:\r\n-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   2970     return graph_function\r\n   2971 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3359 \r\n   3360           self._function_cache.missed.add(call_context_key)\r\n-> 3361           graph_function = self._create_graph_function(args, kwargs)\r\n   3362           self._function_cache.primary[cache_key] = graph_function\r\n   3363 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3204             arg_names=arg_names,\r\n   3205             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3206             capture_by_value=self._capture_by_value),\r\n   3207         self._function_attributes,\r\n   3208         function_spec=self.function_spec,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    988         _, original_func = tf_decorator.unwrap(python_func)\r\n    989 \r\n--> 990       func_outputs = python_func(*func_args, **func_kwargs)\r\n    991 \r\n    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    632             xla_context.Exit()\r\n    633         else:\r\n--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    635         return out\r\n    636 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nValueError: in user code:\r\n\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\r\n        self.build(y_pred, y_true)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:318 build\r\n        self._metrics, y_true, y_pred)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1163 map_structure_up_to\r\n        **kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1258 map_structure_with_tuple_paths_up_to\r\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1258 <listcomp>\r\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1161 <lambda>\r\n        lambda _, *values: func(*values),  # Discards the path arg.\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\r\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\r\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:439 _get_metric_object\r\n        y_t_rank = len(y_t.shape.as_list())\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1190 as_list\r\n        raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n\r\n    ValueError: as_list() is not defined on an unknown TensorShape.\r\n```", "Hi @ririya ! Did you check this similar threads yet ? [link1](https://github.com/tensorflow/tensorflow/issues/41843),[link2](https://github.com/tensorflow/tensorflow/issues/32912) .Could you please provide same as a Colab gist to expedite the issue ?  Thanks!", "@mohantym Thank you for the reply. I followed the suggestion on link1 and it worked. Seems like the parameter output_shapes is not optional as the documentation says. Neither the error displayed nor the documentation suggest that the lack of this parameter is the issue. I think they should be both be improved in a later release.\r\n\r\n", " @ririya! Thanks for confirming the same , Please check in latest version 2.6 too  and feel free to close this issue if it helped. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I have the same problem. Any solution?\r\nI have multiple sequences with a dimension of: (32, 80, 3) as input, where 32 is the batch_size, 80 is the historical time steps, and 3 are the total number of characteristics", "Hi @FernandoDorado ! Could you please create a separate issue for your query ! Thanks!", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52656\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52656\">No</a>\n"]}, {"number": 52655, "title": "2.7 release notes: add link to the extension types guide", "body": null, "comments": []}, {"number": 52654, "title": "Keras Metrics Accuracy Result is not the same to Result caculated by myself", "body": "Here is My notebooks, Could someone give me a reason, And Help me get higher precision about keras metrcs. When I use the accuracy metrics in large images dataset and Train on multi gpus, The accuracy will be not correct.\r\n\r\n```\r\naccuracy1 = model.evaluate(validation_dataset)[-1]\r\n```\r\n```\r\nerror_count = 0\r\nbad_error_count = 0\r\ngood_error_count = 0\r\nbatch_count = 0\r\ncount = 0\r\nfor imgs,labels in validation_dataset:\r\n    current_len = len(imgs)\r\n    count += current_len\r\n    predictions = model.predict(imgs)\r\n    predictions_index = tf.argmax(predictions,axis=1)\r\n    labels_index = tf.argmax(labels,axis=1)\r\n\r\n    for prediction_index,label_index in zip(predictions_index,labels_index):\r\n        if prediction_index != label_index:\r\n            error_count += 1\r\n            if label_index == 0:\r\n                bad_error_count += 1\r\n            else:\r\n                good_error_count+= 1\r\n    batch_count += 1\r\n    # if batch_count == batch_num:\r\n        # break\r\n        \r\nprint(error_count,\r\nbad_error_count,\r\ngood_error_count,\r\nbatch_count)\r\n\r\naccuracy2 = (count-error_count)/count\r\n\r\n```\r\n![image](https://user-images.githubusercontent.com/31404627/138727750-9607d8b8-0bac-47a4-ba62-b052bf717bad.png)\r\n\r\nClick this link below, reproduce this issue.\r\n\r\nhttps://colab.research.google.com/drive/1xNkpQTenCav5tHg8SNO5MaXRs5UI_TNx?usp=sharing", "comments": ["@code-wangshuyi \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52654\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52654\">No</a>\n"]}]