[{"number": 18405, "title": "Reopening #9294 error in RNN tutorial", "body": "Thanks to @kevinashaw for pointing out [various](https://github.com/tensorflow/tensorflow/issues/9294) problems with the RNN tensorflow tutorial\r\n\r\nAlthough the issue was closed, as far as I can see @MarkDaoust @drpngx @ebrevdo @martinwicke \r\nthe tutorial code posted here and at TF site still has the same errors after nearly 12 months\r\n\r\nI did try making some of the modifications suggested in the thread, they don't appear to solve the issue\r\n\r\nHave I written custom code: NO\r\n\r\nOS Platform and Distribution: Windows 10; \r\nPython v. 3.5 \r\nTensorFlow installed from: Anaconda\r\nTensorFlow version 1.2.0\r\nGPU model and memory: CPU 16GB of RAM\r\nExact command to reproduce (see below)\r\n```\r\nXin =tf.random_normal((100,100))\r\n\r\nbatch_size_var  = tf.shape(Xin)[0]\r\nlstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\r\nhidden_state = lstm_cells.zero_state(batch_size_var, tf.float32) \r\ncurrent_state = lstm_cells.zero_state(batch_size_var, tf.float32)\r\n```\r\n\r\nThere was a suggestion to use  dynamic rnn . It wasnt fully explained but using  dynamic rnn renders the reference to .LSTMCell  invalid\r\n\r\nIs there another RNN tutorial or a revised version anyone can recommend?\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "information supplied\r\n", "@numericlee This is a stale issue. Since this issue opened, there were lot of tutorials and guides created on TF and keras websites. A few of the tutorials are here [Text_generation](https://www.tensorflow.org/text/tutorials/text_generation), [RNN guide](https://www.tensorflow.org/guide/keras/rnn), [text classification](https://www.tensorflow.org/text/tutorials/text_classification_rnn), [Time Series](https://www.tensorflow.org/tutorials/structured_data/time_series).\r\n\r\nI am closing this issue as this was resolved. Thanks!"]}, {"number": 18404, "title": "Forcing the symlink creation.", "body": "", "comments": []}, {"number": 18403, "title": "Forcing the symlink creation.", "body": "", "comments": []}, {"number": 18402, "title": "DnnSupport::GetVersion() is failing with 'too perfect fowarding' issue with gcc-6", "body": "A similar issue was #16309\r\nnewly added DnnSupport::GetVersion() call is causing gcc-6 compilation to fail. Using a structure instead of a tuple could workaround the issue.\r\n\r\n\r\n> INFO: From Compiling tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.cc [for host]:\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'\r\n>        return __and_<is_constructible<_Elements, _UElements&&>...>::value;\r\n>                                                                    ^~~~~\r\n> /usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n>  ^\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'\r\n>        return __and_<is_convertible<_UElements&&, _Elements>...>::value;\r\n>                                                                  ^~~~~\r\n> /usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n>  ^\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:662:419:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(const std::tuple<_Args1 ...>&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)\r\n>        return  __and_<__not_<is_same<tuple<_Elements...>,\r\n>                                                                                                                                                                                                                                                     ^    \r\n> /usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'\r\n>      struct is_convertible\r\n>         ^~~~~~~~~~~~~~\r\n> /usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n>  ^\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'\r\n>        return __and_<is_constructible<_Elements, _UElements&&>...>::value;\r\n>                                                                    ^~~~~\r\n> /usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n>  ^\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'\r\n>        return __and_<is_convertible<_UElements&&, _Elements>...>::value;\r\n>                                                                  ^~~~~\r\n> /usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n>  ^\r\n> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n> /usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'\r\n> ./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n> /usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)\r\n>        return  __and_<__not_<is_same<tuple<_Elements...>,\r\n>                                                                                                                                                                                                                                                     ^    \r\n> /usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'\r\n>      struct is_convertible\r\n>         ^~~~~~~~~~~~~~\r\n> /usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n>      }\r\n> ", "comments": ["Hi, @jlebar \r\nGetVersion() calls seem to be added recently and causing issues with gcc6+. Are there any possibilities to replace tuple with a struct?\r\n\r\nThanks", "Hi, thanks for letting me know that you're hitting this problem.\r\n\r\nI would like to understand what is the minimal change we can make to address this problem you're experiencing, so as to minimize the amount of defensive coding we have to do in TF around a compiler that is not used in any of our CI bots.  It's not clear to me that converting every tuple used inside of a StatusOr into a struct is the minimal change.\r\n\r\nI wonder if simply `return {Unimplemented(...)}` would be sufficient.  (Although you really shouldn't need that.)  I don't have access to a copy of gcc6; would you be willing to try that (or make a reproducer on gcc.godbolt.org)?\r\n\r\nI'm going to see how hard it would be to convert StreamExecutor's StatusOr into TF's StatusOr.  TF's StatusOr is more sophisticated, and may avoid this problem.  (It would be great if you could check this as well.)  If it does not avoid this problem, we can try to fix it so that it does.", "> I'm going to see how hard it would be to convert StreamExecutor's StatusOr into TF's StatusOr.\r\n\r\nAnd by that, I mean XLA's StatusOr.  TF doesn't like StatusOr.", "@jlebar I tried your first suggestion, issue is the same. \r\nI also tried using `return port::StatusOr<std::tuple<int,int,int>>(port::UnimplementedError(\r\n        \"DnnSupport::GetVersion not implemented on this platform.\"))` and it didn't change the result.\r\n\r\n[StackOverflow](https://stackoverflow.com/questions/44475317/variadic-template-issue) and [Andrzej's blog](https://akrzemi1.wordpress.com/2013/10/10/too-perfect-forwarding/) describes the issue. It is not happening for every tuple.\r\n\r\nI added a new class to workaround it which is below. Unfortunately my editor ran clang-format before saving so diff looks bigger than it should, sorry about that. In essence I added a class with 3 int members and using it instead of tuple.\r\n\r\nPlease take a look and let me know if I should issue a PR or if you have an alternative solution.\r\n\r\n```\r\ndiff --git a/tensorflow/compiler/xla/service/gpu/cudnn_convolution_algorithm_picker.cc b/tensorflow/compiler/xla/service/gpu/cudnn_convolution_algorithm_picker.cc\r\nindex d6b457a91b..28177e0abe 100644\r\n--- a/tensorflow/compiler/xla/service/gpu/cudnn_convolution_algorithm_picker.cc\r\n+++ b/tensorflow/compiler/xla/service/gpu/cudnn_convolution_algorithm_picker.cc\r\n@@ -99,9 +99,9 @@ bool ShouldIncludeWinogradNonfusedAlgo(const Shape& input_shape,\r\n                                        const ConvolutionDimensionNumbers& dnums,\r\n                                        se::StreamExecutor* stream_exec) {\r\n   // Skip this check for cudnn7 and newer.\r\n-  se::port::StatusOr<std::tuple<int, int, int>> version =\r\n+  auto version =\r\n       stream_exec->AsDnn()->GetVersion();\r\n-  if (version.ok() && std::get<0>(version.ValueOrDie()) >= 7) {\r\n+  if (version.ok() && version.ValueOrDie().maj() >= 7) {\r\n     return true;\r\n   }\r\n \r\ndiff --git a/tensorflow/stream_executor/cuda/cuda_dnn.cc b/tensorflow/stream_executor/cuda/cuda_dnn.cc\r\nindex 1dc7f991b3..c514e84b9c 100644\r\n--- a/tensorflow/stream_executor/cuda/cuda_dnn.cc\r\n+++ b/tensorflow/stream_executor/cuda/cuda_dnn.cc\r\n@@ -18,7 +18,6 @@ limitations under the License.\r\n #include <functional>\r\n #include <memory>\r\n \r\n-#include \"third_party/eigen3/Eigen/Core\"\r\n #include \"tensorflow/core/lib/core/errors.h\"\r\n #include \"tensorflow/core/util/env_var.h\"\r\n #include \"tensorflow/stream_executor/cuda/cuda_activation.h\"\r\n@@ -41,6 +40,7 @@ limitations under the License.\r\n #include \"tensorflow/stream_executor/scratch_allocator.h\"\r\n #include \"tensorflow/stream_executor/stream.h\"\r\n #include \"tensorflow/stream_executor/stream_executor_pimpl.h\"\r\n+#include \"third_party/eigen3/Eigen/Core\"\r\n // clang-format off\r\n #include \"cuda/include/cudnn.h\"\r\n // clang-format on\r\n@@ -63,10 +63,10 @@ namespace perftools {\r\n namespace gputools {\r\n \r\n using dnn::BatchDescriptor;\r\n-using dnn::FilterDescriptor;\r\n using dnn::ConvolutionDescriptor;\r\n-using dnn::PoolingDescriptor;\r\n+using dnn::FilterDescriptor;\r\n using dnn::NormalizeDescriptor;\r\n+using dnn::PoolingDescriptor;\r\n \r\n namespace cuda {\r\n \r\n@@ -215,9 +215,9 @@ CUDNN_DNN_ROUTINE_EACH(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\r\n #if CUDNN_VERSION >= 3000\r\n #define CUDNN_DNN_ROUTINE_EACH_AFTER_R3(__macro)              \\\r\n   __macro(cudnnGetConvolutionBackwardFilterWorkspaceSize)     \\\r\n-  __macro(cudnnGetConvolutionBackwardDataAlgorithm)           \\\r\n-  __macro(cudnnGetConvolutionBackwardFilterAlgorithm)         \\\r\n-  __macro(cudnnGetConvolutionBackwardDataWorkspaceSize)\r\n+      __macro(cudnnGetConvolutionBackwardDataAlgorithm)       \\\r\n+          __macro(cudnnGetConvolutionBackwardFilterAlgorithm) \\\r\n+              __macro(cudnnGetConvolutionBackwardDataWorkspaceSize)\r\n CUDNN_DNN_ROUTINE_EACH_AFTER_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\r\n #undef CUDNN_DNN_ROUTINE_EACH_AFTER_R3\r\n #endif\r\n@@ -477,11 +477,12 @@ port::Status CudnnSupport::Init() {\r\n                                    ToString(status))};\r\n }\r\n \r\n-port::StatusOr<std::tuple<int, int, int>> CudnnSupport::GetVersion() {\r\n+port::StatusOr<perftools::gputools::dnn::VersionInfo>\r\n+CudnnSupport::GetVersion() {\r\n   CudnnVersion version;\r\n   TF_RETURN_IF_ERROR(GetLoadedCudnnVersion(&version));\r\n-  return std::make_tuple(version.major_version, version.minor_version,\r\n-                         version.patch_level);\r\n+  return perftools::gputools::dnn::VersionInfo(\r\n+      version.major_version, version.minor_version, version.patch_level);\r\n }\r\n \r\n // Turns a BatchDescriptor structure into a cudnn tensor handle within a scope.\r\n@@ -1219,8 +1220,7 @@ class CudnnRnnDescriptor : public CudnnDescriptorCommon<dnn::RnnDescriptor> {\r\n       cudnnStatus_t status =\r\n           wrap::cudnnSetRNNMatrixMathType(parent_, rnn_desc_, math_type);\r\n       if (status != CUDNN_STATUS_SUCCESS) {\r\n-        LOG(FATAL) << \"could not set cudnn RNN math type: \"\r\n-                   << ToString(status);\r\n+        LOG(FATAL) << \"could not set cudnn RNN math type: \" << ToString(status);\r\n       }\r\n     }\r\n #endif\r\n@@ -2542,33 +2542,32 @@ bool CudnnSupport::DoConvolveImpl(\r\n   //   GetCudnnConvolutionForwardAlgorithm().\r\n   if (algorithm_config.algorithm().is_default()) {\r\n     // With the default algorithm, use Cudnn's heuristics.\r\n-    auto get_algorithm =\r\n-        [&](bool specify_limit) SHARED_LOCKS_REQUIRED(dnn_handle_mutex_) {\r\n-          cudnnConvolutionFwdPreference_t preference =\r\n-              specify_limit ? CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT\r\n-                            : CUDNN_CONVOLUTION_FWD_NO_WORKSPACE;\r\n-\r\n-          auto memory_limit_bytes =\r\n-              scratch_allocator == nullptr\r\n-                  ? 0\r\n-                  : scratch_allocator->GetMemoryLimitInBytes(stream);\r\n-          if (memory_limit_bytes < 0) {\r\n-            memory_limit_bytes = 0;\r\n-          }\r\n+    auto get_algorithm = [&](bool specify_limit) SHARED_LOCKS_REQUIRED(\r\n+                             dnn_handle_mutex_) {\r\n+      cudnnConvolutionFwdPreference_t preference =\r\n+          specify_limit ? CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT\r\n+                        : CUDNN_CONVOLUTION_FWD_NO_WORKSPACE;\r\n \r\n-          cudnnConvolutionFwdAlgo_t algo_to_use;\r\n-          status = wrap::cudnnGetConvolutionForwardAlgorithm(\r\n-              parent_, ToHandle(dnn_handle_), input_nd.handle(),\r\n-              filter.handle(), conv.handle(), output_nd.handle(),\r\n-              /*preference=*/preference,\r\n-              /*memoryLimitInBytes=*/memory_limit_bytes,\r\n-              /*algo=*/&algo_to_use);\r\n-          CHECK_EQ(status, CUDNN_STATUS_SUCCESS)\r\n-              << \"Unable to find a suitable \"\r\n-                 \"algorithm for doing forward \"\r\n-                 \"convolution\";\r\n-          return algo_to_use;\r\n-        };\r\n+      auto memory_limit_bytes =\r\n+          scratch_allocator == nullptr\r\n+              ? 0\r\n+              : scratch_allocator->GetMemoryLimitInBytes(stream);\r\n+      if (memory_limit_bytes < 0) {\r\n+        memory_limit_bytes = 0;\r\n+      }\r\n+\r\n+      cudnnConvolutionFwdAlgo_t algo_to_use;\r\n+      status = wrap::cudnnGetConvolutionForwardAlgorithm(\r\n+          parent_, ToHandle(dnn_handle_), input_nd.handle(), filter.handle(),\r\n+          conv.handle(), output_nd.handle(),\r\n+          /*preference=*/preference,\r\n+          /*memoryLimitInBytes=*/memory_limit_bytes,\r\n+          /*algo=*/&algo_to_use);\r\n+      CHECK_EQ(status, CUDNN_STATUS_SUCCESS) << \"Unable to find a suitable \"\r\n+                                                \"algorithm for doing forward \"\r\n+                                                \"convolution\";\r\n+      return algo_to_use;\r\n+    };\r\n \r\n     algo = get_algorithm(/*specify_limit=*/scratch_allocator != nullptr);\r\n     use_tensor_ops = true;\r\n@@ -3301,10 +3300,9 @@ bool CudnnSupport::DoFusedConvolve(\r\n #endif\r\n }\r\n \r\n-template<class T>\r\n+template <class T>\r\n DeviceMemory<T> CudnnSupport::MaybeTransformLayout(\r\n-    Stream* stream,\r\n-    BatchDescriptor* output_descriptor,\r\n+    Stream* stream, BatchDescriptor* output_descriptor,\r\n     DeviceMemory<T> backward_output_data,\r\n     std::unique_ptr<TemporaryDeviceMemory<T>>* transform_scratch) {\r\n   if (output_descriptor->layout() == dnn::DataLayout::kBatchDepthYX) {\r\n@@ -3373,8 +3371,7 @@ bool CudnnSupport::DoTransformTensor(Stream* stream,\r\n \r\n template <class T>\r\n bool CudnnSupport::DoConvolveBackwardDataImpl(\r\n-    Stream* stream,\r\n-    const FilterDescriptor& filter_descriptor,\r\n+    Stream* stream, const FilterDescriptor& filter_descriptor,\r\n     const DeviceMemory<T>& filter_data,\r\n     const BatchDescriptor& output_descriptor_in,\r\n     DeviceMemory<T> backward_output_data,\r\n@@ -3422,8 +3419,9 @@ bool CudnnSupport::DoConvolveBackwardDataImpl(\r\n \r\n   if (algorithm_config.algorithm().is_default()) {\r\n     // With the default algorithm, use Cudnn's heuristics.\r\n-    auto get_algorithm = [&](bool specify_limit) SHARED_LOCKS_REQUIRED(\r\n-        dnn_handle_mutex_) -> cudnnConvolutionBwdDataAlgo_t {\r\n+    auto get_algorithm =\r\n+        [&](bool specify_limit) SHARED_LOCKS_REQUIRED(\r\n+            dnn_handle_mutex_) -> cudnnConvolutionBwdDataAlgo_t {\r\n       cudnnConvolutionBwdDataPreference_t preference =\r\n           specify_limit ? CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT\r\n                         : CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE;\r\n@@ -3698,7 +3696,7 @@ bool CudnnSupport::DoConvolveBackwardFilterImpl(\r\n     // specify_limit will occur when we have a scratch allocator and it succeeds\r\n     // in allocating; otherwise, we'll fall back to the \"no workspace\" version.\r\n     auto get_algorithm = [&](bool specify_limit) SHARED_LOCKS_REQUIRED(\r\n-        dnn_handle_mutex_) {\r\n+                             dnn_handle_mutex_) {\r\n       cudnnConvolutionBwdFilterPreference_t preference =\r\n           specify_limit ? CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT\r\n                         : CUDNN_CONVOLUTION_BWD_FILTER_NO_WORKSPACE;\r\n@@ -4691,8 +4689,8 @@ void initialize_cudnn() {\r\n       gpu::PluginRegistry::Instance()\r\n           ->RegisterFactory<gpu::PluginRegistry::DnnFactory>(\r\n               gpu::cuda::kCudaPlatformId, gpu::cuda::kCuDnnPlugin, \"cuDNN\",\r\n-              [](gpu::internal::StreamExecutorInterface*\r\n-                     parent) -> gpu::dnn::DnnSupport* {\r\n+              [](gpu::internal::StreamExecutorInterface* parent)\r\n+                  -> gpu::dnn::DnnSupport* {\r\n                 gpu::cuda::CUDAExecutor* cuda_executor =\r\n                     dynamic_cast<gpu::cuda::CUDAExecutor*>(parent);\r\n                 if (cuda_executor == nullptr) {\r\ndiff --git a/tensorflow/stream_executor/cuda/cuda_dnn.h b/tensorflow/stream_executor/cuda/cuda_dnn.h\r\nindex 0e5368aca8..09d248f137 100644\r\n--- a/tensorflow/stream_executor/cuda/cuda_dnn.h\r\n+++ b/tensorflow/stream_executor/cuda/cuda_dnn.h\r\n@@ -46,7 +46,7 @@ class CudnnSupport : public dnn::DnnSupport {\r\n   ~CudnnSupport() override;\r\n \r\n   port::Status Init() override;\r\n-  port::StatusOr<std::tuple<int, int, int>> GetVersion() override;\r\n+  port::StatusOr<perftools::gputools::dnn::VersionInfo> GetVersion() override;\r\n \r\n   port::StatusOr<std::unique_ptr<dnn::RnnDescriptor>> createRnnDescriptor(\r\n       int num_layers, int hidden_size, int input_size,\r\ndiff --git a/tensorflow/stream_executor/dnn.h b/tensorflow/stream_executor/dnn.h\r\nindex 3c47d2c2e8..024c5787c0 100644\r\n--- a/tensorflow/stream_executor/dnn.h\r\n+++ b/tensorflow/stream_executor/dnn.h\r\n@@ -879,6 +879,19 @@ string ElementwiseOperationString(ElementwiseOperation op);\r\n // Suite of operations typically used for implementing Deep/Convolutional Neural\r\n // Nets. Note: A false return value of an operation indicates the\r\n // implementation is not available.\r\n+class VersionInfo {\r\n+ public:\r\n+  VersionInfo(int major = 0, int minor = 0, int patch = 0)\r\n+      : major_(major), minor_(minor), patch_(patch) {}\r\n+  int maj() { return major_; }\r\n+  int min() { return minor_; }\r\n+  int patch() { return patch_; }\r\n+ private:\r\n+  int major_;\r\n+  int minor_;\r\n+  int patch_;\r\n+};\r\n+\r\n class DnnSupport {\r\n  public:\r\n   DnnSupport() {}\r\n@@ -887,7 +900,7 @@ class DnnSupport {\r\n   virtual port::Status Init() = 0;\r\n \r\n   // Gets the version of the backing library, as a {major, minor, patch} tuple.\r\n-  virtual port::StatusOr<std::tuple<int, int, int>> GetVersion() {\r\n+  virtual port::StatusOr<VersionInfo> GetVersion() {\r\n     return port::UnimplementedError(\r\n         \"DnnSupport::GetVersion not implemented on this platform.\");\r\n   }\r\n@@ -1865,10 +1878,10 @@ class DnnSupport {\r\n   //  bottom_pad: Amount to pad the input at the bottom (high Y).\r\n   //  output_data: un-owned device memory region in which to place the\r\n   //    padded result.\r\n-  virtual bool DoXYPad(Stream* stream, const dnn::BatchDescriptor &dimensions,\r\n-                       const DeviceMemory<float> &input_data,\r\n-                       int64 left_pad, int64 right_pad, int64 top_pad,\r\n-                       int64 bottom_pad, DeviceMemory<float> *output_data) = 0;\r\n+  virtual bool DoXYPad(Stream* stream, const dnn::BatchDescriptor& dimensions,\r\n+                       const DeviceMemory<float>& input_data, int64 left_pad,\r\n+                       int64 right_pad, int64 top_pad, int64 bottom_pad,\r\n+                       DeviceMemory<float>* output_data) = 0;\r\n \r\n   // Extracts a slice of the input in the X and Y dimensions. The feature_map\r\n   // dimension is unchanged.\r\n@@ -1885,10 +1898,10 @@ class DnnSupport {\r\n   //  bottom_trim: Amount to cut off the input at the bottom (high Y).\r\n   //  output_data: un-owned device memory region in which to place the\r\n   //    padded result.\r\n-  virtual bool DoXYSlice(Stream* stream, const dnn::BatchDescriptor &dimensions,\r\n-                    const DeviceMemory<float> &input_data,\r\n-                    int64 left_trim, int64 right_trim, int64 top_trim,\r\n-                    int64 bottom_trim, DeviceMemory<float> *output_data) = 0;\r\n+  virtual bool DoXYSlice(Stream* stream, const dnn::BatchDescriptor& dimensions,\r\n+                         const DeviceMemory<float>& input_data, int64 left_trim,\r\n+                         int64 right_trim, int64 top_trim, int64 bottom_trim,\r\n+                         DeviceMemory<float>* output_data) = 0;\r\n \r\n   // Grows the input tensor by replicating the X and Y dimensions. The batch and\r\n   // depth/feature_map dimensions are unchanged. Currently, the input tensor is\r\n```", "It sounds like you just want this fixed.\r\n\r\nOn my end, I really do not want to convert this tuple into a struct if there are alternatives.  I would much rather look into structural fixes, so we don't have to waste time on this problem in the future.\r\n\r\nI'm hopeful that it may be possible to fix xla::StatusOr so it doesn't have this problem.  If you can't come up with a fix there, I will consult with the C++ experts on my end, but it may take some time.  (It's possible that xla::StatusOr will Just Work.  In any case I'm going to get rid of SE's StatusOr as my first task here.)", "Yes, we are adding new features to TF and usually need to work on master. There are a few changes that went in recently that is fixing other issues that was blocking us. I can branch from before your changes and cherry-pick the fixes but that may cause bigger headaches when we merge back. If it takes you a long time to fix this, I might have to do this anyways. But I don't think the issue is StatusOr, it is template tuple return value optimization and thus will come up in other places as well. If I understood the discussion in the links above correctly, it looks like a gotcha in standard.", "I have not yet fully digested these blog posts, but the StreamExecutor StatusOr has known problems (read: undefined behavior) with std::is_constructible, which I see appearing in these errors.  There's tons of complexity in xla::StatusOr to avoid this fail.\r\n\r\nIf you're willing, it would be great if you could test whether this happens with xla::StatusOr, and even better if you could produce a minimal-ish reproducer using gcc.godbolt.org that shows the build working with clang and failing with gcc6.  I tried and was unable to.", "I've checked in a change to get rid of StreamExecutor's StatusOr.  That will make its way upstream in our next uplift to OSS -- I dunno how often those happen.", "Even after e7b1ab049d22119c7b649046be853ea88120f27a, which got rid of StreamExecutor's StatusOr, I am still running into this problem.\r\n\r\nI do not know C++ well enough to understand what the problem is, but if using a struct instead of a tuple fixes this, IMO we should do that for now, and fix the underlying problem with xla::StatusOr once we know how. @jlebar, what do you think of using a struct for now?", "Thanks a lot for testing, @reedwm.\r\n\r\nI hear that this is frustrating, but if TF does not have buildbots for gcc 6.x, we're going to keep breaking it; as observed, this is not the first breakage we've seen.  That is a waste of everyone's time.\r\n\r\nI want to fix this the right way.  There are various Right Ways -- maybe the Right Way is to change to a struct.  But I certainly don't yet understand this problem well enough yet.  Now that I know that my StatusOr change didn't fix things, I'm asking for help from people more expert than I.  But it's EuroLLVM soon, so we're pretty short-staffed.\r\n\r\nI appreciate that in the meantime, your build is broken without a cherry-pick.  At the risk of being sadistic: That's kind of WAI from my perspective.  If we don't leave your build broken for a time, then nobody has an incentive to shout and get a gcc 6.x buildbot set up -- or to switch to a supported compiler like clang (which you can do today, aiui).  If we do neither of those things, we'll continue to be in this bad situation where your builds break with some frequency, which none of us is happy with.", "We should fix the current breakage on gcc6 with struct while Justin is working on the right fix with StatusOr. struct is better in this case anyway.\r\n\r\nsamikama@, if you have that ready, feel free to issue a PR. reedwm@ can review that. Thanks!\r\n", "@jlebar  @zheng-xq, I created PR#18434 that uses a class instead of tuple.\r\n\r\nThanks,\r\nSami\r\n"]}, {"number": 18401, "title": "[Intel MKL] Preventing MKL_DNN from getting built for non-mkl builds", "body": "", "comments": []}, {"number": 18400, "title": "Using boosted trees without an estimator", "body": "Have I written custom code : NO\r\nOS Platform and Distribution : CentOS\r\nTensorFlow installed from : Sources\r\nTensorFlow version : r1.8\r\nBazel version : 0.11\r\nCUDA/cuDNN version : 9.1/7.0\r\nGPU model and memory : GTX 1080 Ti\r\nExact command to reproduce : N/A\r\n\r\nAt the moment is it  possible to use the TensorFlow implementation of boosted trees without invoking the concept of an Estimator ?\r\n[Examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/boosted_trees) , demonstrate its usage using estimator. \r\n\r\nCan it be used as just another node in a TensorFlow graph ? ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 18 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@yk5 Here's some feedback on boosted trees. PTAL", "@sshrdp @nataliaponomareva please comment if not a recommended way:\r\n\r\nHi, for the asked `contrib.boosted_trees` library, tree model class is public so that you could do similar to what's seen in [`model_fn.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/estimator_batch/model.py#L89) -- creating an object by hand and calling relevant functions - `train()` / `predict()`.\r\n\r\nFor the new boosted_trees library that's migrated into core ([link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/canned/boosted_trees.py#L701)), we mainly provide only Estimator API but keep the model function (`_bt_model_fn`) as internal, until we're sure what'd be the best API exposed to users. Thus you could play around with the model fn out of the Estimator API we provide though, but please note that the function interface is subject to changes.\r\n\r\nThanks,\r\nYounghee", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "In general, as yk5 stated, using an estimator is the easiest way, however nothing prevents you (at least in a contrib version) from using the methods from gbdt_batch.py (contrib version) directly. However keep in mind that many things are hidden from you - sessions, head, loss calculation, which you will have to maintain yourself if you put it as a node in a graph. Also take a look at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/estimator_batch/dnn_tree_combined_estimator.py - this gives an example on how to create a graph that does a neural net and a gdbt, may be you can get some inspiration there", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18399, "title": "Forcing the symlink creation.", "body": "", "comments": []}, {"number": 18398, "title": "Expose Scaffold.default_local_init_op as a public static method.", "body": "As discussed offline with @martinwicke, removes the underscore in all repo usages. Fixes #18242 ", "comments": ["Can you run the api_compatibility_test and do what it says when it fails (it will fail)?", "Done.", "Friendly ping.", "Done.", "Sorry about that. Ran lint this time too to make sure.", "Thanks!"]}, {"number": 18397, "title": "Java wrapper floods temp dir with copies of extracted native library", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: None\r\n\r\n### Describe the problem\r\n\r\nI've been working on a Java application that uses TensorFlow. I launched it thousand times - unit tests, debugging sessions, etc. And at some point I discovered I had 8 GB of tensorflow_jni.dll copies in my Temp directory.\r\n\r\nApparently `deleteOnExit()` is not enough to cleanup the extracted native library ([NativeLibrary.java:150](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java#L150)). Not on Windows at least. It appears DLL is still loaded when the deletion is attempted. So the deletion fails and the DLL is left behind.\r\n\r\nA better approach would be to use semi-static path for library extraction rather than fully random.\r\nIn such case the library could be deleted or re-used upon the next application run.\r\n\r\nI would suggest to use a target folder name like this:\r\n```\r\nFile tmp = new File(System.getProperty(\"java.io.tmpdir\"));\r\nFile dir = new File(tmp, \"tensorflow-\" + TF_VERSION + '-' + System.getProperty(\"user.name\").hashCode());\r\n```\r\n\r\nAnd then check if the folder and files exist already upon startup. And either delete them and extract again (better security) or just call `System.loadLibrary()` directly.\r\n\r\nYou could still keep using `deleteOnExit()`. When it works properly the only copy of the library will not be left laying on the disk after JVM shutdown.\r\n\r\nA similar approach is used by other native libraries handling frameworks. For example, in JNA project.\r\nSee https://github.com/java-native-access/jna/blob/master/src/com/sun/jna/Native.java", "comments": ["Thanks for the report.\r\n\r\nTo be extra sure, the name of the directory should probably be based on the checksum of its contents, which will be a little harder to engineer. We don't want to use a fixed directory otherwise we could run into interference between programs compiled against different versions of the library.\r\n\r\nI don't believe this problem occurs on Linux/Mac though. I don't have enough experience with Windows - is there something about the use of `System.loadLibrary()` that causes deleting the file to fail?\r\n\r\nMarking this as \"Contributions Welcome\" in case someone with a stronger understanding of the JVM on Windows can suggest a clean fix, or if someone wants to take on the fixed directory (in which case I would strongly recommend that the directory name be a function of the _contents_ of the `.jar` file being extracted and not a fixed string).", "(CC @saudet as well - in case he has some insights)", "It's not about `System.loadLibrary()` but about the way files are handled in Windows.\r\nOn Linux (and I suppose Mac) opened files can be deleted (`unlink()`-ed). On Windows - not.\r\nAnd when JVM processes `deleteOnExit`s DLLs are still loaded into JVM address space, i.e. the files are still open.\r\nThere is a hacky way of using a dedicated separate class loader for loading DLLs. And then calling `System.gc()` after null-ing the class loader reference. It helps ... sometimes.\r\n\r\nI included a version of the Tensorflow into the directory name in the sample code above. Do you think it won't be enough?\r\nAlso each user should have his own folder to avoid access rights conflicts. Hence the `System.getProperty(\"user.name\").hashCode()` part. Hash code is used to avoid problems in case user name contains national symbols or spaces.", "Thanks for the info. The version string itself won't be enough, it doesn't capture things that affect the build of the native libraries (like whether it's the CPU or GPU version, or if there are others that package differently built binaries such as with/without AVX support etc.) - hence my suggestion of using the checksum of the resource contents.", "@asimshankar Yes, I do. That's been fixed a long time ago in JavaCPP! :)\r\n\r\nThe problem is that on Windows it's not possible to delete a DLL after it's been loaded. We need to end the process, and let some other process do the clean up. I used to have a hack for that in JavaCPP but switched to using a cache instead, because it wouldn't work with JavaFX, among other things: https://github.com/bytedeco/javacpp/issues/60\r\n\r\n@sabi0 So, one way to work around this is by using the JavaCPP Presets for TensorFlow:\r\nhttps://github.com/bytedeco/javacpp-presets/tree/master/tensorflow\r\nYou'll get access to the C++ API from Java, but we can keep using the official Java API as well.\r\n\r\nA build for Windows has also been released:\r\nhttps://github.com/bytedeco/javacpp-presets/issues/111#issuecomment-380322141\r\n\r\n/cc @agibsonccc", "@saudet Thanks. I will have a look at JavaCPP.\r\n\r\n@asimshankar It is possible to use fully random name for DLL (i.e. not bother with content checksum) as long as the folder name is predictable. Here is how it could work:\r\nFolder name could be like this:\r\n```\r\nFile dir = new File(tmp, \"tensorflow-\" + System.getProperty(\"user.name\").hashCode());\r\n```\r\nExtracted file names could be fully random, e.g. `tf_jni-2387168.dll`. But when such file is extracted another \"marker\" file is created - `tf_jni-2387168.dll.lock`.\r\nThe latter one is immediately registered with `deleteOnExit()`. JVM will not have problems deleting it on any platform.\r\n\r\nAnd then upon start the application scans the user folder and deletes any files that don't have matching `.lock` files. And then proceeds to extract the resources (under random names).\r\nThis might still left some files in Temp on Windows (when user stops using TF). But would help to avoid copies of resources piling up.", "Extracting DLLs every time a new JVM is launched is inefficient though. For\nsomething as big as TensorFlow it takes a few seconds. Consider also that\nframeworks like Hadoop or Spark tend to launch multiple JVMs during\nexecution. That's another reason JavaCPP uses a cache. BTW, JNA is not\nperformance conscious so it's not a good reference if one is interested in\nefficiency.\n", "Thanks @saudet \r\n\r\nCaching seems very reasonable. Though, again, the caching should handle different versions/configurations correctly. So, some form of identification (like the checksum of the file contents) should be included, right? (Seems like JavaCPP uses maven coordinates for the \"cache key\"?)", "Yes, there needs to be some kind of system for that. JavaCPP doesn't use directly Maven coordinates because they are not available when running from an uber JAR, for example, as required by Spark, or just for a standalone application. Instead, it uses the filename of the JAR file itself plus of the path to the files inside it, which happen to contain the Maven coordinates when loaded with it.\r\n\r\nBTW, including additional resources such as header files in the JAR file and extracting them to a cache like this also allows C++ libraries to link with it, not just Java libraries. That's what is happening with, for example, Caffe depending on OpenCV, OpenBLAS, and HDF5 here: https://github.com/bytedeco/javacpp-presets/blob/master/caffe/pom.xml#L17-L37  Though, in the case of TensorFlow, I'm assuming everything can be managed with Bazel...", "@MarkDaoust This one also could be considered \"fixed\" since we're now using JavaCPP for https://github.com/tensorflow/java", "Thanks. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18397\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18397\">No</a>\n"]}, {"number": 18396, "title": "Fix docker 1.8 symlink for devel containers", "body": "", "comments": []}, {"number": 18395, "title": "Adding the python symlink command for devel packages too.", "body": "", "comments": []}, {"number": 18394, "title": "Feature Request: Early Stopping with the tf.estimator", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Pip\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9\r\n- **GPU model and memory**: NVIDIA K80\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI would love for there to be a SessionRunHook implementation in tensorflow that implements early stopping. Now that `tf.contrib.learn` is being officially deprecated, the existing way that I did early stopping (using a ValidationMonitor) is no longer an option. This seems like a super important feature to have.\r\n\r\nThe docs indicate in several places that you can simply extend a SessionRunHook to do this, and that seems reasonable. I think that having a standard way to do this would be super useful to lots of users, perhaps even directly built into TrainSpec.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nN/A", "comments": ["/CC @martinwicke, what do you think of this proposal?", "@ispirmustafa @salehay \r\n\r\nWe have an early stopping hook somewhere, no? Can we move it to TensorFlow?", "Yes we have one in TFX, @ispirmustafa let's chat about moving to core.", "Great, thanks! Do you guys have any approximate timeline for when this could happen? Just trying to decide whether to hack something together ourselves in the meantime.", "My understanding at the moment (from having tried to implement this as a SessionRunHook) is that when using `train_and_evaluate`, which I believe is the canonical way to use an Estimator (and is how SageMaker does it), you cannot use a `run_context.request_stop()` call to actually stop training.\r\n\r\nI know this is a larger issue with how `train_and_evaluate` works, but are there plans to be able to use any sort of Early Stopping hook w/in that framework?\r\n\r\nThanks!", "Interesting, is there any reason that we can\u2019t use a similar logic as StopAtStepHook? Where, rather than checking the step number every time, it runs validation every n steps and then uses the same stop mechanism? \r\n", "That works for the single worker case, but with multiple workers, all of them need to know to stop running. We have an implementation of this, basically, we have the eval worker check if it wants to stop after running eval. If it wants to stop, it sets a REQUEST_STOP variable on the parameter server. The other workers run a Hook which checks this variables and stop if a stop has been requested.", "Ok great, would be great to get that merged! ", "Seconded, this feature would be a great addition.", "Nagging Assignee @ispirmustafa: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@salehay @martinwicke just wanted to check in on this - any update on getting this from TFX into tensorflow?", "@xiejw could you please take a look?", "It looks like in the `tf.estimator.train_and_evaluate` code, there is a line at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/training.py#L432\r\nwhere we instantiate a `_TrainingExecutor`:\r\n\r\n``` python\r\nexecutor = _TrainingExecutor(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\r\n```\r\nHowever, `_TrainingExecutor` also has the optional argument `continuous_eval_listener`, which we could presumably use to track the eval result and do early stopping. Is there a reason `train_and_evaluate` doesn't let us use this argument? It doesn't look like there are any other instances of `_TrainingExecutor` anywhere in the Tensorflow codebase.", "Nagging Assignees @xiejw, @ispirmustafa: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@goutham kindly volunteered on providing TFX early stopping utils in TensorFlow.", "Nagging Assignees @goutham, @ispirmustafa: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Any update on this @goutham?", "@ankitvgupta Under code review internally. ETA: < 1 week from now.", "Fantastic! I appreciate the update @goutham.", "Finally! \ud83c\udf89\r\n\r\nEarly stopping is a crucial component in a proper DL library and something I sorely miss from Keras. Having this in `tf.estimator` would greatly simplify https://github.com/tensorflow/tensorflow/issues/16576 and put the final nail in the coffin regarding https://stackoverflow.com/questions/47137061/early-stopping-with-tf-estimator-how", "Excited about this too! We have been using home-brewed versions of early stopping with combinations of hooks and environmental variables but they have proven brittle to changes in the estimator API. A more robust solution is very welcome.", "It's in: 90e66f2\r\n", "Awesome, thanks @goutham and team!", "Should we expect this to be included in the final release of TF 1.9?", "No. The cutoff for 1.9 is long past. It will be in 1.10.\n", "Makes sense, thanks.", "Also to clarify, you mention that this implementation sets a variable to request a stop, and then other workers check that variable. I can see where the PR sets a variable called STOP. \r\n\r\nWhere is the logic for other variables to check that the STOP variable is set? Is that being separately merged?", "@ankitvgupta It's part of the same PR. If you look at [early_stopping.py](https://github.com/tensorflow/tensorflow/blob/90e66f2aa1015496c8f8e9be573ef83f542a2ad0/tensorflow/contrib/estimator/python/estimator/early_stopping.py) implementation, there are two hooks `_StopOnPredicateHook` and `_CheckForStoppingHook`. The former is used in the chief and sets the variable when early stopping condition is met, while the latter on workers and checks if the variable is set. Did you notice any problems?", "Ah yes, that makes sense. I was testing this on a single GPU a local training configuration. If I'm only using the local case, should I manually add a second hook which is the `_CheckForStoppingHook`?", "I think that the run_local case of train_and_evaluate has to be modified for that to work. Here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/estimator/training.py#L634", "I don't think you should have any problems running in local mode. It is fine to not have `_CheckForStoppingHook` as it is to help with the distributed case. Can you elaborate on what you noticed? I couldn't reproduce any problems when running locally on my machine.", "Interesting, when I run locally, it prints the \u201crequesting stop\u201d message, runs eval/export but then train_and_evaluate just continues training. I assumed this is because of the \u201cwhile True\u201d in the run_local method.\r\n\r\nTo be clear, I\u2019m using TF 1.9, and copied that early stopping hook code directly (since it\u2019s not releasing until 1.10). ", "Also, to clarify, this works fine when I use the `train()` method of an estimator, but does not work when I use `tf.estimator.train_and_evaluate()`", "run_local was also updated to work well with train_and_evaluate. See 3edb609. This should be in 1.10. So, if you really want to use early stopping before 1.10 release, I suggest also patching in this PR. But I recommend waiting for 1.10 so that you don't have more trouble.", "Makes sense! I'll wait for 1.10.", "@ankitvgupta Or tf-nightly pip / docker images to check that all it is in shape before 1.10 it is finally released.", "Hi @goutham, I tried this out on tf-nightly-gpu, and ran into one small bug. \r\n\r\nI used `tf.estimator.train_and_evaluate`, and added the new early stopping hook as one of the train hooks. It looks like it checks for early stopping right after the first checkpoint (step 0), and as a result finds that there is no eval directory made yet since the first eval hasn't happened yet. Specifically, I get this error message (replacing MY_MODEL_DIR with the actual directory)\r\n\r\n```tensorflow.python.framework.errors_impl.NotFoundError: $MY_MODEL_DIR/eval; No such file or directory```\r\n\r\nIn the new version of `run_local`, it looks like evaluation occurs [via a CheckpointSaverListener](https://github.com/tensorflow/tensorflow/blob/3edb609926f2521c726737fc1efeae1572dc6581/tensorflow/python/estimator/training.py#L685), so eval should occur right after the checkpoint is saved. However, it looks like the early stopping hook is running before that happens. \r\n\r\nI believe there is a min_steps parameter, but it appears to be checking for eval stats even if I set that to be high. ", "@ankitvgupta I cannot repro this behavior on my linux workstation, unfortunately. Which OS do you use? Can you provide a fuller stacktrace (the part only tracing through TF code)? That would help.\r\n\r\nWe access the eval directory in the function `_summaries` [here](https://github.com/tensorflow/tensorflow/blob/6c528feaf820bdde820833ad24e05167adb5daa7/tensorflow/contrib/estimator/python/estimator/early_stopping.py#L397). If the directory does not exist, `gfile.Glob` returns an empty list, so no error should be raised.", "@ankitvgupta, I had the same confusion. Temporary fix is to explicitly create the directory:\r\n\r\n```py\r\nestimator = tf.estimator.Estimator(model_fn, model_dir)\r\nos.makedirs(estimator.eval_dir())  # TODO This should not be needed?\r\n# Proceed as usual.\r\n```", "Yep that\u2019s what I did to fix it too @carlthome.\r\n\r\nI\u2019ll try to send a minimal example of this for the TF team. ", "I discovered that in some environments, `gfile.Glob` behaves differently from python [`glob.glob`](https://docs.python.org/2/library/glob.html). This is definitely something to be fixed in `gfile.Glob` but for now I will send out a simple fix in early_stopping library to resolve this.", "Fix is in: 69f229a\r\n(this has missed the boat on 1.10 though)", "Appreciate the help!", "I've been experimenting with the early stopping hooks for estimators recently introduced in TensorFlow 1.10, however, it seems like it's not doing anything.\r\n\r\nHere's what I have written:\r\n```\r\nclassifier = tf.estimator.Estimator(\r\n    model_fn=model_fn, \r\n    model_dir=f\"./artifacts/{file_time}/checkpoints/\")\r\n\r\nos.makedirs(classifier.eval_dir())\r\n\r\nearly_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(\r\n    classifier,\r\n    metric_name=\"loss\",\r\n    max_steps_without_decrease=100)\r\n\r\nclassifier.train(\r\n    input_fn=lambda:train_input_fn(file_time),\r\n    steps=40000,\r\n    hooks=[early_stopping]\r\n)\r\n```\r\nThe training starts, but the training is never stopped by the hook, instead, it continues to train until the steps defined in `classifier.train`. When it's logging to the console, I can see that the loss hasn't decreased any further. I've also tried setting the `run_every_steps` to 100. Any ideas of what I may be doing wrong here?", "You'll want to use train_and_evaluate, so that eval runs every once in a while. The hook just reads the eval metrics and stops when the condition is met. So, if you're not running eval, it'll not stop. Relevant line: https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/contrib/estimator/python/estimator/early_stopping.py#L361", "@ankitvgupta Ah, that makes sense. Thanks! ", "I've had a problem with the the `stop_if_no_decrease` hook and I think I've found the problem in the code I changed below. \r\n\r\nThe problem is that the python `dict.items()` method doesn't return entries in the order they went in. The indeterminate ordering means that the hook can trigger when it comes across any eval checkpoints that are more than max_steps apart without having come across a better eval inbetween. \r\n\r\nTo fix it, I keep the best eval as well as the most current and check how far apart they are.\r\n\r\n```diff\r\ndiff --git a/tensorflow/contrib/estimator/python/estimator/early_stopping.py b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\nindex af4855e..194422b 100644\r\n--- a/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\n+++ b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\n@@ -362,6 +362,8 @@ def _stop_if_no_metric_improvement_hook(\r\n\r\n     best_val = None\r\n     best_val_step = None\r\n+    current_val = None\r\n+    current_step = None\r\n     for step, metrics in eval_results.items():\r\n       if step < min_steps:\r\n         continue\r\n@@ -369,13 +371,16 @@ def _stop_if_no_metric_improvement_hook(\r\n       if best_val is None or is_lhs_better(val, best_val):\r\n         best_val = val\r\n         best_val_step = step\r\n+      if current_val is None or operator.gt(step, current_step):\r\n+        current_val = val\r\n+        current_val_step = step\r\n+    if current_val is not None:\r\n+      if current_step - best_val_step >= max_steps_without_improvement:\r\n+        tf_logging.info(\r\n+            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\r\n+            'to max steps (%s) configured for early stopping.',\r\n+            increase_or_decrease, metric_name, current_step - best_val_step,\r\n+            max_steps_without_improvement)\r\n+        return True\r\n-      if step - best_val_step >= max_steps_without_improvement:\r\n-        tf_logging.info(\r\n-            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\r\n-            'to max steps (%s) configured for early stopping.',\r\n-            increase_or_decrease, metric_name, step - best_val_step,\r\n-            max_steps_without_improvement)\r\n-        return True\r\n     return False\r\n\r\n```", "@Carl-Jensen-Bose Thanks for pointing it out. `read_eval_metrics` should have returned an `OrderedDict` (sorted by global_step key) instead of `dict`. Have a fix out for review.", "@goutham Even better. Thanks!", "Fixed in b9e6bbc.", "SInce it looks like one or two of the bug fixes mentioned here didn't make it into the 1.11 release I've patched the latest version of `early_stopping.py` so that it can be used standalone (this version uses the public API rather than the internal module names) https://gist.github.com/ed-alertedh/2ea554d9a17a67c87f00cbd617b1ff32\r\n\r\nI find this easier than patching the installed package and less risky than switching to a nightly build. Seems to be working in TF 1.10, presumably should be OK with 1.11 too.", "@goutham Is this fix out in 1.12?", "mark", "Does anyone know if this has been taken care of in tf 2 ?", "@plaffitte what are you referring to? I don't think there are open issues (at least not from this thread).", "@martinwicke Sorry for not being clear, as far as I am aware the only option out there to achieve early stopping in tf2 is by using `tf.estimator.experimental.stop_if_no_decrease_hook` but I was wondering if this is stable and working and if there was another solution to this.", "@karmel to keep me honest.\n\nIt should work and it is stable in a sense that we're not planning to\nremove it or change it. You can also always write your own hook with custom\nbehavior.\n\nOn Thu, Apr 16, 2020 at 9:38 AM Pierre Laffitte <notifications@github.com>\nwrote:\n\n> @martinwicke <https://github.com/martinwicke> Sorry for not being clear,\n> as far as I am aware the only option out there to achieve early stopping in\n> tf2 is by using tf.estimator.experimental.stop_if_no_decrease_hook but I\n> was wondering if this is stable and working and if there was another\n> solution to this.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18394#issuecomment-614762907>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAEM57O5YJ4PCTTKSC3PBILRM4YAHANCNFSM4EZ3YZGA>\n> .\n>\n", "@martinwicke Ok I understand, the reason I was asking is because it doesn't seem to be doing anything in my case and since it's in the experimental module I was wondering if it was working at all.\r\nAlso, in general, I find it very weird that tensorflow does not have a built-in early stopping mechanism, or something more accessible as a class in the main package. ", "As [much of the efforts](https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/-kdC7VVkyco) are put over Keras as the highlevel API you can alternatively use https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/callbacks/EarlyStopping", "@bhack Yes I understand that Keras is now the preferred high-level API, but I am getting acquainted with Kubeflow and going over the tutorials which all use the Estimator API, which is why I need to stick with it for the moment", "@plaffitte Yes I know but stuffs are getting in sync:\r\nhttps://github.com/kubeflow/examples/issues/774\r\nhttps://github.com/kubeflow/examples/issues/773", "@bhack Ah awesome thank you!"]}, {"number": 18393, "title": "label_image.py  Example:  Show ONLY results Higher than 75 % ?", "body": "Hello,\r\n\r\ncan Sombody please explain how to change `label_image.py` from the [Example Codes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py)  \r\nso its only Shows the Result (Name,Score) if the Score is Higher than 75 % , else  print \".... \" \r\n\r\nWould be very Helpfull.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18392, "title": "Replace print with logging", "body": "", "comments": []}, {"number": 18391, "title": "Adding the python symlink command for devel packages too.", "body": "", "comments": []}, {"number": 18390, "title": "Update version for 1.8.0rc0", "body": "", "comments": []}, {"number": 18389, "title": "Release notes for r1.8", "body": "", "comments": []}, {"number": 18388, "title": "Branch 192309109", "body": "", "comments": []}, {"number": 18387, "title": "Make custom_graph_optimizer_registry header-only", "body": "Adds the implementation as a dependency of libtensorflow_framework.so so its symbols are available to shared objects which want to register optimizers. No other rules include it, so shared objects won't accidentally get their own version of the registry.\r\n\r\n(CC @samikama )", "comments": []}, {"number": 18386, "title": "Fix incorrect math equation renderings broken by backtick", "body": "This PR is to fix incorrect math equation renderings for markdown.\r\n \r\nThe issue is that \"```\" or \"`\" backtick should not be added when mathjax quote is used (\"\\(\" or \"$$\").", "comments": ["@jhseu I didn't quite understand what the below failed tests info mean, I just fix some doc strings which should not expect to cause such failures. Could you please help kindly have a look here :)", "The failed test is timeout of `common_runtime_ring_reducer_test` seems to be unrelated. @jhseu could u pls kindly take a look what's going wrong here?", "It's unrelated. Merging."]}, {"number": 18385, "title": "Add missing link to the eager guide.", "body": "", "comments": ["just noticed... s/tensorflow/TensorFlow", "> s/tensorflow/TensorFlow\r\n\r\nfixed", "Please pull and rebase to fix build failure on Windows Bazel", "Hi meteorcloudy@.\r\n\r\nI'm not sure what is causing that \"Windows Bazel\" build to fail. But as far as I can tell this patch is based on the current tip of r1.7: \r\n\r\n```\r\ngit log --oneline --graph --decorate\r\n```\r\n\r\n```\r\n* 8a2c8409c7 (HEAD -> MarkDaoust-patch-1, upstream/MarkDaoust-patch-1) Capitalization.\r\n* cf65769bef Add missing link to the eager guide.\r\n*   99322a92bf (upstream/r1.7, r1.7) Merge pull request #18137 from annarev/update_release_notes\r\n|\\  \r\n| * 57de6ef5b1 Also adding a note about Cuda supported version\r\n```\r\n99322a92 is the current top commit of the r1.7 branch. \r\n\r\nThe test logs seem to say that [bazel is not installed](https://source.cloud.google.com/results/invocations/98ea2497-d390-42af-a3a7-6dac17d82843/targets/%2F%2Ftensorflow%2Ftools%2Fci_build%2Fbuilds:gen_win_out/log).\r\n", "The Bazel Presubmit is set up recently. It needs some fixes that's not\nincluded in r1.7. I believe rebase from HEAD should fix the \"Bazel is not\ninstalled\", because the build _tf_windowd.sh should set the correct PATH\nvalue.\n\nOn Tue, Apr 10, 2018, 7:43 PM Mark Daoust <notifications@github.com> wrote:\n\n> Hi meteorcloudy@.\n>\n> I'm not sure what is causing that \"Windows Bazel\" build to fail. But as\n> far as I can tell this patch is based on the current tip of r1.7:\n>\n> git log --oneline --graph --decorate\n>\n> * 8a2c8409c7 (HEAD -> MarkDaoust-patch-1, upstream/MarkDaoust-patch-1) Capitalization.\n> * cf65769bef Add missing link to the eager guide.\n> *   99322a92bf (upstream/r1.7, r1.7) Merge pull request #18137 from annarev/update_release_notes\n> |\\\n> | * 57de6ef5b1 Also adding a note about Cuda supported version\n>\n> 99322a9\n> <https://github.com/tensorflow/tensorflow/commit/99322a92bfcc16191b7e68774d4964866c1f1fea>\n> is the current top commit of the r1.7 branch.\n>\n> The test logs seem to say that bazel is not installed\n> <https://source.cloud.google.com/results/invocations/98ea2497-d390-42af-a3a7-6dac17d82843/targets/%2F%2Ftensorflow%2Ftools%2Fci_build%2Fbuilds:gen_win_out/log>\n> .\n>\n> \u2014\n> You are receiving this because you commented.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/18385#issuecomment-380187247>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AD-nti8p1cQwDdBOx7QWzX2kNamrPAXiks5tnO9fgaJpZM4TOhjO>\n> .\n>\n"]}, {"number": 18384, "title": "tf.decode_csv New Feature Request option to remove leading/trailing whitespace on text fields", "body": "tf.decode_csv currently allows leading and trailing spaces with int or float fields and quietly strips the whitespace off, see: https://www.tensorflow.org/api_docs/python/tf/decode_csv\r\n \r\nIt would be really nice if the text fields could also have the leading/trailing whitespace stripped off. The embedded whitespace in a text field or sentence does need to be left intact, although it might be useful to compress it down to a single space between words. \r\n \r\nPandas.read_csv has an option skipinitialspace to strip leading/trailing whitespace, which defaults to False. I would suggest a similar option for tf.decode_csv for text fields. If you wanted to aggressively deploy the option, you could default it to True.\r\n\r\nCurrently I remove whitespaces via a call to tf.py_func and a small rexexp function. There is also tf_regex_replace which works.\r\n \r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 7\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0 / cudnn64_7\r\n- **GPU model and memory**: Nvidia GeForce GTX660, 2GB RAM\r\n- **Exact command to reproduce**: N/A\r\n", "comments": ["Instead of an option in decode_csv, maybe we could add a `string_strip` op so that it could be used in some other places as well?", "Sounds good. Another place that this would apply is: tf.data.TextLineDataset", "@mrry would you reassign to someone as appropriate?", "Reassigning to \"contributions welcome\" (for the `tf.string_strip()` op).", "Added a PR #18418 for `tf.string_strip`."]}, {"number": 18382, "title": "where can I find people to help with tensorflow for windows? ", "body": "I'm on server 2016, Windows 10 LTSB\r\n\r\nI cannot get tensorflow to work with a tf/python open source project I have interested in.\r\n\r\nIs there somewhere I can find help like someone good at tensorflow on Windows to remote in or use teamviewer to walk me through step by step to show me how to do a net2net and start a training (supervised training, not reinforced training) just in order to show me how to get the process started? \r\n\r\nI would like to convert using Net2Net an existing 15 block 192 filter to 40 block 256 filters and then start trainging it for many steps using raw training data that is also open source/public domain for it to get strong.\r\n\r\nI'm willing to compensate them for said time and effort \r\n", "comments": ["Hi @hydrogenpi, for instructions on how to install TF on Windows please follow the [installation docs](https://www.tensorflow.org/install/install_windows), you will find all the information necessary to successfully install it. The remaining questions are more suitable for StackOverflow where you may reach for community support. Github is strictly for bugs and feature requests as unfortunately isn't possible to help each case due high demand.\r\n\r\nIf you have any further doubt regarding TensorFlow specifically feel free to ask.", "@hydrogenpi, @Carmezim said it best. You can also refer to our [tested source configurations](https://www.tensorflow.org/install/install_sources#tested_source_configurations) table if you want to install from source with certain packages as well. Good luck!"]}, {"number": 18381, "title": "Rename rate parameter to dilation_rate.", "body": "", "comments": ["We're not making more changes to the contrib version, and also this is not ideal to change here because it would break users."]}, {"number": 18380, "title": "TF does not seem to map all available VRAM in multi-gpu config", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: /\r\n- **GCC/Compiler version (if compiling from source)**: /\r\n- **CUDA/cuDNN version**: 9.0/7.0.4\r\n- **GPU model and memory**: Tesla K80 x2\r\n- **Exact command to reproduce**: See script in my comment below to reproduce\r\n\r\n### Describe the problem\r\nI am facing an OOM error (Out of memory) error while running a large TF app on a multi-gpu config (2 Tesla K80).\r\n\r\nThe memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB): \r\n\r\n```\r\nLimit:                 11272152679\r\nInUse:                  7797125376\r\nMaxInUse:              10294759168\r\nNumAllocs:                   41821\r\nMaxAllocSize:           4742250496\r\n```\r\n\r\nI am 100% certain both GPUs are used, since they both show up in the log:\r\n\r\n```\r\n2018-04-10 12:08:37.937431: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use:\r\n AVX2 FMA\r\n2018-04-10 12:08:38.052749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must\r\n be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 12:08:38.053215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\r\n2018-04-10 12:08:38.129345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must\r\n be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 12:08:38.129745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:05.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-04-10 12:08:38.130022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-04-10 12:08:38.658026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-10 12:08:38.658156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 \r\n2018-04-10 12:08:38.658180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N Y \r\n2018-04-10 12:08:38.658201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   Y N \r\n2018-04-10 12:08:38.658793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10\r\n749 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\r\n2018-04-10 12:08:38.853578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10\r\n765 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\r\n```\r\n\r\nThis behavior is inconsistent with TF documentation: https://www.tensorflow.org/programmers_guide/using_gpu#allowing_gpu_memory_growth\r\n\r\n> By default, TensorFlow maps nearly all of the GPU memory of all GPUs\r\n\r\n## logs\r\n```\r\n2018-04-10 12:09:40.993943: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.42GiB.  Current allocation summary follows.\r\n2018-04-10 12:09:40.994041: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 76, Chunks in use: 76. 19.0KiB allocated for chunks. 19.0KiB in use in bin. 1.8KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994060: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994075: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 10, Chunks in use: 10. 11.0KiB allocated for chunks. 11.0KiB in use in bin. 10.0KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 14, Chunks in use: 14. 28.0KiB allocated for chunks. 28.0KiB in use in bin. 28.0KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994097: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 3, Chunks in use: 2. 20.0KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994107: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 12:09:40.994118: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 5, Chunks in use: 5. 80.0KiB allocated for chunks. 80.0KiB in use in bin. 80.0KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994126: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 12:09:40.994137: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 9, Chunks in use: 9. 704.2KiB allocated for chunks. 704.2KiB in use in bin. 600.6KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994148: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 6, Chunks in use: 5. 1.03MiB allocated for chunks. 919.5KiB in use in bin. 919.3KiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 6, Chunks in use: 6. 1.67MiB allocated for chunks. 1.67MiB in use in bin. 1.66MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994169: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 8, Chunks in use: 7. 6.09MiB allocated for chunks. 5.27MiB in use in bin. 5.26MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 4, Chunks in use: 4. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.18MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994190: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 4, Chunks in use: 4. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994200: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 2, Chunks in use: 2. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994213: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 42, Chunks in use: 39. 467.91MiB allocated for chunks. 433.54MiB in use in bin. 426.99MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994224: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 10, Chunks in use: 10. 170.47MiB allocated for chunks. 170.47MiB in use in bin. 157.25MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994233: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 11, Chunks in use: 10. 404.75MiB allocated for chunks. 369.16MiB in use in bin. 350.70MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994269: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 13, Chunks in use: 13. 919.70MiB allocated for chunks. 919.70MiB in use in bin. 918.65MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994281: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 3, Chunks in use: 3. 423.99MiB allocated for chunks. 423.99MiB in use in bin. 353.33MiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994291: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 4, Chunks in use: 3. 8.13GiB allocated for chunks. 4.97GiB in use in bin. 4.97GiB client-requested in use in bin.\r\n2018-04-10 12:09:40.994300: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 4.42GiB was 256.00MiB, Chunk State: \r\n2018-04-10 12:09:40.994314: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 3.17GiB | Requested Size: 2.13MiB | in_use: 0, prev:   Size: 70.67MiB | Requested Size: 70.67MiB | in_use: 1\r\n2018-04-10 12:09:40.994325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280000 of size 1280\r\n2018-04-10 12:09:40.994331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280500 of size 1280\r\n2018-04-10 12:09:40.994339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280a00 of size 256\r\n2018-04-10 12:09:40.994363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280b00 of size 256\r\n2018-04-10 12:09:40.994371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280c00 of size 256\r\n2018-04-10 12:09:40.994379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280d00 of size 256\r\n2018-04-10 12:09:40.994383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280e00 of size 256\r\n2018-04-10 12:09:40.994390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280f00 of size 256\r\n2018-04-10 12:09:40.994398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281000 of size 256\r\n2018-04-10 12:09:40.994406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281100 of size 512\r\n2018-04-10 12:09:40.994414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281300 of size 256\r\n2018-04-10 12:09:40.994422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281400 of size 256\r\n2018-04-10 12:09:40.994429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281500 of size 256\r\n2018-04-10 12:09:40.994437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281600 of size 256\r\n2018-04-10 12:09:40.994444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281700 of size 1024\r\n2018-04-10 12:09:40.994452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281b00 of size 256\r\n2018-04-10 12:09:40.994460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281c00 of size 256\r\n2018-04-10 12:09:40.994478: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281d00 of size 256\r\n2018-04-10 12:09:40.994485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281e00 of size 256\r\n2018-04-10 12:09:40.994494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281f00 of size 2048\r\n2018-04-10 12:09:40.994518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282700 of size 256\r\n2018-04-10 12:09:40.994523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282800 of size 256\r\n2018-04-10 12:09:40.994528: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282900 of size 256\r\n2018-04-10 12:09:40.994532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282a00 of size 256\r\n2018-04-10 12:09:40.994537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282b00 of size 256\r\n2018-04-10 12:09:40.994545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282c00 of size 256\r\n2018-04-10 12:09:40.994554: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282d00 of size 256\r\n2018-04-10 12:09:40.994559: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282e00 of size 256\r\n2018-04-10 12:09:40.994567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282f00 of size 256\r\n2018-04-10 12:09:40.994574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283000 of size 256\r\n2018-04-10 12:09:40.994580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283100 of size 256\r\n2018-04-10 12:09:40.994588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283200 of size 256\r\n2018-04-10 12:09:40.994593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283300 of size 256\r\n2018-04-10 12:09:40.994600: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283400 of size 256\r\n2018-04-10 12:09:40.994605: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283500 of size 256\r\n2018-04-10 12:09:40.994609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283600 of size 256\r\n2018-04-10 12:09:40.994615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283700 of size 256\r\n2018-04-10 12:09:40.994628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283800 of size 512\r\n2018-04-10 12:09:40.994635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283a00 of size 256\r\n2018-04-10 12:09:40.994642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283b00 of size 256\r\n2018-04-10 12:09:40.994648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283c00 of size 256\r\n2018-04-10 12:09:40.994655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283d00 of size 256\r\n2018-04-10 12:09:40.994661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283e00 of size 1536\r\n2018-04-10 12:09:40.994667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284400 of size 256\r\n2018-04-10 12:09:40.994672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284500 of size 256\r\n2018-04-10 12:09:40.994680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284600 of size 256\r\n2018-04-10 12:09:40.994685: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284700 of size 256\r\n2018-04-10 12:09:40.994693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284800 of size 256\r\n2018-04-10 12:09:40.994699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284900 of size 2048\r\n2018-04-10 12:09:40.994706: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285100 of size 256\r\n2018-04-10 12:09:40.994712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285200 of size 256\r\n2018-04-10 12:09:40.994719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285300 of size 256\r\n2018-04-10 12:09:40.994725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285400 of size 256\r\n2018-04-10 12:09:40.994733: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285500 of size 256\r\n2018-04-10 12:09:40.994738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285600 of size 256\r\n2018-04-10 12:09:40.994746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285700 of size 256\r\n2018-04-10 12:09:40.994751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285800 of size 256\r\n2018-04-10 12:09:40.994758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285900 of size 256\r\n2018-04-10 12:09:40.994764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285a00 of size 256\r\n2018-04-10 12:09:40.994772: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285b00 of size 256\r\n2018-04-10 12:09:40.994778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285c00 of size 256\r\n2018-04-10 12:09:40.994785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285d00 of size 256\r\n2018-04-10 12:09:40.994791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285e00 of size 256\r\n2018-04-10 12:09:40.994798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285f00 of size 256\r\n2018-04-10 12:09:40.994803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286000 of size 256\r\n2018-04-10 12:09:40.994810: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286100 of size 256\r\n2018-04-10 12:09:40.994817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286200 of size 256\r\n2018-04-10 12:09:40.994824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286300 of size 256\r\n2018-04-10 12:09:40.994829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286400 of size 256\r\n2018-04-10 12:09:40.994837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286500 of size 256\r\n2018-04-10 12:09:40.994843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286600 of size 256\r\n2018-04-10 12:09:40.994850: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286700 of size 256\r\n2018-04-10 12:09:40.994856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286800 of size 256\r\n2018-04-10 12:09:40.994864: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286900 of size 256\r\n2018-04-10 12:09:40.994869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286a00 of size 256\r\n2018-04-10 12:09:40.994876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286b00 of size 256\r\n2018-04-10 12:09:40.994882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286c00 of size 256\r\n2018-04-10 12:09:40.994890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286d00 of size 256\r\n2018-04-10 12:09:40.994896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286e00 of size 256\r\n2018-04-10 12:09:40.994903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286f00 of size 256\r\n2018-04-10 12:09:40.994908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287000 of size 512\r\n2018-04-10 12:09:40.994917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287200 of size 512\r\n2018-04-10 12:09:40.994922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287400 of size 1024\r\n2018-04-10 12:09:40.994929: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287800 of size 1024\r\n2018-04-10 12:09:40.994935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287c00 of size 1024\r\n2018-04-10 12:09:40.994942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a288000 of size 2048\r\n2018-04-10 12:09:40.994950: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a288800 of size 2048\r\n2018-04-10 12:09:40.994959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a289000 of size 2048\r\n2018-04-10 12:09:40.994964: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a289800 of size 2048\r\n2018-04-10 12:09:40.994968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28a000 of size 2048\r\n2018-04-10 12:09:40.994973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28a800 of size 2048\r\n2018-04-10 12:09:40.994978: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28b000 of size 6912\r\n2018-04-10 12:09:40.994990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28cb00 of size 113152\r\n2018-04-10 12:09:40.994998: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2a8500 of size 256\r\n2018-04-10 12:09:40.995008: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2a8600 of size 65536\r\n2018-04-10 12:09:40.995018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2b8600 of size 81920\r\n2018-04-10 12:09:40.995025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2cc600 of size 147456\r\n2018-04-10 12:09:40.995040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2f0600 of size 512\r\n2018-04-10 12:09:40.995052: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2f0800 of size 294912\r\n2018-04-10 12:09:40.995062: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a338800 of size 294912\r\n2018-04-10 12:09:40.995074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a380800 of size 512\r\n2018-04-10 12:09:40.995080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a380a00 of size 289536\r\n2018-04-10 12:09:40.995086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3c7500 of size 71936\r\n2018-04-10 12:09:40.995092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3d8e00 of size 16384\r\n2018-04-10 12:09:40.995098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3dce00 of size 16384\r\n2018-04-10 12:09:40.995106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3e0e00 of size 16384\r\n2018-04-10 12:09:40.995111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3e4e00 of size 71936\r\n2018-04-10 12:09:40.995118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3f6700 of size 107264\r\n2018-04-10 12:09:40.995127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a410a00 of size 589824\r\n2018-04-10 12:09:40.995134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a4a0a00 of size 1024\r\n2018-04-10 12:09:40.995154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a4a0e00 of size 2359296\r\n2018-04-10 12:09:40.995159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6e0e00 of size 16384\r\n2018-04-10 12:09:40.995164: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6e4e00 of size 65536\r\n2018-04-10 12:09:40.995171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6f4e00 of size 16384\r\n2018-04-10 12:09:40.995179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6f8e00 of size 289536\r\n2018-04-10 12:09:40.995184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a73f900 of size 287488\r\n2018-04-10 12:09:40.995191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a785c00 of size 71936\r\n2018-04-10 12:09:40.995199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a797500 of size 215552\r\n2018-04-10 12:09:40.995207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cbf00 of size 256\r\n2018-04-10 12:09:40.995212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cc000 of size 256\r\n2018-04-10 12:09:40.995219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cc100 of size 256\r\n2018-04-10 12:09:40.995227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x50a7cc200 of size 6656\r\n2018-04-10 12:09:40.995235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cdc00 of size 71936\r\n2018-04-10 12:09:40.995240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x50a7df500 of size 137472\r\n2018-04-10 12:09:40.995247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a800e00 of size 1179648\r\n2018-04-10 12:09:40.995253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a920e00 of size 1024\r\n2018-04-10 12:09:40.995260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a921200 of size 1024\r\n2018-04-10 12:09:40.995266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a921600 of size 2359296\r\n2018-04-10 12:09:40.995273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ab61600 of size 1157888\r\n2018-04-10 12:09:40.995281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ac7c100 of size 1201408\r\n2018-04-10 12:09:40.995289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ada1600 of size 2048\r\n2018-04-10 12:09:40.995294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ada1e00 of size 9437184\r\n2018-04-10 12:09:40.995301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50b6a1e00 of size 9437184\r\n2018-04-10 12:09:40.995306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50bfa1e00 of size 9437184\r\n2018-04-10 12:09:40.995314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50c8a1e00 of size 9437184\r\n2018-04-10 12:09:40.995319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50d1a1e00 of size 9437184\r\n2018-04-10 12:09:40.995326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa1e00 of size 2048\r\n2018-04-10 12:09:40.995334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa2600 of size 2048\r\n2018-04-10 12:09:40.995342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa2e00 of size 2048\r\n2018-04-10 12:09:40.995347: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa3600 of size 2048\r\n2018-04-10 12:09:40.995354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa3e00 of size 2048\r\n2018-04-10 12:09:40.995360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa4600 of size 6912\r\n2018-04-10 12:09:40.995367: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa6100 of size 147456\r\n2018-04-10 12:09:40.995372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daca100 of size 294912\r\n2018-04-10 12:09:40.995380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50db12100 of size 589824\r\n2018-04-10 12:09:40.995387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50dba2100 of size 1179648\r\n2018-04-10 12:09:40.995396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50dcc2100 of size 2359296\r\n2018-04-10 12:09:40.995400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50df02100 of size 4718592\r\n2018-04-10 12:09:40.995407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50e382100 of size 9437184\r\n2018-04-10 12:09:40.995413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ec82100 of size 16777216\r\n2018-04-10 12:09:40.995421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50fc82100 of size 16777216\r\n2018-04-10 12:09:40.995426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x510c82100 of size 8388608\r\n2018-04-10 12:09:40.995433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x511482100 of size 16777216\r\n2018-04-10 12:09:40.995439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x512482100 of size 16777216\r\n2018-04-10 12:09:40.995446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x513482100 of size 8388608\r\n2018-04-10 12:09:40.995454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x513c82100 of size 8388608\r\n2018-04-10 12:09:40.995462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x514482100 of size 14155776\r\n2018-04-10 12:09:40.995468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x515202100 of size 9437184\r\n2018-04-10 12:09:40.995475: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x515b02100 of size 9437184\r\n2018-04-10 12:09:40.995485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x516402100 of size 9437184\r\n2018-04-10 12:09:40.995492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x516d02100 of size 9437184\r\n2018-04-10 12:09:40.995500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517602100 of size 2359296\r\n2018-04-10 12:09:40.995505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517842100 of size 4718592\r\n2018-04-10 12:09:40.995512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517cc2100 of size 9437184\r\n2018-04-10 12:09:40.995518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5185c2100 of size 74097664\r\n2018-04-10 12:09:40.995525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x51cc6c500 of size 74097664\r\n2018-04-10 12:09:40.995530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x521316900 of size 36773888\r\n2018-04-10 12:09:40.995538: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x523628900 of size 36773888\r\n2018-04-10 12:09:40.995545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52593a900 of size 16777216\r\n2018-04-10 12:09:40.995553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52693a900 of size 74097664\r\n2018-04-10 12:09:40.995560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52afe4d00 of size 16777216\r\n2018-04-10 12:09:40.995567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52bfe4d00 of size 16777216\r\n2018-04-10 12:09:40.995573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52cfe4d00 of size 74097664\r\n2018-04-10 12:09:40.995594: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53168f100 of size 74097664\r\n2018-04-10 12:09:40.995603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x535d39500 of size 13893376\r\n2018-04-10 12:09:40.995611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x536a79400 of size 36773888\r\n2018-04-10 12:09:40.995618: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x538d8b400 of size 74097664\r\n2018-04-10 12:09:40.995626: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53d435800 of size 13893376\r\n2018-04-10 12:09:40.995634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53e175700 of size 13893376\r\n2018-04-10 12:09:40.995642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53eeb5600 of size 8388608\r\n2018-04-10 12:09:40.995649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53f6b5600 of size 8388608\r\n2018-04-10 12:09:40.995657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53feb5600 of size 36773888\r\n2018-04-10 12:09:40.995665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5421c7600 of size 36773888\r\n2018-04-10 12:09:40.995672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5444d9600 of size 13893376\r\n2018-04-10 12:09:40.995680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x545219500 of size 16777216\r\n2018-04-10 12:09:40.995688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x546219500 of size 13893376\r\n2018-04-10 12:09:40.995695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x546f59400 of size 8388608\r\n2018-04-10 12:09:40.995703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x547759400 of size 13893376\r\n2018-04-10 12:09:40.995711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x548499300 of size 36773888\r\n2018-04-10 12:09:40.995718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54a7ab300 of size 13893376\r\n2018-04-10 12:09:40.995723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54b4eb200 of size 13893376\r\n2018-04-10 12:09:40.995746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54c22b100 of size 16777216\r\n2018-04-10 12:09:40.995754: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54d22b100 of size 13893376\r\n2018-04-10 12:09:40.995763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54df6b000 of size 13893376\r\n2018-04-10 12:09:40.995770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54ecaaf00 of size 13893376\r\n2018-04-10 12:09:40.995778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54f9eae00 of size 8388608\r\n2018-04-10 12:09:40.995785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5501eae00 of size 13893376\r\n2018-04-10 12:09:40.995793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x550f2ad00 of size 13893376\r\n2018-04-10 12:09:40.995800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x551c6ac00 of size 13893376\r\n2018-04-10 12:09:40.995808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5529aab00 of size 868352\r\n2018-04-10 12:09:40.995813: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x552a7eb00 of size 868352\r\n2018-04-10 12:09:40.995820: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x552b52b00 of size 868352\r\n2018-04-10 12:09:40.995828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x552c26b00 of size 11288320\r\n2018-04-10 12:09:40.995836: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5536eaa00 of size 868352\r\n2018-04-10 12:09:40.995843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5537bea00 of size 215552\r\n2018-04-10 12:09:40.995851: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5537f3400 of size 215552\r\n2018-04-10 12:09:40.995856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x553827e00 of size 868352\r\n2018-04-10 12:09:40.995863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5538fbe00 of size 868352\r\n2018-04-10 12:09:40.995871: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x5539cfe00 of size 10857216\r\n2018-04-10 12:09:40.995879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55442a900 of size 55573504\r\n2018-04-10 12:09:40.995886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55792a500 of size 13893376\r\n2018-04-10 12:09:40.995893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55866a400 of size 13893376\r\n2018-04-10 12:09:40.995901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5593aa300 of size 13893376\r\n2018-04-10 12:09:40.995909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55a0ea200 of size 13893376\r\n2018-04-10 12:09:40.995916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55ae2a100 of size 13945088\r\n2018-04-10 12:09:40.995924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55bb76a00 of size 13893376\r\n2018-04-10 12:09:40.995946: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55c8b6900 of size 74097664\r\n2018-04-10 12:09:40.995954: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x560f60d00 of size 75203584\r\n2018-04-10 12:09:40.995961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x565719100 of size 147089408\r\n2018-04-10 12:09:40.995965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x56e35f900 of size 13893376\r\n2018-04-10 12:09:40.995969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x56f09f800 of size 296390656\r\n2018-04-10 12:09:40.995974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x580b48800 of size 27760896\r\n2018-04-10 12:09:40.995978: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5825c2100 of size 74097664\r\n2018-04-10 12:09:40.996009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x586c6c500 of size 36773888\r\n2018-04-10 12:09:40.996017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x588f7e500 of size 37323776\r\n2018-04-10 12:09:40.996047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x58b316900 of size 149298176\r\n2018-04-10 12:09:40.996055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x594178500 of size 296390656\r\n2018-04-10 12:09:40.996063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5a5c21500 of size 74097664\r\n2018-04-10 12:09:40.996075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5aa2cb900 of size 36773888\r\n2018-04-10 12:09:40.996080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5ac5dd900 of size 37323776\r\n2018-04-10 12:09:40.996086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5ae975d00 of size 148195328\r\n2018-04-10 12:09:40.996091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5b76ca500 of size 74097664\r\n2018-04-10 12:09:40.996098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5bbd74900 of size 74097664\r\n2018-04-10 12:09:40.996106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5c041ed00 of size 4742250496\r\n2018-04-10 12:09:40.996115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x6daeaed00 of size 74097664\r\n2018-04-10 12:09:40.996123: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x6df559100 of size 3400652032\r\n2018-04-10 12:09:40.996130: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \r\n2018-04-10 12:09:40.996141: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 76 Chunks of size 256 totalling 19.0KiB\r\n2018-04-10 12:09:40.996150: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 512 totalling 3.0KiB\r\n2018-04-10 12:09:40.996156: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 1024 totalling 7.0KiB\r\n2018-04-10 12:09:40.996164: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1280 totalling 2.5KiB\r\n2018-04-10 12:09:40.996172: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1536 totalling 1.5KiB\r\n2018-04-10 12:09:40.996184: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 14 Chunks of size 2048 totalling 28.0KiB\r\n2018-04-10 12:09:40.996193: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 6912 totalling 13.5KiB\r\n2018-04-10 12:09:40.996201: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 16384 totalling 80.0KiB\r\n2018-04-10 12:09:40.996210: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 65536 totalling 128.0KiB\r\n2018-04-10 12:09:40.996218: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 71936 totalling 281.0KiB\r\n2018-04-10 12:09:40.996226: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 81920 totalling 80.0KiB\r\n2018-04-10 12:09:40.996234: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 107264 totalling 104.8KiB\r\n2018-04-10 12:09:40.996243: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 113152 totalling 110.5KiB\r\n2018-04-10 12:09:40.996251: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 147456 totalling 288.0KiB\r\n2018-04-10 12:09:40.996259: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 215552 totalling 631.5KiB\r\n2018-04-10 12:09:40.996267: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 287488 totalling 280.8KiB\r\n2018-04-10 12:09:40.996276: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 289536 totalling 565.5KiB\r\n2018-04-10 12:09:40.996284: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 294912 totalling 864.0KiB\r\n2018-04-10 12:09:40.996295: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 589824 totalling 1.12MiB\r\n2018-04-10 12:09:40.996304: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 868352 totalling 4.14MiB\r\n2018-04-10 12:09:40.996312: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1157888 totalling 1.10MiB\r\n2018-04-10 12:09:40.996324: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1179648 totalling 2.25MiB\r\n2018-04-10 12:09:40.996330: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1201408 totalling 1.15MiB\r\n2018-04-10 12:09:40.996338: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 2359296 totalling 9.00MiB\r\n2018-04-10 12:09:40.996350: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 4718592 totalling 9.00MiB\r\n2018-04-10 12:09:40.996359: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 8388608 totalling 56.00MiB\r\n2018-04-10 12:09:40.996371: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 11 Chunks of size 9437184 totalling 99.00MiB\r\n2018-04-10 12:09:40.996378: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 19 Chunks of size 13893376 totalling 251.75MiB\r\n2018-04-10 12:09:40.996386: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 13945088 totalling 13.30MiB\r\n2018-04-10 12:09:40.996395: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 14155776 totalling 13.50MiB\r\n2018-04-10 12:09:40.996403: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 16777216 totalling 144.00MiB\r\n2018-04-10 12:09:40.996411: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 27760896 totalling 26.47MiB\r\n2018-04-10 12:09:40.996420: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 36773888 totalling 280.56MiB\r\n2018-04-10 12:09:40.996428: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 37323776 totalling 35.59MiB\r\n2018-04-10 12:09:40.996436: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 55573504 totalling 53.00MiB\r\n2018-04-10 12:09:40.996445: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 12 Chunks of size 74097664 totalling 847.98MiB\r\n2018-04-10 12:09:40.996453: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 75203584 totalling 71.72MiB\r\n2018-04-10 12:09:40.996461: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 147089408 totalling 140.28MiB\r\n2018-04-10 12:09:40.996470: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 148195328 totalling 141.33MiB\r\n2018-04-10 12:09:40.996478: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 149298176 totalling 142.38MiB\r\n2018-04-10 12:09:40.996486: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 296390656 totalling 565.32MiB\r\n2018-04-10 12:09:40.996494: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 4742250496 totalling 4.42GiB\r\n2018-04-10 12:09:40.996503: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 7.26GiB\r\n2018-04-10 12:09:40.996512: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \r\nLimit:                 11272152679\r\nInUse:                  7797125376\r\nMaxInUse:              10294759168\r\nNumAllocs:                   41821\r\nMaxAllocSize:           4742250496\r\n```", "comments": ["Here a simple program that allocates a large tensor filled with zeros:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport sys\r\n\r\namount = int(sys.argv[1])\r\nprint('Generating tensor with {} zeros' % amount)\r\n_data = np.zeros(amount * (1 << 20), dtype=np.float32)\r\n\r\ndata_init = tf.placeholder(tf.float32, shape=_data.shape)\r\ndata = tf.Variable(data_init, trainable=False, collections=[])\r\na = tf.contrib.memory_stats.MaxBytesInUse()\r\nb = tf.constant('Completed successfully')\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run([data.initializer, a, b], feed_dict={data_init: _data}))\r\n```\r\n\r\nGenerating `1200` or `1300` zeros works ok\r\n\r\n```bash\r\n$ python alloc.py 1200\r\n/home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nGenerating amount  1200\r\nWARNING:tensorflow:From /home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\n2018-04-10 13:59:20.700598: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-04-10 13:59:20.816981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 13:59:20.817404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\r\n2018-04-10 13:59:20.892493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 13:59:20.892925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:05.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-04-10 13:59:20.892991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-04-10 13:59:21.439399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-10 13:59:21.439464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 \r\n2018-04-10 13:59:21.439474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N N \r\n2018-04-10 13:59:21.439479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   N N \r\n2018-04-10 13:59:21.439977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10750 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\r\n2018-04-10 13:59:21.627795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10765 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\r\n[None, 1280, b'I ran OK']\r\n```\r\n\r\nBut as soon as I go over 1300 the allocation fails:\r\n\r\n```\r\n2018-04-10 13:58:38.000952: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.27GiB.  Current allocation summary follows.\r\n2018-04-10 13:58:38.001045: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001098: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\r\n2018-04-10 13:58:38.001111: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001117: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001125: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001135: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001145: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001151: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001191: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001201: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001209: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001219: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001226: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001232: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001239: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001246: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001254: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001265: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 10.50GiB allocated for chunks. 5.27GiB in use in bin. 5.27GiB client-requested in use in bin.\r\n2018-04-10 13:58:38.001278: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 5.27GiB was 256.00MiB, Chunk State: \r\n2018-04-10 13:58:38.001293: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 5.22GiB | Requested Size: 0B | in_use: 0, prev:   Size: 5.27GiB | Requested Size: 5.27GiB | in_use: 1\r\n2018-04-10 13:58:38.001307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280000 of size 1280\r\n2018-04-10 13:58:38.001318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280500 of size 5662310400\r\n2018-04-10 13:58:38.001326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x85ba80500 of size 5610339072\r\n2018-04-10 13:58:38.001336: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \r\n2018-04-10 13:58:38.001346: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\r\n2018-04-10 13:58:38.001354: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5662310400 totalling 5.27GiB\r\n2018-04-10 13:58:38.001364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 5.27GiB\r\n2018-04-10 13:58:38.001376: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \r\nLimit:                 11272650752\r\nInUse:                  5662311680\r\nMaxInUse:               5662311680\r\nNumAllocs:                       2\r\nMaxAllocSize:           5662310400\r\n```\r\n\r\nIn fact, it seems that the allocator is not even able to allocate half of available memory for a single GPU. Is there a maximum limit for single memory allocations ?\r\n", "@jlebar, can you take a look?", "Hi, Reed.\r\n\r\nI work on XLA.  Is this somehow related to that?", "No. I only assigned to your because you authored 9fe7c29605a5ee1519cceba8e67a6d8413444fac. But I can take a look instead.", "Thank you for looking into this. Today, I tried the same thing on a Tesla P100 that has 16GB of VRAM, same outcome. It fails to allocate ~4GB:\r\n```\r\n2018-04-11 06:58:33.346240: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.42GiB.  Current allocation summary follows.\r\n```\r\n```\r\n2018-04-11 06:58:33.346580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f0e30800000 of size 4742250496\r\n2018-04-11 06:58:33.346588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f0f4b290000 of size 74097664\r\n2018-04-11 06:58:33.346596: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x7f0f4f93a400 of size 3773586432\r\n2018-04-11 06:58:33.346603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1084000000 of size 16777216\r\n2018-04-11 06:58:33.346611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1085000000 of size 74097664\r\n2018-04-11 06:58:33.346619: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f10896aa400 of size 16777216\r\n2018-04-11 06:58:33.346630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f108a6aa400 of size 16777216\r\n2018-04-11 06:58:33.346635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f108b6aa400 of size 74097664\r\n2018-04-11 06:58:33.346643: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f108fd54800 of size 74097664\r\n2018-04-11 06:58:33.346649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x7f10943fec00 of size 4022342656\r\n2018-04-11 06:58:33.346657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1184000000 of size 36773888\r\n2018-04-11 06:58:33.346664: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1186312000 of size 36773888\r\n2018-04-11 06:58:33.346671: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1188624000 of size 74097664\r\n2018-04-11 06:58:33.346684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f118ccce400 of size 120790016\r\n2018-04-11 06:58:33.346690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1194000000 of size 8388608\r\n2018-04-11 06:58:33.346695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1194800000 of size 8388608\r\n2018-04-11 06:58:33.346703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1195000000 of size 16777216\r\n2018-04-11 06:58:33.346711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1196000000 of size 16777216\r\n2018-04-11 06:58:33.346719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1197000000 of size 2359296\r\n2018-04-11 06:58:33.346729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1197240000 of size 16515072\r\n2018-04-11 06:58:33.346736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1198200000 of size 9437184\r\n2018-04-11 06:58:33.346744: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1198b00000 of size 9437184\r\n2018-04-11 06:58:33.346750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1199400000 of size 9437184\r\n2018-04-11 06:58:33.346756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x7f1199d00000 of size 9437184\r\n2018-04-11 06:58:33.346763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119a600000 of size 294912\r\n2018-04-11 06:58:33.346769: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119a648000 of size 589824\r\n2018-04-11 06:58:33.346775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119a6d8000 of size 1179648\r\n2018-04-11 06:58:33.346781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119a7f8000 of size 2359296\r\n2018-04-11 06:58:33.346787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119aa38000 of size 4718592\r\n2018-04-11 06:58:33.346793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f119aeb8000 of size 18120704\r\n2018-04-11 06:58:33.346799: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c8400000 of size 9437184\r\n2018-04-11 06:58:33.346806: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c8d00000 of size 589824\r\n2018-04-11 06:58:33.346812: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c8d90000 of size 1179648\r\n2018-04-11 06:58:33.346819: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c8eb0000 of size 2359296\r\n2018-04-11 06:58:33.346829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c90f0000 of size 4718592\r\n2018-04-11 06:58:33.346835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c9570000 of size 9437184\r\n2018-04-11 06:58:33.346841: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11c9e70000 of size 16777216\r\n2018-04-11 06:58:33.346847: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11cae70000 of size 22609920\r\n2018-04-11 06:58:33.346854: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11cc400000 of size 9437184\r\n2018-04-11 06:58:33.346863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11ccd00000 of size 9437184\r\n2018-04-11 06:58:33.346869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11cd600000 of size 14680064\r\n2018-04-11 06:58:33.346875: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11ce400000 of size 16777216\r\n2018-04-11 06:58:33.346885: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11cf400000 of size 8388608\r\n2018-04-11 06:58:33.346891: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11cfc00000 of size 4194304\r\n2018-04-11 06:58:33.346896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11d0000000 of size 289536\r\n2018-04-11 06:58:33.346903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f11d0046b00 of size 289536\r\n2018-04-11 06:58:33.346909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x7f11d008d600 of size 1518080\r\n2018-04-11 06:58:33.346916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400000 of size 1280\r\n2018-04-11 06:58:33.346921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400500 of size 1280\r\n2018-04-11 06:58:33.346928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400a00 of size 256\r\n2018-04-11 06:58:33.346934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400b00 of size 256\r\n2018-04-11 06:58:33.346940: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400c00 of size 256\r\n2018-04-11 06:58:33.346945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400d00 of size 256\r\n2018-04-11 06:58:33.346952: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400e00 of size 256\r\n2018-04-11 06:58:33.346957: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210400f00 of size 256\r\n2018-04-11 06:58:33.346966: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401000 of size 256\r\n2018-04-11 06:58:33.346972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401100 of size 512\r\n2018-04-11 06:58:33.346981: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401300 of size 256\r\n2018-04-11 06:58:33.346988: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401400 of size 256\r\n2018-04-11 06:58:33.346994: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401500 of size 256\r\n2018-04-11 06:58:33.347000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401600 of size 256\r\n2018-04-11 06:58:33.347006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401700 of size 1024\r\n2018-04-11 06:58:33.347012: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401b00 of size 256\r\n2018-04-11 06:58:33.347022: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401c00 of size 256\r\n2018-04-11 06:58:33.347028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401d00 of size 256\r\n2018-04-11 06:58:33.347035: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401e00 of size 256\r\n2018-04-11 06:58:33.347041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210401f00 of size 2048\r\n2018-04-11 06:58:33.347049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402700 of size 256\r\n2018-04-11 06:58:33.347055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402800 of size 256\r\n2018-04-11 06:58:33.347061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402900 of size 256\r\n2018-04-11 06:58:33.347068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402a00 of size 256\r\n2018-04-11 06:58:33.347074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402b00 of size 256\r\n2018-04-11 06:58:33.347079: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402c00 of size 256\r\n2018-04-11 06:58:33.347086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402d00 of size 256\r\n2018-04-11 06:58:33.347092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402e00 of size 256\r\n2018-04-11 06:58:33.347100: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210402f00 of size 256\r\n2018-04-11 06:58:33.347106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403000 of size 256\r\n2018-04-11 06:58:33.347112: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403100 of size 256\r\n2018-04-11 06:58:33.347119: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403200 of size 256\r\n2018-04-11 06:58:33.347126: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403300 of size 256\r\n2018-04-11 06:58:33.347131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403400 of size 256\r\n2018-04-11 06:58:33.347137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403500 of size 256\r\n2018-04-11 06:58:33.347144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403600 of size 256\r\n2018-04-11 06:58:33.347151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403700 of size 256\r\n2018-04-11 06:58:33.347158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403800 of size 512\r\n2018-04-11 06:58:33.347165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403a00 of size 256\r\n2018-04-11 06:58:33.347171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403b00 of size 256\r\n2018-04-11 06:58:33.347177: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403c00 of size 256\r\n2018-04-11 06:58:33.347183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403d00 of size 256\r\n2018-04-11 06:58:33.347190: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210403e00 of size 1536\r\n2018-04-11 06:58:33.347197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404400 of size 256\r\n2018-04-11 06:58:33.347203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404500 of size 256\r\n2018-04-11 06:58:33.347210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404600 of size 256\r\n2018-04-11 06:58:33.347216: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404700 of size 256\r\n2018-04-11 06:58:33.347222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404800 of size 256\r\n2018-04-11 06:58:33.347229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210404900 of size 2048\r\n2018-04-11 06:58:33.347236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405100 of size 256\r\n2018-04-11 06:58:33.347242: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405200 of size 256\r\n2018-04-11 06:58:33.347248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405300 of size 256\r\n2018-04-11 06:58:33.347254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405400 of size 256\r\n2018-04-11 06:58:33.347261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405500 of size 256\r\n2018-04-11 06:58:33.347266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405600 of size 256\r\n2018-04-11 06:58:33.347273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405700 of size 256\r\n2018-04-11 06:58:33.347278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210405800 of size 256\r\n2018-04-11 06:58:33.347284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x7f1210405900 of size 5376\r\n2018-04-11 06:58:33.347290: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210406e00 of size 256\r\n2018-04-11 06:58:33.347297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210406f00 of size 256\r\n2018-04-11 06:58:33.347305: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210407000 of size 512\r\n2018-04-11 06:58:33.347312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210407200 of size 512\r\n2018-04-11 06:58:33.347317: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210407400 of size 1024\r\n2018-04-11 06:58:33.347326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210407800 of size 1024\r\n2018-04-11 06:58:33.347334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210407c00 of size 1024\r\n2018-04-11 06:58:33.347341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210408000 of size 2048\r\n2018-04-11 06:58:33.347346: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210408800 of size 2048\r\n2018-04-11 06:58:33.347354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210409000 of size 2048\r\n2018-04-11 06:58:33.347360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210409800 of size 2048\r\n2018-04-11 06:58:33.347366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121040a000 of size 2048\r\n2018-04-11 06:58:33.347374: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121040a800 of size 2048\r\n2018-04-11 06:58:33.347380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121040b000 of size 6912\r\n2018-04-11 06:58:33.347385: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121040cb00 of size 113152\r\n2018-04-11 06:58:33.347392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210428500 of size 256\r\n2018-04-11 06:58:33.347398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210428600 of size 65536\r\n2018-04-11 06:58:33.347406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210438600 of size 81920\r\n2018-04-11 06:58:33.347411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121044c600 of size 147456\r\n2018-04-11 06:58:33.347418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210470600 of size 512\r\n2018-04-11 06:58:33.347427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210470800 of size 512\r\n2018-04-11 06:58:33.347435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210470a00 of size 1024\r\n2018-04-11 06:58:33.347443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210470e00 of size 1024\r\n2018-04-11 06:58:33.347448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210471200 of size 1024\r\n2018-04-11 06:58:33.347456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210471600 of size 2048\r\n2018-04-11 06:58:33.347461: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210471e00 of size 2048\r\n2018-04-11 06:58:33.347468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210472600 of size 2048\r\n2018-04-11 06:58:33.347473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210472e00 of size 2048\r\n2018-04-11 06:58:33.347481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210473600 of size 2048\r\n2018-04-11 06:58:33.347486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210473e00 of size 2048\r\n2018-04-11 06:58:33.347493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210474600 of size 6912\r\n2018-04-11 06:58:33.347499: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f1210476100 of size 147456\r\n2018-04-11 06:58:33.347505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x7f121049a100 of size 417536\r\n2018-04-11 06:58:33.347511: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size:\r\n2018-04-11 06:58:33.347519: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 52 Chunks of size 256 totalling 13.0KiB\r\n2018-04-11 06:58:33.347528: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 512 totalling 3.0KiB\r\n2018-04-11 06:58:33.347536: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 1024 totalling 7.0KiB\r\n2018-04-11 06:58:33.347543: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1280 totalling 2.5KiB\r\n2018-04-11 06:58:33.347551: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1536 totalling 1.5KiB\r\n2018-04-11 06:58:33.347557: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 14 Chunks of size 2048 totalling 28.0KiB\r\n2018-04-11 06:58:33.347564: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 6912 totalling 13.5KiB\r\n2018-04-11 06:58:33.347571: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 65536 totalling 64.0KiB\r\n2018-04-11 06:58:33.347577: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 81920 totalling 80.0KiB\r\n2018-04-11 06:58:33.347585: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 113152 totalling 110.5KiB\r\n2018-04-11 06:58:33.347591: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 147456 totalling 288.0KiB\r\n2018-04-11 06:58:33.347598: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 289536 totalling 565.5KiB\r\n2018-04-11 06:58:33.347605: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 294912 totalling 288.0KiB\r\n2018-04-11 06:58:33.347611: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 417536 totalling 407.8KiB\r\n2018-04-11 06:58:33.347618: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 589824 totalling 1.12MiB\r\n2018-04-11 06:58:33.347624: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1179648 totalling 2.25MiB\r\n2018-04-11 06:58:33.347630: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 2359296 totalling 6.75MiB\r\n2018-04-11 06:58:33.347637: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 4194304 totalling 4.00MiB\r\n2018-04-11 06:58:33.347642: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 4718592 totalling 9.00MiB\r\n2018-04-11 06:58:33.347651: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 8388608 totalling 24.00MiB\r\n2018-04-11 06:58:33.347657: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 9437184 totalling 63.00MiB\r\n2018-04-11 06:58:33.347663: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 14680064 totalling 14.00MiB\r\n2018-04-11 06:58:33.347670: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 16515072 totalling 15.75MiB\r\n2018-04-11 06:58:33.347686: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 16777216 totalling 112.00MiB\r\n2018-04-11 06:58:33.347693: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 18120704 totalling 17.28MiB\r\n2018-04-11 06:58:33.347705: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 22609920 totalling 21.56MiB\r\n2018-04-11 06:58:33.347713: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 36773888 totalling 70.14MiB\r\n2018-04-11 06:58:33.347720: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 74097664 totalling 353.33MiB\r\n2018-04-11 06:58:33.347734: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 120790016 totalling 115.19MiB\r\n2018-04-11 06:58:33.347742: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 4742250496 totalling 4.42GiB\r\n2018-04-11 06:58:33.347752: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 5.23GiB\r\n2018-04-11 06:58:33.347761: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats:\r\nLimit:                 15868438119\r\nInUse:                  5613834496\r\nMaxInUse:               5613834496\r\nNumAllocs:                   27368\r\nMaxAllocSize:           4742250496\r\n```\r\nLet me know if I can do anything to help debug this. ", "For the short example you posted, my guess is that when you initialize a Variable with a `tf.placeholder` fed with a feed dict, you need to allocate memory both for the Variable data and the `tf.placeholder`, requiring double the memory as what just the Variable requires. (@mrry can you confirm this fact?)\r\n\r\n>The memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB):\r\n\r\nNote that the limit is supposed to show only a single GPU. Each GPU has it's own memory, and ops assigned to that GPU will use that GPU's memory. If there is not enough memory on a GPU to run all the ops assigned to that GPU, you will get an OOM even if there is memory left on the other GPU.\r\n\r\nIn your case, I would guess either you are running all/most your ops on GPU:0, or both GPUs would run out of memory and GPU:0 happens to run out of memory first.\r\n", "@reedwm I think that's correct, yes. Here's where the copy happens:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/0c1ea2db7fb137dd4cf6f334dda9eb9623935d9d/tensorflow/core/kernels/assign_op.h#L106-L121\r\n\r\nYou might be able to avoid this using `tf.get_variable(..., use_resource=True)`, because a `ResourceVariable` will reuse the fed-in value (as long as it has no other users in the same step):\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/0c1ea2db7fb137dd4cf6f334dda9eb9623935d9d/tensorflow/core/kernels/resource_variable_ops.cc#L251-L261", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I don't have access to the GPU machine for now, when I do I'll try the `use_resource` flag. I'm closing this for now because I don't think there is anything to fix in TF, rather I need to redesign a few things to eliminate this op that requires so much vram in my final app.\r\n\r\nBut it's good to keep in mind that although TF maps memory of multiple GPUs, each op must fit into a single GPU, otherwise a memory allocation will be raised."]}, {"number": 18379, "title": "issues in the tflite_camera_example on IOS", "body": "------------------------\r\n\r\n### System information\r\n- **Xcode 9.3 and Mac OS is 10.13.4  **:\r\n- **TensorFlow r1.2**:\r\n- **iPhone 7 plus**:\r\n\r\n\r\n### Describe the problem\r\nNSString* graph_path = FilePathForResourceName(model_file_name, @\"tflite\");\r\n  model = **tflite::FlatBufferModel::BuildFromFile**([graph_path UTF8String]);\r\n  if (!model) {\r\n    LOG(FATAL) << \"Failed to mmap model \" << graph_path;\r\n  }\r\n  LOG(INFO) << \"Loaded model \" << graph_path;\r\n  model->error_reporter();\r\n  LOG(INFO) << \"resolved reporter\";\r\n\r\n### Source code / logs\r\nAfter \"tflite::FlatBufferModel::BuildFromFile\" is excuted, and it returns\r\nnnapi error: unable to open library libneuralnetworks.so\r\nLoaded model 1resolved reporter(lldb) \r\n\r\nDoes anyone know how to solve this issue? Thanks in advance.", "comments": ["This is a duplicate of issue #18343 ", "Thanks @glenn-jocher - closing this since it is a duplicate."]}, {"number": 18378, "title": "update highwayhash library to fix kernel_tests:lookup_ops_test, lookup:lookup_ops_test and string_to_hash_bucket_op_test tests on ppc64le", "body": "  All three of these tests were failing on ppc64le ,because the build was using a version of the highwayhash library which did not properly support the power architecture.  Updating the library to include commit e2098b (https://github.com/google/highwayhash/commit/e2098bc92a8540e133b11207ed1f1abfca57724c) seems to fix the issue.\r\n\r\nThanks !", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Please handle the CLA before we review. Thanks!", "We are getting CLA related issues , because I have accidentally pushed the first commit using invalid user.\r\nClosing this PR , will open new one.", "I have opened a new PR for this - https://github.com/tensorflow/tensorflow/pull/18414 .\r\nWill track the status in new PR.Thanks! "]}, {"number": 18377, "title": "tf.layers.conv3d_transpose with channels_first flips the last two dimensions of the gradient", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: pip3 install --upgrade tf-nightly-gpu\r\n- **TensorFlow version (use command below)**: 1.8.0-dev20180329\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**: 9.0/7.1.2\r\n- **GPU model and memory**: NVIDIA Geforce 940M/2GB\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\na = tf.placeholder(tf.float32, [None, 16, 4, 8, 16])\r\nb = tf.layers.conv3d_transpose(a, 16, [1, 1, 1], (1, 2, 1), 'same', 'channels_first')\r\nc = tf.placeholder(tf.float32, [None, 16, 4, 16, 16])\r\nloss = tf.reduce_mean(tf.squared_difference(b, c))\r\ntrain = tf.train.AdamOptimizer().minimize(loss)\r\n```\r\n\r\n### Describe the problem\r\n\r\nWhen using ```tf.layers.conv3d_transpose``` with ```'channels_first'```, gradients are calculated with the last two dimensions flipped. The only workaround I currently know is to split the 3d convolution into 2d convolutions with the parameters shared.\r\n\r\n### Source code / logs\r\n\r\nError message below.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 667, in merge_with\r\n    new_dims.append(dim.merge_with(other[i]))\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 140, in merge_with\r\n    self.assert_is_compatible_with(other)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 113, in assert_is_compatible_with\r\n    other))\r\nValueError: Dimensions 16 and 8 are not compatible\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 648, in _GradientsHelper\r\n    in_grad.set_shape(t_in.get_shape())\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 471, in set_shape\r\n    self._shape_val = self._shape_val.merge_with(shape)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 670, in merge_with\r\n    raise ValueError(\"Shapes %s and %s are not compatible\" % (self, other))\r\nValueError: Shapes (?, 16, 4, 16, 8) and (?, 16, 4, 8, 16) are not compatible\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#5>\", line 1, in <module>\r\n    train = tf.train.AdamOptimizer().minimize(loss)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 390, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 483, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 488, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 655, in _GradientsHelper\r\n    (op.name, i, t_in.shape, in_grad.shape))\r\nValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: conv3d_transpose/conv3d_transpose.  Input index: 2. Original input shape: (?, 16, 4, 8, 16).  Calculated input gradient shape: (?, 16, 4, 16, 8)\r\n```", "comments": ["Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18376, "title": "Tensorflow MNIST Estimator: does the training batch size affect the graph expected input?", "body": "Hello Tensorflow team, \r\n\r\nFirst of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.\r\n\r\nI am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface. \r\nThe training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.\r\nI thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:\r\n ```python\r\ninput_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1], name=\"input_layer\")\r\n```\r\n\r\nHere is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.\r\n\r\n![image](https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png)\r\n\r\nAt first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.\r\n\r\nFirst of all I tried to test my model changing the amount of input samples using the Estimator interface:\r\n- I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).\r\n- I tried to use the estimator.predict method passing a single sample at a time.  \r\n\r\nIn these cases, everything worked fine.\r\n\r\nAfter that, I have frozen my model using the \"freeze_graph\" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.\r\nThis is the code I have used:\r\n```python\r\nimport tensorflow as tf\r\nimport cv2\r\nimport numpy as np\r\n\r\nwith tf.gfile.GFile(\"/path/to/my/frozen/model.pb\", \"rb\") as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    tf.import_graph_def(graph_def, name=\"prefix\")\r\n\r\n    for op in graph.get_operations():\r\n        print(op.name)\r\n\r\n    # so far it worked: i was able to print the operation of the MNIST model\r\n\r\n    x = graph.get_tensor_by_name('prefix/input_layer:0')\r\n    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        img = cv2.imread(\"/path/to/a/mnist/like/image.png\", cv2.IMREAD_GRAYSCALE)\r\n        img = np.asarray(1-img/255, dtype=np.float32)\r\n        img = np.reshape(img, (28, 28, 1))\r\n\r\n        y_out = sess.run(y, feed_dict={x: [img]})\r\n        print(y_out)\r\n```\r\n\r\nI got this error: **ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'**\r\n\r\nSo, I feel that I get problems if I try to use this model without passing through the Estimator interface.   \r\nThis worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).\r\n\r\n### Environment\r\n**Have I written custom code**: Yes, but only for testing purposes. My model was trained with this [MNIST tutorial code](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py) \r\n**OS Platform and Distribution**: MacOS High Sierra 10.13.3\r\n**TensorFlow installed from**: pip\r\n**TensorFlow version**: 1.7\r\n**Bazel version**: N/A\r\n**CUDA/cuDNN version**: N/A\r\n**GPU model and memory**: N/A\r\n**Exact command to reproduce**: N/A\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["An update on this issue.\r\n\r\nI have asked the same question on StackOverflow too ([here it is](https://stackoverflow.com/questions/49740247/tensorflow-mnist-estimator-batch-size-affects-the-graph-expected-input/49780607#49780607)), and I got the advice to use [`tf.placeholder_with_default`](https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default) in addition to tf.reshape. \r\n\r\nIn fact, tf.reshape does not seem to discard shape information for tensors when using value -1.\r\nUsing a placeholder there seems to solve my problem :)\r\n\r\nSo, firstly, do you suggest me to use a placeholder in this way? Are there any contraindications I should be aware of?  \r\n  \r\nSecondly, I suggest you to add this to your [MNIST tutorial](https://www.tensorflow.org/tutorials/layers) :) .\r\nIn fact, after learning how tf.reshape really works, the description about it in the tutorial is quite misleading: \r\n\r\n> Note that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features[\"x\"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features[\"x\"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1].\r\n\r\nMaybe you can add a more detailed footnote there?\r\n\r\nThank you :)\r\n", "Thanks!\r\nI think using `placeholder_with_default` seems reasonable, but may be a bit confusing for the basic tutorial.\r\n@allenlavoie Do you have thoughts on whether we should update the tutorial or how to better update the comment, since you replied to the SO question?", "The comment looks true to me; the graph building code works for any batch dimension. `features[\"x\"]` is the thing that should have an unknown batch dimension, not some reshape down the line. And you get that by using `export_savedmodel` with placeholders (or, if not using Estimator, by setting `features[\"x\"]` to a placeholder manually).", "Hi @allenlavoie, thanks for addressing this issue.\r\n\r\nCan you please give me more details about your answer?  The part I don't get is this:\r\n> features[\"x\"] is the thing that should have an unknown batch dimension, not some reshape down the line\r\n\r\nIn the MNIST tutorial code, this is the model function:\r\n\r\n```\r\ndef cnn_model_fn(features, labels, mode):\r\n  \"\"\"Model function for CNN.\"\"\"\r\n  # Input Layer\r\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n```\r\n\r\nSo `features` (and thus `features[\"x\"]`) is a parameter of the model function.\r\nAccording to the tutorial, the reshape is what sets the batch dimension as unknown.\r\nI thought that was the reason why it is *the very first* operation performed in the model function\r\n\r\nHow can I make features[\"x\"] have an unknown batch dimension since the beginning?\r\nI'm a bit confused :(", "`features` comes from the `input_fn`, in this case `numpy_input_fn`. Generally for export placeholders with unknown batch dimensions are provided by the [serving_input_receiver_fn](https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators).\r\n\r\nSo maybe the MNIST tutorial should cover or at least link to something about export? It's a reasonable feature request (but not something I'll have time to work on in the foreseeable future).", "We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!\r\n"]}, {"number": 18375, "title": "Using tensorflow lite invoke inference with multiple input tensors and specifying input node?", "body": "**System information**\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Ubuntu  16.04\r\nTensorFlow installed from: source:Yes\r\nTensorFlow version: 1.7.0\r\nPython version: 3.6\r\nBazel version: 0.11.1\r\nGCC/Compiler version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\n\r\n\r\n**Describe the problem**\r\n\r\nI converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])\r\n\r\nWhen invoke inference , I refer to \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md\r\nfloat* input = interpreter->typed_input_tensor<float>(0)\r\n\r\n**My question:**\r\nCan  I assign the data to specific input node  like tensorflow mobile method\r\nex: \r\n\r\nprivate static final String INPUT_DATA_NAME = \"decoded_sample_data:0\";\r\nprivate static final String SAMPLE_RATE_NAME = \"decoded_sample_data:1\"; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);\r\ninferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)\r\ninferenceInterface.run(outputScoresNames);\r\n\r\nThank you!\r\n\r\n\r\n \r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.9 LTS\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.6\r\nPython version: 3.6.1\r\nBazel version (if compiling from source):0.11\r\nGCC/Compiler version (if compiling from source):5.4.0\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nExact command to reproduce:", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Thanks!"]}]